{"text": "\\documentclass[preprint,3p]{elsarticle}\n\\biboptions{sort&compress}\n\n\\usepackage{hyperref}\n\n%---------------  numerara\u00e7\u00e3o das linhas do preprint  para o referee ----------\n\\usepackage[pagewise,mathlines]{lineno}\n%\\usepackage[pagewise,mathlines]{lineno}\n%\\newcommand*\\patchAmsMathEnvironmentForLineno[1]{%\n%\t\\expandafter\\let\\csname old#1\\expandafter\\endcsname\\csname #1\\endcsname\n%\t\\expandafter\\let\\csname oldend#1\\expandafter\\endcsname\\csname end#1\\endcsname\n%\t\\renewenvironment{#1}%\n%\t{\\linenomath\\csname old#1\\endcsname}%\n%\t{\\csname oldend#1\\endcsname\\endlinenomath}}%\n%\\newcommand*\\patchBothAmsMathEnvironmentsForLineno[1]{%\n%\t\\patchAmsMathEnvironmentForLineno{#1}%\n%\t\\patchAmsMathEnvironmentForLineno{#1*}}%\n%\\AtBeginDocument{%\n%\t\\patchBothAmsMathEnvironmentsForLineno{equation}%\n%\t\\patchBothAmsMathEnvironmentsForLineno{align}%\n%\t\\patchBothAmsMathEnvironmentsForLineno{flalign}%\n%\t\\patchBothAmsMathEnvironmentsForLineno{alignat}%\n%\t\\patchBothAmsMathEnvironmentsForLineno{gather}%\n%\t\\patchBothAmsMathEnvironmentsForLineno{multline}%\n%}\n\n%----------------------------------------------------------------\n\n\n\n%\\modulolinenumbers[0]\n\n\\journal{arXiv}\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%\n%% Elsevier bibliography styles\n%%%%%%%%%%%%%%%%%%%%%%%\n%% To change the style, put a % in front of the second line of the current style and\n%% remove the % from the second line of the style you would like to use.\n%%%%%%%%%%%%%%%%%%%%%%%\n\n%% Numbered\n%\\bibliographystyle{model1-num-names}\n\n%% Numbered without titles\n%\\bibliographystyle{model1a-num-names}\n\n%% Harvard\n%\\bibliographystyle{model2-names.bst}\\biboptions{authoryear}\n\n%% Vancouver numbered\n%\\usepackage{numcompress}\\bibliographystyle{model3-num-names}\n\n%% Vancouver name/year\n%\\usepackage{numcompress}\\bibliographystyle{model4-names}\\biboptions{authoryear}\n\n%% APA style\n%\\bibliographystyle{model5-names}\\biboptions{authoryear}\n\n%% AMA style\n%\\usepackage{numcompress}\\bibliographystyle{model6-num-names}\n\n%% `Elsevier LaTeX' style\n\\bibliographystyle{elsarticle-num}\n%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\n\\usepackage{amsfonts}\n\\usepackage{amssymb}\n\\usepackage[utf8]{inputenc}\n\\usepackage{amsmath}\n\\usepackage{amsthm}\n\\usepackage{graphicx}%\n%\\usepackage{hyperref}\n\\usepackage{enumerate}\n\\usepackage{xcolor}\n\\usepackage{color,soul}\n\\usepackage{tikz}\n\\usetikzlibrary{patterns}\n\\usepackage{mathtools}\n\n\n\n%\\setlength{\\textwidth}{16cm}\n%\\setlength{\\textheight}{20 cm}\n%\\addtolength{\\oddsidemargin}{-1.5cm}\n%\\addtolength{\\evensidemargin}{-1.5cm}\n\n%\\usepackage[notcite,notref]{showkeys}\n\n\n\\newtheorem{thm}{Theorem}[section]\n\\newtheorem{cor}[thm]{Corollary}\n\\newtheorem{lem}[thm]{Lemma}\n\\newtheorem{prop}[thm]{Proposition}\n%\\newtheorem{assumption}{A.\\!}\n\n\n%\\newtheorem{rem}{Remark}\n\n\\newtheorem*{assumption*}{\\assumptionnumber}\n\\providecommand{\\assumptionnumber}{}\n\\makeatletter\n\\newenvironment{assumption}[1]\n{%\n\t\\renewcommand{\\assumptionnumber}{A.#1}%\n\t\\begin{assumption*}%\n\t\t\\protected@edef\\@currentlabel{A.#1}%\n\t}\n\t{%\n\t\\end{assumption*}\n}  \n\n\n\n\\theoremstyle{definition}\n\\newtheorem{defn}[thm]{Definition}\n\\theoremstyle{remark}\n\\newtheorem{rem}[thm]{Remark}\n\\newtheorem*{ex}{Example}\n\\numberwithin{equation}{section}\n\n\n\\newcommand{\\ep}{\\varepsilon}\n\\newcommand{\\eps}[1]{{#1}_{\\varepsilon}}\n%\\newcommand{\\rz}{\\rho_1}\n\\newcommand{\\rzn}{\\rho_{0,n}}\n\\newcommand{\\re}{\\rho_3}\n\\newcommand{\\ren}{\\rho_{\\ast,n}}\n\\newcommand{\\rc}{\\rho_2}\n\\newcommand{\\ac}{\\hat{A}}\n\\newcommand{\\X}[2]{L_{#2}^{#1}}\n\n\n\\newcommand{\\R}{\\mathbb{R}}\t\t\t\t      % conjunto dos reais\n\n\n\\newcommand{\\lnum}{ }\n\\newcommand{\\dps}{\\displaystyle}\t\n\\newcommand{\\intq}{\\int_0^T\\int_0^1}\t\n\\newcommand{\\intw}{\\int_0^T\\int_{\\omega}}\t\n\\newcommand{\\intwl}{\\int_0^T\\int_{\\omega'}}\t\n\\newcommand{\\into}{\\int_0^1}\t\n\\newcommand{\\inta}{\\int_0^T\\int_0^{\\alpha'}}\n\\newcommand{\\intb}{\\int_0^T\\int_{\\beta'}^1}\n\\newcommand{\\dom}{Q}\n\\newcommand{\\domw}{Q_\\omega}\n\\newcommand{\\nd}[1]{\\|#1\\|_{L^2(0,1)}}\n\\newcommand{\\nn}[1]{\\|#1\\|}\n%\\newcommand{\\n}[1]{\\|#1\\|}\n\\newcommand{\\ny}[1]{\\|#1\\|_E}\n\\newcommand{\\bu}{\\bar{u}}\n\\newcommand{\\bh}{\\bar{h}}\n\\newcommand{\\nf}[1]{\\left\\|#1\\right\\|_{\\rho_{0}^{2}}}\n\\newcommand{\\gu}{\\ell\\left(\\into u\\right)}\n\\newcommand{\\gbu}{\\ell\\left(\\into \\bu\\right)}\n\\newcommand{\\bl}{b_\\lambda}\n\\newcommand{\\fl}{f_\\lambda}\n\n\\newcommand{\\wei}{e^{2s\\varphi}}\n\n\n\n\\newcommand{\\n}[2]{\\|#1\\|_{_{#2}}}\n\n\\newcommand{\\G}[1]{\\int_0^T\\int_0^1e^{2sA}\\left[s\\lambda\\zeta a |#1_x|^2+(s\\lambda)^{5/3}\\zeta^{5/3} |#1|^2 \\right]  }\n\\newcommand{\\Ga}[1]{\\int_0^{T/2}\\int_0^1e^{2sA}\\left[s\\tau a#1_x^2+(s\\tau)^3\\frac{x^2}{a}#1^2\\right]  }\n\\newcommand{\\Gb}[1]{\\int_{T/2}^{T}\\int_0^1e^{2sA}\\left[s\\tau a#1_x^2+(s\\tau)^3\\frac{x^2}{a}#1^2\\right]  }\n\\newcommand{\\I}[1]{\\int_0^T\\int_0^1e^{2s\\varphi}\\left((s\\theta)a(x)#1_x^2+(s\\theta)^3\\frac{x^2}{a(x)}#1^2\\right)  }\n\n\\newcommand{\\rhat}{\\hat{\\rho}}\n\\newcommand{\\rast}{\\rho_\\ast}\n\\newcommand{\\rhoi}[1]{\\rho_{_{#1}}}\n\\newcommand{\\rz}{\\rho_0}\n\\newcommand{\\zast}{{\\zeta^\\ast}}\n\n\n\\newcommand{\\E}{E}\n\\newcommand{\\F}{F}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\n\n%------------- notes ----------------\n\\usepackage[textsize=scriptsize,textwidth=15mm]{todonotes}\n\\usepackage{marginnote}\n%\\usepackage{authblk}\n\\makeatletter\n\\renewcommand{\\@todonotes@drawMarginNoteWithLine}{%\n\t\\begin{tikzpicture}[remember picture, overlay, baseline=-0.75ex]%\n\t\\node [coordinate] (inText) {};%\n\t\\end{tikzpicture}%\n\t\\marginnote[{% Draw note in left margin\n\t\t\\@todonotes@drawMarginNote%\n\t\t\\@todonotes@drawLineToLeftMargin%\n\t}]{% Draw note in right margin\n\t\t\\@todonotes@drawMarginNote%\n\t\t\\@todonotes@drawLineToRightMargin%\n\t}%\n}\n\\makeatother\n%----------------------------------------------------------------------\n\n\n\\allowdisplaybreaks[1] % permite quebra de p\u00e1ginas em equa\u00e7\u00f5es\n\n\\raggedbottom \n\n\n\n\n\n\n\\begin{document}\n\n\\begin{frontmatter}\n\n\\title{\\textsc{carleman inequality for a linear degenerate parabolic problem}}\n\n\n\t\\author[RCN]{R. Demarque\\corref{mycorrespondingauthor}}\n\\cortext[mycorrespondingauthor]{Corresponding author}\n\\ead{reginaldo@id.uff.br}\n\n%% or include affiliations in footnotes:\n\n\\author[GMA]{J. L\u00edmaco}\n\\ead{jlimaco@id.uff.br}\n\n\\author[GAN]{L. Viana}\n\\ead{luizviana@id.uff.br}\n\n\n\n\n\n\n\n\\address[RCN]{Departamento de Ci\u00eancias da Natureza,\n\tUniversidade Federal Fluminense,\n\tRio das Ostras, RJ, 28895-532, Brazil}\n\\address[GMA]{  Departamento de Matem\u00e1tica Aplicada,\n\tUniversidade Federal Fluminense,\n\tNiter\u00f3i, RJ, 24020-140, Brazil}\n\\address[GAN]{Departamento de An\u00e1lise,\n\tUniversidade Federal Fluminense,\n\tNiter\\'{o}i, RJ, 24020-140, Brazil}\n\n\\begin{abstract}\nIn this work, we prove a Carleman estimate for a parabolic problem which has a dissipative degenerate term. The prove relies on choose  a suitable  weight function that change of sign inside the control domain.\n\\end{abstract}\n\n\\begin{keyword}\nDegenerate parabolic equations\\sep Controllability \\sep  Carleman Inequaility\n\\MSC[2020]{Primary 35K65, 93B05; Secondary  93C20}\n\\end{keyword}\n\n\\end{frontmatter}\n\n%\\linenumbers\n\n\n\t\n\\section{Introduction\\label{intro}}\n\n\n\n\\noindent \n\nLet us consider the degenerate parabolic problem\n\\begin{equation}\\lnum \\label{pb-lin}\n\\left\\{\\begin{array}{ll}\nu_t-\\left(a\\left(x\\right)u_x \\right)_x+c(t,x)u=h\\chi_\\omega, & (t,x)\\in \\dom; \\\\\n\\begin{cases*}\nu(t,0)=0, & \\\\\n\\text{or}\\\\\n(au_x)(t,0)=0,& \n\\end{cases*},&  t\\in (0,T), \\\\\nu(0,x)=u_0(x),& x\\in (0,1),\n\\end{array}\\right.\n\\end{equation}\nwhere $T>0$ is given, $\\dom:=(0,T)\\times (0,1)$, $\\omega=(\\alpha,\\beta)\\subset\\subset (0,1)$, $u_0\\in L^2(0,1)$ and $h\\in L^2(\\domw)$ is a control that acts on the system through $\\domw:=(0,T)\\times \\omega$.  We also specify some properties of $a$.\n\n\n\\begin{assumption}{1} \\label{hip1}\n\tLet  $a \\in C([0,1])\\cap C^1((0,1])$ be a nondecreasing function satisfying $a(0)=0$ and $a>0$ on $(0,1]$. Additionally, we suppose that there exist a $K\\in \\R$ such that  \n\t\\begin{equation}\\label{prop_a}\n\txa'(x)\\leq Ka(x),\\ \\ \\forall x\\in [0,1],\n\t\\end{equation}\n\twhere $K\\in [0,1)$, for the \\textbf{Weak Degeneracy Case} (WDC), and $K\\in [1,2)$, for the \\textbf{Strong Degeneracy} one (SDC). Only for the $(SDC)$, we also assume that\n\t\\begin{equation}\\label{teta}\n\t\\begin{cases}\n\t\\exists \\theta \\in (1,K] \\text{ such that } \\theta a\\leq xa' \\text{ near zero, if } K>1;\\\\\n\t\\exists \\theta \\in (0, 1)  \\text{ such that } \\theta a\\leq xa' \\text{ near zero, if } K=1.\\\\\n\t\\end{cases}\n\t\\end{equation}\n\\end{assumption}\t\n\nUnder these notations, we provide some examples and comments about Hypotheses \\ref{hip1}.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\begin{ex} \n\t\\noindent \n\t\n\t\\begin{itemize}\n\t\t\\item[(a)] Take $\\gamma \\in (0,1)$ and $\\alpha \\geq 0$. Putting $\\beta = \\arctan (\\alpha)$, the function $a_{1} (x) = x^{\\gamma} \\cos (\\beta x)$ fulfills \\eqref{prop_a} for the (WDC). On the other hand, if $\\gamma \\in (1,2)$, then $a_1$ becomes an example for the (SDC); \n\t\t\n\t\t\\item[(b)] For each $\\theta \\in (0,1)$, the function $a_{2} (x) = x^{\\theta} - x$ satisfies \\eqref{prop_a} for the (WDC). However, if $\\theta \\in (1,2)$, then $a_{3} (x) = x^{\\theta} + x$ satisfies \\eqref{prop_a} for the (SDC).\n\t\\end{itemize}\n\\end{ex}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\n\n%Notice that if $p:[0,1]\\to \\hlm{[0,+\\infty)}$ is a  %nonincreasing $C^1$ function, then  $a(x):=x^\\alpha %p(x)$, with $\\alpha \\in (0,1)$, satisfies %(\\ref{prop_a}).\n\n\n\nIt is well known that the null-controllability for \\eqref{pb-lin} is a consequence of an Observability inequality which in turn is a consequence of a Carleman Estimate for the following adjoint system associated to \\eqref{pb-lin}\n\\begin{equation}\\lnum \\label{adj-jlr}\n\\left\\{\\begin{array}{ll}\nv_t+\\left(a\\left(x\\right)v_x \\right)_x+c(t,x)v=F, & (t,x)\\in \\dom, \\\\\n\\begin{cases*}\nv(t,0)=0, & \\\\\n\\text{or}\\\\\n(av_x)(t,0)=0,& \n\\end{cases*},&  t\\in (0,T), \\\\\nv(T,x)=v_T(x), & x\\in (0,1),\n\\end{array}\\right.\n\\end{equation}\nwhere $F\\in L^2(\\dom)$ and $v_T\\in L^2(0,1)$. \n\nAlabau-Boussouira et al.  obtained a Carleman inequality to \\eqref{adj-jlr} in \\cite{alabau2006carleman} and proved null-controllability results to the linear and semilinear problems. However, their Carleman inequality can not be used to proved other controllability results with the same kind of degeneracy, for instance Stalkelberg-Nash null controllability  or null-controllability for nonlinear problems.\n\nAraruna et al.  \\cite{araruna2018stackelberg} proved a new Carleman estimate to \\eqref{adj-jlr} when $a(x)=x^\\alpha$, $\\alpha \\in (0,2)$ and proved a Stalkelberg-Nash null controllability result. In order to do that they  choose  a suitable  weight function that change of sign inside the control domain. Following this ideas, in \\cite{jrl2016,jrl2020EECT}, the authors extended their Carleman Inequality for a general $a=a(x)$ satisfying hypotheses \\eqref{A1}, but just for the weak case, and proved a null-controllability result for a degenerate problem with nonlocal nonlinearities. The aim of the present work is extend the Carleman Inequality proved in \\cite{jrl2016} to the strong case. \n\n In order to state our main result let us  consider $\\omega'=(\\alpha',\\beta')\\subset\\subset \\omega$ and $\\psi \\in C^2 ([0,1];\\R )$ satisfying  \n\\begin{align}\\label{functions1}\n\\psi(x):=\\begin{cases}\n\\displaystyle \\phantom{-}\\int_0^x \\frac{y}{a(y)}dy,\\ x\\in [0,\\alpha') \\vspace{.2cm} \\\\\n\\displaystyle -\\int_{\\beta'}^x \\frac{y}{a(y)}dy,\\ x\\in [\\beta',1].\n\\end{cases}\n\\end{align}\nSetting\n\\begin{multline}\\label{functions}\n\\theta(t):=\\frac{1}{[t(T-t)]^4}, \\ \\eta(x):=e^{\\lambda(|\\psi|_\\infty+\\psi)},\\ \\sigma(x,t):=\\theta(t)\\eta(x) \\mbox{ and }\\\\\n\\varphi(x,t):=\\theta(t)(e^{\\lambda(|\\psi|_\\infty+\\psi)}-e^{3\\lambda|\\psi|_\\infty}),\n\\end{multline}\nwhere $(t,x) \\in (0,T)\\times [0,1]$ and $\\lambda >0$.\n\n\\begin{thm}[Carleman Inequality]\\label{car-strong}\n\tThere exist $C>0$ and $\\lambda_0,s_0>0$ such that every solution  $v$ of (\\ref{adj-jlr}) satisfies, for all $s\\geq s_0$ and $\\lambda\\geq \\lambda_0$,\n\t\\begin{equation}\n\t\\intq e^{2s\\varphi}\\left((s\\lambda)\\sigma av_x^2+(s\\lambda)^{5/3}\\sigma^{5/3}v^2 \\right) \n\t\\leq C\\left(\\intq e^{2s\\varphi}|F|^2\\   +(\\lambda s)^{3}\\intw e^{2s\\varphi}\\sigma^{3}v^{2}\\   \\right),\\label{carl_jlr}\n\t\\end{equation}\n\twhere the constants $C, \\lambda_0,s_0$  only depend on $\\omega$, $a$, $\\n{c}{L^\\infty(\\dom)}$ and $T$.\n\\end{thm}\n\n\n\n\\section{Preliminary Results}\n\n\\noindent\n\n\nIn this section we will  state some notations and results which are necessary to prove Theorem \\ref{car-strong}. At first, we need to introduce some weighted spaces related to the function $a$,  namely\n\n\\begin{defn} [Weighted Sobolev spaces]\n\tLet us consider a real function $a=a(x)$ as in Hypotheses $A$.\n\t\n\t\\begin{itemize}\n\t\t\\item[(I)] For the (WDC), we set \n\t\t\\begin{align*}\n\t\t& \\begin{multlined}[t][0.9\\textwidth]\n\t\tH_a^1:= \\{  u\\in L^2(0,1);\\ u\\mbox{ is absolutely continuous in } [0,1],\\\\\n\t\t\\sqrt{a}u_x\\in L^2(0,1) \\mbox{ and } u(1)=u(0)=0\\},\n\t\t\\end{multlined}\\\\\t\n\t\t\\end{align*}\n\t\tequipped with the natural norm\n\t\t\\[ \\|u\\|_{H_a^1}:=\\left( \\|u\\|_{L^2(0,1)}^2+\\|\\sqrt{a}u_x\\|_{L^2(0,1)}^2 \\right) ^{1/2} .\\]\n\t\t\n\t\t\\item[(II)] For the (SDC),\n\t\t\\begin{align*}\n\t\t& \\begin{multlined}[t][0.9\\textwidth]\n\t\tH_a^1:= \\{  u\\in L^2(0,1);\\ u\\mbox{ is absolutely continuous in } (0,1],\\\\\n\t\t\\sqrt{a}u_x\\in L^2(0,1) \\mbox{ and } u(1)=0\\},\n\t\t\\end{multlined}\\\\\n\t\t\\end{align*}  \n\t\tand the norm keeps the same;\n\t\t\n\t\t\\item[(III)] In both situations, the (WDC) and the (SDC), \n\t\t\\[\n\t\tH_a^2:= \\{  u\\in H_a^1;\\ au_x\\in H^1(0,1) \\}\n\t\t\\]\n\t\twith the norm\n\t\t$\\|u\\|_{H_a^2}:=\\left( \\|u\\|_{H_a^1}^2+\\|(au_x)_x\\|_{L^2(0,1)}^2 \\right) ^{1/2}$. \n\t\\end{itemize}\n\\end{defn}\t\n\n\nAlabau-Boussouira at al. in \\cite{alabau2006carleman} introduced and studied some of the main properties of these spaces.\n\nNow, we will state  a Hardy-Poincar\u00e9 type inequality, whose proof can be found in \\cite{alabau2006carleman}. It represents a powerful estimate in order to hand the degeneracy of the function $a$, related to \\eqref{pb-lin}.\n\\begin{prop}[Hardy-Poincar\u00e9 Inequality]\\label{prop-HP}\n\tLet $\\tilde{a} :[0,1]\\longrightarrow \\R$ be a continuous  function such that $\\tilde{a} (0)=0$ and $\\tilde{a} >0$ in $(0,1]$. The following statements hold:\n\t\\begin{itemize}\n\t\t\\item[(a)] If there exists $\\theta \\in (0,1)$ such that  the function $x\\mapsto a(x)/x^\\theta$ is nonincreasing in $(0,1]$, then there exists a constant $C_H>0$ such that \n\t\t\\begin{equation}\\label{HP_ineq}\n\t\t\\into\\frac{a(x)}{x^2}w^2(x)  \\leq C_H\\into a(x)|w'(x)|^2  ,\n\t\t\\end{equation}\n\t\tfor any real function $w$ that is locally absolutely continuous on $(0,1]$, continuous at $0$, and satisfies\n\t\t\\begin{center}\n\t\t\t$w(0)=0$ and $\\dps\\into a(x)|w'(x)|^2\\   <+\\infty$.\n\t\t\\end{center}\n\t\t\\item[(b)] \tIf there exists $\\theta\\in (1,2)$ such that the function $x\\mapsto a(x)/x^\\theta$ is nondecreasing in a neighborhood of $x=0$, then there exists a constant $C_H>0$ such that \\eqref{HP_ineq} is valid for any function $w$\n\t\tthat is locally absolutely continuous in $(0,1]$, and satisfies\n\t\t\\[w(1)=0\\ \\text{ and } \\int_0^1 a(x)|w'|^2<+\\infty.\\]\n\t\\end{itemize}\n\\end{prop}\n\n\n\\begin{rem}\\label{rem21} \n\tNotice that Hypothesis \\ref{hip1} implies some other useful conditions:\n\t\n\t\\begin{enumerate}\n\t\t\\item[(a)]  The relation \\eqref{prop_a} means that the function $x\\mapsto \\frac{x^r}{a(x)}$ is nondecreasing on $(0,1]$, for all $r\\geq K$, not only for the (WDC), but also for the $(SDC)$. In particular, $\\dps x^2/a(x)\\leq 1/a(1)$, for all $x\\in (0,1]$.\n\t\t\n\t\t\n\t\t\\item[(b)] Particularly for the (SDC), the assumption \\eqref{teta} means that the function $x\\mapsto \\frac{a(x)}{x^\\theta}$  is nondecresing.\n\t\t\n\t\t\n\t\\end{enumerate}\n\\end{rem}\n\n\n\n The wellposednes of \\eqref{pb-lin}, established in \\cite{alabau2006carleman}, is the following: \n\n\\begin{prop}\\label{prop-WP-lin}\n\tFor all $h\\in L^2(\\domw)$ and $u_0\\in L^2(0,1)$, there exists a unique weak solution $u\\in C^0([0,T];L^2(0,1))\\cap L^2(0,T;H_a^1)$ of \\eqref{pb-lin}.\n\tMoreover, if $u_0\\in H_a^1$, then\n\t\\[u\\in\\mathcal{U}:= H^1(0,T;L^2(0,1))\\cap L^2(0,T;H_a^2)\\cap C^0([0,T];H_a^1), \\]\n\tand there exists a positive constant $C_T$ such that\n\t\\begin{equation}\\label{ineq1}\n\t\\sup_{t\\in[0,T]}\\left(\\n{u(t)}{H_a^1}^2\\right)\n\t+\\int_0^T\\left(\\n{u_t}{L^2(0,1)}^2+\\n{(au_x)_x}{L^2(0,1)}^2\\right)\n\t\\leq C_T\\left(\\n{u_0}{H_a^1}^2 +\\n{h}{L^2(\\domw)}^2 \\right)\n\t\\end{equation}\n\\end{prop}\n\n\n\n\n\n\n\n\\section{Proof of Theorem \\ref{car-strong}} \n\\noindent\n\nWe start proving a Carleman inequality for the following problem\n\\begin{equation}\\lnum \\label{pbA1}\n\\left\\{\\begin{array}{ll}\nv_t+\\left(a\\left(x\\right)v_x \\right)_x=h(t,x), & (t,x)\\in \\dom, \\\\\nv(t,1)=0,&  t\\in  (0,T),\\\\\n\\begin{cases*}\nv(t,0)=0, & \\text{ (Weak) }\\\\\n\\text{or}\\\\\n(av_x)(t,0)=0,&  \\text{ (Strong) }\n\\end{cases*},&  t\\in (0,T). \\\\\n\\end{array}\\right.   \\end{equation}\n\n\n\\begin{prop} \\label{propA1}\n\tThere exist $C>0$ and $\\lambda_0,s_0>0$ such that every solution  $v$ of (\\ref{pbA1}) satisfies, for all $s\\geq s_0$ and $\\lambda\\geq \\lambda_0$, \n\t\\begin{equation}\\label{car-A2}\n\t\\intq e^{2s\\varphi}\\left((s\\lambda)\\sigma av_x^2+(s\\lambda)^{5/3}\\sigma^{5/3}v^2 \\right) \\leq C\\left(\\intq e^{2s\\varphi}|h|^2\\   +(\\lambda s)^3\\intw e^{2s\\varphi}\\sigma^3v^2\\   \\right)\n\t\\end{equation} \n\t\n\\end{prop}\n\nWe just need to prove this proposition  for the Strong case, since the inequality \\eqref{car-A2} is a consequence of that proved in \\cite{jrl2016}. In the Strong case, the proof is essentially the same, we just pay attention to the case in which $K=1$. Actually, we just have to present a new proof of  Lemma A.9 of \\cite{jrl2016}, the other lemmas remain the same. However, for the sake of convenience, we will reproduce the entire proof here.\n\nThe proof of Proposition \\ref{propA1} relies on the change of variables $w=e^{s\\varphi}v$. Notice that\n\\begin{align*}\n& v_t=e^{-s\\varphi}(-s\\varphi_tw+w_t),\\\\\n& (av_x)_x=e^{-s\\varphi}(s^2\\varphi^2_xaw-s(a\\varphi_x)_xw-2sa\\varphi_xw_x+(aw_x)_x).\n\\end{align*} \nThen, from \\eqref{pbA1}, we obtain \n\n\\[\\begin{cases}\nL^+w+L^-w=e^{s\\varphi}h,  & (t,x)\\in \\dom, \\\\\nw(t,1)=0,&  t\\in  (0,T),\\\\\n\\begin{cases*}\nw(t,0)=0, & \\text{ (Weak) }\\\\\n\\text{or}\\\\\n(aw_x)(t,0)=0,&  \\text{ (Strong) }\n\\end{cases*},&  t\\in (0,T), \\\\\nw(x,0)=w(x,T)=0, & x\\in (0,1),\n\\end{cases}\\]\nwhere\n\\[L^+w:=-s\\varphi_t w+s^2\\varphi_x^2aw+(aw_x)_x,\\]\n\\[L^-w:=w_t-s(a\\varphi_x)_xw-2sa\\varphi_xw_x.\\]\n\nIn this way,\n\\[\\|L^+w\\|^2+\\|L^-w\\|^2+2(L^+w,L^-w)=\\|e^{s\\varphi}h\\|^2,\\]\nwhere $\\|\\cdot\\|$ and $(\\cdot,\\cdot)$ denote the norm and the inner product in $L^2(\\dom)$, respectively.\n\nFrom now on, we will prove  Lemmas \\ref{A1}--\\ref{A18}. The proof of Proposition \\ref{propA1} will be a consequence of these lemmas.\n\\begin{lem}\\label{lemA2}\n\t\\begin{multline*}\n\t(L^+w,L^-w)  =\\frac{s}{2}\\intq\\varphi_{tt}w^2-2s^2\\intq \\varphi_{tx}a\\varphi_xw^2 +s^3\\intq a\\varphi_x(a\\varphi_x^2)_xw^2\\\\\n\t+s\\intq(a\\varphi_x)_{xx}aww_x\n\t+ 2s\\intq(a\\varphi_x)_xaw_x^2\\\\ -s\\intq a\\varphi_xa_xw_x^2 -s\\int_0^T(a^2\\varphi_xw_x^2)\\big\\vert_{x=0}^{x=1}\n\t\\end{multline*}\n\\end{lem}\n\\begin{proof}\n\tFrom the definition of $L^+w$ and $L^-w$ we have\n\t\\begin{align*}\n\t(L^+w,L^-w) = & \\intq (-s\\varphi_tw+s^2\\varphi_x^2aw+(aw_x)_x)w_t +s^2\\intq\\varphi_tw((a\\varphi_x)_xw+2a\\varphi_xw_x)\\\\\n\t& -s^3\\intq \\varphi^2_xaw((a\\varphi_x)_xw+2a\\varphi_xw_x) -s\\intq(aw_x)_x((a\\varphi_x)_xw+2a\\varphi_xw_x)\\\\\n\t\\phantom{(L^+w,L^-w)} = & I_1+I_2+I_3+I_4.\n\t\\end{align*}\n\t\n\tIntegrating by parts, we obtain\n\t\\[I_1=\\frac{s}{2}\\intq(\\varphi_{tt}-2sa\\varphi_x\\varphi_{xt})w^2,\\]\n\t\\[I_2=-s^2\\intq \\varphi_{tx}a\\varphi_xw^2,\\]\n\t\\[I_3=s^3\\intq a\\varphi_x(a\\varphi_x^2)_xw^2\\]\n\tand\n\t\\begin{equation*} I_4=s\\intq(a\\varphi_x)_{xx}aww_x+2s\\intq(a\\varphi_x)_xaw_x^2\n\t-s\\intq(a\\varphi_x)a_xw_x^2-s\\int_0^T(a^2\\varphi_xw_x^2)\\big\\vert_{x=0}^{x=1},\n\t\\end{equation*}\n\twhich imply the desired result.\n\t\n\t\n\\end{proof}\n\\begin{lem}\\label{A1}\n\t$\\dps-s\\int_0^Ta^2\\varphi_xw_x^2\\big\\vert_{x=0}^{x=1}\\geq 0$\n\\end{lem}\n\\begin{proof} Since $\\psi'(x)=x/a$, if $x\\in [0,\\alpha')$ and $\\psi'(x)=-x/a$, if $x\\in (\\beta'1]$, we have\n\t\\begin{align*} \n\t-s\\int_0^Ta^2\\varphi_xw_x^2\\big\\vert_{x=0}^{x=1}=-s\\lambda\\int_0^Ta^2\\psi'\\sigma w_x^2\\big\\vert_{x=0}^{x=1}\\geq 0.\n\t\\end{align*}\n\t\n\\end{proof}\n%\n\\begin{lem}\\label{A2}\n\t\n\t\\begin{equation*}\n\ts^3\\intq a\\varphi_x(a\\varphi_x^2)_xw^2\\geq C \\lambda^4s^3\\intq a^2|\\psi'|^4\\sigma^3w^2-Cs^3\\lambda^3\\intwl \\sigma^3w^2\n\t+Cs^3\\lambda^3\\inta\\frac{x^2}{a}\\sigma^3w^2.\n\t\\end{equation*}\n\\end{lem}\n\\begin{proof} Firstly, we observe that\n\t\\begin{align*}\n\ts^3\\intq a\\varphi_x(a\\varphi_x^2)_xw^2 &= s^3\\lambda^3\\intq a\\psi'(a(\\psi')^2)_x\\sigma^3w^2 +2s^3\\lambda^4\\intq a^2(\\psi')^4\\sigma^3w^2\\\\\n\t& = I_1+I_2.\n\t\\end{align*}\n\t\n\t\n\tWe can see that\n\t\\[a\\psi'(a(\\psi')^2)_x=\\begin{cases}\n\t\\phantom{-}\\frac{x^2}{a^2}(2a-xa'), & x\\in (0,\\alpha')\\\\\n\t-\\frac{x^2}{a^2}(2a-xa'), & x\\in (\\beta',1),\n\t\\end{cases}\\]\n\tand \\eqref{prop_a} implies $2a-xa'\\geq (2-K)a$. Hence,\n\t\\begin{align*}\n\tI_1 &=\\begin{multlined}[t]\n\ts^3\\lambda^3\\inta a\\psi'(a(\\psi')^2)_x\\sigma^3w^2+s^3\\lambda^3\\intwl a\\psi'(a(\\psi')^2)_x\\sigma^3w^2\\\\+s^3\\lambda^3\\intb a\\psi'(a(\\psi')^2)_x\\sigma^3w^2\n\t\\end{multlined}\t\\\\\n\t& \\geq (2-K) s^3\\lambda^3\\inta \\frac{x^2}{a}\\sigma^3w^2-Cs^3\\lambda^3\\intwl\\sigma^3w^2\n\t-C(2-K)s^3\\lambda^3\\intq a^2|\\psi'|^4\\sigma^3w^2\n\t\\end{align*}\n\t\n\tWe just sum $I_1$ and $I_2$,  and take $\\lambda_0$ large  enough to obtain the desired inequality.\n\t\n\\end{proof}\n\n\\begin{lem}\\label{A3}\n\t\\noindent \n\t\n\t\\begin{equation*}\\dps 2s\\intq(a\\varphi_x)_xaw^2_x\\geq -C\\intwl \\sigma w_x^2+Cs\\lambda^2\\intq a^2(\\psi')^2\\sigma w_x^2\n\t+2s\\lambda\\inta a\\sigma w_x^2\n\t\\end{equation*}\n\\end{lem}\n%\n\\begin{proof} Observe that\n\t\\begin{equation}\\label{ast}\n\t2s\\intq(a\\varphi_x)_xaw^2_x=2s\\intq\\lambda(a\\psi')_xa\\sigma w_x^2\n\t+2s\\lambda^2\\intq a^2(\\psi')^2\\sigma w_x^2\n\t\\end{equation}\n\t\n\tProceeding as in lemma before, we split the first integral over the intervals $[0,\\alpha'], \\omega'$ and $[\\beta',1]$. Since $a^2(\\psi')^2\\geq Ca$ in  $[\\beta',1]$ we can add the integral over $[\\beta',1]$ to the last integral of \\eqref{ast}, which gives us the result.\n\t\n\\end{proof}\n%\n%\n\\begin{lem}\\label{A4}\n\t\\begin{equation*}\\dps-2s^2\\intq\\varphi_{tx}a\\varphi_xw^2\\geq -Cs^2\\lambda^2\\left(\\inta \\frac{x^2}{a}\\sigma^3w^2+\\intwl\\sigma^3w^2\\right.\n\t+\\left.\\intq a^2|\\psi'|^4\\sigma^3w^2\\right)\n\t\\end{equation*}\n\\end{lem}\n%\n%\n\\begin{proof} First of all,\n\t\\begin{equation*}\n\t\\left|2s^2\\intq \\varphi_{tx}a\\varphi_xw^2\\right|\\leq 2s^2\\lambda^2\\intq a|\\psi'|^2|\\theta \\theta'|\\eta^2 w^2\n\t\\leq Cs^2\\lambda^2\\intq a|\\psi'|^2\\sigma^3 w^2\n\t\\end{equation*}\n\t\n\tAs before, we split the last integral over the   intervals $[0,\\alpha'], \\omega'$ and $[\\beta',1]$. The result comes from the boundedness of $a|\\psi'|^2$  in $\\omega'$ and from relations  $\\psi'= x/a$ in $[0,\\alpha']$ and $a|\\psi'|^2\\leq Ca^2|\\psi'|^4$ in $[b',1]$.\n\t\n\\end{proof}\n\n\\begin{lem}\\label{A5}\n\t\\[-s\\intq a\\varphi_x a_xw_x^2\\geq -K\\lambda s \\inta a\\sigma w_x^2-c\\lambda s \\intwl \\sigma w_x^2\\]\n\\end{lem}\n\n\\begin{proof} In fact, from the definition of $\\psi$, we obtain\n\t\\begin{align*} \n\t-s\\intq a\\varphi_x a_xw_x^2& =-s\\lambda \\intq aa_x\\psi'\\sigma w_x^2\\\\\n\t& \\geq -Ks\\lambda \\inta a\\sigma w_x^2-C\\lambda s\\intwl \\sigma w_x^2,\n\t\\end{align*}\n\twhere we proceeded as in the proof of Lemma \\ref{A4}.\n\\end{proof}\n%\n\\begin{lem}\\label{A9} \n\t\\begin{multline*}\n\ts\\intq (a\\varphi_x)_{xx}aw_xw \\geq   -Cs^2\\lambda^4 \\intq a^2|\\psi'|^4 \\sigma^3w^2-C\\lambda^2 \\intq a^2|\\psi'|^2\\sigma w_x^2\\\\ -Cs^2\\lambda^3 \\intwl \\sigma^3w^2\n\t-C\\lambda\\intwl \\sigma w_x^2\\\\\n\t-Cs^2\\lambda^3\\inta \\frac{x^2}{a}\\sigma^3w^2-C\\lambda \\inta a \\sigma w_x^2\n\t\\end{multline*}\n\\end{lem}\n\n\\begin{proof}\n\t\\begin{align*}\n\ts\\intq (a\\varphi_x)_{xx}aw_xw &  =s\\lambda\\intwl (a\\psi')_{xx}a\\sigma w_xw +2s\\lambda^2\\intq (a\\psi')_{x}\\psi'a\\sigma w_xw \\\\\n\t&  +s\\lambda^2\\intq a^2\\psi'\\psi''\\sigma w_xw  +s\\lambda^3\\intq a^2(\\psi')^3\\sigma w_xw\\\\\n\t& =I_1+I_2+I_3+I_4.\n\t\\end{align*}\n\t\n\tThe inequality will be obtained by estimating each one of these fours integrals. For $I_1$, we have\n\t\\begin{align*}\n\t|I_1|& =\\left|s\\lambda\\intwl (a\\psi')_{xx}a\\sigma w_xw\\right|\\leq Cs\\lambda\\intwl \\sigma^2 |w_xw|\\\\\n\t& =Cs\\lambda\\intwl \\sigma^{3/2}|w|\\sigma^{1/2} |w_x|\\leq Cs\\lambda\\intwl \\sigma^3 w^2+Cs\\lambda\\intwl \\sigma w_x^2.\n\t\\end{align*}\n\t\n\tFor $I_2$, we use the facts $\\sigma\\leq C\\sigma^2$ and $x\\leq Ca^2|\\psi'|^3$ in $[\\beta',1]$ to obtain\n\t\\begin{align*}\n\t|I_2| & \\leq Cs\\lambda^2\\inta x\\sigma^2 |w w_x|+ Cs\\lambda^2\\intwl \\sigma^2 |w w_x|\n\t+Cs\\lambda^2\\intb a^2|\\psi'|^3\\sigma^2 |ww_x|\\\\\n\t&\\leq  C\\inta \\left(\\frac{x}{\\sqrt{a}}\\sigma^{3/2}\\lambda^{3/2}s|w|\\right)(\\sqrt{a}\\sigma^{1/2}\\lambda^{1/2}|w_x|) + C\\intwl \\left(\\sigma^{3/2}\\lambda^{3/2}s|w|\\right)(\\sigma^{1/2}\\lambda^{1/2}|w_x|)\\\\\n\t& + C\\intb \\left(s\\sigma^{3/2}\\lambda^{2} a|\\psi'|^2|w|\\right)(\\sigma^{1/2}a|\\psi'||w_x|)\\\\\n\t& \\leq C\\lambda^3s^2\\inta \\frac{x^2}{a}\\sigma^3w^2 +C\\lambda \\inta a\\sigma w_x^2 + C\\lambda^3s^2\\intwl \\sigma^3w^2 +C\\lambda\\intwl \\sigma w_x^2\\\\\n\t&+ Cs^2\\lambda^4 \\intq a^2 |\\psi'|^4\\sigma^3w^2 +C\\intq a^2|\\psi'|^2\\sigma w_x^2\n\t\\end{align*}\n\t\n\tFor $I_3$, since $a'\\geq 0$, for  $x\\in [0,\\alpha']\\cup [\\beta',1]$, we observe that\n\t\\[|a^2\\psi'\\psi''|=\\left|x\\left(\\frac{a-xa'}{a}\\right)\\right|\\leq x \\left|1-\\frac{xa'}{a}\\right|\\leq x\\left(1+\\frac{xa'}{a}\\right)\\leq x(1+k).  \\]\n\tHence, using again that $\\sigma\\leq C\\sigma^2$, we get\n\t\\begin{align*}\n\t|I_3| & \n\t\\begin{multlined}[t]\n\t\\leq s\\lambda^2 \\inta \\left|x\\left(\\frac{a-xa'}{a}\\right)\\right|\\sigma |ww_x|+Cs\\lambda^2\\intwl \\sigma^2 |ww_x|\\\\\n\t+ s\\lambda^2 \\intb  \\left|x\\left(\\frac{a-xa'}{a}\\right)\\right|\\sigma |ww_x|\n\t\\end{multlined}\\\\\n\t& \\leq Cs\\lambda^2\\inta x\\sigma^2 |ww_x|+Cs\\lambda^2\\intwl \\sigma^2 |ww_x| + Cs\\lambda^2\\intb x\\sigma |ww_x|.\n\t\\end{align*} \n\tSo, we get the same estimate for $I_2$. Finally,\n\t\\begin{equation*}\n\t|I_4| \\leq \\intq |s\\lambda^2 a(\\psi')^2\\sigma^{3/2}w| |\\lambda a \\psi'\\sigma^{1/2}w_x|\\leq  Cs^2\\lambda^4\\intq a^2|\\psi'|^4\\sigma^3w^2+C\\lambda^2\\intq a^2|\\psi'|\\sigma w_x^2,\n\t\\end{equation*}\n\tand the proof is complete.\n\\end{proof}\n%\n\\begin{lem}\\label{A10} \n\t\\begin{align*}\n\t\\frac{s}{2}\\intq \\varphi_{tt}w^2\\geq & -Cs\\inta \\sigma a w_x^2-Cs^2\\lambda^2\\inta \\frac{x^2}{a}\\sigma^3w^2 -Cs\\intwl \\sigma w_x^2\\\\ \n\t&-C\\lambda^2s^2\\intwl \\sigma^3w^2-Cs\\intq a^2|\\psi'|^2\\sigma w_x^2-Cs^2\\lambda^2\\intq a^2|\\psi'|^4\\sigma^3w^2\n\t\\end{align*}\n\\end{lem}\n%\n\\begin{proof}\n\tFirstly, since $|\\varphi_{tt}| \\leq C\\sigma^{3/2} $, we have that\n\t\\begin{equation*}\\label{eqA9}\n\t\\left|\\frac{s}{2}\\intq \\varphi_{tt}w^2\\right|\\leq Cs\\intq \\sigma^{3/2}w^2.\n\t\\end{equation*}\n\tTherefore, we just need to bound this last integral. To do that, we will treat two separately cases,  $K\\neq 1$ and $K=1$. \n\t\n\t\n\tFor $k\\neq 1$, we apply  Hardy-Poincar\\'e inequality, to take\n\t\\begin{align*}\n\t\\intq \\sigma^{3/2}w^2& \\leq  \\intq\\left(\\sigma^{1/2}\\frac{\\sqrt{a}}{x}w\\right)\\left(\\sigma\\frac{x}{\\sqrt{a}}w\\right) \\leq \\intq \\sigma\\frac{a}{x^2}w^2+\\intq \\sigma^2\\frac{x^2}{a}w^2\\\\\n\t& \\leq \\intq \\sigma aw^2_x+\\intq\\sigma^3\\frac{x^2}{a}w^2\n\t\\end{align*}\n\t\n\tAgain, the two last intervals can be decomposed in  $[0,\\alpha']$, $\\omega'$ and $[\\beta',1]$. At this point,  relations \n\t$$\\ a\\leq Ca^2|\\psi'|^2  \\mbox{ and } \\frac{x^2}{a}\\leq C a^2|\\psi'|^4, \\mbox{ in } [\\beta',1],$$\n\tgive us the result.\n\t\n\tFor $k=1$, Hardy-Poincar\u00e9 inequality is not valid, since assumption \\eqref{teta} does not give us $\\theta \\in (1,2)$ required in hypothesis in Proposition \\ref{prop-HP}.  Therefore, we will define a function $p=p(x)$ which the Hardy-Poincar\u00e9 inequality holds. \n\t\n\tIndeed, define $p(x):=(a(x)x^4)^{1/3}$ and let $\\theta \\in (0,1)$ given by \\eqref{teta}. If  we take  $q=\\frac{4+\\theta}{3}$, we can see that $q\\in (1,2)$ and  the function $x\\mapsto (p(x)/x^q)$ is  nondecreasing in a neighborhood of $x=0$, hence $p=p(x)$ satisfies the conditions of Proposition \\ref{prop-HP}. \n\t\n\tLet $\\eta^\\ast=\\dps\\max_{x\\in[0,1]}\\eta (x)$, since $\\sigma(t,x) =\\theta(t)\\eta(x)$, $p(x)\\leq C a(x)$ and  $\\eta(x)\\geq 1$ for all $x\\in [0,1]$, we have that\n\t\\begin{equation*}\n\t\\into\\left(\\frac{a}{x^2}\\right)^{1/3}\\sigma w^2\\leq {\\eta^\\ast}\\theta(t)\\into\\left(\\frac{a}{x^2}\\right)^{1/3}w^2 \\\\\n\t=\\eta^\\ast\\theta(t)\\into \\frac{p}{x^2}w^2\\leq C\\eta^\\ast\\theta(t) \\into pw^2 \\leq C\\into \\sigma a w_x^2.\n\t\\end{equation*}\n\t\n\tFrom this inequality and using H\\\"older and Young inequalities for $p=4/3$ and $q=4$, we finally obtain that\t\n\t\\begin{align*}\n\t\\intq \\sigma^{3/2}w^2& =\\intq \\left(\\frac{a^{1/4}}{x^{1/2}}\\sigma^{3/4}w^{3/2}\\right) \\left(\\frac{x^{1/2}}{a^{1/4}}\\sigma^{3/4}w^{1/2}\\right)\\\\\n\t& \\leq  \\left(\\intq \\frac{a^{1/3}}{x^{2/3}}\\sigma w^2\\right)^{3/4} \\left(\\intq \\frac{x^{2}}{a}\\sigma^{3}w^{2}\\right)^{1/4}\\\\\n\t& \\leq  \\left(\\intq \\left(\\frac{a}{x^2}\\right)^{1/3}\\sigma w^2\\right)^{3/4} \\left(\\intq \\frac{x^{2}}{a}\\sigma^{3}w^{2}\\right)^{1/4}\\\\\n\t& \\leq  \\left(\\intq\\sigma a w_x^2\\right)^{3/4} \\left(\\intq \\frac{x^{2}}{a}\\sigma^{3}w^{2}\\right)^{1/4}\\\\\n\t& \\leq C\\left( \\intq\\sigma a w_x^2 + \\intq \\frac{x^{2}}{a}\\sigma^{3}w^{2}\\right),\n\t\\end{align*}\n\twhere this last two integral are the same obtained in the case $K\\neq 1$.\n\\end{proof}\n%\n\\begin{lem}\\label{A17}\n\t\\begin{multline*}\n\ts^3\\lambda^3 \\inta \\frac{x^2}{a}\\sigma^3w^2+s\\lambda \\inta \\sigma a w_x^2 +\n\ts^3\\lambda^4\\intq a^2|\\psi'|^4\\sigma^3w^2+s\\lambda^2\\intq a^2|\\psi'|^2\\sigma w_x^2\\\\\n\t\\leq C\\left(\\intq e^{2s\\varphi}|h|^2+s^3\\lambda^3\\intwl\\sigma^3w^2+\\lambda s \\intwl \\sigma w_x^2\\right)\n\t\\end{multline*}\n\\end{lem}\n%\n\\begin{proof}\n\tFrom Lemmas \\ref{lemA2}-\\ref{A10}, we have\n\t\\begin{multline*}\n\t(L^+w,L^-w)\\geq  C\\Bigg( s^3\\lambda^3 \\inta \\frac{x^2}{a}\\sigma^3w^2+s\\lambda \\inta \\sigma a w_x^2 +\n\t\\lambda^4s^3\\intq a^2|\\psi'|^4\\sigma^3 w^2\\\\\n\t+s\\lambda^2\\intq a^2|\\psi'|^2\\sigma w_x^2 -s^3\\lambda^3\\intwl \\sigma^3w^2-\\lambda s \\intwl \\sigma w_x^2\\Bigg).\n\t\\end{multline*}\n\t\n\tHence, \n\t\\begin{align*}\n\t& \\begin{multlined}[t]\n\tC\\Bigg( s^3\\lambda^3 \\inta \\frac{x^2}{a}\\sigma^3w^2+s\\lambda \\inta \\sigma a w_x^2\n\t+ \\lambda^4s^3\\intq a^2|\\psi'|^4\\sigma^3 w^2\\\\ \n\t+s\\lambda^2\\intq a^2|\\psi'|^2\\sigma w_x^2\n\t-s^3\\lambda^3\\intwl \\sigma^3w^3-\\lambda s \\intwl \\sigma w_x^2\\Bigg)\n\t\\end{multlined}\\\\\n\t& \\leq  \\nn{L^+w}^2+\\nn{L^-w}^2+2(L^+w,L^-w) \\leq \\nn{e^{s\\varphi}h}^2,\n\t\\end{align*}\n\tfollowing the result.\n\\end{proof}\n\nNow, we intend to prove a suitable inequality which will imply Proposition \\ref{propA1}. In order to do that, we recall that $v=e^{-s\\varphi}w$.\n%\n\\begin{lem}\\label{A18}\n\t\\begin{multline*}\n\ts^3\\lambda^3 \\inta e^{2s\\varphi} \\frac{x^2}{a} \\sigma^3 v^2+s\\lambda \\inta e^{2s\\varphi} \\sigma av_x^2 \n\t\\\\\t+s^3\\lambda^4 \\intq e^{2s\\varphi} a^2|\\psi'|^4\\sigma^3v^2+s\\lambda^2\\intq e^{2s\\varphi}a^2|\\psi'|^2\\sigma v_x^2\\\\\n\t\\leq C\\left(\\intq e^{2s\\varphi} |h|^2 +\\lambda^3s^3 \\intw e^{2s\\varphi}\\sigma^3v^2\\right)\n\t% +\\lambda s\\intwl e^{2s\\varphi} \\sigma a v_x^2\n\t\\end{multline*}\n\\end{lem}\n\n\\begin{proof}\n\tSince $v=e^{-s\\varphi}w$, we have\n\t\\begin{align*}\n\t&  e^{s\\varphi}v_x=-s\\lambda \\psi' \\sigma w+w_x %\\Rightarrow  e^{2s\\varphi}v_x^2 \\leq C(s^2\\lambda^2 |\\psi'|^2\\sigma^2w^2+w_x^2)\\nonumber\\\\\n\t%\\Rightarrow & e^{2s\\varphi}s\\lambda^2|\\psi'|^2a^2\\sigma %v_x^2\\leq %C(s^3\\lambda^4|\\psi'|^4\\sigma^3a^2w^2+s\\lambda^2a|\\psi'|%^2 \\sigma w_x^2)\n\t\\end{align*}\n\twhich implies\n\t\\begin{align*}\n\te^{2s\\varphi}s\\lambda^2|\\psi'|^2a^2\\sigma v_x^2\n\t& =(s\\lambda^2|\\psi'|^2a^2\\sigma)e^{2s\\varphi}v_x^2 \\leq C(s\\lambda^2|\\psi'|^2a^2\\sigma)(s^2\\lambda^2|\\psi'|^2\\sigma^2w^2+w_x^2)\\\\\n\t& \\leq C(s^3\\lambda^4|\\psi'|^4\\sigma^3a^2w^2+s\\lambda^2|\\psi'|^2a^2\\sigma w_x^2)\n\t\\end{align*}\n\tBesides that,\n\t\\begin{align*}\n\t& w_x=s\\varphi_xe^{s\\varphi}v+e^{s\\varphi}v_x\\Rightarrow w_x^2\\leq C(s^2\\lambda^2|\\psi'|^2\\sigma^2e^{2s\\varphi}v^2+e^{2s\\varphi}v_x^2)\\nonumber\\\\\n\t\\Rightarrow & w_x^2\\leq C(s^2\\lambda^2\\sigma^2e^{2s\\varphi}v^2+e^{2s\\varphi}av_x^2), \\mbox { in } \\omega'\n\t\\end{align*}\n\t\n\tHence, from Lemma \\ref{A17}, we get\n\t\\begin{align}\\label{A12}\n\t& \\begin{multlined}[t]\n\ts^3\\lambda^3 \\inta e^{2s\\varphi} \\frac{x^2}{a} \\sigma^3  v^2+s\\lambda \\inta e^{2s\\varphi} \\sigma av_x^2 +\ts^3\\lambda^4 \\intq e^{2s\\varphi} a^2|\\psi'|^4\\sigma^3v^2\\nonumber\\\\\n\t+s\\lambda^2\\intq e^{2s\\varphi}a^2|\\psi'|^2\\sigma v_x^2\\nonumber\n\t\\end{multlined}\\\\\n\t&\\begin{multlined}[t]\n\t\\leq C\\bigg(  s^3\\lambda^3 \\inta \\frac{x^2}{a} \\sigma^3  w^2+s\\lambda \\inta  \\sigma aw_x^2  +\ts^3\\lambda^4 \\intq a^2|\\psi'|^4\\sigma^3w^2\\\\\n\t+s\\lambda^2\\intq a^2|\\psi'|^2\\sigma w_x^2\\bigg)\n\t\\end{multlined}\\nonumber\\\\\n\t&\\leq C\\left(\\intq e^{2s\\varphi}|h|^2+s^3\\lambda^3\\intwl\\sigma^3w^2+\\lambda s \\intwl \\sigma w_x^2\\right)\\nonumber\\\\\n\t& \\leq C\\left(\\intq e^{2s\\varphi}|h|^2+s^3\\lambda^3\\intwl e^{2s\\varphi}\\sigma^3v^2+\\lambda s \\intwl e^{2s\\varphi}  \\sigma av_x^2\\right)\n\t\\end{align}\n\t\n\tTo complete the proof we will estimate the last integral of \\eqref{A12}. Firstly, let us take $\\chi\\in C_0^\\infty(\\omega)$  such that $0\\leq \\chi \\leq 1$ and $\\chi\\equiv 1$ in $\\omega'$. Multiplying equation in \\eqref{pbA1} by $\\lambda s e^{2s\\varphi}\\sigma v \\chi$ and integrating over $\\dom$, we obtain\n\t\\begin{equation}\\label{A13}\n\t\\lambda s\\intq e^{2s\\varphi}\\sigma v v_t\\chi+\\lambda s\\intq e^{2s\\varphi} \\sigma (av_x)_xv\\chi \n\t=\\lambda s \\intq e^{2s\\varphi}\\sigma hv\\chi.\n\t\\end{equation}\n\t\n\tWe can see that\n\t\\begin{multline}\\label{A14}\n\t\\left|\\intq e^{2s\\varphi}\\sigma v v_t\\chi\\right|=\\left|\\frac{1}{2}\\intq e^{2s\\varphi}\\sigma \\frac{d}{dt}v^2\\chi\\right|=\\left|-\\frac{1}{2}\\intq (e^{2s\\varphi}\\sigma \\chi)_{_t}v^2\\right| \\\\\n\t=\\left|-\\frac{1}{2}\\intq \\chi e^{2s\\varphi}(2s\\varphi_t\\sigma+\\sigma_t)v^2\\right|\\leq Cs\\intw e^{2s\\varphi} \\sigma^3v^2.\n\t\\end{multline}\n\t\n\tAnd, analogously,\n\t\\begin{align*}\n\t\\intq e^{2s\\varphi}\\sigma (av_x)_x v \\chi=-\\intq e^{2s\\varphi}\\sigma a v_x^2 \\chi -\\intq (e^{2s\\varphi}\\sigma \\chi)_xav_xv.\n\t\\end{align*}\n\tSince $\\varphi_x\\leq C\\sigma$ and $\\sigma_x\\leq C\\sigma$ in $\\domw$, we get\n\t\\begin{equation}\\label{A15}\n\t\\left|\\intq (e^{2s\\varphi}\\sigma \\chi)_xav_xv\\right|\\leq C\\intw  e^{2s\\varphi} \\sigma^2 |av_x||v|.\n\t\\end{equation}\n\t\n\tNow, from \\eqref{A13}-\\eqref{A15} we obtain\n\t\\begin{align*}\n\t& \\lambda s\\intw e^{2s\\varphi} \\sigma a v_x^2\\leq \\lambda s\\intq e^{2s\\varphi} \\sigma a v_x^2\\chi\\\\\n\t& \\leq \\left|-\\lambda s \\intq \\wei\\sigma (a v_x)_xv\\chi -\\lambda s \\intq (\\wei \\sigma \\chi)_xav_xv\\right|\\\\\n\t& \\leq \\lambda s \\intq \\wei \\sigma |vv_t|\\chi +\\lambda s \\intq \\wei \\sigma |hv|\\chi +\\lambda s \\intq |(\\wei \\sigma\\chi)_x||av_xv| \\\\\n\t& \\leq C\\lambda s^2\\intw e^{2s\\varphi} \\sigma^3v^2 + \\lambda s \\intw (e^{s\\varphi} h)(e^{s\\varphi}\\sigma v)+ C\\lambda s\\intw  e^{2s\\varphi} \\sigma^2 |av_x||v|\\\\\n\t& \\leq C\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 + \\frac{1}{2}\\lambda s \\intw e^{2s\\varphi} h^2+\\frac{1}{2}\\lambda s \\intw e^{2s\\varphi} \\sigma^2 v^2\\\\\n\t& \\phantom{\\lambda s \\intq \\wei \\sigma |vv_t|\\chi }+ C\\lambda s\\intw  (e^{s\\varphi} \\sigma^{1/2}a^{1/2}|v_x| )(e^{s\\varphi} a^{1/2}\\sigma^{3/2}|v|)\\\\\n\t& \\leq C\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 + C \\intw e^{2s\\varphi} h^2\\\\\n\t& \\phantom{\\lambda s \\intq \\wei \\sigma |vv_t|\\chi }+ \\ep C\\lambda s\\intw  e^{2s\\varphi} \\sigma a v_x^2+C_\\ep \\intw e^{2s\\varphi} a\\sigma^3 v^2\\\\\n\t& \\leq C\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 + C \\intw e^{2s\\varphi} h^2+ \\ep C\\lambda s\\intw  e^{2s\\varphi} \\sigma a v_x^2.\n\t\\end{align*}\n\tHence, taking $\\ep=1/2C$, we get\n\t\\begin{equation*}\n\t\\lambda s\\intw e^{2s\\varphi} \\sigma a v_x^2\\leq  C\\left(  \\intw e^{2s\\varphi} h^2+\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 \\right).\n\t\\end{equation*}\n\tIt last inequality combined with \\eqref{A12} completes the proof.\t\n\\end{proof}\n%\nNow we are ready to prove Proposition \\ref{propA1}.\n\n\\begin{proof}[Proof of Proposition \\ref{propA1}]\n\t\\noindent \n\t\n\t%\tAs we have pointed out at the beginning, for $K\\neq 1$ the proof is the same that in \\cite{jrl2016}. Therefore, we will just prove the case $K=1$.\n\t\n\tLet $p,q>1$ and $\\beta := \\frac{1}{p}+\\frac{3}{q}$  such that $\\frac{1}{p}+\\frac{1}{q}=1$. These numbers will be precise later depending on the case $K\\neq 1$ or $K=1$.\n\t\n\tUsing H\\\"older and Young inequalities,  we have that\n\t\n\t\\begin{align*}\n\t(\\lambda s)^{\\beta}\\intq \\wei \\sigma^{\\beta}v^2& =(\\lambda s)^{\\beta}\\intq \\sigma^{\\beta}w^2\\\\\n\t& = \\intq \\left((\\lambda s)^3 \\sigma^{3}\\frac{x^2}{a} w^2\\right)^{1/q} \\left((\\lambda s)  \\sigma \\left(\\frac{a}{x^2}\\right)^{p/q} w^2\\right)^{1/p}\\\\\n\t& \\leq  \\left(\\intq (\\lambda s)^3 \\sigma^{3}\\frac{x^2}{a} w^2\\right)^{1/q}  \\left(\\intq(\\lambda s)  \\sigma \\left(\\frac{a}{x^2}\\right)^{p/q} w^2\\right)^{1/p}\\\\\n\t& \\leq C\\left( s^3\\lambda^3\\intq \\sigma^3\\frac{x^2}{a}w^2+s\\lambda \\intq \\sigma\\left(\\frac{a}{x^2}\\right)^{p/q}w^2\\right)\\\\\n\t& =C(I_1+I_p).\n\t\\end{align*}\n\t\n\t\n\tNow, let us estimate $I_1$ and $I_p$ taking into account the terms of the inequality given by Lemma \\ref{A17}.\n\t\n\tSplitting $I_1$ over the   intervals $[0,\\alpha'], \\omega'$ and $[\\beta',1]$, and taking into account that $x^2/a$ is bounded in $\\omega'$ and $x^2/a\\leq a^2|\\psi'|^2$ in $[b',1]$, we use Lemma \\ref{A17} to obtain that\n\t\\begin{align*}\n\tI_1 & \\leq s^3\\lambda^3\\inta \\sigma^3\\frac{x^2}{a}w^2+Cs^3\\lambda^3\\intwl \\sigma^3 w^2+Cs^3\\lambda^4\\intq \\sigma^3 a^2|\\psi'|^4w^2\\\\\n\t& \\leq C\\left(\\intq \\wei h^2+s^3\\lambda^3\\intwl \\sigma^3 w^2+\\lambda s\\intwl \\sigma w_x^2\\right)\n\t\\end{align*}\n\t\n\tIn order to estimate $I_p$, we will consider two cases $K\\neq 1$ and $K=1$. \n\t\n\tIf $K\\neq 1$, we choose $p=2$ and  we can apply Hardy-Poincar\\'e inequality as following\n\t\\begin{align*}\n\t& I_p= s\\lambda\\intq \\frac{a}{x^2}(\\sigma^{1/2}w)^2\\leq Cs\\lambda\\intq a(\\sigma^{1/2}w)_x^2\\\\\n\t& =Cs\\lambda \\intq a\\left(\\frac{1}{2}\\sigma^{-1/2}\\sigma_xw+ \\sigma^{1/2}w_x\\right)^2\\\\\n\t& \\leq Cs\\lambda \\intq a\\sigma^{-1}\\sigma_x^2w^2+Cs\\lambda \\intq a\\sigma w_x^2\\\\\n\t& \\leq Cs\\lambda^3 \\intq a|\\psi'|^2\\sigma w^2+Cs\\lambda \\intq a\\sigma w_x^2\\\\\n\t& \\leq Cs^3\\lambda^3 \\inta \\frac{x^2}{a}\\sigma^3 w^2+Cs^3\\lambda^3 \\intwl \\sigma^3 w^2+Cs^3\\lambda^4 \\intb a^2|\\psi'|^4\\sigma^3 w^2\\\\\n\t&\\phantom{\\leq}+Cs\\lambda \\inta a\\sigma w_x^2+Cs\\lambda \\intwl \\sigma w_x^2+Cs\\lambda^2 \\intb a^2|\\psi'|^2\\sigma w_x^2\\\\\n\t& \\leq C\\left(\\intq \\wei h^2+s^3\\lambda^3\\intwl \\sigma^3 w^2+\\lambda s\\intwl \\sigma w_x^2\\right)\n\t\\end{align*}\n\t\n\tIf $K=1$, we will proceed as in Lemma \\ref{A10}, where have had to define a suitable function in order to apply Hardy-Poincar\u00e9 inequality.\n\t\n\tIn this case, let us choose $p=3/2$ and define $b(x):=\\sqrt{a(x)}x$. Let $\\theta \\in (0,1)$ given by \\eqref{teta}. If  we take  $q=\\frac{\\theta}{2}+1$, we can see that $q\\in (1,3/2)$ and  the function $x\\mapsto (b(x)/x^q)$ is  nondecreasing in a neighborhood of $x=0$, hence $b$ satisfies the conditions of Proposition \\ref{prop-HP}. \n\t\n\tRecalling that $\\eta^\\ast=\\dps\\max_{x\\in[0,1]}\\eta (x)$, since $\\sigma(t,x) =\\theta(t)\\eta(x)$, $b(x)\\leq C a(x)$ and  $\\eta(x)\\geq 1$ for all $x\\in [0,1]$, we have that\n\t\\begin{multline*}\n\t\\into\\left(\\frac{a}{x^2}\\right)^{p/q}\\sigma w^2\\leq\\into\\left(\\frac{a}{x^2}\\right)^{1/2}\\sigma w^2\\leq {\\eta^\\ast}\\theta(t)\\into\\left(\\frac{a}{x^2}\\right)^{1/3}w^2 \\\\\n\t=\\eta^\\ast\\theta(t)\\into \\frac{b}{x^2}w^2\\leq C\\eta^\\ast\\theta(t) \\into bw^2 \\leq C\\into \\sigma a w_x^2.\n\t\\end{multline*}\n\tHence,\n\t\\[I_p=s\\lambda \\intq \\sigma\\left(\\frac{a}{x^2}\\right)^{1/2}w^2 \\leq C\\intq \\sigma a w_x^2,\\]\n\twhich is one of the integral obtained in the case $p=2$.\n\t\n\t\n\t\n\tThus, note that for $p=2$, $\\beta=2$ and for $p=3/2$, $\\beta=5/3$. Therefore, in both cases, we have that\n\t\\begin{multline*}\n\t(\\lambda s)^{5/3}\\intq \\wei \\sigma^{5/3}v^{5/3}\\leq (\\lambda s)^{\\beta}\\intq \\wei \\sigma^{\\beta}v^{\\beta}\\\\\n\t\\leq I_1+I_p \\leq C\\left(\\intq \\wei h^2+s^3\\lambda^3\\intwl \\sigma^3 w^2+\\lambda s\\intwl \\sigma w_x^2\\right).\n\t\\end{multline*}\n\tProceeding exactly as in the proof of Lemma \\ref{A18}, we achieve\n\t\\begin{equation*}\\label{A20}\n\t(\\lambda s)^{5/3}\\intq \\wei \\sigma^{5/3}v^{5/3}\\leq  C\\left(  \\intw e^{2s\\varphi} h^2+\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 \\right),\n\t\\end{equation*}\n\tand the result given by Lemma \\ref{A18} gives us\n\t\\begin{align*}\n\ts\\lambda \\intq \\wei a\\sigma v_x^2 &\\leq s\\lambda \\inta \\wei a\\sigma v_x^2+s\\lambda \\intwl \\wei a\\sigma v_x^2\t+s\\lambda \\intb \\wei a^2|\\psi'|^2\\sigma v_x^2\\\\\n\t&\\leq  C\\left(  \\intw e^{2s\\varphi} h^2+\\lambda^3 s^3\\intw e^{2s\\varphi} \\sigma^3v^2 \\right).\n\t\\end{align*}\n\t\n\tTherefore, this last two estimates conclude the proof of Proposition \\ref{propA1}.\n\t\n\\end{proof}\n\n\n\n\n\\begin{proof}[Proof of Theorem \\ref{car-strong}] \n\tIf $v$ is a solution of \\eqref{adj-jlr}, then $v$ is also a solution of \\eqref{pbA1} with $h=F+cv$. In this case, applying Propostion \\ref{propA1}, there exist $C>0$, $\\lambda_0>0$ and $s_0>0$ such that $v$ satisfies, for all $s\\geq s_0$ and $\\lambda\\geq \\lambda_0$, \n\t\\begin{equation} \\label{A19}\n\t\\intq e^{2s\\varphi}\\left((s\\lambda)\\sigma av_x^2+(s\\lambda)^{5/3}\\sigma^{5/3}v^2 \\right) \t\\leq C\\left(\\intq e^{2s\\varphi}|h|^2\\   +(\\lambda s)^3\\intw e^{2s\\varphi}\\sigma^3v^2\\   \\right).\n\t\\end{equation} \n\t\n\tRecalling that $c\\in L^{\\infty}(\\dom)$ and $\\sigma\\geq C>0$, we can see that\n\t\\begin{align*}\n\t\\intq e^{2s\\varphi}|h|^2& =\\intq e^{2s\\varphi}|F+cv|^2\\\\\n\t& \\leq C\\intq e^{2s\\varphi}|F|^2+C\\n{c}{\\infty}^2\\intq e^{2s\\varphi}|v|^2\\\\\n\t& \\leq C\\intq e^{2s\\varphi}|F|^2+C\\intq e^{2s\\varphi}\\sigma^{5/3}|v|^2.\n\t\\end{align*}\n\t\n\tTherefore, taking $\\lambda_0$ and $s_0$ large enough, the last integral can be absorbed by the left-hand side of \\eqref{A19}, which complete the proof.\n\\end{proof}\n\n\n\n\n\n%---------------------------------------\n\n\n\n\\bibliography{references}\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:53", "yymm": "2010", "arxiv_id": "2010.14486", "url": "https://arxiv.org/abs/2010.14486", "source": "arxiv"}}
{"text": "\\documentclass[11pt,reqno]{amsart}\n\\usepackage{amsmath, amsthm, amssymb}\n%\\usepackage{amsmath, amsthm, amssymb, stmaryrd}\n%\\usepackage{fullpage}\n\\usepackage{mathrsfs}\n\\usepackage{array}\n\\usepackage{caption}\n\\topmargin 0.0cm\n  \\textheight 22.2cm\n\\oddsidemargin 0.8cm\n\\evensidemargin \\oddsidemargin\n\\marginparwidth 2cm\n\\textwidth 15.2cm\n\\def\\a{{\\mathbf a}}\n\\def\\c{{\\mathbf c}}\n\\def\\b{{\\mathbf b}}\n\\def\\B{\\mathcal B}\n\\def\\e{\\varepsilon}\n\\def\\bfh{{\\mathbf h}}\n\\def\\bfb{{\\mathbf b}}\n\\def\\bfc{{\\mathbf c}}\n\\def\\bfy{{\\mathbf y}}\n\\def\\bfx{{\\mathbf x}}\n\\def\\bfz{{\\mathbf z}}\n\\def\\bfr{{\\mathbf r}}\n\\def\\bfw{{\\mathbf w}}\n\\def\\bfv{{\\mathbf v}}\n\\newcommand{\\mmod}[1]{\\,\\,(\\text{\\rm mod}\\,\\, #1)}\n\\def\\bfgamma{{\\boldsymbol \\gamma}}\n\\def\\bfalpha{{\\boldsymbol \\alpha}}\n\\def\\bfbeta{{\\boldsymbol \\beta}}\n\\def\\numset#1{{\\mathbb #1}}\n\\newtheorem{thm}{Theorem}\n\\newtheorem{cor}{Corollary}\n\\newtheorem{propos}{Proposition}\n\\newtheorem{problem}{Problem}\n\\newtheorem{remark}{Remark}\n\\newtheorem{lem}{Lemma}\n\\newtheorem{claim}{Claim}\n\\newtheorem{conj}{Conjecture}\n\\newtheorem{defn}{Definition}\n\\newtheorem{exam}{Example}\n\\newtheorem{prop}{Proposition}\n\\newcommand{\\E}{\\ensuremath{\\mathbb E}}\n\\newcommand{\\U}{\\ensuremath{\\mathcal U}}\n\\numberwithin{equation}{section} \\numberwithin{thm}{section}\n\\numberwithin{lem}{section} \\numberwithin{problem}{section}\n\\numberwithin{cor}{section}\n\\newcommand{\\cc}{\\mathbf c}\n\\newcommand{\\ccc}{\\overline{\\mathbf c}}\n\\newcommand{\\aaa}{\\overline{\\alpha}}\n\\newcommand{\\p}{\\mathbf p}\n\\newcommand{\\ex}{\\text{ex}}\n\\def\\grm{{\\mathfrak m}}\\def\\grM{{\\mathfrak M}}\\def\\grN{{\\mathfrak N}}\\def\\grn{{\\mathfrak n}}\\def\\grL{{\\mathfrak L}}\\def\\grl{{\\mathfrak l}}\\def\\bfgrN{{\\boldsymbol \\mathfrak N}}\\def\\bfgrn{{\\boldsymbol\\mathfrak n}}\\def\\bfgrL{{\\boldsymbol\\mathfrak L}}\\def\\bfgrl{{\\boldsymbol\\mathfrak l}}\\def\\grp{{\\mathfrak p}}\\def\\grP{{\\mathfrak P}}\\def\\grw{{\\mathfrak w}}\\def\\grW{{\\mathfrak W}}\n\\newcommand{\\q}{\\mathbf q}\n\\newcommand{\\rr}{\\mathbf r}\n\\newcommand{\\pp}{\\overline{\\mathbf p}}\n\\newcommand{\\qq}{\\overline{\\mathbf q}}\n\\newcommand{\\nuu}{\\overline{\\mathbf \\nu}}\n\\newcommand{\\Real}{\\mathbb R}\n\\newcommand{\\RPlus}{\\Real^{+}}\n\\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert}\n\\newcommand{\\abs}[1]{\\left\\vert#1\\right\\vert}\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\n\\newcommand{\\seq}[1]{\\left<#1\\right>}\n\\newcommand{\\eps}{\\varepsilon}\n\\newcommand{\\To}{\\longrightarrow}\n\\newcommand{\\BX}{\\mathbf{B}(X)}\n\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\Ha}{\\mathcal{H}}\n\\newcommand{\\Beta}{B}\n\\newcommand{\\Ar}{\\text{Arc}}\n\\newcommand{\\M}{\\mathcal{M}}\n\\newcommand{\\G}{\\mathcal{G}}\n\\newcommand{\\W}{\\mathcal{W}}\n\\newcommand{\\N}{\\mathcal{N}}\n\\newcommand{\\Ll}{\\mathcal{L}}\n\\newcommand{\\Fa}{\\mathcal{F}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\newcommand{\\Lom}{\\mathcal{L}}\n\\newcommand{\\Comp}{\\mathcal{K}}\n\\newcommand{\\Basis}{\\mathcal{B}}\n\\newcommand{\\nnu}{\\mathbf{\\nu^n}}\n\\newcommand{\\F}{\\mathbb F}\n\\newcommand{\\FF}{\\mathcal F}\n\\newcommand{\\MM}{\\mathcal M}\n\\def\\f{\\frac{|\\A||B|}{|G|}}\n\\def\\AB{|\\A\\cap B|}\n%%% ----------------------------------------------------------------------\n%\\nopagenumber\n%\\renewcommand{\\baselinestretch}{1.5}\n%\\textwidth=14cm\n\\parskip 1.5mm\n\n\n\\begin{document}\n\\title[Sums of three cubes]{On Waring's problem in sums of three cubes}\n\\author[Javier Pliego]{Javier Pliego}\n\\address{Purdue Mathematical Science Building, 150 N University St, West Lafayette, IN 47907, United States of America}\n\n\\email{jp17412@bristol.ac.uk}\n\\subjclass[2010]{11P05, 11P55}\n\\keywords{Waring's problem, Hardy-Littlewood method.}\n\n\n\n\\begin{abstract} We investigate the asymptotic formula for the number of representations of a large positive integer as a sum of $k$-th powers of integers represented as the sums of three positive cubes, counted with multiplicities. We also obtain a lower bound for the number of representations when the sums of three cubes are counted without multiplicities.\n\\end{abstract}\n\\maketitle\n\n\\section{Introduction} \nIt is widely believed, but still unknown, that the set of integers $\\mathscr{C}$ represented as a sum of three positive integral cubes has positive density. Hardy and Littlewood \\cite{Har} first announced what is known as the Hypothesis-$K$, which asserts that for each $\\varepsilon>0$, the number of representations $r_{k}(n)$ of $n$ as a sum of $k$ positive integral $k$-th powers is $O(n^{\\varepsilon}).$ Although this conjecture is known to be false when $k=3$ (see Mahler \\cite{Mah}), the weaker claim that \\begin{equation}\\label{ec1.1}\\sum_{n\\leq X}r_{k}(n)^{2}\\ll X^{1+\\varepsilon},\\end{equation} known as Hypothesis $K^{*}$ (see \\cite{Hol2}), would allow one to show, through a standard Cauchy-Schwarz argument, that $\\mathcal{N}(X)=\\lvert \\mathscr{C}\\cap [1,X]\\rvert\\gg X^{1-\\varepsilon}.$ In fact, under some unproved assumptions on the zeros of some Hasse-Weil $L$-functions, Hooley (\\cite{Hol1}, \\cite{Hol2}) and Heath-Brown \\cite{Hea} showed using different procedures that (\\ref{ec1.1}) holds for $k=3$. Nevertheless, some unconditional progress has been made on strengthening  lower bounds for $\\mathcal{N}(X).$ By using methods of diminishing ranges, Davenport \\cite{Dav2} obtained the bound $\\mathcal{N}(X)\\gg X^{47/54-\\varepsilon}.$\nLater on, Vaughan improved it to $\\mathcal{N}(X)\\gg X^{11/12-\\varepsilon}$ by introducing smooth numbers in his ``new iterative method'' \\cite{Vau3}, and Wooley, extending the method to obtain non-trivial bounds for fractional moments of smooth Weyl sums, improved the estimate in a series of papers (\\cite{Woo1}, \\cite{Woo2}, \\cite{Woo3}), the best current one being $\\mathcal{N}(X)\\gg X^{\\beta}$, where $\\beta=0.91709477.$\n\nA vast number of results can be found in the literature on problems involving equations over special subsets of the integers. The Green-Tao Theorem \\cite{G-T}, which proves the existence of arbitrarily long arithmetic progressions over the primes is an example of such problems when the special set is the set of prime numbers. Other instances where the set $\\mathscr{C}$ is involved include some correlation estimates for sums of three cubes by Br\\\"udern and Wooley \\cite{B-W}, and lower bounds of the shape $N_{3}(\\mathscr{C},X)\\gg X^{5/2-\\varepsilon},$ by Balog and Br\\\"udern \\cite{B-B}. The parameter $N_{3}(\\mathscr{C},X)$ here denotes the number of triples with entries in $\\mathscr{C}\\cap [1,X]$ whose entries averages lie on $\\mathscr{C}$ as well. \n\nIn this paper we investigate the asymptotic formula for Waring's problem when the set of $k$-th powers of integers is replaced by the set of $k$-th powers of elements of $\\mathscr{C}$, but before stating the main result that we obtain here it is convenient to introduce some notation. Let $k\\geq 2$ and $n\\in\\mathbb{N}$. Take $P=n^{1/3k}.$ For every vector $\\mathbf{v}\\in\\mathbb{R}^{n}$ and parameters $a,b\\in\\mathbb{R}$ we will write $a\\leq \\mathbf{v}\\leq b$ to denote that $a\\leq v_{i}\\leq b$ for $1\\leq i\\leq n$. We take the function $T(\\mathbf{x})=x_{1}^{3}+x_{2}^{3}+x_{3}^{3},$ and consider the weights $$r_{3}(x)={\\rm card}\\Big\\{\\bfx\\in\\mathbb{N}^{3}:\\ x=T(\\bfx),\\ \\ \\mathbf{x}\\leq P\\Big\\}$$ and the set $$\\mathcal{X}_{n}=\\Big\\{(x_{1},\\ldots,x_{s})\\in\\mathscr{C}^{s},\\ \\ \\ \\ n=\\sum_{i=1}^{s}x_{i}^{k}\\Big\\}.$$ Define the functions \\begin{equation}\\label{Rs}R(n)=\\sum_{\\mathbf{X}\\in\\mathcal{X}_{n}}r_{3}(x_{1})\\cdots r_{3}(x_{s}),\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  r(n)=\\sum_{\\mathbf{X}\\in\\mathcal{X}_{n}}1,\\end{equation} which count the number of representations of $n$ as a sum of $k$-th powers of integers represented as sums of three positive cubes, counted with and without multiplicities respectively. Take the singular series associated to the problem, defined as\n\\begin{equation}\\label{1A}\\mathfrak{S}(n)=\\sum_{q=1}^{\\infty}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\Big(q^{-3}\\sum_{1\\leq \\mathbf{r}\\leq q}e\\big(aT(\\mathbf{r})^{k}/q\\big)\\Big)^{s}e\\big(-an/q\\big).\\end{equation}\nThe main result of this paper establishes an asymptotic formula for $R(n)$. For such purpose, it is convenient to introduce the parameter $H(k)=9k^{2}-k+2.$\n\\begin{thm}\\label{thm9.1}\nLet $s\\geq H(k).$ Then, there exists a constant $\\delta>0$ such that\n\\begin{equation*}R(n)=\\Gamma\\big(4/3\\big)^{3s}\\Gamma\\big(1+1/k\\big)^{s}\\Gamma\\big(s/k\\big)^{-1}\\mathfrak{S}(n)n^{s/k-1}+O(n^{s/k-1-\\delta}),\\end{equation*}where the singular series satisfies $\\mathfrak{S}(n)\\gg 1.$ \n\\end{thm}\n\nOur proof of Theorem \\ref{thm9.1} is based on the application of the Hardy-Littlewood method. In order to discuss the constraint of the previous result on the number of variables, we define first $\\tilde{G}(k)$ as the minimum number such that for $s\\geq \\tilde{G}(k)$, the anticipated asymptotic formula in the classical Waring's problem holds. We remind the reader that as a consequence of Vinogradov's mean value theorem, Bourgain \\cite{Bou} showed that $\\tilde{G}(k)\\leq k^{2}-k+O(\\sqrt{k})$. The lack of understanding of the cardinality of the set $\\mathscr{C}$ mentioned at the beginning of the paper both weakens the minor arc bounds and prevents us from having a better understanding of its distribution over arithmetic progressions, which often comes into play on the major arc analysis. The methods used in this memoir then are based on arguments in which in most of the sums of three cubes employed in the representation, all but one of the cubes is fixed in the associated analysis. Consequently, the constraint for the number of variables that we obtain here is asymptotic to the bound for $\\tilde{G}(3k)$ mentioned above.\n\n The problem becomes more challenging when we remove the counting of the multiplicities, and even if getting an asymptotic formula seems out of reach, Theorem \\ref{thm9.1} can be used to obtain a non-trivial lower bound. However, the whole strategy relies on an estimate for the $L^{2}$-norm of the sequence $\\big(r_{3}(x)\\big)_{x\\leq X}$ of the shape\n\\begin{equation}\\label{rap}\\displaystyle\\sum_{x\\leq X}r_{3}(x)^{2}\\ll X^{7/6+\\varepsilon}\\end{equation} that follows after an application of Hua's Lemma \\cite[Lemma 2.5]{Vau}. Instead of taking that approach, we restrict the triples to lie on $\\mathcal{C}(P)=\\big\\{\\mathbf{x}\\in [1,P]^{3}:\\ x_{1},x_{2}\\in\\mathcal{A}(P,P^{\\eta})\\big\\}$, where $\\eta>0$ is a small enough fixed parameter and \n$$\\mathcal{A}(X,R)=\\{n\\in [1,X]\\cap \\mathbb{N}: p\\mid n\\text{ and $p$ prime}\\Rightarrow p\\leq R\\},$$ and make use of the stronger estimate\n\\begin{equation}\\label{ec12}\\sum_{x\\leq X}s_{3}(x)^{2}\\ll X^{1+\\nu}\\end{equation} due to Wooley \\cite[Theorem 1.2]{Woo3}, where $s_{3}(x)={\\rm card}\\big\\{\\bfx\\in\\mathcal{C}(P):\\ x=T(\\bfx)\\big\\}$ and $\\nu=0.08290523$. It transpires that one should then have some control of the order of magnitude of the analogous function of $R(n)$ when we impose that restriction on the triples. For such matters, we define for each $n\\in\\mathbb{N}$ the aforementioned counting function\n\\begin{equation}\\label{Rseta} R_{\\eta}(n)=\\sum_{\\mathbf{X}\\in\\mathcal{X}_{n}}s_{3}(x_{1})\\cdots s_{3}(x_{s}).\\end{equation}We also introduce Dickman's function, defined for real $x$ by\n$$\\rho(x)=0\\text{ when } x<0,$$\n$$\\rho(x)=1 \\text{ when } 0\\leq x\\leq 1,$$\n$$\\rho \\text{ continuous for } x>0,$$\n$$\\rho \\text{ differentiable for } x>1$$\n$$x\\rho'(x)=-\\rho(x-1) \\text{ when } x>1.$$\n\\begin{thm}\\label{thm9.3}\nLet $s$ be any positive integer with $s\\geq H(k).$ Then, there exists $\\delta>0$ such that\n$$R_{\\eta}(n)=\\Gamma\\big(4/3\\big)^{3s}\\Gamma\\big(1+1/k\\big)^{s}\\Gamma\\big(s/k\\big)^{-1}\\rho\\big(1/\\eta\\big)^{2s}\\mathfrak{S}(n)n^{s/k-1}+O(n^{s/k-1}(\\log n)^{-\\delta}),$$\nwhere the singular series satisfies $\\mathfrak{S}(n)\\gg 1.$ \n\\end{thm}\nAn application of this theorem then, together with equation (\\ref{ec12}) and some other arguments yield the following result, which improves substantially the bound that one could obtain if no restriction on the triples was made.\n\\begin{thm}\\label{thm9.2}\nLet $s$ be any positive integer with $s\\geq H(k)+1.$ One has the lower bound\n$$r(n)\\gg n^{(1-\\nu)s/k-1},$$ where $\\nu$ was defined right after (\\ref{ec12}).\n\\end{thm}\nThe final question that will be addressed here is the constraint on the number of variables that guarantees the existence of solutions. For such purpose, we define $G_{3}(k)$ as the minimum integer such that for all $s\\geq G_{3}(k)$ then $r(n)\\geq 1$ holds for sufficiently large integers. We apply a previous result of Wooley \\cite{Woo7} to obtain the following bound.\n\\begin{thm}\\label{thm1.4}\nLet $k\\in\\mathbb{N}$. Then,\n$$G_{3}(k)\\leq 3k\\big(\\log k+\\log\\log k+O(1)\\big).$$\n\\end{thm}\nOur proofs for the main theorems of the paper are based on the application of the Hardy-Littlewood method. In Section \\ref{sec2}, we apply a mean value estimate related to that of Vinogradov to bound the minor arc contribution. Section \\ref{sec3} deals with estimates of complete exponential sums and other related sums. In Sections \\ref{sec4} we discuss the local solubility of the problem and some properties of the singular series and include a brief proof of Theorem \\ref{thm1.4}. Using the Riemann-Stieltjes integral we give an approximation of $f(\\alpha)$ over the major arcs in Section \\ref{sec6}. In Section \\ref{sec7} we study the singular integral, we obtain an asymptotic formula for the major arcs and we include a proof of Theorem \\ref{thm9.1}. Section \\ref{Sec99} is devoted to the study of the asymptotic formula when we introduce smooth numbers, and Theorem \\ref{thm9.2} is then proven in Section \\ref{Sec999} via an application of Theorem \\ref{thm9.3}. We have also included a small appendix in which we improve the constraint on the number of variables needed in Theorem \\ref{thm9.1} for small exponents by using restriction estimates.\n\n\\emph{Notation}.  Whenever $\\varepsilon$ appears in any bound, it will mean that the bound holds for every $\\varepsilon>0$, though the implicit constant may depend on $\\varepsilon$. We adopt the convention that when we write $\\delta$ in the computations we mean that there exists a positive constant such that the bound holds. Unless specified, any lower case letter $\\mathbf{x}$ written in bold will denote a triple of integers $(x_{1},x_{2},x_{3})$. For any scalar $\\lambda$ and any vector $\\mathbf{x}$ we write $\\lambda \\mathbf{x}$ for the vector $(\\lambda x_{1},\\lambda x_{2}, \\lambda x_{3})$. When $R,V\\in\\mathbb{Z}^{d}$ then $R\\equiv V\\pmod q$ will mean that $R_{i}\\equiv V_{i}\\pmod{q}$ for all $1\\leq i\\leq d$. We use $\\ll$ and $\\gg$ to denote Vinogradov's notation, and write $A\\asymp B$ whenever $A\\ll B\\ll A$. As usual in analytic number theory, for each $x\\in\\mathbb{R}$ then $e(x)$ will mean $\\exp(2\\pi i x),$ and for each prime $p$, the number $e(x/p)$ will be written as $e_{p}(x).$ We write $p^{r}|| n$ to denote that $p^{r}| n$ but $p^{r+1}\\nmid n.$\n\n\\section{Minor arc estimate.}\\label{sec2}\nWe obtain estimates for certain moments of an exponential sum on the minor arcs which we now define. Fix $s,k\\geq 2$ and consider\n\\begin{equation*}f(\\alpha)=\\sum_{\\bfx\\leq P}f_{\\bfx}(\\alpha),\\ \\ \\ \\ \\ \\ \\  \\ \\text{where}\\ \\  f_{\\bfx}(\\alpha)=\\sum_{1\\leq x\\leq P}e\\big(\\alpha T(\\bfx,x)^{k}\\big)\\end{equation*} and $\\mathbf{x}\\in\\mathbb{N}^{2}$. Recalling (\\ref{Rs}), note that by orthogonality it follows that\n$$R(n)=\\int_{0}^{1}f(\\alpha)^{s}e(-\\alpha n)d\\alpha.$$ The purpose of this section is to bound the minor arc contribution of this integral. In order to make further progress we make use of a Hardy-Littlewood dissection in our analysis. When $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ satisfy $0\\leq a\\leq q\\leq P^{\\xi}$ and $(a,q)=1$ with $\\xi<\\frac{s}{s+2}$, consider \n\\begin{equation}\\label{5us}\\grM(a,q)=\\Big\\{ \\alpha\\in [0,1):\\Big\\lvert \\alpha-a/q\\Big\\rvert \\leq \\frac{P^{\\xi}}{qn} \\Big\\}.\\end{equation} Then the major arcs $\\grM$ will be the union of these arcs and $\\grm=[0,1)\\setminus \\grM $ will be the minor arcs. \n\\begin{prop}\\label{prop222} When $s$ is any positive integer with $s\\geq H(k)$ one has\n$$\\int_{\\grm}\\lvert f(\\alpha)\\rvert^{s} {\\rm     d}\\alpha\\ll P^{3s-3k-\\delta}.$$\nMoreover, if $s\\geq 3k(3k+1)$ then it follows that\n$$\\int_{\\grm}\\lvert f(\\alpha)\\rvert^{s} {\\rm     d}\\alpha\\ll P^{3s-3k-\\xi+\\varepsilon}.$$\n\\end{prop}\n\\begin{proof}\nWe bound the previous integrals in terms of a mean value of that of Vinogradov and apply estimates derived from Wooley \\cite[Theorems 14.4, 14.5]{Woo4}. For such purpose, it is convenient to take the set $\\frak{B}=\\grm\\times [0,1)^{k-1}$ and consider the exponential sums \\begin{equation}\\label{GF}G_{\\mathbf{x}}(\\bfalpha)=\\displaystyle\\sum_{ x\\leq P}e\\big(\\alpha_{k} T(x,\\mathbf{x})^{k}+\\displaystyle\\sum_{j=1}^{k-1}\\alpha_{j}x^{3j}\\big)\\ \\ \\ \\ \\text{and} \\ \\ \\ \\ F(\\bfalpha)=\\displaystyle\\sum_{x\\leq P} e\\Big(\\sum_{j=1}^{k}\\alpha_{j}x^{3j}\\Big).\\end{equation} We write $H(k)=2t$ for some positive integer $t$. Using H\\\"older's inequality and orthogonality we find that\n\\begin{align}\\label{puu}&\n\\int_{\\grm}\\lvert f(\\alpha)\\rvert^{2t}d\\alpha\\ll  P^{4t-2}\\int_{\\grm}\\sum_{\\mathbf{x}\\leq P}\\lvert f_{\\mathbf{x}}(\\alpha)\\lvert^{2t}d\\alpha\\nonumber\n\\\\\n&=P^{4t-2}\\sum_{\\substack{\\mathbf{x}\\leq P}}\\sum_{n_{j}}\\int_{\\frak{B}}\\lvert G_{\\mathbf{x}}(\\bfalpha)\\lvert^{2t}e\\big(-\\sum_{j=1}^{k-1}\\alpha_{j} n_{j}\\big)d\\bfalpha\\ll P^{4t+3k(k-1)/2}\\int_{\\frak{B}}\\lvert F(\\bfalpha) \\rvert^{2t}d\\bfalpha,\n\\end{align}\nwhere $(n_{j})_{j}$ runs over the tuples with $1\\leq \\lvert n_{j}\\rvert\\leq tP^{3j}.$ Observe that by Weyl's inequality \\cite[Lemma 2.4]{Vau} one has that\n\\begin{equation*}\\sup_{\\bfalpha\\in\\frak{B}}\\lvert F(\\bfalpha)\\rvert\\ll P^{1-\\delta},\\end{equation*}\nwhence this pointwise bound and Theorem 14.5 of \\cite{Woo4} with the choice $r=3k-2$ deliver the estimate\n\\begin{equation}\\label{BF}\\int_{\\frak{B}}\\lvert F(\\bfalpha)\\rvert^{2t}d\\bfalpha\\ll P^{2t-3k(k+1)/2-\\delta}.\\end{equation} The above equation and (\\ref{puu}) then yield the first part of the proposition. For the second part we use a small modification of Wooley \\cite[Theorem 14.4]{Woo4}. On that paper, the author, in a more general setting, takes the choice $\\xi=1$ and obtains a saving of $X$ over the expected main term. It transpires that the same exact method can be applied to save $X^{\\xi}$ for $\\xi<1$. Thus, we have that for $s\\geq 3k(3k+1)$ then\n$$\\int_{\\frak{B}}\\lvert F(\\bfalpha)\\rvert^{s}d\\bfalpha\\ll P^{s-3k(k+1)/2-\\xi+\\varepsilon}.$$ Replacing $2t$ by $s$ in (\\ref{puu}) and using the previous equation we get the desired result.\n\\end{proof}\n\\section{Complete exponential sums}\\label{sec3}\nIn this section we study the complete exponential sum associated to the problem and deduce some bounds involving this sum. For such purpose, it is convenient to define for $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ the expressions\n\\begin{equation*}S(q,a)=\\sum_{1\\leq\\mathbf{r}\\leq q}e_{q}\\big(aT(\\mathbf{r})^{k}\\big)\\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ S_{k}(q,a)=\\sum_{r=1}^{q}e_{q}(ar^{k}).\\end{equation*}Note that by orthogonality then one can rewrite $S(q,a)$ as\n\\begin{equation}\\label{Sqa}S(q,a)=q^{-1}\\sum_{u=1}^{q}S_{3}(q,u)^{3}S_{k}(q,a,-u),\\ \\ \\ \\ \\ \\ \\text{where}\\  \\ S_{k}(q,a,b)=\\sum_{r=1}^{q}e_{q}(ar^{k}+br).\\end{equation}In what follows we provide bounds for $S(q,a)$ using estimates for $S_{3}(q,a)$ and $S_{k}(q,a,b)$. Observe that by the quasi-multiplicative structure of it then it suffices to investigate the instances when $q=p^{l}$ is a prime power. \n\n\\begin{lem}\\label{Sa}\nLet $l\\geq 2$, let $p$ be a prime number and $a\\in\\mathbb{Z}$ with $(a,p)=1.$ Then,\n\\begin{equation*}S(p^{l},a)\\ll \\min(p^{3l-1},lp^{3l-l/k+\\varepsilon}).\n \\end{equation*}\n\\end{lem}\n\\begin{proof}\nNote that Vaughan \\cite[Theorem 7.1]{Vau} yields the bound $S(p^{l},a,-u)\\ll p^{l(1-1/k)+\\varepsilon}$. Therefore, an application of this estimate and Theorem 4.2 of \\cite{Vau} to equation (\\ref{Sqa}) gives\n\\begin{equation*}S(p^{l},a)\\ll p^{2l-l/k+\\varepsilon}\\sum_{u=1}^{p^{l}}(u,p^{l})\\ll lp^{3l-l/k+\\varepsilon}.\\end{equation*}\nObserve that we can also deduce the bound $S(p^{l},a,-u)\\ll p^{l-1}$ from the proof\\footnote{See in particular the argument following Vaughan \\cite[(7.16)]{Vau}} of Vaughan \\cite[Theorem 7.1]{Vau}, so the application of this estimate instead and the same procedure delivers $S(p^{l},a)\\ll p^{3l-1}$.\n\\end{proof}\nWhen $p$ is prime we can provide a more precise description of $S(p,a)$ by involving the sum $S_{k}(p,a)$ in its expression. Despite not using this refinement in the memoir, we have included such analysis for future work.\n\\begin{lem}\\label{lem3.4}\nLet $p$ be a prime number and $a\\in\\mathbb{Z}$ with $(a,p)=1$. Then,\n$$S(p,a)=p^{2}S_{k}(p,a)+O(p^{2}).$$ In particular, one has the bound $S(p,a)\\ll p^{5/2}.$\n\\end{lem}\n\\begin{proof}\nBy equation (\\ref{Sqa}) it follows that $S(p,a)=p^{2}S_{k}(p,a)+E$, where $$E=p^{-1}\\sum_{1\\leq u\\leq p-1}S_{3}(p,u)^{3}S_{k}(p,a,-u).$$\nUsing Vaughan \\cite[Lemma 4.3]{Vau} to bound $S_{3}(p,u)$ and the work of Weil\\footnote{See Schmidt \\cite[Corollary 2F]{Sch} for an elementary proof of this bound.} \\cite{Wei2} to bound $S_{k}(p,a,-u)$ we obtain the estimate $E\\ll p^{2}$. Consequently, another application of the aforementioned lemma of Vaughan \\cite{Vau} to $S_{k}(p,a)$ delivers $S(p,a)\\ll p^{5/2}.$\n\\end{proof}\nThe reader may notice that this result is best possible since whenever $(k,p-1)>1$ then there is a positive proportion of positive integers $a\\leq p$ for which $S_{k}(p,a)\\gg p^{1/2}$, whence the above result delivers an asymptotic formula in those situations. It seems unclear whether the error term in the formula could be improved. Such improvement though would not have any impact in our work. For future purposes, it is convenient to define, for each $q\\in\\mathbb{N}$, the exponential sums\n\\begin{equation}\\label{kkk}\nS_{n}(q)=\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big(q^{-3}S(q,a)\\big)^{s}e_{q}(-na),\n\\ \\ \\ \\ S_{s}^{*}(q)=\\displaystyle\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big\\lvert q^{-3}S(q,a)\\big\\rvert^{s}\\end{equation} \nand to analyse their behaviour when summing over $q$.\n\\begin{lem}\\label{cor4}\nLet $s\\geq \\max(4,k+1)$. One has\n\\begin{equation}\\label{ssn}\\sum_{q\\leq Q}S_{s}^{*}(q)\\ll Q^{\\varepsilon}\\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\sum_{q\\leq Q}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon},\\end{equation} and for $s\\geq \\max(5, k+2)$ it follows that\n\\begin{equation}\\label{Sas}\\sum_{q\\leq Q}q^{1/k}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon}\\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\sum_{q>Q}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon-1/k}.\\end{equation}\n\\end{lem}\n\\begin{proof}\nTo show (\\ref{ssn}) it suffices to prove the bound for $S_{s}^{*}(q)$ since $\\lvert S_{n}(q)\\rvert\\leq S_{s}^{*}(q)$. Applying Lemmata \\ref{Sa} and \\ref{lem3.4} we deduce trivially that each of $S_{n}(p)$ and $S_{s}^{*}(p)$ is $O(p^{1-s/2}),$ and each of $S_{n}(p^{l})$ and $S_{s}^{*}(p^{l})$ is $O\\big(\\min(p^{l-s},l^{s}p^{l-ls/k+\\varepsilon})\\big)$ when $l\\geq 2$. Consequently, whenever $s\\geq \\max(4,k+1)$ then using the fact that $S_{s}^{*}(q)$ is multiplicative we find that\n\\begin{align*}\\sum_{q\\leq Q}S_{s}^{*}(q)\\ll \\prod_{p\\leq Q}\\big(1+\\sum_{l=1}^{\\infty}S_{s}^{*}(p^{l})\\big)\\ll \\prod_{p\\leq Q}(1+C/p)\\ll Q^{\\varepsilon},\n\\end{align*}\nwhere $C>0$ is some suitable constant. The first assertion of (\\ref{Sas}) follows by the same argument, and the second follows observing that then $$\\sum_{Q\\leq q\\leq 2Q}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon-1/k},$$ whence summing over dyadic intervals we obtained the desired result.\n\\end{proof}\n\\section{Singular series}\\label{sec4}\nWe give sufficient conditions in terms of the number of variables to ensure the local solubility of the problem and combine such work with the bounds obtained in the previous section to introduce and analyse the singular series associated to the problem. We also include a brief proof of Theorem \\ref{thm1.4}. For such purposes, a little preparation is required. Let $p$ a prime number and take $\\tau\\geq 0$ such that $p^{\\tau}|| 3k$. Let $\\gamma=2\\tau+1,$ consider the set\n\\begin{equation}\\label{after}\\mathcal{M}_{n}(p^{h})=\\Big\\{\\mathbf{Y}\\in [1,p^{h}]^{3s}:\\ \\sum_{i=1}^{s}T(\\bfy_{i})^{k}\\equiv n\\pmod{p^{h}}\\Big\\},\\end{equation} where $\\mathbf{Y}=(\\mathbf{y}_{1},\\ldots,\\mathbf{y}_{s})$ with $\\mathbf{y}_{i}\\in\\mathbb{N}^{3},$ and the subset $$\\mathcal{M}_{n}^{*}(p^{h})=\\Big\\{\\mathbf{Y}\\in \\mathcal{M}_{n}(p^{h}):\\  p\\nmid y_{1,1},\\ p\\nmid T(\\mathbf{y}_{1})\\Big\\},$$ \nwhere $\\mathbf{y}_{1}=(y_{1,1},y_{1,2},y_{1,3}).$ Define as well the quantities $M_{n}(p^{h})=\\lvert\\mathcal{M}_{n}(p^{h})\\rvert$ and ${M}_{n}^{*}(p^{h})=\\lvert\\mathcal{M}_{n}^{*}(p^{h})\\rvert.$\nHere the reader may want to observe that the divisibility restrictions on the above definition are imposed for a latter application of Hensel's Lemma. Before showing that under some constraint in the number of variables then ${M}_{n}^{*}(p^{\\gamma})>0$, we first provide an accurate description of the set\n\\begin{equation*}\\mathcal{M}_{3,3}(p^{h})=\\Big\\{T(\\bfx):\\ \\bfx\\in\\Big(\\mathbb{Z}/p^{h}\\mathbb{Z}\\Big)^{3},\\ (x_{1},p)=1\\Big\\}\\end{equation*} that will be used throughout the whole argument. \n\\begin{lem}\\label{lem11.3}\nLet $h\\in\\mathbb{N}.$ Then, whenever $p\\neq 3$ one finds that \\begin{equation}\\label{M33}\\mathcal{M}_{3,3}(p^{h})=\\mathbb{Z}/p^{h}\\mathbb{Z}.\\end{equation} For the case $p=3$ one has $\\mathcal{M}_{3,3}(3)=\\mathbb{Z}/3\\mathbb{Z}$ and when $h\\geq 2$ then $$\\mathcal{M}_{3,3}(3^{h})=\\Big\\{x\\in \\mathbb{Z}/3^{h}\\mathbb{Z}:\\ \\ x\\not\\equiv 4\\mmod{9},\\ x\\not\\equiv 5\\mmod{9}\\Big\\}.$$\n\\end{lem}\n\\begin{proof}\nWhen $p\\neq 3$, we can assume that $h=1$, since an application of Hensel's Lemma would then yield the case $h\\geq 2$. For a better description of the argument, it is convenient to define the counting functions \n\\begin{equation*}N_{n}(p)={\\rm card}\\Big\\{\\mathbf{x}\\in\\big(\\mathbb{Z}/p\\mathbb{Z}\\big)^{3}:\\ T(\\mathbf{x})\\equiv n\\pmod{p}\\Big\\},\\end{equation*}\n\\begin{equation*}N_{n,4}(p)={\\rm card}\\Big\\{\\mathbf{y}\\in\\big(\\mathbb{Z}/p\\mathbb{Z}\\big)^{4}:\\ y_{1}^{3}+y_{2}^{3}+y_{3}^{3}-ny_{4}^{3}\\equiv 0\\pmod{p}\\Big\\}.\\end{equation*}Observe that by making a distinction for the tuples counted in $N_{n,4}(p)$ regarding the divisibility of $y_{4}$ by $p$ one has that $(p-1)N_{n}(p)=N_{n,4}(p)-N_{0}(p)$. Note that when $(n,p)=1$ then the work of Weil \\cite{Wei} on equations over finite fields leads to\n$$\\lvert N_{n,4}(p)-p^{3}\\rvert\\leq 6(p-1)p\\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\lvert N_{0}(p)-p^{2}\\rvert\\leq 2(p-1)\\sqrt{p}.$$ Consequently, one finds that $N_{n}(p)=p^{2}+E_{p}$ with $\\lvert E_{p}\\rvert\\leq 6p+2\\sqrt{p},$\nand hence $N_{n}(p)\\geq 1$ for $p\\geq 7$. Observe as well that $N_{n}(2)\\geq 1$ and $N_{n}(5)\\geq 1$ follow trivially. This implies that there is at least one solution to the equation \\begin{equation}\\label{ec11.8}x^{3}+y^{3}+z^{3}\\equiv n\\pmod{p},\\ \\ \\ \\ \\ \\ (x,p)=1,\\end{equation} and when $n=0$ then $(1,-1,0)$ is also a solution for (\\ref{ec11.8}), whence the preceding discussion yields (\\ref{M33}).\n\nWhen $p=3$ then the case $h=1$ is trivial. Note that since cubes can only be $\\pm 1\\pmod{9}$, the only residues which cannot be written as sums of three cubes are $4$ and $5$. For $h=3$, a slightly tedious computation reveals that the only residues not represented as sums of three cubes are the ones congruent to $4$ or $5\\pmod{9}$. Therefore, a routine application of Hensel's Lemma implies the proof for $h\\geq 4.$\n\n\n\n\\end{proof}\n\nThe previous lemma asserts that the local solubility of the problem studied here only differs from the local solubility of the original Waring's problem at the prime $3.$ This conclusion is gathered in the following statement.\n\\begin{lem}\\label{lem9.1}\nSuppose that $s\\geq \\frac{p}{p-1}\\big(k,p^{\\tau}(p-1)\\big)$ when $p\\neq 2,3$ or $p=2$ and $\\tau=0$, that $s\\geq \\frac{9}{4}\\big(k,\\phi(3^{\\gamma})\\big)$ when $p=3$, that $s\\geq 2^{\\tau+2}$ when $p=2$ and $\\tau>0$ with $k>2$, and that $s\\geq 5$ when $p=k=2.$ Then one has $M_{n}^{*}(p^{\\gamma})>0.$\n\\end{lem}\n\\begin{proof}\nIf $p\\neq 3$ then Lemma \\ref{lem11.3} implies that the local solubility for each of these primes is equivalent to that of the original Waring's problem, hence Vaughan \\cite[Lemma 2.15]{Vau} yields $M_{n}^{*}(p^{\\gamma})>0.$ Here the reader might want to observe that the definition for $\\gamma$ taken here is different from the one in Vaughan \\cite[(2.25)]{Vau}, so one may have to apply Lemma 2.13 of \\cite{Vau} as well. For the case $p=3$, Lemma \\ref{lem11.3} delivers $$\\Big\\lvert\\mathcal{M}_{3,3}(3^{\\gamma})\\cap U(\\mathbb{Z}/3^{\\gamma}\\mathbb{Z})\\Big\\rvert=4\\cdot 3^{\\gamma-2},$$ where $U(\\mathbb{Z}/3^{\\gamma}\\mathbb{Z})$ denotes the group of units of $\\mathbb{Z}/3^{\\gamma}\\mathbb{Z}$. Therefore, using Vaughan \\cite[Lemma 2.14]{Vau} we get that\n$M_{n}^{*}(3^{\\gamma})>0$ whenever $s\\geq \\frac{9}{4}\\big(k,\\phi(3^{\\gamma})\\big).$ \n\\end{proof}\n\nObserve that by the combination of Lemma \\ref{lem11.3} and Vaughan \\cite[Lemma 2.14]{Vau} then for $u\\geq 9k/4$ we find that the form $T(\\mathbf{x}_{1})^{k}+\\dots+T(\\mathbf{x}_{u})^{k}$ covers all the residue classes modulo $3^{k}$. Take now $s$ such that every sufficiently large number can be written as a sum of $s$ integral $3k$-th powers. Given a large integer $n$, we can find integral triples $\\mathbf{x}_{1},\\dots, \\mathbf{x}_{u}$ for which $n\\equiv T(\\mathbf{x}_{1})^{k}+\\dots+T(\\mathbf{x}_{u})^{k}\\mmod{3^{k}}$ and $1\\leq \\mathbf{x}_{i}\\leq 3^{k}.$ Fixing any one such choice of the $\\mathbf{x}_{i}$, we can also find integers $x_{1},\\dots,x_{s}$ satisfying\n$$x_{1}^{3k}+\\dots+x_{s}^{3k}=3^{-k}\\Big(n-\\big(T(\\mathbf{x}_{1})^{k}+\\dots+T(\\mathbf{x}_{u})^{k}\\big)\\Big).$$Here the reader may find convenient to observe that the term on the right side of the equality is still large. Therefore, we obtain the representation\n$$n=T(\\mathbf{x}_{1})^{k}+\\dots+T(\\mathbf{x}_{u})^{3k}+3^{k}\\big(x_{1}^{3k}+\\dots+x_{s}^{3k}\\big).$$ Noting that the sums of three cubes on the right side have been replaced by the specialization $3x^{3}$, one gets $G_{3}(k)\\leq u+s,$ and hence by Wooley \\cite[Corollary 1.2.1]{Woo7} we have that $G_{3}(k)\\leq 3k\\big(\\log k+\\log\\log k+O(1)\\big),$ which yields Theorem \\ref{thm1.4}. As experts will realise, one could apply the ideas of Wooley \\cite{Woo5} to obtain a refinement of the shape $$G_{3}(k)\\leq 3k\\Bigg(\\log k+\\log\\log 3k+\\log 3+2+O\\Big(\\frac{\\log\\log k}{\\log k}\\Big)\\Bigg)$$ by using instead other specializations. For the sake of brevity though we omit making such analysis here.\n\nFinally we combine work of this section with estimates from the previous one to analyse the singular series. Observe that by (\\ref{kkk}) we can rewrite the singular series, defined in (\\ref{1A}), as\n$$\\mathfrak{S}(n)=\\sum_{q=1}^{\\infty}S_{n}(q).$$ To express the above series as a product of local densities it is convenient to define the infinite sum$$\\sigma(p)=\\sum_{l=0}^{\\infty}S_{n}(p^{l})$$ for each prime $p$. \n\\begin{prop}\\label{prop66}\nLet $s\\geq \\max(5,k+2)$. Then, one has \n\\begin{equation}\\label{hr}\\mathfrak{S}(n)=\\prod_{p}\\sigma(p),\\end{equation}\nthe series $\\mathfrak{S}(n)$ converges absolutely and $\\frak{S}(n)\\ll 1$. Moreover, if $s$ satisfy the conditions of Lemma \\ref{lem9.1} one gets $\\mathfrak{S}(n)\\gg 1.$ \n\\end{prop}\n\\begin{proof}\nUsing the estimates mentioned at the beginning of the proof of Lemma \\ref{cor4} we find\n\\begin{equation}\\label{ec4.1}\\sum_{l=1}^{\\infty}\\lvert S_{n}(p^{l})\\rvert\\ll p^{1-s/2}+p^{k-s}+\\sum_{l\\geq k+1}l^{s}p^{l-ls/k+\\varepsilon}\\ll p^{-3/2}.\\end{equation}\n Therefore, (\\ref{hr}) holds by multiplicativity, $\\mathfrak{S}(n)$ converges absolutely and $\\mathfrak{S}(n)\\ll 1.$ \nIn order to prove the lower bound, we recall first (\\ref{kkk}) and (\\ref{after}) to deduce that orthogonality then yields\n$$\\sum_{l=0}^{h}S_{n}(p^{l})=M_{n}(p^{h})p^{h(1-3s)}.$$\n If $s$ satisfy the conditions of Lemma \\ref{lem9.1}, an application of Hensel's Lemma gives the lower bound $M_{n}(p^{h})\\geq p^{(3s-1)(h-\\gamma)},$ which combined with the above equation implies that $\\sigma(p)\\geq p^{-(3s-1)\\gamma}.$ Consequently, the previous estimate and (\\ref{ec4.1}) deliver the lower bound $\\mathfrak{S}(n)\\gg 1$.\n\\end{proof}\n\\section{Approximation on the major arcs.}\\label{sec6}\nIn this section we use a simple argument involving the Riemman-Stieltjes integral and integration by parts to approximate $f(\\alpha)$ by an auxiliary function on the major arcs. We also provide bounds for this function. For such purposes, we introduce first some notation. Let $\\alpha\\in [0,1)$ and $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ with $(a,q)=1$. Denote $\\beta=\\alpha-a/q$ and define the aforementioned auxiliary function\n\\begin{equation}\\label{vbet}V(\\alpha,q,a)=q^{-3}S(q,a)v(\\beta),\\ \\ \\ \\ \\ \\ \\text{where}\\ \\ v(\\beta)=\\int_{[0,P]^{3}}e\\big(\\beta T(\\mathbf{x})^{k}\\big)d\\mathbf{x}.\\end{equation}\n\\begin{lem}\\label{lem6}\nLet $q<P$. Then one has that\n\\begin{equation*}\\label{fVV}f(\\alpha)=V(\\alpha,q,a)+O\\big(P^{2}q(1+n\\lvert \\beta\\rvert)\\big).\\end{equation*}\n\\end{lem}\n\\begin{proof}\nBefore embarking on our task, it is convenient to define the sums\n \\begin{equation*}K_{\\mathbf{r}}(\\beta)=\\displaystyle\\sum_{\\substack{\\mathbf{x}\\leq P\\\\ \\mathbf{x}\\equiv\\mathbf{r}\\pmod{q}}}e\\big(F_{\\beta}(\\mathbf{x})\\big),\\ \\ \\ \\ \\ \\ \\ B_{r}(x)=\\displaystyle\\sum_{\\substack{0<z\\leq x\\\\ z\\equiv r\\pmod{q}}}1,\\end{equation*} where $F_{\\beta}(\\mathbf{x})=\\beta T(\\mathbf{x})^{k}$. Observe that by sorting the summation into arithmetic progressions modulo $q$ we find that\n\\begin{equation}\\label{halpa}\nf(\\alpha)=\\sum_{\\mathbf{r}\\leq q}e_{q}\\big(aT(\\mathbf{r})^{k}\\big)K_{\\mathbf{r}}(\\beta).\n\\end{equation} \nFor each $\\mathbf{r}\\in\\mathbb{N}^{3}$ write $\\mathbf{r}=(\\mathbf{r}_{1},r_{3}).$ Then by Abel's summation formula we obtain \\begin{align*}\nK_{\\mathbf{r}}(\\beta)=&\nB_{r_{3}}(P)\\sum_{\\mathbf{x}_{1}}e\\big(F_{\\beta}(\\mathbf{x}_{1}, P)\\big)-\\int_{0}^{ P}\\sum_{\\mathbf{x}_{1}}\\frac{\\partial }{\\partial z}e\\big(F_{\\beta}(\\mathbf{x}_{1},z)\\big)B_{r_{3}}(z)dz,\n\\end{align*}\nwhere $\\mathbf{x}_{1}$ runs over pairs $\\mathbf{x}_{1}\\in [1,P]^{2}$ with $\\mathbf{x}_{1}\\equiv \\mathbf{r}_{1}\\mmod{q}$. Consequently, using the equation $B_{r_{3}}(x)=x/q+O(1)$ and integration by parts one gets\n$$K_{\\mathbf{r}}(\\beta)= q^{-1}\\int_{0}^{P}\\sum_{\\mathbf{x}_{1}}e\\big(F_{\\beta}(\\mathbf{x}_{1},z)\\big)dz+O\\big(q^{-2}P^{2}(1+n\\lvert\\beta\\rvert)\\big).$$ We repeat the exact same procedure for the first two variables to obtain\n$$K_{\\mathbf{r}}(\\beta)=q^{-3}v(\\beta)+O\\big(q^{-2}P^{2}(1+n\\lvert\\beta\\rvert)\\big),$$ whence the combination of the above expression with (\\ref{halpa}) yields the result claimed above.\n\\end{proof}\nIn order to make further progress, we provide an upper bound for $v(\\beta)$ in the following lemma. This lemma will be used throughout the major arc analysis.\n\\begin{lem}\\label{cota}\nLet $\\beta\\in\\mathbb{R}.$ One has that\n$$v(\\beta)\\ll \\frac{P^{3}}{(1+n\\lvert\\beta\\rvert)^{1/k}}.$$\n\\end{lem}\n\\begin{proof}\nLet $\\mathbf{y}\\in [0,P]^{2}$ and set $C_{\\mathbf{y}}=y_{1}^{3}+y_{2}^{3}$. Define the auxiliary function $B_{\\mathbf{y}}(y)=(3k)^{-1}y^{1/k-1}(y^{1/k}-C_{\\mathbf{y}})^{-2/3}$. Note that by a change of variables one can rewrite $v(\\beta)$ as \n\\begin{equation}\\label{bri}v(\\beta)=\\int_{\\mathbf{y}\\in[0,P]^{2}}\\int_{N_{\\mathbf{y}}}^{M_{\\mathbf{y}}}B_{\\mathbf{y}}(y)e(\\beta y)dyd\\mathbf{y},\\end{equation} where\n$N_{\\mathbf{y}}=C_{\\mathbf{y}}^{k}$ and $M_{\\mathbf{y}}=(P^{3}+C_{\\mathbf{y}})^{k}.$\nObserve first that when $\\lvert\\beta\\rvert\\leq n^{-1}$ then one trivially gets\n$$v(\\beta)\\ll \\int_{\\mathbf{y}\\in[0,P]^{2}}\\int_{N_{\\mathbf{y}}}^{M_{\\mathbf{y}}}B_{\\mathbf{y}}(y)dyd\\mathbf{y}\\ll P^{3}.$$\n\nFor the case $\\lvert\\beta\\rvert>n^{-1}$ we split the integral into\n$$v(\\beta)\\ll I_{1}+I_{2}+I_{3},$$ where $$I_{i}=\\int_{\\mathbf{x}\\in\\mathcal{T}_{i}}e\\big(\\beta T(\\mathbf{x})^{k}\\big)d\\mathbf{x}\\ \\ \\ \\ \\text{for each $i\\in\\{1,2,3\\}$}$$ and the sets of integration taken are\n$$\\mathcal{T}_{1}=\\Big\\{\\mathbf{x}\\in[0,P]^{3}:\\ \\ \\mathbf{x}\\leq \\lvert\\beta\\rvert^{-1/3k}\\Big\\},\\ \\ \\ \\mathcal{T}_{2}=\\Big\\{\\mathbf{x}\\in[0,P]^{3}:\\ \\ x_{2},x_{3}> \\lvert\\beta\\rvert^{-1/3k}\\Big\\},$$ $$\\mathcal{T}_{3}=\\Big\\{\\mathbf{x}\\in[0,P]^{3}:\\ \\ x_{3}> \\lvert\\beta\\rvert^{-1/3k},\\ \\ \\ \\ \\ \\ x_{1},x_{2}\\leq \\lvert\\beta\\rvert^{-1/3k}\\Big\\}.$$Note that for the first integral one has $I_{1}\\leq \\lvert \\mathcal{T}_{1}\\rvert\\ll \\lvert\\beta\\rvert^{-1/k}.$ For the other two it is convenient to define the parameter $T_{\\beta}=(\\lvert\\beta\\rvert^{-1/k}+C_{\\mathbf{y}})^{k}$ and consider the set $\\mathcal{M}_{2}=[0,P]\\times[\\lvert\\beta\\rvert^{-1/3k},P]$. Then, by applying integration by parts we find that\n$$I_{2}=\\int_{\\mathbf{y}\\in\\mathcal{M}_{2}}\\int_{T_{\\beta}}^{M_{\\mathbf{y}}}B_{\\mathbf{y}}(y)e(\\beta y)d\\mathbf{y}dy\\ll \\lvert\\beta\\rvert^{-1}\\int_{\\mathbf{y}\\in\\mathcal{M}_{2}}B_{\\mathbf{y}}(T_{\\beta})d\\mathbf{y},$$ where we used the fact that the function $B_{\\mathbf{y}}(y)$ is decreasing. Observe that whenever $\\mathbf{y}\\in \\mathcal{M}_{2}$ then one has $\\lvert\\beta\\rvert^{-1/k}\\leq C_{\\mathbf{y}}$, which delivers the estimate\n$$I_{2}\\ll \\lvert\\beta\\rvert^{-1+2/3k}\\int_{\\mathbf{y}\\in\\mathcal{M}_{2}}C_{\\mathbf{y}}^{1-k}d\\mathbf{y}\\ll \\lvert\\beta\\rvert^{-1+2/3k}\\int_{\\lvert\\beta\\rvert^{-1/3k}\\leq x}x^{4-3k}dx\\ll \\lvert\\beta\\rvert^{-1/k}.$$ Likewise, we introduce the set $\\mathcal{M}_{3}=[0,\\lvert\\beta\\rvert^{-1/3k}]^{2}$ to handle $I_{3}$. Using the same argument we get that\n$$I_{3}\\ll \\lvert\\beta\\rvert^{-1}\\int_{\\mathbf{y}\\in\\mathcal{M}_{3}}B_{\\mathbf{y}}(T_{\\beta})d\\mathbf{y},$$\nand applying the fact that $C_{\\mathbf{y}}\\ll \\lvert\\beta\\rvert^{-1/k}$ whenever $\\mathbf{y}\\in\\mathcal{M}_{3}$ to bound $B_{\\mathbf{y}}(T_{\\beta})$ then we obtain\n$$I_{3}\\ll  \\lvert\\beta\\rvert^{-1}\\int_{\\mathbf{y}\\in\\mathcal{M}_{3}}\\lvert\\beta\\rvert^{1-1/3k}d\\mathbf{y}\\ll \\lvert\\beta\\rvert^{-1/k}.$$The combination of the bounds for $I_{1},$ $I_{2}$ and $I_{3}$ yields the result of the lemma.\n\\end{proof}\n\\section{The asymptotic formula for $R(n)$.}\\label{sec7}\nWe compute the size of the singular integral and use the work and the bounds obtained in the previous sections to obtain an asymptotic formula for $R(n)$. Whenever $s\\geq k+1$ define the aforementioned singular integral by $$J(n)=\\displaystyle\\int_{-\\infty}^{\\infty}v(\\beta)^{s}e(-\\beta n) d\\beta.$$ Consider the set $$\\mathcal{S}=\\Big\\{(\\mathbf{y}_{1},y_{1},\\dots,\\mathbf{y}_{s},y_{s})\\in\\mathbb{R}^{3s}:\\ \\ \\mathbf{y}_{i}\\in [0,P]^{2},\\ \\ \\ N_{\\mathbf{y}_{i}}\\leq y_{i}\\leq M_{\\mathbf{y}_{i}}\\Big\\}.$$ Then, recalling (\\ref{bri}) and using a change of variables it follows that\n\\begin{align*}J(n)&\n=\\displaystyle\\lim_{\\lambda\\to\\infty}\\int_{-\\lambda}^{\\lambda}\\int_{\\mathbf{Y}\\in\\mathcal{S}}\\prod_{i=1}^{s}B_{\\mathbf{y}_{i}}(y_{i})e\\Big(\\beta\\Big(\\sum_{i=1}^{s}y_{i}-n\\Big)\\Big)d\\mathbf{Y}d\\beta\n\\\\\n&=\\lim_{\\lambda\\to\\infty}\\int_{0}^{3^{k}sn}\\phi(v)\\frac{\\sin\\big(2\\pi\\lambda(v-n)\\big)}{\\pi(v-n)}dv,\n\\end{align*}\nwhere we have taken \\begin{equation*}\\phi(v)=\\int_{\\mathbf{Y}\\in\\mathcal{S}'}B_{\\mathbf{y}_{s}}(\\gamma_{v})\\prod_{i=1}^{s-1}B_{\\mathbf{y}_{i}}(y_{i})\\ d\\mathbf{Y},\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{with}\\ \\ \\gamma_{v}=v-\\displaystyle\\sum_{i=1}^{s-1}y_{i}\\end{equation*}  and $\\mathcal{S}'\\subset \\mathbb{N}^{3s-1}$ is the set determined by the underlying inequalities. Observe that $\\phi(v)$ is a function of bounded variation, whence by Fourier's Integral Theorem it follows that $J(n)=\\phi(n)$. To obtain a precise formula for $J(n)$ it is convenient to introduce the subset $\\mathcal{Y}\\subset [0,n]^{s-1}$ defined by the constraint $0\\leq \\gamma_{n}\\leq n$. Then, by several subsequent changes of variables and the formula of the Euler's Beta function one has that\n\\begin{align}\\label{ec7.3} J(n)&\n=3^{-3s}k^{-s}\\Gamma\\big(1/3\\big)^{3s}\\int_{\\mathcal{Y}}\\gamma_{n}^{1/k-1}\\Big(\\prod_{i=1}^{s-1}y_{i}^{1/k-1}\\Big)\\ dy_{1}\\cdots dy_{s-1}\\nonumber\n\\\\\n&=\\Gamma\\big(4/3\\big)^{3s}\\Gamma\\big(1+1/k\\big)^{s}\\Gamma\\big(s/k\\big)^{-1}n^{s/k-1}.\n\\end{align}\nWe are now equipped to compute an asymptotic formula for the major arc contribution, which we define by\n$$R_{\\grM}(n)=\\int_{\\grM}f(\\alpha)^{s}e(-\\alpha n)d\\alpha.$$ \n\\begin{prop}\\label{prop7}\nLet $s\\geq \\max(5,k+2)$. Then,\n$$R_{\\grM}(n)=\\Gamma\\big(4/3\\big)^{3s}\\Gamma\\big(1+1/k\\big)^{s}\\Gamma\\big(s/k\\big)^{-1}\\mathfrak{S}(n)n^{s/k-1}+O(n^{s/k-1-\\delta}).$$\n\\end{prop}\n\\begin{proof}\nFor the sake of simplicity we consider the auxiliary function $f^{*}(\\alpha)$ for $\\alpha\\in [0,1)$ by putting $f^{*}(\\alpha)=V(\\alpha,q,a)$ when $\\alpha\\in\\grM(a,q)\\subset\\grM$ and $f^{*}(\\alpha)=0$ for $\\alpha\\in\\grm.$ We remind the reader that $V(\\alpha,q,a)$ was defined in (\\ref{vbet}). Recalling Lemma \\ref{lem6} then whenever $\\alpha\\in \\grM (a,q)$ one has that\n$$f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\ll P^{2s}q^{s}(1+n\\lvert \\beta\\rvert)^{s}+P^{2}q(1+n\\lvert \\beta\\rvert)\\lvert f^{*}(\\alpha)\\rvert^{s-1}.$$\nIntegrating over the major arcs, which were defined in (\\ref{5us}), we find that\n\\begin{align}\\label{ugu}\\int_{\\grM}\\lvert f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\rvert d\\alpha&\n\\ll P^{2s+\\xi(s+2)}n^{-1}+ P^{3s-3k-1+\\xi}\\sum_{q\\leq P^{\\xi}}S_{s-1}^{*}(q),\n\\end{align}\nand hence Lemma \\ref{cor4} and the assumption on $\\xi$ stated before (\\ref{5us}) implies that the above integral is $O(P^{3s-3k-\\delta})$. Observe that by the same lemma and Lemma \\ref{cota} respectively we have $$\\displaystyle\\sum_{ P^{\\xi}< q}\\lvert S_{n}(q)\\rvert =O(P^{-\\delta}) \\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\displaystyle\\int_{\\lvert \\beta\\rvert> \\frac{P^{\\xi}}{qn}}\\lvert v(\\beta)\\rvert^{s}d\\beta=O\\big(P^{3s-3k}q^{\\delta}P^{-\\delta\\xi}\\big)$$ for $q\\leq P^{\\xi}$. Combining these observations with the aforementioned lemmata and equations (\\ref{Sas}) and (\\ref{ugu}) we obtain $R_{\\grM}(n)=\\frak{S}(n)J(n)+O(n^{s/k-1-\\delta})$, and hence (\\ref{ec7.3}) delivers the result.\n\\end{proof}\nTheorem \\ref{thm9.1} then follows applying Propositions \\ref{prop222}, \\ref{prop66} and \\ref{prop7}.\n\\section{Asymptotic formula over the smooth numbers.}\\label{Sec99}\nIn this section we investigate the asymptotic formula for the representation function when two of the variables of each triple lie on the smooth numbers. The strategy for bounding the integral over the minor arcs of $g(\\alpha)$ combines arguments of Section \\ref{sec2} with major arc techniques. \nWe define the major arcs $\\grN$ to be the union of \n\\begin{equation}\\label{kioto}\\grN(a,q)=\\Big\\{ \\alpha\\in [0,1): \\big\\lvert \\alpha-a/q\\big\\rvert \\leq q^{-1}(\\log P)^{\\kappa}P^{-3k}\\Big\\}\\end{equation} with $0\\leq a\\leq q\\leq (\\log P)^{\\kappa}$ and $(a,q)=1$, where $\\kappa=1/5$. We take the minor arcs $\\grn=[0,1)\\setminus \\grN$. Similarly, when $1\\leq X\\leq L$ with $L=P^{1/3k},$ define $\\grW(X)$ as the union of the arcs\n$$\\grW(\\mathbf{a},q)=\\Big\\{\\boldsymbol{\\alpha}\\in [0,1)^{k}: \\lvert \\alpha_{j}-a_{j}/q\\rvert\\leq q^{-1}XP^{-3j}\\ \\ \\ \\ (1\\leq j\\leq k)\\Big\\}$$ with $0\\leq \\mathbf{a}\\leq q\\leq X$ and $(q,a_{1},\\dots,a_{k})=1$. For the sake of simplicity we write $$\\grW=\\grW(L),\\ \\ \\ \\ \\ \\ \\grP=\\grW\\big((\\log P)^{\\kappa}\\big),$$ and we take the minor arcs $\\grw=[0,1)^{k}\\setminus\\grW$ and $\\grp=[0,1)^{k}\\setminus\\grP.$\nFirst we prove a lemma which permits us to have a saving over the trivial bound for some Weyl sum on $\\grp$. For such purposes we consider the exponential sum associated to the Vinogradov's mean value system\n$$f_{k}(\\bfalpha;X)=\\sum_{1\\leq x\\leq X}e\\big(\\alpha_{1}x+\\ldots +\\alpha_{k} x^{k}\\big).$$\n\n\\begin{lem}\\label{pity}\nLet $X$ be any real positive number sufficiently big in terms of $k$, let $\\mu$ be a real number such that $\\mu^{-1}>4k(k-1)$ and let $\\gamma$ denote a real number with $X^{-\\mu}\\leq \\gamma\\leq 1.$ Then whenever $\\lvert f_{k}(\\bfalpha;X)\\rvert\\geq \\gamma X$, there exist an integer $q\\in\\mathbb{N}$ and a tuple $\\mathbf{a}=(a_{1},\\dots, a_{k})\\in\\mathbb{N}^{k}$ with $(q,a_{1},\\dots, a_{k})=1$ and $1\\leq q\\ll\\gamma^{-k-\\varepsilon}$ and such that\n$$ \\lvert q\\alpha_{j}-a_{j}\\rvert\\ll\\gamma^{-k-\\varepsilon}X^{-j}\\ \\ \\ \\ \\ (1\\leq j\\leq k).$$\n\\end{lem}\n\n\\begin{proof}\nSuppose that  $\\lvert f_{k}(\\bfalpha;X)\\rvert\\geq \\gamma X.$ Then, applying Wooley \\cite[Theorem 1.6]{Woo6} we obtain that there exist $q\\in\\mathbb{N}$ and $\\mathbf{a}\\in\\mathbb{N}^{k}$ with $(q,a_{1},\\dots, a_{k})=1$ such that $1\\leq q\\leq X^{1/k}$ and\n\\begin{equation}\\label{piiuuoo}\\lvert q\\alpha_{j}-a_{j}\\rvert\\leq X^{1/k-j}\\ \\ \\ \\ \\ \\ \\ (1\\leq j\\leq k).\\end{equation}\nIn order to make further progress it is convenient to define the auxiliary function \n$$T(\\bfalpha;q,\\mathbf{a})=q+\\lvert q\\alpha_{1}-a_{1}\\rvert X+\\dots+\\lvert q\\alpha_{k}-a_{k}\\rvert X^{k}.$$\nBy Theorems 7.1, 7.2 and 7.3 of Vaughan \\cite{Vau} one has that \n\\begin{equation*}\\lvert f_{k}(\\bfalpha;X)\\rvert\\ll q^{\\varepsilon}X T(\\bfalpha;q,\\mathbf{a})^{-1/k}+T(\\bfalpha;q,\\mathbf{a}).\n\\end{equation*}\nObserve that equation (\\ref{piiuuoo}) yields $T(\\bfalpha;q,\\mathbf{a})\\ll X^{1/k}$, which implies that $q^{\\varepsilon}X T(\\bfalpha;q,\\mathbf{a})^{-1/k}$ is the term dominating in the previous estimate. Therefore, by the preceding discussion and the fact that $q\\leq T(\\bfalpha;q,\\mathbf{a})$ we obtain $$\\gamma X\\leq \\lvert f_{k}(\\bfalpha;X)\\rvert\\ll XT(\\bfalpha;q,\\mathbf{a})^{-1/k+\\varepsilon},$$ which gives $T(\\bfalpha;q,\\mathbf{a})\\ll\\gamma^{-k-\\varepsilon}$ and delivers the lemma.\n\\end{proof}\nWe are now equipped to prove the minor arc estimate. Recalling (\\ref{Rseta}) and the definition of $\\mathcal{C}(P)$ made after (\\ref{rap}), observe that by orthogonality one has that\n\\begin{equation*}\\label{Reta}R_{\\eta}(n)=\\int_{0}^{1}g(\\alpha)^{s}e(-\\alpha n)d\\alpha, \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{where}\\ \\ g(\\alpha)=\\sum_{\\mathbf{x}\\in \\mathcal{C}(P)}e\\big(\\alpha T(\\mathbf{x})^{k}\\big).\\end{equation*}\nIn what follows we show that the minor arc contribution is smaller than the expected main term by combining the previous lemma and other minor arc estimates with some major arc ideas.\n\\begin{prop}\\label{prop123} Whenever $s$ is any positive integer with $s\\geq H(k)$ one has\n$$\\int_{\\grn}\\lvert g(\\alpha)\\rvert^{s} {\\rm     d}\\alpha\\ll P^{3s-3k}(\\log P)^{-\\delta}.$$\n\\end{prop}\n\n\\begin{proof}\nWe write $H(k)=2t$ for some positive integer $t$. Recalling (\\ref{GF}) and using the same argument as in (\\ref{puu}) it follows that\n\\begin{align}\\label{tiio}\n\\int_{\\grn}\\lvert g(\\alpha)\\rvert^{2t}d\\alpha\\ll P^{4t+3k(k-1)/2}\\int_{\\grn}\\int_{[0,1)^{k-1}}\\lvert F(\\bfalpha)\\lvert^{2t}d\\bfalpha.\n\\end{align}\nObserve that we can estimate the above integral by\\begin{equation}\\label{Falp}\\int_{\\grn}\\int_{[0,1)^{k-1}}\\lvert F(\\bfalpha)\\lvert^{2t}d\\bfalpha\\ll \\int_{\\grw}\\lvert F(\\bfalpha)\\lvert^{2t}d\\bfalpha+\\int_{\\grW\\setminus \\grP}\\lvert F(\\bfalpha)\\lvert^{2t}d\\bfalpha.\\end{equation}\nNote as well that combining Vaughan \\cite[Theorem 5.2]{Vau} with Bourgain's result on Vinogradov's mean value theorem \\cite[Theorem 1.1]{Bou} one has that\n\\begin{equation*}\\sup_{\\bfalpha\\in\\grw}\\lvert F(\\bfalpha)\\rvert\\ll P^{1-\\delta}. \\end{equation*}We then bound the first term on the right side of (\\ref{Falp}) via an application of the above pointwise bound and Wooley \\cite[Theorem 14.5]{Woo4} in the same way as in (\\ref{BF}) to obtain $$\\int_{\\grw}\\lvert F(\\bfalpha)\\lvert^{2t}d\\bfalpha\\ll P^{2t-3k(k+1)/2-\\delta}.$$\n\nIn order to estimate the second one we provide a major arc analysis. For such purpose we consider the auxiliary function $V(\\bfalpha;q,\\mathbf{a})=q^{-1}S(q,\\mathbf{a})I(\\bfalpha-\\mathbf{a}/q),$ where\n$$S(q,\\mathbf{a})=\\sum_{r=1}^{q}e_{q}\\big(a_{1}r^{3}+\\ldots +a_{k}r^{3k}\\big),\\ \\ \\ \\ \\ \\ I(\\bfbeta)=\\int_{0}^{P}e(\\beta_{1}\\gamma^{3}+\\ldots+\\beta_{k}\\gamma^{3k})d\\gamma.$$ For the sake of conciseness, we define for $\\bfalpha\\in [0,1)^{k}$ the function $V(\\bfalpha)=V(\\bfalpha;q,\\mathbf{a})$ when $\\bfalpha\\in \\grW(\\mathbf{a},q)\\subset \\grW$ and $V(\\bfalpha)=0$ for $\\bfalpha\\in\\grw.$ Observe that by Vaughan \\cite[Theorem 7.2]{Vau} then whenever $\\bfalpha\\in\\grW$ it follows that\n$$F(\\bfalpha)-V(\\bfalpha)\\ll L,$$ whence the triangle inequality then yields $$\\lvert F(\\bfalpha)\\rvert^{2t-2}-\\lvert V(\\bfalpha)\\rvert^{2t-2}\\ll LP^{2t-3}.$$ Therefore, combining the fact that ${\\rm mes}(\\grW)\\ll L^{k+1}P^{-3k(k+1)/2}$ with the above estimate we get\n$$\\int_{\\grW}\\lvert F(\\bfalpha)\\rvert^{2t-2}d\\bfalpha-\\int_{\\grW}\\lvert V(\\bfalpha)\\rvert^{2t-2}d\\bfalpha\\ll P^{2t-2-3k(k+1)/2-\\delta}.$$\nOn the other hand, note that Vaughan \\cite[Theorems 7.1, 7.3]{Vau} gives\n$$V(\\bfalpha)\\ll q^{\\varepsilon}P\\Big(q +\\lvert q\\alpha_{1}-a_{1}\\rvert P^{3}+\\cdots+\\lvert q\\alpha_{k}-a_{k}\\rvert P^{3k}\\Big)^{-1/3k},$$ and consequently, it follows that $$\\int_{\\grW}\\lvert F(\\bfalpha)\\rvert^{2t-2}d\\bfalpha\\ll P^{2t-2-3k(k+1)/2}.$$We finally apply Lemma \\ref{pity} to $F(\\bfalpha)$ to obtain that when $\\bfalpha\\in \\grp$ then one has $F(\\bfalpha)<P(\\log P)^{-\\delta}$ for some $\\delta>0$. Therefore, combining this bound with the above major arc estimate we obtain $$\\int_{\\grW\\setminus \\grP}\\lvert F(\\bfalpha)\\rvert^{2t}d\\bfalpha\\ll P^{2t-3k(k+1)/2}(\\log P)^{-\\delta}.$$ The preceding discussion and equations (\\ref{tiio}) and (\\ref{Falp}) imply the proposition.\n\\end{proof}Next we introduce some properties of the smooth numbers concerning their density and distribution over arithmetic progressions which will be used throughout the argument for the approximation of $g(\\alpha)$ over the major arcs. For such purposes, it is convenient to define\n$$A_{r}(m)=\\sum_{\\substack{x\\in \\mathcal{A}(m,P^{\\eta})\\\\ x\\equiv r\\pmod q}}1.$$\n\\begin{lem}\\label{lem8.1}\nLet $q,m\\in\\mathbb{N}$ with $q\\leq P^{\\eta}$ and $P^{\\eta}< m\\leq P.$ Then for each $0\\leq r\\leq q-1$ one has\n\\begin{equation*}A_{r}(m)=q^{-1}m\\rho\\Big(\\frac{\\log m}{\\eta\\log P}\\Big)+O\\Big(\\frac{m}{\\log m}\\Big),\\end{equation*} where the function $\\rho(x)$ was defined before Theorem \\ref{thm9.3}.\n\\end{lem}\n\\begin{proof}\nIt follows from Montgomery and Vaughan \\cite[Theorem 7.2]{Mon} and the argument of the proof of Vaughan \\cite[Lemma 5.4]{Vau3}.\n\\end{proof}\nWe are now equipped to provide the approximation for $g(\\alpha)$. In fact, we prove here a generalized version for future use in one of our forthcoming article. For such purpose, we take constants $0\\leq C_{1}<C_{2}$ and $C_{3}>0$. Let $Q>0$, let $m\\in\\mathbb{N}$ and define the exponential sum\n\\begin{equation*}g_{Q,m}(\\alpha)=\\displaystyle\\sum_{\\substack{\\mathbf{x}\\in\\mathcal{B}}}e\\big(\\alpha T(m\\mathbf{x})^{k}\\big),\\end{equation*} where $$\\mathcal{B}=\\Big\\{\\mathbf{x}\\in\\mathbb{N}^{3}:\\ \\ C_{1}Q<x_{1}\\leq C_{2}Q,\\ \\ \\  x_{2},x_{3}\\in \\mathcal{A}(C_{3}Q,Q^{\\eta})\\Big\\}.$$\nDespite making the choice $\\kappa=1/5$ in the definition (\\ref{kioto}), the following lemma contains a result which makes no use of that choice and remains valid for the range $0<\\kappa<1$.\n\\begin{lem}\\label{lem888}Let $\\alpha\\in \\grN(a,q)$, where $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ with $(a,q)=1$ and $q\\leq (\\log)^{\\kappa}$. Let $m\\in\\mathbb{N}$ with $(m,q)=1$. Take $Q>0$ with the property that $mQ\\asymp P$ and consider $\\beta=\\alpha-a/q$. Then,\n$$g_{Q,m}(\\alpha)=V_{Q,m}(\\alpha,q,a)+O\\big(E(Q)\\big),$$\nwhere we take $E(Q)=Q^{3}(\\log Q)^{\\kappa-1}\\log\\log Q$ and $$V_{Q,m}(\\alpha,q,a)=q^{-3}S(q,a)\\rho\\big(1/\\eta\\big)^{2}\\int_{\\mathbf{x}\\in\\mathcal{S}_{Q}}e\\big(F_{m}(\\mathbf{x})\\big)d\\mathbf{x}$$with $$F_{m}(\\mathbf{x})=\\beta T(m\\mathbf{x})^{k},\\ \\ \\ \\ \\ \\ \\mathcal{S}_{Q}=\\Big\\{\\mathbf{x}\\in \\mathbb{R}^{3}:\\ \\ C_{1}Q\\leq x_{1}\\leq C_{2}Q,\\ \\ 0\\leq x_{2},x_{3}\\leq C_{3}Q\\Big\\}.$$\n\\end{lem}\n\\begin{proof}For ease of notation, we omit the subscripts for the rest of the proof. We combine the ideas of the proof of Lemma \\ref{lem6} with the analysis of the distribution of smooth numbers discussed above. For such purposes, it is convenient to define first $$K_{\\mathbf{r}}(\\beta;m)=\\sum_{\\substack{\\mathbf{x}\\in\\mathcal{B}\\\\ \\mathbf{x}\\equiv\\mathbf{r}\\pmod{q}}}e\\big(F_{m}(\\mathbf{x})\\big).$$ Observe that by sorting the summation into arithmetic progressions modulo $q$ one has\n\\begin{equation}\\label{halp}\ng_{Q,m}(\\alpha)=\\sum_{\\mathbf{r}\\leq q}e_{q}\\big(aT(m\\mathbf{r})^{k}\\big)K_{\\mathbf{r}}(\\beta;m).\n\\end{equation} \nFor each $\\mathbf{r}\\in\\mathbb{N}^{3},$ write $\\mathbf{r}=(\\mathbf{r}_{1},r_{3})$ with $\\mathbf{r}_{1}=(r_{1},r_{2}).$ Then, we find that\n$$K_{\\mathbf{r}}(\\beta;m)=\\sum_{\\mathbf{x}_{1}}\\int_{0}^{C_{3}Q}e\\big(F_{m}(\\mathbf{x}_{1},x)\\big)dA_{r_{3}}(x),$$ where the integral on the right side is the Riemann-Stieltjes integral and $\\mathbf{x}_{1}$ runs over the set $$\\mathcal{C}_{\\mathbf{r}_{1}}=\\Big\\{\\mathbf{x}_{1}\\in\\mathbb{N}^{2},\\ \\ C_{1}Q< x_{1}\\leq C_{2}Q,\\ \\ x_{2}\\in\\mathcal{A}(C_{3}Q,Q^{\\eta}),\\ \\ \\mathbf{x}_{1}\\equiv \\mathbf{r}_{1}\\pmod{q}\\Big\\}.$$ The reader may find useful to observe that the contribution of the set $[0,Q/\\log Q]$ to the above integral is $O\\big(q^{-3}Q^{3}(\\log Q)^{-1}\\big)$, whence integration by parts yields\n\\begin{align*}\nK_{\\mathbf{r}}(\\beta;m)=&\nA_{r_{3}}(C_{3}Q)\\sum_{\\mathbf{x}_{1}}e\\big(F_{m}(\\mathbf{x}_{1},C_{3}Q)\\big)-\\int_{Q/\\log Q}^{C_{3}Q}\\sum_{\\mathbf{x}_{1}}\\frac{\\partial }{\\partial z}e\\big(F_{m}(\\mathbf{x}_{1},z)\\big)A_{r_{3}}(z)dz\n\\\\\n&+O\\big(q^{-3}Q^{3}(\\log Q)^{-1}\\big).\n\\end{align*}\nObserve that $(mQ)^{3k}\\lvert\\beta\\rvert\\ll n\\lvert\\beta\\rvert\\ll q^{-1}(\\log Q)^{\\kappa}$. Therefore, the integral of the error term that arises when we approximate $A_{r_{3}}(z)$ in the above equation is bounded above by $$\\int_{Q/\\log Q}^{C_{3}Q}\\sum_{\\mathbf{x}_{1}}\\Big\\lvert\\frac{\\partial F_{m}}{\\partial z}(\\mathbf{x}_{1},z)\\Big\\rvert\\frac{z}{\\log z}dz\\ll q^{-3}Q^{3}(\\log Q)^{\\kappa-1}.$$ \n\nBefore embarking in the process of giving a better description of the above equation, we recall that an application of the mean value theorem gives that for any $w\\in [Q/\\log Q,C_{3}Q]$ then\n\\begin{equation*}\\label{tuii}\\Big\\lvert\\rho\\Big(\\frac{1}{\\eta}\\Big)-\\rho\\Big(\\frac{\\log w}{\\eta \\log Q}\\Big)\\Big\\rvert\\ll \\frac{\\log\\log Q}{\\log Q}.\\end{equation*}\nConsequently, by Lemma \\ref{lem8.1} and the preceding discussion we obtain \n\\begin{align*}\\label{Keta}K_{\\mathbf{r}}(\\beta;m)=&\nq^{-1}\\rho\\big(1/\\eta\\big)C_{3}Q\\sum_{\\mathbf{x}_{1}}e\\big(F_{m}(\\mathbf{x}_{1},C_{3}Q)\\big)\n\\\\\n&-q^{-1}\\rho\\big(1/\\eta\\big)\\int_{Q/\\log Q}^{C_{3}Q}z\\sum_{\\mathbf{x}_{1}}\\frac{\\partial }{\\partial z}e\\big(F_{m}(\\mathbf{x}_{1},z)\\big)dz+O\\big(q^{-3}E(Q)\\big),\n\\end{align*}\nand hence integration by parts yields \n$$K_{\\mathbf{r}}(\\beta;m)=q^{-1}\\rho\\big(1/\\eta\\big)\\int_{0}^{C_{3}Q}\\sum_{\\mathbf{x}_{1}}e\\big(F_{m}(\\mathbf{x}_{1},z)\\big)dz+O\\big(q^{-3}E(Q)\\big),$$ where we implicitly used that the term arising after evaluating at the endpoints and the contribution of the interval $[0,Q/\\log Q]$ to the above integral is $O(q^{-3}Q^{3}(\\log Q)^{-1}).$ Likewise, applying a similar procedure for the second variable one gets\n\\begin{equation}\\label{Kq}K_{\\mathbf{r}}(\\beta;m)=q^{-2}\\rho\\big(1/\\eta\\big)^{2}\\int_{\\mathbf{y}\\in[0,C_{3}Q]^{2}}\\sum_{x}e\\big(F_{m}(x,\\mathbf{y})\\big)d\\mathbf{y}+O\\big(q^{-3}E(Q)\\big),\\end{equation}\nwhere $x$ runs over the range $C_{1}Q< x\\leq C_{2}Q$ and $x\\equiv r_{1}\\mmod{q}$.\nFor the first variable, we follow the same procedure as in Lemma \\ref{lem6} to obtain \n$$\\sum_{x\\equiv r_{1}\\mmod{q}}e\\big(F_{m}(x,\\mathbf{y})\\big)=q^{-1}\\int_{C_{1}Q}^{C_{2}Q}e\\big(F_{m}(x,\\mathbf{y})\\big)dx+O\\big(1+q^{-1}(\\log Q)^{\\kappa}\\big).$$ Consequently, combining the above equation with (\\ref{Kq}) we get\n$$K_{\\mathbf{r}}(\\beta;m)=q^{-3}\\rho\\big(1/\\eta\\big)^{2}\\int_{\\mathbf{x}\\in\\mathcal{S}_{Q}}e\\big(F_{m}(\\mathbf{x})\\big)d\\mathbf{x}+O\\big(q^{-3}E(Q)\\big).$$Observe that since $(m,q)=1$ then a change of variables yields $S(q,am^{3k})=S(q,a).$ The lemma then follows by the preceding discussion and (\\ref{halp}).\n\\end{proof}\n\\begin{cor}\\label{corcor}\nLet $\\alpha\\in \\grN(a,q)$ where $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ with $(a,q)=1$ and $q\\leq (\\log P)^{\\kappa}$. Consider $\\beta=\\alpha-a/q.$ One has that\n$$g(\\alpha)=W(\\alpha,q,a)+O(P^{3}(\\log P)^{\\kappa-1}\\log\\log P),$$ where on recalling (\\ref{vbet}) we take\n$$W(\\alpha,q,a)=q^{-3}S(q,a)\\rho(1/\\eta)^{2}v(\\beta).$$\n\\end{cor}\n\\begin{proof}\nNote that $g(\\alpha)=g_{P,1}(\\alpha)$ with the choices $C_{1}=0$, $C_{2}=1$ and $C_{3}=1$. The result is then a consequence of the previous lemma.\n\\end{proof}\nIn the rest of the section we deduce an asymptotic formula for the contribution over the major arcs. For such purposes, consider the integral\n$$R_{\\grN}(n)=\\int_{\\grN}g(\\alpha)^{s}e(-\\alpha n)d\\alpha.$$ Define the auxiliary function $g^{*}(\\alpha)$ for $\\alpha\\in[0,1)$ by putting $g^{*}(\\alpha)=W(\\alpha,q,a)$ when $\\alpha\\in\\grN(a,q)\\subset\\grN$ and $g^{*}(\\alpha)=0$ for $\\alpha\\in\\grn.$ \n\n\\begin{prop}\\label{thm10.1}\nLet $s\\geq \\max(5,k+2)$. Then, there exists a constant $\\delta>0$ such that\n$$R_{\\grN}(n)=\\Gamma\\big(4/3\\big)^{3s}\\Gamma\\big(1+1/k\\big)^{s}\\Gamma\\big(s/k\\big)^{-1}\\rho\\big(1/\\eta\\big)^{2s}\\mathfrak{S}(n)n^{s/k-1}+O(n^{s/k-1}(\\log n)^{-\\delta}).$$\n\\end{prop}\n\n\n\n\\begin{proof}\nObserve that by the definition (\\ref{kioto}) then for $\\alpha\\in\\grN(a,q)$ and $\\beta=\\alpha-a/q$ one has $$(1+n\\lvert\\beta\\rvert)^{-(s-1)/k}\\geq (\\log P)^{-(s-1)\\kappa/k}\\geq (\\log P)^{(s-1)(\\kappa-1)}.$$ Consequently, Lemmata \\ref{cota} and Corollary \\ref{corcor} yield\n$$g(\\alpha)^{s}-g^{*}(\\alpha)^{s}\\ll P^{3s}(\\log P)^{\\kappa-1+\\varepsilon}(1+n\\lvert\\beta\\rvert)^{-(s-1)/k},$$\nwhence integrating over the major arcs we obtain that\n\\begin{align*}\\int_{\\grN}\\big\\lvert g(\\alpha)^{s}-g^{*}(\\alpha)^{s}\\big\\rvert d\\alpha\\ll P^{3s-3k}(\\log P)^{-\\delta}.\n\\end{align*} \nObserve that by Lemmata \\ref{cor4} and \\ref{cota} respectively we have $$\\displaystyle\\sum_{ q>(\\log P)^{\\kappa}}\\lvert S_{n}(q)\\rvert\\ll (\\log P)^{-\\delta}\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\displaystyle\\int_{\\lvert \\beta\\rvert> \\frac{(\\log P)^{\\kappa}}{qn}}\\lvert v(\\beta)\\rvert^{s}d\\beta\\ll P^{3s-3k}q^{\\delta}(\\log P)^{-\\delta\\kappa},$$ where in the second integral $q\\leq (\\log P)^{\\kappa}$. Consequently, the combination of the aforementioned lemmas, equations (\\ref{Sas}) and (\\ref{ec7.3}) and the above bounds deliver the theorem.\n\\end{proof}\nTheorem \\ref{thm9.3} then follows by the application of Proposition \\ref{prop66}, the estimate for the minor arcs in Proposition \\ref{prop123} and the above proposition.\n\\section{Lower bound for $r(n)$.}\\label{Sec999}\nIn this section we prove Theorem \\ref{thm9.2} via an application of Theorem \\ref{thm9.3}. The main idea is to show that the contribution to $R_{\\eta}(n)$ of tuples whose coordinates have many representations as sums of three positive integral cubes is fairly small. We present first some notation and a simple lemma which will be used in the proof. Recalling the definition for $s_{3}(n)$ described before (\\ref{ec12}) and the parameter $\\nu$ presented right after that equation, let $\\theta=\\nu/ k$ and consider the set \n$$S_{K}(n)=\\Big\\{m\\in\\mathbb{N}:\\ 1\\leq m\\leq n^{1/k}:\\ s_{3}(m)>Kn^{\\theta}\\Big\\},$$ where $K>0$.\n\\begin{lem}\\label{lemup}\nLet $n\\in\\mathbb{N}$ and $K>0$. Then\n$$\\sum_{m\\in S_{K}(n)}s_{3}(m)\\ll K^{-1}n^{1/k}.$$\n\\end{lem}\n\\begin{proof} It follows by noting that \n$$\\sum_{m\\in S_{K}(n)}s_{3}(m)\\ll K^{-1}n^{-\\theta}\\sum_{m\\in S_{K}(n)}s_{3}(m)^{2}\\ll K^{-1}n^{1/k},$$\nwhere in the last step we used (\\ref{ec12}).\n\\end{proof}Define $R_{1}(n)$ as the contribution to $R_{\\eta}(n)$ of tuples $\\mathbf{X}\\in\\mathscr{C}^{s}$ for which $x_{i}\\in S_{K}(n)$ for some $i$. Let $R_{0}(n)$ be the contribution to $R_{\\eta}(n)$ of tuples $\\mathbf{X}\\in\\mathscr{C}^{s}$ with $x_{i}\\notin S_{K}(n)$ for every $1\\leq i\\leq s$. Observe that with this notation then one has\n\\begin{equation}\\label{puff}R_{\\eta}(n)=R_{0}(n)+R_{1}(n).\\end{equation}\nNote that by orthogonality, Theorem \\ref{thm9.3} and Lemma \\ref{lemup} one finds that\n\\begin{align*}R_{1}(n)&\n\\ll \\sum_{m\\in S_{K}(n)}s_{3}(m)\\int_{0}^{1}g(\\alpha)^{s-1}e\\big(-\\alpha (n-m^{k})\\big)\\ d\\alpha\\ll n^{(s-1)/k-1}\\sum_{m\\in S_{K}(n)}s_{3}(m)\n\\\\\n&\\ll K^{-1}n^{s/k-1}.\n\\end{align*}\nwhenever $s-1\\geq H(k)$. Therefore, taking $K$ to be big enough in terms of $k$ and $s$, we have by Theorem \\ref{thm9.3} and (\\ref{puff}) that $R_{\\eta}(n)\\asymp R_{0}(n)$. Since each representation of $n$ as a sum of $k$-th powers of elements of $\\mathscr{C}$ is counted at most $s_{3}(x_{1})\\dots s_{3}(x_{s})\\leq K^{s}n^{s\\theta}$ times by $R_{0}(n)$, we find that\n$$r(n)\\gg n^{s/k-1-s\\theta}=n^{(1-\\nu)s/k-1},$$ which delivers Theorem \\ref{thm9.2}.\n\\appendix\n\\section{Asymptotic formula for small powers}\nWe improve the constraint on the number of variables in Theorem \\ref{thm9.1} for the cases $2\\leq k\\leq 7$ by interpolating between some restriction estimates and mean value bounds for Weyl sums over the minor arcs computed in Proposition \\ref{prop222}. In the following lemma we present the aforementioned restriction estimate bounds, but first define $r(k)=2^{k}$ for $2\\leq k\\leq 3$ and $r(k)=k(k+1)$ when $4\\leq k\\leq 7.$ For the sake of conciseness, we omit writing the dependence on $k$ for the rest of the section.\n\\begin{lem}\\label{lem123}\nOne has that\n$$\\int_{0}^{1}\\lvert f(\\alpha)\\rvert^{r}{\\rm     d}\\alpha\\ll P^{13r/4-3k+\\varepsilon}.$$\n\\end{lem}\n\\begin{proof}\nNote that recalling the definition of $r_{3}(n)$ before (\\ref{Rs}) we can rewrite the exponential sum $f(\\alpha)$ as $$f(\\alpha)=\\displaystyle\\sum_{x\\leq 3P^{3}}r_{3}(x)e(\\alpha x^{k}).$$\nWe then apply mean value estimates of Bourgain \\cite[(1.6)]{Bou1} when $k=2$, Hughes and Wooley \\cite[Theorem 4.1]{Hug} for the case $k=3$ and Wooley \\cite[Corollary 1.4]{Woo4} when $4\\leq k\\leq 7$ to obtain\n\\begin{align*}\\int_{0}^{1}\\lvert f(\\alpha)\\rvert^{r}d\\alpha\\ll  P^{3r/2-3k+\\varepsilon}\\Big(\\sum_{1\\leq m\\leq 3P^{3}} r_{3}(m)^{2}\\Big)^{r/2}.\\end{align*} Observe that the cited result for the case $4\\leq k\\leq 7$ is the weighted version of Vinogradov's mean value theorem. As experts will realise, we can apply such result to obtain the estimate that we use here via an analogue argument of the one used in (\\ref{puu}). The lemma then follows by combining the previous bound with (\\ref{rap}).\n\\end{proof}\nBefore describing the rest of the proof it is convenient to introduce some parameters. Take $h=\\lfloor (k+1)/2\\rfloor.$ Consider $p=1+r/4\\xi_{0}$ and the exponents $q=p/(p-1)$ and $t=r/p+3k(3k+1)/q$, where $\\xi_{0}$ is defined as the positive root of the quadratic equation obtained imposing the condition $\\xi_{0}=1-1/(t-2h+1)$. Let $s=\\lceil t\\rceil.$ Both the values of $s$ and $t$ are gathered in Table \\ref{chart2}. The following statement improves the number of variables obtained in Proposition \\ref{prop222} by interpolating the estimates that we get in the second part of Proposition \\ref{prop222} with Lemma \\ref{lem123}. \n\\begin{table}\\label{table2}\n\\begin{tabular}{ | m{1cm} | m{1.5cm}| m{1.5cm}  | m{1.5cm}  | m{1.5cm}  | m{1.5cm} | m{1.5cm} |} \n\\hline\n$k$ &  $2$ & $3$ & $4$ & $5$ & $6$ & $7$ \\\\ \n\\hline\n$s$ &  $24$ & $63$ & $134$ & $216$ & $316$ & $435$ \\\\ \n\\hline\n$t$ &  $23.4331$ & $62.9722$ & $133.4783$ & $215.3978$ & $315.9897$ & $434.9924$ \\\\ \n\\hline\n\\end{tabular}\n\\caption{}\n\\label{chart2}\n\\end{table}\n\\begin{prop}\\label{prop24}\nOne has that\n$$\\int_{\\grm}\\lvert f(\\alpha)\\rvert^{s} {\\rm     d}\\alpha\\ll P^{3s-3k-\\delta},$$\nwhere we take the minor arcs $\\grm$ to be as described right after (\\ref{5us}) with $\\xi$ on the range $\\xi_{0}<\\xi<1-1/(s-2h+1)$.\n\\end{prop}\n\\begin{proof} By H\\\"older's inequality, Proposition \\ref{prop222} and Lemma \\ref{lem123} we obtain that\n\\begin{align*}\\int_{\\grm}\\lvert f(\\alpha)\\rvert^{t} {\\rm     d}\\alpha\\ll\n& \\Big(\\int_{0}^{1}\\lvert f(\\alpha)\\rvert ^{r}d\\alpha\\Big)^{1/p}\\Big(\\int_{\\grm}\\lvert f(\\alpha)\\rvert ^{3k(3k+1)}d\\alpha\\Big)^{1/q}\n\\\\\n&\\ll \\big(P^{13r/4-3k+\\varepsilon}\\big)^{1/p}\\big(P^{27k^{2}+6k-\\xi+\\varepsilon}\\big)^{1/q}\\ll P^{3t-3k-\\delta},\n\\end{align*}from where the lemma follows by observing that $t<s.$\n\\end{proof}\nThe rest of the appendix is devoted to make a refinement of the argument used in Proposition \\ref{prop7} to enlarge the major arcs by taking $\\xi$ on the range described above and win one variable for the cases $k=3,6$ and $7$. Let $q<P$. Denote by $N(q,P)$ the number of solutions of the congruence \n$$T(\\mathbf{x}_{1})^{k}+\\ldots+T(\\mathbf{x}_{h})^{k}\\equiv T(\\mathbf{y}_{1})^{k}+\\ldots+T(\\mathbf{y}_{h})^{k}\\pmod{q},$$where $0\\leq\\mathbf{x}_{i},\\mathbf{y}_{i}\\leq P.$ By expressing $q$ as the product of prime powers, using the structure of the ring of integers of these prime powers and noting that the number of primes dividing $q$ is bounded by $q^{\\varepsilon}$ we obtain $N(q,P)\\ll q^{\\varepsilon-1}P^{2h},$ and hence orthogonality yields\n\\begin{equation}\\label{oror}\\sum_{a=1}^{q}\\lvert f(\\beta+a/q)\\rvert^{2h}\\ll qN(q,P)\\ll q^{\\varepsilon}P^{2h}.\\end{equation}\nNow consider the difference function $D(\\alpha)=f(\\alpha)-f^{*}(\\alpha).$ By the triangle inequality one has\n$$\\lvert f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\rvert \\ll F_{1}(\\alpha)+F_{2}(\\alpha),$$\nwhere $F_{1}(\\alpha)=\\lvert f(\\alpha)\\rvert^{2h}\\lvert D(\\alpha)\\rvert\\big( \\lvert f^{*}(\\alpha)\\rvert^{s-2h-1}+\\lvert D(\\alpha)\\rvert^{s-2h-1}\\big)$ and $F_{2}(\\alpha)=\\lvert D(\\alpha)\\rvert \\lvert f^{*}(\\alpha)\\rvert^{s-1}.$ The integral over the major arcs for $F_{2}(\\alpha)$ is bounded in the same way as in equation (\\ref{ugu}), and by combining Lemmata \\ref{lem6} and \\ref{cota} with equation (\\ref{oror}) we get\n\\begin{align*}\\int_{\\grM}F_{1}(\\alpha) d\\alpha&\n\\ll P^{3s-3k+\\xi-1+\\varepsilon}\\sum_{q\\leq P^{\\xi}}S_{s-2h-1}^{*}(q)+P^{3s-3k+(s-2h+1)\\xi-s+2h}\\sum_{q\\leq P^{\\xi}}q^{\\varepsilon-1}.\n\\end{align*}\nUsing the fact that $\\xi<1-1/(s-2h+1)$ and Lemma \\ref{cor4} we obtain that the previous integral is $O(P^{3s-3k-\\delta}).$ Therefore, by the preceding discussion, the argument following (\\ref{ugu}) and Propositions \\ref{prop66} and \\ref{prop24} then the conclusion of Theorem \\ref{thm9.1} holds for the values of $s$ in Table \\ref{chart2}.\n\n\\emph{Acknowledgements}: The author's work was supported in part by a European Research Council Advanced\nGrant under the European Union\u2019s Horizon 2020 research and innovation programme via grant agreement No. 695223 during his studies at the University of Bristol. It was completed while the author was visiting Purdue University under Trevor Wooley's supervision. The author would like to thank him for his guidance and helpful comments, and both the University of Bristol and Purdue University for their support and hospitality.\n\n\\begin{thebibliography}{9}\n\\bibitem{B-B} A. Balog, J. Br\\\"udern, \\emph{Sums of three cubes in three linked three-progressions}, J. Reine Angew. Math. 466 (1995), 45--85. \n\\bibitem{Bou1} J. Bourgain, \\emph{On $\\Lambda(p)-$subsets of squares}, Israel J. Math. 67, No. 3 (1989), 291--311.\n\\bibitem{Bou} J. Bourgain, \\emph{On the Vinogradov mean value}, Tr. Mat. Inst. Steklova 296 (2017), Analiticheskaya i Kombinatornaya Teoriya Chisel, 36--46.\n\\bibitem{B-W} J. Br\\\"udern, T. D. Wooley, \\emph{Correlation estimates for sums of three cubes}, Ann. Sc. Norm. Super. Pisa Cl. Sci. (5) 16, No. 3 (2016), 789--816.\n\\bibitem{Dav2} H. Davenport, \\emph{Sums of three positive cubes}, J. London Math. Soc. 25 (1950), 339--343.\n\\bibitem{G-T} B. Green, T. Tao, \\emph{The primes contain arbitrarily long arithmetic progressions}, Ann. of Math. 167 (2008), 481--547.\n\\bibitem{Har} G. H. Hardy, J. E. Littlewood, \\emph{A new solution of Waring's problem}, Quarterly Journal of Mathematics 48 (1920), 272--293.\n\\bibitem{Hea} D. R. Heath-Brown, \\emph{The circle method and diagonal cubic forms}, Phil. Trans. Roy. Soc. London Ser. A 356, No. 1738 (1998), 673--699.\n\\bibitem{Hol1} C. Hooley, \\emph{On Waring's problem}, Acta Math. 157 (1986), 49--97.\n\\bibitem{Hol2} C. Hooley, \\emph{On Hypothesis $K^{*}$ in Waring's problem}, Sieve methods, exponential sums and their applications in number theory (Cardiff, 1995), London Math. Soc. Lecture Note Ser. 237, Cambridge University Press, Cambridge 1997, 175--185.\n\\bibitem{Hug} K. Hughes, T. D. Wooley, \\emph{Discrete restriction for $(x,x^{3})$ and related topics}, preprint.\n\\bibitem{Mah} K. Mahler, \\emph{Note on hypothesis $K$ of Hardy and Littlewood}, J. London Math. Soc. 11 (1936), 136--138.\n\\bibitem{Mon} H. L. Montgomery, R. C. Vaughan, \\emph{Multiplicative Number Theory: I. Classical Theory}, Cambridge University Press, 2006.\n\\bibitem{Sch} W. M. Schmidt, \\emph{Equations over finite fields. An elementary approach. Lecture Notes in Mathematics}, 536 (1976), Berlin: Springer--Verlag.\n\\bibitem{Vau3} R. C. Vaughan, \\emph{A new iterative method in Waring's problem}, Acta Math. 162 (1989), 1--71.\n\\bibitem{Vau} R. C. Vaughan, \\emph{The Hardy-Littlewood method}, 2nd edition, Cambridge University Press, Cambridge, 1997.\n\\bibitem{Wei2} A. Weil, \\emph{On some exponential sums}, Proc. Nat. Acad. Sci. U.S.A. 34 (1948), 204--207.\n\\bibitem{Wei} A. Weil, \\emph{Number of solutions of equations in finite fields}, Bull. Amer. Math. Soc. 55 (1949), 497--508.\n\\bibitem{Woo7} T. D. Wooley, \\emph{Large Improvements in Waring's Problem}, Annals of Math, Second Series, Vol. 135, No. 1 (1992), 131--164.\n\\bibitem{Woo1} T. D. Wooley, \\emph{Breaking classical convexity in Waring's problem: Sums of cubes and quasidiagonal\nbehaviour}, Inventiones Math. 122 (1995), 421--451.\n\\bibitem{Woo5} T. D. Wooley, \\emph{New estimates for smooth Weyl sums}, London Math. Soc. (2) 51, No. 1 (1995), 1--13.\n\\bibitem{Woo2} T. D. Wooley, \\emph{Sums of three cubes}, Mathematika. 47, No. 1--2 (2000),  53--61.\n\\bibitem{Woo6} T. D. Wooley, \\emph{Vinogradov's mean value theorem via efficient congruencing}, Annals of Math, Vol. 175 (2012), 1575--1627.\n\\bibitem{Woo3} T. D. Wooley, \\emph{Sums of three cubes, II}, Acta Arith. 170, No. 1 (2015), 73--100.\n\\bibitem{Woo4} T. D. Wooley, \\emph{Nested efficient congruencing and relatives of Vinogradov's mean value theorem}, Proc. London Math. Soc. (3) 118, No. 4 (2019), 942--1016.\n\n\\end{thebibliography}\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:01:02", "yymm": "2010", "arxiv_id": "2010.14536", "url": "https://arxiv.org/abs/2010.14536", "source": "arxiv"}}
{"text": "%%\n%% This is file `sample-acmsmall.tex',\n%% generated with the docstrip utility.\n%%\n%% The original source files were:\n%%\n%% samples.dtx  (with options: `acmsmall')\n%% \n%% IMPORTANT NOTICE:\n%% \n%% For the copyright see the source file.\n%% \n%% Any modified versions of this file must be renamed\n%% with new filenames distinct from sample-acmsmall.tex.\n%% \n%% For distribution of the original source see the terms\n%% for copying and modification in the file samples.dtx.\n%% \n%% This generated file may be distributed as long as the\n%% original source files, as listed above, are part of the\n%% same distribution. (The sources need not necessarily be\n%% in the same archive or directory.)\n%%\n%% The first command in your LaTeX source must be the \\documentclass command.\n%\\documentclass[acmsmall,review,anonymous]{acmart}\n%\\documentclass[acmsmall,review,dvipsnames,x11names ]{acmart}\n%\\settopmatter{printfolios=true,printccs=false,printacmref=false}\n%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)\n%\\documentclass[acmsmall,review,anonymous]{acmart}\\settopmatter{printfolios=true,printccs=false,printacmref=false}\n%% For double-blind review submission, w/ CCS and ACM Reference\n%\\documentclass[acmsmall,review,anonymous]{acmart}\\settopmatter{printfolios=true}\n%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)\n%\\documentclass[acmsmall,review]{acmart}\\settopmatter{printfolios=true,printccs=false,printacmref=false}\n%% For single-blind review submission, w/ CCS and ACM Reference\n%\\documentclass[acmsmall,review]{acmart}\\settopmatter{printfolios=true}\n%% For final camera-ready submission, w/ required CCS and ACM Reference\n\\documentclass[acmsmall,dvipsnames,x11names]{acmart}\n\\settopmatter{printacmref=false} % Removes citation information below abstract\n\\renewcommand\\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column\n\\pdfoutput=1\n%\\pagestyle{plain}\n\n\n%% Journal information\n%% Supplied to authors by publisher for camera-ready submission;\n%% use defaults for review submission.\n\\acmJournal{PACMPL}\n\\acmVolume{1}\n\\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA\n%\\acmArticle{1}\n\\acmYear{2020}\n\\acmMonth{10}\n%\\acmDOI{} % \\acmDOI{10.1145/nnnnnnn.nnnnnnn}\n\\startPage{1}\n\n%% Copyright information\n%% Supplied to authors (based on authors' rights management selection;\n%% see authors.acm.org) by publisher for camera-ready submission;\n%% use 'none' for review submission.\n\\setcopyright{none}\n%\\setcopyright{acmcopyright}\n%\\setcopyright{acmlicensed}\n%\\setcopyright{rightsretained}\n%\\copyrightyear{2018}           %% If different from \\acmYear\n\n%% Bibliography style\n\\bibliographystyle{ACM-Reference-Format}\n%% Citation style\n%% Note: author/year citations are required for papers published as an\n%% issue of PACMPL.\n\\citestyle{acmauthoryear}   %% For author/year citations\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%% Note: Authors migrating a paper from PACMPL format to traditional\n%% SIGPLAN proceedings format must update the '\\documentclass' and\n%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n% !TEX root = ./main.tex\n\n%% MARGIN MAGIC\n%\n\\def\\changemargin#1#2{\\list{}{\\rightmargin#2\\leftmargin#1}\\item[]}\n\\let\\endchangemargin=\\endlist\n\n\n\\newcommand{\\highlight}[1]{\\colorbox{gray!30}{$\\displaystyle#1$}}\n\n\\newcommand{\\ie}{i.e.,\\ }\n\\newcommand{\\eg}{e.g.,\\ }\n\n% TODOS\n\n\\setlength{\\marginparwidth}{1.5cm} %This is also for todonotes\n\\newcommand{\\blkcomment}[1]{\\todo[color=cyan!30,size=\\scriptsize,fancyline,author=Benjamin]{#1}\\xspace}\n\\newcommand{\\blkcommentinline}[1]{\\todo[inline,color=cyan!30,author=Benjamin]{#1}\\xspace}\n\\newcommand{\\atblk}{\\colorbox{cyan!30}{\\textbf{@Benjamin}}}\n\n\\newcommand{\\jpkcomment}[1]{\\todo[color=orange!80,size=\\scriptsize,fancyline,author=Joost-Pieter]{#1}\\xspace}\n\\newcommand{\\jpkcommentinline}[1]{\\todo[inline,color=orange!80,author=Joost-Pieter]{#1}\\xspace}\n\\newcommand{\\atjpk}{\\colorbox{orange!80}{\\textbf{@Joost-Pieter}}}\n\n\\newcommand{\\cmcomment}[1]{\\todo[color=green,size=\\scriptsize,fancyline,author=Christoph]{#1}\\xspace}\n\\newcommand{\\cmcommentinline}[1]{\\todo[inline,color=green,author=Christoph]{#1}\\xspace}\n\\newcommand{\\atcm}{\\colorbox{green}{\\textbf{@Christoph}}}\n\n\\newcommand{\\kbcomment}[1]{\\todo[color=yellow,size=\\scriptsize,fancyline,author=Kevin]{#1}\\xspace}\n\\newcommand{\\kbcommentinline}[1]{\\todo[inline,color=yellow,author=Kevin]{#1}\\xspace}\n\\newcommand{\\atkb}{\\colorbox{yellow}{\\textbf{@Kevin}}}\n\n\\newcommand{\\tncomment}[1]{\\todo[color=blue!25,size=\\scriptsize,fancyline,author=Thomas]{#1}\\xspace}\n\\newcommand{\\tncommentinline}[1]{\\todo[inline,color=blue!25,author=Thomas]{#1}\\xspace}\n\\newcommand{\\attn}{\\colorbox{blue!25}{\\textbf{@Thomas}}}\n\n\n\n%%%%    LOGICS    %%%%\n\\newcommand{\\Sup}{\\reflectbox{\\textnormal{\\textsf{\\fontfamily{phv}\\selectfont S}}}\\hspace{.2ex}}\n\\newcommand{\\Inf}{\\raisebox{.6\\depth}{\\rotatebox{-30}{\\textnormal{\\textsf{\\fontfamily{phv}\\selectfont \\reflectbox{J}}}}\\hspace{-.1ex}}}\n\\newcommand{\\Quant}{\\reflectbox{\\textnormal{\\textsf{\\fontfamily{phv}\\selectfont Q}}}\\hspace{.2ex}}\n\\newcommand{\\SupV}[1]{\\Sup #1\\colon}\n\\newcommand{\\InfV}[1]{\\Inf #1\\colon}\n\\newcommand{\\qprefix}[1]{\\sfsymbol{Prefix} \\left( #1 \\right) \\xspace}\n\n\\newcommand{\\interpret}{\\ensuremath{\\mathfrak{I}}\\xspace}\n\\newcommand{\\pstate}{\\pstatea}\n\\newcommand{\\pstatea}{\\ensuremath{\\sigma}\\xspace}\n\\newcommand{\\pstateb}{\\ensuremath{\\tau}\\xspace}\n\n\\newcommand{\\mforall}{\\forall \\hspace{.2ex}}\n\\newcommand{\\mexists}{\\exists \\hspace{.2ex}}\n\n\\newcommand{\\relPrime}[2]{#1 \\bot #2}\n\n\n\n\\newcommand{\\emp}{\\iverson{\\sfsymbol{\\textbf{emp}}}}\n\\newcommand{\\notemp}{\\iverson{\\neg \\sfsymbol{\\textbf{emp}}}}\n\\newcommand{\\singleton}[2]{\\iverson{#1 \\mapsto #2}}\n\\newcommand{\\containsPointer}[2]{\\iverson{#1 \\hookrightarrow #2}}\n\\newcommand{\\validpointer}[1]{\\iverson{#1 \\mapsto \\,{-}\\,}}\n\\newcommand{\\heapSize}{\\sfsymbol{\\textbf{size}}}\n\\newcommand{\\sepcon}{\\mathbin{{\\star}}}\n\\newcommand{\\sepadd}{\\mathbin{{\\oplus}}}\n\\newcommand{\\sepminus}{\\mathbin{{\\ominus}}}\n\\newcommand{\\sepmax}[2]{\\underline{{\\max}}\\left( #1,#2 \\right)}\n\\newcommand{\\sepimp}{\\mathbin{\\text{\\raisebox{-0.1ex}{$\\boldsymbol{{-}\\hspace{-.55ex}{-}}$}}\\hspace{-1ex}\\text{\\raisebox{0.13ex}{\\rotatebox{-17}{$\\star$}}}}}\n\\newcommand{\\nil}{0}\n\\newcommand{\\nt}[1]{\\textit{numtree}\\left(#1\\right)}\n\n\\newcommand{\\bigsepcon}[1]{\\ensuremath{\\underset{#1}{\\bigstar}}}\n\\newcommand{\\bbigsepcon}[2]{\\ensuremath{\\overset{#2}{\\underset{#1}{\\bigstar}}}}\n\n\n%%%% Syntax for Expectations %%%%\n\\newcommand{\\TT}{\\TTa\\xspace}\n\\newcommand{\\TTa}{\\ensuremath{a}\\xspace}\n\\newcommand{\\TTb}{\\ensuremath{b}\\xspace}\n\\newcommand{\\TTc}{\\ensuremath{c}\\xspace}\n\n\\newcommand{\\BB}{\\ensuremath{\\BBa}\\xspace}\n\\newcommand{\\BBa}{\\ensuremath{\\varphi}\\xspace}\n\\newcommand{\\BBb}{\\ensuremath{\\psi}\\xspace}\n\\newcommand{\\BBc}{\\ensuremath{\\xi}\\xspace}\n\n\\newcommand{\\FF}{\\ensuremath{f}\\xspace}\n\\newcommand{\\FG}{\\ensuremath{g}\\xspace}\n\\newcommand{\\FH}{\\ensuremath{h}\\xspace}\n\n\\newcommand{\\RR}{\\ensuremath{\\RRa}\\xspace}\n\\newcommand{\\RRa}{\\ensuremath{r}\\xspace}\n\\newcommand{\\RRb}{\\ensuremath{s}\\xspace}\n\\newcommand{\\RRc}{\\ensuremath{t}\\xspace}\n\n\\newcommand{\\XX}{\\ensuremath{x}\\xspace}\n\\newcommand{\\XY}{\\ensuremath{y}\\xspace}\n\\newcommand{\\XZ}{\\ensuremath{z}\\xspace}\n\n\n\\newcommand{\\VV}{\\ensuremath{v}\\xspace}\n\\newcommand{\\VW}{\\ensuremath{w}\\xspace}\n\\newcommand{\\VU}{\\ensuremath{u}\\xspace}\n\n\\newcommand{\\VVcut}{\\VV_{\\sfsymbol{Cut}}}\n\\newcommand{\\VVcutnum}[1]{\\VV_{\\sfsymbol{Cut}_{#1}}}\n\\newcommand{\\toExp}[1]{\\iverson{#1}}\n\\newcommand{\\varSymb}{\\mathit{var}}\n\n%\\newcommand{\\expressexpsymbol}{\\cong}\n%\\newcommand{\\expressexp}[2]{#1 \\cong #2}\n\n%%% Syntax for First order Arithmetic\n\\newcommand{\\PP}{\\ensuremath{P}\\xspace}\n\\newcommand{\\isNat}{\\ensuremath{N}\\xspace}\n\n\n%%%% Dedekind Cuts %%%%\n\\newcommand{\\dcut}[1]{\\ensuremath{\\sfsymbol{Cut} \\left( #1 \\right)} \\xspace}\n\n\\newcommand{\\dcutzero}[1]{\\ensuremath{\\sfsymbol{\\underline{Cut}} \\left( #1 \\right)} \\xspace}\n\n\n\\newcommand{\\dexpvar}[2]{\\ensuremath{\\sfsymbol{Dedekind} [#1,  #2 ]} \\xspace}\n\n\\newcommand{\\dexp}[1]{\\dexpvar{\\VVcut}{#1}}\n\n\n\n%%%   G\u00f6del Stuff   %%%\n\\newcommand{\\gBeta}{\\ensuremath{\\beta}\\xspace}\n\\newcommand{\\expBeta}[3]{\\iverson{\\gBeta\\left( #1, #2, #3 \\right)}}\n\n\\newcommand{\\gnum}{num}\n\n\\newcommand{\\seqelemsymbol}{\\sfsymbol{Elem}}\n\\newcommand{\\seqelem}[3]{\\ensuremath{\\seqelemsymbol\\left( #1, #2 ,#3 \\right)}\\xspace}\n\\newcommand{\\rseqelemsymbol}{\\sfsymbol{RElem}}\n\n\\newcommand{\\rseqelem}[3]{\\ensuremath{\\rseqelemsymbol\\left( #1, #2 ,#3 \\right)}\\xspace}\n\\newcommand{\\seqnum}[1]{\\ensuremath{\\langle #1 \\rangle}\\xspace}\n\\newcommand{\\stateseqnum}[1]{\\ensuremath{\\langle (#1) \\rangle}\\xspace}\n\n\\newcommand{\\stateseq}[3]{\\ensuremath{\\sfsymbol{StateSequence}_{\\varseq{#1}}\\left(#2, #3 \\right)}\\xspace}\n\n\\newcommand{\\sequencesymbol}{\\sfsymbol{Sequence}}\n\\newcommand{\\sequence}[2]{\\sequencesymbol \\left(#1, #2\\right)}\n\n\\newcommand{\\rsequencesymbol}{\\sfsymbol{RSequence}}\n\\newcommand{\\rsequence}[2]{\\rsequencesymbol \\left(#1, #2\\right)}\n\n\\newcommand{\\encodesstate}[2]{\\sfsymbol{EncodesState}_{\\varseq{#1}} \\left( #2 \\right)}\n\n\\newcommand{\\gPair}{\\sfsymbol{Pair}\\xspace}\n\\newcommand{\\gRho}{\\ensuremath{\\rho}\\xspace}\n\n\\newcommand{\\facpred}[2]{\\ensuremath{\\sfsymbol{Fac} \\left( #1, #2 \\right)} \\xspace}\n\\newcommand{\\facexp}[1]{\\ensuremath{\\sfsymbol{Fac} \\left( #1\\right)} \\xspace}\n\n\\newcommand{\\harmpred}[2]{\\ensuremath{\\sfsymbol{Harm} \\left( #1, #2 \\right)} \\xspace}\n\\newcommand{\\harmexp}[1]{\\ensuremath{\\sfsymbol{Harmonic} \\left( #1\\right)} \\xspace}\n\n\\newcommand{\\gproductsymbol}{\\sfsymbol{Product}}\n\\newcommand{\\gproductvar}[3]{\\ensuremath{\\gproductsymbol \\left[ #1, #2, #3 \\right]}\\xspace}\n\\newcommand{\\gproduct}[2]{\\gproductvar{\\vprod}{#1}{#2}}\n\n\\newcommand{\\vprod}{\\VV_{\\textnormal{prod}} \\xspace}\n\n\\newcommand{\\gsumsymbol}{\\sfsymbol{Sum}}\n\n\\newcommand{\\gsumvar}[3]{\\ensuremath{\\gsumsymbol \\left[ #1, #2, #3 \\right]}\\xspace}\n\n\\newcommand{\\gsum}[2]{\\gsumvar{\\vsum}{#1}{#2}}\n\n\n\n\\newcommand{\\gapply}[3]{\\sfsymbol{Subst}_{\\varseq{#1}} \\left[ #2, #3  \\right]}\n\n\\newcommand{\\gsubst}[3]{\\sfsymbol{Subst}_{\\varseq{#1}} \\left[ #2,#3\\right]}\n\n\\newcommand{\\vsum}{\\VV_{\\textnormal{sum}} \\xspace}\n\n\n \\newcommand{\\pathexpsymbol}{\\sfsymbol{Path}}\n \n \\newcommand{\\pathexppost}[3]{\\pathexpsymbol\\left[ #1 \\right] \\left( #2,#3 \\right)}\n \n\\newcommand{\\pathexp}[2]{\\pathexppost{\\FF}{#1}{#2}}\n\n\n\n%%%%    TODONOTES    %%%%\n\\newcommand{\\todoin}[1]{\\todo[inline]{#1}}\n\n\\newcommand{\\QSL}{\\sfsymbol{QSL}\\xspace}\n\\newcommand{\\SL}{\\sfsymbol{SL}\\xspace}\n\n\n%%%%    SYMBOLS    %%%%\n\\newcommand{\\cmark}{{\\large\\ding{51}}}\n\\newcommand{\\xmark}{}%{\\scriptsize\\ding{55}}}\n\n%%%%    WP-STYLE TRANSFORMERS    %%%%\n\n\\newcommand{\\hoare}[3]{\\left\\langle \\,{#1}\\vphantom{#3}\\, \\right\\rangle \\mathrel{#2} \\left\\langle \\, {#3}\\vphantom{#1} \\, \\right\\rangle}\n\\newcommand{\\partialhoare}[3]{\\left\\langle \\,{#1}\\vphantom{#3}\\, \\right\\rangle \\mathrel{\\widetilde{#2}} \\left\\langle \\, {#3}\\vphantom{#1} \\, \\right\\rangle}\n\n\\newcommand{\\sfsymbol}[1]{\\textsf{\\upshape {#1}}}\n\\newcommand{\\boldsfsymbol}[1]{\\textbf{\\textsf{\\upshape {#1}}}}\n\\newcommand{\\ttsymbol}[1]{\\texttt{\\upshape {#1}}}\n%\\newcommand{\\Assert}[1]{\\ensuremath{{}\\hspace*{-.5ex}{\\fatslash}\\hspace*{-.5ex}{\\fatslash}\\hspace*{1ex} \\text{\\footnotesize $\\displaystyle #1$} }}\n\\newcommand{\\Assert}[1]{\\ensuremath{\\text{\\footnotesize ~\\texttt{//}~$\\displaystyle #1$} }}\n\n% general transformer\n\\newcommand{\\transformersymbol}{\\mathcal{T}}\n\\newcommand{\\boldtransformersymbol}{\\boldsymbol{\\transformersymbol}}\n\\newcommand{\\transformer}[2]{\\transformersymbol \\, \\left\\llbracket {#1} \\right\\rrbracket \\, \\left( {#2} \\right)}\n\\newcommand{\\transformerC}[1]{\\transformersymbol \\, \\left\\llbracket {#1} \\right\\rrbracket}\n\n% weakest preexpectation\n\\newcommand{\\wpsymbol}{\\sfsymbol{wp}}\n\\newcommand{\\boldwpsymbol}{\\textbf{\\sfsymbol{wp}}}\n\\renewcommand{\\wp}[2]{\\wpsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\extwp}[2]{\\Ext{\\wpsymbol}\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\wpC}[1]{\\wpsymbol\\llbracket#1\\rrbracket}\n\n% other transformers\n\n% segfault probability\n\\newcommand{\\segprobsymbol}{\\sfsymbol{segprob}}\n\\newcommand{\\boldsegprobsymbol}{\\textbf{\\sfsymbol{segprob}}}\n\\newcommand{\\segprob}[2]{\\segprobsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\segprobC}[1]{\\segprobsymbol\\llbracket#1\\rrbracket}\n\n% angelic weakest preexpectation\n\\newcommand{\\awpsymbol}{\\sfsymbol{awp}}\n\\newcommand{\\boldawpsymbol}{\\textbf{\\sfsymbol{awp}}}\n\\newcommand{\\awp}[2]{\\awpsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\awpC}[1]{\\awpsymbol\\llbracket#1\\rrbracket}\n\n% weakest liberal preexpectation\n\\newcommand{\\wlpsymbol}{\\sfsymbol{wlp}}\n\\newcommand{\\boldwlpsymbol}{\\textbf{\\sfsymbol{wlp}}}\n\\newcommand{\\wlp}[2]{\\wlpsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\wlpC}[1]{\\wlpsymbol\\llbracket#1\\rrbracket}\n\n% weakest extrinsic memory safe preexpectation\n\\newcommand{\\esepcon}{\\mathbin{{\\bullet}}}\n\\newcommand{\\esepimp}{\\mathbin{\\text{\\raisebox{-0.1ex}{$\\boldsymbol{{-}\\hspace{-.55ex}{-}}$}}\\hspace{-1ex}\\text{\\raisebox{0.13ex}{\\rotatebox{-17}{$\\bullet$}}}}}\n\\newcommand{\\wepsymbol}{\\sfsymbol{wep}}\n\\newcommand{\\boldwepsymbol}{\\textbf{\\sfsymbol{wep}}}\n\\newcommand{\\wep}[2]{\\wepsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\wepC}[1]{\\wepsymbo\\llbracket#1\\rrbracket}\n\n% angelic weakest liberal preexpectation\n\\newcommand{\\awlpsymbol}{\\sfsymbol{awlp}}\n\\newcommand{\\boldawlpsymbol}{\\textbf{\\sfsymbol{awlp}}}\n\\newcommand{\\awlp}[2]{\\awlpsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\awlpC}[1]{\\awlpsymbol\\llbracket#1\\rrbracket}\n\n% angelic weakest extrinsic memory safe preexpectation\n\\newcommand{\\awepsymbol}{\\sfsymbol{awep}}\n\\newcommand{\\boldawepsymbol}{\\textbf{\\sfsymbol{awep}}}\n\\newcommand{\\awep}[2]{\\awepsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\awepC}[1]{\\awepsymbol\\llbracket#1\\rrbracket}\n\n% angelic weakest liberal extrinsic memory safe preexpectation\n\\newcommand{\\awlepsymbol}{\\sfsymbol{awlep}}\n\\newcommand{\\boldawlepsymbol}{\\textbf{\\sfsymbol{awlep}}}\n\\newcommand{\\awlep}[2]{\\awlepsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\awlepC}[1]{\\awlepsymbol\\llbracket#1\\rrbracket}\n\n% weakest liberal extrinsic memory safe preexpectation\n\\newcommand{\\wlepsymbol}{\\sfsymbol{wlep}}\n\\newcommand{\\boldwlepsymbol}{\\textbf{\\sfsymbol{wlep}}}\n\\newcommand{\\wlep}[2]{\\wlepsymbol\\llbracket#1\\rrbracket\\left(#2\\right)}\n\\newcommand{\\wlepC}[1]{\\wlepsymbol\\llbracket#1\\rrbracket}\n\n% conditional weakest preexpectation\n\\newcommand{\\cwpsymbol}{\\sfsymbol{cwp}}\n\\newcommand{\\conditionalPair}[2]{{\\let\\oldarraystretch\\arraystretch}\\renewcommand{\\arraystretch}{1}~\\holter{~\\raisebox{.5ex}{${#1}$}~}{~\\raisebox{.125ex}{${#2}$}~}~\\renewcommand{\\arraystretch}{\\oldarraystretch}}\n\\newcommand{\\boldcwpsymbol}{\\textbf{\\sfsymbol{cwp}}}\n\\newcommand{\\cwp}[3]{\\cwpsymbol \\, \\left\\llbracket {#1} \\right\\rrbracket \\, \\left( \\conditionalPair{#2}{#3} \\right)}\n\\newcommand{\\cwpC}[2]{\\cwpsymbol \\, \\left\\llbracket {#1} \\right\\rrbracket \\, \\left( {#2} \\right)}\n\n%%%%    Constants    %%%%%%%\n\\newcommand{\\cc}{\\ensuremath{C}} % programs\n\\newcommand{\\guard}{\\BB} % conditial guard\n\\newcommand{\\ee}{\\ensuremath{e}} % expressions\n\n\\newcommand{\\preda}{\\ensuremath{\\varphi}} % predicates\n\\newcommand{\\predb}{\\ensuremath{\\psi}} \n\\newcommand{\\predc}{\\ensuremath{\\vartheta}} \n\\newcommand{\\predd}{\\ensuremath{\\xi}} \n\n\\newcommand{\\hh}{\\ensuremath{h}} % heap\n\\newcommand{\\sk}{\\ensuremath{s}} % stack \n\n\\newcommand{\\pp}{\\ensuremath{p}} % probabilities\n\\newcommand{\\qq}{\\ensuremath{q}} % probabilities\n\n\\newcommand{\\ff}{\\ensuremath{X}} % expectations\n\\newcommand{\\fg}{\\ensuremath{Y}}\n\\newcommand{\\fh}{\\ensuremath{Z}}\n\\newcommand{\\fk}{\\ensuremath{R}}\n\\newcommand{\\inv}{\\ensuremath{I}} % invariants\n\n\\newcommand{\\oa}{\\ensuremath{\\alpha}} % ordinals\n\\newcommand{\\ob}{\\ensuremath{\\beta}} \n\\newcommand{\\oc}{\\ensuremath{\\delta}} \n\n\\newcommand{\\za}{\\ensuremath{\\alpha}} % quantified variables\n\\newcommand{\\zb}{\\ensuremath{\\beta}}\n\\newcommand{\\zc}{\\ensuremath{\\gamma}} \n\\newcommand{\\zd}{\\ensuremath{\\delta}} \n\n\n\n\n%%%%    PGCL PROGRAMS    %%%%\n\\newcommand{\\SKIP}{\\ttsymbol{skip}}\n\\newcommand{\\EMPTY}{\\ensuremath{\\textnormal{\\texttt{empty}}}}\n\\newcommand{\\HALT}{\\ensuremath{\\textnormal{\\texttt{halt}}}}\n\\newcommand{\\ABORT}{\\ensuremath{\\textnormal{\\texttt{abort}}}}\n\\newcommand{\\DIVERGE}{\\ensuremath{\\textnormal{\\texttt{diverge}}}}\n\n\\newcommand{\\OBSERVE}[1]{\\ensuremath{\\textnormal{\\texttt{observe}} ~ {#1}}}\n\\newcommand{\\ASSUME}[1]{\\ensuremath{\\textnormal{\\texttt{assume}} ~ {#1}}}\n\\newcommand{\\ASSERT}[1]{\\ensuremath{\\textnormal{\\texttt{assert}} ~ {#1}}}\n%\\newcommand{\\CALL}[1]{\\ensuremath{\\textnormal{\\texttt{call}} ~ {#1}}}\n\n\\newcommand{\\AssignSymbol}{\\mathrel{\\textnormal{\\texttt{:=}}}}\n\\newcommand{\\ASSIGN}[2]{\\ensuremath{#1 \\AssignSymbol #2}}\n\\newcommand{\\UNIFORM}[2]{\\ensuremath{\\mathtt{uniform}\\left(#1,#2\\right)}}\n\\newcommand{\\ASSIGNUNIFORM}[3]{\\ensuremath{#1 \\AssignSymbol \\UNIFORM{#2}{#3}}}\n\\newcommand{\\ALLOC}[2]{\\ensuremath{{#1} \\AssignSymbol \\mathtt{new}\\left( #2 \\right)}}\n\n\\newcommand{\\AVAILLOC}[1]{\\PosNats}\n%\\newcommand{\\AVAILLOC}[1]{\\ensuremath{\\mathrm{loc}(#1)}}\n\n%\\newcommand{\\dereference}[1]{\\overline{#1}}\n%\\newcommand{\\dereference}[1]{{}^*\\!{#1}}\n\\usepackage{actuarialangle}\n\n\\newcommand{\\dereference}[1]{\\texttt{<}\\,#1\\,\\texttt{>}}\n%\\newcommand{\\dereference}[1]{\\angl{\\,#1\\,}}\n\n\\newcommand{\\HASSIGN}[2]{\\ensuremath{\\dereference{#1} \\AssignSymbol #2}}\n\\newcommand{\\ASSIGNH}[2]{\\ensuremath{#1 \\AssignSymbol \\dereference{#2}}}\n\\newcommand{\\FREE}[1]{\\ensuremath{\\mathtt{free}(#1)}}\n\n\\newcommand{\\AppAssignSymbol}{\\mathrel{\\textnormal{\\texttt{:}}\\hspace{-.1em}{\\approx}}}\n\\newcommand{\\PASSIGN}[2]{\\ensuremath{#1 \\AppAssignSymbol\\hspace{.1em} #2}}\n\n\\newcommand{\\SEMI}{\\ensuremath{\\,;\\,}}\n%\\newcommand{\\SEMI}{\\ensuremath{\\,\\fatsemi\\,}}\n%\\newcommand{\\COMPOSE}[2]{\\ensuremath{{#1}{\\,\\fatsemi}~ {#2}}}\n\\newcommand{\\COMPOSE}[2]{\\ensuremath{{#1}{\\,;}~ {#2}}}\n\\newcommand{\\PCHOICE}[3]{\\ensuremath{\\left\\{\\, {#1} \\,\\right\\}\\mathrel{\\left[\\,#2\\,\\right]}\\left\\{\\, {#3} \\,\\right\\}}}\n\\newcommand{\\NDCHOICE}[2]{\\ensuremath{\\left\\{\\, {#1} \\,\\right\\}\\mathrel{\\Box}\\left\\{\\, {#2} \\,\\right\\}}}\n\\newcommand{\\NDBRACK}{\\ensuremath{\\left.\\right\\}\\mathrel{\\Box}\\left\\{\\right.}}\n\n\n\\newcommand{\\IFSYMBOL}{\\ensuremath{\\textnormal{\\texttt{if}}}}\n\\newcommand{\\IF}[1]{\\ensuremath{\\IFSYMBOL\\,\\left(\\, {#1} \\,\\right)\\,\\{}}\n\\newcommand{\\ELSESYMBOL}{\\ensuremath{\\textnormal{\\texttt{else}}}}\n\\newcommand{\\ELSE}{\\ensuremath{\\}\\,\\ELSESYMBOL\\,\\{}}\n\\newcommand{\\ITE}[3]{\\ensuremath{\\IFSYMBOL\\,\\left(\\, {#1} \\,\\right)\\,\\left\\{\\, {#2} \\,\\right\\}\\,\\ELSESYMBOL\\,\\left\\{\\, {#3} \\,\\right\\}}}\n\n\\newcommand{\\WHILESYMBOL}{\\ensuremath{\\textnormal{\\texttt{while}}}}\n\\newcommand{\\WHILE}[1]{\\ensuremath{\\WHILESYMBOL \\left(\\, {#1} \\,\\right)\\left\\{\\right.}}\n\n\\newcommand{\\WHILEDO}[2]{\\ensuremath{\\WHILESYMBOL \\left(\\, {#1} \\,\\right)\\left\\{\\, {#2} \\,\\right\\}}}\n\n\n%\\newcommand{\\BOUNDEDWHILE}[3]{\\ensuremath{\\WHILE^{<{#1}}\\:(#2)\\:\\{#3\\}}}\n\n\n\n\n%%%%    SETS    %%%%\n%\\newcommand{\\terms}{\\textnormal{\\sfsymbol{Terms}}\\xspace}\n\\newcommand{\\booleans}{\\textnormal{\\sfsymbol{Bools}}\\xspace}\n\n\\newcommand{\\gcl}{\\textnormal{\\sfsymbol{GCL}}\\xspace}   % Programs\n\\newcommand{\\pgcl}{\\textnormal{\\sfsymbol{pGCL}}\\xspace}   % Programs\n%\\newcommand{\\hgcl}{\\textnormal{\\sfsymbol{hGCL}}\\xspace}   % Programs\n\\newcommand{\\hpgcl}{\\textnormal{\\sfsymbol{hpGCL}}\\xspace}   % Programs\n\\newcommand{\\boldhpgcl}{\\textnormal{\\textbf{\\sfsymbol{hpGCL}}}\\xspace}   % Programs\n\\newcommand{\\cpgcl}{\\textnormal{\\textbf{\\sfsymbol{cpGCL}}}\\xspace}   % Programs\n\\newcommand{\\boldgcl}{\\textnormal{\\textbf{\\sfsymbol{GCL}}}\\xspace}   % Programs\n\\newcommand{\\boldpgcl}{\\textnormal{\\textbf{\\sfsymbol{pGCL}}}\\xspace}   % Programs\n\\newcommand{\\boldcpgcl}{\\textnormal{\\textbf{\\sfsymbol{cpGCL}}}\\xspace}   % Programs\n\\newcommand{\\Vars}{\\ensuremath{\\mathsf{Vars}}\\xspace}   % Variables\n\\newcommand{\\LVars}{\\ensuremath{\\mathsf{L\\hspace{-.2ex}Vars}}\\xspace}   % Variables\n\\newcommand{\\Terms}{\\ensuremath{\\mathsf{AExpr}}\\xspace}   % Terms\n\\newcommand{\\Bools}{\\ensuremath{\\mathsf{Bool}}\\xspace}   % Boolean expressions\n\\newcommand{\\Vals}{\\ensuremath{\\mathsf{Vals}}\\xspace}    % Values\n\\newcommand{\\EVars}{\\ensuremath{\\mathsf{E}}_{\\Vars}\\xspace}\n\n\\newcommand{\\Nats}{\\ensuremath{\\mathbb{N}}\\xspace}\n\\newcommand{\\PosNats}{\\ensuremath{\\mathbb{N}_{>0}}\\xspace}\n\\newcommand{\\Ints}{\\ensuremath{\\mathbb{Z}}\\xspace}\n\\newcommand{\\Rats}{\\ensuremath{\\mathbb{Q}}\\xspace}\n\\newcommand{\\Reals}{\\mathbb{R}}\n\\newcommand{\\PosReals}{\\mathbb{R}_{\\geq 0}}\n\\newcommand{\\PosRats}{\\mathbb{Q}_{\\geq 0}}\n\\newcommand{\\PosRealsInf}{\\mathbb{R}_{\\geq 0}^\\infty}\n\n\\newcommand{\\Preds}{\\pot{\\States}}\n\\newcommand{\\E}{\\mathbb{E}}\n\\newcommand{\\SyntE}{\\ensuremath{\\mathsf{Exp}}\\xspace}\n\\newcommand{\\SyntEStates}{\\SyntE_{\\States}}\n\n\\newcommand{\\Ebounded}{\\mathbb{E}_{\\leq b}}\n\\newcommand{\\Eone}{\\mathbb{E}_{\\leq 1}}\n\\newcommand{\\Universe}{\\mathfrak{U}}\n\\newcommand{\\FOArith}[1]{\\mathbf{A}_{#1}}\n\\newcommand{\\FOArithPosRats}{\\FOArith{\\PosRats}}\n\\newcommand{\\FOArithNats}{\\FOArith{\\Nats}}\n\n\\newcommand{\\monus}{\\mathbin{\\dot-}}\n\\newcommand{\\abs}[1]{|#1|}\n\n\\newcommand{\\exprod}{{}\\odot{}}\n\n\\newcommand{\\natExp}[1]{\\iverson{#1 \\in \\Nats}}\n\n\\newcommand{\\dist}[1]{\\ensuremath{\\sfsymbol{Dist}\\left(#1\\right)} \\xspace}\n\n\\newcommand{\\Mod}[1]{\\ensuremath{\\sfsymbol{Mod}\\left(#1\\right)}}\n\n\\newcommand{\\FV}[1]{\\ensuremath{\\sfsymbol{FV}\\left(#1\\right)}}\n\n\\newcommand{\\DExprs}{\\ensuremath{\\mathsf{PGuards}}\\xspace}    % Distribution Expression\n\\newcommand{\\Dists}[1]{\\ensuremath{\\mathcal{D}\\left({#1}\\right)}}\n\n\\newcommand{\\Permutations}{\\ensuremath{\\Pi}}\n\\newcommand{\\FinPermutations}[1]{\\ensuremath{\\Pi_{#1}}}\n%\n%\n%\\newcommand{\\exProgs}{\\textnormal{\\sfsymbol{exProgs}}}\n%\\newcommand{\\appProgs}{\\Stmt}\n%\\newcommand{\\BDists}{\\textnormal{\\sfsymbol{BDists}}}\n%\\newcommand{\\E}{\\ensuremath{\\mathbb{E}_{\\geq 0}^{{\\infty}}}}\n%\\newcommand{\\Epm}{\\ensuremath{\\mathbb{E}^{{\\star}}}}\n%\\newcommand{\\Pairs}{\\ensuremath{\\mathbb{P}}}\n%\\newcommand{\\EqPairs}{\\ensuremath{\\mathbb{I\\hspace{-.1ex}E}}}\n%\\newcommand{\\EE}{\\ensuremath{\\mathbb{E}}}\n%\\newcommand{\\Eefin}{\\ensuremath{\\E^*}}\n%\\newcommand{\\States}{\\ensuremath{\\Sigma}}\n%\\newcommand{\\R}{\\ensuremath{\\mathbb{R}}}\n%\\newcommand{\\Rpos}{\\ensuremath{\\R_{{}\\geq 0}}}\n%\\newcommand{\\Rposinf}{\\ensuremath{\\Rpos^{\\infty}}}\n%\\newcommand{\\Rpminf}{\\ensuremath{\\R^{\\infty}}}\n%\\newcommand{\\Rinf}{\\ensuremath{\\R^{{\\pm}\\infty}}}\n%\\newcommand{\\bigO}{\\ensuremath{\\mathcal{O}}}\n%\\newcommand{\\littleO}{\\ensuremath{o}}\n%\\newcommand{\\Ints}{\\ensuremath{\\mathbb Z}\\xspace}\n%\\newcommand{\\Nats}{\\ensuremath{\\mathbb N}\\xspace}\n%\\newcommand{\\Rationals}{\\ensuremath{\\mathbb Q}\\xspace}\n%\\newcommand{\\PReals}{\\ensuremath{\\mathbb R_{\\geq 0}}\\xspace}\n%\\newcommand{\\Bool}{\\ensuremath{\\mathsf{Bool}}\\xspace}\n%\\newcommand{\\ZO}{[0,\\,\\! 1]}                             % real interval [0,1]\n\n\n\n\n%%%%    Functions    %%%%\n\n\\newcommand{\\prenex}[1]{\\sfsymbol{Prenex}\\left( #1 \\right)}\n\n\\newcommand{\\toFOPosRats}[1]{#1_{\\PosRats}}\n\n\n\\newcommand{\\dom}[1]{\\sfsymbol{dom}\\left({#1}\\right)}\n\\newcommand{\\iverson}[1]{\\left[ {#1} \\right]}\n\\newcommand{\\bigiverson}[1]{\\vphantom{\\big(}\\iverson{#1}\\vphantom{\\big)}}\n\\newcommand{\\Min}[2]{\\min\\left\\{\\,{#1},\\: {#2}\\,\\right\\}}\n\\newcommand{\\Max}[2]{\\max\\left\\{\\,{#1},\\: {#2}\\,\\right\\}}\n%\\newcommand{\\Exp}[2]{\\sfsymbol{Exp}_{#1}\\left( {#2} \\right)}\n\\newcommand{\\Exp}[2]{\\int_\\States \\; {#2} \\; d \\,{#1} }\n%\\newcommand{\\Exp}[2]{\\int_\\States {#2} \\: d {#1} }\n\n\\newcommand{\\subst}[2]{\\left[ {#1} \\middle/ {#2}\\right]}\n\\newcommand{\\statesubst}[2]{\\left[ {#1} \\mapsto {#2}\\right]}\n\\newcommand{\\multstatesubst}[1]{\\left[ #1\\right]}\n\n%\\newcommand{\\charfun}[4]{\\tensor*[^{#2}_{{#1}{#3}}]{\\Phi}{_{{#4}}}}\n\\newcommand{\\charfun}[4]{\\tensor*[^{#1}_{{\\langle #2, #3 \\rangle}}]{\\Phi}{_{{#4}}}}\n\\newcommand{\\charfunn}[5]{\\tensor*[^{#1}_{{\\langle #2, #3 \\rangle}}]{\\Phi}{_{{#4}}^{{#5}}}}\n%\\newcommand{\\charwp}[3]{\\charfun{\\wpsymbol}{#1}{#2}{#3}}\n\\newcommand{\\charwpsym}{\\Phi}\n%\\newcommand{\\charwp}[3]{\\charwpsym\\llbracket#1,#2,#3\\rrbracket} %\\charfun{\\wpsymbol}{#1}{#2}{#3}}\n\\newcommand{\\charwp}[3]{\\charwpsym_{#3}} %\\charfun{\\wpsymbol}{#1}{#2}{#3}}\n\\newcommand{\\charwpn}[4]{\\charwpsym^{#4}_{#3}} %\\charfun{\\wpsymbol}{#1}{#2}{#3}}\n\\newcommand{\\charwlp}[3]{\\charfun{\\wlpsymbol}{#1}{#2}{#3}}\n\\newcommand{\\charawp}[3]{\\charfunn{\\awpsymbol}{#1}{#2}{#3}}\n%\\newcommand{\\charwpn}[4]{\\charfunn{\\wpsymbol}{#1}{#2}{#3}{#4}}\n\\newcommand{\\charwlpn}[4]{\\charfunn{\\wlpsymbol}{#1}{#2}{#3}{#4}}\n\\newcommand{\\charawpn}[4]{\\charfunn{\\awpsymbol}{#1}{#2}{#3}{#4}}\n\n\n\n\\newcommand{\\eval}[1]{\\ensuremath{\\left\\llbracket {#1} \\right\\rrbracket}}\n\\newcommand{\\sem}[3]{\\ensuremath{\\tensor*[^{#2}_{}]{\\left\\llbracket {#1} \\right\\rrbracket}{}}}\n\\newcommand{\\semleft}[3]{\\ensuremath{\\tensor*[^{#2}_{}]{\\llbracket {#1} }{}}}\n\\newcommand{\\semright}{\\rrbracket}\n\n\\newcommand{\\probof}[2]{\\ensuremath{\\llbracket {#1} \\colon {#2} \\rrbracket}}\n\\newcommand{\\pot}[1]{\\mathcal{P}\\left({#1}\\right)}\n\n\\newcommand{\\restrictFunc}[2]{\\left.#1\\right\\rceil_{#2}}\n\n\n\n\n%%%% Standards %%%%\n\n\\newcommand{\\Stacks}{\\mathcal{S}}\n\\newcommand{\\Heaps}{\\mathcal{H}}\n\\newcommand{\\emptyheap}{h_\\emptyset}\n\\newcommand{\\disjoint}{\\mathrel{\\bot}}\n\\newcommand{\\States}{\\Sigma}\n\\newcommand{\\To}{\\rightarrow}\n\\newcommand{\\true}{\\mathsf{true}}\n\\newcommand{\\false}{\\mathsf{false}}\n\\newcommand{\\mydot}{\\text{{\\Large\\textbf{.}}~}}\n\n\\newcommand{\\varseq}[1]{\\ensuremath{\\mathbf{#1}}\\xspace}\n\\newcommand{\\equivstatesrel}[1]{\\sim_{#1}}\n\\newcommand{\\equivclass}[2]{\\ensuremath{\\left[ #1 \\right]_{\\equivstatesrel{#2}}}\\xspace}\n\\newcommand{\\equivstates}[3]{#1 \\equivstatesrel{#2} #3}\n\\newcommand{\\equivstatespred}[3]{\\iverson{#1 \\equivstatesrel{#2} #3}}\n\\newcommand{\\partitionedstates}[1]{\\States_{\\varseq{#1}} }\n\\newcommand{\\statepred}[2]{\\iverson{#1}_{#2}}\n\n\n%%%%    Shortcuts    %%%%\n\n\\newcommand{\\qiff}{\\quad\\textnormal{iff}\\quad}\n\\newcommand{\\qqiff}{\\qquad\\textnormal{iff}\\qquad}\n\\newcommand{\\lqiff}{\\textnormal{iff}\\quad}\n\\newcommand{\\lqqiff}{\\textnormal{iff}\\qquad}\n\n\\newcommand{\\qand}{\\quad\\textnormal{and}\\quad}\n\\newcommand{\\qqand}{\\qquad\\textnormal{and}\\qquad}\n\n\\newcommand{\\qor}{\\quad\\textnormal{or}\\quad}\n\\newcommand{\\qqor}{\\qquad\\textnormal{or}\\qquad}\n\n\\newcommand{\\qimplies}{\\quad\\textnormal{implies}\\quad}\n\\newcommand{\\qqimplies}{\\qquad\\textnormal{implies}\\qquad}\n\\newcommand{\\lqimplies}{\\textnormal{implies}\\quad}\n\\newcommand{\\lqqimplies}{\\textnormal{implies}\\qquad}\n\n\\newcommand{\\pprec}{\\mathrel{{\\prec}\\hspace{-.5ex}{\\prec}}}\n\\newcommand{\\ppprec}{~{}\\pprec{}~}\n\n\n\\newcommand{\\ppreceq}{~{}\\preceq{}~}\n\\newcommand{\\ssucceq}{~{}\\succeq{}~}\n\\newcommand{\\defeq}{~{}\\triangleq{}~}\n\\newcommand{\\ddefeq}{~{}\\defeq{}~}\n\\newcommand{\\eeq}{~{}={}~}\n\\newcommand{\\eequiv}{~{}\\equiv{}~}\n\\newcommand{\\pplus}{~{}+{}~}\n\\newcommand{\\ccdot}{~{}\\cdot{}~}\n\\newcommand{\\llongrightarrow}{~{}\\longrightarrow{}~}\n\\newcommand{\\qlongrightarrow}{\\quad{}\\longrightarrow{}\\quad}\n\\newcommand{\\qqlongrightarrow}{\\qquad{}\\longrightarrow{}\\qquad}\n\\newcommand{\\mmid}{~{}|{}~}\n\\newcommand{\\qmid}{\\quad{}|{}\\quad}\n\\newcommand{\\tto}{~{}\\to{}~}\n\\newcommand{\\nneq}{~{}\\neq{}~}\n\\newcommand{\\qeq}{\\quad{}={}\\quad}\n\\newcommand{\\qqeq}{\\qquad{}={}\\qquad}\n\\newcommand{\\lleq}{~{}\\leq{}~}\n\\newcommand{\\LL}{~{}<{}~}\n\\newcommand{\\GG}{~{}>{}~}\n\\newcommand{\\ggeq}{~{}\\geq{}~}\n\\newcommand{\\ssqsubseteq}{~{}\\sqsubseteq{}~}\n\\newcommand{\\iimplies}{~{}\\implies{}~}\n\\newcommand{\\mmodels}{~{}\\models{}~}\n\\newcommand{\\nnotmodels}{~{}\\not\\models{}~}\n\\newcommand{\\iin}{~{}\\in{}~}\n\\newcommand{\\nnotin}{~{}\\not\\in{}~}\n\n\\newcommand{\\cwedge}{\\,{}\\wedge{}\\,}\n\n\n\\newcommand{\\setcomp}[2]{\\left\\{\\, {#1} ~\\middle|~ {#2} \\,\\right\\}}\n\\newcommand{\\sepconsupcomp}[6]{\\sup_{{#3}, {#4}}\\left\\{\\, {#5} (#1, #3) \\cdot {#6} (#1, #4) ~\\middle|~ {#2} = {#3} \\sepcon {#4} \\,\\right\\}} % [#1 : s, #2 : h, #3 : h_1, #4 : h_2, #5 : f, #6 : g]\n\n\n\\newcommand{\\blue}[1]{\\textcolor{DodgerBlue3}{#1}}\n%\\newcommand{\\blue}[1]{\\textcolor{blue}{#1}}\n\n\n\\newcommand{\\lfp}{\\ensuremath{\\textnormal{\\sfsymbol{lfp}}~}}\n\\newcommand{\\gfp}{\\ensuremath{\\textnormal{\\sfsymbol{gfp}}~}}\n\n\n\n\n\n\n\n\n \n\\usepackage{hyperref}\n\\usepackage{subcaption}                        \n\\usepackage{adjustbox}\n\\usepackage{amsmath,amsfonts}\n\\usepackage{marvosym}\n%\\usepackage{esrelation}\n\n\\usepackage{cleveref}\n\\usepackage{graphicx}\n\\usepackage{nameref}\n\\usepackage{stmaryrd}\n\\usepackage{xcolor}\n\\usepackage{xfrac}\n\\usepackage{xspace}\n\\usepackage{cancel}\n\\usepackage{csquotes}\n\\usepackage{nicefrac}\n\n\n\\usepackage{listings,multicol}\n\n\\usepackage{tensor}\n\\usepackage{tikz}\n\\usetikzlibrary{patterns,decorations.pathreplacing,arrows,arrows.meta,decorations.pathmorphing,positioning,fit,trees,shapes,shadows,automata,calc}\n\\usepackage{pgfplots}\n\n\\usepackage{caption}\n\\usepackage{proof}\n\\usepackage{mathtools}\n\n%\\usepackage[textwidth=19mm]{todonotes}\n\n\\allowdisplaybreaks\n\n%%\n%% end of the preamble, start of the body of the document source.\n\\begin{document}\n\n%% Title information\n\\title{Relatively Complete Verification of Probabilistic Programs} %(Submission + Appendix)}         %% [Short Title] is optional;\n\\subtitle{An Expressive Language for Expectation-based Reasoning}                     %% \\subtitle is optional\n%\\subtitlenote{with subtitle note}       %% \\subtitlenote is optional;\n                                        %% can be repeated if necessary;\n                                        %% contents suppressed with 'anonymous'\n\n\n%% Author information\n%% Contents and number of authors suppressed with 'anonymous'.\n%% Each author should be introduced by \\author, followed by\n%% \\authornote (optional), \\orcid (optional), \\affiliation, and\n%% \\email.\n%% An author may have multiple affiliations and/or emails; repeat the\n%% appropriate command.\n%% Many elements are not rendered, but should be provided for metadata\n%% extraction tools.\n\n%% Author with single affiliation.\n\\author[Batz]{Kevin Batz}\n\\authornote{Batz and Katoen are supported by the ERC AdG 787914 FRAPPANT.}\n%\\authornote{with author1 note}          %% \\authornote is optional;\n                                        %% can be repeated if necessary\n%\\orcid{nnnn-nnnn-nnnn-nnnn}             %% \\orcid is optional\n\\affiliation{\n  %\\position{Position1}\n  %\\department{Software Modeling and Verification Group}              %% \\department is recommended\n  \\institution{RWTH Aachen University, Germany}            %% \\institution is required\n  %\\streetaddress{Street1 Address1}\n  %\\city{City1}\n  %\\state{State1}\n  %\\postcode{Post-Code1}\n  %\\country{Germany}                    %% \\country is recommended\n}\n\\email{kevin.batz@cs.rwth-aachen.de}          %% \\email is recommended\n\n\n\\author[Kaminski]{Benjamin Lucien Kaminski}\n%\\authornote{with author1 note}          %% \\authornote is optional;\n                                        %% can be repeated if necessary\n%\\orcid{nnnn-nnnn-nnnn-nnnn}             %% \\orcid is optional\n\\affiliation{\n  %\\position{Position1}\n  %\\department{Software Modeling and Verification Group}              %% \\department is recommended\n  \\institution{University College London, United Kingdom}            %% \\institution is required\n  %\\streetaddress{Street1 Address1}\n  %\\city{City1}\n  %\\state{State1}\n  %\\postcode{Post-Code1}\n  %\\country{Germany}                    %% \\country is recommended\n}\n\\email{b.kaminski@ucl.ac.uk}          %% \\email is recommended\n\n\n\\author[Katoen]{Joost-Pieter Katoen}\n\\authornotemark[1]\n%\\authornote{with author1 note}          %% \\authornote is optional;\n                                        %% can be repeated if necessary\n%\\orcid{nnnn-nnnn-nnnn-nnnn}             %% \\orcid is optional\n\\affiliation{\n  %\\position{Position1}\n  %\\department{Software Modeling and Verification Group}              %% \\department is recommended\n  \\institution{RWTH Aachen University, Germany}            %% \\institution is required\n  %\\streetaddress{Street1 Address1}\n  %\\city{City1}\n  %\\state{State1}\n  %\\postcode{Post-Code1}\n  %\\country{Germany}                    %% \\country is recommended\n}\n\\email{katoen@cs.rwth-aachen.de}          %% \\email is recommended\n\n\n\\author[Matheja]{Christoph Matheja}\n%\\authornote{with author1 note}          %% \\authornote is optional;\n                                        %% can be repeated if necessary\n%\\orcid{nnnn-nnnn-nnnn-nnnn}             %% \\orcid is optional\n\\affiliation{\n  %\\position{Position1}\n  %\\department{Software Modeling and Verification Group}              %% \\department is recommended\n  \\institution{ETH Z\\\"urich, Switzerland}            %% \\institution is required\n  %\\streetaddress{Street1 Address1}\n  %\\city{City1}\n  %\\state{State1}\n  %\\postcode{Post-Code1}\n  %\\country{Germany}                    %% \\country is recommended\n}\n\\email{cmatheja@inf.ethz.ch}          %% \\email is recommended\n\n\n%% Abstract\n%% Note: \\begin{abstract}...\\end{abstract} environment must come\n%% before \\maketitle command\n\\begin{abstract}\n        We study \\emph{a syntax for specifying quantitative \\enquote{assertions}}---functions mapping program states to numbers---for probabilistic program verification.\n        We prove that our syntax is expressive in the following sense: Given any probabilistic program $\\cc$, if a function $\\FF$ is expressible in our syntax, then the function mapping each initial state $\\pstate$ to the expected value of $\\FF$ evaluated in the final states reached after termination of $\\cc$ on $\\sigma$ (also called the weakest preexpectation $\\wp{\\cc}{\\FF}$) is also expressible in our syntax.\n        \n        As a consequence, we obtain a \\emph{relatively complete verification system}  for reasoning about expected values and probabilities in the sense of Cook:\n        %Apart from a single reasoning step about the inequality of two functions expressed as syntactic expressions in our language, given $\\FF$, $\\FG$, and $\\cc$, we can check whether $\\FG \\preceq \\wp{\\cc}{\\FF}$.\n        Apart from proving a single inequality between two functions given by syntactic expressions in our language, \n        given $\\FF$, $\\FG$, and $\\cc$, we can check whether $\\FG \\preceq \\wp{\\cc}{\\FF}$.\n\\end{abstract}\n\n%% Keywords\n%% comma separated list\n%\\keywords{probabilistic programs, randomized algorithms, formal verification, quantitative verification, quantitative reasoning}\n\n\n%% \\maketitle\n%% Note: \\maketitle command must come after title commands, author\n%% commands, abstract environment, Computing Classification System\n%% environment and commands, and keywords command.\n\\maketitle\n\n\n% !TEX root = ./main.tex\n\n\n\\section{Introduction}\\label{sec:introduction}\n\n\nProbabilistic programs are ordinary programs whose execution may depend on the outcome of random experiments, such as\nsampling from primitive probability distributions or branching on the outcome of a coin flip.\nConsequently, running a probabilistic program (repeatedly) on a single input generally gives not a single output but a \\emph{probability distribution} over outputs.\n\nIntroducing randomization into computations is an important tool for the design and analysis\nof \\emph{efficient algorithms}~\\cite{Motwani99}.\nHowever, increasing efficiency by randomization often comes at the price of introducing a non-zero probability of producing incorrect outputs.\nFurthermore, even though a program may be efficient \\emph{in expectation}, individual executions may exhibit a long---even infinite---run time~\\cite{DBLP:conf/rta/BournezG05,DBLP:journals/jacm/KaminskiKMO18}.\n\nReasoning about these probabilistic phenomena is hard.\nFor instance, deciding termination of probabilistic programs has been shown to be strictly more complex than for ordinary\nprograms~\\cite{DBLP:conf/mfcs/KaminskiK15,acta19}.\nNonetheless, probabilistic program verification is an active research area.\nAfter seminal work on probabilistic program semantics by \\citet{Kozen1979,Kozen1981}, many different techniques have been developed, see \\cite{DBLP:conf/popl/HartSP82} for an early example.\nModern approaches include, amongst others, \nmartingale-based techniques~\\cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/ChatterjeeFNH16,DBLP:conf/cav/ChatterjeeFG16,DBLP:conf/popl/ChatterjeeNZ17,DBLP:conf/aplas/HuangFC18,DBLP:conf/vmcai/FuC19} and\nweakest-precondition-style calculi~\\cite{benni_diss,McIverM05,DBLP:conf/pldi/NgoC018,DBLP:journals/jacm/KaminskiKMO18,DBLP:journals/pacmpl/BatzKKMN19}.\nThe former can be phrased in terms of the latter, and all of the aforementioned techniques can be understood as instances or extensions of Kozen's probabilistic propositional dynamic logic (\\textsf{PPDL})~\\cite{Kozen1983,Kozen1985}.\n\n\\paragraph{Probabilistic program verification, extensionally}\n\nThere are two perspectives for reasoning about programs: the \\emph{extensional} and the \\emph{intensional}.\nWhereas intensional approaches provide a syntax, \\ie a formal language, for  assertions, extensional approaches admit arbitrary assertions and dispense with considerations about syntax altogether---they treat assertions as purely mathematical entities.\n\nA standard technique for probabilistic program verification that takes the extensional approach is the \\emph{weakest preexpectation \\textnormal{($\\wpsymbol$)} calculus} of~\\citet{McIverM05}---itself an instance of Kozen's \\textsf{PPDL}~\\cite{Kozen1983,Kozen1985}.\nGiven a probabilistic program~$\\cc$ and \\emph{some function} $\\FF$ (called the \\emph{postexpectation}), mapping (final) states to numbers, the weakest preexpectation $\\wp{\\cc}{\\FF}$ is a mapping from (initial) states to numbers, such that%\n%\n\\begin{align*}\n\t\\wp{\\cc}{\\FF}(\\sigma) \\eeq \\begin{array}{l}\n\t\t\\textnormal{Expected value of $\\FF$, measured in final states reached}\\\\\n\t\t\\textnormal{after termination of $\\cc$ on initial state $\\sigma$}~.\n\t\t\\end{array}\n\\end{align*}%\n%\nFor probabilistic programs with \\emph{discrete} probabilistic choices, the $\\wpsymbol$ calculus can be defined for \\emph{arbitrary} real-valued postexpectations $\\FF$~\\cite{benni_diss,McIverM05}.\n%For programs sampling from \\emph{continuous} distributions, one has to take care of measurability of $\\FF$~\\cite{Kozen1983,Kozen1985}, but nevertheless:\n%It is not necessary to provide any \\emph{syntax} for these functions.\n%They are purely mathematical entities.\n\n\\paragraph{Probabilistic program verification, intensionally}\nWhile the extensional approach often yields elegant formalisms, it is unsuitable for developing practical verification\ntools, which ultimately rely on some syntax for assertions.\nIn particular, we cannot---in general---rely on the property, implicitly assumed in the extensional approach, that\nthere is no distinction between assertions representing the same mathematical entity: a tool may not realize that $4 \\cdot 0.5$\nand $\\sum_{i=0}^{\\infty} \\nicefrac{1}{2^i}$ represent the same mathematical entity (the number $2$).\n\nAn example of intensional probabilistic program verification is the \nverifier of \\citet{DBLP:conf/pldi/NgoC018} which specifies a simple syntax which is extensible by user-specified base and rewrite functions.\n%As verification is generally computationally intractable, a first angle of attack is to actually define a syntax, i.e.\\ a language, in which reasoning can be carried out.\n%Typically, one then restricts to syntactic subclasses of programs and assertions for which verification can indeed be performed.\n%A classical example this is Floyd-Hoare logic (or simply Hoare logic)~\\cite{floyd1967assigning,Hoare1969} \n%or Dijkstra's weakest precondition calculus \\cite{Dijkstra1976} together with the language of first-order arithmetic.\n\n\\paragraph{Main contribution}\nGiven a calculus for program verification and an assertion language, two fundamental questions immediately arise:%\n%\n\\begin{enumerate}\n  \\item \\emph{Soundness:} \\emph{Are only true assertions derivable} in the calculus?\n  \\item \\emph{Completeness}: \\emph{Can every true assertion be derived} \\underline{and} \\emph{is it expressible} in the assertion language?\n\\end{enumerate}%\n%\nWhile soundness is typically a \\emph{must} for any verification system,\ncompleteness is---as noted by \\citet{DBLP:journals/fac/AptO19} in their recent survey of 50 years of Hoare logic---a \n\\enquote{subtle matter and requires careful analysis}.\n\nIn fact, to the best of our knowledge, existing probabilistic program verification techniques \n(including all of the above references amongst many other works) \neither take the extensional approach\nor do not aim for completeness.\n%Probabilistic program verification techniques typically take the extensional approach \n%intensional aspects are less well understood.\n%While extensional probabilistic program analysis is quite well studied (see e.g., almost all \n%of the above references amongst many other works), intensional aspects are less well understood.\nIn this paper, we take the intensional path and make the following contribution to %intensional \nformal reasoning about probabilistic programs: % verification:\n%\n\\begin{center}%\n\\vspace{.5em}%\n\\fbox{\\parbox{0.98\\textwidth}{%\n\t\\begin{center}\n\tWe provide a simple formal \\emph{language of functions} for probabilistic program verification such that: % for probabilistic program analysis, such that:%\n\t\n\t\\vspace{.5em}%\n\tIf $\\FF$ is syntactically expressible, then $\\wp{\\cc}{f}$ is syntactically expressible.\n\t\\end{center}\n}}%\n\\vspace{.5em}%\n\\end{center}\n%\n%\\paragraph{Relative completeness}\nA language from which we can draw functions $\\FF$ with the above property is called \\emph{expressive}.\n%Although we cannot hope to achieve completeness for $\\wpsymbol$---Hoare logic is already incomplete~\\cite{DBLP:journals/fac/AptO19} and is subsumed by $\\wpsymbol$---\nHaving an expressive language renders the $\\wpsymbol$ calculus \\emph{relatively} complete~\\cite{Cook1978SoundnessAC}:\n%Apart from \\emph{a single reasoning} about the inequality of two functions given as syntactic expressions in our language, we can check whether $\\FG \\preceq \\wp{\\cc}{\\FF}$.\n%the question whether a syntactic function $\\FG$ is bounded by $\\wp{\\cc}{\\FF}$\n%is reduced to comparing the syntactical functions \n%$\\FF$ and $\\wp{\\cc}{\\FF}$.\n%Hence, $\\wpsymbol$ is complete \\emph{modulo} the fact that we need an oracle to compare syntactical functions.\nGiven functions $\\FF$ and $\\FG$ in our language and a probabilistic program $\\cc$, suppose we want to verify $\\FG \\preceq \\wp{\\cc}{\\FF}$, where $\\preceq$ denotes the point-wise order of functions\tmapping states to numbers.\nDue to expressiveness,\n%Since our language is expressive, \nwe can effectively construct in our language a function $\\FH$ representing $\\wp{\\cc}{\\FF}$.\nHence, verification is complete \\emph{modulo} checking whether the inequality $\\FG \\preceq \\FH$ between two functions in our language holds. % $\\wp{\\cc}{\\FF}$ and $\\FG$ represent the same function.\nIndeed, Hoare logic is also only complete \\emph{modulo} deciding an implication between two formulae in the language of \\mbox{first-order arithmetic~\\cite{DBLP:journals/fac/AptO19}}.\n\n\n\\paragraph{Challenges and usefulness}\nNotice that providing \\emph{some} expressive language is rather easy:\nA~single{\\-}ton language that can only represent the null-function is trivially expressive since, for any program $\\cc$, the expected value of $0$ is $0$. That is, $\\wp{\\cc}{0} = 0$.\nThe challenge in a quest for an expressive language for probabilistic program verification is hence to find a language that (i) is closed under taking weakest preexpectations and (ii) can express \\emph{interesting (quantitative) properties}.\n\nIndeed, our language can: % changed from \"...satisfies both properties.\" We only speak about the latter property in this paragraph.\nFor instance, it is capable of expressing \\emph{termination probabilities} (via~$\\wp{\\cc}{1}$---the expected value of the constant function 1).\nThese can be \\emph{irrational numbers} like the reciprocal of the golden ratio~$\\sfrac{1}{\\varphi}$~\\cite{OlmedoKKM16}.\nIn general, termination probabilities carry a high internal degree of complexity~\\cite{acta19}.\nOur language can also express probabilities over program variables on termination of a program and that can be expressed in terms of $\\pi$, $\\sqrt 3$ and so forth. These can e.g., be generated by Buffon machines, \\ie probabilistic programs that only use Bernoulli experiments~\\cite{DBLP:conf/soda/FlajoletPS11}.\n\nTermination probabilities already hint at one of the technical challenges we face:\nEven starting from a constant function like $1$, our language has to be able to express mappings from states to highly complex real numbers.\nAnother challenge we face is that when constructing $\\wp{\\cc}{\\FF}$, due to probabilistic branching in combination with loops, considering single execution traces is not enough:\nWe have to collect all terminating traces and average over the values of $\\FF$ in terminal states.\nWe attack these challenges via G\u00f6del numbers for rational sequences and encodings of Dedekind cuts.\n\nAside from termination probabilities, our language is capable of expressing \\emph{a wide range of practically relevant functions}, like \\emph{polynomials} or \\emph{Harmonic numbers}.\nPolynomials are a common subclass of ranking functions\\footnote{In probabilistic program analysis terminology: ranking supermartingales.} for automated probabilistic termination analysis; harmonic numbers are ubiquitous in expected runtime analysis. \nWe present more scenarios covered by our syntax and avenues for future work in Sections~\\ref{sec:applications} and~\\ref{sec:conclusion}.\n\nOverall, we believe that an expressive \\emph{syntax} for probabilistic program verification is what really expedites a search for tractable fragments of both programs and \\enquote{assertion} language in the first place.\nStudying such fragments may also yield additional insights:\nFor example, \\citet{DBLP:journals/tocl/Kozen00} and \\citet{DBLP:journals/isci/KozenT01} studied the propositional fragment of Hoare logic and showed that it is subsumed \nby an extension of KAT---Kleene algebra with tests.\n\n\n\\paragraph{Further related work}\nRelative completeness of Hoare logic was shown by \\citet{Cook1978SoundnessAC}.\n\\citet{winskel} and \\citet{loeckx1984foundations} proved expressiveness of first-order arithmetic for Dijkstra's weakest precondition calculus.\nFor \\emph{separation logic}~\\cite{DBLP:conf/lics/Reynolds02}---a very successful logic for compositional reasoning about \\emph{pointer programs}---expressiveness was shown by~\\citet{expressiveness_sl_conference,expressiveness_sl}, almost a decade later than the logic was originally developed and started to be used.\n\nPerhaps most directly related to this paper is the work by \\citet{DBLP:journals/ijfcs/HartogV02} on a Hoare-like logic for verifying probabilistic programs.\nThey prove relative completeness (also in the sense of \\citet{Cook1978SoundnessAC}) of their logic for \\emph{loop-free} probabilistic programs and \\emph{restricted postconditions}; they leave expressiveness for loops as an open problem: \\enquote{It is not clear whether the probabilistic predicates are sufficiently expressive [\\dots] for a given while loop.}\n\n\n%\\blkcommentinline{ LEFTOVER FROM CHRISTOPH: DIDN't QUITE KNOW HOW TO INTEGRATE:\n%\n%In the \\emph{intensional approach}, where the specification language is given by a formal syntax,\n%completeness is typically not achievable due to~\\cite{goedel, tarski}.\n%The best we can hope for is \\emph{relative completeness}, i.e.\\ given an oracle that discharges whether \n%\\medskip\n%\n%Due to Tarski's undefinability theorem~\\cite{tarski1936}, no sfficently \n%\\medskip\n%\n%In the \\emph{extensional approach}, where the specification language is purely mathematical rather than being defined by a formal syntax, completeness is typically immediate (cf.\\cite{Nielson92}).\n%However, deriving a true formula may require may require non-trivial transformations that are not restricted by any syntax:\n%Since there is no distinction between the number $2$ and, for instance, the geometric series $\\sum_{i=0}^{\\infty} \\nicefrac{1}{2}$ (which converges to $2$), a derivation that starts with the former but only works with the latter derivation is considered derivable---to the best of our knowledge, all calculi for reasoning about probabilistic programs either take the extensional approach or do not aim for completeness.\n%}\n\n\n\\subsubsection*{Organization of the paper}\n\nWe give an introduction to \\emph{syntax, extensional semantics, and verification systems} for probabilistic programs, in particular the weakest preexpectation calculus, in~\\Cref{sec:extensional}.\nWe formulate the \\emph{expressiveness problem} in \\Cref{sec:towards-expressiveness}.\nWe \\emph{define the syntax and semantics} of our \\emph{expressive language of expectations} in \\Cref{sec:syntax}.\nWe \\emph{prove expressiveness of our language for loop-free probabilistic programs} in \\Cref{sec:expressiveness:loop-free}.\nWe then move to proving expressiveness of our language for loops.\nWe \\emph{outline the expressiveness proof for loops} in \\Cref{sec:proof-outline} and \\emph{do the full technical proof} throughout Sections~\\ref{sec:embedding}~--~\\ref{sec:expressiveness}.\n%As we will evade the issue of \\emph{negative numbers}, we make remarks on how to deal with them in \\Cref{sec:negatives}.\n%Finally, we discuss applications of our language---scenarios in which it can be applied---in \\Cref{sec:applications} and conclude in \\Cref{sec:conclusion}.\nIn \\Cref{sec:negatives} and \\Cref{sec:applications}, we discuss extensions and a few scenarios in which our language could be useful; we conclude in \\Cref{sec:conclusion}.\n \n% !TEX root = ./main.tex\n\n\n\n\n\\section{Probabilistic Programs --- The Extensional Perspective}\n\\label{sec:extensional}\n%\nWe briefly recap classical reasoning about probabilistic programs \\'{a} la \\citet{Kozen1985}, which is agnostic of any \nparticular syntax for expressions or formulae---it takes an \\emph{extensional} approach.\n%\n\n\n\n\n\\subsection{The Probabilistic Guarded Command Language}\n\\label{sec:pgcl}\n%\nWe consider the imperative probabilistic programming language $\\pgcl$ featuring discrete probabilistic choices---branching on outcomes of coin flips---as well as standard control-flow instructions.\n\n\\subsubsection{Syntax}\nFormally, a program $\\cc$ in $\\pgcl$ adheres to the grammar\n%\n\\begin{align*}\n\\cc \\qqlongrightarrow \t\n%\n&  \\SKIP \t\\tag{effectless program} \\\\\n%\n& \\qmid \\ASSIGN{\\XX}{\\TT}\t\\tag{assignment} \\\\\n%\n& \\qmid \\COMPOSE{\\cc}{\\cc}\t\\tag{sequential composition} \\\\\n%\n& \\qmid \\PCHOICE{\\cc}{p}{\\cc}\t\\tag{probabilistic choice} \\\\\n%\n& \\qmid  \\ITE{\\BB}{\\cc}{\\cc}\t\\tag{conditional choice} \\\\\n%\n& \\qmid  \\WHILEDO{\\BB}{\\cc}~,\t\\tag{while loop} \n\\end{align*}\n%\nwhere $x$ is taken from a countably infinite set of \\emph{variables} $\\Vars$,\n$\\TT$ is an \\emph{arithmetic expression} over variables,\n$p \\in [0,1] \\cap \\Rats$ is a rational probability, and\n$\\BB$ is a Boolean expression (also called \\emph{guard}) over variables.\nFor an overview of metavariables $\\cc$, $\\XX$, $\\TT$, $\\BB$, \\dots, used throughout this paper, see \\Cref{tab:metavariables} at the end of this section.\n\n%\nFor the moment, we assume that both arithmetic and Boolean expressions are standard expressions without bothering to provide them with a concrete syntax. \nHowever, we will require them to adhere to a concrete syntax which we provide in Sections~\\ref{sec:syntax:terms}~and~\\ref{sec:syntax:bool}.\n%alongside our syntax for expectations---the quantitative analogon to assertions---\n%\n\n\n\n\n\\subsubsection{Program States}\n\\label{sec:program-states}\n%\nA program state $\\pstate$ maps each variable in $\\Vars$ to its value---a positive rational number in $\\PosRats$.\\footnote{To keep the presentation simple, we consider only \\emph{unsigned} variables; we discuss this design choice and an extension to signed variables, which can also evaluate to negative rationals, in Section~\\ref{sec:negatives}.}\nTo ensure that the set of program states is countable,\\footnote{Working with probabilistic programs over a countable set of states avoids technical issues related to measurability.} \nwe restrict ourselves to states in which at most finitely many variables---intuitively those that appear in a given program---are assigned non-zero values; every state can thus be understood as a finite mapping that only keeps track of assignments to non-zero values.\nFormally, the set $\\States$ of program states is\n%\n\\begin{align*}\n  \\States \\eeq \\setcomp{ \n    \\pstate\\colon \\Vars \\to \\PosRats ~\n    }{\n    \\vphantom{\\big(} \\setcomp{ x \\in \\Vars }{ \\pstate(x) \\neq 0} \\textnormal{ is finite}\n%    \\exists V \\subseteq \\Vars\\colon\n%        |V| < \\infty\n%        \\wedge \\forall x \\in (\\Vars\\setminus V)\\colon \\pstate(x) = 0\n  }~.\n\\end{align*}\n%\nWe use metavariables $\\pstatea$, $\\pstateb$, \\dots, for program states, see also \\Cref{tab:metavariables}.\nWe denote by $\\sem{\\ee}{\\pstate}{}$\nthe evaluation of (arithmetic or Boolean) expression $\\ee$ in $\\pstate$, i.e.,\nthe value obtained from evaluating $\\ee$ after replacing every variable $x$ in $\\ee$ \nby $\\pstate(x)$.\nWe define the semantics of expressions more formally in \\Cref{sec:semantics}.\n\n\n\n\n\n\\subsubsection{Forward Semantics}\n\\label{sec:forward-semantics}\nOne of the earliest ways to give semantics to a probabilistic program~$\\cc$ is by means of \\emph{forward-moving measure transformers} \\cite{Kozen1979,Kozen1981}.\nThese transform an initial state~$\\pstate$ into a probability distribution $\\mu_\\cc^{\\pstate}$ over final states (\\ie a measure on $\\States$).\nWe consider Kozen's semantics the \\emph{reference} forward semantics.\nMore operational semantics are provided in the form of probabilistic transition systems~\\cite{GretzKM14,benni_diss}, where programs describe potentially infinite Markov chains whose state spaces comprise of program states, or trace semantics~\\cite{DBLP:conf/esop/CousotM12,DBLP:conf/birthday/PierroW16,acta19}, where the traces are sequences of program states and each trace is assigned a certain probability.\n\nIn any of these semantics, the probabilistic choice $\\PCHOICE{\\cc_1}{p}{\\cc_2}$ flips a coin with bias $p$ towards heads. \nIf the coin yields heads, $\\cc_1$ is executed (with probability $p$); otherwise, $\\cc_2$.\nMoreover, $\\SKIP$ does nothing.\n$\\ASSIGN{x}{\\TT}$ assigns the value of expression $\\TT$ (evaluated in the current program state) to $x$.\nThe sequential composition $\\COMPOSE{\\cc_1}{\\cc_2}$ first executes $\\cc_1$ and then $\\cc_2$.\nThe conditional choice $\\ITE{\\BB}{\\cc_1}{\\cc_2}$ executes $\\cc_1$ if the guard $\\BB$ is satisfied; otherwise, it executes $\\cc_2$.\nFinally, the loop $\\WHILEDO{\\BB}{\\cc}$ keeps executing the loop body $\\cc$ as long as $\\BB$ evaluates to true.\n%\n\n\n\n\n\n\n\n\\subsection{Weakest Preexpectations}\n\n%Before we discuss requirements for a syntax that is both useful and allows relatively complete verification of $\\pgcl$ programs, let us consider the underlying technique for reasoning about probabilistic programs in general, i.e., independent of any particular syntax.\n%\nDually to the forward semantics, probabilistic programs can also be provided with semantics in the form of \\emph{backward-moving random variable transformers}, originally due to~\\citet{Kozen1983,Kozen1985}.\nThis paper is set within this dual view, which is a standard setting for probabilistic program verification.\n\n\n\n\n\n\n\\subsubsection{Expectations}\n\\label{sec:sem-exp}\n\\emph{Floyd-Hoare logic}~\\cite{Hoare1969,floyd1967assigning} as well as the \\emph{weakest precondition calculus} of \\citet{Dijkstra1976} employ first-order predicates for reasoning about program correctness.\nFor probabilistic programs, \\citet{Kozen1983,Kozen1985} was the first to generalize from predicates to measurable functions (or random variables). \nLater, \\citet{McIverM05} coined the term \\emph{expectation}---not to be confused with expected value---for such functions.\nIn reference to Dijkstra's weakest precondition calculus, their verification system is called the \\emph{weakest preexpectation calculus}.\n\nFormally, the set $\\E$ of \\emph{semantic expectations} is defined as\n%\n\\begin{align*}\n  \\E \\eeq \\setcomp{ \\ff }{ \\ff\\colon \\States \\to \\PosRealsInf }~,\n\\end{align*}\n%\n\\ie functions $\\ff$ that associate a non-negative \\emph{quantity} (or infinity) to each program state.\nWe use metavariables $\\ff$, $\\fg$, $\\fh$ for semantic expectations.\n\nExpectations form the \\emph{assertion \\enquote{language}} of the weakest preexpectation calculus.\nHowever, we note that---so far---expectations are \\emph{in no way defined syntactically}:\nThey are just the whole set of functions from $\\States$ to $\\PosRealsInf$.\nIt is hence borderline to speak of a \\emph{language}.\nThe goal of this paper is to provide a \\emph{syntactically defined subclass of\\:~$\\E$}---\\ie an \\emph{actual language}---such that formal reasoning about probabilistic programs can take place completely within this class.\n\nWe furthermore note that we work with more general expectations than \\citet{McIverM05}, who only allow \\emph{bounded} expectations, \\ie expectations $\\ff$ for which there is a bound $\\alpha \\in \\PosReals$ such \\mbox{that $\\forall \\pstate\\colon \\ff(\\pstate) \\leq \\alpha$}.\nIn contrast to McIver and Morgan, our structure $(\\E,\\, \\preceq)$ of \\emph{unbounded} expectations forms a \\emph{complete lattice} with least element $0$ and greatest element $\\infty$, where $\\preceq$ lifts the standard ordering  $\\leq$\non the (extended) reals to expectations by pointwise application. That is, \n%\n\\begin{align*}\n\t\\ff \\ppreceq \\fg \\qquad \\text{iff} \\qquad \\forall \\pstate  \\in \\States \\colon\\quad \\ff(\\pstate) \\lleq \\fg(\\pstate)~.\t\n\\end{align*}%\n%\nExamples of (bounded) expectations include, for instance, \\citet{Iverson1962} brackets $\\iverson{\\BB}$, which associate to a Boolean expression $\\BB$ its indicator function:\\footnote{We use $\\lambda$-expressions to denote functions; function $\\lambda x\\mydot f$ applied to $a$ evaluates to $f$ in which $x$ is replaced by $a$.}%\n%\n\\begin{align*}\n\t\\label{eqn:sem_iverson}\n\t\\iverson{\\BB} \\eeq \\lambda \\pstate \\mydot \n\t\\begin{cases}\n\t\t1, &\\text{if}~\\sem{\\BB}{\\pstate}{} = \\true \\\\\n\t\t%\n\t\t0, &\\text{if}~ \\sem{\\BB}{\\pstate}{}= \\false~.\n\t\\end{cases}\n\\end{align*}%\n%\nIverson brackets embed Boolean predicates into the set of expectations, rendering McIver and Morgan's calculus a conservative extension of Dijkstra's calculus.\n\nExamples of \\emph{unbounded} expectations are arithmetic expressions over variables, like%\n%\n\\begin{align*}\n\tx + y \\eeq \\lambda \\pstate\\mydot \\pstate(x) + \\pstate(y)~,\n\\end{align*}%\n%\nwhere we point-wise lifted common operators on the reals, such as $+$, to operators on expectations.\nStrictly speaking, \\emph{McIver and Morgan's calculus cannot handle expectations like $x + y$} off-the-shelf.\n\nWe denote by $\\ff\\subst{x}{\\TT}$ the \\enquote{substitution} of variable $x$ by expression $a$ in expectation $\\ff$, i.e.,\n%\n\\begin{align*}\n\t\\ff\\subst{x}{\\TT} \\eeq \\lambda \\pstate \\mydot  \\ff\\Bigl(\\pstate \\statesubst{x}{\\sem{\\TT}{\\pstate}{}} \\Bigr)~, \n\t%\n\t\\qquad\\text{where}\\qquad \n\t%\n\t\\pstate \\statesubst{x}{r} \\eeq \\lambda y \\mydot \\begin{cases}\n\t\t\tr, & \\textnormal{if } y = x, \\\\\n\t\t\t\\pstate(y), & \\textnormal{else}.\n\t\t\\end{cases}\n\\end{align*}\n%\n\n\n\n\n\\subsubsection{Backward Semantics: The Weakest Preexpectation Calculus}\n\n%\n%\n\\begin{figure}[t]\n\t\\begin{center}\n\t\t\\begin{adjustbox}{max width=.8\\textwidth}\n\t\t\t\t\\begin{tikzpicture}[node distance=4mm, decoration={snake,pre=lineto,pre length=.5mm,post=lineto,post length=1mm, amplitude=.2mm}]\n\t\t\t\t\t\\draw[lightgray,use as bounding box,draw=none] (-3.75,-.875) grid (3.25, 3.25);\n\t\t\t\t\t\\node (sigma) at (0, 3) {\\Large$\\boldsymbol{~\\pstate}$};\n\t\t\t\t\t\n\t\t\t\t\t\\node[gray,inner sep=0pt, outer sep=0pt] (branch) at (-0.225, 1.4) {$\\bullet$};\n\t\t\t\t\t\n\t\t\t\t\t\\node (tau1) at (-2, 0) {$\\bullet$};\n\t\t\t\t\t\\node (tau2) at (-.5, .25) {$\\bullet$};\n\t\t\t\t\t\\node (tau3) at (1, .125) {$\\bullet$};\n\t\t\t\t\t\\node[inner sep=0pt] (taudots) at (2.5, 0) {$\\ddots$};\n\t\t\t\t\t\n\t\t\t\t\t\\node[below of=tau1] {$\\ff(\\tau_1)$};\n\t\t\t\t\t\\node[below of=tau2] {$\\ff(\\tau_2)$};\n\t\t\t\t\t\\node[below of=tau3] {$\\ff(\\tau_3)$};\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\\node (Exp) at (-3.1, -0.25) {\\Large $\\textbf{\\textsf{Exp}}\\boldsymbol{\\Bigl[}$};\n\t\t\t\t\t\\node at (3.1, -0.25) {\\Large $\\boldsymbol{\\Bigr]}$};\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\\node[gray] (C) at (0.5, 1.5) {$\\cc$};\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (sigma) -- (tau1);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,thick] (sigma) -- (branch);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (branch) -- (tau2);\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (branch) -- (tau3);\n\t\t\t\t\t\\draw[gray,decorate,thick] (sigma) -- (taudots);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[decorate,lightgray] (tau1) -- (tau2) -- (tau3) -- (taudots);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray] (sigma) edge[|->,bend right=45,above left,thick] node {\\Large$\\wp{\\cc}{\\ff}$} (Exp);\n\t\t\t\t\t%\\draw (B) edge[->, very thick, right] node{\\white{$\\sfrac{1}{2}$}} (C);\n\t\t\t\t\\end{tikzpicture}\n\t\t\t\t\\qquad\\quad\n\t\t\t\t\\begin{tikzpicture}[node distance=4mm, decoration={snake,pre=lineto,pre length=.5mm,post=lineto,post length=1mm, amplitude=.2mm}]\n\t\t\t\t\t\\draw[lightgray,use as bounding box,draw=none] (-3.75,-.875) grid (3.25, 3.25);\n\t\t\t\t\t\\node (sigma) at (0, 3) {\\Large$\\boldsymbol{~\\pstate'}$};\n\t\t\t\t\t\n\t\t\t\t\t\\node[gray,inner sep=0pt, outer sep=0pt] (branch) at (.2, 1.25) {$\\bullet$};\n\t\t\t\t\t\n\t\t\t\t\t\\node (tau1) at (-2, 0) {$\\bullet$};\n\t\t\t\t\t\\node (tau2) at (-.75, .25) {$\\bullet$};\n\t\t\t\t\t\\node (tau3) at (1, -0.25) {$\\bullet$};\n\t\t\t\t\t\\node[inner sep=0pt] (taudots) at (2.5, 0) {$\\ddots$};\n\t\t\t\t\t\n\t\t\t\t\t\\node[below of=tau1] {$\\ff(\\tau_1')$};\n\t\t\t\t\t\\node[below of=tau2] {$\\ff(\\tau_2')$};\n\t\t\t\t\t\\node[below of=tau3] {$\\ff(\\tau_3')$};\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\\node at (-3.1, -0.25) {\\Large $\\textbf{\\textsf{Exp}}\\boldsymbol{\\Bigl[}$};\n\t\t\t\t\t\\node at (3.1, -0.25) {\\Large $\\boldsymbol{\\Bigr]}$};\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\\node[gray] (C) at (1, 1) {$\\cc$};\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (sigma) -- (tau1);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,thick] (sigma) -- (branch);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (branch) -- (tau2);\n\t\t\t\t\t\\draw[gray,decorate,->,thick] (branch) -- (tau3);\n\t\t\t\t\t\\draw[gray,decorate,thick] (sigma) -- (taudots);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[decorate,lightgray] (tau1) -- (tau2) -- (tau3) -- (taudots);\n\t\t\t\t\t\n\t\t\t\t\t\\draw[gray] (sigma) edge[|->,bend right=45,above left,thick] node {\\Large$\\wp{\\cc}{\\ff}$} (Exp);\n\t\t\t\t\\end{tikzpicture}%\n\t\t\\end{adjustbox}%\n\t\\end{center}%\n\t\\caption{The weakest preexpectation $\\wp{\\cc}{\\ff}$ maps every initial state $\\pstate$ to the expected value of $\\ff$, measured with respect to the final distribution over states reached after termination of program $\\cc$ on input $\\pstate$. \n\t$\\wpC{\\cc}$ is backward-moving in the sense that it transforms an $\\ff\\colon \\States \\To \\PosRealsInf$, evaluated in final states after termination of $\\cc$, into $\\wp{\\cc}{\\ff}\\colon \\States \\To \\PosRealsInf$, evaluated in initial states before execution of $\\cc$.}%\n\t\\label{fig:prog-execution}%\n\\end{figure}%\n%\n%\nSuppose we are interested in the expected value of the quantity (expectation) $\\ff$ after termination of $\\cc$.\nIn analogy to Dijkstra, $\\ff$ is called the \\emph{postexpectation} and the sough-after expected value is called the \\emph{weakest preexpectation} of $\\cc$ with respect to \\emph{postexpectation} \n$\\ff$, denoted $\\wp{\\cc}{\\ff}$~\\cite{McIverM05}.\nAs the expected value of $\\ff$ generally depends on the initial state $\\pstate$ on which $\\cc$ is executed, the \\emph{weakest preexpectation} $\\wp{\\cc}{\\ff}$ is itself also a map of type $\\E$, mapping an initial program state $\\pstate$ to the \\emph{expected value} of $\\ff$ (measured in the final states)\nafter successful termination of $\\cc$ on $\\pstate$, see \\Cref{fig:prog-execution}. %\nThe weakest preexpectation calculus is a backward semantics in the sense that it transforms a postexpectation $\\ff \\in \\E$, evaluated in final states after termination of $\\cc$, into a preexpectation $\\wp{\\cc}{\\ff} \\in \\E$, evaluated in initial states before execution of $\\cc$.\n\nBetween forward-moving measure transformers and backward-moving expectation transformers, there exists the following duality established by Kozen:%\n%\n%\n\\begin{theorem}[Kozen Duality \\textnormal{[\\citeyear{Kozen1983,Kozen1985}]}]%\n\\label{thm:kozen-duality}%\n\tIf $\\mu_{\\cc}^{\\pstate}$ is the distribution over final states obtained by running $\\cc$ on initial state $\\pstate$, then for any postexpectation $\\ff$,%\n%\n\\begin{align*}\n\t\\sum_{\\tau \\in \\States} \\mu_{\\cc}^{\\pstate}(\\tau) \\cdot \\ff(\\tau) \\eeq \\wp{\\cc}{\\ff}(\\pstate)~.\n\\end{align*}\n%\n\\end{theorem}%\n%\n%\n\\noindent{}%\nIn particular, if $\\ff = \\iverson{\\BB}$, then $\\wp{\\cc}{\\ff}(\\pstate)$ is the \\emph{probability} that\nrunning $\\cc$ on $\\pstate$ terminates in a final state satisfying $\\BB$---thus generalizing Dijkstra's weakest preconditions.\n\nAs with standard weakest preconditions, weakest preexpectations are not determined monolithically for the whole program $C$ as characterized above.\nRather, they are determined \\emph{compositionally} using a backward-moving \\emph{expectation transformer}\n\\begin{align*}\n\\wpsymbol \\colon \\pgcl \\to (\\E \\to \\E)\n\\end{align*}\nwhich is defined recursively on the structure of $\\cc$ according to the rules in Figure~\\ref{table:wp}.%\n%\n\\begin{figure}[t]\n\n\t\\renewcommand{\\arraystretch}{1.5}\n\n\\begin{tabular}{@{\\hspace{1em}}l@{\\hspace{2em}}l}\n\t\\hline\\hline\n\t$\\boldsymbol{\\cc}$\t\t\t& $\\boldsymbol{\\textbf{\\textsf{wp}}\\,\\left \\llbracket \\cc\\right\\rrbracket  \\left(\\ff \\right)}$ \\\\\n\t\\hline\n\t$\\SKIP$\t\t\t\t\t& $\\ff$ \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\\\n\t%\n\t$\\ASSIGN{x}{\\TT}$\t\t\t& $\\ff\\subst{x}{\\TT}$ \\\\\n\t%\n\t$\\COMPOSE{\\cc_1}{\\cc_2}$\t\t& $\\wp{\\cc_1}{\\vphantom{\\big(}\\wp{\\cc_2}{\\ff}}$ \\\\\n\t%\n\t$\\PCHOICE{\\cc_1}{\\pp}{\\cc_2}$\t\t& $\\pp \\cdot \\wp{\\cc_1}{\\ff} + (1- \\pp) \\cdot \\wp{\\cc_2}{\\ff}$ \\\\\n\t%\n\t$\\ITE{\\guard}{\\cc_1}{\\cc_2}$\t\t& $\\iverson{\\guard} \\cdot \\wp{\\cc_1}{\\ff} + \\iverson{\\neg \\guard} \\cdot \\wp{\\cc_2}{\\ff}$ \\\\\n\t%\n\t$\\WHILEDO{\\guard}{\\cc'}$\t\t& $\\lfp \\fg\\mydot \\iverson{\\neg \\guard} \\cdot \\ff + \\iverson{\\guard} \\cdot \\wp{\\cc'}{\\fg}$ \\\\\n\t\\hline\\hline\n\\end{tabular}\n\\caption{Rules defining the weakest preexpectation of program $\\cc$ with respect to postexpectation $\\ff$.}\n\\label{table:wp}\n\\end{figure} %\nMost of these rules are standard: \n$\\wpC{\\SKIP}$ is the identity as $\\SKIP$ does not modify the program state.\nFor the assignment $\\ASSIGN{x}{\\TT}$, \\mbox{$\\wp{\\ASSIGN{x}{\\TT}}{\\ff}$} substitutes in $\\ff$ the assignment's left-hand side $x$ by its\nright-hand side $\\TT$.\nFor sequential composition, $\\wp{\\COMPOSE{\\cc_1}{\\cc_2}}{\\ff}$ first determines the weakest preexpectation $\\wp{\\cc_2}{\\ff}$\nwhich is then fed into $\\wpC{\\cc_1}$ as a postexpectation.\nFor both the probabilistic choice $\\PCHOICE{\\cc_1}{p}{\\cc_2}$ and the conditional choice $\\ITE{\\BB}{\\cc_1}{\\cc_2}$, the\nweakest preexpectation with respect to $\\ff$ yields a convex sum $p \\cdot \\wp{\\cc_1}{\\ff} + (1-p) \\cdot \\wp{\\cc_2}{\\ff}$.\nIn the former case, the weights are given by the probability~$p$.\nIn the latter case, they are determined by the guard $\\BB$, \\ie we have  $p = \\iverson{\\BB}$ and $1 - \\iverson{\\BB} = \\iverson{\\neg \\BB}$.\n\nThe weakest preexpectation of a loop is given by the least fixed point of its unrollings, \\ie \n%\n\\begin{align*}\n\t\\wp{\\WHILEDO{\\BB}{\\cc'}}{\\ff} \\eeq \\lfp \\fg \\mydot \\charwp{\\BB}{\\cc'}{\\ff}(\\fg)~,\n\\end{align*}%\n%\nwhere the \\emph{characteristic function} \n$\\charwp{\\BB}{\\cc'}{\\ff}$ of $\\WHILEDO{\\BB}{\\cc'}$ with respect to $\\ff \\in \\E$ is defined as\n\\begin{align*}\n\\charwp{\\BB}{\\cc'}{\\ff}\\colon \\quad \\E \\to \\E, \\quad \\fg ~{}\\mapsto{}~ \\iverson{\\neg \\guard} \\cdot \\ff + \\iverson{\\BB} \\cdot \\wp{\\cc'}{\\fg}~.\n\\end{align*}\nSince $(\\E, \\leq)$ is a complete lattice and $\\charwp{\\BB}{\\cc'}{\\ff}$ is monotone, fixed points \nexist due to the Knaster-Tarski fixed point theorem; we take the least fixed point because we reason about total correctness.\n%\n%\n\nThroughout this paper, we exploit that $\\charwp{\\BB}{\\cc'}{\\ff}$ is, in fact, \nScott-continuous (cf.~\\cite{OlmedoKKM16}).\nKleene's theorem then allows us to approximate the least fixed point iteratively:\n\\begin{lemma}[\\textnormal{\\citet{kleene1952introduction}}]\n\t\\label{lem:kleene_for_wp}\n\tWe have \n\t%Let $\\cc = \\WHILEDO{\\BB}{\\cc'}$ be a loop and let $\\ff$ be an expectation. We have\n\t%\n\t\\begin{align*}\n\t\\wp{\\WHILEDO{\\BB}{\\cc'}}{ \\ff}\n\t%\n\t\\eeq\n\t\\lfp \\fg \\mydot \\charwp{\\BB}{\\cc'}{\\ff}(\\fg)\n\t%\n\t\\eeq\n\t\\sup_{n \\in \\Nats} \\charwpn{\\BB}{\\cc'}{\\ff}{n}(0)~,\n\t\\end{align*}\n    where $0 = \\lambda \\pstate\\mydot 0$ is the constant-zero expectation\n    and $\\charwpn{\\BB}{\\cc'}{\\ff}{n}(\\fg)$ denotes the $n$-fold application of \n    $\\charwp{\\BB}{\\cc'}{\\ff}$ to $\\fg$.%, i.e.,\\\n%    \\begin{align*}\n%        \\charwpn{\\BB}{\\cc'}{\\ff}{0}(0) \\eeq 0\n%        \\qquad \\text{and} \\qquad\n%        \\charwpn{\\BB}{\\cc'}{\\ff}{n+1}(0)  \\eeq \\charwp{\\BB}{\\cc'}{\\ff}(\\charwpn{\\BB}{\\cc'}{\\ff}{n}(0) )~.\n%    \\end{align*}\n\\end{lemma}\n%\n%%%%%\\noindent{}%\n%%%%%Before we take a closer look at examples motivating our search for a suitable syntax, \n%%%%%we note that the weakest preexpectation is \\emph{sound} in the sense that the rules in Figure~\\ref{table:wp} indeed compute the desired expected value~\\cite{GretzKM14}. That is, \n%%%%%\\begin{align*}\n%%%%%    \\wp{\\WHILEDO{\\BB}{\\cc'}}{\\ff}(\\pstate)\n%%%%%    \\eeq \n%%%%%    \\sum_{\\pstate, \\ldots, \\pstate_n \\in \\mathrm{Paths}} \\mathrm{Pr}(\\pstate, \\ldots, \\pstate_n) \\cdot \\ff(\\pstate_n)~,\n%%%%%\\end{align*}\n%%%%%where $\\mathrm{Paths}$ is the set of all execution paths $\\pstate, \\ldots, \\pstate_n$ of program $\\WHILEDO{\\BB}{\\cc'}$ that (i) start in initial state $\\pstate$ and (ii) terminate in some state $\\pstate_n$; \n%%%%%$\\mathrm{Pr}(\\pstate, \\ldots, \\pstate_n)$ denotes the probability that the given path $\\pstate, \\ldots, \\pstate_n$ is executed.\n%%%%%%\n%\n\\begin{table}[t]\n\t\\caption{Metavariables used throughout this paper.}%\n\t\\label{tab:metavariables}%\n\t\\renewcommand{\\arraystretch}{1.25}%\n\t\\begin{tabular}{l@{\\qquad}l@{\\qquad}l@{\\qquad}l}\n\t\t\\hline\\hline\n\t\t\\textbf{Entities}\t\t\t& \\textbf{Metavariables}  \t\t\t\t& \\textbf{Domain}\t\t& \\textbf{Defined}\t\t\t\\\\\n\t\t\\hline\n\t\tNatural numbers \t\t& $n,\\, i,\\, j,\\, k$ \t\t\t\t& $\\Nats$\t\t\t\t&\t\t\t\t\t\t\\\\\n\t\tPositive rationals \t\t& $\\RRa,\\, \\RRb,\\, \\RRc$ \t\t\t\t& $\\PosRats$\t\t\t&\t\t\t\t\t\t\\\\\n\t\tPositive extended reals \t& $\\alpha,\\, \\beta,\\, \\gamma$\t\t\t& $\\PosRealsInf$\t\t&\t\t\t\t\t\t\\\\\n\t\tRational probabilities \t& $p,\\, q$ \t\t\t\t\t\t\t& $[0,\\, 1] \\cap \\Rats$\t&\t\t\t\t\t\t\\\\[.75em]\n\t\t%\n\t\tVariables\t\t\t\t& $\\XX,\\, \\XY,\\, \\XZ,\\, \\VV,\\, \\VW,\\, \\VU, \\gnum$\t& \\Vars\t\t\t\t& \\Cref{sec:pgcl}\t \t\t\\\\\n%%%%%\t\tLogical variables\t\t& $\\VV,\\, \\VW,\\, \\VU$\t\t\t& \\LVars\t\t\t\t& \\Cref{sec:syntax:terms}\t\t\\\\[.75em]\n\t\t%\n\t\tArithmetic expressions \t& $\\TTa,\\, \\TTb$ \t\t\t\t& \\Terms\t\t\t\t& \\Cref{sec:syntax:terms}\t\t\\\\\n\t\tBoolean expressions \t& $\\BBa,\\, \\BBb,\\, \\BBc$\t \t\t\t& \\Bools\t\t\t\t& \\Cref{sec:syntax:bool}\t\t\\\\[.75em]\n\t\tSyntactic expectations \t& $\\FF,\\, \\FG,\\, \\FH$ \t\t\t\t\t& \\SyntE\t\t\t\t& \\Cref{sec:syntax:exp}\t\t\\\\\n\t\t%\n\t\tSemantic expectations \t& $\\ff,\\, \\fg,\\, \\fh$ \t\t\t\t\t& $\\E$\t\t\t\t& \\Cref{sec:sem-exp}\t\t\\\\[.75em]\n\t\t%\n\t\tPrograms \t\t\t\t& $C$ \t\t\t\t\t\t\t& \\pgcl \t\t\t\t& \\Cref{sec:pgcl}\t\t\t\\\\\n\t\tProgram states \t\t& $\\sigma,\\, \\tau$ \t\t\t\t\t& $\\States$ \t\t\t& \\Cref{sec:program-states}\t\\\\\n%%%%%\t\tInterpretations \t\t\t& $\\interpret$ \t\t\t\t& \t\t \t\t\t& \\Cref{sec:semantics}\t\t\\\\\n\t\t\\hline\\hline\n\t\\end{tabular}%\n\t\\renewcommand{\\arraystretch}{1}%\n\t%\\vspace*{.5em}%\n\\end{table}%\n%\n \n% !TEX root = ./main.tex\n\n\n\\section{Towards an Expressive Language for Expectations}\n\\label{sec:towards-expressiveness}\n%\nAs long as we take the extensional approach to program verification, \\ie we admit all expectations in $\\E$, \nreasoning about expected values of $\\pgcl$ programs is \\emph{complete}: \nFor every program $\\cc$ and postexpectation $\\ff$, it is, in principle, possible to find an expectation $\\wp{\\cc}{\\ff} \\in \\E$ which---by the above soundness property---coincides with the\nexpected value of $\\ff$ after termination of $\\cc$.\n\nThe main goal of this paper is to enable (relatively) complete verification of probabilistic programs by taking an \\emph{intensional} approach. \nThat is, we use the same verification technique described in Section~\\ref{sec:extensional} (\\ie the weakest preexpectation calculus) but%\n%\n\\begin{center}\n\tfix a set $\\SyntE$ of syntactic expectations $\\FF$.\n\\end{center}%\n%\nWe use metavariables $\\FF$, $\\FG$, $\\FH$, \\dots, for syntactic expectations, as opposed to \\mbox{$\\ff$, $\\fg$, $\\fh$, \\dots,} for semantic expectations in $\\E$, see also \\Cref{tab:metavariables}. \nWhile $\\FF$ itself is merely a syntactic entity to begin with, we denote by $\\eval{\\FF}$ the corresponding semantic expectation in $\\E$.\n%\nHaving a syntactic set of expectations at hand immediately raises the question of \\emph{expressiveness}: \n%\n\\begin{center}\n\tFor $\\FF \\in \\mathbf{E}$, is the weakest preexpectation $\\wp{\\cc}{\\eval{\\FF}}$ again expressible in $\\mathbf{E}$?\n\\end{center}%\n%\n%\n\\begin{definition}[Expressiveness of Expectations]\n\\label{def:expressiveness}\n    The set $\\SyntE$ of syntactic expectations is \\emph{expressive}\n    iff\n    for all programs $\\cc$ and all $\\FF \\in \\SyntE$\n    there exists a syntactic expectation $\\FG \\in \\SyntE$,\n    such that%\n    %\n\t\\begin{align*}\n\t\t\\wp{\\cc}{\\eval{\\FF}} = \\eval{\\FG}~. \\tag*{$\\triangle$}\n\t\\end{align*}%\n\\end{definition}\n%\n%\n\\noindent%\nNotice that constructing \\emph{some} expressive set of syntactic expectations is straightforward.\nFor example, the set $\\SyntE = \\{ 0 \\}$, which consists of a single expectation $0$---interpreted as the constant expectation $\\eval{0} = \\lambda \\pstate\\mydot 0$---is expressive: $\\wp{\\cc}{\\eval{0}} = \\eval{0}$ holds for every $\\cc$ by strictness of $\\wpsymbol$.\\footnote{$\\wpsymbol$ being strict means that $\\wp{\\cc}{0} = 0$ for every $\\cc$, see~\\cite{benni_diss}.}\n\nThe main challenge is thus to find a syntactic set $\\SyntE$ that (i) can be proven expressive \\emph{and} (ii)~covers interesting properties---at the very least, it should cover all Boolean expressions $\\BB$ (to reason about probabilities) and all arithmetic expressions $\\TT$ (to reason about expected values).\n%To guide our search towards such a syntax, this section proposes a few baseline requirements---expectations that we deem essential and that have to be included in any useful set of syntactic expectations.\n%After that, we perform a case study on what forms of expectations are typically found in the probabilistic program verification literature. The results serve as a sanity check on the relevance of the concrete syntax presented in the next section.\n%%\n%\\subsection{Essentials for Reasoning about Probabilities}\n%%\n%%\n%\\subsection{Essentials for Reasoning about Expected Values}\n%%\n%%\n%\\subsection{Case Study: How are Expectations used in the Literature?}\n%%\n%%\n%\\cmcommentinline{Remainder of this section:}\n%%\n%\\begin{itemize}\n%        \\item at the very least, $\\mathbf{E}$ should cover common guards $\\BB$\n%        \\item this automatically gives us some interesting things, namely $\\iverson{\\true}$ and \n%              characteristic assertions; essentially all distribution transformer\n%        \\item for expected values, it seems reasonable to also \n%        \\item what about it does not cover expected values beyond probabilities though?\n%\\end{itemize}\n\n\n\n\n%\n \n% !TEX root = ./main.tex\n\n\\section{Syntactic Expectations}\n\\label{sec:syntax}\n\nWe now describe the syntax and semantics for a set $\\SyntE$ of syntactic expectations which we will (in the subsequent sections) prove to be expressive and which can be used to express interesting properties such as, amongst others, the expected value of a variable $x$, the probability to terminate, the probability to terminate in a set described by a first-order arithmetic predicate $\\BB$, etc.\n\n\n\n\\subsection{Syntax of Arithmetical Expressions}\n\\label{sec:syntax:terms}\n\nWe first describe a \\emph{syntax for arithmetic expressions}, which form \\emph{precisely the right-hand-sides of \\underline{assi}g\\underline{nments} that we allow in \\pgcl programs}.\nNaturally, the syntax of arithmetical expressions will reoccur in our syntax of expectations.\nFormally, the set \\Terms of arithmetic expressions is given by%\n%\n\\begin{align*}\n\t\\TT \\qqlongrightarrow \t\n\t%\n\t%\n\t& \\RR \\iin \\PosRats \t\\tag{non-negative rationals} \\\\\n\t%\n\t& \\qmid  \\XX \\iin \\Vars \t\\tag{$\\PosRats$-valued variables} \\\\\n\t%\n%%%%%\t& \\qmid  \\VV \\iin \\LVars \t\\tag{$\\PosRats$-valued \\enquote{logical} variables} \\\\\n\t%\n\t& \\qmid  \\TT + \\TT \t\t\\tag{addition} \\\\\n\t%\n\t& \\qmid  \\TT \\cdot \\TT~, \t\\tag{multiplication} \\ \\\\\n\t%\n\t& \\qmid \\TT \\monus \\TT~, \\tag{subtraction truncated at 0 (\\enquote{monus})}\n\\end{align*}\n%\nwhere $\\Vars$ is a \\emph{countable} set of $\\PosRats$-valued variables.\n%%%%% and $\\LVars$ is a countable set of $\\PosRats$-valued logical variables. \nWe use metavariables $\\RRa,\\, \\RRb,\\, \\RRc$ for non-negative rationals, $\\XX,\\, \\XY,\\, \\XZ,\\, \\VV,\\, \\VW,\\, \\VU$ for variables, and $\\TTa,\\, \\TTb,\\, \\TTc$ for arithmetic expressions, see also \\autoref{tab:metavariables}.%\n%%%%Given a variable $\\varSymb$ and arithmetic expressions $\\TT, \\TT'$, the arithmetic expression $\\TT\\subst{\\varSymb}{\\TT'}$ obtained from substituting\n%%%%every occurrence of $\\varSymb$ in $\\TT$ by $\\TT'$ is defined recursively as follows:\n%%%%%\n%%%%\\begin{align*}\n%%%%r\\subst{\\varSymb}{\\TT'} &\\ddefeq r \\\\\n%%%%%\n%%%%x\\subst{\\varSymb}{\\TT'} & \\ddefeq  \\begin{cases}\n%%%%\\TT', & \\text{if}~x = \\varSymb  \\\\\n%%%%%\n%%%%x, & \\text{otherwise}~\n%%%%\\end{cases} \\\\\n%%%%%\n%%%%v\\subst{\\varSymb}{\\TT'} & \\ddefeq  \\begin{cases}\n%%%%\\TT', & \\text{if}~v = \\varSymb  \\\\\n%%%%%\n%%%%x, & \\text{otherwise}~\n%%%%\\end{cases} \\\\\n%%%%%\n%%%%\\left( \\TTa + \\TTb \\right)\\subst{\\varSymb}{\\TT'} & \\ddefeq \\TTa\\subst{\\varSymb}{\\TT'} + \\TTb\\subst{\\varSymb}{\\TT'} \\\\\n%%%%%\n%%%%\\left( \\TTa \\cdot \\TTb \\right)\\subst{\\varSymb}{\\TT'} & \\ddefeq \\TTa\\subst{\\varSymb}{\\TT'} \\cdot \\TTb\\subst{\\varSymb}{\\TT'} \\\\\n%%%%\\end{align*}%\n\n%%%%%The arithmetic expressions in which \\emph{no logical variables occur} form precisely the set of arithmetic expressions which we allow as right-hand-sides of assignments in \\pgcl programs.\n%%%%%The logical variables play their role \\enquote{merely} in making our language of expectations expressive.\n\t\n\t\n\t\n\t\n\\subsection{Syntax of Boolean Expressions}\n\\label{sec:syntax:bool}\n\nWe next describe a \\emph{syntax for Boolean expressions} over $\\Terms$, which form \\emph{precisely the g\\underline{uards} that we allow in \\pgcl programs} (for conditional choices and while loops).\nAgain, the syntax of Boolean expressions will also naturally reoccur in our syntax of expectations.\nFormally, the set \\Bools of Boolean expressions is given by%\n%\n\\begin{align*}\n\t\\BB \\qqlongrightarrow \t\n\t%\n\t%\n\t& \\TT < \\TT \t\t\t\\tag{strict inequality of arithmetic expressions} \\\\\n\t%\n\t& \\qmid  \\BB \\wedge \\BB \t\\tag{conjunction} \\\\\n\t%\n\t& \\qmid  \\neg \\BB~. \t\t\\tag{negation}\n\\end{align*}%\n%\nWe use metavariables $\\BBa,\\, \\BBb,\\, \\BBc$ for Boolean expressions, see also \\autoref{tab:metavariables}.\n%%%%%The Boolean expressions in which \\emph{no logical variables occur} (within the arithmetic expressions) form precisely the set of Boolean expressions which we allow as guards of conditional choices and loops in \\pgcl programs.\n\nThe following expressions are syntactic sugar with their standard interpretation and semantics:\n%\n\\begin{align*}\n    \\false~,\n    \\qquad \n    \\true~,\n    \\qquad\n    \\BBa \\vee \\BBb~,\n    \\qquad\n    \\BBa \\longrightarrow \\BBb~,\n    \\qquad \n    \\TTa = \\TTb~,\n    \\qqand\n    \\TTa \\leq \\TTb~.\n\\end{align*}%\n%\n%%\n%\\begin{align*}\n%    \\false \\ddefeq & \n%    0 < 0 \n%    \\tag{false} \\\\\n%    %\n%    \\true \\ddefeq &\n%    \\neg \\false \n%    \\tag{true} \\\\\n%    %\n%    \\BBa \\vee \\BBb \\ddefeq & \n%    \\neg (\\neg \\BBa \\wedge \\neg \\BBb) \n%    \\tag{disjunction} \\\\\n%    %\n%    \\BBa \\longrightarrow \\BBb \\ddefeq & \n%     (\\neg \\BBa \\vee \\BBb) \n%    \\tag{implication} \\\\\n%    %\n%    \\TTa = \\TTb \\ddefeq & \n%    \\neg (\\TTa < \\TTb) \\wedge \\neg (\\TTb < \\TTa) \n%    \\tag{equality of arithmetic expressions} \\\\\n%\t%\n%    \\TTa \\leq \\TTb \\ddefeq & \n%\t\\TTa = \\TTb \\vee \\TTa < \\TTb \n%    \\tag{inequality of arithmetic expressions}\n%\\end{align*}%\n%%\n%%%%Given a variable $\\varSymb$, a Boolean expression $\\BB$ and an arithmetic expression $\\TT$, the Boolean expression obtained from\n%%%%substituting every occurrence of $\\varSymb$ in $\\BB$ by $\\TT$ is defined recursively as follows:%\n%%%%%\n%%%%\\begin{align*}\n%%%%   \\left( \\TTa < \\TTb \\right)\\subst{\\varSymb}{\\TT} \\ddefeq& \\TTa\\subst{\\varSymb}{\\TT} < \\TTb \\subst{\\varSymb}{\\TT} \\\\\n%%%%   %\n%%%%   \\left( \\BBa \\wedge \\BBb \\right)\\subst{\\varSymb}{\\TT} \\ddefeq& \\BBa\\subst{\\varSymb}{\\TT} \\wedge \\BBb\\subst{\\varSymb}{\\TT} \\\\\n%%%%   %\n%%%%   \\left(\\neg \\BB \\right)\\subst{\\varSymb}{\\TT} \\ddefeq& \\neg \\left(\\BB \\subst{\\varSymb}{\\TT} \\right)\n%%%%%\\end{align*}%\n%\n%\n%\n\n\n\\subsection{Syntax of Expectations}\n\\label{sec:syntax:exp}\n\nWe now describe the syntax of a set of \\emph{expressive expectations} which can be used as both pre- and postexpectations for the verification of probabilistic programs.\nFormally, the set \\SyntE of \\emph{syntactic expectations} is given by%\n%\n\\begin{align*}\n\t\\FF \\qqlongrightarrow \t\n\t%\n\t%\n\t& \\TT \t\t\\tag{arithmetic expressions} \\\\\n\t%\n\t& \\qmid \\iverson{\\BB} \\cdot \\FF \\tag{guarding} \\\\\n\t%\n\t& \\qmid  \\FF + \\FF \t\t\\tag{addition} \\\\\n\t%\n\t& \\qmid \\TT \\cdot \\FF \\tag{scaling by arithmetic expressions} \\\\\n\t%\n\t& \\qmid \\SupV{\\XX} \\FF  \t\\tag{supremum over $\\XX$} \\\\\n\t%\n\t& \\qmid \\InfV{\\XX} \\FF~.  \t\\tag{infimum over $\\XX$}\n\t%\n\t%\n\t%& \\qmid \\iverson{b} \t\\tag{iverson brackets, i.e.\\ indicator functions} \\\\\n\t%\n\t%& \\qmid  f \\cdot f \t\\tag{multiplication} \\\\\n\t%\n\t%& \\qmid  t \\cdot f \t\\tag{scaling} \\\\\n\t%\n\t%& \\qmid  \\iverson{b} \\cdot f \t\\tag{guarded multiplication} \\\\\n\\end{align*}\n%\nAs mentioned before, we use metavariables $\\FF,\\, \\FG,\\, \\FH$ for syntactic expectations, see also \\autoref{tab:metavariables}.\nLet us go over the different possibilities of syntactic expectations according to the above grammar.\n\n\\paragraph{Arithmetic expressions}\nThese form the base case and it is immediate that they are needed for an expressive language.\nAssume, for instance, that we want to know the \\enquote{expected} (in fact: certain) value of variable $x$---itself an arithmetic expression by definition---after executing $\\ASSIGN{x}{\\TT}$.\nThen this is given by $\\wp{\\ASSIGN{x}{\\TT}}{x} = \\TT$---again an arithmetic expression.\nAs $\\TT$ could have been \\emph{any} arithmetic expression, we at least need all arithmetic expressions in an \\mbox{expressive expectation language}.\n\n\\paragraph{Guarding and addition.}\nBoth guarding---multiplication with a predicate---and addition are used for expressing weakest preexpectations of conditional choices and loops.\nAs we have, for instance,\n%\n\\begin{align*}\n\t\\wp{\\ITE{\\BB}{\\cc_1}{\\cc_2}}{f}  \\eeq \\iverson{\\BB} \\cdot \\wp{\\cc_1}{f} + \\iverson{\\neg\\BB} \\cdot \\wp{\\cc_1}{f}~,\n\\end{align*}%\n%\nit is evident that guarding and addition is convenient, if not necessary, for being expressive.\n\n\\paragraph{Scaling by arithmetic expressions.}\nOne could ask why we restrict to multiplications of arithmetic expressions and expectations and do not simply allow for multiplication of two arbitrary expectations $\\FF \\cdot \\FG$.\nWe will defer this discussion to \\Cref{sec:note-on-f-times-f}.\nFor now, it suffices to say that we can express all multiplications we need without running into trouble with quantifiers which would happen otherwise.\n\n\\paragraph{Suprema and infima.}\nThe supremum and infimum constructs $\\SupV{\\XX} \\FF$ and $\\InfV{\\XX} \\FF$ take over the role of the $\\exists$ and $\\forall$ quantifiers of first-order logic.\nWe use them to \\emph{bind} variables $\\XX$. \nThe \\mbox{$\\Sup$ and $\\Inf$}~quantifiers are necessary to make our expectation language expressive in the same was as, for instance, at least the $\\exists$ quantifier is necessary to make first-order logic expressive for weakest preconditions of non-probabilistic programs.\n\\medskip \n\nAs is standard, we additionally admit %in our syntax \n\\emph{parentheses} for clarifying the order of precedence in syntactic expectations.\n%To mostly avoid parentheses, however, \nTo keep the amount of parentheses to a minimum,\nwe assume that $\\cdot$ has precedence over $+$ and that the quantifiers~\\Sup and \\Inf have the \\emph{least} precedence.\n\nThe set of \\emph{free variables} $\\FV{\\FF} \\subseteq \\Vars$ % \\cup \\LVars$ of some syntactic expectation $\\FF$ \nis the set of all variables that occur syntactically in $\\FF$\nand that are not in the scope of some \\Sup or \\Inf quantifier. \n%Since quantification over program variables is not allowed,\n%$\\FV{\\FF}$ contains at least all program variables occurring in $\\FF$. \nWe write $\\FF(\\XX_1,\\, \\ldots,\\, \\XX_n)$ to indicate\nthat \\emph{at most} the variables $\\XX_1,\\, \\ldots,\\, \\XX_n$ occur freely in $\\FF$.\n\nGiven a syntactic expectation $\\FF$, a variable $\\XX \\in \\FV{\\FF}$, and an arithmetic expression $\\TT$, we denote by $\\FF\\subst{\\XX}{\\TT}$ the \\emph{syntactic replacement} of every occurrence of $\\XX$ in $\\FF$ by $\\TT$.\nGiven a syntactic expectation of the form $\\FF(\\ldots, \\XX_i, \\ldots)$, we often write $\\FF(\\ldots,\\TT,\\ldots)$ instead\nof the more cumbersome $\\FF(\\ldots, \\XX_i, \\ldots)\\subst{\\XX_i}{\\TT}$.\n\n%%%%The following common constructs are expressible as syntactic expectations:%\n%%%%%\n%%%%\\begin{align*}\n%%%%    \\iverson{\\BB} \\ddefeq & \n%%%%    \\iverson{\\BB} \\cdot 1\n%%%%    \\tag{Iverson brackets, i.e.\\ indicator functions} \\\\\n%%%%    %\n%%%%    \\Min{\\FF}{\\FG} \\ddefeq & \t\n%%%%    \\InfV{\\XX} \\iverson{0 < \\XX} \\cdot \\FF + \\iverson{\\neg (0 < \\XX)} \\cdot \\FG, \\qquad \\textnormal{where } \\XX \\not\\in \\FV{\\FF} \\cup \\FV{\\FG}\n%%%%    \\tag{point-wise minimum} \\\\\n%%%%\t%\n%%%%\t\\Max{\\FF}{\\FG} \\ddefeq &\n%%%%    \\SupV{\\XX} \\iverson{0 < \\XX} \\cdot \\FF + \\iverson{\\neg (0 < \\XX)} \\cdot \\FG, \\qquad \\textnormal{where } \\XX \\not\\in \\FV{\\FF} \\cup \\FV{\\FG}\n%%%%    \\tag{point-wise maximum}\n%%%%\\end{align*}%\n%%%%%\n%%% is defined recursively as follows:\n%%%%\n%%%\\begin{align*}\n%%%   \\TTa \\subst{\\varSymb}{\\TT}&~\\text{is the substitution for arithmetic expressions} \\\\\n%%%   %\n%%%   \\left( \\SupV{\\XX} \\FF'\\right) &\\ddefeq \\SupV{\\XX} \\FF'\\subst{\\varSymb}{\\TT} \\\\\n%%%   %\n%%%   \\left( \\InfV{\\XX} \\FF'\\right) &\\ddefeq \\InfV{\\XX} \\FF'\\subst{\\varSymb}{\\TT} \\\\ \n%%%   %\n%%%   \\left(  \\iverson{\\BB} \\cdot \\FF' \\right)\\subst{\\varSymb}{\\TT} & \\ddefeq \\iverson{\\BB}\\subst{\\varSymb}{\\TT} \\cdot \\FF'\\subst{\\varSymb}{\\TT} \\\\\n%%%   %\n%%%    \\left(  \\TT' \\cdot \\FF' \\right)\\subst{\\varSymb}{\\TT} & \\ddefeq \\TT' \\subst{\\varSymb}{\\TT} \\cdot \\FF'\\subst{\\varSymb}{\\TT} \\\\\n%%%    %\n%%%    \\left(\\FF + \\FG \\right)\\subst{\\varSymb}{\\TT} &\\ddefeq \\FF\\subst{\\varSymb}{\\TT} + \\FG\\subst{\\varSymb}{\\TT}\n%%%\\end{align*}\n%%%%\n%%%\\blkcommentinline{... bis hier.}%\n%\n%%%%%Finally, we should mention that the syntactic expectations in which \\emph{no logical variables occur f\\underline{reel}y} form precisely the set of syntactic expectations which we will prove \\emph{expressiveness}.\n \n% !TEX root = ./main.tex\n\n\\subsection{Semantics of Expressions and Expectations} \n\\label{sec:semantics}\n\nThe semantics of arithmetic and Boolean expressions is standard---see \\Cref{fig:semantics:expressions}.\n%We now give a Tarski-style semantics for syntactic expectations.\n%\n\\begin{table}[t]\n\t\\renewcommand{\\arraystretch}{1.5}\n\n    \\begin{tabular}{@{\\hspace{1em}}l@{\\hspace{2em}}l|@{\\hspace{1em}}l@{\\hspace{2em}}l}\n\t\\hline\\hline\n    $\\boldsymbol{\\TT}$ & $\\boldsymbol{\\sem{\\TT}{\\pstate}{}}$ & $\\boldsymbol{\\BB}$ & $\\boldsymbol{\\sem{\\BB}{\\pstate}{} = \\true}\\quad\\textbf{iff}$ \\\\\n\t\\hline\n\t%\n    $\\RR\\quad(\\in \\PosRats)$ & $\\RR$ & $\\TTa < \\TTb$ &  $\\sem{\\TTa}{\\pstate}{} < \\sem{\\TTb}{\\pstate}{}$ \\\\\n    $\\XX\\quad(\\in \\Vars)$ & $\\pstate(\\XX)$ & $\\BBb \\wedge \\BBc$ & $\\sem{\\BBb}{\\pstate}{\\interpret} = \\true = \\sem{\\BBc}{\\pstate}{\\interpret}$   \\\\\n    $\\TTb + \\TTc$ & $\\sem{\\TTb}{\\pstate}{} + \\sem{\\TTc}{\\pstate}{}$ & $\\neg \\BBb$ & $\\sem{\\BBb}{\\pstate}{} = \\false$ \\\\\n    $\\TTb \\cdot \\TTc$ & $\\sem{\\TTb}{\\pstate}{} \\cdot \\sem{\\TTc}{\\pstate}{}$ & \\\\\n    $\\TTb \\monus \\TTc$ & $\\begin{cases}\n    \\sem{\\TTb}{\\pstate}{} - \\sem{\\TTc}{\\pstate}{}, & \\text{if}~\\sem{\\TTb}{\\pstate}{} \\geq \\sem{\\TTc}{\\pstate}{} \\\\\n    0\\,, &\\text{else}\n    \\end{cases}\n    $& \\\\\n    %\n\t\\hline\\hline\n\\end{tabular}\n\\caption{The semantics of arithmetic expressions $\\TT$ and Boolean expressions $\\BB$.}\n\\label{fig:semantics:expressions}\n\\end{table}\n %\n%We now give a recursively defined Tarski-style quantitative semantics to arithmetic and Boolean expressions and finally to syntactic expectations.\n%%%%%The intention of syntactic expectations is to assign quantities to program states, i.e.\\ to describe a mapping from program states (i.e.\\ valuations of program variables) to $\\PosRealsInf$.\n%%%%%In order to provide a recursively defined semantics, however, we also need to be able to assign values to the logical variables.\n%%%%%As is standard in logic, we achieve the above by means of interpretations.\n%%%%%For us, an \\emph{interpretation}~$\\interpret\\colon \\LVars \\to \\PosRats$ is a mapping from logical variables to non-negative rationals.\n%%%%%We can now give a fully recursive semantics to expressions and expectations.\n%\n%\n%\n%\n%\\subsubsection{Semantics of Arithmetic Expressions}\n%\n%The semantics $\\sem{\\TT}{\\pstate}{}$ of an arithmetic expression \\TT under state \\pstate \n%%%%%%and interpretation \\interpret \n%is a \\emph{positive rational} defined recursively as follows:\n%%\n%\\begin{align*}\n%\t\\sem{\\RR}{\\pstate}{\\interpret} &\\ddefeq \\RR~,  \n%    \\tag*{for $\\RR \\in \\PosRats$} \\\\\n%\t%\n%    \\sem{\\XX}{\\pstate}{\\interpret} &\\ddefeq \\pstate(\\XX)~,  \n%    \\tag*{for $\\XX \\in \\Vars$} \\\\\n%\t%\n%%%%%%\t\\sem{\\VV}{\\sigma}{\\interpret} &\\ddefeq\\interpret(\\VV)~,  \n%%%%%%    \\tag*{for $\\VV \\in \\LVars$} \\\\[.5em]\n%\t%\n%\t\\sem{\\TTa + \\TTb}{\\pstate}{\\interpret} &\\ddefeq \\sem{\\TTa}{\\pstate}{\\interpret} \\pplus \\sem{\\TTb}{\\pstate}{\\interpret}\\\\\n%\t%\n%\t\\sem{\\TTa \\cdot \\TTb}{\\pstate}{\\interpret} &\\ddefeq \\sem{\\TTa}{\\pstate}{\\interpret} \\ccdot \\sem{\\TTb}{\\pstate}{\\interpret}\n%\\end{align*}\n%%\n%\n%\n%\t\n%\\subsubsection{Boolean Expressions}\\label{sec:boolean_expressions}\n%\n%The semantics $\\sem{\\BB}{\\pstate}{\\interpret}$ of a Boolean expression \\BB under state \\pstate \n%%%%%%and interpretation \\interpret \n%is a \\emph{truth value} defined recursively as follows:\n%%\n%\\begin{align*}\n%\t\\sem{\\TTa < \\TTb}{\\pstate}{\\interpret} &\\ddefeq \\begin{cases}\n%\t\t\\true, & \\textnormal{ if }~ \\sem{\\TTa}{\\pstate}{\\interpret} \\LL \\sem{\\TTb}{\\pstate}{\\interpret}\\\\\n%\t\t\\false, & \\textnormal{ else }\n%\t\\end{cases} \\\\[.125em]\n%\t%\n%\t\\sem{\\BBa \\wedge \\BBb}{\\pstate}{\\interpret} &\\ddefeq \\begin{cases}\n%\t\t\\true, & \\textnormal{ if }~ \\sem{\\BBa}{\\pstate}{\\interpret} = \\true = \\sem{\\BBb}{\\pstate}{\\interpret} \\\\\n%\t\t\\false, & \\textnormal{ else }\n%\t\\end{cases} \\\\[.125em]\n%\t%\n%\t\\sem{\\neg \\BB}{\\pstate}{\\interpret} &\\ddefeq \\begin{cases}\n%\t\t\\true, & \\textnormal{ if }~ \\sem{\\BB}{\\pstate}{\\interpret} = \\false \\\\\n%\t\t\\false, & \\textnormal{ else }\n%\t\\end{cases}\n%\\end{align*}\n%%\n%\n%\n%\n%\n%\\subsubsection{Semantics of Expectations}\n%\nFor a program state~$\\sigma$, \n%%%%%and interpretation $\\interpret$,\nwe define\n%\n%\n\\begin{align*}\n\\sigma\\statesubst{\\XX}{\\RR} \\ddefeq \\lambda \\XY \\mydot \n\\begin{cases}\n  \\RR, &\\text{if}~\\XY=\\XX \\\\\n  %\n  \\sigma(\\XY), &\\text{otherwise.}\n\\end{cases}\n%%%%%\\qquad \n%%%%%\\text{and}\n%%%%%\\qquad\n%%%%%\\interpret\\statesubst{\\VV}{\\RR} \\ddefeq \\lambda \\VW \\mydot\n%%%%%\\begin{cases}\n%%%%%   \\RR ,& \\text{if}~\\VW=\\VV \\\\\n%%%%%   %\n%%%%%   \\interpret(\\VW), & \\text{otherwise}~.\n%%%%%\\end{cases}\n\\end{align*}\n%\nThe semantics $\\sem{\\FF}{\\pstate}{\\interpret}$ of an expectation \\FF under state \\pstate \n%%%%%and interpretation \\interpret \nis an \\emph{extended positive real} (\\ie a positive real number or $\\infty$) defined inductively as follows:\n%\n\\begin{align*}\n\t\\sem{\\TT}{\\pstate}{\\interpret} &\\ddefeq \\sem{\\TT}{\\pstate}{\\interpret}~\\footnotemark\\\\[.125em]\n\t%\n\t\\sem{\\iverson{\\BB} \\cdot \\FF}{\\pstate}{\\interpret} &\\ddefeq \\begin{cases}\n            \\sem{\\FF}{\\pstate}{\\interpret}, & \\textnormal{ if }~ \\sem{\\BB}{\\sigma}{\\interpret} = \\true \\\\\n\t\t0, & \\textnormal{ else }\n\t\\end{cases} \\\\[.75em]\n\t%\n\t%\n\t\\sem{\\FF + \\FG}{\\pstate}{\\interpret} &\\ddefeq \\sem{\\FF}{\\pstate}{\\interpret} \\pplus \\sem{\\FG}{\\pstate}{\\interpret}\\\\[.75em]\n\t%\n\t\\sem{\\TT \\cdot \\FF}{\\pstate}{\\interpret} &\\ddefeq \\sem{\\TT}{\\pstate}{\\interpret} \\ccdot \\sem{\\FF}{\\pstate}{\\interpret}\n    \\\\[.75em]\n    \t%\n\t\\sem{\\SupV{\\XX} \\FF}{\\pstate}{\\interpret} & \\ddefeq \\sup~\\setcomp{\\sem{\\FF}{\\pstate\\statesubst{\\XX}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats}\\\\[.125em]\n\t%\n\t\\sem{\\InfV{\\XX} \\FF}{\\pstate}{\\interpret} &\\ddefeq \\inf\\hspace{1.1ex}\\setcomp{\\sem{\\FF}{\\pstate\\statesubst{\\XX}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats}\n\t%\n\t%\n%\t\\sem{\\Min{f}{g}}{\\sigma}{\\interpret} &\\qeq \\Min{\\sem{f}{\\sigma}{\\interpret}}{\\sem{g}{\\sigma}{\\interpret}} \\\\\n%\t%\n%\t\\sem{\\Max{f}{g}}{\\sigma}{\\interpret} &\\qeq \\Max{\\sem{f}{\\sigma}{\\interpret}}{\\sem{g}{\\sigma}{\\interpret}} \\\\[.75em]\n\t%\n\\end{align*}%\n\\footnotetext{Here, on the left-hand-side $\\sem{\\:\\cdot\\:}{\\pstate}{\\interpret}$ denotes the semantics of expectations, whereas on the right-hand-side $\\sem{\\:\\cdot\\:}{\\pstate}{\\interpret}$ denotes the semantics of arithmetic expressions.}%\n%\n%\nWe assume that $0 \\cdot \\infty = 0$.\nMost of the above are self-explanatory.\nThe most involved definitions are the ones for quantifiers.\nThe interpretation of the $\\SupV{\\XX} \\FF$ quantification, for example, interprets~$\\FF$ under all possible values of the bounded variable $\\XX$ and then returns the supremum of all these values.\nAnalogously, $\\InfV{\\XX} \\FF$ returns the infimum. \nNotice that---even though all variables evaluate to rationals---both the supremum and the infimum are taken over a set of reals.\nHence, an expectation $\\FF$ involving $\\Sup$ or $\\Inf$ possibly evaluates to an \\emph{irrational} number. \nFor example, the expectation\n%Consider, e.g., the expectation\n\\[\n   \\FF \\eeq \\Sup \\XX \\colon \\iverson{x \\cdot x < 2} \\cdot x~,\n\\]\n%\nevaluates to $\\sqrt{2} \\not\\in\\PosRats$ under every state $\\pstate$.\n\nThe supremum of $\\emptyset$ is $0$.\nDually, the infimum of $\\emptyset$ is $\\infty$. \nThe supremum of an unbounded set is~$\\infty$.\nWe also note that our semantics can generate $\\infty$ only by using a $\\Sup$ quantifier.%\n% and moreover that%\n%\\begin{align*}\n%\t\\sem{a}{\\pstate}{\\interpret} = 0\n%\t\\qand\n%\t\\sem{f}{\\pstate}{\\interpret} = \\infty\n%\t\\qqimplies \n%\t\\sem{a \\cdot f}{\\pstate}{\\interpret} = 0~.\n%\\end{align*}\n%Put simply, our semantics gives $0 \\cdot \\infty = 0$ which is standard in measure theory and $\\wpsymbol$ reasoning.\n\nAs a shorthand for turning syntactic expectations into semantic ones, we define%\n%\n\\begin{align*}\n\t\\eval{\\FF} \\ddefeq \\lambda \\pstate\\mydot \\sem{\\FF}{\\pstate}{}~.\n\\end{align*}%\n%\n\n\n\n\\subsection{Equivalence and Ordering of Expectations}\n\nFor two expectations $\\FF$ and $\\FG$, we write $\\FF = \\FG$ only if they are \\emph{syntactically equal}.\nOn the other hand, we say that two expectations $\\FF$ and $\\FG$ are \\emph{semantically equivalent}, denoted $\\FF \\equiv \\FG$, if their semantics under every state \n%and interpretation \nis equal, \\ie \n%\n\\begin{align*}\n\t\\FF \\eequiv \\FG \\qqiff \\eval{\\FF} \\eeq \\eval{\\FG}~.\n\\end{align*}%\n%\nSimilarly to the partial order $\\preceq$ on semantical expectations in $\\E$, we define a (semantical) partial order~$\\preceq$ on syntactic expectations in $\\SyntE$ by%\n%\n\\begin{align*}\n\t\\FF \\ppreceq \\FG \\qqiff \\eval{\\FF} \\ppreceq \\eval{\\FG}~.\n\\end{align*}%\n%\n\n\n\n\n\\subsection{A Note on Forbidding $\\boldsymbol{\\FF \\cdot \\FG}$ in our Syntax}\n\\label{sec:note-on-f-times-f}\n\nAnalogously to classical logic, a syntactic expectation $\\FF$ is in \\emph{prenex normal form}, if it is of the form\n%\n\\begin{align*}\n\tf \\eeq \\Quant_1 \\XX_1 \\ldots \\Quant_k \\XX_k  \\colon \\FG~,\n\\end{align*}\n%\nwhere $\\Quant_i \\in \\{\\Sup, \\Inf\\}$ and where $\\FG$ is quantifier-free.\nBeing able to transform any syntactic expectation into prenex normal form while preserving its semantics will be essential to our expressiveness proof.\nIn particular, we require that there is an algorithm that brings arbitrary syntactic expectations into prenex normal form, without inspecting their semantics.\n\nThe problem with allowing $\\FF \\cdot \\FG$ arises in the context of the $0 \\cdot \\infty = 0$ phenomenon.\nSuppose for the moment that we allow for $\\FF \\cdot \\FG$ syntactically and define\n%\n\\begin{align*}\n   \\sem{\\FF \\cdot \\FG}{\\sigma}{\\interpret}\n   %\n   \\ddefeq\n   %\n    \\sem{\\FF}{\\sigma}{\\interpret} \\cdot \\sem{\\FG}{\\sigma}{\\interpret}\n\\end{align*}%\n%\nsemantically, where $0 \\cdot \\infty = \\infty \\cdot 0 = 0$. \nBecause of commutativity of multiplication, the above is an absolutely natural definition.\nThis also immediately gives us that $\\sem{\\FF \\cdot \\FG}{\\sigma}{\\interpret} = \\sem{\\FG \\cdot \\FF}{\\sigma}{\\interpret}$.\n\nWe now show that we encounter a problem when trying to transform expectations into prenex normal form. For that, consider the two expectations\n%\n\\begin{align*}\n\t\\FF \\eeq \\Inf \\XX \\colon \\frac{1}{\\XX +1}\n\t\\qqand\n\t\\quad  \\FG \\eeq \\Sup \\XY \\colon \\XY~.\n\\end{align*}\n%\nNotice that we slightly abuse notation since, strictly speaking, $\\frac{1}{\\XX +1}$ is not allowed by our syntax. We can however express it as $\\Sup \\XZ \\colon \\iverson{\\XZ \\cdot (\\XX +1) = 1}\\cdot \\XZ $. \nClearly, we have $\\sem{\\FF}{\\sigma}{} = 0$ and $\\sem{\\FG}{\\sigma}{} = \\infty$\nfor all $\\sigma$, \\ie both $\\FF$ and $\\FG$ are constant expectations.\n\nLet us now consider the product of $\\FF$ and $\\FG$.\nFor all $\\sigma$, its semantics is given by\n% \n\\begin{align*}\n\t\\sem{\\FF \\cdot \\FG}{\\sigma}{\\interpret} \\eeq \\sem{\\FF}{\\sigma}{\\interpret} \\cdot \\sem{\\FG}{\\sigma}{\\interpret} \\eeq 0 \\cdot \\infty \\eeq 0 \\eeq \\infty \\cdot 0 \\eeq \\sem{\\FG}{\\sigma}{\\interpret} \\cdot \\sem{\\FF}{\\sigma}{\\interpret} \\eeq \\sem{\\FG \\cdot \\FF}{\\sigma}{\\interpret}~.\n\\end{align*}%\n%\nNow consider the following:\n%\n\\begin{align*}\n\t\\blue{\\sem{\\FF \\cdot \\FG}{\\sigma}{\\interpret}} \n\t%\n\t\\eeq & \\sem{\\left(\\Inf \\XX \\colon \\frac{1}{\\XX +1} \\right) \\cdot \\bigl(\\Sup \\XY \\colon \\XY\\bigr)}{\\sigma}{\\interpret}\\\\\n\t%\n\t%\n\t\\eeq &\\sem{\\Inf \\XX \\colon \\Sup \\XY \\colon \\frac{1}{\\XX +1} \\cdot \\XY}\n    {\\sigma}{\\interpret} \\tag{by prenexing}\\\\\n    %\n    \\eeq & \\inf \\setcomp{\n        \\sup \\setcomp{\\frac{1}{\\RRa +1} \\cdot \\RRb}\n        {\\RRb \\in \\PosRats}\n    }\n    {\\RRa \\in \\PosRats} \\\\\n    %\n    \\eeq & \\inf \\setcomp{\n    \t\\infty\n    }\n    {\\RRa \\in \\PosRats} \\\\\n    %\n    \\blue{\\eeq} & \\blue{\\infty} \\\\\n    %\n    \\blue{~{}\\neq{}~}& \\blue{0} \\\\\n    %\n    \\eeq& \\sup \\setcomp{\n    \t0\n    }\n    {\\RRb \\in \\PosRats} \\\\\n    %\n    \\eeq& \\sup \\setcomp{\n    \t\\inf \\setcomp{\\frac{1}{\\RRa +1} \\cdot \\RRb}\n    \t{\\RRa \\in \\PosRats}\n    }\n    {\\RRb \\in \\PosRats} \\\\\n    %\n    \\eeq& \\sup \\setcomp{\n    \t\\inf \\setcomp{\\RRb \\cdot \\frac{1}{\\RRa +1} }\n    \t{\\RRa \\in \\PosRats}\n    }\n    {\\RRb \\in \\PosRats} \\tag{by commutativity of $\\cdot$ in $\\PosRealsInf$}\\\\\n    %\n    %\n    \\eeq & \\sem{\\Sup\\XY \\colon \\Inf \\XX \\colon \\XY \\cdot  \\frac{1}{\\XX +1}}\n    {\\sigma}{\\interpret} \\\\\n    %\n    \\eeq & \\sem{\\bigl(\\Sup \\XY \\colon \\XY\\bigr) \\cdot \\left(\\Inf \\XX \\colon \\frac{1}{\\XX +1} \\right) }{\\sigma}{\\interpret} \\tag{by un-prenexing}\\\\\n    %\n    \\blue{\\eeq} & \\blue{\\sem{\\FG \\cdot \\FF}{\\sigma}{\\interpret}}\n\\end{align*}\n%\n%\nWe see that $\\Sup\\XY \\colon \\Inf \\XX \\colon \\frac{1}{\\XX +1} \\cdot \\XY$ is a sound prenex normal form of $\\FG \\cdot \\FF$ whereas $\\Inf \\XX \\colon \\Sup \\XY \\colon \\frac{1}{\\XX +1} \\cdot \\XY$ apparently is not a sound prenex normal form of $\\FF \\cdot \\FG$.\nA fact that seems even more off-putting is that---even though $f \\equiv 0$---the above argument would not have worked for $f = 0$.\n\nTo summarize, we deem the above considerations enough grounds to forbid $f \\cdot g$ altogether, in particular since the rescaling $a \\cdot f$ suffices in order for our syntactic expectations to be expressive. \nWe also note that we will later provide a syntactic, but much more complicated, way to write down arbitrary products between syntactic expectations, see~\\Cref{thm:prod_exp}.\n%Moreover, in our semantics \\enquote{$0 \\cdot \\infty = 0$} is a theorem---not a definition.\n\n\n%%%%%\\emph{Ideas for dealing with this problem.} One idea is to compare the outermost quantifiers of $\\FF$ and $\\FG$ and to always pull out $\\Sup$ first. \n%%%%%This works for our example depicted above. However, we encounter a problem if we add a \\enquote{dummy quantifier} to $f_2$. Let \n%%%%%%\n%%%%%\\begin{align*}\n%%%%%    \\FG' \\eeq \n%%%%%    \\eeq  \\Inf \\VV \\colon\\Inf  \\XX_{\\text{egal}} \\colon \\frac{1}{\\VV +1}~.\n%%%%%\\end{align*}\n%%%%%%\n%%%%%Clearly, $\\FG \\equiv \\FG'$ since $\\XX_{\\text{egal}}$ does not occur in $f_2$.\n%%%%%Now, the outermost quantifier of both $\\FF$ and $\\FG'$ is $\\Inf$. How to decide which of these quantifiers we pull out first? If we choose the wrong one (namely $\\Inf \\VV$), then we once again end up with an unsound prenex normal evaluating to $\\infty$ rather than $0$.\n%%%%%\\kbcommentinline{We could improve this idea by not only considering the outermost quantifiers, but all quantifiers until we encounter the first supremum.}\n%%%%%\\kbcommentinline{No, Kevin, this also fails since we can add dummy suprema. Damn.}\n%%%%%\n%%%%%Another idea to deal with $\\FF \\cdot \\FG$ is to still forbid this arbitrary multiplication of expectations syntactically, but to show that it can be expressed in our language of syntactic expectations. Put more formally:\n%%%%%%\n%%%%%\\begin{align*}\n%%%%% \\text{for every $\\FF, \\FG \\in \\SyntE$, there is an $\\FF \\in \\SyntE$ such that} \\quad\n%%%%% \\forall \\sigma \\forall \\interpret \\colon\n%%%%%  \\sem{\\FF}{\\sigma}{\\interpret} \\cdot \\sem{\\FG}{\\sigma}{\\interpret}  \\eeq \n%%%%%  \\sem{\\FF}{\\sigma}{\\interpret} ~.\n%%%%%\\end{align*}\n%%%%%%\n%%%%%\\kbcommentinline{The Dedekind normal form presented in Section~\\ref{sec:normalforms} might enable this. I will investigate this.}\n%%%%%\n%%%%%\\kbcommentinline{I think there is a further reason for forbidding $\\FF \\cdot \\FG$:}\n%%%%%%\n%%%%%In our current syntax (without $\\FF \\cdot \\FG$), we do not even have to define that $0 \\cdot \\infty = 0$.\n%%%%%A situation of the form\n%%%%%%\n%%%%%\\begin{align*}\n%%%%%   & \\sem{\\FF}{\\sigma}{\\interpret} \\cdot \\sem{\\FG}{\\sigma}{\\interpret} \\eeq 0 \\cdot \\infty\n%%%%%\\end{align*}\n%%%%%%\n%%%%%can occur only if $\\FF$ is something quantifier-free and $\\FG$ is something containing a supremum.\n%%%%%Hence, we can always invoke Lemma~\\ref{thm:prenex:aux} (with $c = \\sem{\\FF}{\\sigma}{\\interpret}  = 0$) to see that the above evaluates to $0$. No need to explicitly define $0 \\cdot \\infty = 0$.\n%%%%%\n%%%%%On the other hand, if we allowed for \\kbcommentinline{The Dedekind normal form presented in Section~\\ref{sec:normalforms} might enable this. I will investigate this.}\n%%%%%\\cmcommentinline{As staded above, in my view this has no priority.}\n%%%%%\\blkcommentinline{So far, all but the last argument appeal to prenexing, which would be nice to have, but is not a natural property, I think. having $f \\cdot f$ syntactically on the other hand is rather natural. Moreover, I don't find $0 \\cdot \\infty = 0$ needing a definition unnatural.}\n \n% !TEX root = ./main.tex\n\n\n\\section{Expressiveness for Loop-free Programs}\n\\label{sec:expressiveness:loop-free}\n\n\n\\noindent{}%\nBefore we deal with loops, we now show that our set $\\SyntE$ of syntactic expectations is\n\\emph{expressive for all \\underline{loo}p\\underline{-}f\\underline{ree} $\\pgcl$ programs}.\n%, which we collect in the set $\\pgcl_{\\textrm{loop-free}}$.\nProving expressiveness for loops is \\emph{way more involved} and will be addressed \n\\mbox{separately in the remaining sections}.\n%\n\\begin{lemma}%\n\\label{thm:expressive-loop-free}%\n\t$\\SyntE$ is expressive (see \\textnormal{\\Cref{def:expressiveness}}) for all loop-free $\\pgcl$ programs $\\cc$, \\ie \n\tfor all $\\FF \\in \\SyntE$ there exists a syntactic expectation $\\FG \\in \\SyntE$, such that\n\t%\n\t\\begin{align*}\n%\t\t\\forall \\textnormal{loop-free }\\cc~ \n%\t\t\\forall \\FF \\in \\SyntE~ \n%\t\t\\exists \\FG \\in \\SyntE\n%\t\t\\colon \\qquad\n\t\t\\wp{\\cc}{\\eval{\\FF}} \\eeq \\eval{\\FG}~.\n\t\\end{align*}%\n\\end{lemma}%\n%\n%\n\\noindent{}%\nFor proving this expressiveness lemma (and also for the case of loops), we need the following technical lemma about substitution of variables by values in our semantics:\n%\n%\n\\begin{lemma}%\n\\label{lem:substitution}%\n\tFor all $\\pstate$, $\\FF$, and $\\TT$,\n\t%\n\t\\begin{align*}\n\t   \\sem{\\FF\\subst\\XX{\\TTa}}{\\sigma}{\\interpret}\n\t   \\eeq\n\t   \\sem{\\FF}{\\sigma \\statesubst\\XX{\\sem{\\TTa}{\\sigma}{\\interpret}}}{\\interpret}\n\t   %\n\t   %\n\t   \\qquad\\textnormal{or equivalently}\\qquad\n\t   %\n\t   %\n\t   \\eval{\\FF\\subst\\XX{\\TTa}}\n\t   \\eeq\n\t   \\eval{\\FF}\\subst\\XX{\\TTa}\n\t   %\n%%%%%\t   \\qquad\n%%%%%\t   \\textnormal{and}\n%%%%%\t   \\qquad\n%%%%%\t   \\sem{\\FF\\subst{\\VV}{\\TTb}}{\\sigma}{\\interpret}\n%%%%%\t   \\eeq\n%%%%%\t   \\sem{\\FF}{\\sigma}{\n%%%%%\t   \t\\interpret\\statesubst{\\VV}{\\sem{\\TTb}{\\sigma}{\\interpret}}}~.\n\t\\end{align*}\n\\end{lemma}%\n%\n%\n\\begin{proof}\n\tBy induction on the structure of $\\FF$.\n\\end{proof}%\n%\n%\n\\noindent{}%\nIntuitively, Lemma~\\ref{lem:substitution} states that syntactically replacing variable $\\XX$ by an arithmetical expression $a$ in expectation $\\FF$ amounts to interpreting $\\FF$ in states where the variable~$\\XX$ has been substituted by the evaluation of $\\TTa$ under that state.\n%%%%%The analogous explanation goes for syntactic substitution of variables by an arbitrary arithmetic expression $\\TTb$.\n\n\\begin{proof}[Proof of \\textnormal{\\Cref{thm:expressive-loop-free}}]\n\tLet $\\FF \\in \\SyntE$ be arbitrary.\n\tThe proof goes by induction on the structure of loop-free programs $\\cc$.\n\tIt is somewhat standard, but it demonstrates nicely that our syntactic constructs are actually needed, so we provide it here.\n\tWe start with the atomic programs:\n\t%\n\t\\paragraph{The effectless program $\\SKIP$}\n\tWe have $\\wp{\\SKIP}{\\eval{\\FF}} = \\eval{\\FF}$ and $\\FF \\in \\SyntE$ by assumption.\n\t\n\t\\paragraph{The assignment $\\ASSIGN{x}{\\TT}$} \n\tWe have \n\t\\begin{align*}\n\t\t\\wp{\\ASSIGN{x}{\\TT}}{\\eval{\\FF}} \n\t\t& \\eeq \\eval{\\FF}\\subst{x}{\\TT} \t\t\\\\\n\t\t& \\eeq \\eval{\\FF\\subst{x}{\\TT}} \t\t\\tag{by \\Cref{lem:substitution}}\n\t\\end{align*}%\n\tand $\\FF\\subst{x}{\\TT} \\in \\SyntE$ since $\\FF\\subst{x}{\\TT}$ is obtained from $\\FF$ by a syntactical replacement.\n\n\t\\paragraph{Induction Hypothesis}\n\tFor arbitrary loop-free $\\cc_1$ and $\\cc_2$, there exist syntactic expectations $\\FG_1,\\FG_2 \\in \\SyntE$, such that%\n\t\\begin{align*}\n\t\t\\wp{\\cc_1}{\\eval{\\FF}} \\eeq \\eval{\\FG_1}\n\t\t\\qqand\n\t\t\\wp{\\cc_2}{\\eval{\\FF}} \\eeq \\eval{\\FG_2}~.\n    \\end{align*}\n    %\n    We then proceed with the compound loop-free programs:\n\n    \\paragraph{The probabilistic choice $\\PCHOICE{\\cc_1}{p}{\\cc_2}$} \n    We have%\n    %\n    \\begin{align*}\n       &\\wp{\\PCHOICE{\\cc_1}{p}{\\cc_2}}{\\eval{\\FF}} \\\\\n       %\n       & \\eeq  p \\cdot \\wp{\\cc_1}{\\eval{\\FF}} + (1-p) \\cdot \\wp{\\cc_2}{\\eval{\\FF}}\n       \\tag{by definition of $\\wpsymbol$} \\\\\n       %\n       & \\eeq p \\cdot \\eval{\\FG_1} + (1-p) \\cdot \\eval{\\FG_2}\n       \\tag{by I.H.\\ on $\\cc_1$ and $\\cc_2$} \\\\\n       %\n       & \\eeq \\eval{p \\cdot \\FG_1 + (1-p) \\cdot \\FG_2}\n       \\tag{pointwise addition and multiplication}\n    \\end{align*}\n    %\n    and $p \\cdot \\FG_1 + (1-p) \\cdot \\FG_2 \\in \\SyntE$, see \\Cref{sec:syntax:exp}.\n    \n    \n    \\paragraph{The conditional choice $\\ITE{\\BB}{\\cc_1}{\\cc_2}$} \n    We have%\n    %\n    \\begin{align*}\n       & \\wp{\\ITE{\\BB}{\\cc_1}{\\cc_2}}{\\eval{\\FF}} \\\\\n       %\n       & \\eeq  \\iverson{\\BB} \\cdot \\wp{\\cc_1}{\\eval{\\FF}}  + \\iverson{\\neg\\BB}\\cdot \\wp{\\cc_2}{\\eval{\\FF}} \n       \\tag{by definition of $\\wpsymbol$} \\\\\n       %\n       & \\eeq \\iverson{\\BB} \\cdot \\eval{\\FG_1} + \\iverson{\\neg\\BB} \\cdot \\eval{\\FG_2}\n       \\tag{by I.H.\\ on $\\cc_1$ and $\\cc_2$} \\\\\n       %\n       & \\eeq \\eval{\\iverson{\\BB} \\cdot  \\FG_1 + \\iverson{\\neg\\BB} \\cdot  \\FG_2}\n       \\tag{pointwise addition and multiplication}\n    \\end{align*}\n    %\n    and $\\iverson{\\BB} \\cdot  \\FG_1 + \\iverson{\\neg\\BB} \\cdot  \\FG_2 \\in \\SyntE$, see \\Cref{sec:syntax:exp}.\n    \\medskip\n    \n    Hence, $\\SyntE$ is expressive for loop-free programs.\n    %\n\\end{proof}\n \n% !TEX root = ./main.tex\n\n\n\\section{Expressiveness for Loopy Programs --- Overview}\n\\label{sec:proof-outline}\n\n\\newcommand{\\syntsum}[3]{\\sfsymbol{Sum}_{#1,#2}\\left( #3 \\right)}\n\\newcommand{\\cciter}{\\cc_{\\textrm{iter}}}\n\nBefore we get to the proof itself, we outline the main challenges---and the steps we took to address them---of \nproving expressiveness of our syntactic expectations $\\SyntE$ for $\\pgcl$ programs including loops; \nthe technical details of the involved encodings and auxiliary results are considered throughout Sections~\\ref{sec:embedding}~--~\\ref{sec:expressiveness}.\nThis section is intended to support navigation through the individual components of the expressiveness proof; as such, we provide various references to follow-up sections.\n\n\\subsection{Setup}\n%%%%%Our overall goal is to prove that $\\SyntE$ is expressive, i.e.\\ for all $\\pgcl$ programs $C$ and all syntactic postexpectations $\\FF \\in \\SyntE$, there exists a syntactic weakest preexpectation $\\FG \\in \\SyntE$ such that\n%%%%%\\[ \\wp{\\cc}{ \\eval{\\FF} } \\eeq \\eval{\\FG}~. \\]\n\nAs in the loop-free case considered in Section~\\ref{sec:expressiveness:loop-free}, we prove expressiveness of $\\SyntE$ for all $\\pgcl$ programs (including loopy ones) by induction\non the program structure; all cases except loops are completely analogous to the proof of Lemma~\\ref{thm:expressive-loop-free}.\n%\nOur remaining proof obligation thus boils down to proving that, for every loop $\\cc = \\WHILEDO{\\BB}{\\cc'}$,\n\\begin{align*}\n  \\forall\\, \\FF \\in \\SyntE ~ \\exists\\, \\FG \\in \\SyntE\\colon \\quad \n  \\wp{\\,\\WHILEDO{\\BB}{\\cc'}}{ \\eval{\\FF} } \\eeq \\eval{\\FG}~, \\tag{$\\dagger$}\n\\end{align*}\nwhere we already know by the I.H. that the same property holds for the loop body $\\cc'$, i.e.,%\n%\n\\begin{align}\n\t\\forall\\, \\FF' \\in \\SyntE ~ \\exists\\, \\FG' \\in \\SyntE\\colon \\quad \n\t\\wp{\\cc'}{ \\eval{\\FF'} } \\eeq \\eval{\\FG'}~.\n\t\\label{eq:loops:ih}\n\\end{align}%\n%\n\n\\paragraph{Remark (A Simplification for this Overview)}\\label{sec:overview:simplification}\nJust for this overview section, we assume that the set $\\Vars$ of all variables is \\emph{finite} instead of countable.\nThis is a convenient simplification to avoid a few purely technical details such that we can focus on the actual ideas of the proof.\nWe do \\emph{not} make this assumption in follow-up sections.\nRather, our construction will ensure that only the finite set of ``relevant'' variables---those that appear in \nthe program or the postcondition under consideration---is taken into account.\\hfill$\\triangle$\n\n\\subsection{Basic Idea: Exploiting the Kozen Duality}\n\\label{sec:kozen_duality}\n%\n%Exploiting Kozen duality, \nWe first move to an alternative characterization of the weakest preexpectation of loops \nwhose components are simpler to capture with syntactic expectations.\nIn particular, we will be able to apply our induction hypothesis (\\ref{eq:loops:ih}) to some of these components.\n\nRecall the Kozen duality between forward moving measure transformers and backward moving expectation transformers (see \\Cref{thm:kozen-duality} and Figure~\\ref{fig:prog-execution} in Section~\\ref{sec:extensional}):%\n%\n\\begin{align*}\n    \\wp{\\cc}{\\ff}\n    \\eeq \n    \\lambda \\pstate_0\\mydot \n    \\sum_{\\tau \\in \\States} \\ff(\\tau) \\cdot \\mu_{\\cc}^{\\pstate_0}(\\tau)~,\n\\end{align*}%\n%\nwhere $\\mu_{\\cc}^{\\pstate_0}$ is the probability distribution over final states obtained by running $\\cc$ on initial state~$\\pstate_0$. \nAdapting the above equality to our concrete case in which $\\cc$ is a loop and $\\ff = \\eval{\\FF}$, we obtain\n%\n\\begin{align*}\n    \\wp{\\,\\WHILEDO{\\BB}{\\cc'}}{\\eval{\\FF}}\n    \\eeq \n    \\lambda \\pstate_0\\mydot \n    \\sum_{\\tau \\in \\States} \\, \\eval{\\iverson{\\neg \\BB} \\cdot \\FF}(\\tau) \\cdot \\mu_{\\WHILEDO{\\BB}{\\cc'}}^{\\pstate_0}(\\tau)~,\n\\end{align*}\n%\nwhere we strengthened the postexpectation $\\FF$ to $\\iverson{\\neg\\BB} \\cdot \\FF$ to account for the fact that the loop guard $\\BB$ is violated in every final state, see~\\cite[Corollary 4.6, p.~85]{benni_diss}.\n%\nThe main idea is---instead of viewing the whole distribution $\\mu_{\\WHILEDO{\\BB}{\\cc'}}^{\\sigma_0}$ in a single \\enquote{big step}---to take a more operational \\enquote{small-step} view: \nwe consider the intermediate states reached after each guarded loop iteration, which corresponds to executing the program%\n\\begin{align*}\n\t\\cciter \\eeq \\ITE{\\BB}{\\cc'}{\\SKIP}~.\n\\end{align*}%\n%\nWe then sum over all terminating \\emph{execution paths}---finite sequences of states $\\pstate_0, \\ldots \\pstate_{k-1}$ with initial state $\\pstate_0$ and final state $\\pstate_{k-1} = \\tau$---instead of a single final state $\\tau$. \nThe probability of an execution path is then given by the product of the probability  $\\mu_{\\cciter}^{\\pstate_{i}}(\\pstate_{i+1})$ of each intermediate step, i.e., the probability of reaching the state $\\pstate_{i+1}$ from the previous state $\\pstate_{i}$:\n%\n\\begin{align}\n    \\wp{\\,\\WHILEDO{\\BB}{\\cc'}}{\\eval{\\FF}} \\eeq \n    \\lambda \\pstate_0\\mydot \n    \\sup_{k \\in \\Nats}\n    \\sum_{\\sigma_0, \\ldots, \\sigma_{k-1} \\in \\States} \n    \\eval{\\iverson{\\neg \\BB} \\cdot \\FF}(\\pstate_{k-1}) \\cdot\n    \\prod_{i = 0}^{k-2}\n    \\mu_{\\cciter}^{\\pstate_i}(\\pstate_{i+1})~.\n    \\label{eq:loops:small-step}\n\\end{align}\nNotice that the above sum (without the $\\sup$) considers all execution paths of a fixed length $k$; we take the supremum over all natural numbers\n$k$ to account for all terminating execution paths.\n\n%\n%Notice that the first state of every execution path is the initial state $\\pstate_0$ which is supplied as an argument of the expectation.\n%\nNext, we aim to apply the induction hypothesis (\\ref{eq:loops:ih}) to the probability $\\mu_{\\cciter}^{\\pstate_i}(\\pstate_{i+1})$ of each step\nsuch that we can write it as a syntactic expectation.\nTo this end, we need to characterize $\\mu_{\\cciter}^{\\pstate_i}(\\pstate_{i+1})$ in terms of weakest preexpectations.\nWe employ a syntactic expectation $\\statepred{\\pstate}{}$---called the \\emph{characteristic assertion}~\\cite{winskel} of state $\\pstate$---that captures the values assigned to variables by state $\\pstate$:\\footnote{Recall from our remark on simplification that $\\Vars$ is finite.}\n\\begin{align*}\n  \\statepred{\\pstate}{} \\eeq \\iverson{\\bigwedge_{x \\in \\Vars} x = \\pstate(x)}~.\n\\end{align*}\n%\nBy Kozen duality (\\Cref{thm:kozen-duality}), \nthe probability of reaching state $\\pstate_{i+1}$ from $\\pstate_{i}$ in one guarded loop iteration~$\\cc_{\\textrm{iter}}$ is then given by\n%\n\\begin{align*}\n  \\mu_{\\cciter}^{\\pstate_i}(\\pstate_{i+1})\n  \\eeq  \n  \\wp{\\cciter}{\\eval{\\statepred{\\pstate_{i+1}}{}}}(\\pstate_i)~.\n  %\\eeq\n  %\\wp{\\ITE{\\BB}{\\cc'}{\\SKIP}}{\\eval{\\statepred{\\pstate_{i+1}}{}}}(\\pstate_i)~.\n\\end{align*}\nBy the same reasoning as for conditional choices in Lemma~\\ref{thm:expressive-loop-free}\nand the induction hypothesis (\\ref{eq:loops:ih}), \nthere exists a syntactic expectation $\\FG_{\\cciter}^{\\pstate_{i+1}} \\in \\SyntE$ such that\n\\begin{align*}\n  \\mu_{\\cciter}^{\\pstate_i}(\\pstate_{i+1}) \n  \\eeq\n  \\wp{\\cciter}{\\eval{\\statepred{\\pstate_{i+1}}{}}}(\\pstate_i)\n  \\eeq\n   \\eval{\\FG_{\\cciter}^{\\pstate_{i+1}}}(\\pstate_{i})~.\n\\end{align*}\n%\nPlugging the above equality into our \\enquote{small-step} characterization of loops (\\ref{eq:loops:small-step}) \nthen yields the following characterization of $\\eval{g}$ in ($\\dagger$):\n\\begin{align}\n    \\wp{\\,\\WHILEDO{\\BB}{\\cc'}}{\\eval{\\FF}} \\eeq \n    \\lambda \\pstate_0\\mydot \n    ~\n    \\underbrace{\\sup_{k \\in \\Nats}\n    ~\n    \\underbrace{\\sum_{\\sigma_0, \\ldots, \\sigma_{k-1} \\in \\States}\n    ~\n    \\underbrace{\n    \\Bigl\\llbracket\\,\n    \t\\underbrace{\n\t\t\\iverson{\\neg \\BB} \\cdot \\FF\\!\n    \t}_{\\in \\SyntE}\n     \\;\\Bigr\\rrbracket(\\pstate_{k-1})\n        ~\\cdot~ \\underbrace{\\prod_{i = 0}^{k-2}\n    ~\n    \\Bigl\\llbracket~\n    \\underbrace{\n            \\FG_{\\cciter}^{\\pstate_{i+1}}}_{{}\\in \\SyntE}\n    ~\\Bigr\\rrbracket(\\pstate_{i})\n    }_{\\mathclap{\\textrm{non-constant product expressible in $\\SyntE$?}}}\n    }_{\\textrm{simple product expressible in $\\SyntE$?}}\n    }_{\\textrm{non-constant sum over paths of length $k$ expressible in $\\SyntE$? }}\n    }_{\\Sup k\\colon \\ldots\\, {}\\in \\SyntE}\n    \\label{eq:loops:main}\n\\end{align}\n%\nA formal proof of the above characterization is provided alongside \\Cref{thm:wp_loop_as_sum}.\n%\n\\subsection{Encoding Loops as Syntactic Expectations}\n%\nLet us now revisit the individual components of the expectation (\\ref{eq:loops:main}) above \nand discuss how to encode them as\nsyntactic expectations in $\\SyntE$, moving through the braces from bottom to top:\n\n\\subsubsection{The supremum $\\sup_{k \\in \\Nats}$}\n\\label{sec:outline:supremum}\nThe supremum ensures that terminating execution paths \\emph{of arbitrary length} are accounted for; it is supported in $\\SyntE$\nby the $\\Sup$ quantifier.\nIf we already know a syntactic expectation~$\\FG_{\\textrm{sum}}(k) \\in \\SyntE$ for the entire sum that follows, we hence obtain\nan encoding \n%$\\FG \\in \\SyntE$ \nof the whole expectation, namely%\n%\n\\begin{align*}\n\t\\Sup k\\colon \\FG_{\\textrm{sum}}(k) ~{}\\in{}~\\SyntE~.\n\\end{align*}%\n%\n\n\\subsubsection{The non-constant sum $\\sum_{\\sigma_0, \\ldots, \\sigma_{k-1} \\in \\States}$}\n\\label{sec:outline:sum}\nThis sum \\emph{cannot} directly be written as a syntactic expectation: % for two reasons:\nFirst, it sums over \\emph{execution paths} whereas all variables and constants in syntactic expectations are evaluated to rational numbers.\nSecond, its number of summands depends on the length $k$ of execution paths whereas $\\SyntE$ only supports sums with a constant number of summands.\n\nTo deal with the first issue, there is a standard solution in proofs of expressiveness~(cf.~\\cite{Loeckx87,winskel,expressiveness_sl,expressiveness_sl_conference}): We employ \\emph{G\\\"odelization} to encode both program states and finite sequences of program states as natural numbers in syntactic expectations. \nThe details are found in \\Cref{sec:embedding}. In particular:\n\\begin{itemize}\n  \\item We show that $\\SyntE$ subsumes first-order arithmetic over the natural numbers.\n  \\item We adapt the approach of \\citet{goedel_beta} to encode sequences of both natural numbers and non-negative rationals as G\\\"odel numbers in our language $\\SyntE$.\n  \\item We define a predicate (in $\\SyntE$) \\stateseq{}{u}{\\VV} that\n        is satisfied iff $u$ is the G\\\"odel number of a sequence of states of length $\\VV-1$.\n\\end{itemize}\n%\n\\noindent\nTo deal with the second issue (the sum having a variable number of summands), we also rely on the ability to encode sequences as G\\\"odel numbers in $\\SyntE$---the details are found in Section~\\ref{sec:sums_prod_via_goedel}. Roughly speaking, we encode the sum as follows:\n%\n\\begin{itemize}\n  \\item We define a syntactic expectation $\\FH(\\vsum)$ that serves as a map from $\\vsum$ to individual summands, i.e.,\n          $\\FH\\subst{\\vsum}{i}$ yields the $i$-th summand.\n  \\item We construct a syntactic expectation $\\gsum{\\FH}{\\VV}$ for partial sums, summing up the first $\\VV$ summands defined by the syntactic expectation $\\FH$---see \\Cref{thm:sum_exp} for details.\n%More formally, we will show in Theorem~\\ref{thm:sum_exp} that\n%\\[ \n%    \\forall \\pstate \\in \\States ~\n%    \\forall \\FH \\in \\SyntE\\colon \\qquad\n%    \\sem{\\gsum{\\FH}{\\VV}}{\\sigma}{\\interpret} \\eeq \\sum_{i=0}^{\\pstate(\\VV)} \\sem{\\FH\\subst{\\vsum}{i}}{\\sigma}{}~. \n%\\]\n\\end{itemize}\n%\n\\subsubsection{The product $\\eval{\\iverson{\\neg \\BB} \\cdot \\FF} \\cdot \\ldots$}\n\\label{sec:outline:binary-product}\nThis product is not directly expressible in $\\SyntE$ as arbitrary products between syntactic expectations are not allowed.\nThey are, however, expressible in our language. \nWe define a product operation $\\FH_1 \\exprod \\FH_2$ and prove its correctness in \n\\Cref{cor:unrestricted_product}.\n\n\\subsubsection{The non-constant product $\\prod_{i = 0}^{k-2} \\eval{\\FG_{\\cciter}^{\\pstate_{i+1}}}(\\pstate_{i})$}\n\\label{sec:outline:product}\nThis product consists of $k-1$ factors; its encoding requires a similar approach as for non-constant sums.\nThat is, we define a syntactic expectation $\\gproduct{\\FH}{\\VV}$ that multiplies the first $\\VV$\n\\emph{factors} defined by the syntactic expectation $\\FH(\\vprod)$. Details are provided in Theorem~\\ref{thm:prod_exp}.\n%More formally, we will show in\n%Theorem~\\ref{thm:prod_exp}, \\Cref{sec:prod_via_goedel}, that\n%\\begin{align*}\n%    \\forall \\pstate \\in \\States ~\n%    \\forall \\FH \\in \\SyntE\\colon \\qquad\n%    \\sem{\\gproduct{\\FH}{\\VV}}{\\sigma}{}\n%    \\eeq \n%    \\prod_{j=0}^{\\pstate(\\VV)} \\sem{\\FH\\subst{\\vprod}{j}}{\\pstate}{}~.\n%\\end{align*}\n%\n%\n\\subsubsection{The expectations $\\eval{\\iverson{\\neg \\BB} \\cdot \\FF}$ and $\\eval{\\FG_{\\cciter}^{\\pstate_{i+1}}}$}\nBoth are syntactic expectations by construction.\n\n\\subsection{The Expressiveness Proof}\n%\nIt remains to glue together the constructions for the individual components of the expectation (\\ref{eq:loops:main}), \nwhich characterizes the weakest preexpectation of loops.\nWe present the full construction, a proof of its correctness, and an example of the resulting syntactic expectation in \\Cref{sec:expressiveness}.\n%\n\n\n \n\n%\\input{multiplication}\n\n% !TEX root = ./main.tex\n\n\\section{G\\\"odelization for Syntactic Expectations}\n\\label{sec:embedding}\n\n\n% !TEX root = ./main.tex\n\n\n\\begin{figure}[t]\n\t\\begin{minipage}{.5\\textwidth}\n\t\t\\centering\n\t\\renewcommand{\\arraystretch}{1.5}\n\t\\begin{tabular}{@{\\hspace{1em}}l@{\\hspace{2em}}l}\n\t\t\\hline\\hline\n\t\t$P$\t\t\t& $\\toFOPosRats{P}$ \\\\\n\t\t\\hline\n\t\t$\\BB$\t\t\t\t\t&  \n        $\\BB \\wedge \\isNat(x_1) \\wedge \\ldots \\wedge \\isNat(x_n)$  \\\\\n\t\t%\n\t\t$\\exists x \\colon \\PP' $\t\t\t& $\\exists x \\colon \\toFOPosRats{\\PP'} $ \\\\\n\t\t%\n\t\t$\\forall x \\colon \\PP' $\t\t& $\\forall x \\colon \\isNat(x) \\longrightarrow \\toFOPosRats{\\PP'} $ \\\\\n\t\t%\n\t\t\\hline\\hline\n\t\\end{tabular}\n    \\captionof{figure}{Rules defining the formula formula $\\toFOPosRats{\\PP} \\in \\FOArithPosRats$ for a Boolean expression $\\BB$ and $\\FV{\\PP} = \\{x_1,\\ldots,x_n\\}$. }\n\t\\label{table:fonat_to_foposrat}\n\\end{minipage}\n%\n\\qquad\n%\n\\begin{minipage}{.39\\textwidth}\n\t\\centering\n\t\\renewcommand{\\arraystretch}{1.5}\n\t\\begin{tabular}{@{\\hspace{1em}}l@{\\hspace{2em}}l}\n\t\t\\hline\\hline\n\t\t$P$\t\t\t& $\\iverson{P}$ \\\\\n\t\t\\hline\n\t\t$\\BB$\t\t\t\t\t&  \n\t\t$\\iverson{\\BB}$ \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\\\n\t\t%\n\t\t$\\exists \\VV \\colon \\PP' $\t\t\t& $\\Sup \\VV \\colon \\iverson{\\PP'} $ \\\\\n\t\t%\n\t\t$\\forall \\VV \\colon \\PP' $\t\t& $\\Inf \\VV \\colon  \\iverson{\\PP'} $ \\\\\n\t\t%\n\t\t\\hline\\hline\n\t\\end{tabular}\n\t\\captionof{figure}{ Rules for transforming a formula $P \\in \\FOArithPosRats$ into an expectation $\\iverson{\\PP} \\in \\SyntE$.}\n\t\\label{table:foposrat_to_synte}\n\t\\end{minipage}\n\\end{figure}\n\n \nWe embed the (standard model of) first-order arithmetic over both the rational and the natural numbers\nin our language $\\SyntE$---thereby addressing the first issue raised in \\Cref{sec:outline:supremum}. % of the proof outline.\n%\nConsequently, $\\SyntE$ conservatively extends the standard assertion language of Floyd-Hoare logic (cf.\\ \\cite{winskel, loeckx1984foundations, Cook1978SoundnessAC}), enabling us to encode finite sequences of both rationals and naturals in $\\SyntE$\nby means of G\\\"odelization~\\cite{goedel_beta}.\n\nRecall from \\autoref{tab:metavariables} that we use, \\eg metavariables $\\BBa$, $\\BBb$ for Boolean expressions, $\\pstate$ for program states, and so on and we will omit providing the types in order to unclutter the presentation.\n%\n\\subsection{Embedding First-Order Arithmetic in $\\boldsymbol{\\SyntE}$}\nWe denote by $\\FOArithPosRats$ the set of formulas $\\PP$ in \\emph{first-order arithmetic} over $\\PosRats$, \\ie the extension of Boolean expressions $\\BB$\n(see \\Cref{sec:syntax:bool}) by an existential quantifier $\\exists x\\colon \\PP$ and a universal quantifier $\\forall x\\colon P$ with the usual semantics, \\eg\n$\\sem{\\forall x\\colon \\PP}{\\pstate}{} = \\true$ \niff for all $r \\in \\PosRats$, \n$\\sem{\\PP}{\\pstate\\statesubst{x}{r}}{} = \\true$.\nThe set $\\FOArithNats$ of formulas $\\PP$ in first-order arithmetic over $\\Nats$ is defined analogously by\nrestricting ourselves to\n(1) states\\footnote{Program states serve here the role of \\emph{interpretations} in classical first-order logic.} $\\pstate\\colon \\Vars \\to \\Nats$\nand (2) constants in $\\Nats$ rather than $\\PosRats$.\n%\n\n%\nFor simplicity, \\emph{we assume without loss of generality that all formulas $\\PP$ are in prenex normalform}, \\ie $\\PP$ is a Boolean expression comprising of a block of quantifiers followed by a quantifier-free formula.\n%\n%\\begin{definition}[First-order arithmetic]\n%    The set $\\FOArithPosRats$ of formulas $\\PP$ in \\emph{first-order arithmetic} over the non-negative rationals $\\PosRats$ is given by the grammar\n%\t\\begin{align*}\n%\t\\PP \\qqlongrightarrow \t\n%\t&\\BB\t\\quad \\qmid \\quad \\exists x\\colon \\PP~ \\quad \\qmid \\quad \\forall x\\colon \\PP~,\n%\t\\end{align*}\n%    where $\\BB$ is a Boolean expression.\n%    For every state $\\pstate$, we extend the semantics $\\sem{\\BB}{\\pstate}{}$ of Boolean expressions (see \\Cref{sec:syntax:bool})\n%    to formulas $\\PP$ in $\\FOArithPosRats$ in the usual fashion:\n%    \\begin{align*}\n%        \\sem{\\exists x\\colon \\PP}{\\pstate}{} \\eeq &\n%        \\begin{cases}\n%            \\true, \n%            & \\text{if, for some } r \\in \\PosRats, \\sem{\\PP}{\\pstate\\statesubst{x}{r}}{} = \\true \\\\\n%            \\false, \n%            & \\text{else}\n%        \\end{cases}\n%        \\\\\n%        \\sem{\\forall x\\colon \\PP}{\\pstate}{} \\eeq &\n%        \\begin{cases}\n%            \\true, \n%            & \\text{if, for all} r \\in \\PosRats, \\sem{\\PP}{\\pstate\\statesubst{x}{r}}{} = \\true \\\\\n%            \\false, \n%            & \\text{else}\n%        \\end{cases}\n%    \\end{align*}\n%\\end{definition}\n%\nRecall that program states originally evaluate variables to \\emph{rationals}.\nSince our expressiveness proof requires encoding sequences of \\emph{naturals}, \nit is crucial that we can assert that a variable evaluates to a natural.\nTo this end, we adapt a result by \\citet{robinson_define_z}:\n%\n%Two formulas $\\PP, \\PP'$ are \\emph{equivalent}, denoted $\\PP \\equiv \\PP' \\in \\FOArithPosRats \\cup \\FOArithNats$, if their truth values coincide for all program states $\\sigma$ and all suitable interpretations $\\interpret$, i.e.\n%%\n%\\[\n%\t\\text{for all $\\sigma$ and all suitable}~\\interpret~ \\colon  \\PP \\equiv \\PP' \\qquad \\text{iff} \\qquad \\sem{\\PP}{\\sigma}{\\interpret} = \\sem{\\PP'}{\\sigma}{\\interpret}~.\n%\\]\n%\n%\n%\n\\begin{lemma}\\label{lem:nats_definable}\n\t$\\Nats$ is definable in $\\FOArithPosRats$, i.e.~there exists a formula\n\t$\\isNat(x) \\in \\FOArithPosRats$, such that for all $\\sigma$,\n\t%\n\t\\begin{align*}\n        \t\\sem{\\isNat(x)}{\\pstate}{} \\eeq \\true \\qqiff \\pstate(x) \\iin \\Nats~.\n\t\\end{align*}%\n\\end{lemma}%\n%\n%\\begin{proof}\n%%\tWe adapt a result by Robinson~\\cite{robinson_define_z}. \n%See Appendix~\\ref{proof:nats_definable} for details.\n%\\end{proof}\n%\n\\noindent\nWe use the above assertion $\\isNat$ to first embed $\\FOArithNats$ in $\\FOArithPosRats$.\nThereafter, we embed $\\FOArithPosRats$ in \n$\\SyntE$.\nEmbedding a formula $\\PP \\in \\FOArithNats$ in $\\FOArithPosRats$ amounts to\n(1) asserting $\\isNat(x)$ for every $x \\in \\FV{\\PP}$ and (2) guarding every quantified variable $x$ in $\\PP$ with $\\isNat(x)$, \\ie whenever we attempt to evaluate the embedding-formula for non-naturals, we default to $\\false$---see~\\Cref{table:fonat_to_foposrat} for a formal definition.\n%\n\\begin{theorem}\\label{thm:fo_rats_subsumes_fo_nats}\n    Let $\\toFOPosRats{\\PP} \\in \\FOArithNats$ be the embedding of \n    $\\PP \\in \\FOArithNats$ as defined in \\textnormal{\\Cref{table:fonat_to_foposrat}}.\n    Then, for all $\\pstate$,\n\t%\n\t\\begin{align*}\n\t%\n    \\sem{\\toFOPosRats{P}}{\\sigma}{}\n\t%\n\t\\eeq\n\t%\n\t\\begin{cases}\n\t%\n    \\sem{\\PP}{\\pstate}{}, & \\textnormal{if } \\pstate(x) \\in \\Nats \\textnormal{ for all } x \\in \\FV{\\PP}, \\\\\n    %\n    \\false, & \\textnormal{otherwise}~.\n\t\\end{cases}\n\t\\end{align*}\n\t%\n%\t\\sem{\\toFOPosRats{P}}{\\sigma}{\\interpret}\n%\t%\n%\t \\eeq\n%\t %\n%\t\\begin{cases}\n%\t%\n%\t\\false, & \\text{if there is}~\\VV \\in \\FV{\\PP} ~\\text{with}~\\interpret(\\VV) \\not \\in \\Nats  \\\\\n%\t%\n%\t\\sem{\\PP}{\\sigma}{\\interpret}, & \\text{otherwise}~.\n%\t\\end{cases}\n%\t\\end{align*}\n\\end{theorem}\n%\n%\n%\n%\\begin{proof}\n%\tSee Appendix~\\ref{proof:fo_rats_subsumes_fo_nats}.\n%\\end{proof}\n%\n%\n\\noindent{}%\nEmbedding a formula $\\PP \\in \\FOArithPosRats$ into $\\SyntE$ amounts to (1) taking its Iverson bracket for every Boolean\nexpression and (2) substituting the quantifiers $\\exists/\\forall$ by their quantitative analogs  $\\Sup/\\Inf$, see \\Cref{table:foposrat_to_synte}.\n%\n\\begin{theorem}\\label{thm:exp_subsumes_fo_rats}\n    Let $\\iverson{\\PP} \\in \\SyntE$ be the embedding of $\\PP \\in \\FOArithPosRats$ \n    as defined in \\textnormal{\\Cref{table:foposrat_to_synte}}.\n    Then, for all $\\pstate$,\n%\tDefine the expectation $\\iverson{\\PP}$ inductively as follows:\n%\t%\n%\t\\begin{align*}\n%\t&\\text{If} ~ \\PP \\eeq \\BB ~\\text{, then}& \\iverson{\\PP} &\\ddefeq \\iverson{\\BB} \\\\\n%\t%\n%\t&\\text{If} ~ \\PP \\eeq \\left( \\exists \\VV \\colon \\PP' \\right) ~\\text{, then}&\\iverson{\\PP} & \\ddefeq \\SupV{\\VV} \\iverson{\\PP'} \\\\\n%\t%\n%\t&\\text{If} ~ \\PP \\eeq \\left( \\forall \\VV \\colon \\PP' \\right) ~\\text{, then}& \\iverson{\\PP} & \\ddefeq\\InfV{\\VV}  \\iverson{\\PP'}\n%\t\\end{align*}\n\t%\n\t%\n\t\\begin{align*}\n\t\\sem{\\iverson{\\PP}}{\\sigma}{} \\eeq \n\t%\n\t\\begin{cases}\n\t%\n\t1, &\\text{if}~ \\sem{\\PP}{\\sigma}{} = \\true \\\\\n\t%\n\t0, & \\text{if}~ \\sem{\\PP}{\\sigma}{} = \\false~.\n\t\\end{cases}\n\t\\end{align*}\n\\end{theorem}\n%\n%\\begin{proof}\n%\tSee Appendix~\\ref{proof:exp_subsumes_fo_rats}.\n%\\end{proof}\n%\n%\\begin{definition}\n%\tWe say that a formula $P\\in \\FOArithPosRats$ is \\emph{definable} in $\\SyntE$, if there is an\n%\t$f \\in \\SyntE$ with $\\FV{f} = \\FV{P}$ such that for all states $\\sigma \\in \\States$ and all interpretations $\\interpret \\colon \\LVars \\to \\PosRats$,\n%\t%a\n%\t\\begin{align*}\n%\t\t\t\\sem{f}{\\sigma}{\\interpret} \\eeq \n%\t\t\t%\n%\t\t\t\\begin{cases}\n%\t\t\t    %\n%\t\t\t\t1, &\\text{if}~ \\interpret \\models P \\\\\n%\t\t\t\t%\n%\t\t\t\t0, & \\text{if}~ \\interpret \\not\\models P~.\n%\t\t\t\\end{cases}\n%\t\\end{align*}\n%\t%\n%\tMoreover, we say that $\\SyntE$ \\emph{subsumes} $\\FOArith{\\Universe}$, if every $P \\in \\FOArith{\\Universe}$ is definable in $\\SyntE$.\t\n%%\\cmcommentinline{So for $\\interpret(\\VV) \\not\\in \\Universe$ we don't care about the value? This probably won't work as the supremum in the proof %below than might actually lead to something larger than one? E.g. $\\Universe = \\{1\\}$ and $\\FF = \\iverson{\\VV = 1} \\cdot 1 + \\iverson{\\VV \\neq 1} %\\cdot 2$. Then $\\sem{\\SupV{v} \\FF}{\\pstate}{\\interpret} = 2 > 1$. Perhaps we can just map to $0$ if a value is not in $\\Universe$?}\n%\\end{definition}\n%\n%\\begin{theorem}\\label{thm:exp_subsumes_fo_rats}\n%\t%\n%\tOur language of expectations $\\SyntE$ subsumes $\\FOArithPosRats$.\n%\t%\n%\\end{theorem}\n%%\n%\\begin{proof}\n%\tBy induction on the structure of $P \\in \\FOArithPosRats$. For the base base, i.e.\\ $P = b$ for some Boolean expression $b$, this is immediate by choosing\n%    $f = \\iverson{b}$\\cmcomment{Due to the issue with the grammar, there is at least  one case missing here.}\n%    As the induction hypothesis now assume that for some arbitrary, but fixed, $P' \\in \\FOArithPosRats$ is definable in $\\SyntE$ by $\\FF'$. \n%    \n%    For the case $P = \\exists \\VV \\colon P'$, choose $\\FF = \\SupV{\\VV} P'$. Since $P$ does not contain program variables, \\FF does not contain program variables. Hence, for all states $\\pstate \\in  \\States$ and all interpretations $\\interpret$, we have:\n%\t%\n%\t\\begin{enumerate}\n%\t\t%\n%\t\t\\item If $\\interpret \\models P$, then there is an $\\RR \\in \\PosRats$ with $\\interpret\\statesubst{\\VV}{\\RR} \\models P'$. Our induction hypothesis then yields $\\sem{\\FF'}{\\pstate}{\\interpret\\statesubst{\\VV}{\\RR}} = 1$ and $\\FF' \\preceq 1$.\n%              It follows that $1 \\geq \\sem{\\SupV{\\VV} \\FF'}{\\sigma}{\\interpret} \\geq \\sem{\\FF'}{\\pstate}{\\interpret\\statesubst{\\VV}{\\RR}} = 1$. \n%              Hence, $\\sem{\\SupV{\\VV} \\FF'}{\\sigma}{\\interpret} = 1$.\n%\t\t%\n%\t\t%\n%\t\t\\item If $\\interpret \\not\\models P$, then there is no $\\RR \\in \\PosRats$ with $\\interpret\\statesubst{\\VV}{\\RR} \\models P'$. Our induction hypothesis then yields $\\FF' \\equiv 0$.\n%\t\tIt follows that \n%        $\\sem{\\SupV{\\VV} \\FF'}{\\sigma}{\\interpret} = \\sem{\\SupV{\\VV} 0}{\\sigma}{\\interpret} = 0$.\n%\t\\end{enumerate}\n%\n%\tFor the case $P = \\forall \\VV \\colon P'$, choose $\\FF $\n%\\end{proof}\n%\n%\n%\n%\\subsection{Embedding of First order Arithmetic over Naturlas}\n%In order to show that $\\SyntE$ subsumes $\\FOArithNats$, it suffices to show that $\\FOArithPosRats$ subsumes $\\FOArithNats$, i.e., every formula definable in $\\FOArithNats$ is also definable in $\\FOArithPosRats$.  This relies on the fact below.\n%%\n%%\n%\n%%\n%%\n%%\n%\n%%\n%\\begin{theorem}\\label{thm:fo_rats_subsumes_fo_nats}\n%\tLet $P \\in \\FOArithNats$ and let $V = \\{v_1, \\ldots, v_n\\} = \\FV{P}$ be the set of free variables occurring in $P$. Moreover, let $N(V) = N(v_1) \\wedge  \\ldots \\wedge  N(v_n)$. Then there is a formula $\\toFOPosRats{P} \\in \\FOArithPosRats$ equivalent to $P$\n%\tdefined by inductively by:\n%    \\cmcommentinline{Apart from the missing additional case, this looks fine}\n%\t%\n%\t%\n%\t\\begin{align*}\n%\t\t &\\text{If} ~ P \\eeq b ~\\text{, then}& \\toFOPosRats{P} &\\eeq P \\wedge N(V) \\\\\n%\t\t %\n%\t\t &\\text{If} ~ P \\eeq \\left( \\exists v \\colon P' \\right) ~\\text{, then}&\\toFOPosRats{P} & \\eeq \\exists v \\colon \\left( \\toFOPosRats{P'} \\wedge N(v) \\right)\n%\t\\end{align*}\n%\t%\n%\\end{theorem}\n%%\n%%\n%%\n%\\begin{proof}\n%\tBy induction on the structure of $P$ and by using Lemma~\\ref{lem:nats_definable}. For the base case $P=b$, consider the following:. Let $\\interpret \\colon \\LVars \\to \\Nats$ and assume $\\interpret \\models P$.\n%\tSince $\\interpret(v) \\in \\Nats$ for all $v \\in \\LVars$, \n%\twe have $\\interpret(v) \\models N(v)$ for all $v \\in \\LVars$ (Lemma~\\ref{lem:nats_definable}). Hence, $\\interpret \\models P \\wedge N(V)$ \n%\tand obviously $P \\wedge N(V) \\in \\FOArithPosRats$.\n%\t\n%\tNow let $\\interpret \\colon \\LVars \\to \\PosRats$\n%\tand assume $\\interpret \\models  P \\wedge N(V)$.\n%\tLemma~\\ref{lem:nats_definable} implies that $\\interpret(v) \\in \\Nats$ for all\n%\t$v \\in \\FV{P}$. We can thus construct an interpretation $\\interpret' \\colon \\LVars \\to \\Nats$ by\n%\t\\[\n%\t\t\\interpret'(v) \\eeq \n%\t\t\\begin{cases}\n%\t\t\t\\interpret(v), & \\text{if}~v\\in \\FV{P} \\\\\n%\t\t\t0, & \\text{otherwise}~.\n%\t\t\\end{cases}\n%\t\\]\n%\t%\n%\tSince $\\interpret \\models P$, we also have $\\interpret' \\models P$ as the truth value of $P$ depends on the interpretation of the free variables of $P$ only. Furthermore, we obviously have $P \\in \\FOArithNats$.\n%\t\n%\tAs the induction hypothesis now assume that the theorem holds for some arbitrary, but fixed $P' \\in \\FOArithNats$.\n%\t\n%\tFor the case $P = \\left( \\exists v \\colon P' \\right)$, consider the following: Let $\\interpret \\colon \\LVars \\to \\Nats$ and assume $\\interpret \\models P$.\n%\tHence, there is an $n \\in \\Nats$ with $\\interpret\\statesubst{v}{n} \\models P'$. Lemma~\\ref{lem:nats_definable} implies that $\\interpret\\statesubst{v}{n} \\models N(v)$.\n%\tOur induction hypothesis further implies $\\interpret\\statesubst{v}{n} \\models \\toFOPosRats{P'}$. Overall, we get $\\interpret\\statesubst{v}{n} \\models \\toFOPosRats{P'} \\wedge N(v)$ and thus $\\interpret \\models \\exists v \\colon\\toFOPosRats{P'} \\wedge N(v)$.\n%\t\n%\tNow let $\\interpret \\colon \\LVars \\to \\PosRats$. This case is analagous to the base case, i.e.\\ we again construct an interpretation $\\interpret' \\colon \\LVars \\to \\Nats$ with $\\interpret' \\models P$.\n%\\end{proof}\n%%\n%%\n%%\n%\\begin{theorem}\\label{thm:exp_subsumes_fo_nats}\n%\tOur language of expectations $\\SyntE$ subsumes $\\FOArithNats$.\n%\\end{theorem}\n%%\n%\\begin{proof}\n%\tFollows immediately from Theorem~\\ref{thm:exp_subsumes_fo_rats} and Theorem~\\ref{thm:fo_rats_subsumes_fo_nats}.\n%\\end{proof}\n%\n%\n\\noindent{}%\nGiven $\\PP(\\VV_1, \\ldots, \\VV_n) \\in \\FOArithPosRats$, we often write $\\toExp{\\PP(\\VV_1, \\ldots, \\VV_n)}$ instead of\n$\\toExp{\\PP}(\\VV_1, \\ldots, \\VV_n)$.\n%\n%\n\\subsection{Encoding Sequences of Natural Numbers}\n%\nThe embedding of $\\FOArithNats$ in our language $\\SyntE$ of syntactic expectations\ngives us access to a classical result by \\citet{goedel_beta} for encoding finite sequences of naturals in a \\emph{single} natural.\n%\n\\begin{lemma}[\\textnormal{\\citet{goedel_beta}}]\\label{lem:goedel_beta}\n\tThere is a formula $\\seqelem{\\VV_1}{\\VV_2}{\\VV_3} \\in \\FOArithNats$ (with quantifiers) satisfying:\n    For every finite sequence of natural numbers $n_0,\\ldots, n_{k-1}$, there is a (G\\\"odel) number $\\gnum \\in \\Nats$ \n    that encodes it, \\ie\n\tfor all $i \\in \\{0,\\ldots, k-1 \\}$ and all $m \\in \\Nats$, it holds that\n\t%\n\t\\[\n\t   \\seqelem{\\gnum}{i}{m} \\eequiv \\true \\qqiff \\quad m \\eeq n_i~.\n\t\\]\n\\end{lemma}\n%\n%\\begin{example}\n%We define a factorial predicate $\\facpred{\\VV_1}{\\VV_2} \\in \\FOArithNats$ that evaluates to $\\true$ on interpretation $\\interpret$ if and only if $\\interpret(\\VV_2) = \\interpret(\\VV_1)!$. For that, we make use of the well-known inductive definition of the factorial: For all $n \\in \\Nats$, we have\n%%\n%\\begin{align*}\n%   0! \\eeq 1 \\qquad \\text{and} \\qquad \n%   %\n%   (n+1)! \\eeq  (n+1) \\cdot n!~.\n%\\end{align*}\n%%\n%Now consider the formula $\\facpred{\\VV_1}{\\VV_2}$ given by\n%%\n%\\begin{align*}\n%   \\facpred{\\VV_1}{\\VV_2} \\eeq& \\exists \\gnum \\colon \\seqelem{\\gnum}{0}{1} \\wedge \\seqelem{\\gnum}{\\VV_1}{\\VV_2}  \\\\\n%   %\n%   & \\qquad \\wedge \\big( \\forall \\VU \\colon \\forall \\VW \\colon \n%           (\\VU < \\VV_1 \\wedge \\seqelem{\\gnum}{\\VU}{\\VW})  \\longrightarrow %\n%           \\seqelem{\\gnum}{\\VU+1}{\\VW\\cdot(\\VU+1)} \\big) ~.\n%\\end{align*}\n%%\n%%\n% The subformula right after the $\\exists \\gnum$ quantifier evaluates to $\\true$ on interpretation $\\interpret$ if and only if \n%%\n%\\begin{enumerate}\n%\t\\item $\\interpret(\\gnum)$ encodes a sequence $n_0, n_1, \\ldots$ satisfying\n%       %\n%       \\[\n%        %\n%            n_0 = 1, ~ n_1 = 1 \\cdot n_0, ~ n_2 = 2 \\cdot n_1, ~\\ldots,  ~n_{\\interpret(\\VV_1)} = \\interpret(\\VV_1) \\cdot n_{\\interpret(\\VV_1) -1}~, \\text{and}\n%        %\n%       \\]\n%       %\n%       \\item $\\interpret(\\VV_2)  = n_{\\interpret(\\VV_1)} = \\interpret(\\VV_1)!$.\n%\\end{enumerate}\n%%\n%Such a sequence exists  iff $\\interpret(\\VV_2)  = \\interpret(\\VV_1)!$.\n%Hence,  $\\sem{\\facpred{\\VV_1}{\\VV_2}}{}{\\interpret} = \\true$ iff $\\interpret(\\VV_2) = \\interpret(\\VV_1)!$.\n%\\end{example}\n%%\n%%\n\\noindent\nBy Theorem~\\ref{thm:exp_subsumes_fo_rats}, we also have an expectation $\\iverson{\\seqelem{\\VV_1}{\\VV_2}{\\VV_3}}$ expressing $\\seqelemsymbol$ in $\\SyntE$.\n%\n%\n\\begin{example}[Factorials via G\u00f6del]\n%\nThe syntactic expectation below evaluates to the factorial $x!$:\n%\n\\begin{align*}\n   \\facexp{x} \\eeq& \\Sup \\VV \\colon \\Sup \\gnum \\colon \\VV \\cdot \n   %\n   \\big[ \\seqelem{\\gnum}{0}{1} \\wedge \\seqelem{\\gnum}{x}{\\VV}  \\\\\n   %\n   &\\quad \\wedge \\forall \\VU \\colon \\forall  \\VW  \\colon \\bigl(\\VU<x \\wedge \\seqelem{\\gnum}{\\VU}{\\VW} \\longrightarrow \\seqelem{\\gnum}{\\VU+1}{\\VW\\cdot(\\VU+1)}  \\bigr)\n    \\big]~.\n\\end{align*}\n%\nFor every state $\\pstate$, the quantifier $\\Sup \\gnum$  \nselects a sequence $n_0,n_1\\ldots$ satisfying $n_{\\sigma(x)} = \\sigma(x)!$. \nThe quantifier $\\Sup \\VV$ then binds $\\VV$ to the value $n_{\\sigma(x)} = \\sigma(x)!$. Finally, \nby multiplying the $\\{0,1\\}$-valued expectation specifying the sequence by $\\VV$, we get that $\\sem{\\facexp{x}}{\\sigma}{\\interpret} = \\sigma(x)!$.\\hfill$\\triangle$\n\\end{example}\n%\n\\noindent\nTo assign a \\emph{unique} G\\\"odel number $\\gnum$ to a sequence $n_0,\\ldots,n_{k-1}$ of length $k$ we employ \\emph{minimalization}, \\ie we take the least suitable G\\\"odel number. Formally, we define the formula\n%\n\\begin{align*}\n   &\\sequence{\\gnum}{\\VV} \\\\\n   %\n    &\\ddefeq\n   \\left( \\forall \\VU \\colon \\VU < \\VV \\longrightarrow \\exists \\VW \\colon \\seqelem{\\gnum}{\\VU}{\\VW} \\right) \\\\\n   %\n   &\\quad\\qquad\\wedge\\big( \\forall \\gnum' \\colon \n   \\big(  \\forall \\VU \\colon \\VU<\\VV \\longrightarrow \\exists \\VW \\colon \\seqelem{\\gnum}{\\VU}{\\VW} \\wedge \\seqelem{\\gnum'}{\\VU}{\\VW} \\big) \\\\\n   &\\quad\\qquad\\qquad \\longrightarrow \\gnum' \\geq \\gnum \\big)~.\n\\end{align*}\n%\n%A state $\\pstate$ satisfies $ \\sequence{\\gnum}{\\VV}$ iff $\\gnum$ encodes a sequence of length at least $\\pstate(\\VV)$ (first conjunct) and if $\\gnum$ is the \\emph{least} number for encoding the (sub)sequence $n_0,\\ldots,n_{\\interpret(\\VV)-1}$ (second conjunct). \nFor every $k$ and every sequence $n_0,\\ldots,n_{k-1}$ of length $k$, we then define \\emph{the} G\\\"odel number encoding the sequence $n_0,\\ldots,n_{k-1}$ as the unique natural number $\\seqnum{n_0,\\ldots,n_{k-1}}$ satisfying\n%\n%\n\\[\n    \\sequence{\\seqnum{n_0,\\ldots,n_{k-1}}}{k} ~{}\\wedge{}~ \\bigwedge\\limits_{i=0}^{k-1} \\seqelem{\\seqnum{n_0,\\ldots,n_{k-1}}}{i}{n_i}~.\n\\]\n%\n%\n%\n\\subsection{Encoding Sequences of Non-negative Rationals}\n%\nRecall that program states in $\\pgcl$ map variables to values in $\\PosRats$.\nTo encode sequences of program states, we thus\nfirst lift G\\\"odel's encoding $\\seqelem{\\gnum}{i}{n}$ to uniquely encode sequences over $\\PosRats$.\nThe main idea is to represent such a sequence by pairing two sequences over $\\Nats$.\n%\n\\begin{lemma}[Pairing Functions~\\textnormal{\\cite{cantor1878beitrag}}]\\label{lem:pairing}\n\tThere is a formula $\\gPair(\\VV_1, \\VV_2, \\VV_3) \\in \\FOArithNats$ satisfying: For every pair of natural numbers $(n_1, n_2)$, there is \\emph{exactly one} natural number $n$ such that\n\t%\n\t\\[\n\t\\gPair(n, n_1, n_2) \\eequiv \\true~.\n\t\\]\n\t%\n\\end{lemma}\n%\n%We combine $\\seqelemsymbol$ and $\\gPair$ to obtain a formula $\\gRho \\in \\FOArithPosRats$\n%for sequences of \\emph{non-negative rational numbers}.\n%\n\\begin{theorem}\n\t\\label{thm:rho_expectation}\n\tThere is a formula $\\rseqelem{\\VV_1}{\\VV_2}{\\VV_3} \\in \\FOArithPosRats$ satisfying:\n\tFor every finite sequence $\\RR_0, \\ldots, \\RR_{k-1} \\subset \\PosRats$  there is a \n\tG\\\"odel number $\\gnum$, such that for all $i \\in \\{ 0,\\ldots, k-1 \\}$ and $s \\in \\PosRats$,\n\t%\n\t\\[\n\t\\rseqelem{\\gnum}{i}{s} \\eequiv \\true \\quad \\text{iff} \\quad s \\eeq r_i~.\n\t\\]\n\\end{theorem}\n%\n%\\begin{proof}\n%\tSee Appendix~\\ref{proof:rho_expectation}.\n%\\end{proof}\n% \n%\n%\n\\begin{example}[Harmonic Numbers]\n\t\\label{ex:harmonic}\n    For every $\\pstate$ with $\\pstate(x) = k \\in \\Nats$, the expectation $\\harmexp{x} \\in \\SyntE$ below evaluates to the $k$-th \n    harmonic number $\\mathcal{H}(k) \\eeq \\sum_{i=1}^{k} \\frac{1}{i}$.\n\t%\n\t\\begin{align*}\n\t\\harmexp{x} \\eeq& \\Sup \\VV \\colon \\Sup \\gnum \\colon \\VV \\cdot \n\t%\n\t\\big[ \\rseqelem{\\gnum}{0}{0} \\wedge \\rseqelem{\\gnum}{x}{\\VV} \\\\\n\t%\n\t&\\quad \\wedge \\forall \\VU \\colon \\forall \\VW \\colon (\\VU<x \\wedge  \\rseqelem{\\gnum}{\\VU}{\\VW}) \\\\ \n\t& \\qquad \\quad \\longrightarrow \\exists \\VW' \\colon \\VW' \\cdot (\\VU+1) = 1 \\wedge \\rseqelem{\\gnum}{\\VU+1}{\\VW +\\VW'} \\big] ~\n\t\\end{align*}\n\t%\n    Notice that the above Iverson bracket evaluates to $1$ on state $\\sigma$ iff $\\sigma(\\gnum)$ encodes  a sequence $r_0,r_1,\\ldots, r_{\\sigma(x)}$ such that $\\sigma(\\VV) = r_{\\sigma(x)}$ and\n\t%\n\t\\[\n\tr_0 \\eeq 0~, ~r_1 = \\frac{1}{1} + r_0,~~ ~r_2 = \\frac{1}{2} + r_1~, ~\\ldots~, r_{\\sigma(x)} \\eeq \\frac{1}{\\sigma(x)} + r_{\\sigma(x) -1}~.\n\t\\]   \n\t%\n   By Theorem~\\ref{thm:fo_rats_subsumes_fo_nats}, we do not need to require that $\\sigma(u) \\in \\Nats$ as $\\rseqelem{\\gnum}{i}{w}$ is $\\false$ if $\\sigma(u) \\not\\in \\Nats$.\\hfill$\\triangle$\n\\end{example}\n%\n\\noindent\nAnalogously to the previous section, we define a predicate $\\rsequence{\\gnum}{\\VV}$ that uses minimalization to \na \\emph{unique} G\\\"odel number $\\gnum$ for every sequence $r_0,\\ldots,r_{k-1}$ of length $k$;\nthe only difference between $\\rsequence{\\gnum}{\\VV}$ and $\\sequence{\\gnum}{\\VV}$ is that every occurrence of\n$\\seqelem{.}{.}{.}$ is replaced by $\\rseqelem{.}{.}{.}$.\n%\n%\\begin{align*}\n%&\\rsequence{\\gnum}{\\VV} \\\\\n%%\n%\\ddefeq&\n%\\left( \\forall \\VU \\colon \\VU < \\VV \\longrightarrow \\exists \\VW \\colon \\rseqelem{\\gnum}{\\VU}{\\VW} \\right) \\\\\n%%\n%&\\wedge\\big( \\forall \\gnum' \\colon \n%\\big(  \\forall \\VU \\colon \\VU<\\VV \\longrightarrow \\exists \\VW \\colon \\rseqelem{\\gnum}{\\VU}{\\VW} \\wedge \\seqelem{\\gnum'}{\\VU}{\\VW} \\big) \\\\\n%&\\qquad \\longrightarrow \\gnum' \\geq \\gnum \\big)~.\n%\\end{align*}\n%\n%A state $\\pstate$ satisfies $ \\sequence{\\gnum}{\\VV}$ iff $\\gnum$ encodes a sequence of length at least $\\pstate(\\VV)$ (first conjunct) and if $\\gnum$ is the \\emph{least} number for encoding the (sub)sequence $n_0,\\ldots,n_{\\interpret(\\VV)-1}$ (second conjunct). \n%\nMoreover, for every $k$ and every sequence $r_0,\\ldots,r_{k-1}$, we define \\emph{the} G\\\"odel number encoding the sequence $r_0,\\ldots,r_{k-1}$ as the unique natural number $\\seqnum{r_0,\\ldots,r_{k-1}}$ satisfying\n%\n%\n\\[\n\\rsequence{\\seqnum{r_0,\\ldots,r_{k-1}}}{k} ~{}\\wedge{}~ \\bigwedge\\limits_{i=0}^{k-1} \\rseqelem{\\seqnum{r_0,\\ldots,r_{k-1}}}{i}{r_i}~.\n\\]\n%\n\\subsection{Encoding Sequences of Program States}\n\\label{sec:encoding_states}\n%\nTo encode sequences of program states, we first fix a finite set $\\varseq{x} = \\{x_0,\\ldots,x_{k-1}\\}$ of \\emph{relevant variables}.\nIntuitively, \\varseq{x} consists of all variables that appear in a given program or a postexpectation. We define an equivalence relation $\\equivstatesrel{\\varseq{x}}$ on states by \n%\n%\n\\[\n\\equivstates{\\sigma_1}{\\varseq{x}}{\\sigma_2}\n\\qquad\n\\text{iff}\n\\qquad \n\\forall x \\in \\varseq{x}\\colon \\sigma_1(x) = \\sigma_2(x)~.\n\\]\n\nEvery $\\gnum$ satisfying $\\sequence{\\gnum}{k}$ encodes \\emph{exactly one} state $\\pstate$ (modulo $\\equivstatesrel{\\varseq{x}}$).\nThe G\\\"odel number encoding~$\\sigma$ (w.r.t.\\ $\\varseq{x}$), which we denote by $\\seqnum{\\sigma}_{\\varseq{x}}$, is then the unique number satisfying\n%\n\\[\n\\rsequence{\\seqnum{\\sigma}_{\\varseq{x}}}{k} ~{}\\wedge{}~\\bigwedge\\limits_{i=0}^{k-1}\n\\rseqelem{\\seqnum{\\sigma}_{\\varseq{x}}}{i}{\\sigma(x_i)}~.\n\\]\n\\noindent\n%\nNotice that we implictly fixed an ordering of the variables in $\\varseq{x}$ to identify each value stored in~$\\pstate$\nfor a variable in $\\varseq{x}$.\n%\nThe formula\n%The fact that $\\gnum$ is the G\\\"odel number of the \\emph{current}\\blkcomment{Was hei\u00dft current state hier?} state $\\sigma$ is expressed by\n%\n\\[\n\\encodesstate{x}{\\gnum} \\ddefeq \\rsequence{num}{k} ~{}\\wedge{}~\\bigwedge\\limits_{i=0}^{k-1}\n\\rseqelem{\\gnum}{i}{x_i}\n\\]\n\\noindent\nevaluates to $\\true$ on state $\\sigma$ iff $\\sigma(\\gnum)$ is the G\\\"odel number of a state $\\sigma'$ with $\\equivstates{\\sigma}{\\varseq{x}}{\\sigma'}$.\nNow, let $\\sigma_0,\\ldots,\\sigma_{n-1}$ be a sequence of states of length $n$. \n\\emph{The} G\\\"odel number encoding $\\sigma_0,\\ldots,\\sigma_{n-1}$ (w.r.t.\\ $\\varseq{x}$), which we denote by $\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{n-1}}_{\\varseq{x}}$, is then the unique number satisfying\n%\n\\[\n\\sequence{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{n-1}}_{\\varseq{x}}}{n} ~{}\\wedge{}~\\bigwedge\\limits_{i=0}^{n-1}\n\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{n-1}}_{\\varseq{x}}}{i}{\\seqnum{\\sigma_i}_{\\varseq{x}}}~.\n\\]\n%\nWe are now in a position to encode sequences of states. \n%\nThe formula\n%\n\\begin{align*}\n%\n&\\stateseq{x}{\\gnum}{\\VV}  \\\\\n%\n\\eeq& \\sequence{\\gnum}{\\VV} \\wedge \\left( \\exists \\VV' \\colon \\seqelem{\\gnum}{0}{\\VV'} \\wedge \\encodesstate{x}{\\VV'} \\right) \\\\\n%\n&\\wedge \\forall \\VU \\colon \\forall \\VV' \\colon \\left( ( \\VU <\\VV \\wedge\\seqelem{\\gnum}{\\VU}{\\VV'} )\\longrightarrow \\rsequence{\\VV'}{k} \\right)\n%\n\\end{align*}\n%\nevaluates to $\\true$ on state $\\pstate$ iff (1) $\\gnum$ is the G\\\"odel number of some sequence $\\pstate_0,\\ldots,\\sigma_{\\pstate(\\VV-1)} \\in \\States$ of states of length $\\pstate(\\VV)$ and where (2) $\\sigma$ and $\\sigma_0$ coincide on all variables in $\\varseq{x}$, \\ie $\\equivstates{\\sigma}{\\varseq{x}}{\\sigma_0}$.\n%\nNotice that, for every sequence $\\sigma_0,\\ldots,\\sigma_{n-1}$ of states of length $n$, there is \\emph{exactly one} $\\gnum$ satisfying $\\stateseq{x}{\\gnum}{n}$.\nIf clear from the context, we often omit the subscript $\\varseq{x}$ and simply write $\\seqnum{\\sigma}$ (resp.\\ $\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{n-1}}$) instead of $\\seqnum{\\sigma}_{\\varseq{x}}$ (resp.\\ $\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{n-1}}_{\\varseq{x}}$).\n\n\n\n\n\n\n % Bibliography\n\n% !TEX root = ./main.tex\n%\n\\section{The Dedekind Normal Form}\n%\\section{Normal Forms}\n\\label{sec:normalforms}\n%\nBefore we encode sums and products of non-constant size in $\\SyntE$---as required to deal with the challenges in~\\Cref{sec:outline:sum,sec:outline:binary-product,sec:outline:product}---we introduce a normal form that gives a convenient handle to \nencode real numbers as syntactic expectations.\n\nAs a first step, we transform syntactic expectations into prenex normal form, \\ie we rewrite every $\\FF \\in \\SyntE$ into an equivalent syntactic expectation of the form %a semantically equivalent expectation of the form\n%\n%\n$\\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k  \\colon \\FF'$,\n%\n%\nwhere $\\Quant_i \\in \\{\\Sup, \\Inf\\}$ and $\\FF'$ is \\enquote{quantifier}--free, \\ie contains neither \\Sup{} nor \\Inf.\n%\n%to reduce the technical effort in the remaining proofs.\n%we introduce three (effectively constructible) normalforms for our syntactic expectations.\n%Their sole purpose is to reduce the overall technical efforts in the remaining proofs.\n%In particular, the \\emph{summation normal form} represents every syntactical expectation as a constant-size sum of guarded arithmetic expressions with a quantifier prefix.\n%In particular, the \\emph{Dedekind normal form} gives a convenient handle to encode real numbers as syntactical expectations. \n%\\cmcommentinline{Move everything but the two normal forms to the appendix}\n%\\subsection{Prenex Normal Form}\n%As discussed in \\Cref{sec:note-on-f-times-f},\n%we first transform syntactic expectations into prenex normal form, i.e., we rewrite every $\\FF \\in \\SyntE$ into an equivalent syntactic expectation of the form %a semantically equivalent expectation of the form\n%%\n%%\n%$\\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k  \\colon \\FF'$,\n%%\n%%\n%where $\\Quant_i \\in \\{\\Sup, \\Inf\\}$ and $\\FF'$ is \\enquote{quantifier}--free, i.e.\\ contains neither \\Sup{} nor \\Inf.\n%\nThe following lemma justifies that any expectation can indeed be transformed into an equivalent one in prenex normal form\nby iteratively pulling out quantifiers.\nIn case the quantified logical variable already appears in the expectation the quantifier is pulled over, we rename it by a fresh one first.\n%\n%\n\\begin{lemma}[Prenex Transformation Rules]\n\\label{thm:prenex-rules}\n For all \\FF, $\\FF_1$, $\\FF_2 \\in \\SyntE$, terms $\\TT$, and Boolean expressions $\\BB$, quantifiers $\\Quant \\in \\{\\Sup, \\Inf\\}$, and fresh logical variables $\\VV'$, the following equivalences hold:\n%\n\\begin{enumerate}\n  %\n  \\item\\label{thm:prenex-rules:plus-left} \n  $(\\Quant \\VV\\colon \\FF_1) \\pplus \\FF_2 \\phantom{aa} \\equiv \\phantom{aa} \\Quant \\VV'\\colon \\FF_1\\subst{\\VV}{\\VV'} \\pplus \\FF_2$, \n  %\n  \\item\\label{thm:prenex-rules:plus-right} \n  $\\FF_1 \\pplus (\\Quant \\VV'\\colon \\FF_2) \\phantom{a}\\, \\equiv \\phantom{aa}\\Quant \\VV'\\colon \\FF_1 \\pplus \\FF_2\\subst{\\VV}{\\VV'}$,\n  %\n  \\item\\label{thm:prenex-rules:mult-term} \n  $\\TT \\ccdot \\Quant \\VV\\colon \\FF  \\phantom{aaa}\\hspace{0.02cm} \\, \\,\\, \\, \\,\\, \\equiv \\phantom{aa} \\Quant \\VV'\\colon \\TT \\cdot \\FF\\subst{\\VV}{\\VV'}$,  and\n  %\n  \\item\\label{thm:prenex-rules:mult-guard} \n  $\\iverson{\\BB} \\ccdot \\Quant \\VV\\colon \\FF \\phantom{a}\\hspace{0.04cm}\\, \\, \\,\\,\\,\\, \\equiv \\phantom{aa}  \\Quant \\VV'\\colon \\iverson{\\BB} \\cdot \\FF\\subst{\\VV}{\\VV'}$.\n  %\n\\end{enumerate}\n%\n\\end{lemma}\n%\n%\\begin{proof}\n%\tSee Appendix~\\ref{proof:prenex-rules}.\n%\\end{proof}\n\n\n\n%Terms and Iverson brackets are by definition quantifier--free, thus trivially in prenex normal form.\n%For addition and multiplication, the rules are provided in \\autoref{tab:pnf}. \n%%\n%%\n%%\\begin{table}[b]\n%%\t\\caption{Rules for transforming composite expectations into prenex normal form.}\n%%\t\\label{tab:pnf}\n%%\t\\renewcommand{\\arraystretch}{1.5}\n%%\t\\begin{tabular}{l@{\\qquad}l@{\\qquad}l@{\\qquad}l}\t\n%%\t\t\\textbf{Expectation $\\boldsymbol{h}$} & $\\boldsymbol{\\boldsfsymbol{Prenex}(h)}$ & \\textbf{Side conditions} & \\\\\n%%\t\t\\hline\\hline\n%%\t\t%\n%%\t\t%\n%%\t\t$(\\Quant v\\colon f) \\pplus g$ & $\\Quant u: f\\subst{v}{u} + g$ & $u$ is fresh & \\gray{(add-l)} \\\\\n%%\t\t%\n%%\t\t$f \\pplus (\\Quant v\\colon g)$ & $\\Quant u: f + g\\subst{v}{u}$ & $u$ is fresh & \\gray{(add-r)} \\\\[.5em]\n%%\t\t%\n%%\t\t\\hline\\\\[-1.5em]\n%%\t\t%\n%%\t\t$(\\Quant v\\colon f) \\ccdot g$ & $\\Quant v\\colon f \\cdot g$ & $g$ is quantifier-free & \\gray{(mult-l)} \\\\\n%%\t\t%\n%%\t\t$f \\ccdot (\\Quant v\\colon g)$ & $\\Quant v\\colon f \\cdot g$ & $f$ is quantifier-free & \\gray{(mult-l)} \\\\[.5em]\n%%\t\t%\n%%\t\t$(\\Sup v\\colon f) \\ccdot (\\Sup w\\colon g)$ & $\\Sup u \\: \\Sup z\\colon f\\subst{v}{u} \\cdot g\\subst{w}{z}$ & $u$ and $z$ are fresh & \\gray{(mult-ss)} \\\\\n%%\t\t%\n%%\t\t$(\\Inf v\\colon f) \\ccdot (\\Inf w\\colon g)$ & $\\Inf u \\: \\Inf z\\colon f\\subst{v}{u} \\cdot g\\subst{w}{z}$ & $u$ and $z$ are fresh & \\gray{(mult-ii)} \\\\\n%%\t\t%\n%%\t\t$(\\blue{\\Sup v\\colon f}) \\ccdot (\\orange{\\Inf w\\colon g})$ & $\\blue{\\Sup u} \\: \\orange{\\Inf z}\\colon \\blue{f\\subst{v}{u}} \\cdot \\orange{g\\subst{w}{z}}$ & $u$ and $z$ are fresh & \\gray{(mult-si)} \\\\\n%%\t\t%\n%%\t\t$(\\orange{\\Inf v\\colon f}) \\ccdot (\\blue{\\Sup w\\colon g})$ & $\\blue{\\Sup z} \\: \\orange{\\Inf u}\\colon \\orange{f\\subst{v}{u} }\\cdot \\blue{g\\subst{w}{z}}$ & $u$ and $z$ are fresh & \\gray{(mult-is)} \\\\[.5em]\n%%\t\t\\hline\\\\[-1.5em]\n%%\t\t\\multicolumn{4}{c}{$u$ and $z$ being \\emph{fresh} means that $u$ and $z$ are freshly drawn logical}\\\\[-.6125em]\n%%\t\t\\multicolumn{4}{c}{variables from $\\LVars$ that occur neither in $f$ nor in $g$.}\\\\\n%%\t\\end{tabular}\n%%\t\\renewcommand{\\arraystretch}{1}\n%%\\end{table}%\n%%\n%%\n%For addition (rules (add-l) and (add-r)), we can just pull quantifiers one after the other out of the summands in front of the sum.\n%We merely have to rename the bound variable such that the quantified variable name does not occur in the other summand.\n%We can do the same for multiplication, if we pull out quantifiers from one factor when the \\emph{other} factor is quantifier--free (rules (mult-l) and (mult-r)).\n%If, for multiplication, both factors contain quantifiers, we can pull out the leading two quantifiers at the same time, again subject to appropriate renaming (rules (mult-ss) and (mult-ii)).\n%\n%The situation is more subtle when facing a multiplication with a leading $\\Sup$ in one factor and a leading $\\Inf$ in the other factor. \n%In this case, we always have to pull out the $\\Sup$--quantifier first and then the $\\Inf$--quantifier.\n%Intuitively, the reason is that $0 \\cdot \\infty = 0$.\n%ADD MORE EXPLANATION HERE.\n%\n%\n%\n%\n%\\subsection{Dedekind Normal Form}\n%\n%In this section we present a \\emph{Dedekind normal form} of syntactic expectations. \n\\noindent\nThe Dedekind normal form is motivated by the notion of \\emph{Dedekind cuts}~\\cite{bertrand1863traite}.\nWe denote by $\\dcut{\\alpha}$ the Dedekind cut of a real number, \\ie the set of all rationals strictly smaller than $\\alpha$. \n%\n%\\[\n%\t\\dcut{a} \\eeq \\setcomp{r \\in \\Rats}{r < a}~.\n%\\]\n%\n%\nIn the realm of \\emph{all} reals, it is required that a Dedekind cut is neither  the empty set nor the whole set of rationals $\\Rats$. \nHowever, since we operate in the realm of non-negative reals with infinity $\\PosRealsInf$, we \\emph{do} allow for both empty cuts and $\\PosRats$. More formally, we define:\n%\n\\begin{definition}\n\tLet $\\alpha \\in \\PosRealsInf$.\n\tThe \\emph{Dedekind cut} $\\dcut{\\alpha} \\subseteq \\PosRats$ of $\\alpha$ is defined as\n\t%\n\t\\[\n\t\t\\dcut{\\alpha} \\ddefeq \\setcomp{r \\in \\PosRats}{ r < \\alpha}~.\n\t\\]\n\t%\n\tFurthermore, we define $\\dcutzero{\\alpha} \\defeq \\dcut{\\alpha} \\cup \\{0\\}$.\n\\end{definition}\n%\n\\noindent\nDedekind cuts are relevant for our technical development as they allow to describe every real number $\\alpha$ as a supremum over a set of rational numbers. \nIn particular, the Dedekind cut $\\dcut{0}$ of $0$ is the empty set with supremum $0$, and the Dedekind cut $\\dcut{\\infty}$ of $\\infty$ is the set $\\PosRats$ with supremum $\\infty$.\nFormally:\n\\begin{lemma} For every $\\alpha \\in \\PosRealsInf$, we have $\\alpha = \\sup \\dcut{\\alpha}$. \n\\end{lemma}\n%\n%Since the supremum of $\\emptyset$ (resp.\\ $\\PosRats$) in the domain $\\PosRealsInf$ is $0$ (resp.\\ $\\infty$), our definition preserves the property that $a = \\sup \\dcut{a}$ for every $a \\in \\PosRealsInf$.\n%\n%\n\\begin{theorem}\n\t\\label{thm:dedekind_nf}\n\t%\n    For every $\\FF \\in \\SyntE$, there is a syntactic expectation in prenex normal form\n    \\[ \\dexp{\\FF} \\eeq  \\qprefix{\\FF} \\colon \\iverson{\\BB}~, \\]\n    where $\\qprefix{\\FF}$ is the quantifier prefix,\n    $\\BB$ is an effectively constructible Boolean expression,\n    and the free variable $\\VVcut$ is fresh; we call $\\dexp{\\FF}$ the \\emph{Dedekind normal form} of $\\FF$.\n\n    Moreover, for all program states $\\pstate$, we have\n\t\\[\n\t\t\t\\sem{\\dexp{\\FF}}{\\sigma}{\\interpret} \n\t\t\t\\eeq\n\t\t\t\\begin{cases}\n\t\t\t   1, & \\text{if}~~\\sigma(\\VVcut) < \\sem{f}{\\sigma}{\\interpret} \\\\\n\t\t\t   %\n\t\t\t   0, &\\text{otherwise}~.\n\t\t\t\\end{cases}\n\t\\]\n%\n\\end{theorem}\n%\n%\n%\\begin{proof}\n%\tSee Appendix~\\ref{proof:dedekind_nf}.\n%\\end{proof}\n%\n%\n%We call $\\VVcut$ the \\emph{cut variable} of $\\dexp{\\FF}$.\nThe Dedekind normal form $\\dexp{\\FF}$ defines the Dedekind cut of every $\\sem{\\FF}{\\sigma}{\\interpret}$, \\ie\n%\n%\n\\[\n    \\text{for all $\\sigma$}\\colon \\quad \\dcut{\\sem{\\FF}{\\sigma}{\\interpret}}\n    \\eeq \\setcomp{\\RR \\in \\PosRats}{ \\RR = \\sigma(\\VVcut), \\sem{\\dexp{\\FF}}{\\sigma}{\\interpret\\statesubst{\\VVcut}{\\RR}} = 1 }~.\n\\] \n%\nHence, we can recover $\\FF$ from $\\dexp{\\FF}$:\n%\n\\begin{lemma}\n\t\\label{lem:dedekind_nf_recover}\n\tLet $\\dexp{\\FF}$ be in Dedekind normal form. Then \n\t%\n\t\\[\n\t      \\FF \\eequiv \\Sup \\VVcut \\colon \\dexp{\\FF} \\cdot \\VVcut~. \n\t\\]\n\\end{lemma}\n%\n%\\begin{proof}\n%\tSee Appendix \\ref{proof:dedekind_nf_recover}.\n%\\end{proof}\n \n\\section{Sums, Products, and Infinite Series of Syntactic Expectations}\n\\label{sec:sums_prod_via_goedel}\n\nThis section deals with the syntactic $\\gsumsymbol$ and $\\gproductsymbol$ expectations as described in \\Cref{sec:outline:sum}. Since a syntactic expectation $\\FF$ evaluates to a non-negative \\emph{extended real}, we rely on a reduction from sums over reals to suprema of sums over \\emph{rationals}:\n\n\\begin{lemma}\n\t\\label{lem:sum_by_cut}\n\tFor all $\\alpha_0,\\ldots,\\alpha_n \\in \\PosRealsInf$, we have\n\t%\n\t\\[\n\t\\sum_{j=0}^n  \\alpha_j \n\t\\eeq\n\t\\sup \\setcomp{\\sum_{j=0}^n  r_j}{\\forall i \\in \\{0,\\ldots,n\\} \\colon  r_i \\in \\dcutzero{\\alpha_i}}\n\t\\]\n\\end{lemma}\n%\n\\begin{theorem}\n\t\\label{thm:sum_exp}\n\tFor every $\\FF \\in \\SyntE$ with free variable $\\vsum$,\n\tthere is an effectively constructible expectation \n\t$\\gsum{\\FF}{\\VV} \\in \\SyntE$ such that for all states $\\sigma$ with $\\sigma(\\VV) \\in \\Nats$, we have\n\t%\n\t\\[\n\t\\sem{\\gsum{\\FF}{\\VV}}{\\sigma}{\\interpret}\n\t\\eeq\n\t\\sum_{j=0}^{\\sigma(\\VV)} \\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{\\interpret}\n\t%\n\t~\n\t\\text{and}\n\t~\n\t\\sem{\\Sup \\VV \\colon \\gsum{\\FF}{\\VV}}{\\sigma}{\\interpret}\n\t\\eeq\n\t\\sum_{j=0}^{\\infty} \\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{\\interpret}~.\n\t\\]\n\\end{theorem}\n%\n\\begin{proof}\n\tWe sketch the construction of $\\gsum{\\FF}{\\VV}$. \n\t%\n\t%\n\t\\noindent\n\t\\Cref{lem:sum_by_cut} and the Dedekind normal form $\\dexp{\\FF}$ of $\\FF$  (cf. \\Cref{thm:dedekind_nf}) give us\n\t%\n\t%\n\t\\begin{align}\n\t&\\sum_{j=0}^{\\sigma(\\VV)}  \\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{\\interpret}\n\t\\notag\\\\\n\t%\n\t\\eeq&\n\t\\sup \\setcomp{\\sum_{j=0}^{\\sigma(\\VV)}  r_j}{\\forall j \\in \\{0,\\ldots,\\sigma(\\VV)\\} \\colon  r_j \\in \\dcutzero{\\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{\\interpret}}} \n\t\\notag\\\\\n\t%\n\t%\n\t\\eeq&\n\t\\sup \\setcomp{\\sum_{j=0}^{\\sigma(\\VV)}  r_j}{\\forall j \\in \\{0,\\ldots,\\sigma(\\VV)\\} \\colon  \\sem{\\dexpvar{\\FF}{r_j}}{\\sigma}{\\interpret}=1~\\text{or}~r_j = 0}~.\n\t%\n\t\\label{eqn:derive_sum_exp}\n\t\\end{align}\n\t%\n\t%\n\tWriting $\\dexp{\\FF} = \\qprefix{\\FF} \\colon \\iverson{\\BB}$ (cf.\\ \\Cref{thm:dedekind_nf}), \n\twe then construct a syntactic expectation $\\FG$ with free variables $\\VV$ and $\\gnum$ by\n\t%\n\t\\begin{align*}\n\t&\\Sup \\VV' \\colon \n\t\\VV' \\cdot \\Inf \\VU \\colon \\Inf z \\colon \\Sup \\VVcut \\colon \\qprefix{\\FF} \\colon \\\\\n\t%\n\t& [\n\t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV}  \\\\\n\t&  \\quad \\wedge \\big( (\\VU < \\VV+1 \\wedge \\rseqelem{\\gnum}{\\VU}{z} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{\\VU} \\vee \\VVcut = 0) ) \\\\\n\t& \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{\\VU+1}{z + \\VVcut}   \\big)]~.\n\t\\end{align*}\n\t%\n\t%\n\tFor every state $\\sigma$ where $\\sigma(\\gnum)$ is a G\\\"odel number encoding some sequence\n\t%\n\t\\begin{align*}\n\t1,~~~~ 1\\cdot r_1, ~~~~1 + r_1 + r_2, ~~~~\\ldots ~~~~, 1 +  r_1 + \\ldots +  r_{\\sigma(\\VV)}\n\t\\end{align*}\n\t%\n\twith $r_j \\in  \\dcutzero{\\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{}}$\n\tfor all $0 \\leq j \\leq \\sigma(\\VV)$, expectation $\\FG$ evaluates to the last element of the above sequence, \\ie an element of the set from Equation (\\ref{eqn:derive_sum_exp}). Hence, by \\Cref{lem:sum_by_cut}, the supremum over these sequences, i.e, all G\\\"odel numbers, gives us \n\t%\n\t%\n\t\\[\n\t\\gsum{\\FF}{\\VV} \\eeq \\Sup \\gnum \\colon \\FG~.\n\t\\]\n\t%\n\tSee Appendix \\ref{proof:sum_exp} for a detailed proof.\n\\end{proof}\n%\n%\n%\n%\n\\noindent\nFor an arithmetic expression $\\TT$, we write  $\\gsum{\\FF}{\\TT}$ instead of $\\gsum{\\FF}{\\VV}\\subst{\\VV}{\\TT}$. \n\n\\begin{example}\n\t$\\gsumsymbol$ provides us with a much more convenient way to construct $\\harmexp{x}$ from \\Cref{ex:harmonic}. Let $\\FF = \\nicefrac{1}{\\vsum}$ where $\\nicefrac{1}{\\vsum}$ is a shorthand for $\\Sup \\VW \\colon \\VW \\cdot \\iverson{\\VW \\cdot \\vsum = 1}$. Then, by \\Cref{thm:sum_exp}, we have for every $\\sigma \\in \\States$\n\t%\n\t\\begin{align*}\n\t  \\sem{\\gsum{\\FF}{x}}{\\sigma}{\\interpret} \n\t  \\eeq\n\t  \\sum_{j=0}^{\\sigma(x)} \\sem{\\FF\\subst{\\vsum}{j}}{\\sigma}{\\interpret} \n\t  \\eeq\n\t  %\n\t  \\sum_{j=1}^{\\sigma(x)} \\frac{1}{j}\n\t  %\n\t  \\eeq\n\t  \\mathcal{H}(\\sigma(x))~.\n\t\\end{align*}\n\t%\n\\end{example}\n\n\n%\n%\nThe construction of the syntactic $\\gproductsymbol$ expectation is completely analogous:\n\\begin{theorem}\n\t\\label{thm:prod_exp}\n\tFor every $\\FF \\in \\SyntE$ with free variable $\\vprod$,\n\tthere is an effectively constructible expectation \n\t$\\gproduct{\\FF}{\\VV} \\in \\SyntE$ such that for every\n\t state $\\sigma$ with $\\sigma(\\VV) \\in \\Nats$, we have\n\t%\n\t\\[\n\t     \\sem{\\gproduct{\\FF}{\\VV}}{\\sigma}{\\interpret}\n\t     \\eeq\n\t     \\prod_{j=0}^{\\sigma(\\VV)} \\sem{\\FF\\subst{\\vprod}{j}}{\\sigma}{\\interpret}~.\n\t     %\n\t     %\n\t\\]\n\\end{theorem}\n%\\begin{proof}\n%\t%\n%See Appendix~\\ref{proof:prod_exp}.\n%\\end{proof}\n%\n%\n%\nFor an arithmetic expression $\\TT$, we write  $\\gproduct{\\FF}{\\TT}$ instead of $\\gproduct{\\FF}{\\VV}\\subst{\\VV}{\\TT}$.\n\nAn immediate, yet important, consequence of Theorem~\\ref{thm:prod_exp} is that, even though syntactically forbidden, \\emph{arbitrary products} of syntactic expectations are expressible in $\\SyntE$.\n%\n%\nLet $\\FF, \\FG \\in \\SyntE$, and let $\\vprod$ be a fresh variable. We define the \\emph{(unrestricted) product} $\\FF \\exprod \\FG$ of $\\FF$ and $\\FG$ by\n\t%\n\t\\[\n\t      \\FF \\exprod \\FG \\ddefeq \n\t      \\gproduct{\\iverson{\\vprod = 0} \\cdot \\FF + \\iverson{\\vprod = 1} \\cdot \\FG}{1}~.\n\t\\]\n%\n%\n%\n%\n\\begin{corollary}\n\t\\label{cor:unrestricted_product}\n\t Let $f,g \\in \\SyntE$. For all states $\\sigma$, we have\n\t %\n\t \\[\n\t    \\sem{\\FF \\exprod \\FG}{\\sigma}{\\interpret}\n\t    \\eeq\n\t    \\sem{\\FF}{\\sigma}{\\interpret} \\cdot \\sem{\\FG}{\\sigma}{\\interpret}~.\n\t \\]\n\\end{corollary}\n%\n\n\n\n \n%\\input{pgcl_wp}\n\n\\section{Expressiveness of our Language}\n\\label{sec:expressiveness}\n\nWith the results from the preceding sections at hand, we give a constructive expressiveness proof for our language $\\SyntE$.\n%for \\emph{all} $\\pgcl$ programs---in particular for loops.\n%\nFix a set of variables $\\varseq{x} = \\{ x_0,\\ldots, x_{n-1}\\}$.\n%\n%\nWe assume a fixed set $\\partitionedstates{x} \\subseteq \\States$ that contains \\emph{exactly one} state from each equivalence class of $\\equivstatesrel{\\varseq{x}}$ (cf.\\ \\Cref{sec:encoding_states}).\n%\nGiven a state $\\sigma \\in \\States$, we define the \\emph{characteristic expectation} $\\statepred{\\sigma}{\\varseq{x}}$ of $\\sigma$ (w.r.t.\\ $\\varseq{x}$) as\n%\n\\[\n\\statepred{\\sigma}{\\varseq{x}} \\ddefeq \\iverson{x_0 = \\sigma(x_0) \\wedge \\ldots \\wedge x_{n-1} = \\sigma(x_{n-1})}~.\n\\]\n%\nThe expectation $\\statepred{\\sigma}{\\varseq{x}}$ evaluates to $1$ on state $\\sigma'$ if $\\equivstates{\\sigma}{\\varseq{x}}{\\sigma'}$, and to $0$ otherwise.  Finally, we denote by $\\Vars(\\cc)$ the set of all variables that appear in the $\\pgcl$ program $\\cc$. \n\nLet us now formalize the characterization of $\\wp{\\WHILEDO{\\BB}{\\cc'}}{\\eval{\\FF}}$ from \\Cref{sec:kozen_duality}:\n%\n%If clear from the context, we often omit the subscribt $\\varseq{x}$ and simply write $\\statepred{\\sigma}{}$. Notice that if $\\Vars(\\ff) \\subseteq \\varseq{x}$ for some expectation $\\ff$, then $\\equivstates{\\sigma_1}{\\varseq{x}}{\\sigma_2}$\n%implies $\\ff(\\sigma_1) = \\ff(\\sigma_2)$\n%\n\\begin{theorem}\n\t\\label{thm:wp_loop_as_sum}\n\tLet $\\cc = \\WHILEDO{\\BB}{\\cc'}$ be a loop and let $\\FF \\in \\SyntE$. Furthermore, let $\\varseq{x}$ be a finite set of variables with $\\Vars(\\cc) \\cup \\FV{\\FF} \\subseteq \\varseq{x}$.  We have\n\t%\n\t%\n\t\\begin{align*}\n\t&\\wp{\\WHILEDO{\\BB}{\\cc'}}{\\eval{\\FF}}  \\\\\n\t%\n\t\\eeq &\\lambda \\sigma \\mydot \\sup_{k \\in \\Nats}\n\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t\\statepred{\\sigma_0}{\\varseq{x}}(\\sigma)\n\t\\cdot (\\iverson{\\neg \\BB} \\cdot \\eval{\\FF})(\\sigma_{k-1}) \\\\\n\t &\\qquad \\qquad \\qquad \\qquad \\qquad \\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc'}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{\\varseq{x}}}(\\sigma_i)~.\n\t\\end{align*}\n\t%\n\\end{theorem}\n%\n\\begin{proof}\n\tSee Appendix \\ref{proof:wp_prob_times_exp}.\n\\end{proof}\n%\n%\n%\n%\n%\nWe are finally in a position to prove expressiveness (cf. \\Cref{def:expressiveness}).\n%\n%\n\\begin{theorem}\n\t\\label{thm:expressive}\n\tThe language $\\SyntE$ of syntactic expectations is expressive.\n\\end{theorem}\n%\n\\begin{proof}\n\tBy induction on the structure of $\\cc$. \n    All cases except loops are completely analogous to the proof of\n    Lemma~\\ref{thm:expressive-loop-free}.\n Let us thus consider the case $\\cc \\eeq \\WHILEDO{\\BB}{\\cc_1}$.\n    We employ the syntactic $\\gsumsymbol$- and $\\gproductsymbol$ expectations from Theorems~\\ref{thm:sum_exp} and~\\ref{thm:prod_exp} to\n    construct the series from Theorem~\\ref{thm:wp_loop_as_sum} in $\\SyntE$, thus expressing $\\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\sem{\\FF}{}{}}$.\n    %Now Recall from Theorem~\\ref{thm:wp_loop_as_sum} that \n    %\n%    \t\\begin{align*}\n%    &\\wp{\\WHILEDO{\\BB}{\\cc'}}{\\ff}(\\sigma)  \\\\\n%    %\n%    \\eeq & \\sup_{k \\in \\Nats}\n%    \\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n%    \\statepred{\\sigma_0}{\\varseq{x}}(\\sigma)\n%    \\cdot (\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\\\\\n%    &\\qquad \\qquad \\qquad \\qquad \\cdot\n%    \\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc'}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{\\varseq{x}}}(\\sigma_i)~.\n%    \\end{align*}\n    %\n   %We show that this infinite series is expressible in $\\SyntE$ \n   %by means of the syntactic $\\gsumsymbol$- and $\\gproductsymbol$ expectations from %Theorems~\\ref{thm:sum_exp} and~\\ref{thm:prod_exp}, respectively. \n    \n    The products ocurring in Theorem~\\ref{thm:wp_loop_as_sum} are expressed\n     %using $\\gproductsymbol$ \n     by an effectively constructible  syntactic expectation $\\pathexp{\\VV_1}{\\VV_2}$ (where $\\VV_1$ and $\\VV_2$ are fresh variables) satisfying:\n    %\n    \\begin{enumerate}\n    \t\\item \n    \t\\label{eqn:pathexp_spec_1}\n    If $\\sigma(\\VV_1) \\in \\Nats$ with $\\sigma(\\VV_1) > 0$ and  $\\sigma(\\VV_2)=\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{\\sigma(\\VV_1)-1}}_{\\varseq{x}}$, then \n    %\n%\n    \\begin{align}\n       &\\sem{\\pathexp{\\VV_1}{\\VV_2}}{\\sigma}{\\interpret} \\notag\\\\\n       %\n      \\eeq & (\\iverson{\\neg \\BB} \\cdot \\sem{\\FF}{}{})(\\sigma_{\\sigma(\\VV_1)-1})\n       \\cdot\n       \\prod\\limits_{i=0}^{\\sigma(\\VV_1)-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{\\varseq{x}}}(\\sigma_i)\n       %\n    \\end{align}\n    %\\substack{\\text{if}~\\sigma(\\VV_1)  \\not\\in\\Nats  ~\\text{or}~\\sigma(\\VV_1) = 0~.}\n    %\n    \\item\n    \\label{eqn:pathexp_spec_2}\n    If $\\sigma(\\VV_1)  \\not\\in\\Nats$  or $\\sigma(\\VV_1) = 0$, then \n    %\n     % \n    %\n         $\\sem{\\pathexp{\\VV_1}{\\VV_2}}{\\sigma}{\\interpret} = 0$.\n     %\n    %\n    \\end{enumerate}\n    %\n    Then, for the syntactic expectation \n    %\n    \\begin{align*}\n    %\n       \\FH \\eeq & \\semleft{\\Sup length \\colon \\Sup nums \\colon\n       \t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{}{} \\\\\n       %\n       %\n       &\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n       \\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright~,\n     %\n    \\end{align*}\n    %\n    we have \n    %\n    ~$\\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\sem{\\FF}{}{}} = \\eval{\\FH}$.\n    %\n\n    %\n    Here, the quantifier $\\Sup length$ in $\\FH$ corresponds to the $\\sup k$ from Theorem~\\ref{thm:wp_loop_as_sum}.  The subsequent $\\gsumsymbol$ expectation expresses the sum from Theorem~\\ref{thm:wp_loop_as_sum}: Summing over sequences of states of length $length$ is realized by summing over all G\\\"odel numbers $\\gnum$ satisfying $\\stateseq{\\varseq}{\\gnum}{length}$. See \\ref{proof:epressiveness_appendix} for a detailed correctness proof.\n    %\n\\end{proof}\n%\n%\n\\subsection{Example}\n    We conclude this section by sketching the construction of a syntactic expectation for a concrete loop.\n\tConsider the program $\\cc$ given by \n\t%\n\t\\begin{align*}\n\t%\n\t    &\\WHILE{c = 1 } \\\\\n\t    & \\quad \\PCHOICE{\\ASSIGN{c}{0}}{\\nicefrac{1}{2}}{\\ASSIGN{c}{1}}; \\\\\n\t    &\\quad \\ASSIGN{x}{x+1} ~ \\}\n\t %\n\t\\end{align*}\n\t%\n\twhere we denote the loop body by $\\cc'$.\n    Morever, let $\\FF \\defeq x \\in \\SyntE$. \n    Then the syntactic\n    expectation $\\FH$ expressing $\\wp{\\WHILEDO{c=1}{\\cc'}}{\\sem{x}{}{}}$ as sketched in the \n    proof of Theorem~\\ref{thm:expressive} is \n    %is constructive, we obtain a syntactic \n\t%\n\t%\n\t\\begin{align*}\n\t\\FH   \n\t%\n\t\\eeq\n\t%\n\t&\\semleft{\\Sup length \\colon \\Sup nums \\colon\n\t\t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{}{} \\\\\n\t%\n\t%\n\t&\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n\t\\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright~,\n\t%\n\t\\end{align*}\n\t%\n\twhere the syntactic expectation $\\pathexppost{\\FF}{length}{\\VV_2}$ is defined as follows:\n\t%\n\t\\begin{align*}\n\t%&\\pathexppost{\\FF}{length}{\\VV_2} \\\\\n\t%\n\t%\\eeq& \n\t%\n    & \\iverson{length < 2} \\cdot (\\Sup \\gnum \\colon \\iverson{\\seqelem{\\vsum}{length -1}{\\gnum}}\n\t\\exprod \\gapply{x}{(\\iverson{\\neg (c=1)} \\cdot x)}{\\gnum}) \\\\\n\t%\n\t+& \\iverson{length \\geq 2} \\cdot\n\t%\n\t(\\Sup \\gnum \\colon \\iverson{\\seqelem{\\vsum}{length -1}{\\gnum}}\n\t\\exprod \\gapply{x}{(\\iverson{\\neg (c=1)} \\cdot x)}{\\gnum}) \\\\\n\t%\n\t&\\quad\\exprod\n\t\\gproductsymbol \\big(\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n\t\\iverson{\\seqelem{\\vsum}{\\vprod}{\\gnum_1} \\wedge \\seqelem{\\vsum}{\\vprod+1}{\\gnum_2}} \\\\\n\t&\\qquad  \\quad \n\t\\exprod\n\t\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}, length - 2 \\big)\n\t%\n\t%\n\t\\end{align*}\n\t%\n\tand where \n\t%\n\t\\begin{align*}\n\t   \\FG \\eeq \\iverson{c=1} \\cdot \\frac{1}{2} \\cdot \\left( \\iverson{0=c' \\wedge x+1=x'} + \\iverson{1=c' \\wedge x+1=x'} \\right) + \\iverson{\\neg{(c=1)}} \\cdot \\iverson{c=c' \\wedge x=x'}~.\n\t\\end{align*}\n\t%\n\t%\n\tWe omit unfolding $\\FH$ further. Although our general construction yields rather complex syntactic preexpectations, notice we can express $\\wp{\\WHILEDO{c=1}{\\cc'}}{\\sem{x}{}{}}$ much more concisely as \n\t%\n\t\\[\n\t    x \\pplus \\iverson{c=1} \\cdot 2 \\quad{}\\in{}\\quad \\SyntE~.\n\t\\]\n\t\n\t\n\n\n \n% !TEX root = ./main.tex\n\n\\section{On Negative Numbers}\\label{sec:negatives}\n\n%The attentive reader may have noticed that we evaded negative numbers throughout the paper:\n%with regard to two aspects:\nThroughout the paper, we have evaded supporting negative numbers in two aspects:\n%\n%\n\\begin{enumerate}\n\t\\item In our \\emph{verification system}---the weakest preexpectation calculus---we allow expectations, both syntactic and semantic, to map program states to \\emph{non-negative} values in $\\PosRealsInf$ only.\n\t\\item In our \\emph{programming language}, we allow variables to assume \\emph{non-negative} values in $\\PosRats$ only.\n\\end{enumerate}%\n%\nWhile the former restriction is fairly standard in the literature on probabilistic programs (cf.~\\cite{McIverM05}), considering only unsigned program variables is less common.\n%(cf.~\\cite{winskel}).\nAn attentive reader may thus ask whether our completeness results rely on the above restrictions.\n%\n%\nIn this section, we briefly comment on our reasons for\nconsidering only non-negative numbers.\nMoreover, we discuss how one \\emph{could} incorporate support for negative numbers in both of the above aspects.\n\n\\subsection{Signed Expectations}\n\n%Although the assumption that expectations evaluate to non-negative values is fairly common, \nThere exist approaches that support signed expectations, which allow arbitrary reals in their codomain.\n%Another angle of attack are singed expectations, which allow negative numbers as part of their codomain.\n%The benefit is that one could then allow for signed program variables as well, without having to worry about positivity at all.\n%On the downside, signed expectations require significant technical overhead~\\cite{DBLP:conf/lics/KaminskiK17} and proof rules for loops become much more involved involved.\nHowever, as working with signed expectations may lead to integrability issues, \nthese approaches require a significant technical overhead (cf. \\cite{DBLP:conf/lics/KaminskiK17} for details). \nMoreover, proof rules for loops become much more involved.\nCalculi like Kozen's PPDL \\emph{in principle} allow signed expectations off-the-shelf, but PPDL's induction rule for loops is restricted to non-negative expectations as well~\\cite{Kozen1983}.\nWe thus opted for the more common approach of considering only unsigned expectations.\n%\nAn alternative is to perform a \\emph{Jordan decomposition} on the expectation (\\ie decomposing it into positive and negative parts) and then reason individually about the positive and the negative part.\nAs outlined below, such a decomposition can already be performed on program level \\emph{without} changing the verification system.\n\n\\subsection{Signed Program Variables}\n\nOmitting negative numbers does \\emph{not} affect our results because they can easily be encoded in our (Turing complete) programming language:\n%On the other hand, Turing-completeness does not require negative numbers. \nwe can emulate signed variables, for instance, by splitting each variable $x$ into two variables $\\abs{x}$ and $x_{\\mathit{sgn}}$, representing the absolute value of $x$ and its sign ($x_{\\mathit{sgn}} = 1$ if $x$ negative, and $x_{\\mathit{sgn}} = 0$ otherwise), respectively.\nWith this convention, \nthe program below emulates \nthe subtraction assignment $\\ASSIGN{z}{x - y}$ using only addition and monus: % as follows:%\n%\n%\n\\begin{align*}\n\t& \\IF{x_{\\mathit{sgn}} = y_{\\mathit{sgn}}} \\tag*{\\textcolor{gray}{\\texttt{// calculuate magnitude of $z$}}}\\\\\n\t& \\qquad \\ASSIGN{\\abs{z}}{\\bigl(\\abs{x} \\monus \\abs{y} \\bigr) \\pplus \\bigl(\\abs{y} \\monus \\abs{x} \\bigr)} \\\\\n\t& \\ELSE\\\\\n\t& \\qquad \\ASSIGN{\\abs{z}}{\\abs{x} + \\abs{y}} \\\\\n\t& \\COMPOSE{\\}}{} \\\\\n\t%\n\t& \\IF{\\abs{x} > \\abs{y}} \\tag*{\\textcolor{gray}{\\texttt{// calculuate sign of $z$}}}\\\\\n\t& \\qquad \\ASSIGN{z_{\\mathit{sgn}}}{x_{\\mathit{sgn}}} \\\\\n\t& \\ELSE \\\\\n\t& \\qquad \\IF{\\abs{x} = \\abs{y}} \\\\\n\t& \\qquad \\qquad \\ASSIGN{z_{\\mathit{sgn}}}{0} \\\\\n\t& \\qquad \\ELSE \\\\\n\t& \\qquad \\qquad \\ASSIGN{z_{\\mathit{sgn}}}{1 \\monus y_{\\mathit{sgn}}} \\\\\n\t& \\qquad \\} \\\\\n\t& \\}\n\\end{align*}%\n%\nSimilar emulations can be performed for addition, multiplication, etc.\nFor the purpose of proving relative completeness, signed variables are thus syntactic sugar; we omit them for simplicity.\n\nOur main reason for disallowing negative numbers as values of program variables is that we want~$x$ to be a valid (unsigned) expectation.\nIf $x$ was signed, it would not be a valid expectation as it does not map only to non-negative values.\n%(cf. next subsection).\nIn order to fix this problem to some extent, one would have to \\enquote{make $x$ non-negative}, \\eg by instead using the expectation $\\iverson{x \\geq 0} \\cdot x$ ($x$ truncated at $0$) or the expectation $|x|$ (absolute value of $x$; not supported (but can be encoded) in our current syntax). However, neither of the above expectations actually represents \\enquote{the value of $x$}.\n\n\n\n \n% !TEX root = ./main.tex\n\n\\section{Discussion}\\label{sec:applications}\n%\\section{Applications}\\label{sec:applications}\n\nWe now discuss a few aspects\n%collect various  %scenarios \nin which our expressive language $\\SyntE$ of expectations could be useful.\n\n\\subsection{Relative Completeness of Probabilistic Program Verification}\n%\nAn immediate consequence of \\Cref{thm:expressive} is that, for all $\\pgcl$ programs $\\cc$ and all syntactic expectations $\\FF, \\FG \\in \\SyntE$, verifying the bounds \n%\n\\begin{align*}\n        \\eval{\\FG} \\ppreceq \\wp{\\cc}{\\eval{\\FF}} \n        \\qquad\\text{or}\\qquad\n        \\wp{\\cc}{\\eval{\\FF}} \\ppreceq \\eval{\\FG}\n\\end{align*}\n%\nreduces to \\emph{checking a single inequality} between two syntactic expectations in $\\SyntE$, namely $\\FG$ and the \\emph{effectively constructible expectation} for $\\wp{\\cc}{\\eval{\\FF}}$.\nIn that sense, the $\\wpsymbol$ calculus together with $\\SyntE$ form a \\emph{relatively complete} (cf.~\\cite{Cook1978SoundnessAC}) system for probabilistic program verification.\nGiven an oracle for discharging inequalities between syntactic expectations, \nevery correct inequality of the above form can be derived.\n%Checking inequalities of the form $\\wp{\\cc}{\\eval{\\FF}} \\preceq \\eval{\\FG}$ is typically needed in invariant-style reasoning for probabilistic programs~\\cite{benni_diss}.\n%the correctness of every\n%on expected values of $\\pgcl$ programs can be derived. % with weakest preexpectations (for total correctness).\n%Notice that, in the above inequalities, we did not translate $\\FF$ into an expectation $\\eval{\\FF}$ before computing the weakest preexpectation. By \\Cref{thm:expressive}, we know how to construct a suitable syntactic expectation $\\wp{\\cc}{\\FF}$ without reverting to a semantical definition.\n\n\\subsection{Termination Probabilities}\n\nFor each probabilistic program $\\cc$, the weakest preexpectation%\n%\n\\begin{align*}\n\t\\wp{\\cc}{1}\n\\end{align*}%\n%\nis a mapping from initial state $\\pstate$ to the \\emph{probability that $C$ terminates on $\\pstate$}.\nSince $1 \\in \\SyntE$, \\emph{termination probabilities of any \\pgcl program on any input are expressible in our syntax}.\n\nThis demonstrates that our syntax is capable of capturing mappings from states to numbers that are \\emph{far from trivial} as termination probabilities in general carry a \\emph{high degree of internal complexity}~\\cite{DBLP:conf/mfcs/KaminskiK15,acta19}.\nMore concretely, given $C$, $\\pstate$, and $\\alpha$, deciding whether $C$ terminates on $\\pstate$ \\emph{at least} with probability $\\alpha$ is $\\Sigma_1^0$--complete in the arithmetical hierarchy.\n%, thus strictly harder than the (non-universal) termination problem for non-probabilistic programs.\nDeciding whether $C$ terminates on $\\pstate$ \\emph{at most} with probability $\\alpha$ is even $\\Pi_2^0$--complete, thus strictly harder than, \\eg the universal termination problem for non-probabilistic programs.\n\n\n\\subsection{Probability to Terminate in Some Postcondition}\n\nFor a probabilistic program $\\cc$ and a first-order predicate $\\iverson{\\BB}$, the weakest preexpectation%\n%\n\\begin{align*}\n\t\\wp{\\cc}{\\iverson{\\varphi}}\n\\end{align*}%\n%\nis a mapping from initial state $\\pstate$ to the \\emph{probability that $C$ terminates on $\\pstate$ in a state $\\tau \\models \\BB$}.\nSince $\\iverson{\\varphi}$~is expressible in $\\SyntE$, we have that $\\wp{\\cc}{\\iverson{\\varphi}}$ is also expressible in $\\SyntE$ by expressivity of $\\SyntE$. \nWe can thus embed \\emph{and generalize Dijkstra's weakest preconditions completely in our system}.\n\n\n\\subsection{Distribution over Final States}\n\nLet $\\cc$ be a probabilistic program in which only the variables $\\XX_1,\\, \\ldots,\\, \\XX_k$ occur.\nMoreover, let $\\mu_\\cc^\\pstate$ be the final distribution obtained by executing $\\cc$ on input $\\pstate$, cf.~\\Cref{sec:forward-semantics}.\nThen, by the Kozen duality (cf.~\\Cref{thm:kozen-duality}), we can express the probability $\\mu_\\cc^\\pstate(\\tau)$ of $\\cc$ terminating in final state $\\tau$ on initial state $\\pstate$, where~\\mbox{$\\tau(\\XX_i) = \\XX_i'$}, by\n%\n\\begin{align*}\n\t\\mu_{\\cc}^{\\pstate}(\\tau) \\eeq \\wp{\\cc}{\\iverson{\\XX_1 = \\XX_1' \\wedge {\\cdots} \\wedge \\XX_k = \\XX_k'}}(\\sigma)~.\n\\end{align*}\n%\nIntuitively, we can write the initial values of $\\XX_1,\\, \\ldots,\\, \\XX_k$ into $\\sigma(\\XX_1),\\, \\ldots,\\, \\sigma(\\XX_k)$ and the final values into $\\sigma(\\XX_1'),\\, \\ldots,\\, \\sigma(\\XX_k')$.\n\nSince $\\iverson{\\XX_1 = \\XX_1' \\wedge {\\cdots} \\wedge \\XX_k = \\XX_k'} \\in \\SyntE$, we have that $\\wp{\\cc}{\\iverson{\\XX_1 = \\XX_1' \\wedge {\\cdots} \\wedge \\XX_k = \\XX_k'}}$ is expressible in $\\SyntE$ as well.\nHence, \\emph{we can express Kozen's measure transformers in our syntax}.\n\n\n\\subsection{Ranking Functions / Supermartingales}\n\nThere is a plethora of methods for proving termination of probabilistic programs based on ranking supermartingales~\\cite{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/FioritiH15,DBLP:conf/popl/ChatterjeeFNH16,DBLP:conf/popl/ChatterjeeNZ17,DBLP:conf/aplas/HuangFC18,DBLP:conf/vmcai/FuC19,DBLP:journals/pacmpl/Huang0CG19}.\nRanking supermartingales are similar to ranking functions, but one requires that the value decreases \\emph{in expectation}.\nWeakest preexpectations are the natural formalism to reason about this.\n\nFor algorithmic solutions, ranking supermartingales are often assumed to be, for instance, linear~\\cite{DBLP:journals/toplas/ChatterjeeFNH18} or polynomial~\\cite{DBLP:conf/cav/ChatterjeeFG16,DBLP:journals/corr/abs-1910-12634,DBLP:conf/pldi/NgoC018}.\nThis also applies to the allowed shape of templates for loop invariants in works~\\cite{DBLP:conf/sas/KatoenMMM10,DBLP:conf/atva/FengZJZX17} on the automated synthesis of probabilistic loop invariants.\n\\emph{Functions linear or polynomial in the program variables are obviously subsumed by our syntax.}\nHowever, our syntax now enables searching for \\emph{wider} tractable classes. % of ranking supermartingales.\n\n\n\\subsection{Harmonic Numbers}\n\nHarmonic numbers are ubiquitous in reasoning about expected values or expected runtimes of randomized algorithms.\nThey appear, for instance, as the expected runtime of Hoare's randomized quicksort or the coupon collector problem, or as ranking functions for proving almost-sure termination~\\cite{benni_diss,OlmedoKKM16,DBLP:journals/jacm/KaminskiKMO18,DBLP:journals/pacmpl/McIverMKK18}.\nHarmonic numbers are syntactically expressible in our language as in \\Cref{ex:harmonic}, or more conveniently as\n%\n\\begin{align*}\n\tH_\\XX \\eeq \\eval{\\gsum{\\tfrac{1}{\\vsum}}{\\XX}}~, \\qquad \\textnormal{where }~ \\tfrac{1}{\\vsum} \\eeq \\Sup \\XZ \\colon \\iverson{\\XZ \\cdot \\vsum = 1}\\cdot \\XZ~.\n\\end{align*}%\n%\nWe note that, in termination proofs, the Harmonic numbers do \\emph{not} occur as termination probabilities, but rather \\emph{in ranking functions} whose expected values after one loop iteration need to be determined.\nOur syntax is capable of handling such ranking functions and we could safely add $H_x$ to our syntax.\n \n% !TEX root = ./main.tex\n\n\n\\section{Conclusion and Future Work}\\label{sec:conclusion}\n\nWe have presented a \\emph{language of syntactic expectations} that is \\emph{expressive for weakest preexpectations} of probabilistic programs \\'{a} la \\citet{Kozen1985} and \\citet{McIverM05}.\nAs a consequence, verification of bounds on expected values of functions (expressible in our language) after probabilistic program execution is \\emph{relative complete} in the sense of~\\citet{Cook1978SoundnessAC}.\n\nWe have discussed various scenarios covered by our language, such as reasoning about termination probabilities, thus demonstrating the language's usefulness.\n\n\\subsubsection*{Future Work}\nWe currently do not support probabilistic programs with (binary) \\emph{non-deterministic} choices, as do \\citet{McIverM05}, and it is not obvious how to incorporate it, given our current encoding.\nWhat seems even more out of reach is handling \\emph{unbounded non-determinism}, which would be needed, for instance, to come up with an expressive expectation language for \\emph{quantitative separation logic} (\\QSL)---an (extensional) verification system for compositional reasoning about probabilistic pointer programs with access to a heap~\\cite{DBLP:journals/pacmpl/BatzKKMN19,Matheja20}.\n\nFor non-probabilistic heap-manipulating programs, a topic considered by~\\citet{expressiveness_sl} are inductive definitions of predicates in classical separation logic (\\SL) and proving that  \\SL is expressive in this context. \n\\QSL also features inductive definitions and it would be interesting to consider expressiveness in this setting.\n%For \\SL, only recently the question of expressiveness was addressed by~\\citet{DBLP:journals/tcs/AmeenT16} in the context of \\emph{recursive procedure calls}.\n%It would be interesting future work to consider expressiveness of $\\SyntE$ for recursive and higher order probabilistic programs~\\cite{OlmedoKKM16,DBLP:journals/pacmpl/DahlqvistK20,DBLP:conf/pldi/GehrSV20,DBLP:journals/pacmpl/SatoABGGH19,DBLP:conf/lics/KobayashiLG19,DBLP:conf/lics/StatonYWHK16}.\n%\n%For \\SL,~\\citet{expressiveness_sl} address the \\emph{complexity of finding loop invariants}, using their expressiveness result.\n%In the context of probabilistic loop invariants~\\cite{DBLP:conf/qest/GretzKM13,DBLP:conf/sas/KatoenMMM10,benni_diss}, this is an interesting question as well.\n\nDespite its similarity to the $\\wpsymbol$ calculus, we did not consider the \\emph{expected runtime calculus} ($\\textsf{ert}$) by \\citet{DBLP:journals/jacm/KaminskiKMO18}.\nWe strongly conjecture that $\\SyntE$ is expressive for expected \\mbox{runtimes as well}.\n\nFinally, the \\emph{conditional weakest preexpectation} calculus (\\textsf{cwp})~\\cite{benni_diss,DBLP:journals/toplas/OlmedoGJKKM18} for probabilistic programs with \\emph{conditioning} needs weakest \\emph{liberal} preexpectations, which generalize Dijkstra's weakest liberal preconditions.\nIt currently remains open, whether $\\wlp{\\cc}{f}$ is expressible in $\\SyntE$.\nThere is the duality $\\wlp{\\cc}{f} = 1 - \\wp{\\cc}{1{-}f}$, originally due to \\citet{Kozen1983}, but it is not immediate how to express $1{-}f$ in $\\SyntE$, if $f$ is not a plain arithmetic expression.\n\n \n\\bibliography{literature}\n\n\\appendix\n\\newpage\n%\n\n\\section{Appendix to Section~\\ref{sec:normalforms} (The Dedekind Normal Form)}\n\n\\subsection{Proof of Lemma~\\ref{thm:prenex-rules}}\n\n\\begin{lemma}\n\t\\label{thm:prenex:aux}\n\tLet $\\alpha \\in \\PosReals$ and $A,B \\subseteq \\PosRealsInf$. Then, we have:\n\t\\begin{enumerate}\n\t\t%\n\t\t\\item\\label{thm:prenex:aux:sup-mult}\n\t\t\\makebox[2.8cm]{$\\alpha \\cdot \\sup A$} $\\eeq \\sup \\{ \\alpha \\cdot a \\mmid a \\in A \\}$,\n\t\t%\n\t\t\\item\\label{thm:prenex:aux:inf-mult}\n\t\t\\makebox[2.8cm]{$\\alpha \\cdot \\inf A$} \n\t\t$\\eeq \\inf \\{ \\alpha \\cdot a \\mmid a \\in A \\}$,\n\t\t%\n\t\t\\item\\label{thm:prenex:aux:sup-plus}\n\t\t\\makebox[2.8cm]{$(\\sup A) + (\\sup B)$} \n\t\t$\\eeq \\sup \\{ \\beta + \\gamma \\mmid \\beta \\in A, \\gamma \\in B \\}$, \n\t\t%\n\t\t\\item\\label{thm:prenex:aux:inf-plus}\n\t\t\\makebox[2.8cm]{$(\\inf A) + (\\inf B)$} \n\t\t$\\eeq \\inf \\{ \\beta + \\gamma \\mmid \\beta \\in A, \\gamma \\in B \\}$, and\n\t\t%\n\t\t\\item\\label{thm:prenex:aux:singleton}\n\t\tif $A$ is a singleton, i.e.,  $A = \\{ \\beta \\}$, then $\\sup A = \\inf A = \\beta$,\n\t\t%\n\t\\end{enumerate}\n\twhere we define $0 \\cdot \\infty = 0$.\n\\end{lemma}\n\n\\emph{Proof of \\Cref{thm:prenex-rules}}.\n\t\\label{proof:prenex-rules}\n\t%\n\tBy definition of equivalence between expectations, we have \n\t\\begin{align*}\n\t\\FF_1 \\equiv \\FF_2 \n\t\\qiff \n\t\\text{for all $\\sigma$}\\colon \\sem{\\FF_1}{\\sigma}{\\interpret} \\eeq \\sem{\\FF_2}{\\sigma}{\\interpret}.\n\t\\end{align*}\n\tLet us fix an arbitrary state $\\sigma$.\n\t\n\tTo prove Lemma~\\ref{thm:prenex-rules}~(\\ref{thm:prenex-rules:plus-left}) for $\\Quant = \\Sup$, we proceed as follows:\n\t%\n\t\\begin{align*}\n\t%\n\t& \\sem{(\\SupV{\\VV} \\FF_1) \\pplus \\FF_2}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq & \n\t\\sup~\\setcomp{\\sem{\\FF_1}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats} \n\t\\pplus \\sem{\\FF_2}{\\pstate}{\\interpret} \n\t\\tag{Semantics of expecations} \\\\\n\t%\n\t\\eeq & \n\t\\sup~\\setcomp{\\sem{\\FF_1}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats} \n\t\\pplus \n\t\\sup~\\left\\{\\sem{\\FF_2}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret}\\right\\}\n\t\\tag{Lemma~\\ref{thm:prenex:aux}~(\\ref{thm:prenex:aux:singleton})} \\\\\n\t%\n\t\\eeq & \n\t\\sup~\\setcomp{\\sem{\\FF_1\\subst{\\VV}{\\VV'}}{\\pstate\\statesubst{\\VV'}{\\RR}}{\\interpret\\statesubst{\\VV'}{\\RR}} + \\sem{\\FF_2}{\\pstate}{\\interpret\\statesubst{\\VV'}{\\RR}}}{\\RR \\in \\PosRats} \n\t\\tag{Lemma~\\ref{thm:prenex:aux}~(\\ref{thm:prenex:aux:sup-plus}), $\\VV'$ fresh} \\\\\n\t%\n\t\\eeq & \n\t\\sem{\\SupV{\\VV'} \\FF_1\\subst{\\VV}{\\VV'} \\pplus \\FF_2 }{\\sigma}{\\interpret}.\n\t\\tag{Semantics of expectation}\n\t\\end{align*}\n\t%\n\tThe proofs for $\\Quant = \\Inf$ as well as the proof of Lemma~\\ref{thm:prenex-rules}~(\\ref{thm:prenex-rules:plus-right}) are completely analogous.\n\t%\n\t\n\t%\n\tTo prove Lemma~\\ref{thm:prenex-rules}~(\\ref{thm:prenex-rules:mult-term}) for $\\Quant = \\Inf$, we proceed as follows:\n\t\\begin{align*}\n\t%\n\t& \\sem{\\TT \\cdot \\InfV{\\VV} \\FF}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq & \n\t\\sem{\\TT}{\\sigma}{\\interpret} \\cdot \\inf \\setcomp{ \\sem{\\FF}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} }{ \\RR \\in \\PosRats }\n\t\\tag{Semantics of expectations} \\\\\n\t%\n\t\\eeq & \n\t\\inf \\setcomp{\\sem{\\TT}{\\sigma}{\\interpret} \\cdot \\sem{\\FF}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} }{ \\RR \\in \\PosRats }\n\t\\tag{Lemma~\\ref{thm:prenex:aux}~(\\ref{thm:prenex:aux:inf-mult})} \\\\\n\t%\n\t\\eeq & \n\t\\inf \\setcomp{\\sem{\\TT}{\\sigma}{\\interpret\\statesubst{\\VV'}{\\RR}} \\cdot \\sem{\\FF\\subst{\\VV}{\\VV'}}{\\sigma\\statesubst{\\VV'}{\\RR}}{\\interpret\\statesubst{\\VV'}{\\RR}} }{ \\RR \\in \\PosRats }\n\t\\tag{$\\VV'$ fresh} \\\\\n\t%\n\t\\eeq & \n\t\\sem{\\InfV{\\VV'} \\TT \\cdot \\FF\\subst{\\VV}{\\VV'}}{\\sigma}{\\interpret} \n\t\\tag{Semantics of expectations}.\n\t%\n\t\\end{align*}\n\t%\n\tThe proofs for $\\Quant = \\Sup$ as well as the proof of Lemma~\\ref{thm:prenex-rules}~(\\ref{thm:prenex-rules:mult-guard}) are completely analogous.\n\t%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Proof of Theorem~\\ref{thm:dedekind_nf}}\n\n\nFirst, we prove that every $\\FF \\in\\SyntE$ is equivalent to some expectation in \\emph{summation normal form}. For that, we employ an auxiliary result:\n\n\\begin{lemma}\n\t\\label{lem:quantifier_free_smf}\n\tLet $\\FF \\in \\SyntE$ be quantifier-free. Then there exist (1) a natural number $n\\geq 1$, (2) Boolean expressions $\\BB_1,\\ldots,\\BB_n$, and (3) terms $\\TT_1,\\ldots,\\TT_n$ such that $\\FF$ is equivalent to an expectation \\mbox{$\\FF'$ given by}\n\t%\n\t\\[\n\t\\FF' \\eeq \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i ~,\n\t\\]\n\t%\n\twhere the above sum is a shorthand for $\\iverson{\\BB_1}\\cdot \\TT_1 + \\ldots + \\iverson{\\BB_n}\\cdot \\TT_n$.\n\\end{lemma}\n%\n\n\\begin{proof}\n\t\n\tBy induction on the structure of quantifier-free syntactic expectations. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{Base case $\\FF = \\TT$.} The expectation $\\FF$ is obviously equivalent to \n\t%\n\t\\[\n\t\\FF' \\eeq \\sum\\limits_{i=1}^{1} \\iverson{\\true}\\cdot \\TT ~.\n\t\\]\n\t%\n\tAs the induction hypothesis now assume that for some arbitrary, but fixed, quantifier-free syntactic expectations $\\FF_1$ and $\\FF_2$\n\tthere are expectations $\\FF_1'$ and $\\FF_2'$ equivalent to $\\FF_1$ and $\\FF_2$, respectively, given by\n\t%\n\t\\begin{align*}\n\t\\FF_1' &\\eeq \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~,~\\text{and} \\\\\n\t%\n\t\\FF_2' &\\eeq \\sum\\limits_{i=1}^{m} \\iverson{\\BB_i'}\\cdot \\TT_i' ~.\n\t\\end{align*}\n\t%\n\t\\noindent\n\t\\emph{The case $\\FF = \\TT \\cdot \\FF_1$.} We have\n\t%\n\t\\begin{align*}\n\t&\\TT \\cdot \\FF_1 \\\\\n\t%\n\t\\eequiv & \\TT \\cdot \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i\n\t\\tag{by I.H.} \\\\\n\t%\n\t\\eequiv &  \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i} \\cdot \\TT \\cdot \\TT_i\n\t\\tag{$\\cdot$ distributes over $+$ in the quantifier-free setting} \\\\\n\t%\n\t\\eequiv &  \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i} \\cdot u_i ~.\n\t\\tag{let $u_i = \\TT \\cdot \\TT_i$}\n\t\\end{align*}\n\t%\\kbcommentinline{TODO: Prove distributivity of $\\cdot$ over %$+$ in the quantifier-free setting}\n\t%\\cmcommentinline{That should be immediate since it just uses %pointwise distributitivity and the fact that we only talk about %finite sums?}\n\t%\\kbcommentinline{Yes}\n\t%\n\t\\emph{The case $\\FF = \\iverson{\\BB} \\cdot \\FF_1$.} We have\n\t%\n\t\\begin{align*}\n\t&\\iverson{\\BB} \\cdot \\FF_1 \\\\\n\t%\n\t\\eequiv & \\iverson{\\BB} \\cdot \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i\n\t\\tag{by I.H.} \\\\\n\t%\n\t\\eequiv &  \\sum\\limits_{i=1}^{n} \\iverson{\\BB} \\cdot  \\iverson{\\BB_i} \\cdot \\TT_i\n\t\\tag{$\\cdot$ distributes over $+$ in the quantifier-free setting} \\\\\n\t%\n\t\\eequiv &  \\sum\\limits_{i=1}^{n} \\iverson{G_i} \\cdot  \\TT_i ~.\n\t\\tag{let $G_i = \\iverson{\\BB \\wedge \\BB_i}$}\n\t\\end{align*}\n\t%\n\t\\emph{The case $\\FF = \\FF_1 + \\FF_2$.} This case is trivial since\n\t%\n\t\\begin{align*}\n\t&\\FF_1 + \\FF_2\n\t%\n\t\\eequiv  \\FF_1' + \\FF_2'~,\n\t\\tag{by I.H.}\n\t\\end{align*}\n\t%\n\twhere $\\FF_1' + \\FF_2'$ is of the desired form.\n\t%\n\tThis completes the proof.\n\\end{proof}\n\n\n\n\n\\begin{theorem}[Summation Normal Form]\n\t\\label{thm:summation_nf}\n\tEvery syntactic expectation $\\FF$ is equivalent to an expectation $\\FF'$ in \\emph{summation normal form}, i.e.\\\n\t$\\FF'$ is of the form\n\t%\n\t\\[\n\t\\FF' \\eeq \\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i ~.\n\t\\]\n\\end{theorem}\n%\n\\begin{proof}\n\t\\label{proof:summation_nf}\n\tBy Lemma~\\ref{thm:prenex-rules}, \\FF is equivalent to an expectation in prenex normal form, i.e.,\n\t%\n\t\\[\n\t\\FF \\equiv \\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon g~,\n\t\\]\n\t%\n\twhere $g$ is quantifier-free. \n\tBy Lemma~\\ref{lem:quantifier_free_smf}, $g$ is then equivalent to an expectation of the form\n\t%\n\t\\[\n\t\\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~.\n\t\\]\n\t%\n\tHence, \\FF is equivalent to the following expectation in summation normal form:\n\t\\[\n\t\\FF' \\eeq \\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~.\n\t\\]\n\\end{proof}\n\n\n\\begin{definition}[Dedekind Normal Form]\n\t%\n\tLet $\\FF$ be an expectation in summation normal form, say\n\t%\n\t\\[\n\t\\FF \\eeq \\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~.\n\t\\]\n\t%\n\tThe \\emph{Dedekind normal form} $\\dexp{\\FF}$ of \\FF w.r.t. the fresh variable $\\VVcut$ is given by:\n\t%\n\t\\[\n\t\\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon\n\t\\left[ \\bigwedge_{\\big( (B_i, T_i)_{1\\leq i \\leq n} \\big)  \\in \\bigtimes_{i = 1}^{n} \\big\\{ (\\BB_i, \\TT_i), (\\neg \\BB_i, 0) \\big\\}}\n\t\\Big( \\bigwedge_{i=1}^{n} B_i \\longrightarrow \\VVcut < \\sum_{i=1}^{n} T_i \\Big) \\right] ~.\n\t\\]\n\tWe call $\\VVcut$ the \\emph{cut variable} of $\\dexp{\\FF}$.\n\t%\n\\end{definition}\n\n\n\\begin{proof}\n\t\\label{proof:dedekind_nf}\n\t%\n\tFirst notice that indeed $\\sem{\\dexp{f}}{\\sigma}{\\interpret} \\in \\{0,1\\}$. We proceed by induction on $k$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{Base case $k=0$.} In this case,\n\t%\n\t\\[\n\t\\FF \\eeq \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~.\n\t\\]\n\t%\n\tNow there is \\emph{exactly one} $((B_1', T_1'), \\ldots, (B_n', T_n')) \\in \\bigtimes_{i = 1}^{n} \\{ (\\BB_i, \\TT_i), (\\neg \\BB_i, 0) \\}$ such that\n\t\\[\n\t\\sem{\\bigwedge_{i=1}^{n} B_i'}{\\sigma}{\\interpret} \\eeq \\true~.\n\t\\]\n\t%\n\tHence, we have\n\t%\n\t\\begin{align*}\n\t& \\sem{f}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq & \\sem{\\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i}{\\sigma}{\\interpret}\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq & \\sem{\\sum\\limits_{i=1}^{n} T_i'}{\\sigma}{\\interpret}~.\n\t\\tag{since $\\sem{\\iverson{\\BB_j}}{\\sigma}{\\interpret}$ = 0 if $B_j = \\neg \\BB_j$}\n\t\\end{align*}\n\t%\n\tThis is gives us\n\t%\n\t\\begin{align*}\n\t&\\sem{\\dexp{F}}{\\sigma}{\\interpret}  \\eeq 1 \\\\\n\t%\n\t\\text{iff} \\quad & \\sem{\\iverson{\\bigwedge_{((B_1, T_1), \\ldots, (B_n, T_n)) \\in \\bigtimes_{i = 1}^{n} \\{ (\\BB_i, \\TT_i), (\\neg \\BB_i, 0) \\}}\n\t\t\t\\big( \\bigwedge_{i=1}^{n} B_i \\longrightarrow \\VVcut < \\sum_{i=1}^{n} T_i \\big)} }{\\sigma}{\\interpret} \\eeq 1 \n\t\\tag{by definition}\\\\\n\t%\n\t\\text{iff} \\quad & \\sem{\\iverson{\\bigwedge_{i=1}^{n} B_i' \\longrightarrow \\VVcut < \\sum_{i=1}^{n} T_i' }}{\\sigma}{\\interpret} \\eeq 1 \n\t\\tag{by above reasoning}\\\\\n\t%\n\t\\text{iff} \\quad & \\sem{\\iverson{\\VVcut < \\sum_{i=1}^{n} T_i' }}{\\sigma}{\\interpret} \\eeq 1 \n\t\\tag{left-hand side of implication evaluates to $\\true$ by construction}\\\\\n\t%\n\t\\text{iff} \\quad & \\interpret(\\VVcut) \\LL \\sem{\\sum_{i=1}^{n} T_i'}{\\sigma}{\\interpret} \n\t\\tag{by definition}\\\\\n\t%\n\t\\text{iff} \\quad & \\interpret(\\VVcut) \\LL \\sem{f}{\\sigma}{\\interpret}~. \n\t\\tag{by above reasoning}\\\\\n\t\\end{align*}\n\t%\n\tAs the induction hypothesis now assume that for some arbitrary, but fixed, $k \\in \\Nats$, all states $\\sigma$, and all syntactic expectations\n\t%\n\t\\[\n\t\\FF \\eeq \\Quant_1 \\VV_1 \\ldots \\Quant_k \\VV_k \\colon \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i\n\t\\]\n\t%\n\tit holds that \n\t%\n\t\\[\n\t\\sem{\\dexp{F}}{\\sigma}{\\interpret} \n\t\\eeq\n\t\\begin{cases}\n\t1, & \\text{if}~\\interpret(\\VVcut) < \\sem{f}{\\sigma}{\\interpret} \\\\\n\t%\n\t0, &\\text{otherwise}~.\n\t\\end{cases}\n\t\\]\n\t%\n\t%\n\t\\emph{Induction step.} We now consider an expectation of the form\n\t%\n\t\\[\n\t\\FF \\eeq \\Quant_1 \\VV_1 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\sum\\limits_{i=1}^{n} \\iverson{\\BB_i}\\cdot \\TT_i~.\n\t\\]\n\t%\n\tWrite $\\dexp{\\FF} = \\Quant_1 \\VV_1 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'$.\n\tWe distinguish the cases $\\Quant_1 = \\Sup$ and $\\Quant_1 = \\Inf$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{The case $\\Quant_1 = \\Sup$.} We have\n\t%\n\t\\begin{align*}\n\t& \\sem{\\dexp{f}}{\\sigma}{\\interpret} \\eeq  1 \\\\\n\t%\n\t\\text{iff} \\quad & \\sem{ \\Sup \\VV_1 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma}{\\interpret} \\eeq  1 \n\t\\tag{by definition} \\\\\n\t%\n\t\\text{iff} \\quad & \\sup \n\t\\setcomp{   \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF' }{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret}   }{\\RR \\in \\PosRats} \\eeq 1\n\t\\tag{by definition} \\\\\n\t%\n\t\\text{iff}\\quad & \\text{there is}~\\RR \\in \\PosRats~\\text{with}~\n\t\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \\eeq 1\n\t\\tag{expression on the left-hand side of the set comprehension evaluates to either $0$ or $1$} \\\\\n\t%\n\t\\text{iff}\\quad & \\text{there is}~\\RR \\in \\PosRats~\\text{with}~\n\t\\sigma\\statesubst{\\VV_1}{\\RR}(\\VVcut) \\LL  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \n\t\\tag{by I.H.} \\\\\n\t%\n\t\\text{iff}\\quad & \\text{there is}~\\RR \\in \\PosRats~\\text{with}~\n\t\\sigma(\\VVcut) \\LL  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \n\t\\tag{$\\VV_1 \\neq \\VVcut$ by construction} \\\\\n\t%\n\t\\text{iff}\\quad & \n\t\\sigma(\\VVcut) \\LL  \\sup \\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }\n\t\\tag{see below} \\\\\n\t%\n\t\\text{iff}\\quad & \n\t\\sigma(\\VVcut) \\LL   \\sem{\\Sup \\VV_1 \\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma}{\\interpret} \n\t%\n\t\\tag{by definition}\n\t\\end{align*}\n\t%\n\tWe justify the second last step as follows. The \\enquote{only if}-direction is obvious.\n\t\n\tFor the \\emph{if}-direction, assume for a contradiction that\n\t%\n\t\\begin{align}\n\t\\label{eq:proof_dedekind_nf_1}\n\t\\sigma(\\VVcut) \\LL  \\sup \\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }\n\t\\end{align}\n\t%\n\tand\n\t%\n\t\\begin{align}\n\t\\label{eq:proof_dedekind_nf_2}\n\t\\text{for all}~\\RR \\in \\PosRats~\\text{it holds that}~\n\t\\sigma(\\VVcut) \\ggeq  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} ~.\n\t\\end{align}\n\t%\n\tInequality~(\\ref{eq:proof_dedekind_nf_2}) implies that $\\sigma(\\VVcut)$ is an upper bound on\n\t$ \\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }$. Hence, $\\sigma(\\VVcut)$ is greater than or equal to the \\emph{least} upper bound of this set. This contradicts inequality~(\\ref{eq:proof_dedekind_nf_1}). \\\\ \\\\\n\t%\n\t%\n\t\\noindent\n\t\\emph{The case $\\Quant_1 = \\Inf$.} We have\n\t%\n\t\\begin{align*}\n\t& \\sem{\\dexp{f}}{\\sigma}{\\interpret} \\eeq  1 \\\\\n\t%\n\t\\text{iff} \\quad & \\sem{ \\Inf  \\VV_1 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma}{\\interpret} \\eeq  1 \n\t\\tag{by definition} \\\\\n\t%\n\t\\text{iff} \\quad & \\inf \n\t\\setcomp{   \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF' }{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}}   }{\\RR \\in \\PosRats} \\eeq 1\n\t\\tag{by definition} \\\\\n\t%\n\t\\text{iff}\\quad & \\text{for all}~\\RR \\in \\PosRats~\\text{we have}~\n\t\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \\eeq 1\n\t\\tag{expression on the left-hand side of the set comprehension evaluates to either $0$ or $1$} \\\\\n\t%\n\t\\text{iff}\\quad & \\text{for all}~\\RR \\in \\PosRats~\\text{we have}~\n\t\\sigma\\statesubst{\\VV_1}{\\RR}(\\VVcut) \\LL  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \n\t\\tag{by I.H.} \\\\\n\t%\n\t%\n\t\\text{iff}\\quad & \\text{for all}~\\RR \\in \\PosRats~\\text{we have}~\n\t\\sigma(\\VVcut) \\LL  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} \n\t\\tag{$\\VV_1 \\neq \\VVcut$ by construction} \\\\\n\t%\n\t\\text{iff}\\quad & \n\t\\sigma(\\VVcut) \\LL  \\inf \\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }\n\t\\tag{see below} \\\\\n\t%\n\t\\text{iff}\\quad & \n\t\\sigma(\\VVcut) \\LL   \\sem{\\Inf \\VV_1 \\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma}{\\interpret} \n\t%\n\t\\tag{by definition}\n\t\\end{align*}\n\t%\n\tWe justify the second last step as follows. The \\enquote{if}-direction is obvious.\n\t\n\tFor the \\enquote{only-if}-direction, assume the contrary, i.e.\\ assume for a contradiction that\n\t%\n\t\\begin{align}\n\t\\label{eq:proof_dedekind_nf_3}\n\t\\text{for all}~\\RR \\in \\PosRats~\\text{we have}~\n\t\\sigma(\\VVcut) \\LL  \\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}}\n\t\\end{align}\n\t%\n\tbut\n\t%\n\t\\begin{align}\n\t\\label{eq:proof_dedekind_nf_4}\n\t%\n\t\\sigma(\\VVcut) \\ggeq  \\inf \\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }~.\n\t\\end{align}\n\t%\n\tInequality~(\\ref{eq:proof_dedekind_nf_3}) implies that $\\sigma(\\VVcut)$ is a strict lower bound on $\\setcomp{\\sem{\\Quant_2 \\VV_2 \\ldots \\Quant_{k+1} \\VV_{k+1} \\colon \\FF'}{\\sigma\\statesubst{\\VV_1}{\\RR}}{\\interpret\\statesubst{\\VV_1}{\\RR}} }{\\RR \\in  \\PosRats }$ and must hence also be a strict lower bound on the \\emph{greatest} lower bound of this set. This contradicts Inequality~(\\ref{eq:proof_dedekind_nf_4}). \n\\end{proof}\n\n\n\\subsection{Proof of Lemma \\ref{lem:dedekind_nf_recover}}\n\n\\begin{proof}\n\t\\label{proof:dedekind_nf_recover}\n\t\tLet $\\sigma$ be a state. We have\n\t\t%\n\t\t\\begin{align*}\n\t\t%\n\t\t& \\sem{\\Sup \\VVcut \\colon \\dexp{f} \\cdot \\VVcut}{\\sigma}{\\interpret} \\\\\n\t\t%\n\t\t\\eeq & \\sup \\setcomp{   \\sem{\\dexp{f} \\cdot \\VVcut}{\\sigma\\statesubst{\\VVcut}{\\RR}}{\\interpret\\statesubst{\\VVcut}{\\RR}}   }{\\RR \\in \\PosRats} \n\t\t\\tag{by definition}\\\\\n\t\t%\n\t\t\\eeq & \\sup \\setcomp{\\sem{\\VVcut}{\\sigma\\statesubst{\\VVcut}{\\RR}}{\\interpret\\statesubst{\\VVcut}{\\RR}}}{ \\RR \\in \\dcut{\\sem{\\FF}{\\sigma}{\\interpret}}}\n\t\t\\tag{since $\\sem{\\dexp{\\FF}}{\\sigma\\statesubst{\\VVcut}{\\RR}}{\\interpret\\statesubst{\\VVcut}{\\RR}} = 0$ if $\\RR \\not \\in \\dcut{\\sem{\\FF}{\\sigma}{\\interpret}}$ } \\\\\n\t\t%\n\t\t\\eeq & \\sup \\setcomp{\\RR \\in \\PosRats}{\\RR \\in \\dcut{\\sem{\\FF}{\\sigma}{\\interpret}}} \n\t\t\\tag{by definition}\\\\\n\t\t%\n\t\t\\eeq & \\sem{\\FF}{\\sigma}{\\interpret}~.\n\t\t\\tag{by definition}\n\t\t\\end{align*}\n\t\n\\end{proof} \n%%\\section{Appendix to Section~\\ref{sec:product_of_exp} (Products of Expectations)}\n%%\\input{appendix_products}\n\n\\section{Appendix to Section~\\ref{sec:embedding} (G\\\"odelization for Syntactic Expectations)}\n\n\\subsection{Proof of Lemma~\\ref{lem:nats_definable}}\n\n\\begin{proof}\n\t\\label{proof:nats_definable}\n\t\n\tWe employ a result by Robinson~\\cite[Section 3]{robinson_define_z}: For $a,b,k \\in \\Rats$, let\n\t%\n\t\\begin{align*}\n\t%\n\t\\Phi(a, b, k) &\\ddefeq \\exists x,y,z \\in \\Rats \\colon  2 + abk^2 + bz^2 = x^2 + ay^2 \\\\\n\t%\n\tB(a,b) &\\ddefeq  \\Phi(a,b,0) \\wedge \\forall m \\in \\Rats \\colon (\\Phi(a,b,m) \\longrightarrow \\Phi(a,b,m+1)) \\\\\n\t%\n\tA(k)  &\\ddefeq  \\forall a,b \\in \\Rats \\colon \n\tB(a,b) \\longrightarrow \\Phi(a,b,k)~.\n\t%\n\t\\end{align*}\n\t%\n\t%\n\tThen $k \\in \\Rats$ is an integer if and only if $A(k)$ holds. Denote by $A'$ (resp. $\\Phi', B'$) the formula obtained from\n\t$A$ (resp. $\\Phi, B$) by replacing every occurrence of $\\Rats$ by $\\PosRats$, i.e.\\ we restrict to quantification over $\\PosRats$. Note that $\\Phi(a',b',k')$ iff $\\Phi'(a',b',k')$ for all $a',b',k' \\in \\PosRats$ since all occurrences of $x,y,z$ in $B$ are squared.\n\t\n\tSince $A'(k')$ is expressible in $\\FOArithPosRats$, we prove the lemma by showing that for every $k' \\in \\PosRats$, \n\t%\n\t\\[\n\tk' \\in \\Nats \\qquad \\text{if and only if} \\qquad A'(k')~.\n\t\\]\n\t%\n\tThe \\enquote{only if} direction is straightforward since\n\t%\n\t\\[\n\t\\Phi'(a,b,0) \\wedge \\forall m \\in \\PosRats \\colon (\\Phi'(a,b,m) \\longrightarrow \\Phi'(a,b,m+1))\n\t\\]\n\t%\n\timplies $\\Phi(a,b,k')$ for all $k' \\in  \\Nats$. Hence, if $a,b \\in \\PosRats$ and $B'(a,b)$ holds, then $\\Phi'(a,b,k')$ holds, which implies $A'(k')$.  \\\\ \\\\\n\t%\n\t%\n\t\\noindent\n\tThe \\enquote{if} direction is less obvious. We proceed by recapping the crucial parts of Robinson's proof that $A(k)$ implies $k \\in \\Ints$ for all $k \\in \\Rats$ on a sufficient level of abstraction. We then show how to employ the same proof to show that $A'(k')$ implies $k' \\in \\Nats$ for all $k' \\in \\PosRats$.\n\t\n\tRobinson shows that it suffices to derive the following two facts from assumption $A(k)$:\n\t%\n\t\\begin{align}\n\t%\n\t&\\Phi(1, p, k)~\\text{holds for all primes $p \\in P_1$} \n\t\\label{eqn:proof_nats_definable_1}\\\\\n\t%\n\t&\\Phi(q,p,k)~\\text{holds for all primes $p \\in P_2 $ and all $q \\in Q $}~,\n\t\\label{eqn:proof_nats_definable_2}\n\t%\n\t\\end{align}\n\t%\n\twhere $P_1, P_2, Q \\subseteq \\Nats$ are some non-empty sets of primes. We do not give these sets explicitly here since they are not relevant for this proof.\n\t(\\ref{eqn:proof_nats_definable_1}) and (\\ref{eqn:proof_nats_definable_2}) in conjunction imply $k \\in \\Ints$. Now, since $\\Phi(a',b',k')$ and $\\Phi'(a',b',k')$ are equivalent for all $a',b',k' \\in \\PosRats$, our proof obligation is to show that for every $k' \\in \\PosRats$, $A'(k')$ implies:\n\t%\n\t\\begin{align}\n\t%\n\t&\\Phi'(1, p, k')~\\text{holds for all primes $p \\in P_1$}~,\\text{and}\n\t\\label{eqn:proof_nats_definable_3}\\\\\n\t%\n\t&\\Phi'(q,p,k')~\\text{holds for all primes $p \\in P_2 $ and all $q \\in Q $}~.\n\t\\label{eqn:proof_nats_definable_4}\n\t%\n\t\\end{align}\n\t%\n\tWe may then invoke Robinson's result from above to conclude that $k' \\in \\Nats$.\n\t%\n\t\n\tTo prove~(\\ref{eqn:proof_nats_definable_1}), Robinson shows that $B(1, p)$ holds for every $p \\in P_1$. Since $B(1,p)$ implies $B'(1,p)$ for all $p \\in P_1$ (recall that $p$ is a natural number), we also get $B'(1,p)$. Now, assumption $A(k)$ and the fact that $B(1,p)$ holds imply $\\Phi(1,p,k)$. We apply the same reasoning for $\\Phi'(1,p,k)$: Assumption $A'(k)$ and the fact that $B'(1,p)$ holds imply $\\Phi'(1,p,k')$, which proves~(\\ref{eqn:proof_nats_definable_3}).\n\t\n\tThe proof of~(\\ref{eqn:proof_nats_definable_4}) is completely analogous.\n\t\n\\end{proof}\n\n\n\n\\subsection{Proof of Theorem~\\ref{thm:fo_rats_subsumes_fo_nats}}\n\n\\begin{proof}\n\t\\label{proof:fo_rats_subsumes_fo_nats}\n\tBy induction on the structure of $\\PP$ and by using Lemma~\\ref{lem:nats_definable}. \n\tLet $\\interpret \\colon \\LVars \\to \\PosRats$.\\\\ \\\\\n\t%\n\t\\emph{Base case $\\PP =\\BB$.} If there is $\\VV \\in \\FV{\\PP}$ with $\\pstate(\\VV) \\not\\in \\Nats$, then $\\sem{\\isNat(\\VV)}{\\sigma}{\\interpret} = \\false$ and thus $\\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} = \\false$. Conversely, if for all $\\VV \\in \\FV{\\PP}$ it holds that $\\sigma(\\VV) \\in \\Nats$, then $\\sigma$ is an interpretation for $\\PP$ and obviously $\\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} = \\sem{\\PP}{\\sigma}{\\interpret}$ since $\\sem{\\isNat(\\VV)}{\\sigma}{\\interpret} = \\true$. \\\\ \\\\\n\t%\n\t\\noindent As the induction hypothesis (I.H.) now assume that the theorem holds for some arbitrary, but fixed, $\\PP' \\in \\FOArithNats$. \\\\ \\\\\n\t%\n\t\\emph{The case $\\PP = \\exists \\VV \\colon \\PP'$.} First notice that $\\FV{\\PP} = \\FV{\\PP'} \\setminus \\{ \\VV \\}$.\n\tHence, if there is $\\VV' \\in \\FV{\\PP}$ with $\\sigma(\\VV') \\not\\in \\Nats$, then $\\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} = \\sem{\\toFOPosRats{\\PP'}}{\\sigma}{\\interpret}  = \\false$ by I.H. Now assume that for all $\\VV' \\in \\FV{\\PP}$ it holds that $\\sigma(\\VV') \\in \\Nats$, rendering $\\sigma$ an interpretation for $\\PP$. We have\n\t%\tIf $v \\not\\in \\FV{P'}$, then our induction hypothesis yields\n\t%\t%\n\t%\t\\begin{align*}\n\t%\t   & \\sem{\\toFOPosRats{P}}{}{\\interpret} \\\\\n\t%\t   %\n\t%\t   \\eeq & \\sem{\\exists \\VV \\colon \\left( \\toFOPosRats{P'} \\right)}{}{\\interpret}\n\t%\t   \\tag{by definition} \\\\\n\t%\t   %\n\t%\t   \\eeq &\\sem{\\toFOPosRats{P'}}{}{\\interpret} \n\t%\t   \\tag{$v \\not \\in \\FV{P'}$} \\\\\n\t%\t   %\n\t%\t   \\eeq &\\sem{P'}{}{\\interpret}\n\t%\t   \\tag{by I.H.}~.\n\t%\t\\end{align*}\n\t%\n\t%Conversely, if $\\VV \\in \\FV{P'}$, our induction hypothesis implies, we get\n\t%\n\t\\begin{align*}\n\t& \\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} \\eeq \\true\\\\\n\t%\n\t\\qqiff & \\sem{\\exists \\VV \\colon \\left( \\toFOPosRats{\\PP'} \\right)}{\\sigma}{\\interpret} \\eeq \\true\n\t\\tag{by definition} \\\\\n\t%\n\t\\qqiff & \\text{there is}~\\RR \\in \\PosRats~\\text{with}~ \\sem{\\toFOPosRats{\\PP'}}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq \\true\n\t\\tag{by definition}\\\\\n\t%\n\t\\qqiff& \\text{there is}~n \\in \\Nats~\\text{with}~ \\sem{\\toFOPosRats{\\PP'}}{\\sigma\\statesubst{\\VV}{n}}{\\interpret\\statesubst{\\VV}{n}} \\eeq \\true \n\t\\tag{If $v \\in \\FV{\\PP'}$, then $\\sem{\\toFOPosRats{\\PP'}}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} = \\true$ only if  $\\RR \\in \\Nats$ by I.H.} \\\\\n\t%\n\t\\qqiff& \\text{there is}~n \\in \\Nats~\\text{with}~ \\sem{\\PP'}{\\sigma\\statesubst{\\VV}{n}}{\\interpret\\statesubst{\\VV}{n}} \\eeq \\true \n\t\\tag{by I.H. } \\\\\n\t%\n\t\\qqiff &\\sem{\\exists \\VV \\colon \\PP' }{\\sigma}{\\interpret} \\eeq \\true\n\t\\tag{by definition}  \\\\\n\t%\n\t\\qqiff & \\sem{\\PP}{\\sigma}{\\interpret} \\eeq \\true~.\n\t\\tag{by definition} \n\t\\end{align*}\n\t\n\t%$\\sem{\\toFOPosRats{P'}}{}{\\interpret\\statesubst{\\VV}{r}} = \\false$ for all $r \\in \\PosRats \\setminus %\\Nats$ and $\\sem{\\toFOPosRats{P'}}{}{\\interpret\\statesubst{\\VV}{n}} = %\\sem{P'}{}{\\interpret\\statesubst{\\VV}{n}}$ for all $n \\in \\Nats$, which implies the claim. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{The case $\\PP = \\forall \\VV \\colon \\PP'$.} First notice that $\\FV{\\PP} = \\FV{\\PP'} \\setminus \\{ \\VV \\}$.\n\tHence, if there is $\\VV' \\in \\FV{\\PP}$ with $\\sigma(\\VV') \\not\\in \\Nats$, then\n\t%\n\t\\begin{align*}\n\t& \\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq & \\sem{\\forall \\VV \\colon \\left(\\toFOPosRats{\\PP'} \\vee \\neg \\isNat(\\VV) \\right)}{\\sigma}{\\interpret}\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq & \\sem{\\forall \\VV \\colon \\neg \\isNat(\\VV)}{\\sigma}{\\interpret}.\n\t\\tag{$\\sem{\\toFOPosRats{\\PP'}}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} = \\false$ for all $\\RR \\in \\PosRats \\setminus \\Nats$ by I.H.} \\\\\n\t%\n\t\\eeq& \\false ~.\n\t\\tag{there is an $\\RR \\in \\PosRats$ with $\\RR \\not\\in \\Nats$}\n\t\\end{align*}\n\t%\n\tNow assume that for all $\\VV' \\in \\FV{\\PP}$ it holds that $\\sigma(\\VV') \\in \\Nats$, rendering $\\sigma$ an interpretation for $\\PP$. We have\n\t%\n\t\\begin{align*}\n\t%\n\t& \\sem{\\toFOPosRats{\\PP}}{\\sigma}{\\interpret} \\eeq \\true\\\\\n\t%\n\t\\qqiff & \\sem{\\forall \\VV \\colon \\left( \\toFOPosRats{\\PP'} \\vee \\neg \\isNat(\\VV) \\right)}{\\sigma}{\\interpret} \\eeq \\true\n\t\\tag{by definition} \\\\\n\t%\n\t\\qqiff & \\text{for all}~\\RR \\in\\PosRats~\\text{we have}~\\sem{\\toFOPosRats{\\PP'} \\vee \\neg \\isNat(\\VV)}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{n}} \\eeq \\true \\\\\n\t%\n\t\\qqiff& \\text{for all}~n\\in\\Nats~\\text{we have}~\\sem{\\toFOPosRats{\\PP'}}{\\sigma\\statesubst{\\VV}{n}}{\\interpret\\statesubst{\\VV}{n}} \\eeq \\true\n\t\\tag{$\\sem{\\neg \\isNat(\\VV)}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}]} = \\true$ for all $\\RR \\in \\PosRats\\setminus\\Nats$} \\\\\n\t%\n\t\\qqiff& \\text{for all}~n\\in\\Nats~\\text{we have}~\\sem{\\PP'}{\\sigma\\statesubst{\\VV}{n}}{\\interpret\\statesubst{\\VV}{n}} \\eeq \\true\n\t\\tag{by I.H.} \\\\\n\t%\n\t\\qqiff& \\sem{\\forall \\VV \\colon \\PP'}{\\sigma}{\\interpret} \\eeq \\true\n\t\\tag{by definition} \\\\\n\t%\n\t\\qqiff& \\sem{\\PP}{\\sigma}{\\interpret} \\eeq \\true~.\n\t\\tag{by definition} \n\t\\end{align*}\n\t\n\t\n\t\n\t%\tSince $\\interpret(v) \\in \\Nats$ for all $v \\in \\LVars$, \n\t%\twe have $\\interpret(v) \\models N(v)$ for all $v \\in \\LVars$ (Lemma~\\ref{lem:nats_definable}). Hence, $\\interpret \\models P \\wedge N(V)$ \n\t%\tand obviously $P \\wedge N(V) \\in \\FOArithPosRats$.\n\t%\t\n\t%\tNow let $\\interpret \\colon \\LVars \\to \\PosRats$\n\t%\tand assume $\\interpret \\models  P \\wedge N(V)$.\n\t%\tLemma~\\ref{lem:nats_definable} implies that $\\interpret(v) \\in \\Nats$ for all\n\t%\t$v \\in \\FV{P}$. We can thus construct an interpretation $\\interpret' \\colon \\LVars \\to \\Nats$ by\n\t%\t\\[\n\t%\t\\interpret'(v) \\eeq \n\t%\t\\begin{cases}\n\t%\t\\interpret(v), & \\text{if}~v\\in \\FV{P} \\\\\n\t%\t0, & \\text{otherwise}~.\n\t%\t\\end{cases}\n\t%\t\\]\n\t%\t%\n\t%\tSince $\\interpret \\models P$, we also have $\\interpret' \\models P$ as the truth value of $P$ depends on the interpretation of the free variables of $P$ only. Furthermore, we obviously have $P \\in \\FOArithNats$.\n\t%\t\n\t%\tAs the induction hypothesis now assume that the theorem holds for some arbitrary, but fixed $P' \\in \\FOArithNats$.\n\t%\t\n\t%\tFor the case $P = \\left( \\exists v \\colon P' \\right)$, consider the following: Let $\\interpret \\colon \\LVars \\to \\Nats$ and assume $\\interpret \\models P$.\n\t%\tHence, there is an $n \\in \\Nats$ with $\\interpret\\statesubst{v}{n} \\models P'$. Lemma~\\ref{lem:nats_definable} implies that $\\interpret\\statesubst{v}{n} \\models N(v)$.\n\t%\tOur induction hypothesis further implies $\\interpret\\statesubst{v}{n} \\models \\toFOPosRats{P'}$. Overall, we get $\\interpret\\statesubst{v}{n} \\models \\toFOPosRats{P'} \\wedge N(v)$ and thus $\\interpret \\models \\exists v \\colon\\toFOPosRats{P'} \\wedge N(v)$.\n\t%\t\n\t%\tNow let $\\interpret \\colon \\LVars \\to \\PosRats$. This case is analagous to the base case, i.e.\\ we again construct an interpretation $\\interpret' \\colon \\LVars \\to \\Nats$ with $\\interpret' \\models P$.\n\\end{proof}\n\n\n\\subsection{Proof of Theorem~\\ref{thm:exp_subsumes_fo_rats}}\n\n\\begin{proof}\n\t\\label{proof:exp_subsumes_fo_rats}\n\tFirst notice that $\\sem{\\iverson{\\PP}}{\\sigma}{\\interpret} \\in \\{0,1\\}$ for all $\\PP\\in\\FOArithPosRats$.\n\tWe now proceed by induction on the structure of $\\PP$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{Base case $\\PP = \\BB$.} This case follows immediately from the definition of $\\sem{\\BB}{\\sigma}{\\interpret}$. \\\\ \\\\\n\t%\n\t\\noindent\n\tAs the induction hypothesis now assume that the theorem holds for some arbitrary, but fixed, $\\PP' \\in \\FOArithPosRats$. \\\\ \\\\\n\t%\n\t\\noindent\n\t%\n\t\\emph{The case $\\PP = \\exists \\VV \\colon \\PP'$.} We have\n\t%\n\t\\begin{align*}\n\t&\\sem{\\iverson{\\PP}}{\\sigma}{\\interpret} \\eeq 1 \\\\\n\t%\n\t\\qiff &  \\sem{\\SupV{\\VV} \\iverson{\\PP'}}{\\sigma}{\\interpret} \\eeq 1 \n\t\\tag{by definition} \\\\\n\t%\n\t\\qiff & \\sup~\\setcomp{\\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats} \\eeq 1\n\t\\tag{by definition} \\\\\n\t%\n\t\\qiff & \\text{there is $\\RR \\in \\PosRats$ with}~\\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq 1\n\t\\tag{$\\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\in \\{0,1\\}$}\\\\\n\t%\n\t\\qiff& \\text{there is $\\RR \\in \\PosRats$ with}~ \\sem{\\PP'}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq \\true\n\t\\tag{by I.H.} \\\\\n\t%\n\t\\qiff&\\sem{\\exists \\VV \\colon \\PP'}{\\pstate}{\\interpret} \\eeq \\true~.\n\t\\tag{by definition}\n\t\\end{align*}\n\t%\n\t%\n\t\\emph{The case $\\PP = \\forall \\VV \\colon \\PP'$.} We have\n\t%\n\t\\begin{align*}\n\t&\\sem{\\iverson{\\PP}}{\\sigma}{\\interpret} \\eeq 1 \\\\\n\t%\n\t\\qiff &  \\sem{\\InfV{\\VV} \\iverson{\\PP'}}{\\sigma}{\\interpret} \\eeq 1 \n\t\\tag{by definition} \\\\\n\t%\n\t\\qiff & \\inf\\hspace{1.1ex}\\setcomp{\\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}}}{\\RR \\in \\PosRats} \\eeq 1 \\\\\n\t%\n\t\\qiff& \\text{for all $\\RR \\in \\PosRats$ we have}~ \\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq 1\n\t\\tag{$\\sem{\\iverson{\\PP'}}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\in \\{0,1\\}$} \\\\\n\t%\n\t\\qiff &\\text{for all $\\RR \\in \\PosRats$ we have}~ \\sem{\\PP'}{\\pstate\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq \\true\n\t\\tag{by I.H.} \\\\\n\t%\n\t\\qiff & \\sem{\\forall \\VV \\colon \\PP'}{\\pstate}{\\interpret} \\eeq \\true \n\t\\tag{by definition} \\\\\n\t%\n\t\\qiff& \\sem{\\PP}{\\pstate}{\\interpret} \\eeq \\true~.\n\t\\tag{by definition}\n\t\\end{align*}\n\\end{proof}\n\n\n\n\n\\subsection{Proof of Theorem~\\ref{thm:rho_expectation}}\n\n\\begin{proof}\n\t\\label{proof:rho_expectation}\n\tWe define $\\rseqelemsymbol$ by\n\t%\n\t\\begin{align*}\n\t%\n\t&\\rseqelem{\\VV_1}{\\VV_2}{\\VV_3} \\\\\n\t%\n\t\\eeq & \\exists n, n_1, n_2 \\colon\n\t\\gPair(n, n_1, n_2) \\wedge\n\t\\seqelem{\\VV_1}{\\VV_2}{n} \\wedge n_2 \\cdot \\VV_3 = n_1 \n\t\\wedge \\left( \\relPrime{n_1}{n_2} \\vee (n_1=0 \\wedge n_2=1) \\right)~,\n\t%\n\t\\end{align*}\n\t%\n\twhere $\\relPrime{n_1}{n_2}$ denotes \\emph{relative primality} of $n_1$ and $n_2$, which is definable in $\\FOArithNats$. \n\t%\n\tLet $\\RR_0 = \\frac{n_{0,1}}{n_{0,2}}, \\ldots, \\RR_{k-1} = \\frac{n_{k-1, 1}}{n_{k-1, 2}}$ such that each $n_{i,j}$ is a natural number satisfying: If $\\RR_i = 0$, then $n_{i,1} = 0$ and $n_{i,2} = 1$. If $\\RR_i \\neq 0$, then $n_{i,1}$ and $n_{i,2}$ are relatively prime. Notice that\n\tthese conditions imply that the pairs $n_{i,0}, n_{i,1}$ are \\emph{unique}.\n\t\n\tFurthermore, by Lemma~\\ref{lem:pairing}, there is a \\emph{unique} sequence of natural numbers $n_0,\\ldots,n_{k-1}$ with \n\t%\n\t\\[\n\t\\gPair(n_i, n_{i, 1}, n_{i,2}) \\eequiv \\true \\quad \\text{for all}~i\\in\\{0,\\ldots, k-1\\} ~.\n\t\\]\n\t%\n\tFinally, by Lemma~\\ref{lem:goedel_beta}, there is a natural number $a$ encoding the sequence $n_0,\\ldots,n_{k-1}$. This gives us\n\t%\n\t\\begin{align*}\n\t&\\rseqelem{a}{i}{ r} \\eequiv \\true \\\\\n\t%\n\t\\text{iff} \\quad & \\exists n, n_1, n_2 \\colon\n\t\\gPair(n, n_1, n_2) \\wedge\n\t\\seqelem{a}{i}{n} \\wedge n_2 \\cdot r = n_1\n\t\\wedge \\left( \\relPrime{n_1}{n_2} \\vee (n_1=0 \\wedge n_2=1) \\right)\n\t\\eequiv \\true\n\t\\tag{by definition} \\\\\n\t%\n\t\\text{iff} \\quad &\n\t\\gPair(n_i, n_{i,1}, n_{i,2}) \\wedge\n\t\\seqelem{a}{i}{n_i} \\wedge n_{i, 2} \\cdot r = n_{i,1} \\eequiv \\true\n\t\\tag{by above reasoning and uniqueness of the $n$s and the pairs $n_{i,1}, n_{i,2}$} \\\\\n\t%\n\t\\text{iff} \\quad & r = r_i\n\t\\tag{by construction}~,\n\t\\end{align*}\n\t%\n\twhich completes the proof.\n\t%\n\t%\n\t%\n\\end{proof}\n \n\\section{Appendix to Section~\\ref{sec:sums_prod_via_goedel} (Sums, Products, and Infinite Series of Syntactic Expectations)}\n\n\\subsection{Proof of Theorem~\\ref{thm:sum_exp}}\n\n\\begin{proof}\n\t\\label{proof:sum_exp}\n\t\n\tWrite \n\t%\n\t\\begin{align*}\n\t\\dexp{\\FF} \\eeq \\qprefix{\\FF} \\colon \\iverson{\\BB}~,\n\t\\end{align*}\n\t%\n\twith cut variable $\\VVcut$ and\n\twhere $\\qprefix{\\FF} = \\Quant_1 \\VV_1 \\colon \\ldots \\colon \\Quant_n \\VV_n$. Furthermore, assume that $\\VV, \\VV', \\gnum, \\VU,z$ are fresh logical variables not occurring in $\\dexp{\\FF}$. Now define\n\t\\begin{align*}\n\t\\gsum{\\FF}{\\VV}\n\t\\ddefeq &\n\t\\Sup \\VV' \\colon \\Sup \\gnum \\colon \n\t\\VV' \\cdot \\Inf \\VU \\colon \\Inf z \\colon \\Sup \\VVcut \\colon \\qprefix{\\FF} \\colon \\\\\n\t%\n\t& [\n\t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV}  \\\\\n\t&  \\quad \\wedge \\big( (\\VU < \\VV+1 \\wedge \\rseqelem{\\gnum}{\\VU}{z} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{\\VU} \\vee \\VVcut = 0) ) \\\\\n\t& \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{\\VU+1}{z + \\VVcut}   \\big)]~.\n\t\\end{align*}\n\t%\n\tThe reasoning is now analagous to the proof of Theorem~\\ref{thm:prod_exp} using Lemma~\\ref{lem:sum_by_cut}.\n\tThe equality $\\sem{\\Sup \\VV \\colon \\gsum{\\FF}{\\VV}}{\\sigma}{\\interpret}\n\t=\n\t\\sum_{j=0}^{\\infty} \\sem{\\FF}{\\sigma}{\\interpret\\statesubst{\\vsum}{j}}$ holds since an infinite series evaluates to the supremum of its partial sums.\n\t\n\t\n\\end{proof}\n\n\n\n\\subsection{Proof of Theorem~\\ref{thm:prod_exp}}\n\nWe employ the following auxiliary result.\n\n\\begin{lemma}\n\t\\label{lem:prod_by_cut}\n\tFor all $\\alpha_0,\\ldots,\\alpha_n \\in \\PosRealsInf$, we have\n\t%\n\t\\[\n\t\\prod_{j=0}^n  \\alpha_j \n\t\\eeq\n\t\\sup \\setcomp{\\RR \\in \\PosRats}{r = r_0 \\cdot \\ldots \\cdot r_n,~\\forall 0 \\leq i \\leq n \\colon r_i \\in \\dcutzero{\\alpha_i}}~.\n\t\\]\n\\end{lemma}\n%\n\\begin{proof}\n\tBy induction on $n$.\n\\end{proof}\n\nWe now prove Theorem~\\ref{thm:prod_exp}.\n\n\\begin{proof}\n\t\\label{proof:prod_exp}\n\t\n\tWrite \n\t%\n\t\\begin{align*}\n\t\\dexp{\\FF} \\eeq \\qprefix{\\FF} \\colon \\iverson{\\BB}~,\n\t\\end{align*}\n\t%\n\twith cut variable $\\VVcut$ and\n\twhere $\\qprefix{\\FF} = \\Quant_1 \\VV_1 \\colon \\ldots \\colon \\Quant_n \\VV_n$. Furthermore, assume that $\\VV, \\VV',\\gnum, \\VU,z$ are fresh logical variables not occurring in $\\dexp{\\FF}$.\n\tNow define \n\t%\n\t\\begin{align*}\n\t\\gproduct{\\FF}{\\VV}\n\t\\ddefeq &\n\t\\Sup \\VV' \\colon \\Sup \\gnum \\colon \n\t\\VV' \\cdot \\Inf \\VU \\colon \\Inf z \\colon \\Sup \\VVcut \\colon \\qprefix{\\FF} \\colon \\\\\n\t%\n\t& [\n\t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV'}  \\\\\n\t&  \\quad \\wedge \\big( (\\VU < \\VV+1 \\wedge \\rseqelem{\\gnum}{\\VU}{ z} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{\\VU} \\vee \\VVcut = 0) ) \\\\\n\t& \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{\\VU+1}{z \\cdot \\VVcut}   \\big)]~.\n\t\\end{align*}\n\t%\n\t%\n\tThe crux of the proof is to show that the $\\{0,1\\}$-valued expectation right after $\\VV' \\cdot \\ldots$ evaluates to $1$ on state $\\sigma$ and interpretation $\\sigma$ iff $\\sigma(\\gnum)$ encodes a sequence  \n\t$1, 1\\cdot r_1, 1\\cdot r_1 \\cdot r_2, \\ldots, 1\\cdot r_1 \\cdot \\ldots \\cdot r_{\\sigma(\\VV)}$ where  $r_j \\in  \\dcutzero{\\sem{\\FF\\subst{\\vprod}{j}}{\\sigma}{\\interpret\\statesubst{\\vprod}{j}}}$\n\tfor all $0 \\leq j \\leq \\sigma(\\VV)$ and where $\\sigma(\\VV') = \\prod\\limits_{j=0}^{\\sigma(\\VV)} r_j$.\n\tThis implies\n    %\n\t%\n\t\\begin{align*}\n\t&\\sem{\\gproduct{f}{\\VV}}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq&\\sem{\\Sup \\VV' \\colon \\Sup \\gnum \\colon \\VV' \\cdot \\ldots}{\\sigma}{\\interpret}\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq&\\sup_{r \\in \\PosRats}\n\t\\sup_{r' \\in \\PosRats}\n\t\\setcomp{r}{r'~\\text{encodes}~1,\\ldots, 1\\cdot r_1 \\cdot \\ldots \\cdot r_{\\interpret(\\VV)} ~\\text{and}~r = \\prod\\limits_{j=0}^{\\sigma(\\VV)} r_j~\\text{where}~r_j \\in  \\dcutzero{\\sem{\\FF}{\\sigma\\statesubst{\\vprod}{j}}{\\interpret\\statesubst{\\vprod}{j}}} }\n\t\\tag{claim proven below}\\\\\n\t%\n\t\\eeq&\\sup_{r \\in \\PosRats}\n\t\\setcomp{r}{r = \\prod\\limits_{j=0}^{\\sigma(\\VV)} r_j~\\text{where}~r_j \\in  \\dcutzero{\\sem{\\FF}{\\sigma\\statesubst{\\vprod}{j}}{\\interpret\\statesubst{\\vprod}{j}}}}~.\n     \\\\\n\t%\n\t\\eeq&\\prod\\limits_{j=0}^{\\sigma(\\VV)} \n\t\\sem{\\FF}{\\sigma\\statesubst{\\vprod}{j}}{\\interpret\\statesubst{\\vprod}{j}}~.\n\t\\tag{by Lemma~\\ref{lem:prod_by_cut}}\n\t\\end{align*}\n%\n%\nWe have\n%\n%\n\\begin{align*}\n   &\\semleft{\\Inf \\VU \\colon \\Inf z \\colon \\Sup \\VVcut \\colon \\qprefix{\\FF} \\colon}{\\sigma}{\\interpret} \\\\\n   %\n   & [\n   \\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV'}  \\\\\n   &  \\quad \\wedge \\big( (\\VU < \\VV+1 \\wedge \\rseqelem{\\gnum}{\\VU}{z} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{\\VU} \\vee \\VVcut = 0) ) \\\\\n   & \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{\\VU+1}{z \\cdot \\VVcut}   \\big)] \\semright = 1 \\\\\n   %\n   %\n   %\n   \\text{iff}\\quad&\\text{for all}~r,s \\in \\PosRats~\\text{there is}~t \\in \\PosRats~\\text{with} \\semleft{\\qprefix{\\FF} \\colon}{\\sigma}{\\interpret} \\\\\n  %\n  & [\n  \\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV'}  \\\\\n  &  \\quad \\wedge \\big( (r < \\VV+1 \\wedge \\rseqelem{\\gnum}{r}{s} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{r}\\subst{\\VVcut}{t} \\vee t = 0) ) \\\\\n  & \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{r+1}{s \\cdot t}   \\big)] \\semright = 1 \n  \\tag{expectation is \\{0,1\\}-valued}\\\\\n  %\n  %\n  %\n  \\text{iff}\\quad&\\sem{[\n  \t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV'}]}{\\sigma}{\\interpret} =1 ~\\text{and}~\n  \\text{for all}~r,s \\in \\PosRats \\\\\n  &\\text{there is}~t \\in \\PosRats~\\text{with} \\semleft{\\qprefix{\\FF} \\colon}{\\sigma}{\\interpret} \\\\\n  %\n  & [ \\big( (r < \\VV+1 \\wedge \\rseqelem{\\gnum}{r}{s} \\wedge (\\iverson{\\BB} \\subst{\\vprod}{r}\\subst{\\VVcut}{t} \\vee t = 0) ) \\\\\n  & \\qquad \\quad  \\longrightarrow  \\rseqelem{\\gnum}{r+1}{s \\cdot t}   \\big)] \\semright \\eeq 1 \\\\\n  %\n  %\n  %\n  \\text{iff}\\quad&\\sem{[\n  \t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV'}]}{\\sigma}{\\interpret} =1 ~\\text{and}~\n  \\text{for all}~r,s \\in \\PosRats~\\text{there is}~t \\in \\PosRats~\\text{with} \\\\\n  &\\sem{ [ r < \\VV+1 \\wedge \\rseqelem{\\gnum}{r}{s}}{\\sigma}{\\interpret} =1 ~\\text{and}~\n   \\sem{\\qprefix{\\FF} \\colon \\iverson{\\BB} \\subst{\\vprod}{r}\\subst{\\VVcut}{t} \\vee t = 0}{\\sigma}{\\interpret} = 1 \\\\\n   &\\quad \\text{implies}~\\sem{\\rseqelem{\\gnum}{r+1}{s \\cdot t} }{\\sigma}{\\interpret} \\eeq 1 \\\\\n   %\n   %\n   %\n   \\text{iff}\\quad&\\sem{[\n   \t\\rseqelem{\\gnum}{0}{1} \\wedge \\rseqelem{\\gnum}{\\VV+1}{\\VV}]}{\\sigma}{\\interpret} =1 ~\\text{and}~\n   \\text{for all}~r,s \\in \\PosRats~\\text{there is}~t \\in \\PosRats~\\text{with} \\\\\n   &\\sem{ [ r < \\VV+1 \\wedge \\rseqelem{\\gnum}{r}{s}}{\\sigma}{\\interpret} =1 ~\\text{and}~\n   t \\in \\dcut{\\sem{\\FF}{\\sigma\\statesubst{\\vprod}{r}}{\\interpret\\statesubst{\\vprod}{r}}} \\cup \\{0\\} \\\\\n   &\\quad \\text{implies}~\\sem{\\rseqelem{\\gnum}{r+1}{s \\cdot t} }{\\sigma}{\\interpret} \\eeq 1 \n   \\tag{by Theorem~\\ref{thm:dedekind_nf}}\\\\\n   %\n   %\n   %\n   \\text{iff}\\quad & \\sigma(\\gnum)~\\text{encodes sequence} ~1, 1\\cdot r_1, 1\\cdot r_1 \\cdot r_2, \\ldots, 1\\cdot r_1 \\cdot \\ldots \\cdot r_{\\sigma(\\VV)}~ \\\\\n   &\\text{with}~  r_j \\in  \\dcut{\\sem{\\FF}{\\sigma\\statesubst{\\vprod}{j}}{\\interpret\\statesubst{\\vprod}{j}}}%\\cup \\{0\\}\n   ~\\text{for all}~0 \\leq j \\leq \\sigma(\\VV)~\\\\\n   &\\text{and where} ~\\sigma(\\VV') = \\prod\\limits_{j=0}^{\\sigma(\\VV)} r_j~.\n\\end{align*}\n\t\n\t\n\t\n%\tLet us first characterize for which interpretations of $\\VV$ and $\\gnum$ the $\\{0,1\\}$-valued expectation right after $\\VV'\\cdot \\ldots$ evaluates to $1$. Let $\\sigma$ be a program state and $\\interpret$ be an interpretation. We have\n%\t%\n%\t%\n%\t\\begin{align*}\n%\t& \\semleft{ \\Inf \\VU \\colon \\Inf z \\colon \\Inf \\VVcut \\colon \\qprefix{\\FF} \\colon }{\\sigma}{\\interpret}  \\\\\n%\t%\n%\t& \\left[\n%\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right.\\\\\n%\t& \\left. \\quad \\wedge \\big( (\\VU < \\VV+1 \\wedge \\gRho(\\gnum, \\VU, z) \\wedge \\iverson{\\BB} \\subst{\\vprod}{\\VU}) \n%\t\\implies \\gRho(\\gnum, \\VU+1, z \\cdot \\VVcut)\\big)\n%\t\\right] \\semright \\eeq 1 \\\\\n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\text{for all}~ \\VU,z \\in \\PosRats \\colon\n%\t\\semleft{\\Inf \\VVcut \\colon\\qprefix{\\FF} \\colon }{\\sigma}{\\interpret} \\\\\n%\t%\n%\t& \\left[\n%\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right.\\\\\n%\t& \\left. \\quad \\wedge \\big( (\\VU < n+1 \\wedge \\gRho(\\gnum, \\VU, z) \\wedge \\iverson{\\BB} \\subst{\\vprod}{\\VU}) \n%\t\\implies \\gRho(\\gnum, \\VU+1, z \\cdot \\VVcut)\\big)\n%\t\\right] \\semright \\eeq 1\n%\t\\tag{since the expectation is $\\{0,1\\}$-valued, abuse notation for $i, z$} \\\\ \n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~  i,z \\in \\PosRats \\colon\n%\t\\semleft{\\Inf \\VVcut \\colon \\qprefix{\\FF} \\colon }{\\sigma}{\\interpret} \\\\\n%\t%\n%\t& \\left[  \\big( (i < \\VV+1 \\wedge \\gRho(\\gnum, i, z) \\wedge \\iverson{\\BB} \\subst{\\vprod}{i}) \n%\t\\implies \\gRho(\\gnum, i+1, z \\cdot \\VVcut)\\big)\n%\t\\right] \\semright \\eeq 1 \\\\\n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~  i \\in \\Nats~\\text{and}~z \\in \\PosRats \\colon\n%\t\\semleft{\\Inf \\VVcut  \\colon \\qprefix{\\FF} \\colon }{\\sigma}{\\interpret} \\\\\n%\t%\n%\t& \\left[ (i < \\VV+1 \\wedge \\gRho(\\gnum, i, z) \\wedge \\iverson{\\BB} \\subst{\\vprod}{i}) \n%\t\\implies \\gRho(\\gnum, i+1, z \\cdot \\VVcut)\n%\t\\right] \\semright \\eeq 1\n%\t\\tag{$\\iverson{\\gRho(\\gnum, i, z)} \\equiv 0$ and $\\iverson{\\gRho(\\gnum, i+1, z \\cdot \\VVcut)} \\equiv 0$\n%\t\tif $i \\not\\in  \\Nats$ by Theorem~\\ref{thm:fo_rats_subsumes_fo_nats}} \\\\\n%\t%\n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~ i \\in \\Nats~\\text{with}~ i < \\interpret(\\VV+1)~\\text{and all}~z \\in \\PosRats \\colon \\\\\n%\t&\\quad \n%\t\\semleft{\\Inf \\VVcut \\colon \\qprefix{\\FF} \\colon }{\\sigma}{\\interpret} \n%\t%\n%\t\\left[(\\gRho(\\gnum, i, z) \\wedge   \\iverson{\\BB} \\subst{\\vprod}{i})\n%\t\\implies \\gRho(\\gnum, i+1, z \\cdot \\VVcut)\\big)\n%\t\\right] \\semright \\eeq 1 \\\\\n%\t%\n%\t%\n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~   i \\in \\Nats~\\text{with}~ i < \\interpret(\\VV+1)~\\text{and all}~z,r \\in \\PosRats \\colon \\big( \\sem{\\gRho(\\gnum, i, z)}{\\sigma}{\\interpret} = 1 \\\\\n%\t&\\quad \\text{and}~\n%\t\\sem{\\dexp{\\FF}}{\\sigma}{\\interpret[\\vprod \\mapsto i, \\VVcut \\mapsto r]} = 1\\big)\n%\t~\\text{implies}~\n%\t\\sem{\\iverson{\\gRho(\\gnum, i+1, z \\cdot \\VVcut)}}{\\sigma}{\\interpret[\\vprod \\mapsto i, \\VVcut \\mapsto r]} = 1 \\\\\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~   i \\in \\Nats~\\text{with}~ i < \\interpret(\\VV+1)~\\text{and all}~z,r \\in \\PosRats \\colon \\big( \\sem{\\gRho(\\gnum, i, z)}{\\sigma}{\\interpret} = 1 \\\\\n%\t&\\quad \\text{and}~\n%\t\\sem{\\dexp{\\FF}}{\\sigma}{\\interpret[\\vprod \\mapsto i, \\VVcut \\mapsto r]} = 1\\big)\n%\t~\\text{implies}~\n%\t\\sem{\\iverson{\\gRho(\\gnum, i+1, r \\cdot \\VVcut)}}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t%\n%\t\\text{iff} \\quad & \\sem{\\left[\n%\t\t\\gRho(\\gnum, 0, 1) \\wedge \\gRho(\\gnum, \\VV+1, \\VV') \\right]}{\\sigma}{\\interpret} = 1 \\\\\n%\t%\n%\t&\\text{and for all}~   i \\in \\Nats~\\text{with}~ i < \\interpret(\\VV+1)~\\text{and all}~z,r \\in \\PosRats \\colon \\big( \\sem{\\gRho(\\gnum, i, z)}{\\sigma}{\\interpret} = 1 \\\\\n%\t&\\quad \\text{and}~\n%\tr \\in \\dcut{\\sem{\\FF}{\\sigma}{\\interpret\\statesubst{\\vprod}{i}}} \\big)\n%\t~\\text{implies}~\n%\t\\sem{\\iverson{\\gRho(\\gnum, i+1, r \\cdot \\VVcut)}}{\\sigma}{\\interpret} = 1 \n%\t\\tag{by Theorem~\\ref{thm:dedekind_nf}}\\\\\n%\t%\n%\t%\n%\t\\text{iff} \\quad& \\gnum~\\text{encodes sequence}~1, 1\\cdot r_1, 1\\cdot r_1 \\cdot r_2, \\ldots, 1\\cdot r_1 \\cdot \\ldots \\cdot r_\\interpret(\\VV) \\\\\n%\t&\\text{and}~\\interpret(\\VV') = \\prod\\limits_{j=0}^{\\interpret(n)} r_j\\\\\n%\t&\\text{where}~r_j \\in  \\dcut{\\sem{\\FF}{\\sigma}{\\interpret\\statesubst{\\vprod}{j}}}~\n%\t\\text{for all $0 \\leq j \\leq \\interpret(\\VV)$}~.\n%\t\\end{align*}\n%\t%\n%\t%\n%\t\n\t\n\\end{proof}\n\n \n\n\\section{Appendix to Section~\\ref{sec:expressiveness} (Expressiveness of our Language)}\n\\label{app:expressiveness}\nGiven an expectation $\\ff \\in \\E$, we denote by\n%\n\\[\n\\Vars(\\ff) \\eeq \\setcomp{x \\in \\Vars}{\\exists \\sigma \\in \\States \\colon \\exists n,n' \\in \\Nats  \\colon \\ff(\\sigma\\statesubst{x}{n}) \\neq \\ff(\\sigma\\statesubst{x}{n'})}\n\\]\n%\nthe set of all \\enquote{relevant} variables in $\\ff$. We restrict to expectations $\\ff$ with $|\\Vars(\\ff)| < \\infty$, since $|\\Vars(\\eval{\\FF})| < \\infty$ holds for every \\emph{syntactic} expectation $\\FF$. \n\\Cref{thm:wp_loop_as_sum} is a consequence of the $\\WHILESYMBOL$-case of the following theorem.\n%\n\\begin{theorem}\n\t\\label{thm:wp_prob_times_exp}\n\t%\n\t%\n\tLet $\\cc$ be a program and $\\ff$ be an expectation. Furthermore, let $\\varseq{x}$ be a finite set of program variables with $\\Vars(\\cc) \\cup \\Vars(\\ff) \\subseteq \\varseq{x}$. We have\n\t%\n\t\\[\n\t\\wp{\\cc}{\\ff} \\eeq \\lambda \\sigma_0 \\mydot \\sum_{\\sigma \\in \\partitionedstates{x}} \n\t\\wp{\\cc}{\\statepred{\\sigma}{\\varseq{x}}}(\\sigma_0) \\cdot \\ff(\\sigma)~. \n\t\\]\n\\end{theorem}\n\\begin{proof}\n\t\\label{proof:wp_prob_times_exp}\n\tBy induction on the structure of $\\cc$. For a state $\\sigma'$, we often abbreviate $\\statepred{\\sigma'}{\\varseq{x}}$ by $\\statepred{\\sigma'}{}$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{The case $\\cc = \\SKIP$.} We have\n\t%\n\t\\begin{align*}\n\t&\\wp{\\SKIP}{\\ff}(\\sigma_0) \\\\\n\t%\n\t\\eeq & \\ff(\\sigma_0)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq& \\statepred{\\sigma_0}{}(\\sigma_0) \\cdot \\ff(\\sigma_0) \n\t\\tag{$\\statepred{\\sigma_0}{}(\\sigma_0) = 1$} \\\\\n\t%\n\t\\eeq& \\wp{\\SKIP}{\\statepred{\\sigma_0}{}}(\\sigma_0) \\cdot \\ff(\\sigma_0) \n\t\\tag{$\\wp{\\SKIP}{\\statepred{\\sigma_0}{}} = \\statepred{\\sigma_0}{}$} \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma \\in \\partitionedstates{x}}\n\t\\wp{\\SKIP}{\\statepred{\\sigma}{}}(\\sigma_0) \\cdot \\ff(\\sigma) \n\t\\tag{there is exactly one $\\sigma \\in \\partitionedstates{x}$ with\n\t\t$\\wp{\\SKIP}{\\statepred{\\sigma}{}}(\\sigma_0) = 1$ and for this $\\sigma$ we have $\\equivstates{\\sigma}{\\varseq{x}}{\\sigma_0}$}~.\n\t\\end{align*}\n\t%\n\t%\n\t%\n\t\\emph{The case $\\ASSIGN{\\XX}{\\TT}$.}  We have\n\t%\n\t\\begin{align*}\n\t& \\wp{\\ASSIGN{\\XX}{\\TT}}{\\ff}(\\sigma_0) \\\\\n\t%\n\t\\eeq &  \\ff(\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}) \n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq & \\statepred{\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}{}}{}\n\t(\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}})\n\t\\cdot \n\t\\ff(\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}) \n\t\\tag{$\\statepred{\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}{}}{}\n\t\t(\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}) = 1$} \\\\\n\t%\n\t\\eeq& \\wp{\\ASSIGN{\\XX}{\\TT}}{\n\t\t\\statepred{\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}{}}{}\n\t}(\\sigma_0) \n\t\\cdot \n\t\\ff(\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}})\n\t\\tag{by definition}  \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma \\in \\partitionedstates{x}}\n\t\\wp{\\ASSIGN{\\XX}{\\TT}}{\\statepred{\\sigma}{}}(\\sigma_0) \\cdot \\ff(\\sigma) ~.\n\t\\tag{$\\substack{\\text{there is exactly one $\\sigma \\in \\partitionedstates{x}$ with\n\t\t$\\wp{\\ASSIGN{\\XX}{\\TT}}{\\statepred{\\sigma}{}}(\\sigma_0) = 1$} \\\\ \\text{and for this $\\sigma$ we have $\\equivstates{\\sigma}{\\varseq{x}}{\\sigma_0\\statesubst{\\XX}{\\sem{\\TT}{\\sigma_0}{}}}$}}$}\n\t\\end{align*}\n\t%\n\tAs the induction hypothesis now assume that the theorem holds for some arbitrary, but fixed programs $\\cc_1, \\cc_2$ and all postexpectations $\\ff$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{The case $\\cc = \\COMPOSE{\\cc_1}{\\cc_2}$.} We have\n\t%\n\t\\begin{align*}\n\t&\\wp{\\COMPOSE{\\cc_1}{\\cc_2}}{\\ff}(\\sigma_0) \\\\\n\t%\n\t\\eeq&\\wp{\\cc_1}{\\wp{\\cc_2}{\\ff}}(\\sigma_0)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq&\\sum_{\\sigma \\in \\partitionedstates{x}} \\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\wp{\\cc_2}{\\ff}(\\sigma)\n\t\\tag{I.H.\\ on $\\cc_1$} \\\\\n\t%\n\t\\eeq & \\sum_{\\sigma \\in \\partitionedstates{x}} \\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\sum_{\\sigma' \\in \\partitionedstates{x}} \\wp{\\cc_2}{\\statepred{\\sigma'}{}}(\\sigma)\n\t\\cdot \\ff(\\sigma')\n\t\\tag{I.H.\\ on $\\cc_2$} \\\\\n\t%\n\t\\eeq & \\sum_{\\sigma \\in \\partitionedstates{x}}  \\sum_{\\sigma' \\in \\partitionedstates{x}} \\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot\\wp{\\cc_2}{\\statepred{\\sigma'}{}}(\\sigma)\n\t\\cdot \\ff(\\sigma')\n\t\\tag{algebra} \\\\\n\t%\n\t\\eeq &  \\sum_{\\sigma' \\in \\partitionedstates{x}} \\sum_{\\sigma \\in \\partitionedstates{x}}  \\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot\\wp{\\cc_2}{\\statepred{\\sigma'}{}}(\\sigma)\n\t\\cdot \\ff(\\sigma')\n\t\\tag{algebra} \\\\\n\t%\n\t%\n\t\\eeq &  \\sum_{\\sigma' \\in \\partitionedstates{x}}  \\wp{\\cc_1}{\\wp{\\cc_2}{\\statepred{\\sigma'}{}}}(\\sigma_0)\n\t\\cdot \\ff(\\sigma')\n\t\\tag{I.H.\\ on $\\cc_1$} \\\\\n\t%\n\t%\n\t\\eeq &\\sum_{\\sigma' \\in \\partitionedstates{x}} \\wp{\\COMPOSE{\\cc_1}{\\cc_2}}{\\statepred{\\sigma'}{}}(\\sigma_0)\n\t\\cdot \\ff(\\sigma')~.\n\t\\tag{by definition}\n\t\\end{align*}\n\t%\n\t%\n\t\\emph{The case $\\cc = \\ITE{\\BB}{\\cc_1}{\\cc_2}$.} We distinguish the cases \n\t$\\iverson{\\BB}(\\sigma_0) = 1$ and $\\iverson{\\neg \\BB}(\\sigma_0) = 1$. For $\\iverson{\\BB}(\\sigma_0) = 1$, we have\n\t%\n\t\\begin{align*}\n\t& \\wp{\\ITE{\\BB}{\\cc_1}{\\cc_2}}{\\ff}(\\sigma_0) \\\\\n\t%\n\t\\eeq & \\iverson{\\BB}(\\sigma_0) \\cdot \\wp{\\cc_1}{\\ff}(\\sigma_0)\n\t+\n\t\\iverson{\\neg \\BB}(\\sigma_0) \\cdot \\wp{\\cc_2}{\\ff}(\\sigma_0)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq & \\iverson{\\BB}(\\sigma_0) \\cdot \\wp{\\cc_1}{\\ff}(\\sigma_0)\n\t\\tag{$\\iverson{\\neg \\BB}(\\sigma_0)=0$ by assumption} \\\\\n\t%\n\t\\eeq& \\iverson{\\BB}(\\sigma_0) \\cdot \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0) \\cdot \\ff(\\sigma_1) \n\t\\tag{I.H.\\ on $\\cc_1$} \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\\iverson{\\BB}(\\sigma_0) \\cdot \n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0) \\cdot \\ff(\\sigma_1) \n\t\\tag{algebra} \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\left(\n\t\\iverson{\\BB}(\\sigma_0) \\cdot \n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0)\n\t+\n\t\\iverson{\\neg \\BB}(\\sigma_0) \\cdot \\wp{\\cc_2}{\\statepred{\\sigma_1}{}}(\\sigma_0)\n\t\\right)\n\t\\cdot \\ff(\\sigma_1) \n\t\\tag{$\\iverson{\\neg \\BB}(\\sigma_0)=0$ by assumption} \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\wp{\\ITE{\\BB}{\\cc_1}{\\cc_2}}{\\sigma_1}(\\sigma_0)\n\t\\cdot \\ff(\\sigma_1) \n\t\\tag{by definition}~.\n\t\\end{align*}\n\t%\n\tThe case $\\iverson{\\neg \\BB}(\\sigma_0)=1$ is completely analogous. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{The case $\\cc = \\WHILEDO{\\BB}{\\cc_1}$.} This case is more involved.\n\t%\\charwp{\\BB}{\\cc'}{\\ff}(\\fg)\n\tFirst observe that for every $\\sigma_1 \\in \\States$,\n\t%\n\t\\begin{align}\n\t\\label{eqn:proof_thm_wp_prob_times_exp_1}\n\t\\sup_{k \\in \\Nats} \\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma_0)\n\t\\eeq\n\t\\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\statepred{\\sigma_1}{}}(\\sigma_0)~.\n\t\\tag{by Lemma~\\ref{lem:kleene_for_wp}}\n\t\\end{align}\n\t%\n\tWe proceed by induction on $k$ to show that\n\t%\n\t\\begin{align}\n\t&\\charwpn{\\BB}{\\cc_1}{\\ff}{k}(0)(\\sigma_0) \\notag \\\\\n\t%\n\t%\n\t\\eeq& \n\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i) \\notag \\\\\n\t%\n\t%\n\t\\eeq& \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1)~.\n\t\\label{eqn:proof_thm_wp_prob_times_exp_2}\n\t\\end{align}\n\t%\n\tThis implies the claim, since\n\t%\n\t\\begin{align*}\n\t&\\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\ff}(\\sigma_0) \\\\\n\t%\n\t\\eeq&\\sup_{k \\in \\Nats} \\charwpn{\\BB}{\\cc_1}{\\ff}{k}(0)(\\sigma_0)\n\t\\tag{by Lemma~\\ref{lem:kleene_for_wp}} \\\\\n\t%\n\t\\eeq& \\sup_{k \\in \\Nats}\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1)\n\t\\tag{by Equation~\\ref{eqn:proof_thm_wp_prob_times_exp_2}} \\\\\n\t%\n\t\\eeq& \\sup_{k \\in \\Nats} \\sup_{k' \\in \\Nats}\\sum\\limits_{i=0}^{k'}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sfsymbol{enum}(i)}{}}{k}(0)(\\sigma_0) \\cdot \\ff(\\sfsymbol{enum}(i))\n\t\\tag{choose some bijection $\\sfsymbol{enum}\\colon \\Nats \\to \\partitionedstates{x}$, value of infinite series is supremum of partial sums} \\\\\n\t\\eeq&\\sup_{k' \\in \\Nats} \\sup_{k \\in \\Nats} \\sum\\limits_{i=0}^{k'}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sfsymbol{enum}(i)}{}}{k}(0)(\\sigma_0) \\cdot \\ff(\\sfsymbol{enum}(i))\n\t\\tag{swap suprema} \\\\\n\t%\n\t\\eeq&\\sup_{k' \\in \\Nats}  \\sum\\limits_{i=0}^{k'} \\sup_{k \\in \\Nats}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sfsymbol{enum}(i)}{}}{k}(0)(\\sigma_0) \\cdot \\ff(\\sfsymbol{enum}(i))\n\t\\tag{algebra, sum is finite} \\\\\n\t%\n\t\\eeq& \\sup_{k' \\in \\Nats}  \\sum\\limits_{i=0}^{k'} \\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\statepred{\\sfsymbol{enum}(i)}{}}(\\sigma_0) \\cdot \\ff(\\sfsymbol{enum}(i)) \n\t\\tag{by Lemma~\\ref{lem:kleene_for_wp}} \\\\\n\t%\n\t\\eeq& \\sum_{\\sigma_1 \\in \\partitionedstates{x}} \\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\statepred{\\sigma_1}{}}(\\sigma_0) \\cdot \\ff(\\sigma_1) \n\t\\tag{value of infinite series is supremum of partial sums}~.\n\t\\end{align*}\n\t%\n\t%\n\t\\noindent\n\t\\emph{Base case $n=0$.} For $\\charwpn{\\BB}{\\cc_1}{\\ff}{0}(0)(\\sigma_0)$, we have\n\t%\n\t\\begin{align*}\n\t&\\charwpn{\\BB}{\\cc_1}{\\ff}{0}(0)(\\sigma_0) \\\\\n\t%\n\t\\eeq & 0 \\\\\n\t%\n\t\\eeq  &\\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)~.\n\t\\tag{empty sum evaluates to $0$}\n\t\\end{align*}\n\t%\n\tFor $\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{0}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1)$, we have\n\t%\n\t\\begin{align*}\n\t&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{0}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1) \\\\\n\t%\n\t\\eeq & \\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t0 \\cdot \\ff(\\sigma_1) \\\\\n\t%\n\t\\eeq & 0~.\n\t\\end{align*}\n\t%\n\tAs the induction hypothesis now assume that Equation~(\\ref{eqn:proof_thm_wp_prob_times_exp_2}) holds for some arbitrary, but fixed, $k\\in\\Nats$. \\\\ \\\\\n\t%\n\t\\noindent\n\t\\emph{Induction Step.} For $\\charwpn{\\BB}{\\cc_1}{\\ff}{k+1}(0)(\\sigma_0)$, we have\n\t%\n\t\\begin{align*}\n\t& \\charwpn{\\BB}{\\cc_1}{\\ff}{k+1}(0)(\\sigma_0) \\\\\n\t%\n\t\\eeq& \\charwp{\\BB}{\\cc_1}{k} \\left( \\charwpn{\\BB}{\\cc_1}{\\ff}{k}(0)\\right)(\\sigma_0)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq&\\iverson{\\BB}(\\sigma_0) \\cdot \\wp{\\cc_1}{\\charwpn{\\BB}{\\cc_1}{\\ff}{k}(0)}(\\sigma_0)\n\t+ \\iverson{\\neg\\BB}(\\sigma_0) \\cdot \\ff(\\sigma_0)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq&\\iverson{\\BB}(\\sigma_0)  \\\\\n\t& \\quad \\cdot \\wp{\\cc_1}{ \\lambda \\sigma_0 \\mydot\n\t\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\t\\cdot\n\t\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)    \n\t}(\\sigma_0) \\\\\n\t&\\quad + \\iverson{\\neg\\BB}(\\sigma_0) \\cdot \\ff(\\sigma_0)\n\t\\tag{I.H. on $k$} \\\\\n\t%\n\t%\n\t\\eeq&\\iverson{\\BB}(\\sigma_0) \\cdot\n\t\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma _0) \\\\\n\t& \\quad \\cdot \n\t\\left( \\lambda \\sigma_0 \\mydot\n\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)    \n\t\\right) (\\sigma_1) \\\\\n\t&\\quad + \\iverson{\\neg\\BB}(\\sigma_0) \\cdot \\ff(\\sigma_0)\n\t\\tag{I.H. on $\\cc_1$} \\\\\n\t%\n\t%\n\t\\eeq&\\iverson{\\BB}(\\sigma_0) \\cdot\n\t\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma _0) \\\\\n\t& \\quad \\cdot \n\t\\left( \n\t\\sum_{\\sigma_1,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k})\n\t\\cdot\n\t\\prod\\limits_{i=1}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)    \n\t\\right)  \\\\\n\t&\\quad + \\iverson{\\neg\\BB}(\\sigma_0) \\cdot \\ff(\\sigma_0)\n\t\\tag{applying $\\sigma_1$ and index shift} \\\\\n\t%\n\t%\n\t\\eeq&\n\t\\sum_{\\sigma_1 \\in \\partitionedstates{x}} \\iverson{\\BB}(\\sigma_0) \\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma _0) \\\\\n\t& \\quad \\cdot \n\t\\left( \n\t\\sum_{\\sigma_1,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k})\n\t\\cdot\n\t\\prod\\limits_{i=1}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)    \n\t\\right)  \\\\\n\t&\\quad + \\iverson{\\neg\\BB}(\\sigma_0) \\cdot \\ff(\\sigma_0)\n\t\\tag{algebra} \\\\\n\t%\n\t%\n\t\\eeq&\n\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i) ~.\n\t%\n\t\\tag{see below} \n\t\\end{align*}\n\t%\n\tTo see that the last step is sound, distinguish the cases $\\iverson{\\BB}(\\sigma_0) =1$\n\tand $\\iverson{\\BB}(\\sigma_0)=0$. If $\\iverson{\\BB}(\\sigma_0)=1$, then \n\t$\\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_1}{}}(\\sigma_0)\n\t= \\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0)$. Conversely, if $\\iverson{\\BB}(\\sigma_0)=0$, then there is \\emph{exactly one}\n\tsequence of states $\\sigma_0, \\ldots,\\sigma_k = \\sigma_0, \\ldots, \\sigma_0$ such that\n\t%\n\t\\[\n\t\\prod\\limits_{i=0}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)\n\t\\]\n\t%\n\tevaluates to $1$. For all other sequences, the above product evaluates to $0$. This gives us \n\t%\n\t\\begin{align*}\n\t&\\sum_{\\sigma_0,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i) \\\\\n\t%\n\t\\eeq& \n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{0})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{0}}{}}(\\sigma_0)  \\\\\n\t%\n\t\\eeq & (\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{0})~,\n\t\\end{align*}\n\t%\n\twhich completes this case. \\\\ \\\\\u00a0\n\t%\n\t%\n\t\\noindent\n\tFor $\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k+1}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1)$, we have\n\t%\n\t%\n\t\\begin{align*}\n\t&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k+1}(0)(\\sigma_0) \\cdot \\ff(\\sigma_1) \\\\\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\charwp{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}(\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0))(\\sigma_0)\n\t\\cdot \\ff(\\sigma_1) \n\t\\tag{by definition}\\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\left(\n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)}(\\sigma_0)\n\t+ (\\iverson{\\neg\\BB} \\cdot \\statepred{\\sigma_1}{})(\\sigma_0)\n\t\\right)\n\t\\cdot \\ff(\\sigma_1)\n\t\\tag{by definition} \\\\\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)}(\\sigma_0)\n\t\\cdot \\ff(\\sigma_1) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{$(\\iverson{\\neg\\BB} \\cdot \\statepred{\\sigma_1}{})(\\sigma_0) \\neq 0$ \n\t\tonly if $\\equivstates{\\sigma_0}{\\varseq{x}}{\\sigma_1}$} \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}}\n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\left(\\sum_{\\sigma \\in \\partitionedstates{x}}\n\t\\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma)\\right)\n\t\\cdot \\ff(\\sigma_1) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{I.H.\\ on $\\cc_1$} \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}} \\sum_{\\sigma \\in \\partitionedstates{x}}\n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma)\n\t\\cdot \\ff(\\sigma_1) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{algebra} \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma \\in \\partitionedstates{x}} \\sum_{\\sigma_1 \\in \\partitionedstates{x}} \n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma)\n\t\\cdot \\ff(\\sigma_1) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{swap sums} \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma \\in \\partitionedstates{x}} \n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0)\n\t\\cdot \\left(\n\t\\sum_{\\sigma_1 \\in \\partitionedstates{x}} \\charwpn{\\BB}{\\cc_1}{\\statepred{\\sigma_1}{}}{k}(0)(\\sigma)\n\t\\cdot \\ff(\\sigma_1) \\right) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{algebra} \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma \\in \\partitionedstates{x}} \n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma}{}}(\\sigma_0) \\\\\n\t%\n\t& \\quad \\cdot \\left(\n\t%\n\t%\n\t\\lambda \\sigma_0 \\mydot \\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)\n\t%\n\t%\n\t\\right)(\\sigma) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{I.H. on $k$} \\\\ \n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}} \n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0) \\\\\n\t%\n\t& \\quad \\cdot \\left(\n\t%\n\t%\n\t\\lambda \\sigma_0 \\mydot \\sum_{\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k-1})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)\n\t%\n\t%\n\t\\right)(\\sigma_1) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{rename $\\sigma$ by $\\sigma_1$} \\\\ \\\\\n\t%\n\t%\n\t\\eeq&\\sum_{\\sigma_1 \\in \\partitionedstates{x}} \n\t\\iverson{\\BB}(\\sigma_0)  \n\t\\cdot\n\t\\wp{\\cc_1}{\\statepred{\\sigma_1}{}}(\\sigma_0) \\\\\n\t%\n\t& \\quad \\cdot \\left(\n\t%\n\t%\n\t\\sum_{\\sigma_1,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k}) \n\t\\cdot \n\t\\prod\\limits_{i=1}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i)\n\t%\n\t%\n\t\\right) \\\\\n\t&\n\t+ (\\iverson{\\neg\\BB} \\cdot \\ff)(\\sigma_0)\n\t\\tag{applying $\\sigma_1$ and index shift} \\\\ \n\t%\n\t\\eeq&\n\t\\sum_{\\sigma_0,\\ldots,\\sigma_{k} \\in \\partitionedstates{x}}\n\t(\\iverson{\\neg \\BB} \\cdot \\ff)(\\sigma_{k})\n\t\\cdot\n\t\\prod\\limits_{i=0}^{k-1} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{}}(\\sigma_i) ~.\n\t%\n\t\\tag{see reasoning for previous case}\n\t\\end{align*}\n\t%\n\tThis completes the proof.\n\\end{proof}\n\n\n\n\n\n\n\\subsection{Proof of \\Cref{thm:expressive}}\n\\label{proof:epressiveness_appendix}\nWe employ an auxiliary result.\n    \\begin{lemma}\n\t\\label{lem:express_statepred_exp}\n\tLet $\\cc \\in \\pgcl$. Then, for every $\\sigma \\in \\States$, we have\n\t%\n\t\\begin{align*}\n\t\\wp{\\cc}{\\statepred{\\sigma}{\\varseq{x}}} \\eeq \n\t\\wp{\\cc}{\\iverson{x_0 = x_0' \\wedge \\ldots \\wedge x_{n-1}=x_{n-1}'}}\n\t\\left[ x_0' / \\sigma(x_0) , \\ldots ,  x_{n-1}' / \\sigma(x_{n-1}) \\right]~.\n\t\\end{align*}\n\t%\n\\end{lemma} \n%\n\\begin{proof}\n\tBy induction on $\\cc$.\n\\end{proof}\n\n\n\nSince we encode program states $\\sigma$ as G\\\"odel numbers $\\seqnum{\\sigma}$, we define for every $\\FF \\in \\SyntE$ a syntactic expectation $\\gsubst{\\varseq{x}}{\\FF}{\\VV}$ such that $\\gsubst{\\varseq{x}}{\\FF}{\\seqnum{\\sigma}}$ is equivalent to the syntactic expectation obtained from substituting every $x \\in \\varseq{x}$ by $\\sigma(x)$ in $\\FF$. For that, let $\\VV_0,\\ldots,\\VV_{n-1}$ be fresh variables not occurring in $\\FF$. Now define\n%\n\\begin{align*}\n&\\gsubst{\\varseq{x}}{\\FF}{\\VV} \\\\\n%\n\\ddefeq&\n\\Sup \\VV_0 \\colon \\ldots \\colon \\Sup \\VV_{n-1} \\colon\n\\iverson{\\rseqelem{\\VV}{0}{\\VV_0}\n\t\\wedge \\ldots \\wedge \\rseqelem{\\VV}{n-1}{\\VV_{n-1}}}\n\\exprod\n\\FF\n\\left[ x_0 / \\VV_0 , \\ldots ,  x_{n-1} / \\VV_{n-1} \\right]~.\n\\end{align*}\n%\n%\n%\n\\begin{lemma}\n\t\\label{lem:subst_goedel}\n\t%Let $f \\in \\SyntE$, $\\varseq{x} = \\{x_0,\\ldots,x_{n-1}\\}$, and\n\t%let $\\VV_0,\\ldots,\\VV_{n-1}$ be fresh logical variables.\n\t%Then, for every $\\gnum = \\seqnum{\\sigma}_{\\varseq{x}}$ with $\\sigma \\in \\States$, we have\n\t%\n\tFor every $\\sigma \\in \\States$ and $\\gnum = \\seqnum{\\sigma}$, we have\n\t%\n\t\\begin{align*}\n\t\\FF\\left[ x_0 / \\sigma(x_0) , \\ldots ,  x_n / \\sigma(x_n) \\right] \n\t\\eequiv\n\t\\gsubst{x}{\\FF}{\\gnum}~.\n\t\\end{align*}\n\t%\n\\end{lemma}\n%\n\\begin{proof}\n\tSee Appendix~\\ref{proof:subst_goedel}.\n\\end{proof}\n%\n%\nIf $\\FV{\\FF} \\subseteq \\varseq{x}$, then substituting every $x \\in \\varseq{x}$ by $\\sigma'(x)$ in $\\FF$ corresponds to \\emph{evaluating} $\\eval{\\FF}$ in $\\sigma'$:\n%\n\\begin{lemma}\n\t%\n\t\\label{lem:apply_goedel}\n\t%Let $\\FF \\in \\SyntEStates$ and $\\FV{\\FF} \\subseteq \\varseq{x} = \\{x_0,\\ldots,x_{n-1}\\}$.\n\t%Then, for all states $\\sigma, \\sigma'$ and every $\\gnum = \\seqnum{\\sigma'}_{\\varseq{x}}$, we have\n\tIf $\\FV{\\FF} \\subseteq \\varseq{x}$, then , for all states $\\sigma, \\sigma'$ and every $\\gnum = \\seqnum{\\sigma'}$, we have\n\t%\n\t\\[\n\t\\sem{\\gapply{x}{\\FF}{\\gnum}}{\\sigma}{\\interpret}\n\t\\eeq\n\t\\sem{\\FF}{}{}(\\sigma')~.\n\t\\]\n\t%\n\\end{lemma}\n\\begin{proof}\n\tSee Appendix~\\ref{proof:apply_goedel}.\n\\end{proof}\n%\nIn particular, $\\sem{\\gapply{x}{\\FH}{\\VV}}{\\sigma}{\\interpret}$ is independent of $\\sigma$ since $\\gapply{x}{\\FH}{\\VV}$ does not contain free program variables. \\\\ \\\\\n%\n%\n\\noindent\n\\emph{Proof of of \\Cref{thm:expressive}.}\n\nWe prove that\n\n\\begin{align*}\n&\\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\sem{\\FF}{}{}}(\\sigma)   \\\\\n%\n\\eeq & \\semleft{\\Sup length \\colon \\Sup nums \\colon\n\t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{\\sigma}{} \\\\\n%\n%\n&\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n\\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright ~.\n%\n\\end{align*}\n%\nAssuming that $\\pathexpsymbol$ satisfies Equations (\\ref{eqn:pathexp_spec_1}) and (\\ref{eqn:pathexp_spec_2}), we have\n%\n\\begin{align*}\n& \\semleft{\\Sup length \\colon \\Sup nums \\colon\n\t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{\\sigma}{} \\\\\n%\n%\n&\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n\\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright \\\\\n%\n%\n\\eeq&  \\sup \\big\\{\n\\semleft{ \\Sup nums \\colon\n\t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{\\sigma\\statesubst{length}{r}}{} \\\\\n%\n%\n&\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n\\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright \n~\\mid~ {r \\in \\PosRats} \\big\\}\n\\tag{by definition} \\\\\n%\n%\n\\eeq&\\sup_{r \\in \\PosRats}\n\\sem{\\Sup nums \\colon\n\t\\gsum{\\iverson{\\stateseq{x}{\\vsum}{r}} \\exprod\t\\pathexp{r}{\\vsum}}{nums}}{\\sigma}{\\interpret}\n\\tag{rewrite supremum} \\\\\n%\n\\eeq&\\sup_{r\\in \\PosRats} \\sum\\limits_{j=0}^{\\infty}\n\\sem{\\iverson{\\stateseq{x}{\\vsum}{r}} \\exprod\t\\pathexp{r}{\\vsum}}{\\sigma\\statesubst{\\vsum}{j}}{\\interpret\\statesubst{\\vsum}{j}}\n\\tag{by Theorem~\\ref{thm:sum_exp}} \\\\\n%\n\\eeq & \\sup_{r\\in \\PosRats} \\sum\\limits_{j=0}^{\\infty}\n\\sem{\\iverson{\\stateseq{x}{j}{r}} \\exprod\t\\pathexp{r}{j}}{\\sigma}{\\interpret}\n\\tag{Lemma \\ref{lem:substitution}} \\\\\n%\n\\eeq & \\sup_{k\\in \\Nats} \\sum_{j=0}^{\\infty}\n\\sem{\\iverson{\\stateseq{x}{j}{r}} \\exprod \\pathexp{k}{j}}{\\sigma}{\\interpret}\n\\tag{$\\pathexp{r}{j}=0$, if $r \\not\\in \\Nats$, replace $r$ by $k$} \\\\\n% \n\\eeq & \\sup_{k\\in \\Nats} \\sum_{\\substack{j=\\seqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}\n\t\t\\\\ \\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x} \\\\ \\equivstates{\\sigma_0}{\\varseq{x}}{\\sigma}}}\n\\sem{\\pathexp{k}{j}}{\\sigma}{\\interpret}\n\\tag{for every sequence $\\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}$ there is exactly one G\\\"odel number and $\\equivstates{\\sigma_0}{\\varseq{x}}{\\sigma}$} \\\\\n%\n%\n%\n\\eeq& \\sup_{k\\in \\Nats} \\sum_{\\substack{j=\\seqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}\n\t\t\\\\ \\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}} \\statepred{\\sigma_0}{\\varseq{x}}(\\sigma) \\cdot\n(\\iverson{\\neg \\BB} \\cdot \\sem{\\FF}{}{})(\\sigma_{k-1})\n\\cdot\n\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}{}}{}}(\\sigma_i)\n%\n\\tag{by Equation~(\\ref{eqn:pathexp_spec_1}) and $\\statepred{\\sigma_0}{\\varseq{x}}(\\sigma) = 1$ iff $\\equivstates{\\sigma_0}{\\varseq{x}}{\\sigma}$} \\\\\n%\n\\eeq& \\sup_{k\\in \\Nats} \\sum_{ \\sigma_0,\\ldots,\\sigma_{k-1} \\in \\partitionedstates{x}}\n\\statepred{\\sigma_0}{\\varseq{x}}(\\sigma) \\cdot\n(\\iverson{\\neg \\BB} \\cdot \\sem{\\FF}{}{})(\\sigma_{k-1})\n\\cdot\n\\prod\\limits_{i=0}^{k-2} \\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}{}}{}}(\\sigma_i)\n\\tag{product does not depend on $j$} \\\\\n%\n%\n\\eeq& \\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\sem{\\FF}{}{}}(\\sigma)  \n\\tag{by Theorem~\\ref{thm:wp_loop_as_sum}}~.\n\\end{align*}\n%\n%\nIt remains to give $\\pathexp{\\VV_1}{\\VV_2}$.\nBy I.H., there is a $\\FG \\in \\SyntE$ with  \n%\n\\[\n\\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\iverson{x_0 = x_0' \\wedge \\ldots \\wedge x_n=x_n'}} \\eeq \\eval{\\FG}~.\n\\]\n%\nHence, by Lemma~\\ref{lem:express_statepred_exp}, we have for every $\\sigma \\in \\States$:\n%\n\\begin{align}\n\\label{eqn:g_express_wp_body}\n\\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma}{\\varseq{x}}}\n\\eeq\n\\eval{\\FG\\left[ x_0' / \\sigma(x_0) , \\ldots ,  x_n' / \\sigma(x_n) \\right]}\n\\end{align}\n%\n%\n%\n%\n%\nNow define\n%\n%\n%\n\\begin{align*}\n&\\pathexp{\\VV_1}{\\VV_2} \\\\\n%\n\\ddefeq & \n%\n\\iverson{\\VV_1 < 2} \\cdot (\\Sup \\gnum \\colon \\iverson{\\seqelem{\\VV_2}{\\VV_1 -1}{\\gnum}}\n\\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}) \\\\\n%\n+& \\iverson{\\VV_1 \\geq 2} \\cdot\n%\n(\\Sup \\gnum \\colon \\iverson{\\seqelem{\\VV_2}{\\VV_1 -1}{\\gnum}}\n\\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}) \\\\\n%\n&\\quad\\exprod\n\\gproductsymbol \\big(\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n\\iverson{\\seqelem{\\VV_2}{\\vprod}{\\gnum_1} \\wedge \\seqelem{\\VV_2}{\\vprod+1}{\\gnum_2}} \\\\\n&\\qquad  \\quad \n\\exprod\n\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}, \\VV_1 - 2 \\big)\n%\n%\n\\end{align*}\n%\nHere $\\Sup \\gnum \\colon \\iverson{\\seqelem{\\VV_2}{\\VV_1 -1}{\\gnum}} \\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}$ is a shorthand for \n%\n\\[\n\\Sup \\gnum \\colon \\Sup \\VV \\colon \\iverson{\\VV +1 = \\VV_1} \\cdot \\iverson{\\seqelem{\\VV_2}{\\VV}{\\gnum}} \\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}~.\n\\]\n%\nSimilarily, $\\gproduct{\\ldots}{\\VV_1 -2}$ is shorthand for\n%\n\\[\n\\Sup \\VV \\colon \\iverson{\\VV + 2 = \\VV_1} \\cdot \\gproduct{\\ldots}{\\VV}~.\n\\]\n%\nWe now show that $\\pathexp{\\VV_1}{\\VV_2}$ indeed satisfies the specification from (\\ref{eqn:pathexp_spec_1}) and (\\ref{eqn:pathexp_spec_2}). We distinguish the following cases: \\\\ \\\\\n%\n%\n\\noindent\n\\emph{The case $\\sigma(\\VV_1) \\not\\in \\Nats$.} By Theorem~\\ref{thm:fo_rats_subsumes_fo_nats}, we have \n%\n\\[\n\\sem{\\Sup \\gnum \\colon \\iverson{\\seqelem{\\VV_2}{\\VV_1 -1}{\\gnum}} \\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}}{\\sigma}{\\interpret} = 0\n\\]\n%\nand hence $\\sem{\\pathexp{\\VV_1}{\\VV_2}}{\\sigma}{\\interpret} = 0$. \\\\ \\\\\n%\n%\n\\noindent\n\\emph{The case $\\sigma(\\VV_1) = 0$.} In this case, we have\n%\n\\[\n\\sem{\\iverson{\\VV +1 = \\VV_1}}{\\sigma\\statesubst{\\VV}{\\RR}}{\\interpret\\statesubst{\\VV}{\\RR}} \\eeq 0\n\\]\n%\nfor all $\\RR \\in \\PosRats$ and thus $\\sem{\\pathexp{\\VV_1}{\\VV_2}}{\\sigma}{\\interpret} = 0$. \\\\ \\\\\n%\n%\n\\noindent\n\\emph{The case $\\sigma(\\VV_1) = 1$ and $\\sigma(\\VV_2) = \\stateseqnum{\\sigma_0}$.} We have\n%\n\\begin{align*}\n&\\sem{\\pathexp{1}{\\stateseqnum{\\sigma_0}}}{\\sigma}{\\interpret} \\\\\n%\n%\n%\n\\eeq&\\sem{\\Sup \\gnum \\colon \\iverson{\\seqelem{\\stateseqnum{\\sigma_0}}{0}{\\gnum}}\n\t\\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum}}{\\sigma}{\\interpret}\n\\tag{$\\sem{\\iverson{\\VV_1 \\geq 2}}{\\sigma}{\\interpret} = 0$\n\tand $\\sem{\\iverson{\\VV_1 < 2}}{\\sigma}{\\interpret} = 1$} \\\\\n%\n%\n\\eeq&\\sem{\\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\seqnum{\\sigma_0}}}{\\sigma}{\\interpret}\n\\tag{$\\sem{\\iverson{\\seqelem{\\stateseqnum{\\sigma_0}}{0}{\\gnum}}}{\\sigma}{\\interpret} = 1$ only for $\\sigma(\\gnum) = \\seqnum{\\sigma_0}$} \\\\\n%\n\\eeq & \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_0)\n\\tag{by Lemma~\\ref{lem:apply_goedel}} \\\\\n%\n\\eeq&(\\iverson{\\neg b} \\cdot \\sem{\\FF}{}{})(\\sigma_0)\n\\cdot\n\\prod\\limits_{i=0}^{\\sigma(\\VV_1)-2} \\wp{\\ITE{b}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}{}}{}}(\\sigma_i)~.\n\\tag{empty product equals $1$}\n\\end{align*}\n\n\\noindent\n\\emph{The case $\\sigma(\\VV_1) = k \\in \\Nats$ with $k \\geq 2$ and $\\sigma(\\VV_2) = \\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}$.} We have\n%\n%\n\\begin{align*}\n%\n&\\sem{\\pathexp{k}{\\stateseqnum{\\sigma_0, \\ldots, \\sigma_{k-1}}}}{\\sigma}{\\interpret} \\\\\n%\n%\n\\eeq& \\semleft{(\\Sup \\gnum \\colon \\iverson{\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{k -1}{\\gnum}}\n\t\\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum})}{\\sigma}{\\interpret} \\\\\n%\n&\\quad\\exprod\n\\gproductsymbol \\big(\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n[\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod}{\\gnum_1}\\\\\n& \\qquad \\quad \\wedge \\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod+1}{\\gnum_2}] %\n%\n\\exprod\n\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}, k - 2 \\big)\n\\semright\n\\tag{$\\sem{\\iverson{\\VV_1 \\geq 2}}{\\sigma}{\\interpret} = 1$\n\tand $\\sem{\\iverson{\\VV_1 < 2}}{\\sigma}{\\interpret} = 0$} \\\\\n%\n%\n\\eeq& \\semleft{(\\Sup \\gnum \\colon \\iverson{\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{k -1}{\\gnum}}\n\t\\exprod \\gapply{x}{(\\iverson{\\neg b} \\cdot f)}{\\gnum})}{\\sigma}{\\interpret} \\semright \\\\\n%\n&\\quad\\cdot\\semleft{\n\t\\gproductsymbol \\big(\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n\t[\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod}{\\gnum_1}}{\\sigma}{\\interpret}\\\\\n& \\qquad \\quad \\wedge \\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod+1}{\\gnum_2}] %\n%\n\\exprod\n\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}, k  -2 \\big)\n\\semright\n\\tag{by Theorem~\\ref{cor:unrestricted_product}}\\\\\n%\n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1}) \\\\\n%\n&\\quad\\cdot\\semleft{\n\t\\gproductsymbol \\big(\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n\t[\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod}{\\gnum_1}}{\\sigma}{\\interpret}\\\\\n& \\qquad \\quad \\wedge \\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{\\vprod+1}{\\gnum_2}] %\n%\n\\exprod\n\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}, k -2  \\big)\n\\semright\n\\tag{see reasoning for previous case} \\\\\n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1})  \\\\\n%\n&\\quad\\cdot\n\\prod\\limits_{i=0}^{k-2 }\\semleft{\\Sup \\gnum_1 \\colon \\Sup \\gnum_2 \\colon\n\t[\\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{i}{\\gnum_1}}{\\sigma}{\\interpret}\\\\\n& \\qquad \\qquad\\quad  \\wedge \\seqelem{\\stateseqnum{\\sigma_0,\\ldots,\\sigma_{k-1}}}{i+1}{\\gnum_2}] %\n%\n\\exprod\n\\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\gnum_2}}{\\gnum_1}\n\\semright\n\\tag{by Theorem~\\ref{thm:prod_exp} and $k \\geq 2$ by assumption} \\\\\n%\n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1})  \\\\\n%\n&\\quad\\cdot\n\\prod\\limits_{i=0}^{k-2 }\\sem{ \\gapply{\\varseq{x}}{\\gsubst{\\varseq{x'}}{g}{\\seqnum{\\sigma_{i+1}}}}{\\seqnum{\\sigma_{i}}}}{\\sigma}{\\interpret}\n\\tag{$\\Sup$ quantifiers enforce $\\sigma(\\gnum_1) = \\seqnum{\\sigma_i}$\n\tand $\\sigma(\\gnum_2) = \\seqnum{\\sigma_{i+1}}$} \\\\\n%\n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1})  \\\\\n%\n&\\quad\\cdot\n\\prod\\limits_{i=0}^{k-2 }\\sem{ \\gapply{\\varseq{x}}{\\FG\\left[ x_0' / \\sigma_{i+1}(x_0) , \\ldots ,  x_n' / \\sigma_{i+1}(x_n) \\right] }{\\seqnum{\\sigma_{i}}}}{\\sigma}{\\interpret}\n\\tag{by Lemma~\\ref{lem:subst_goedel}} \\\\\n%\n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1})  \\\\\n%\n&\\quad\\cdot\n\\prod\\limits_{i=0}^{k-2 }\\sem{ \\FG\\left[ x_0' / \\sigma_{i+1}(x_0) , \\ldots ,  x_n' / \\sigma_{i+1}(x_n) \\right] }{}{}(\\sigma_i)\n\\tag{by Lemma~\\ref{lem:apply_goedel}}  \\\\\n%        \n%\n\\eeq& \\sem{\\iverson{\\neg b} \\cdot \\FF}{}{}(\\sigma_{k-1})  \\\\\n%\n&\\quad\\cdot\n\\prod\\limits_{i=0}^{k-2 }\\wp{\\ITE{\\BB}{\\cc_1}{\\SKIP}}{\\statepred{\\sigma_{i+1}}{\\varseq{x}}}(\\sigma_i)~,\n\\tag{by Equation~\\ref{eqn:g_express_wp_body}} \n%        \n\\end{align*}\n%\n%\nwhich is what we had to show. Hence, we finally obtain\n%\n\\begin{align*}\n& \\wp{\\WHILEDO{\\BB}{\\cc_1}}{\\sem{\\FF}{}{}} \\\\\n\\eeq \n& \\semleft{\\Sup length \\colon \\Sup nums \\colon\n\t\\gsumsymbol\\big[\\vsum, \\iverson{\\stateseq{x}{\\vsum}{length}}}{}{} \\\\\n%\n%\n&\\qquad \\qquad \\qquad \\qquad\\qquad\\qquad \\qquad \n\\exprod\t\\pathexp{length}{\\vsum}, {nums} \\big] \\semright ~.\n\\end{align*}\n%\nThis completes the proof.\n\n\n\n\n\n\n\n\n\\subsection{Proof of Lemma~\\ref{lem:subst_goedel}}\n\n\\begin{proof}\n\t\\label{proof:subst_goedel}\n\tWe have\n\t%\n\t\\begin{align*}\n\t& \\gsubst{x'}{\\FF}{\\gnum} \\\\\n\t%\n\t\\eequiv& \\Sup \\VV_0 \\colon \\ldots \\colon \\Sup \\VV_{n-1} \\colon\n\t\\iverson{\\rseqelem{\\gnum}{0}{\\VV_0}\n\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\VV_{n-1}}}\n\t\\exprod\n\t\\FF\n\t\\left[ x_0' / \\VV_0 , \\ldots ,  x_{n-1}' / \\VV_{n-1} \\right]\n\t\\tag{by definition} \\\\\n\t%\n\t\\eequiv & \n\t\\iverson{\\rseqelem{\\gnum}{0}{\\sigma(x_0)}\n\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\sigma(x_{n-1})}}\n\t\\exprod\n\t\\FF\n\t\\left[ x_0' / \\sigma(x_{0}) , \\ldots ,  x_{n-1}' / \\sigma(x_{n-1}) \\right]\n\t\\tag{for $0 \\leq j \\leq n-1$, $\\rseqelem{\\gnum}{j}{m} \\equiv 1$ only for $m = \\sigma(x_j)$} \\\\\n\t%\n\t\\eequiv & \\FF\n\t\\left[ x_0' / \\sigma(x_{0}) , \\ldots ,  x_{n-1}' / \\sigma(x_{n-1}) \\right]~.\n\t\\tag{$\\iverson{\\rseqelem{\\gnum}{0}{\\sigma(x_0)}\n\t\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\sigma(x_{n-1})}} \\equiv 1$}\n\t\\end{align*}\n\t\n\\end{proof}\n\n\n\\subsection{Proof of Lemma~\\ref{lem:apply_goedel}}\n\n\\begin{proof}\n\t\\label{proof:apply_goedel}\n\t\n\tWe have\n\t%\n\t\\begin{align*}\n\t& \\sem{\\gapply{x}{\\FF}{\\gnum}}{\\sigma}{\\interpret} \\\\\n\t%\n\t\\eeq & \\sem{\\Sup \\VV_0 \\colon \\ldots \\colon \\Sup \\VV_{n-1} \\colon\n\t\t\\iverson{\\rseqelem{\\gnum}{0}{\\VV_0}\n\t\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\VV_{n-1}}}\n\t\t\\exprod\n\t\t\\FF\n\t\t\\left[ x_0 / \\VV_0 , \\ldots ,  x_{n-1} / \\VV_{n-1} \\right]}{\\sigma}{\\interpret}\n\t\\tag{by definition} \\\\\n\t%\n\t%\n\t\\eeq& \\sem{\\iverson{\\rseqelem{\\gnum}{0}{\\sigma'(x_0)}\n\t\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\sigma'(x_{n-1})}}\n\t\t\\exprod\n\t\t\\FF\n\t\t\\left[ x_0 / \\sigma'(x_0) , \\ldots ,  x_{n-1} / \\sigma'(x_{n-1}) \\right]}{\\sigma}{\\interpret}\n\t\\tag{for $0 \\leq j  \\leq n-1$, $\\sem{\\rseqelem{\\gnum}{j}{\\VV_{j}}}{\\sigma}{\\interpret} = 1$ only for $\\sigma(\\VV_j) = \\sigma'(x_j)$, Lemma~\\ref{lem:substitution}} \\\\\n\t%\n\t%\n\t\\eeq &\\sem{\\FF\n\t\t\\left[ x_0 / \\sigma'(x_0) , \\ldots ,  x_{n-1} / \\sigma'(x_{n-1}) \\right]}{\\sigma}{\\interpret}\n\t\\tag{$\\iverson{\\rseqelem{\\gnum}{0}{\\sigma'(x_0)}\n\t\t\t\\wedge \\ldots \\wedge \\rseqelem{\\gnum}{n-1}{\\sigma'(x_{n-1})}} \\eequiv 1$} \\\\\n\t%\n\t\\eeq &\\sem{\\FF}{}{}(\\sigma')~.\n\t\\tag{$\\Vars(\\sem{\\FF}{}{})\\subseteq \\FV{\\FF} \\subseteq  \\varseq{x}$ and Lemma~\\ref{lem:substitution}}\n\t\\end{align*}\n\t\n\t\n\\end{proof}\n\n \n\\end{document}", "meta": {"timestamp": "2020-10-29T00:01:50", "yymm": "2010", "arxiv_id": "2010.14548", "url": "https://arxiv.org/abs/2010.14548", "source": "arxiv"}}
{"text": "\\documentclass[11pt,reqno]{amsart}\r\n\\usepackage{amsmath, amsthm, amssymb}\r\n%\\usepackage{amsmath, amsthm, amssymb, stmaryrd}\r\n%\\usepackage{fullpage}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{array}\r\n\\usepackage{caption}\r\n\\topmargin 0.0cm\r\n  \\textheight 22.2cm\r\n\\oddsidemargin 0.8cm\r\n\\evensidemargin \\oddsidemargin\r\n\\marginparwidth 2cm\r\n\\textwidth 15.2cm\r\n\\def\\a{{\\mathbf a}}\r\n\\def\\c{{\\mathbf c}}\r\n\\def\\b{{\\mathbf b}}\r\n\\def\\B{\\mathcal B}\r\n\\def\\e{\\varepsilon}\r\n\\def\\bfh{{\\mathbf h}}\r\n\\def\\bfb{{\\mathbf b}}\r\n\\def\\bfc{{\\mathbf c}}\r\n\\def\\bfy{{\\mathbf y}}\r\n\\def\\bfx{{\\mathbf x}}\r\n\\def\\bfz{{\\mathbf z}}\r\n\\def\\bfr{{\\mathbf r}}\r\n\\def\\bfw{{\\mathbf w}}\r\n\\def\\bfv{{\\mathbf v}}\r\n\\def\\bfgamma{{\\boldsymbol \\gamma}}\r\n\\def\\bfalpha{{\\boldsymbol \\alpha}}\r\n\\def\\numset#1{{\\mathbb #1}}\r\n\\newtheorem{thm}{Theorem}\r\n\\newtheorem{cor}{Corollary}\r\n\\newtheorem{propos}{Proposition}\r\n\\newtheorem{problem}{Problem}\r\n\\newtheorem{remark}{Remark}\r\n\\newtheorem{lem}{Lemma}\r\n\\newtheorem{claim}{Claim}\r\n\\newtheorem{conj}{Conjecture}\r\n\\newtheorem{defn}{Definition}\r\n\\newtheorem{exam}{Example}\r\n\\newtheorem{prop}{Proposition}\r\n\\newcommand{\\mmod}[1]{\\,\\,(\\text{\\rm mod}\\,\\, #1)}\r\n\\newcommand{\\E}{\\ensuremath{\\mathbb E}}\r\n\\newcommand{\\U}{\\ensuremath{\\mathcal U}}\r\n\\numberwithin{equation}{section} \\numberwithin{thm}{section}\r\n\\numberwithin{lem}{section} \\numberwithin{problem}{section}\r\n\\numberwithin{cor}{section}\r\n\\newcommand{\\cc}{\\mathbf c}\r\n\\newcommand{\\ccc}{\\overline{\\mathbf c}}\r\n\\newcommand{\\aaa}{\\overline{\\alpha}}\r\n\\newcommand{\\p}{\\mathbf p}\r\n\\newcommand{\\ex}{\\text{ex}}\r\n\\def\\grm{{\\mathfrak m}}\\def\\grM{{\\mathfrak M}}\\def\\grN{{\\mathfrak N}}\\def\\grn{{\\mathfrak n}}\r\n\\newcommand{\\q}{\\mathbf q}\r\n\\newcommand{\\rr}{\\mathbf r}\r\n\\newcommand{\\pp}{\\overline{\\mathbf p}}\r\n\\newcommand{\\qq}{\\overline{\\mathbf q}}\r\n\\newcommand{\\nuu}{\\overline{\\mathbf \\nu}}\r\n\\newcommand{\\Real}{\\mathbb R}\r\n\\newcommand{\\RPlus}{\\Real^{+}}\r\n\\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert}\r\n\\newcommand{\\abs}[1]{\\left\\vert#1\\right\\vert}\r\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\r\n\\newcommand{\\seq}[1]{\\left<#1\\right>}\r\n\\newcommand{\\eps}{\\varepsilon}\r\n\\newcommand{\\To}{\\longrightarrow}\r\n\\newcommand{\\BX}{\\mathbf{B}(X)}\r\n\\newcommand{\\A}{\\mathcal{A}}\r\n\\newcommand{\\Ha}{\\mathcal{H}}\r\n\\newcommand{\\Beta}{B}\r\n\\newcommand{\\Ar}{\\text{Arc}}\r\n\\newcommand{\\M}{\\mathcal{M}}\r\n\\newcommand{\\G}{\\mathcal{G}}\r\n\\newcommand{\\W}{\\mathcal{W}}\r\n\\newcommand{\\N}{\\mathcal{N}}\r\n\\newcommand{\\Ll}{\\mathcal{L}}\r\n\\newcommand{\\Fa}{\\mathcal{F}}\r\n\\newcommand{\\Z}{\\mathbb{Z}}\r\n\\newcommand{\\Lom}{\\mathcal{L}}\r\n\\newcommand{\\Comp}{\\mathcal{K}}\r\n\\newcommand{\\Basis}{\\mathcal{B}}\r\n\\newcommand{\\nnu}{\\mathbf{\\nu^n}}\r\n\\newcommand{\\F}{\\mathbb F}\r\n\\newcommand{\\FF}{\\mathcal F}\r\n\\newcommand{\\MM}{\\mathcal M}\r\n\\def\\f{\\frac{|\\A||B|}{|G|}}\r\n\\def\\AB{|\\A\\cap B|}\r\n%%% ----------------------------------------------------------------------\r\n%\\nopagenumber\r\n%\\renewcommand{\\baselinestretch}{1.5}\r\n%\\textwidth=14cm\r\n\\parskip 1.5mm\r\n\r\n\r\n\\begin{document}\r\n\\title[Sums of three cubes]{On squares of sums of three cubes}\r\n\\author[Javier Pliego]{Javier Pliego}\r\n\\address{Department of Mathematics, Purdue University, 150 N. University Street, West Lafayette, IN 47907-2067, USA}\r\n\r\n\r\n\\email{jp17412@bristol.ac.uk}\r\n\\subjclass[2010]{11P05, 11P55}\r\n\\keywords{Waring's problem, Hardy-Littlewood method.}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\\begin{abstract} We show that almost every positive integer can be expressed as a sum of four squares of integers represented as the sums of three positive cubes.\r\n\\end{abstract}\r\n\\maketitle\r\n\\section{Introduction}\r\nIt is often the case in additive number theory that there might be problems involving the representation of integers that remain open, yet it can be shown that almost all integers have a representation. Lagrange's celebrated theorem, proven in 1770, states that every positive integer $n$ can be written as\r\n\\begin{equation}\\label{sqa}n=x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2},\\end{equation} where $x_{i}\\in\\mathbb{N}\\cup\\{0\\}.$ Let $\\mathscr{C}$ denote the set of integers represented as sums of three positive cubes. In this memoir we will focus our attention on the problem of solving equation (\\ref{sqa}) where the set of variables lies on the set $\\mathscr{C}$. \r\n\r\nNot very much is known about $\\mathscr{C}$. In fact, it isn't even known whether it has positive density or not, the best current lower bound on the cardinality of the set being $$\\mathcal{N}(X)=\\lvert\\mathscr{C}\\cap [1,X]\\rvert\\gg X^{\\beta-\\varepsilon},$$ where  \r\n$\\beta=0.91709477,$ due to Wooley \\cite{Woo3}. Under some unproved assumptions on the zeros of some Hasse-Weil $L$-functions, Hooley (\\cite{Hol1}, \\cite{Hol2}) and Heath-Brown \\cite{Hea} showed using different procedures that\r\n$$\\sum_{n\\leq X}r_{3}(n)^{2}\\ll X^{1+\\varepsilon},$$ where $r_{3}(n)$ is the number of representations of $n$ as a sum of three positive integral cubes, which implies by applying a standard Cauchy-Schwarz argument that $\\mathcal{N}(X)\\gg X^{1-\\varepsilon}.$\r\nThis lack of understanding of the cardinality of the set also prevents us from understanding its distribution over arithmetic progressions, which often comes into play on the major arc analysis. In this memoir, though, we use the classical approach for dealing with exceptional sets involving Bessel's inequality and we make use of an estimate for the minor arcs obtained in forthcoming work of the author \\cite{Pli1} to prove that for almost every positive integer $n$ the equation (\\ref{sqa}) has a solution with $x_{i}\\in\\mathscr{C}.$ More precisely, let $E(N)$ be the number of positive integers $n\\leq N$ for which (\\ref{sqa}) fails to possess a solution with $x_{i}\\in\\mathscr{C}$. \r\n\\begin{thm}\\label{thm01}\r\nFor each $\\varepsilon>0$ one has \\begin{equation}\\label{EN}E(N)\\ll N(\\log N)^{-4/31+\\varepsilon}.\\end{equation}\r\n\\end{thm}\r\nThe reader might want to observe that when $n=2^{6+12j}$ for $j\\geq 0$ then by taking the equation modulo powers of $2$ one finds that the only solution to (\\ref{sqa}) is $x_{i}=2^{2+6j}$. Therefore, $x_{i}\\equiv 4\\mmod{9}$, and hence $x_{i}$ cannot lie on $\\mathscr{C}.$ In the above theorem we are far from obtaining an upper bound of the expected size, but as shown on the preceeding discussion, the exceptional set of integers not represented as in (\\ref{sqa}) has infinite cardinality, and in fact\r\n\\begin{equation*}E(N)\\gg \\log N.\\end{equation*}\r\n\r\nBy using the natural polynomial structure given by $\\mathscr{C}$ and an estimate for a mean value of some weighted exponential sums, the author proves in \\cite{Pli1} via an application of the Hardy-Littlewood method that every sufficiently large integer $n$ can be represented as\r\n$$n=\\sum_{i=1}^{8}x_{i}^{2}$$ with $x_{i}\\in\\mathscr{C}.$ \r\nIn the setting of this paper, the constraint that prevents us from taking fewer variables is the analysis of the minor arcs. Such analysis is based on the use of non-optimal estimates of sums of the shape \\begin{equation*}\\sum_{m\\leq X}a_{m}^{2},\\ \\ \\ \\ \\ \\ \\ \\ \\text{where}\\ \\ a_{m}=\\Big\\{\\mathbf{x}\\in\\mathbb{N}^{3}:\\ m=x_{1}^{3}+x_{2}^{3}+x_{3}^{3},\\ \\ x_{2},x_{3}\\in \\mathcal{A}(P,P^{\\eta})\\Big\\}\\end{equation*} with $\\eta>0$ a small enough parameter and\r\n$$\\mathcal{A}(Y,R)=\\{n\\in [1,Y]\\cap \\mathbb{N}: p\\mid n\\text{ and $p$ prime}\\Rightarrow p\\leq R\\}.$$ Here, the reader may find it useful to observe that it is a consequence of Vaughan and Montgomery \\cite[Theorem 7.2]{Mon} that \\begin{equation}\\label{smo}\\text{card}\\big(\\mathcal{A}(P,P^{\\eta})\\big)=c_{\\eta}P+O\\big(P/\\log P\\big)\\end{equation} for some constant $c_{\\eta}>0$ that only depends on $\\eta$. \r\n\r\nIn order to prove Theorem \\ref{thm01} we show that for almost every integer the minor arc contribution is of smaller size than the expected main term. We also approximate the generating exponential sums of the problem by an auxiliary function over a set of narrower major arcs. Finally, we show via Bessel's inequality that for almost all integers the $n$-th Fourier coefficient of such exponential sums can also be approximated on the wider major arcs. As experts will realise, the power of $\\log N$ saved in (\\ref{EN}) comes from the choice of the narrower major arcs and the fact that the error term in (\\ref{smo}) only saves a factor of $\\log N$. Without severely complicating the argument, this choice seems inevitable for exploiting the information given by the variables $x_{2}$ and $x_{3}$ lying on $\\mathcal{A}(P,P^{\\eta})$ to ensure the convergence of the singular series and to obtain suitable properties for it. Therefore, the power saving for the bound of the cardinality of the exceptional set seems out of reach with these methods.\r\n\r\nThe application of Bessel's inequality for bounding exceptional sets has already been used by some authors before (see for instance Montgomery and Vaughan \\cite{MonVa}). There is another approach by Wooley which instead uses an exponential sum over the exceptional set that often gives stronger upper bounds for the cardinality of those sets (see Wooley \\cite{Woo7}, \\cite{Woo8}). However, in order to be able to use the latter method, one would need stronger  minor arc bounds for auxiliary $8$-th moments together with near optimal bounds for $a_{m}$, which are not available in the literature so far.\r\n\r\nWe devote the rest of the discussion to introduce a harder version of the problem studied here. It is well-known that the numbers that cannot be written as sums of three squares are the ones of the shape $4^{\\nu}\\cdot m$ for $m\\equiv 7\\mmod{8}$. Let $$\\mathcal{N}=\\big\\{n\\in\\mathbb{N}:\\ n\\not \\equiv 7\\mmod{9},\\ \\ \\ \\ n\\neq 4^{\\nu}\\cdot m\\ \\text{for some}\\ m\\equiv 7\\mmod{8},\\ \\ \\nu\\geq 0\\big\\}.$$ Then one would hope to have for almost all integers $n\\in\\mathcal{N}$ a representation\r\n$$n=x_{1}^{2}+x_{2}^{2}+x_{3}^{2}$$ for some $x_{i}\\in\\mathscr{C}.$ \r\nIf we seek to prove this statement using the circle method approach then one should be able to obtain good enough minor arc bounds of moments of exponential sums involving six variables. We remind the reader though that we are just able to deal with minor arc bounds when we have eight or more variables, and it seems out of reach to lower that number down to $6$. Likewise, the analysis of the singular series with just three variables looks very challenging.\r\n\r\n\\textbf{Acknowledgements}: The author's work was supported in part by a European Research Council Advanced\r\nGrant under the European Union\u2019s Horizon 2020 research and innovation programme via grant agreement No. 695223 during his studies at the University of Bristol. It was completed while the author was visiting Purdue University under Trevor Wooley's supervision. The author would like to thank him for his guidance and helpful comments, the referee for useful remarks and both the University of Bristol and Purdue University for their support and hospitality.\r\n\r\n\\section{Notation and preliminary definitions} Unless specified, any lower case letter $\\mathbf{x}$ written in bold will denote a triple of integers $(x_{1},x_{2},x_{3})$. We will write $a\\leq \\mathbf{V}\\leq b$ when $a\\leq v_{i}\\leq b$ for $1\\leq i\\leq n$. As usual in analytic number theory, for each $x\\in\\mathbb{R}$ we denote $\\exp(2\\pi i x)$ by $e(x)$, and for each natural number $q$ then $e(x/q)$ will be written as $e_{q}(x).$ For any scalar $\\lambda$ and any vector $\\mathbf{x}$ we write $\\lambda \\mathbf{x}$ for the vector $(\\lambda x_{1},\\lambda x_{2}, \\lambda x_{3})$. Let $N$ be a natural number and consider the parameters $$P=\\lfloor N^{1/6}\\rfloor,\\ \\ \\ \\ M=P^{2/5},\\ \\ \\ \\ H=P^{9/5}.$$Observe that then one has $M^{3}H=P^{3}.$ Consider as well$$H_{1}=\\Big(\\frac{1}{2}\\Big)^{1/3}H^{1/3},\\ \\ \\ \\ H_{2}=\\Big(\\frac{2}{3}\\Big)^{1/3}H^{1/3},\\ \\ \\ \\ H_{3}=\\Big(\\frac{1}{6}\\Big)^{1/3}H^{1/3}.$$ For any vector $\\mathbf{x}\\in \\mathbb{R}^{3}$ set the function $T(\\mathbf{x})=x_{1}^{3}+x_{2}^{3}+x_{3}^{3},$ which will be used throughout the paper.\r\nTake the sets of triples\r\n$$\\mathcal{H}=\\Big\\{\\mathbf{y}\\in\\mathbb{N}^{3}:\\ \\ P/2< y_{1}\\leq P,\\ \\ \\ (y_{2},y_{3})\\in\\mathcal{A}(P,P^{\\eta})^{2}\\Big\\},$$ $$\\mathcal{W}=\\Big\\{\\mathbf{y}\\in\\mathbb{N}^{3}:\\ \\ H_{1}< y_{1}\\leq H_{2},\\ \\ (y_{2},y_{3})\\in\\mathcal{A}(H_{3},P^{\\eta})^{2}\\Big\\},$$ where $\\eta$ is a sufficiently small but positive parameter. Let $n\\in\\mathbb{N}$ such that $N/2\\leq n\\leq N$. We define $R(n)$ as the number of solutions of the equation\r\n$$n=T(p_{1}\\mathbf{x}_{1})^{2}+T(p_{2}\\mathbf{x}_{2})^{2}+T(\\mathbf{x}_{3})^{2}+T(\\mathbf{x}_{4})^{2},$$ where \r\n$\\mathbf{x}_{1},\\mathbf{x}_{2}\\in \\mathcal{W},$ $\\mathbf{x}_{3},\\mathbf{x}_{4}\\in \\mathcal{H}$ and $M/2\\leq p_{1},p_{2}\\leq M.$ Our goal in the next sections will be to obtain a lower bound for $R(n)$ for almost all natural numbers. For such purpose, it is convenient to define the weights $$a_{x}=\\Big\\lvert\\big\\{\\mathbf{y}\\in\\mathcal{H}:\\ \\ x=T(\\mathbf{y})\\big\\}\\Big\\rvert\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ b_{h}=\\Big\\lvert\\big\\{\\mathbf{y}\\in\\mathcal{W}:\\ \\ h=T(\\mathbf{y})\\big\\}\\Big\\rvert,$$\r\nand consider the exponential sums\r\n$$h(\\alpha)=\\sum_{x\\leq 3P^{3}}a_{x}e(\\alpha x^{2})\\ \\ \\ \\ \\ \\ \\ \\  \\text{and} \\ \\ \\ \\ \\ \\ \\ \\ \\ W(\\alpha)=\\sum_{M/2\\leq p\\leq M}\\sum_{\\frac{H}{2}\\leq h\\leq H}b_{h}e(\\alpha p^{6}h^{2}).$$ Observe that by orthogonality it follows that\r\n$$R(n)=\\int_{0}^{1}h(\\alpha)^{2}W(\\alpha)^{2}e(-\\alpha n)d\\alpha.$$\r\n\r\nWe will make use of two Hardy-Littlewood dissections in our analysis, and these we now describe. Let $1\\leq X\\leq P^{4/5}$. When $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ satisfy $0\\leq a\\leq q\\leq X$ and $(a,q)=1$, consider \r\n\\begin{equation*}\\grM(a,q)=\\Big\\{ \\alpha\\in [0,1): \\Big\\lvert \\alpha-a/q\\Big\\rvert \\leq \\frac{X}{qn}\\Big\\}.\\end{equation*} We take the major arcs $\\grM(X)$ to be the union of the arcs $\\grM(a,q)$. For the sake of simplicity we write\r\n$$\\grM=\\grM(P^{4/5}),\\ \\ \\ \\ \\ \\ \\ \\ \\grN=\\grM\\big((\\log P)^{\\tau}\\big),$$ where $\\tau=18/31.$ We also define the minor arcs as $\\grm=[0,1)\\setminus \\grM$.\r\n\r\nNext we introduce the auxiliary functions that play a leading role in the discussion of Sections \\ref{sec3} to \\ref{sec6}. For $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$, let $S(q,a)$ denote the complete exponential sum associated to the problem, which we define by\r\n$$S(q,a)=\\sum_{\\mathbf{r}\\leq q}e_{q}\\big(aT(\\mathbf{r})^{2}\\big).$$ Consider the functions\r\n\\begin{equation*}v(\\beta)=\\int_{\\mathbf{x}\\in\\mathcal{S}}e\\big(F(\\mathbf{x})\\big)d\\mathbf{x}\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ v_{p}(\\beta)=\\int_{\\mathbf{x}\\in \\mathcal{S}_{W}}e\\big(F_{p}(\\mathbf{x})\\big)d\\mathbf{x},\\end{equation*}where $F(\\mathbf{x})=\\beta T(\\mathbf{x})^{2}$ and $F_{p}(\\mathbf{x})=\\beta T(p\\mathbf{x})^{2},$ and the sets of integration taken are $$\\mathcal{S}=\\Big\\{\\mathbf{x}\\in [0,P]^{3}:\\ \\ P/2\\leq x_{1}\\leq P\\Big\\},\\ \\ \\ \\ \\mathcal{S}_{W}=\\Big\\{\\mathbf{x}\\in\\mathbb{R}^{3}:\\ \\ H_{1}\\leq x_{1}\\leq H_{2},\\ \\ 0\\leq x_{2}, x_{3}\\leq H_{3}\\Big\\}.$$ Let $\\alpha\\in [0,1)$ and choose $\\beta=\\alpha-a/q$. Recalling the constant $c_{\\eta}$ mentioned in (\\ref{smo}), define  \\begin{equation}\\label{Vup}V(\\alpha,q,a)=q^{-3}S(q,a)c_{\\eta}^{2}v(\\beta)\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ W(\\alpha,q,a)=\\sum_{M/2\\leq p\\leq M}V_{p}(\\alpha,q,a),\\end{equation}where $V_{p}(\\alpha,q,a)=q^{-3}S(q,a)c_{\\eta}^{2}v_{p}(\\beta).$ For the sake of brevity, we define the auxiliary functions $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$ by setting\r\n\\begin{equation*}h^{*}(\\alpha)=V(\\alpha,q,a)\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ W^{*}(\\alpha)=W(\\alpha,q,a) \\end{equation*} when $\\alpha\\in\\grM(a,q)\\subset\\grM$ and $h^{*}(\\alpha)=W^{*}(\\alpha)=0$ for $\\alpha\\in\\grm.$\r\nBefore describing the outline of the memoir, it is convenient to introduce $$\\mathcal{F}(\\alpha)=h(\\alpha)^{2}W(\\alpha)^{2}-h^{*}(\\alpha)^{2}W^{*}(\\alpha)^{2}.$$\r\n\r\nIn Section \\ref{sec3} we approximate $h(\\alpha)$ and $W(\\alpha)$ by  the functions $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$ respectively when $\\alpha\\in\\grN$. Making use of these approximations we bound the integral of $\\mathcal{F}(\\alpha)e(-\\alpha n)$ over $\\grN$ in Section \\ref{sec5}. In the second part of that section and Section \\ref{sec6} we show that the upper bound for the integral of the same function over $\\grM\\setminus\\grN$ still holds for almost all integers. We obtain such result by estimating the integral of $\\lvert\\mathcal{F}(\\alpha)\\rvert^{2}$ and applying Bessel's inequality. Section \\ref{sec4} is devoted to the study of the singular series. In such analysis we give a lower bound of the singular series for almost all integers, which combined with the lower bound for the singular integral computed in Section \\ref{sec6} provides a lower bound for the major arc contribution. We also combine the major arc estimates obtained throughout the memoir with a result in forthcoming work of the author \\cite{Pli1} to show in Section \\ref{sec6} that the minor arc contribution is smaller than the major arc one for almost all integers.\r\n\r\nWhenever $\\varepsilon$ appears in any bound, it will mean that the bound holds for every $\\varepsilon>0$, though the implicit constant then may depend on $\\varepsilon$. We adopt the convention that when we write $\\delta$ in the computations we mean that there exists a positive constant such that the bound holds. We use $\\ll$ and $\\gg$ to denote Vinogradov's notation, and write $A\\asymp B$ whenever $A\\ll B\\ll A$. We write $p^{r}|| n$ to denote that $p^{r}| n$ but $p^{r+1}\\nmid n.$\r\n\\section{Approximation of exponential sums over the major arcs.}\\label{sec3}\r\nBased on previous work by the author we briefly provide some technical lemmas to approximate the exponential sums over the set of narrower major arcs. \r\n\r\n\r\n\\begin{lem}\\label{lem1}Let $\\alpha\\in \\grN(a,q)$ with $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ and $(a,q)=1$. Then one obtains the formula\r\n$$h(\\alpha)=V(\\alpha,q,a)+O\\big(P^{3}(\\log P)^{\\tau-1+\\varepsilon}\\big).$$\r\n\\end{lem}\r\n\\begin{proof}\r\nThis is a consequence of Lemma 7.3 of \\cite{Pli}. The reader may check that the exponential sum $h(\\alpha)$ here corresponds to $g_{Q,m}(\\alpha)$ with the choices $Q=P,$ $m=1$ and constants $C_{1}=1/2$, $C_{2}=1$ and $C_{3}=1.$\r\n\\end{proof}\r\n\r\n\\begin{lem}\\label{lem3}Let $\\alpha\\in \\grN(a,q)$ with $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ and $(a,q)=1$. Then,\r\n$$W(\\alpha)=W(\\alpha,q,a)+O\\big(HM(\\log P)^{\\tau-2+\\varepsilon}\\big).$$\r\n\\end{lem}\r\n\\begin{proof}\r\nObserve that $$W(\\alpha)=\\sum_{M/2\\leq p\\leq M}W_{p}(\\alpha),\\ \\ \\ \\ \\ \\ \\text{where}\\ \\ W_{p}(\\alpha)=\\sum_{\\mathbf{x}\\in\\mathcal{W}}e\\big(\\alpha T(p\\mathbf{x})^{2}\\big).$$\r\nWe also apply Lemma 7.3 of \\cite{Pli} to $W_{p}(\\alpha)$. The reader may check that $W_{p}(\\alpha)$ here corresponds to $g_{Q,m}(\\alpha)$ with the choices $Q=H^{1/3}$ and $m=p$ and the constants $C_{1}=\\big(1/2\\big)^{1/3}$, $C_{2}=\\big(2/3\\big)^{1/3}$ and $C_{3}=\\big(1/6\\big)^{1/3}.$ Consequently, it transpires that $$W_{p}(\\alpha)=V_{p}(\\alpha,q,a)+O\\big(H\\big(\\log P)^{\\tau-1+\\varepsilon}\\big),$$\r\nwhich delivers the result.\r\n\\end{proof}\r\nThe following series of lemmas make use of the work done in forthcoming publications of the author (\\cite {Pli} and \\cite{Pli1}) to give upper bounds for the auxiliary functions that play a role in the main term of the contribution of the major arcs.\r\n\\begin{lem}\\label{lema4}\r\nLet $ \\beta \\in\\mathbb{R}.$ Then one has that\r\n$$v(\\beta)\\ll \\frac{P^{3}}{1+n\\lvert \\beta\\rvert}\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ v_{p}(\\beta)\\ll \\frac{H}{1+n\\lvert \\beta\\rvert}.$$ \r\n\\end{lem}\r\n\\begin{proof}\r\nFor each $\\mathbf{y}\\in\\mathbb{R}^{2},$ consider $C_{\\mathbf{y}}=y_{1}^{3}+y_{2}^{3}$. Define the auxiliary functions $$v_{\\mathbf{y}}(\\beta)=\\int_{M_{\\mathbf{y}}}^{N_{\\mathbf{y}}}B_{\\mathbf{y}}(\\gamma)e(\\beta \\gamma)d\\gamma\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ v_{\\mathbf{y},p}(\\beta)=\\int_{M_{\\mathbf{y},p}}^{N_{\\mathbf{y},p}}B_{\\mathbf{y},p}(\\gamma)e(\\beta \\gamma)d\\gamma$$ where $B_{\\mathbf{y}}(\\gamma)$, $B_{\\mathbf{y},p}(\\gamma)$ and the limits of integration taken are$$B_{\\mathbf{y}}(\\gamma)=\\frac{1}{6}\\gamma^{-1/2}\\big(\\gamma^{1/2}-C_{\\mathbf{y}}\\big)^{-2/3},\\ \\ \\  M_{\\mathbf{y}}=\\Big(\\frac{P^{3}}{8}+C_{\\mathbf{y}}\\Big)^{2},\\ \\ \\ N_{\\mathbf{y}}=\\big(P^{3}+C_{\\mathbf{y}}\\big)^{2}$$and\r\n$$B_{\\mathbf{y},p}(\\gamma)=\\frac{1}{6p}\\gamma^{-1/2}\\big(\\gamma^{1/2}-C_{p\\mathbf{y}}\\big)^{-2/3},\\ \\ M_{\\mathbf{y},p}=\\Big(\\frac{p^{3}H}{2}+C_{p\\mathbf{y}}\\Big)^{2} \\ \\text{and}\\ \\ N_{\\mathbf{y},p}=\\Big(\\frac{2p^{3}H}{3}+C_{p\\mathbf{y}}\\Big)^{2}.$$\r\nBy a change of variables we find that\r\n\\begin{equation}\\label{vbeta}v(\\beta)=\\int_{\\mathbf{y}\\in [0,P]^{2}}v_{\\mathbf{y}}(\\beta)d\\mathbf{y}\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ v_{p}(\\beta)=\\int_{\\mathbf{y}\\in [0,H_{3}]^{2}}v_{\\mathbf{y},p}(\\beta)d\\mathbf{y}.\\end{equation}\r\nObserve that Lemma 5.2 of \\cite{Pli1} yields the pointwise bounds $v_{\\mathbf{y}}(\\beta)\\ll P(1+n\\lvert\\beta\\rvert)^{-1}$ and $v_{\\mathbf{y},p}(\\beta)\\ll H^{1/3}(1+n\\lvert\\beta\\rvert)^{-1}.$ The result then follows applying these estimates trivially to the above integrals. \r\n\\end{proof}\r\n\\begin{lem}\\label{lem0}\r\nLet $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1.$ Then, one has\r\n\\begin{equation}\\label{kkk}S(q,a)\\ll q^{5/2+\\varepsilon}.\\end{equation} Moreover, when $p$ is prime and $l\\geq 3$ one finds that \\begin{equation}\\label{kk}S(p^{l},a)\\ll lp^{5l/2+\\varepsilon}.\\end{equation} When $l=2$ then $S(p^{2},a)\\ll p^{5}$ and for the case $l=1$ we obtain the refinement\r\n\\begin{equation}\\label{Sap}S(p,a)=p^{2}S_{2}(p,a)+O(p^{2}), \\ \\ \\ \\ \\ \\ \\ \\text{where}\\  S_{2}(p,a)=\\sum_{r=1}^{p}e_{p}(ar^{2}).\\end{equation}\r\n\\end{lem}\r\n\\begin{proof}\r\nEquations (\\ref{kk}) and (\\ref{Sap}) follow from Lemmata 3.1 and 3.2 of \\cite{Pli} respectively. The bound for the case $l=2$ also follows from Lemma 3.1 of \\cite{Pli}. We remind the reader of the estimates $$d(q)\\ll q^{\\varepsilon},\\ \\ \\ \\ \\ \\ \\ \\ \\omega(q)\\ll \\log q/\\log\\log q,$$ where the functions $d(q)$ and $\\omega(q)$ denote the number of divisors of $q$ and the number of prime divisors of $q$, respectively. Combining such bounds with the multiplicative property of $S(q,a)$ and the estimates for $S(p^{l},a)$ discussed before we obtain (\\ref{kkk}).\r\n\\end{proof}The next lemma gathers the previous results to provide an upper bound for the auxiliary functions $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$.\r\n\\begin{lem}\\label{lem06}\r\nLet $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$. Take $\\alpha\\in \\grM(a,q)$. Then,\r\n$$h^{*}(\\alpha)\\ll \\frac{q^{-1/2+\\varepsilon}P^{3}}{1+n\\lvert\\beta\\rvert}\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ W^{*}(\\alpha)\\ll \\frac{q^{-1/2+\\varepsilon}HM}{(\\log P)(1+n\\lvert\\beta\\rvert)}.$$\r\n\\end{lem}\r\n\\begin{proof}\r\nThis follows from Lemmata \\ref{lema4} and \\ref{lem0} via equation (\\ref{Vup}).\r\n\\end{proof}\r\n\r\n\r\n\r\n\r\n\r\n\\section{Treatment of the singular series}\\label{sec4}\r\nIn this section we discuss some convergence properties of the singular series and we analyse the local solubility of the problem. As a consequence, we derive a lower bound for the singular series for almost all integers. For such purposes, it is convenient to define, for $q\\in\\mathbb{N}$, the sums\r\n$$S_{n}(q)=\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big(q^{-3}S(q,a)\\big)^{4}e_{q}(-na),\\ \\ \\ \\ \\ \\ \\ \\ \\mathfrak{S}(n)=\\sum_{q=1}^{\\infty}S_{n}(q)$$and for each prime $p$, the infinite series\r\n$$\\sigma(p)=\\sum_{l=0}^{\\infty}S_{n}(p^{l}).$$\r\n\\begin{lem}\\label{lema3}\r\nOne has that\r\n\\begin{equation*}\\mathfrak{S}(n)=\\prod_{p}\\sigma(p),\\end{equation*}\r\nthe singular series $\\mathfrak{S}(n)$ converges absolutely and $\\mathfrak{S}(n)\\ll n^{\\varepsilon}$. Also, when $Q> 0$ one gets\r\n\\begin{equation}\\label{tup}\\sum_{q\\leq Q}q^{1/2}\\lvert S_{n}(q)\\rvert\\ll (nQ)^{\\varepsilon}\\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\ \\sum_{q\\geq Q}\\lvert S_{n}(q)\\rvert\\ll n^{\\varepsilon}Q^{\\varepsilon-1/2}.\\end{equation}Moreover, for any constant $\\upsilon>0$ there exists a set $A_{\\upsilon}\\subset [1,N]$ with $\\lvert A_{\\upsilon}\\rvert\\ll N(\\log N)^{-\\upsilon}$ and such that for every $n\\in [1,N]\\setminus A_{\\upsilon}$ one obtains\r\n$$\\mathfrak{S}(n)\\gg (\\log N)^{-\\upsilon}.$$ \r\n\\end{lem}\r\n\\begin{proof}\r\nRecalling (\\ref{Sap}), consider the exponential sum\r\n$$S_{n,2}(q)=\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big(q^{-1}S_{2}(q,a)\\big)^{4}e_{q}(-na).$$ By Lemma \\ref{lem0} one has that \\begin{equation}\\label{Sp}S_{n}(p)=S_{n,2}(p)+O(p^{-3/2}).\\end{equation}Observe that an application of the same lemma yields $S_{n}(p^{l})\\ll l^{4}p^{-l+\\varepsilon}$ when $l\\geq 3$ and $S_{n}(p^{2})\\ll p^{-2}$. One can also deduce from equation (4.27) of Vaughan \\cite[Theorem 4.3]{Vau} that whenever $p\\nmid n$ then $S_{n,2}(p)\\ll p^{-3/2}.$ Therefore, the combination of the previous estimates gives\r\n $$\\displaystyle\\sum_{l=1}^{\\infty}\\lvert S_{n}(p^{l})\\rvert\\ll p^{-3/2}.$$ Likewise, when $p\\mid n,$ then an application of the aforementioned bounds for $S_{n}(p^{l})$ and  the estimate $S_{n,2}(p)\\ll p^{-1}$, which is an immediate consequence of Vaughan \\cite[Lemma 4.3]{Vau}, lead to $$\\displaystyle\\sum_{l=1}^{\\infty}\\lvert S_{n}(p^{l})\\rvert\\ll p^{-1}.$$ Therefore, by the preceeding discussion and the multiplicative property of $S_{n}(q)$, one gets the convergence for $\\frak{S}(n)$ and the upper bound\r\n$$\\frak{S}(n)\\ll \\prod_{p\\nmid n}\\big(1+C_{1}p^{-3/2}\\big)\\prod_{p\\mid n}\\big(1+C_{2}p^{-1}\\big)\\ll n^{\\varepsilon}$$ for some constants $C_{1},C_{2}>0$. Similarly, one finds that\r\n$$\\sum_{l=1}^{\\infty}p^{l/2}\\lvert S_{n}(p^{l})\\rvert\\ll p^{-\\xi},$$ where $\\xi=1$ if $p\\nmid n$ and $\\xi=1/2$ if $p\\mid n$. Consequently, the combination of the above estimates yields the bound\r\n$$\\sum_{q\\leq Q}q^{1/2}\\lvert S_{n}(q)\\rvert\\ll \\prod_{\\substack{p\\leq Q\\\\ p\\nmid n}}(1+C_{1}p^{-1})\\prod_{\\substack{p\\leq Q\\\\ p|n}}(1+C_{2}p^{-1/2})\\ll (nQ)^{\\varepsilon}.$$The second estimate in (\\ref{tup}) follows observing that as a consequence of the above equation then\r\n$$\\sum_{Q\\leq q\\leq 2Q}\\lvert S_{n}(q)\\rvert\\ll n^{\\varepsilon}Q^{\\varepsilon-1/2},$$ whence summing over dyadic intervals we obtain the desired result.\r\n\r\n\r\n\r\nWe will devote the rest of the section to prove the lower bound for the singular series. By equation (4.27) of Vaughan \\cite[Theorem 4.3]{Vau} and (\\ref{Sp}) then whenever $p\\nmid n$ one has $S_{n}(p)\\ll p^{-3/2}$. We can also deduce from the proof\\footnote{See the argument just before \\cite[Theorem 4.6]{Vau}} of \\cite[Theorem 4.5]{Vau} that $S_{n,2}(p)\\geq 0$ for $p\\mid n$, which, combined with (\\ref{Sp}), yields $S_{n}(p)\\geq -C_{3}p^{-3/2}$ for some $C_{3}>0$. Consequently, using the bound $S_{n}(p^{l})\\ll l^{4}p^{-l+\\varepsilon}$ for $l\\geq 2$ mentioned after (\\ref{Sp}) one gets that in both cases then $\\sigma(p)\\geq 1-C_{4}p^{-3/2}$ for some $C_{4}>0,$ and hence there exists a constant $C>0$ for which\r\n\\begin{equation}\\label{prod}\\mathfrak{S}(n)\\gg \\prod_{p\\leq C}\\sigma(p).\\end{equation}In order to give a more arithmetic description of $\\sigma(p)$ we define for each $h\\in\\mathbb{N}$ the set $$\\mathcal{M}_{n}(p^{h})=\\Big\\{\\mathbf{Y}\\in [1,p^{h}]^{12}:\\ \\sum_{i=1}^{4}T(\\bfy_{i})^{2}\\equiv n\\mmod{p^{h}}\\Big\\},$$ and ${M}_{n}(p^{h})=\\lvert\\mathcal{M}_{n}(p^{h})\\rvert$. Observe that orthogonality yields the identity\r\n$$\\sum_{l=0}^{h}S_{n}(p^{l})=p^{-11h}M_{n}(p^{h}),$$ and hence $\\sigma(p)=\\lim_{h\\to \\infty}p^{-11h}M_{n}(p^{h}).$ For further discussion, it is relevant to introduce the set $$\\mathcal{M}_{n}^{*}(p^{h})=\\Big\\{\\mathbf{Y}\\in \\mathcal{M}_{n}(p^{h}):\\ \\  p\\nmid y_{1,1},\\ p\\nmid T(\\mathbf{y}_{1})\\Big\\},$$ where $\\mathbf{y}_{1}=(y_{1,1},y_{1,2},y_{1,3}),$ and ${M}_{n}^{*}(p^{h})=\\lvert\\mathcal{M}_{n}^{*}(p^{h})\\rvert.$ By Lemma 4.2 of \\cite{Pli} we have that whenever $p\\neq 2,3$ then $M_{n}^{*}(p)>0$ for all $n$. Consequently, a standard application of Hensel's Lemma leads to $M_{n}(p^{h})\\geq p^{11(h-1)}$, which yields $\\sigma(p)\\geq p^{-11}.$ For the cases $p=2,3$, it is convenient to define the set\r\n\\begin{equation*}\\label{ec11.0}\\mathcal{M}_{3,3}(p^{h})=\\Big\\{T(\\bfx):\\ \\bfx\\in\\big(\\mathbb{Z}/p^{h}\\mathbb{Z}\\big)^{3},\\ (x_{1},p)=1\\Big\\}.\\end{equation*} A slightly tedious computation reveals that $\\mathcal{M}_{3,3}(27)$ is the set of residues not congruent to $4$ or $5$ modulo $9$. Therefore, one has that $$A=\\Big\\{x^{2}\\mmod{27},\\ \\ \\ \\ x\\in \\mathcal{M}_{3,3}(27)\\Big\\}=\\Big\\{0,1,4,9,10,13,19,22\\Big\\}.$$ Consider the set $B=\\{y\\in A:\\ (y,3)=1\\big\\}.$ Observe that then $$A+B=\\Big\\{1,2,4,5,8,10,11,13,14,17,19,20,22,23,26\\Big\\}.$$ Consequently, by Cauchy-Davenport (see \\cite[Lemma 2.14]{Vau}) we find that $M_{n}^{*}(27)>0$, whence another application of Hensel's Lemma gives $M_{n}(3^{h})\\geq 3^{11(h-3)}$, and hence $\\sigma(3)\\geq 3^{-33}.$\r\n\r\nThe rest of the discussion will be devoted to the analysis for the prime $p=2$. Take $\\gamma\\geq 0$ to be the exponent for which $2^{\\gamma}|| n$ and let $\\theta=\\lfloor (\\gamma-1)/2\\rfloor$. A routine application of Hensel's Lemma reveals that $\\mathcal{M}_{3,3}(2^{h})$ consists of all the residue classes modulo $2^{h}$. Therefore, when $\\gamma\\leq 2$, one has that $M_{n}^{*}(8)>0$, whence another application of Hensel's Lemma would yield $\\sigma(2)\\geq 2^{-33}.$ For the case $\\gamma\\geq 3$ then whenever $h\\geq \\gamma+2$ one can check that the congruence \r\n\\begin{equation}\\label{squares}x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}\\equiv n\\mmod{2^{h}}\\end{equation} is soluble with solutions $x_{i}=2^{\\theta}y_{i},$ where $y_{i}$ is defined modulo $2^{h-\\theta}$ and \r\n\\begin{equation}\\label{mod8}y_{1}^{2}+y_{2}^{2}+y_{3}^{2}+y_{4}^{2}\\equiv 2^{-2\\theta}n \\mmod{2^{h-2\\theta}}\\end{equation}\r\nwith $2\\nmid y_{1}$. Note that (\\ref{mod8}) has a solution modulo $8$ with $2\\nmid y_{1}$, and hence by Lemma 2.13 of \\cite{Vau} there are at least  $2^{3(h-2\\theta-3)}\\times 2^{4\\theta}$ solutions to (\\ref{squares}). By the same lemma, one has that the number of solutions to $$z_{1}^{3}+z_{2}^{3}+z_{3}^{3}\\equiv x_{i}\\mmod{2^{h}}$$ is bounded below by $2^{2(h-1)}$. Consequently, we obtain $M_{n}(2^{h})\\geq 2^{11h-\\gamma-16}$, which delivers $\\sigma (2)\\gg 2^{-\\gamma}.$ \r\n\r\n\r\n\r\nTo finish the proof we take $A_{\\upsilon}\\subset [1,N]$ to be the set of numbers with $2^{\\gamma}\\geq (\\log N)^{\\upsilon}$. Observe that $\\lvert A_{\\upsilon}\\rvert \\leq N(\\log N)^{-\\upsilon}$. Then, by the preceeding discussion and (\\ref{prod}) it follows that whenever $n\\notin A_{\\upsilon}$ one has\r\n$$\\mathfrak{S}(n)\\gg (\\log N)^{-\\upsilon}.$$\r\n\r\n\r\n\r\n\\end{proof}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\\section{Mean values of the error term over the major arcs}\\label{sec5}\r\nBefore proving an estimate for the first and second moment of $\\mathcal{F}(\\alpha)$ over $\\grN$ and $\\grM\\setminus \\grN$ respectively we will present some major arc type bounds that will be used later on the proof. For such matters, it is convenient to introduce the auxiliary multiplicative function $w_{2}(q)$, defined for prime powers by taking\r\n\\begin{equation}\\label{wuok}w_{2}(p^{6u+v})=\\left\\{\r\n\t       \\begin{array}{ll}\r\n         p^{-u-v/6}\\ \\ \\ \\ \\ \\ \\ \\text{when $u\\geq 1$ and $1\\leq v\\leq 6$}   \\\\\r\n         p^{-1}\\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\text{when $u=0$ and $2\\leq v\\leq 6$}    \\\\\r\n         p^{-1/2}\\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\text{when $u=0$ and $v=1$.}    \\\\\r\n    \\end{array}  \\right. \\end{equation}\r\n\\begin{lem}\\label{prop4}\r\nLet $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ and take $\\alpha\\in\\grM(a,q)$. Denote $\\beta=\\alpha-a/q.$ Then, \r\n$$h(\\alpha)\\ll \\frac{q^{\\varepsilon}w_{2}(q)P^{3}}{1+n\\lvert \\beta\\rvert},$$ and for $\\lvert\\beta\\rvert\\leq (12q)^{-1}H^{1/3}n^{-1}$ and $q\\leq M/4$ we have that\r\n\\begin{equation}\\label{lam}W(\\alpha)\\ll \\frac{q^{\\varepsilon}w_{2}(q)HM}{(\\log P)(1+n\\lvert \\beta\\rvert)}.\\end{equation}\r\n\\end{lem}\r\n\\begin{proof}\r\nLemmata 3.1 and 5.2 of \\cite{Pli1} yield the bounds\r\n$$h(\\alpha)\\ll q^{\\varepsilon}w_{2}(q)P^{3}(1+n\\lvert\\beta\\rvert)^{-1}+P^{2}q^{1+\\varepsilon}w_{2}(q)$$whenever $\\alpha\\in\\grM(a,q).$ Observe that $(1+n\\lvert\\beta\\rvert)^{-1}\\geq qP^{-1}$ when $\\alpha\\in\\grM(a,q)$, and so the first term on the right side of the above equation dominates over the second one. Likewise, Lemmata 3.2 and 5.2 of \\cite{Pli1} deliver $$W(\\alpha)\\ll q^{\\varepsilon}w_{2}(q)MH(\\log P)^{-1}(1+n\\lvert \\beta\\rvert)^{-1}+MH^{2/3}q^{1+\\varepsilon}w_{2}(q)(\\log P)^{-1}$$ for the range described just before (\\ref{lam}). Noting that $(1+n\\lvert\\beta\\rvert)^{-1}\\geq qH^{-1/3}$ we find that the first term also dominates over the second one in the above equation. The preceeding discussion then provides the lemma.\r\n\\end{proof}\r\n\r\n\r\n\\begin{lem}\\label{flo}\r\nFor $q\\in\\mathbb{N}$ and every $Q>0$ one finds that $w_{2}(q)\\leq q^{-1/6}$. Moreover, one has \\begin{equation*}\\sum_{q\\leq Q}w_{2}(q)^{2}\\ll Q^{\\varepsilon}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\text{and}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\sum_{q\\leq Q}w_{2}(q)^{2+\\delta}\\ll 1\\end{equation*} for any $\\delta>0$.\r\n\\end{lem}\r\n\\begin{proof}\r\nBoth estimates follow from the definition (\\ref{wuok}) and the fact that $w_{2}(q)$ is multiplicative. \r\n\\end{proof}\r\nCombining the previous technical lemmas, we provide bounds for the $L^{1}$-norm of $\\mathcal{F}(\\alpha)$ over the set of arcs $\\grN$ and the $L^{2}$-norm of the same function over $\\grM\\setminus\\grN$ which are good enough for our purposes.\r\n\\begin{prop}\\label{prop11}\r\nOne has that\r\n\\begin{equation}\\label{tus}\\int_{\\grN}\\big\\lvert \\mathcal{F}(\\alpha)\\big\\rvert d\\alpha\\ll (HM)^{2}(\\log P)^{3\\tau/2-3+\\varepsilon}.\r\n\\end{equation}\r\n\\end{prop}\r\n\\begin{proof}\r\nRecalling Lemmata \\ref{lem1} and \\ref{lem06} it follows that whenever $\\alpha\\in\\grN(a,q)\\subset \\grN$ then\r\n\\begin{equation}\\label{hal}h(\\alpha)^{2}-h^{*}(\\alpha)^{2}\\ll P^{6}(\\log P)^{\\tau-1+\\varepsilon}\\Big((\\log P)^{\\tau-1}+q^{-1/2}(1+n\\lvert\\beta\\rvert)^{-1}\\Big).\\end{equation} Likewise, by Lemmata \\ref{lem3} and \\ref{lem06} we have that for $\\alpha\\in\\grN(a,q)\\subset\\grN$ then\r\n\\begin{equation}\\label{Wal}W(\\alpha)^{2}-W^{*}(\\alpha)^{2}\\ll (HM)^{2}(\\log P)^{\\tau-3+\\varepsilon}\\Big((\\log P)^{\\tau-1}+q^{-1/2}(1+n\\lvert\\beta\\rvert)^{-1}\\Big).\\end{equation}\r\nDenote by $N(q)$ the number of solutions of the congruence \r\n$$T(p_{1}\\mathbf{x}_{1})^{2}\\equiv T(p_{2}\\mathbf{x}_{2})^{2}\\mmod {q},$$ where $\\mathbf{x}_{i}\\in [1,H^{1/3}]^{3}$ and $M/2\\leq p_{i}\\leq M$. By expressing $q$ as the product of prime powers, using the structure of the ring of integers of those prime powers and noting that the number of primes dividing $q$ is bounded by $q^{\\varepsilon}$, we obtain\r\n\\begin{equation*}\\label{Nq}N(q)\\ll q^{\\varepsilon-1}(HM)^{2}(\\log P)^{-2},\\end{equation*}and hence orthogonality delivers \\begin{equation}\\label{Wint}\\sum_{a=1}^{q}\\lvert W(\\beta+a/q)\\rvert^{2}\\leq qN(q)\\ll q^{\\varepsilon}(HM)^{2}(\\log P)^{-2}.\\end{equation}\r\nIntegrating over the major arcs and applying (\\ref{hal}) and (\\ref{Wint}) one gets\r\n\\begin{align*}\\label{ugu}&\\int_{\\grN}\\big\\lvert h(\\alpha)^{2}-h^{*}(\\alpha)^{2}\\big\\rvert \\lvert W(\\alpha)\\rvert^{2}d\\alpha\\ll (HM)^{2}(\\log P)^{3\\tau-4+\\varepsilon}\\sum_{q\\leq (\\log P)^{\\tau}}q^{-1}\r\n\\\\\r\n&+(HM)^{2}(\\log P)^{\\tau-3+\\varepsilon}\\sum_{q\\leq (\\log P)^{\\tau}}q^{-1/2}\\ll (HM)^{2}(\\log P)^{3\\tau/2-3+\\varepsilon}.\\nonumber\r\n\\end{align*}\r\nSimilarly, using  Lemma \\ref{lem06} and (\\ref{Wal}) we obtain\r\n\\begin{align*}\r\n\\int_{\\grN}\\lvert h^{*}(\\alpha)\\rvert ^{2}\\big\\lvert W(\\alpha)^{2}-W^{*}(\\alpha)^{2}\\big\\rvert d\\alpha\\ll (HM)^{2}(\\log P)^{3\\tau/2-3+\\varepsilon}.\r\n\\end{align*}\r\nEquation (\\ref{tus}) then holds combining the previous estimates and the triangle inequality.\r\n\\end{proof}\r\nObserve that the error term in Lemmata \\ref{lem1} and \\ref{lem3} when we approximate $h(\\alpha)$ and $W(\\alpha)$ by $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$ respectively is non-trivial only for the set of small major arcs $\\grN$. For the wider major arcs, we obtain instead an almost all result via Bessel's inequality.\r\n\\begin{prop}\\label{lem7}\r\nOne has that\r\n\\begin{equation*}\\int_{\\grM\\setminus \\grN}\\big\\lvert \\mathcal{F}(\\alpha)\\big\\rvert^{2}d\\alpha\\ll P^{6}(HM)^{4}(\\log P)^{-4-2\\tau/3+\\varepsilon}.\\end{equation*}\r\n\\end{prop}\r\n\\begin{proof}\r\nNote that $\\lvert \\mathcal{F}(\\alpha)\\rvert^{2}\\ll \\lvert h(\\alpha)\\rvert^{4}\\lvert W(\\alpha)\\rvert^{4}+\\lvert h^{*}(\\alpha)\\rvert^{4}\\lvert W^{*}(\\alpha)\\rvert^{4}.$\r\nFor bounding the above integral we make use of standard major arc techniques and we exploit the extra number of variables that we get by taking squares. Before going into the proof, it is convenient to define $\\Upsilon_{\\varepsilon}(\\alpha)$ for $\\alpha\\in [0,1)$ and $\\varepsilon>0$ by taking\r\n$$\\Upsilon_{\\varepsilon}(\\alpha)=q^{\\varepsilon}w_{2}(q)(1+n\\lvert\\alpha-a/q\\lvert)^{-1}$$ when $\\alpha\\in\\grM(a,q)\\subset\\grM$ and $\\Upsilon_{\\varepsilon}(\\alpha)=0$ otherwise. Using Lemma \\ref{prop4} we find that\r\n$$\\int_{\\grM\\setminus \\grN}\\lvert h(\\alpha)\\rvert^{4}\\lvert W(\\alpha)\\rvert^{4}d\\alpha\\ll P^{12}\\int_{\\grM\\setminus \\grN}\\lvert W(\\alpha)\\rvert^{4}\\Upsilon_{\\varepsilon}(\\alpha)^{4}d\\alpha.$$ \r\nObserve that combining Lemma \\ref{flo} with equation (\\ref{Wint}) we obtain that the contribution of the arcs with $q>M/4$ or $q\\leq M/4$ and $\\lvert\\beta\\rvert>  (12q)^{-1}H^{1/3}n^{-1}$ is $O\\big((HM)^{4}P^{6-\\delta}).$ Let $I'$ be the contribution to $I$ of the arcs with $q\\leq M/4$ and $\\lvert\\beta\\rvert\\leq (12q)^{-1}H^{1/3}n^{-1}$. Then  Lemma \\ref{prop4} yields\r\n\\begin{equation*}I'\\ll P^{12}(HM)^{2}(\\log P)^{-2}\\int_{\\grM\\setminus \\grN}\\lvert W(\\alpha)\\rvert^{2}\\Upsilon_{\\varepsilon}(\\alpha)^{6}d\\alpha,\\end{equation*}\r\nwhence using Lemma \\ref{flo} and (\\ref{Wint}) again we get that $I'=O\\big(P^{6}(HM)^{4}(\\log P)^{-4-2\\tau/3+\\varepsilon}\\big).$\r\nOn the other hand, an application of Lemma \\ref{lem06} gives the estimate\r\n\\begin{equation*}\\int_{\\grM\\setminus \\grN}\\lvert h^{*}(\\alpha)\\rvert^{4}\\lvert W^{*}(\\alpha)\\rvert^{4}\\ll P^{6}(HM)^{4}(\\log P)^{-4-2\\tau+\\varepsilon},\r\n\\end{equation*}which concludes the proof.\r\n\\end{proof}\r\n\r\n\\section{Singular integral and Proof of Theorem 1.1}\\label{sec6}\r\n\r\nWe briefly introduce the singular integral, give upper and lower bounds for it and discuss the size of the exceptional sets of the integers $n$ with large minor arc contribution and for which the $n$-th Fourier coefficient of $\\mathcal{F}(\\alpha)$ over $\\grM\\setminus\\grN$ is large as well.\r\nConsider \\begin{equation}\\label{Jn}J(n)=\\sum_{\\mathbf{p}}\\int_{\\mathbf{Y}}J_{\\mathbf{Y},\\mathbf{p}}(n)d\\mathbf{Y},\\end{equation} where we define the collection $J_{\\mathbf{Y},\\mathbf{p}}(n)$ of singular integrals by \\begin{equation*}J_{\\mathbf{Y},\\mathbf{p}}(n)=\\int_{-\\infty}^{\\infty}V_{\\mathbf{Y},\\mathbf{p}}(\\beta)e(-n\\beta)d\\beta\\ \\ \\ \\text{and}\\ \\ \\ \\ V_{\\mathbf{Y},\\mathbf{p}}(\\beta)=\\prod_{i=1}^{2}v_{\\mathbf{y}_{i},p_{i}}(\\beta)\\prod_{i=3}^{4}v_{\\mathbf{y}_{i}}(\\beta).\\end{equation*}\r\nThe range of integration taken above is the set of tuples $\\mathbf{Y}=(\\mathbf{y}_{1},\\ldots,\\mathbf{y}_{4})$ with $\\mathbf{y}_{1},\\mathbf{y}_{2}\\in\\mathcal{A}(H_{3},P^{\\eta})^{2}$ and $\\mathbf{y}_{3},\\mathbf{y}_{4}\\in\\mathcal{A}(P,P^{\\eta})^{2}$. Likewise, $\\mathbf{p}$ runs over pairs of primes $(p_{1},p_{2})$ with $M/2\\leq p_{i}\\leq M.$  Here the reader might find useful to recall (\\ref{vbeta}) and to observe that Lemma \\ref{lema4} guarantees the absolute convergence of the above integrals.\r\n\\begin{lem}\\label{JN}\r\nOne has that\r\n$$J(n)\\asymp (HM)^{2}(\\log N)^{-2}.$$\r\n\\end{lem}\r\n\\begin{proof}\r\nAn inspection of the proof of Lemma 5.1 of \\cite{Pli1} reveals that the positivity and the upper bound for $J_{\\mathbf{Y},\\mathbf{p}}(n)$ deduced there remain valid subject only to the condition $s+t\\geq 2$. Consequently, on making the choices $k=s=t=2$ here we obtain $0\\leq J_{\\mathbf{Y},\\mathbf{p}}(n)\\ll P^{-4}H^{2/3}$, whence applying this estimate trivially to (\\ref{Jn}) gives the required upper bound. Likewise, when $M/2\\leq p_{i}\\leq 51 M/100$ for $i\\leq t$ and $\\mathbf{y}_{i}\\leq P/2$ for $t+1\\leq i\\leq s+t$ then the lower bound obtained in that lemma also holds as long as $\\big(\\big(3/8\\big)^{k}s+\\big(1/8\\big)^{k}t\\big)P^{3k}<n$. Therefore, on considering such range here we get that $J_{\\mathbf{Y},\\mathbf{p}}(n)\\gg P^{-4}H^{2/3}$. Observe that the set of tuples on that range has positive density over the set without the restrictions. Consequently, the preceeding remark and the positivity of $J_{\\mathbf{Y},\\mathbf{p}}(n)$ deliver the lower bound stated at the beginning.\r\n\\end{proof}\r\nWe remind the reader of the definition (\\ref{Vup}). Note that then the combination of Lemma \\ref{lema4} and equation (\\ref{tup}) with a change of variables yields\r\n\\begin{equation}\\label{hWW}\\int_{\\grM}h^{*}(\\alpha)^{2}W^{*}(\\alpha)^{2}e(-\\alpha n)d\\alpha=\\frak{S}(n)J(n)+O\\big((HM)^{2}N^{-\\delta}\\big).\\end{equation}\r\nFor the rest of the section we introduce the exceptional sets which arise in both the major and the minor arc analysis and we give bounds for the cardinality of them. Let $\\delta>0$ and let $\\mathcal{E}_{\\delta}(N)$ denote the set of integers $N/2\\leq n\\leq N$ such that \r\n$$\\int_{\\grm} h(\\alpha)^{2}W(\\alpha)^{2}e(-n\\alpha)d\\alpha\\gg (HM)^{2}P^{-\\delta/2}.$$ Likewise, define $\\mathcal{E}(N)$ to be the set of integers $N/2\\leq n\\leq N$ for which\r\n\\begin{equation}\\label{exc}\\int_{\\grM\\setminus\\grN}\\mathcal{F}(\\alpha)e(-n\\alpha)d\\alpha\\gg (HM)^{2}(\\log P)^{-2-2\\tau/9}.\\end{equation}\r\n\\begin{prop}\\label{prop1}\r\nWith the above notation, one has that $$\\lvert \\mathcal{E}(N)\\rvert\\ll N(\\log N)^{-2\\tau/9+\\varepsilon},$$ and there exists some $\\delta>0$ for which $\\lvert \\mathcal{E}_{\\delta}(N)\\rvert\\ll N^{1-\\delta}.$\r\n\\end{prop}\r\n\\begin{proof}\r\nWe obtain these two bounds via a routine application of Bessel's inequality. For such matters, observe first that Proposition 1 of \\cite{Pli1} gives the estimate $$\\int_{\\grm}\\lvert h(\\alpha)W(\\alpha)\\rvert^{4}d\\alpha\\ll (HM)^{4}P^{6-2\\delta},$$ for some $\\delta>0$. Define the Fourier coefficient $c(n)$ of the product of the generating functions on the minor arcs by $$c(n)=\\int_{\\grm} h(\\alpha)^{2}W(\\alpha)^{2}e(-n\\alpha)d\\alpha.$$ Note that Bessel's inequality yields\r\n$$\\sum_{N/2\\leq n\\leq N}\\lvert c(n)\\rvert^{2}\\ll \\int_{\\grm}\\lvert h(\\alpha)W(\\alpha)\\rvert^{4}d\\alpha\\ll (HM)^{4}P^{6-2\\delta},$$whence the bound on $\\lvert\\mathcal{E}_{\\delta}(N)\\rvert$ follows from last equation.\r\nSimilarly, we introduce the Fourier coefficient $$a(n)=\\int_{\\grM\\setminus\\grN}\\mathcal{F}(\\alpha)e(-n\\alpha)d\\alpha.$$ Then by Proposition \\ref{lem7} and Bessel's inequality we get\r\n$$\\sum_{N/2\\leq n\\leq N}\\lvert a(n)\\rvert^{2}\\ll \\int_{\\grM\\setminus\\grN}\\lvert \\mathcal{F}(\\alpha)\\rvert^{2}d\\alpha\\ll P^{6}(HM)^{4}(\\log P)^{-4-2\\tau/3+\\varepsilon},$$\r\nwhich yields the bound for $\\lvert\\mathcal{E}(N)\\rvert$ stated at the beginning of the proposition.\r\n\\end{proof}\r\n\\emph{Proof of Theorem \\ref{thm01}}. Take $n\\in\\mathbb{N}$ with $N/2\\leq n\\leq N$ and $n\\notin  \\mathcal{E}_{\\delta}(N)\\cup \\mathcal{E}(N).$ Recalling the definitions before (\\ref{exc}) and combining Propositions \\ref{prop11} and (\\ref{hWW}) we obtain\r\n\\begin{align*}\r\nR(n)&\r\n=\\int_{\\grm}h(\\alpha)^{2}W(\\alpha)^{2}e(-\\alpha n)d\\alpha+\\int_{\\grM}h^{*}(\\alpha)^{2}W^{*}(\\alpha)^{2}e(-\\alpha n)d\\alpha+\\int_{\\grM}\\mathcal{F}(\\alpha)e(-\\alpha n)d\\alpha\r\n\\\\\r\n&=\\frak{S}(n)J(n)+O\\big((HM)^{2}(\\log N)^{-2-2\\tau/9+\\varepsilon}\\big).\r\n\\end{align*}\r\nNow fix a parameter $\\upsilon<2\\tau/9$. Then applying Lemmata \\ref{lema3} and \\ref{JN} we find that whenever $n$ is as described above with the additional condition $n\\notin A_{\\upsilon}(N)$ then one has\r\n$$R(n)\\gg (HM)^{2}(\\log N)^{-2-\\upsilon}.$$ Observe that by Lemma \\ref{lema3} and Proposition \\ref{prop1} the cardinality of the set of integers $N/2\\leq n\\leq N$ with $n\\notin  \\mathcal{E}_{\\delta}(N)\\cup \\mathcal{E}(N)\\cup A_{\\upsilon}(N)$ is $O\\big(N(\\log N)^{-\\upsilon}\\big).$ Consequently, summing over dyadic intervals and observing that we can take $\\upsilon$ to be as close to $2\\tau/9$ as possible we obtain the desired result.\r\n\r\n\r\n\r\n\\begin{thebibliography}{9}\r\n\r\n\\bibitem{Hea} D.R. Heath-Brown, \\emph{The circle method and diagonal cubic forms}, Phil. Trans. Roy. Soc. London Ser. A 356 (1998), 673--699.\r\n\\bibitem{Hol1} C. Hooley, \\emph{On Waring's problem}, Acta Math., 157 (1986), 49--97.\r\n\\bibitem{Hol2} C. Hooley, \\emph{On Hypothesis $K^{*}$ in Waring's problem}, Sieve methods, exponential sums and their applications in number theory (Cardiff, 1995), London Math. Soc. Lecture Note Ser., 237, Cambridge University Press, Cambridge 1997,  175--185.\r\n\\bibitem{MonVa} Hugh L. Montgomery, R. C. Vaughan, \\emph{The exceptional set in Goldbach's problem,} Acta Arith. 27 (1975), 353--370.\r\n\\bibitem{Mon} Hugh L. Montgomery, R. C. Vaughan, \\emph{Multiplicative Number Theory: I. Classical Theory}, Cambridge University Press, 2006.\r\n\\bibitem{Pli} J. Pliego, \\emph{On Waring's problem in sums of three cubes}, preprint.\r\n\\bibitem{Pli1} J. Pliego, \\emph{On Waring's problem in sums of three cubes for smaller powers}, preprint.\r\n\\bibitem{Vau} R. C. Vaughan, \\emph{The Hardy-Littlewood method}, 2nd edition, Cambridge University Press, Cambridge, 1997.\r\n\\bibitem{Woo7} T. D. Wooley, \\emph{Slim exceptional sets for sums of four squares}, Proc. London Math. Soc. (3) 85 (2002), 1--21.\r\n\\bibitem{Woo8} T. D. Wooley, \\emph{Slim Exceptional Sets for Sums of Cubes}, Canad. J. Math. Vol. 54 (2), (2002), 417--448.\r\n\\bibitem{Woo3} T. D. Wooley, \\emph{Sums of three cubes, II}, Acta Arith. 170, No. 1 (2015), 73--100.\r\n\r\n\\end{thebibliography}\r\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:03:05", "yymm": "2010", "arxiv_id": "2010.14572", "url": "https://arxiv.org/abs/2010.14572", "source": "arxiv"}}
{"text": "%% LyX 2.3.1-1 created this file.  For more info, see http://www.lyx.org/.\r\n%% Do not edit unless you really know what you are doing.\r\n\\documentclass[12pt,oneside,english]{amsart}\r\n\\usepackage[T1]{fontenc}\r\n\\usepackage[latin9]{inputenc}\r\n\\usepackage{geometry}\r\n\\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=2.5cm,rmargin=2.5cm,headheight=1cm,headsep=1cm,footskip=1cm}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{amstext}\r\n\\usepackage{amsthm}\r\n\\usepackage{amssymb}\r\n\r\n\\makeatletter\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.\r\n\\numberwithin{equation}{section}\r\n\\numberwithin{figure}{section}\r\n\\theoremstyle{plain}\r\n\\newtheorem{thm}{\\protect\\theoremname}[section]\r\n\\theoremstyle{plain}\r\n\\newtheorem{question}[thm]{\\protect\\questionname}\r\n\\theoremstyle{plain}\r\n\\newtheorem{lem}[thm]{\\protect\\lemmaname}\r\n\\theoremstyle{plain}\r\n\\newtheorem{prop}[thm]{\\protect\\propositionname}\r\n\\theoremstyle{plain}\r\n\\newtheorem{cor}[thm]{\\protect\\corollaryname}\r\n\\theoremstyle{remark}\r\n\\newtheorem{rem}[thm]{\\protect\\remarkname}\r\n\\theoremstyle{definition}\r\n\\newtheorem{defn}[thm]{\\protect\\definitionname}\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.\r\n\\usepackage{amsthm}\r\n\\usepackage{amscd}\r\n\r\n\\makeatother\r\n\r\n\\usepackage{babel}\r\n\\providecommand{\\corollaryname}{Corollary}\r\n\\providecommand{\\definitionname}{Definition}\r\n\\providecommand{\\lemmaname}{Lemma}\r\n\\providecommand{\\propositionname}{Proposition}\r\n\\providecommand{\\questionname}{Question}\r\n\\providecommand{\\remarkname}{Remark}\r\n\\providecommand{\\theoremname}{Theorem}\r\n\r\n\\begin{document}\r\n\\global\\long\\def\\R{\\mathbb{R}}%\r\n\r\n\\global\\long\\def\\C{\\mathbb{C}}%\r\n\r\n\\global\\long\\def\\Q{\\mathbb{Q}}%\r\n\r\n\\global\\long\\def\\Z{\\mathbb{Z}}%\r\n\r\n\\global\\long\\def\\P{\\mathbb{P}}%\r\n\r\n\\global\\long\\def\\T{\\mathbb{T}}%\r\n\r\n\\global\\long\\def\\F{\\mathbb{F}}%\r\n\r\n\\global\\long\\def\\bbN{\\mathbb{N}}%\r\n\r\n\\global\\long\\def\\A{\\mathrm{A}}%\r\n\r\n\\global\\long\\def\\H{\\mathrm{H}}%\r\n\r\n\\global\\long\\def\\D{\\mathrm{\\mathrm{D}}}%\r\n\r\n\\global\\long\\def\\B{\\mathrm{\\mathrm{B}}}%\r\n\r\n\\global\\long\\def\\N{\\mathrm{\\mathrm{N}}}%\r\n\r\n\\global\\long\\def\\inf{\\mathrm{inf}}%\r\n\r\n\\global\\long\\def\\sup{\\mathrm{sup}}%\r\n\r\n\\global\\long\\def\\Hom{\\mathbb{\\mathrm{Hom}}}%\r\n\r\n\\global\\long\\def\\Ext{\\mathbb{\\mathbb{\\mathrm{Ext}}}}%\r\n\r\n\\global\\long\\def\\Ker{\\mathbb{\\mathrm{Ker}}}%\r\n\r\n\\global\\long\\def\\Gal{\\mathrm{Gal}}%\r\n\r\n\\global\\long\\def\\Aut{\\mathrm{Aut}}%\r\n\r\n\\global\\long\\def\\End{\\mathrm{End}}%\r\n\r\n\\global\\long\\def\\Char{\\mathrm{Char}}%\r\n\r\n\\global\\long\\def\\rank{\\mathrm{rank}}%\r\n\r\n\\global\\long\\def\\deg{\\mathrm{deg}}%\r\n\r\n\\global\\long\\def\\det{\\mathrm{det}}%\r\n\r\n\\global\\long\\def\\Tr{\\mathrm{Tr}}%\r\n\r\n\\global\\long\\def\\Id{\\mathrm{Id}}%\r\n\r\n\\global\\long\\def\\Spec{\\mathrm{Spec}}%\r\n\r\n\\global\\long\\def\\Lie{\\mathrm{Lie}}%\r\n\r\n\\global\\long\\def\\span{\\mathrm{span}}%\r\n\r\n\\global\\long\\def\\sep{\\mathrm{sep}}%\r\n\r\n\\global\\long\\def\\sgn{\\mathrm{sgn}}%\r\n\r\n\\global\\long\\def\\dist{\\mathrm{dist}}%\r\n\r\n\\global\\long\\def\\val{\\mathrm{val}}%\r\n\r\n\\global\\long\\def\\dR{\\mathrm{dR}}%\r\n\r\n\\global\\long\\def\\st{\\mathrm{st}}%\r\n\r\n\\global\\long\\def\\rig{\\mathrm{rig}}%\r\n\r\n\\global\\long\\def\\cris{\\mathrm{cris}}%\r\n\r\n\\global\\long\\def\\Mat{\\mathrm{Mat}}%\r\n\r\n\\global\\long\\def\\cyc{\\mathrm{cyc}}%\r\n\r\n\\global\\long\\def\\et{\\mathrm{\\acute{e}t}}%\r\n\r\n\\global\\long\\def\\Frob{\\mathrm{Frob}}%\r\n\r\n\\global\\long\\def\\SL{\\mathrm{SL}}%\r\n\r\n\\global\\long\\def\\GL{\\mathrm{GL}}%\r\n\r\n\\global\\long\\def\\Br{\\mathrm{Br}}%\r\n\r\n\\global\\long\\def\\Ind{\\mathrm{Ind}}%\r\n\r\n\\global\\long\\def\\LT{\\mathrm{LT}}%\r\n\r\n\\global\\long\\def\\Res{\\mathrm{Res}}%\r\n\r\n\\global\\long\\def\\SL{\\mathrm{SL}_{2}}%\r\n\r\n\\global\\long\\def\\Mod{\\mathrm{Mod}}%\r\n\r\n\\global\\long\\def\\Fil{\\mathrm{Fil}}%\r\n\r\n\\global\\long\\def\\la{\\mathrm{la}}%\r\n\r\n\\global\\long\\def\\pa{\\mathrm{pa}}%\r\n\r\n\\global\\long\\def\\Sen{\\mathrm{Sen}}%\r\n\r\n\\global\\long\\def\\dif{\\mathrm{dif}}%\r\n\r\n\\global\\long\\def\\HT{\\mathrm{HT}}%\r\n\r\n\\global\\long\\def\\Kla{K-\\mathrm{la}}%\r\n\r\n\\global\\long\\def\\Kpa{K-\\mathrm{pa}}%\r\n\r\n\\global\\long\\def\\an{\\mathrm{an}}%\r\n\r\n\\global\\long\\def\\grad{\\mathrm{\\triangledown}}%\r\n\r\n\\global\\long\\def\\weak{\\rightharpoonup}%\r\n\r\n\\global\\long\\def\\weakstar{\\overset{*}{\\rightharpoonup}}%\r\n\r\n\\title{Lubin-Tate theory and overconvergent Hilbert modular forms of low\r\nweight}\r\n\\author{Gal Porat}\r\n\\begin{abstract}\r\nLet $K$ be a finite extension of $\\Q_{p}$ and let $\\Gamma$ be the\r\nGalois group of the cyclotomic extension of $K$. Fontaine's theory\r\ngives a classification of $p$-adic representations of $\\Gal\\left(\\overline{K}/K\\right)$\r\nin terms of $(\\varphi,\\Gamma)$-modules. A useful aspect of this classification\r\nis Berger's dictionary which expresses invariants coming from $p$-adic\r\nHodge theory in terms of these $\\left(\\varphi,\\Gamma\\right)$-modules.\r\n\r\nIn this article, we use the theory of locally analytic vectors to\r\ngeneralize this dictionary to the setting where $\\Gamma$ is the Galois\r\ngroup of a Lubin-Tate extension of $K$. As an application, we show\r\nthat if $F$ is a totally real number field and $v$ is a place of\r\n$F$ lying above $p$, then the $p$-adic representation of $\\Gal\\left(\\overline{F}_{v}/F_{v}\\right)$\r\nassociated to a finite slope overconvergent Hilbert eigenform which\r\nis $F_{v}$-analytic up to a twist is Lubin-Tate trianguline. Furthermore,\r\nwe determine a triangulation in terms of a Hecke eigenvalue at $v$.\r\nThis generalizes results in the case $F=\\Q$ obtained previously by\r\nChenevier, Colmez and Kisin.\r\n\\end{abstract}\r\n\r\n\\maketitle\r\n\\tableofcontents{}\r\n\r\n\\section{Introduction}\r\n\r\nLet $p$ be a prime number. Kisin showed in \\cite{Ki03} that the\r\n$p$-adic representation $\\rho_{f}$ of $\\Gal\\left(\\overline{\\Q}/\\Q\\right)$\r\nattached to a finite slope $p$-adic eigenform $f$ has a very special\r\nproperty: its restriction to $\\Gal\\left(\\overline{\\Q}_{p}/\\Q_{p}\\right)$\r\nalways has a crystalline period. Even better, this period is an eigenvector\r\nfor crystalline Frobenius, with eigenvalue coinciding with that arising\r\nfrom the Hecke action of $U_{p}$ on $f$. Consequently, Kisin was\r\nable to verify the Fontaine-Mazur conjecture for these $p$-adic representations.\r\nIn a subsequent work \\cite{Co08}, Colmez gave a reinterpertation\r\nof Kisin's result to the effect that the $(\\varphi,\\Gamma)$-module\r\nattached to $\\rho_{f}|_{\\Gal\\left(\\overline{\\Q}_{p}/\\Q_{p}\\right)}$\r\nis an extension of $\\left(\\varphi,\\Gamma\\right)$-modules of rank\r\n1, where $\\Gamma\\cong\\Z_{p}^{\\times}$ is the Galois group of the\r\ncyclotomic extension of $\\Q_{p}$. Colmez coined the term ``trianguline''\r\nfor the $p$-adic representations satisfying this property, and studied\r\nthem in detail in dimension 2. Then in \\cite{Co10} he attached to\r\nany 2-dimensional trianguline representation of $\\Gal\\left(\\overline{\\Q}_{p}/\\Q_{p}\\right)$\r\na unitary Banach representation of $\\GL_{2}\\left(\\Q_{p}\\right)$.\r\nBy a suitable continuity argument he was able to extend this procedure\r\nto any $2$-dimensional $p$-adic representation of $\\Gal\\left(\\overline{\\Q}_{p}/\\Q_{p}\\right)$,\r\nthereby constructing the $p$-adic Langlands correspondence for $\\GL_{2}(\\Q_{p})$.\r\nThis circle of ideas came to a satisfying conclusion when Emerton\r\nused this correspondence in \\cite{Em11} to show that the trianguline\r\nproperty at $\\Gal\\left(\\overline{\\Q}_{p}/\\Q_{p}\\right)$ characterizes\r\nthese 2-dimensional representations of $\\Gal\\left(\\overline{\\Q}/\\Q\\right)$\r\nwhich are attached to finite slope $p$-adic eigenforms.\r\n\r\nIn this article, we are concerned with performing the reinterpertation\r\nstep of Colmez in an analogous story when $\\Q$ is replaced with a\r\ntotally real number field $F$. Namely, the $p$-adic representation\r\n$\\rho_{f}$ of $\\Gal(\\overline{F}/F)$ will be attached to a finite\r\nslope $p$-adic Hilbert eigenform $f$, and we would like to show\r\n$\\rho_{f}$ is trianguline at a place $v\\mid p$. However, when $F_{v}\\neq\\Q_{p}$,\r\nthere is more than one meaning one can attach to the phrase ``$\\rho_{f}$\r\nis trianguline at a place $v\\mid p$''. On the one hand, there are\r\n\\emph{cyclotomic trianguline} $\\Gal(\\overline{F}_{v}/F_{v})$-representations.\r\nThese are the trianguline representations in the sense of Nakamura\r\nin \\cite{Na09}; in that setting, $\\Gamma$ is the Galois group of\r\nthe cyclotomic extension of $F_{v}$ and is isomorphic to an open\r\nsubgroup of $\\Z_{p}^{\\times}$. On the other hand, there are \\emph{Lubin-Tate\r\ntrianguline} $\\Gal(\\overline{F}_{v}/F_{v})$-representations in the\r\nsense of Fourquaux and Xie in \\cite{FX13}, where $\\Gamma=\\Gamma_{F_{v}}$\r\nis the Galois group of a Lubin-Tate extension and is isomorphic to\r\n$\\mathcal{O}_{F_{v}}^{\\times}$. The representation $\\rho_{f}|_{\\Gal(\\overline{F}_{v}/F_{v})}$\r\nhas been known to be cyclotomic trianguline for a while by the global\r\ntriangulation theory of Kedlaya-Pottharst-Xiao in \\cite{KPX14} and\r\nLiu in \\cite{Li12}. Although these results have found many applications,\r\nit seems like this notion of cyclotomic triangulinity may not be the\r\nmost suitable for applications to a hypothetical $p$-adic Langlands\r\ncorrespondence for $\\GL_{2}(F_{v})$. Rather, the replacement of $\\Z_{p}^{\\times}$\r\nby $\\mathcal{O}_{F_{v}}^{\\times}$ seems more natural, which leads\r\nus in this work to focus on the notion of Lubin-Tate triangulinity\r\nof Fourquaux and Xie.\r\n\r\nLet us explain what the difficulties are in proving such a result\r\nwhen $F_{v}\\neq\\Q_{p}$. The methods of \\cite{KPX14} and \\cite{Li12}\r\ncan still be used to show the existence of a crystalline period which\r\nis a Frobenius eigenvector. However, Colmez's reformulation of this\r\ncondition in terms of $\\left(\\varphi,\\Gamma\\right)$-module for $F_{v}=\\Q_{p}$\r\nrelies on Berger's dictionary, which expresses invariants coming from\r\n$p$-adic Hodge theory in terms of these $\\left(\\varphi,\\Gamma\\right)$-modules.\r\nThis dictionary is only available in the cyclotomic setting. Indeed,\r\nthe proof of this dictionary ultimately relies on Sen theory and the\r\nCherbonnier-Colmez theorem. Unfortunately, a direct attempt to use\r\nthese methods breaks down whenever $F_{v}\\neq\\Q_{p}$, because of\r\nthe failure of the Tate-Sen axioms for Lubin-Tate extensions.\r\n\r\nNow let $K$ be a finite extension of $\\Q_{p}$. Recall that a representation\r\n$V$ of $\\Gal(\\overline{K}/K)$ with coefficients in $K$ is called\r\n$K$-analytic if $\\C_{p}\\otimes_{K}^{\\tau}V$ is trivial for each\r\nnontrivial embedding $\\tau:K\\rightarrow\\overline{K}$. In \\cite{BC16},\r\nBerger and Colmez were able to find a certain generalization of Sen\r\ntheory for Lubin-Tate extensions of $K$ using ideas coming from the\r\ntheory of $K$-locally analytic vectors. Berger then used this theory\r\nin \\cite{Be16} to prove that $K$-analytic representations are overconvergent,\r\nso that we can associate to $V$ a Lubin-Tate $(\\varphi_{q},\\Gamma_{K})$-module\r\n$\\D_{\\rig,K}^{\\dagger}(V)$ over the (Lubin-Tate) Robba ring $\\B_{\\rig,K}^{\\dagger}$\r\n(see $\\mathsection5$). By adapting the original techniques of \\cite{Be02}\r\nto the setting of $K$-locally analytic vectors, we are able to extend\r\nBerger's dictionary to Lubin-Tate extensions of $K$. Our first main\r\nresult is the following (see Theorem 5.4).\\\\\r\n\r\n\\textbf{Theorem A. }\\emph{Let $V$ be a $K$-analytic representation\r\nof $G_{K}$. For $*\\in\\left\\{ \\Sen,\\dif,\\dR,\\cris,\\st\\right\\} $,\r\nthere is a natural isomorphism\r\n\\[\r\n\\D_{*,K}(V)\\cong\\D_{*,K}\\left(\\D_{\\rig,K}^{\\dagger}(V)\\right).\r\n\\]\r\n}\\\\\r\n\r\nFor the definition of the functors $\\D_{*,K}$ we refer to $\\mathsection3$.\r\nWhen $K=\\Q_{p}$ they coincide with the usual definitions and the\r\ntheorem is already known, but note that in contrast, it is not a-priori\r\nclear how to even define $\\D_{\\Sen,K}$ and $\\D_{\\dif,K}$ in the\r\ngeneral case. \r\n\r\nWhen $V$ is 2-dimensional, one can deduce from Theorem A that the\r\nLubin-Tate triangulinity of $V$ can be detected from the existence\r\nof a crystalline period which is a Frobenius eigenvector. On the other\r\nhand, techniques going back to the original paper of Colmez show that\r\nthe cyclotomic triangulinity of $V$ can also be detected in a similar\r\nway. From this we deduce that the two notions of triangulinity actually\r\ncoincide for $K$-analytic representations of dimension 2 (see Theorem\r\n6.8 for a more precise version).\\\\\r\n\r\n\\textbf{Theorem B. }\\emph{Let $V$ be a 2-dimensional $K$-analytic\r\nrepresentation of $G_{K}$. Then $V$ is Lubin-Tate trianguline if\r\nand only if $V$ is cyclotomic trianguline.}\\\\\r\n\r\nAlthough we do not pursue this here, it can be shown that under some\r\ngenericity assumptions the theorem is true for $V$ of arbitrary dimension.\r\nIn addition, let us mention that after the completion of this paper\r\nwe have been informed that a result of L\u00e9o Poyeton establishes an\r\nequivalence of categories between analytic Lubin-Tate $(\\varphi_{q},\\Gamma_{K})$-modules\r\nand analytic $\\B$-pairs. It seems likely one can also prove Theorem\r\nB as a consequence of this equivalence.\r\n\r\nAs mentioned above, it is known that the local Galois representations\r\nassociated to finite slope overconvergent Hilbert eigenforms are cyclotomic\r\ntrianguline. It is then natural to use Theorem B to translate this\r\ninto a Lubin-Tate triangulinity result, provided that this local representation\r\nis analytic. Furthermore, it is possible to explicitly determine this\r\ntriangulation, generalizing previous work of Chenevier and Colmez\r\n(see Theorem 7.4 for a more precise statement). To state the result,\r\nlet $\\rho_{f}$ be the $p$-adic representation of $\\Gal(\\overline{F}/F)$\r\nassociated to a finite slope overconvergent Hilbert eigenform of weights\r\n$(k,1,...,1)$ at $v$ and determinant $\\eta\\chi_{\\cyc}^{w-1}$ for\r\nsome potentially unramified character $\\eta$. For the sake of simplifying\r\nthe introduction, assume here that the restriction of $\\rho_{f}$\r\nto a decomposition group $G_{F_{v}}=\\Gal(\\overline{F}_{v}/F_{v})$\r\nhas coefficients in $F_{v}$ and that $k,w\\in\\Z$. Removing these\r\nassumptions only requires introducing more notation. To state the\r\nresult, choose a uniformizer $\\pi_{v}$ of $F_{v}$, write $\\chi_{\\pi_{v}}$\r\nfor the corresponding Lubin-Tate character and let $a_{v}\\in F_{v}^{\\times}$\r\nbe such that $U_{v}f=a_{v}f$.  If $y\\in F_{v}^{\\times}$, write\r\n$\\mu_{y}:F_{v}^{\\times}\\rightarrow F_{v}^{\\times}$ for the character\r\ndefined by $\\mu_{y}(z)=y^{\\val_{\\pi_{v}}(z)}$. Let $x:F_{v}^{\\times}\\rightarrow F_{v}^{\\times}$\r\nbe the character $x(z)=z$ and $x_{0}:F_{v}^{\\times}\\rightarrow F_{v}^{\\times}$\r\nbe the character $x_{0}(z)=x/\\mu_{\\pi_{v}}$. We say that $f$ is\r\n$F_{v}$-analytic up to a twist if the same holds for $\\rho_{f}|_{G_{F_{v}}}$.\\\\\r\n\r\n\\textbf{Theorem C. }\\emph{Suppose that $f$ is $F_{v}$-analytic up\r\nto a twist. Then it is Lubin-Tate trianguline. If $\\D_{\\rig,F_{v}}^{\\dagger}\\left(\\rho_{f}|_{G_{F_{v}}}^{\\vee}\\right)$\r\nis the $\\left(\\varphi_{q},\\Gamma_{F_{v}}\\right)$-module over $\\B_{\\rig,F_{v}}^{\\dagger}$\r\nassociated to $\\rho_{f}|_{G_{F_{v}}}^{\\vee}$, a triangulation is\r\ngiven by the short exact sequence  \r\n\\[\r\n0\\rightarrow\\B_{\\rig,F_{v}}^{\\dagger}\\left(\\delta_{1}\\right)\\rightarrow\\D_{\\rig,K}^{\\dagger}\\left(\\rho_{f}|_{G_{F_{v}}}^{\\vee}\\right)\\rightarrow\\B_{\\rig,F_{v}}^{\\dagger}\\left(\\delta_{2}\\right)\\rightarrow0,\r\n\\]\r\nwhere $\\delta_{2}=\\delta_{1}^{-1}\\det(V)$ and $\\delta_{1}:F_{v}^{\\times}\\rightarrow F_{v}^{\\times}$\r\nis a character. Here and $\\delta_{1}$ and $\\rho_{f}|_{G_{F_{v}}}$\r\nsatisfy the following. }\r\n\\begin{enumerate}\r\n\\item \\emph{If $k\\notin\\Z_{\\geq1}$ then $\\delta_{1}=\\mu_{a_{v}}x_{0}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ x_{0}\\right)^{\\frac{1-w}{2}}$\r\nand $\\rho_{f}|_{G_{F_{v}}}$ is irreducible and not Hodge-Tate.}\r\n\\item \\emph{If $k\\in\\Z_{\\geq1}$ and $\\val_{\\pi_{v}}(a_{v})<\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right]$,\r\nthen $\\delta_{1}=\\mu_{a_{v}}x_{0}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ x_{0}\\right)^{\\frac{1-w}{2}}$\r\nand $\\rho_{f}|_{G_{F_{v}}}$ is irreducible and potentially semistable.}\r\n\\item \\emph{If $k\\in\\Z_{>1}$ and} $\\val_{\\pi_{v}}(a_{v})=\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right]$,\r\nthen either\r\n\\begin{enumerate}\r\n\\item $\\delta_{1}=\\mu_{a_{v}}x_{0}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ x_{0}\\right)^{\\frac{1-w}{2}}$\r\nand \\emph{$\\rho_{f}|_{G_{F_{v}}}$ is reducible, nonsplit and potentially\r\nordinary, or}\r\n\\item $\\delta_{1}=x^{1-k}\\mu_{a_{v}}x_{0}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ x_{0}\\right)^{\\frac{1-w}{2}}$\r\nand \\emph{$\\rho_{f}|_{G_{F_{v}}}$ is a sum of two characters and\r\npotentially crystalline.}\r\n\\end{enumerate}\r\n\\item \\emph{If $k\\in\\Z_{\\geq1}$ and $\\val_{\\pi_{v}}(a_{v})>\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right]$,\r\nthen $\\delta_{1}=x^{1-k}\\mu_{a_{v}}x_{0}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ x_{0}\\right)^{\\frac{1-w}{2}}$\r\nand $\\rho_{f}|_{G_{F_{v}}}$ is irreducible, Hodge-Tate and not potentially\r\nsemistable.}\\\\\r\n\\end{enumerate}\r\nThe condition on the weights at $v$ to be of the form $(k,1,...,1)$\r\nis necessary but not sufficient for $f$ to be $F_{v}$-analytic up\r\nto a character twist. In fact, the computations of \\cite[Proposition 2.10]{Na09}\r\nand \\cite[Theorem 0.3]{FX13} suggest that this stronger condition\r\nof $F_{v}$-analyticity cuts out a locus of codimension $[F_{v}:\\Q_{p}]-1$\r\ninside the locus of weights $(k,1,...,1)$ at $v$ of the Hilbert\r\neigenvariety. However, under suitable local-global compatibility conjectures,\r\nit contains all classical points of weights $(k,1,...,1)$. We believe\r\nit might be possible to obtain a version of Theorem C for arbitrary\r\n$f$ if one works with $\\left(\\varphi_{q},\\Gamma_{F_{v}}\\right)$-modules\r\nover multivariable Robba rings as in \\cite{Be13}.\r\n\r\nFinally, we make some further speculations. For simplicity, assume\r\nthat $p$ is inert in $F$. The small slope condition $\\val_{p}(a_{p})<\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{p}:\\Q_{p}\\right]$\r\nin Theorem C agrees with the optimal bound in partial weight 1 conjectured\r\nin an unpublished note of Breuil (see Proposition 4.3 of \\cite{Br10}).\r\nThis suggests that $F_{p}$-analytic finite slope $p$-adic Hilbert\r\neigenforms of weights $(k,1,...,1)$ and $\\val_{p}(a_{p})<\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{p}:\\Q_{p}\\right]$\r\nshould be classical. If such a classicality criterion were known,\r\nan argument as in Theorem 6.6 of \\cite{Ki03} using our Theorem 7.4\r\nwould verify the Fontaine-Mazur conjecture for representations which\r\narise from $F_{v}$-analytic finite slope $p$-adic Hilbert eigenforms.\r\nConversely, if the Fontaine-Mazur conjecture were known in our context\r\nthen Theorem 7.4 would imply such a classicaility criterion. See $\\mathsection7.2$\r\nfor a more precise discussion.\r\n\r\nIn another direction, suppose again that $p$ is inert in $F$ and\r\nthat $V$ is a $p$-adic representation of $\\Gal(\\overline{F}/F)$\r\nwhich is irreducible, totally odd, unramified at almost all primes\r\nand Lubin-Tate trianguline at $p$. Recall again the theorem of Emerton\r\n(Theorem 1.2.4 of \\cite{Em11}) which asserts that if $F=\\Q$ and\r\n$\\overline{V}$ satisfies certain technical conditions then $V$ is\r\nthe character twist of the Galois representation attached to an (elliptic)\r\noverconvergent $p$-adic eigenform of finite slope. In light of Theorem\r\n7.4, we ask the following.\r\n\\begin{question}\r\nIs $V$ necessarily the character twist of a representation attached\r\nto an $F_{p}$-analytic overconvergent $p$-adic Hilbert eigenform\r\nof finite slope?\r\n\\end{question}\r\n\r\n\r\n\\subsection{Structure of the article}\r\n\r\n$\\mathsection2$ contains preliminaries regarding locally $K$-analytic\r\nvectors. In $\\mathsection3$ we define the functors $\\D_{*,K}$ for\r\n\\emph{$*\\in\\left\\{ \\Sen,\\dif,\\dR,\\cris,\\st\\right\\} $} and prove their\r\nbasic properties. In $\\mathsection4$ we study some big period rings\r\nand their $K$-locally analytic vectors. Theorem A is proved in $\\mathsection5$.\r\nThis proof involves reinterperting several constructions in $p$-adic\r\nHodge theory in terms of $K$-locally analytic vectors, as well as\r\nsome computations with rather large rings of periods, and so involves\r\nmost of the work done in $\\mathsection\\mathsection2$-5. In $\\mathsection6$\r\nwe relate this to Lubin-Tate triangulinity and prove Theorem B. Finally,\r\nin $\\mathsection7$ we prove Theorem C, concluding with an example.\r\n\r\n\\subsection{Notations and conventions}\r\n\r\nThe field $K$ denotes a finite extension of $\\Q_{p}$, with ring\r\nof integers $\\mathcal{O}_{K}$, uniformizer $\\pi$, and residue field\r\n$k$. The field $K_{0}=\\mathrm{W}(k)[1/p]$ is the maximal unramified\r\nsubextension of $K$. Let $q=p^{f}$ be the cardinality of the residue\r\nfield and $e$ the absolute ramification index of $K$, so that $[K:\\Q_{p}]=ef$.\r\nWe let $\\Sigma_{K}$ denote the set of embeddings of $K$ into $\\overline{\\Q}_{p}$.\r\n\r\nDenote by $G_{K}$ the absolute Galois group of $K$. If $\\mathcal{F}$\r\nis a formal Lubin-Tate group associated to $\\pi$, then $K_{n}=K(\\mathcal{F}[\\pi^{n}])$\r\nand $K_{\\infty}=\\cup_{n\\geq1}K_{n}$ are abelian extensions of $K$\r\nwhich depend only on $\\pi$. The Lubin-Tate character $\\chi_{\\pi}:G_{K}\\rightarrow\\mathcal{O}_{K}^{\\times}$\r\nis the character given by the action of $G_{K}$ on $\\mathcal{F}[\\pi^{\\infty}]$.\r\nIt induces an isomorphism of $\\Gamma_{K}=\\Gal(K_{\\infty}/K)$ with\r\n$\\mathcal{O}_{K}^{\\times}$. Its kernel is $H_{K}=\\Gal(\\overline{K}/K_{\\infty})$,\r\nand $G_{K}/H_{K}=\\Gamma_{K}$. The cyclotomic character $\\chi_{\\mathrm{cyc}}$\r\nof $G_{K}$ satisfes the relation $\\mathrm{N}_{K/\\Q_{p}}\\circ\\chi_{\\pi}=\\chi_{\\mathrm{cyc}}\\eta$\r\nfor an unramified character $\\eta$.\r\n\r\nA $K$-linear representation $V$ of $\\Gal(\\overline{K}/K)$ is called\r\n$K$-analytic if $\\C_{p}\\otimes_{K}^{\\tau}V$ is trivial for each\r\n$\\tau\\in\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} $.\r\n\r\nFinally, all characters and representations appearing in this article\r\nare assumed to be continuous. We normalize the $p$-adic valuation\r\nand $p$-adic logarithm so that $\\val_{p}(p)=1$ and $\\log(p)=0$.\r\nThe Hodge-Tate weight of $\\chi_{\\cyc}$ is $1$.\r\n\r\n\\subsection{Acknowledgments}\r\n\r\nI am grateful to my advisor Matthew Emerton for suggesting I try to\r\nprove Lubin-Tate triangulinity results for $p$-adic modular forms,\r\nand for his support throughout the project. I would like to thank\r\nLaurent Berger, Ehud de-Shalit, Yulia Kotelnikova, Hao Lee, and Alexander\r\nPetrov for many useful comments, Eric Stubley for useful explanations\r\nabout partial weight 1 Hilbert modular forms, and Richard Moy and\r\nJoel Specter for sharing with me their calculations of the coefficients\r\nof the modular form appearing in $\\mathsection7.3$. \r\n\r\n\\section{Locally $K$-analytic and pro $K$-analytic vectors}\r\n\r\n\r\n\\subsection{Locally analytic and pro analytic vectors}\r\n\r\nWe briefly recall the treatment given in $\\mathsection2$ of \\cite{Be16}\r\nand in $\\mathsection2$ of \\cite{BC16}. \r\n\r\nLet $W$ be a Banach $\\Q_{p}$-linear representation of $\\Gamma_{K}$.\r\nGiven an open subgroup $H$ of $\\Gamma_{K}$ with coordinates $c_{1},...,c_{d}:H\\xrightarrow{\\sim}\\Z_{p}^{d}$,\r\nwe have the subspace $W^{H-\\an}$ of $H$-analytic vectors in $W$.\r\nThese are the elements $w\\in W$ for which there exists a sequence\r\nof vectors $\\left\\{ w_{k}\\right\\} _{k\\in\\bbN^{d}}$ with $w_{k}\\rightarrow0$\r\nand $g(w)=\\sum_{k\\in\\bbN^{d}}c_{k}(g)^{k}w_{k}$ for all $g\\in H$.\r\nWe write $W^{\\la}=\\cup_{H}W^{H-\\an}$ for the subspace of locally\r\nanalytic vectors of $W$. If $W$ is a Fr\u00e9chet space whose topology\r\nis defined by a countable sequence of seminorms, let $W_{i}$ be the\r\nHausdorff completion of $W$ for the $i$'th norm, so that $W=\\underset{\\leftarrow}{\\lim}W_{i}$\r\nis a projective limit of Banach spaces. We write $W^{\\pa}=\\underset{\\leftarrow}{\\lim}W_{i}^{\\la}$\r\nfor the subspace of pro analytic vectors. \r\n\r\nFor $n\\gg0$, we have an isomorphism $l:\\Gamma_{K_{n}}\\rightarrow\\pi^{n}\\mathcal{O}_{K}$,\r\ngiven by $g\\mapsto\\log(\\chi_{\\pi}(g))$. We have the subspace $W^{\\Gamma_{K_{n}}-\\an,K-\\la}$\r\nof vectors which are $K$-analytic on $\\Gamma_{K_{n}}$, i.e. such\r\nthat there exists a sequence $\\left\\{ w_{k}\\right\\} _{k\\in\\mathbb{N}}$\r\nwith $\\pi^{nk}w_{k}\\rightarrow0$ and $g(w)=\\sum_{k\\in\\mathbb{N}^{d}}l(g)^{k}w_{k}$\r\nfor all $g\\in\\Gamma_{K_{n}}$. We write $W^{K-\\la}=\\cup_{n\\gg0}W^{\\Gamma_{K_{n}}-\\an,K-\\la}$\r\nfor the subspace of $K$-locally analytic vectors of $W$. If $W=\\underset{\\leftarrow}{\\lim}W_{i}$\r\nis a Fr\u00e9chet space as above, we write $W^{K-\\pa}=\\underset{\\leftarrow}{\\lim}W_{i}^{K-\\la}$\r\nfor the subspace of pro $K$-analytic vectors. We extend the definitions\r\nof locally $K$-analytic vectors and pro $K$-analytic vectors to\r\nLB and LF spaces (i.e. filtered colimits of Banach spaces and Fr\u00e9chet\r\nspaces) in the obvious way.\r\n\r\nFor each $\\tau\\in\\Sigma_{K}$, there is a differential operator $\\nabla_{\\tau}\\in K^{\\Gal}\\otimes_{\\Q_{p}}\\Lie(\\Gamma_{K})$\r\n(see $\\mathsection2$ of \\cite{Be16}) where $K^{\\Gal}$ is the Galois\r\nclosure of $K$. It is defined in such a way that if $W$ is $K^{\\Gal}$-linear,\r\nthen for $w\\in W^{\\la}$ and $g\\in\\Gamma_{K_{n}}$ with $n\\gg0$ we\r\nhave $g(w)=\\sum_{k\\in\\bbN^{\\Sigma_{K}}}l(g)^{k}\\frac{\\nabla^{k}(w)}{k!}$,\r\nwhere $l(g)^{k}=\\prod_{\\tau\\in\\Sigma_{K}}\\tau(l(g))^{k_{\\tau}}$ and\r\n$\\nabla^{k}(w)=\\prod_{\\tau\\in\\Sigma_{K}}\\nabla_{\\tau}(w)^{k_{\\tau}}$.\r\nIn other words, we can think of $\\tau\\circ l$ as giving coordinates\r\nfor $\\Gamma_{K}$ and $\\nabla^{k}(w)$ as being an iterated directional\r\nderivative of $w$. In particular, $W^{K-\\la}$ is the subspace of\r\n$W^{\\la}$ where $\\nabla_{\\tau}=0$ for each $\\tau\\in\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} $.\r\nOn $W^{K-\\la}$ (or on $W^{K-\\pa}$ if $W$ is Fr\u00e9chet) we write $\\nabla=\\nabla_{\\Id}$\r\nwhen there is no danger of confusion; it is given by the forumla\r\n\\[\r\n\\nabla(w)=\\lim_{g\\rightarrow1}\\frac{g(w)-w}{\\log(\\chi_{\\pi}(g))},\r\n\\]\r\nand we have $\\nabla(w)=\\frac{\\log(g)(w)}{\\log(\\chi_{\\pi}(g))}$ when\r\n$g$ is sufficiently close to $1$.\r\n\r\nThe next lemma is proved in the same way as Proposition 2.2 and Proposition\r\n2.4 of \\cite{Be16}.\r\n\\begin{lem}\r\nLet $B$ be a Banach (resp. Fr\u00e9chet) $\\Gamma_{K}$-ring and let $W$\r\nbe a free $B$-module of finite rank, equipped with a compatible action\r\nof $\\Gamma_{K}$. If the $B$ module has a basis $w_{1},...,w_{d}$\r\nin which the function $\\Gamma_{K}\\rightarrow\\GL_{d}(B)\\subset M_{d}(B),$\r\n$g\\mapsto\\Mat(g)$ is locally $K$-analytic (resp. pro $K$-analytic),\r\nthen $W^{K-\\la}=\\oplus_{j=1}^{d}B^{K-\\la}w_{i}$ (resp. $W^{K-\\pa}=\\oplus_{j=1}^{d}B^{K-\\pa}w_{i}$).\r\n\\end{lem}\r\n\r\n\r\n\\subsection{Locally analytic vectors in $\\widehat{K}_{\\infty}$-semilinear representations }\r\n\r\nLet $L$ be a finite extension of $K$, and write $\\Gamma_{L}=\\Gal(L_{\\infty}/L)$\r\nwhere $L_{\\infty}=LK_{\\infty}$. Recall that following result (Proposition\r\n2.10 of \\cite{Be16}):\r\n\\begin{prop}\r\n$\\widehat{L}_{\\infty}^{K-\\la}=L_{\\infty}$. \r\n\\end{prop}\r\n\r\nThe purpose of this subsection is to prove a similar descent result\r\nfor representations.\r\n\\begin{thm}\r\nLet $W$ be a finite dimensional $\\widehat{L}_{\\infty}$-semilinear\r\nrepresentation of $\\Gamma_{L}$. Then the natural map $\\widehat{L}_{\\infty}\\otimes_{L_{\\infty}}W^{K-\\la}\\rightarrow W$\r\nis an isomorphism.\r\n\\end{thm}\r\n\r\nThis is proved in $\\mathsection4$ of \\cite{BC16} under the assumption\r\nthat $K$ is Galois over $\\Q_{p}$. Here we shall adapt the methods\r\nof ibid. to get rid of this assumption. \r\n\r\nFirst, we reduce to the case where $L$ is Galois over $\\Q_{p}$.\r\n\\begin{lem}\r\nSuppose that Theorem 2.3 holds for $M=L^{\\Gal}$, the Galois closure\r\nof $L$ over $\\Q_{p}$. Then Theorem 2.3 holds for $L$.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nLet $L$ be any finite extension of $K$ and let $W$ be a finite\r\ndimensional $\\widehat{L_{\\infty}}$-semilinear representation of $\\Gamma_{K}$.\r\nWrite $W_{M}=\\widehat{M}_{\\infty}\\otimes_{\\widehat{L}_{\\infty}}W$,\r\nso that $W_{M}$ is a finite dimensional $\\widehat{M}_{\\infty}$-semilinear\r\nrepresentation of $\\Gamma_{M}$. Note that $W_{M}$ is actually endowed\r\nwith a semilinear $\\Gal(M_{\\infty}/L)$-action, which restricts to\r\na $\\Gamma_{M}$ action. By the assumption, we have $\\widehat{M}_{\\infty}\\otimes_{M_{\\infty}}W_{M}^{K-\\la}\\cong W_{M}.$\r\nOn the other hand, the extension $\\Gal(M_{\\infty}/L_{\\infty})$ is\r\nfinite, so we are in the setting for completed Galois descent (see\r\n$\\mathsection2.2$ of \\cite{BC09}). We have \r\n\\[\r\nW^{K-\\la}=W_{M}^{K-\\la}\\cap W=\\left(W_{M}^{K-\\la}\\right)^{\\Gal(M_{\\infty}/L_{\\infty})}\r\n\\]\r\nwhich implies that $\\widehat{M}_{\\infty}\\otimes_{M_{\\infty}}W_{M}^{K-\\la}\\cong\\widehat{M}_{\\infty}\\otimes_{L_{\\infty}}W^{K-\\la}$.\r\nWe then have the following chain of natural isomorphisms \r\n\r\n\\[\r\n\\begin{aligned}\\widehat{L}_{\\infty}\\otimes_{L_{\\infty}}W^{K-\\la} & \\cong\\left(\\widehat{M}_{\\infty}\\otimes_{L_{\\infty}}W^{K-\\la}\\right)^{\\Gal(M_{\\infty}/L_{\\infty})}\\\\\r\n & \\cong\\left(\\widehat{M}_{\\infty}\\otimes_{M_{\\infty}}W_{M}^{K-\\la}\\right)^{\\Gal(M_{\\infty}/L_{\\infty})}\\\\\r\n & \\cong\\left(W_{M}\\right)^{\\Gal(M_{\\infty}/L_{\\infty})}\\\\\r\n & \\cong W\r\n\\end{aligned}\r\n\\]\r\nwhose composition is the natural map $\\widehat{L}_{\\infty}\\otimes_{L_{\\infty}}W^{K-\\la}\\rightarrow W$,\r\nwhich proves the claim.\r\n\\end{proof}\r\n\\begin{prop}\r\nIf $\\tau\\in\\Sigma_{K}\\backslash\\left\\{ \\mathrm{Id}\\right\\} $ and\r\n$K^{\\Gal}\\subset L$, there exists an element $x_{\\tau}\\in\\widehat{L}_{\\infty}$\r\nsuch that $g(x_{\\tau})=x_{\\tau}+\\tau(l(g))$ for $g\\in G_{K^{\\Gal}}$.\r\nIn particular, $\\nabla_{\\tau}(x_{\\tau})=1$ and $\\nabla_{\\sigma}(x_{\\tau})=0$\r\nfor $\\sigma\\neq\\tau$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nBy $\\mathsection3.2$ of \\cite{Fo09}, there exists an element $\\xi_{\\tau}\\in\\C_{p}^{\\times}$\r\nsuch that $\\xi_{\\tau}/g(\\xi_{\\tau})=\\tau(\\chi_{\\pi}(g))$ for $g\\in G_{K^{\\Gal}}$.\r\nThis equation makes it clear that $\\xi_{\\tau}$ lies in the completion\r\nof $K^{\\Gal}K_{\\infty}$, which is contained in $\\widehat{L}_{\\infty}$.\r\nNow take $x_{\\tau}=-\\log\\xi_{\\tau}$.\r\n\\end{proof}\r\nFor each $n\\geq1$ and for each $\\tau\\neq\\Id$, choose $x_{\\tau}$\r\nas in Proposition 2.5 and let $x_{n,\\tau}\\in L_{\\infty}$ be such\r\nthat $||x_{\\tau}-x_{n,\\tau}||\\leq p^{-n}$. For $k\\in\\bbN^{\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} }$\r\nwe write $(x-x_{n})^{k}=\\prod_{\\tau\\in\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} }(x_{\\tau}-x_{n,\\tau})^{k_{\\tau}}$. \r\n\r\n\\emph{Proof of Theorem 2.3. }By Lemma 2.4, we may assume $L$ is Galois\r\nover $\\Q_{p}$. Recall that by Theorem 1.7 of \\cite{BC16}, the natural\r\nmap $\\widehat{L}_{\\infty}\\otimes_{\\widehat{L}_{\\infty}^{\\la}}W^{\\la}\\rightarrow W$\r\nis an isomorphism. Therefore, it is enough to prove that the natural\r\nmap $\\widehat{L}_{\\infty}^{\\la}\\otimes_{L_{\\infty}}W^{K-\\la}\\rightarrow W^{\\la}$\r\nis an isomorphism. To prove injectivity, take $\\sum_{i=1}^{n}\\alpha_{i}\\otimes x_{i}\\in\\widehat{L}_{\\infty}^{\\la}\\otimes_{L_{\\infty}}W^{K-\\la}$\r\nof minimal length such that $\\sum_{i=1}^{n}\\alpha_{i}x_{i}=0$. We\r\nmay assume that $\\alpha_{1}=1$. For each $\\tau\\neq\\Id$, we have\r\n$\\nabla_{\\tau}\\left(\\sum_{i=1}^{n}\\alpha_{i}x_{i}\\right)=\\sum_{i=2}^{n}\\nabla_{\\tau}(\\alpha_{i})x_{i}$,\r\nso by minimality $\\nabla_{\\tau}(\\alpha_{i})=0$ for all $i$. This\r\nmeans that each $\\alpha_{i}\\in L_{\\infty}$, so $\\sum_{i=1}^{n}\\alpha_{i}\\otimes x_{i}=0$.\r\n\r\nTo prove surjectivity, we give a sketch, omitting all details of convergence;\r\nthese can be provided in exactly the same way as in $\\mathsection4$\r\nof \\cite{BC16}. For each $z\\in W^{\\la}$, and for each $i\\in\\bbN^{\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} }$,\r\nlet\r\n\\[\r\ny_{i}=\\sum_{k\\in\\bbN^{\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} }}(-1)^{|k|}(x-x_{n})^{k}\\frac{\\nabla^{k+i}(z)}{(k+i)!}{k+i \\choose k}.\r\n\\]\r\nOne can show that $y_{i}\\in W^{\\la}$. By Proposition 2.5, for each\r\n$\\tau\\in\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} $ we have $\\nabla_{\\tau}\\left((x-x_{n})^{k}\\right)=k_{\\tau}(x-x_{n})^{k-1_{\\tau}}$,\r\nwhere $1_{\\tau}$ is the tuple $\\left(k_{\\sigma}\\right)\\in\\bbN^{\\Sigma_{K}}$\r\nwith $k_{\\tau}=1$ and $k_{\\sigma}=0$ for $\\sigma\\neq\\tau$. By a\r\ndirect calculation this implies that $\\nabla_{\\tau}(y_{i})=0$, so\r\nthat $y_{i}\\in W^{K-\\la}$. Finally, the identity\r\n\\[\r\nz=\\sum_{i\\in\\bbN^{\\Sigma_{K}\\backslash\\left\\{ \\Id\\right\\} }}y_{i}(x-x_{n})^{i}\r\n\\]\r\nshows that $z\\in\\widehat{L}_{\\infty}\\otimes_{\\widehat{L}_{\\infty}^{\\la}}W^{\\la}$.$\\hfill\\ensuremath{\\Box}$\r\n\r\n\\subsection{Pro analytic vectors in $\\protect\\B_{\\protect\\dR}$}\r\n\r\nThe ring $\\B_{\\dR}^{+}$ contains an element $t_{K}$ for which each\r\n$g\\in G_{K}$ acts by $g(t_{K})=\\chi_{\\pi}(g)t_{K}$. It differs from\r\nthe usual $t$ by a unit, but it has the advantage that it carries\r\nan action of $\\Gamma_{K}$, which is moreover $K$-analytic. As $\\B_{\\dR}^{+}/t_{K}\\cong\\C_{p}$,\r\nthe quotients $\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)^{H_{K}}$ for $l\\geq1$\r\nare Banach $\\Gamma_{K}$-rings. The ring and $\\left(\\B_{\\dR}^{+}\\right)^{H_{K}}$\r\nis a Fr\u00e9chet $\\Gamma_{K}$-ring and $\\left(\\B_{\\dR}\\right)^{H_{K}}$\r\nis an LF $\\Gamma_{K}$-ring.\r\n\\begin{prop}\r\n1.$\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)^{H_{K},K-\\la}=K_{\\infty}[t_{K}]/t_{K}^{l}$.\r\n\r\n2. $\\left(\\B_{\\dR}^{+}\\right)^{H_{K},K-\\pa}=K_{\\infty}[[t_{K}]]$.\r\n\r\n3. $\\left(\\B_{\\dR}\\right)^{H_{K},K-\\pa}=K_{\\infty}\\left(\\left(t_{K}\\right)\\right)$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\n(3) follows from (2) and (2) follows from (1). To prove (1), we argue\r\nby induction. For $l=1$, this is Proposition 2.2. For $l\\geq2$,\r\nwe have a short exact sequence\r\n\\[\r\n0\\rightarrow\\C_{p}(l-1)\\rightarrow\\B_{\\dR}^{+}/t_{K}^{l}\\rightarrow\\B_{\\dR}^{+}/t_{K}^{l-1}\\rightarrow0.\r\n\\]\r\nTaking $H_{K}$ invariants and $K$-locally analytic vectors is left\r\nexact, so we have\r\n\\[\r\n0\\rightarrow K_{\\infty}(l-1)\\rightarrow\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)^{H_{K},K-\\la}\\rightarrow\\left(\\B_{\\dR}^{+}/t_{K}^{l-1}\\right)^{H_{K},K-\\la}=K_{\\infty}[t_{K}]/t_{K}^{l-1}.\r\n\\]\r\nThis shows that $\\dim_{K_{\\infty}}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)^{H_{K},K-\\la}\\leq l$,\r\nso the containment $K_{\\infty}[t_{K}]/t_{K}^{l}\\subset\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)^{H_{K},K-\\la}$\r\nhas to be an equality, concluding the proof.\r\n\\end{proof}\r\n\r\n\\section{Lubin-Tate $p$-adic Hodge theory}\r\n\r\nTo goal of this section is to provide constructions and properties\r\nof several of Fontaine's functors on $p$-adic representations where\r\n$\\Q_{p}$-coefficients are systematically replaced by $K$-coefficients.\r\nThroughout, we fix a $K$-linear $G_{K}$-representation $V$ of dimension\r\n$d$.\r\n\r\n\\subsection{The modules $\\protect\\D_{\\protect\\Sen,K}$ and $\\protect\\D_{\\protect\\dif,K}$}\r\n\r\nWhen $K=\\Q_{p}$, the modules $\\D_{\\Sen,K}$ and $\\D_{\\dif,K}$ can\r\nbe defined using the method of Sen (see $\\mathsection4$ of \\cite{BC08}).\r\nIt is unavailable for $K\\neq\\Q_{p}$, so we make use of locally analytic\r\nand pro analytic vectors instead.\r\n\r\nWe set $W_{+,l}=\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K}V\\right)^{H_{K}}$\r\nfor $l\\geq1$, $W_{+}=\\left(\\B_{\\dR}^{+}\\otimes_{K}V\\right)^{H_{K}}$\r\nand $W=\\left(\\B_{\\dR}\\otimes_{K}V\\right)^{H_{K}}$. By Proposition\r\n2.6, we have $K_{\\infty}[t_{K}]/t_{K}^{l}$-submodules $\\D_{\\dif,K}^{+,l}(V)=W_{+,l}^{K-\\la}$\r\nfor $l\\geq1$, a $K_{\\infty}[[t_{K}]]$-submodule $\\D_{\\dif,K}^{+}(V)=W_{+}^{K-\\pa}$\r\nand a $K_{\\infty}\\left(\\left(t_{K}\\right)\\right)$-vector space $\\D_{\\dif,K}(V)=W^{K-\\pa}$.\r\nThe subspace $\\D_{\\dif,K}^{+,1}(V)$ is also called $\\D_{\\Sen,K}(V)$,\r\nand was already constructed in \\cite{BC16}.\r\n\\begin{lem}\r\nThe natural map $\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K_{\\infty}[t_{K}]/t_{K}^{l}}W_{+,l}\\rightarrow\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K}V$\r\nis an isomorphism. \r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nIt suffices to prove that $\\H^{1}\\left(H_{K},\\GL_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)\\right)=1$.\r\nWhen $l=1$ this is true by almost \u00e9tale descent. For $l\\geq2$, we\r\nhave a short exact sequence\r\n\\[\r\n1\\rightarrow I+t_{K}^{l-1}\\mathrm{M}_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)\\rightarrow\\GL_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)\\rightarrow\\GL_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l-1}\\right)\\rightarrow1.\r\n\\]\r\nAs $I+t_{K}^{l-1}\\mathrm{M}_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)\\cong\\mathrm{M}_{d}\\left(\\C_{p}(l-1)\\right)$,\r\nthe group $\\H^{1}\\left(H_{K},I+t_{K}^{l-1}\\mathrm{M}_{d}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\right)\\right)$\r\nis trivial, and we conclude by induction.\r\n\\end{proof}\r\nWe will also need the following.\r\n\\begin{lem}\r\nLet $w\\in W_{+,l}$ and suppose that $t_{K}\\cdot w\\in\\D_{\\dif,K}^{+,l}(V)$.\r\nThen $w\\in\\D_{\\dif,K}^{+,l}(V)$.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nSince $\\nabla(t_{K}w)=t_{K}(w+\\nabla(w))$, we have that $\\frac{\\nabla^{k}(t_{K}w)}{k!}$\r\nis divisible by $t_{K}$ for $k\\geq1$. If $t_{K}\\cdot w\\in\\D_{\\dif,K}^{+,l}(V)$,\r\nthere exists an $n\\gg0$ such that for $g\\in\\Gamma_{n}$, we have\r\n$g(t_{K}w)=\\sum_{k\\geq0}l(g)^{k}t_{K}w_{k}$, where $w_{k}=t_{K}^{-1}\\frac{\\nabla^{k}(t_{K}w)}{k!}$.\r\nTherefore, $g(w)=\\chi_{\\pi}(g^{-1})\\sum_{k\\geq0}l(g)^{k}w_{k}$, so\r\n$w$ is locally $K$-analytic. \r\n\\end{proof}\r\n\\begin{prop}\r\n1. The natural map $\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K_{\\infty}[t_{K}]/t_{K}^{l}}\\D_{\\dif,K}^{+,l}(V)\\rightarrow\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K}V$\r\nis an isomorphism, and $\\D_{\\dif,K}^{+,l}(V)$ is a free $K_{\\infty}[t_{K}]/t_{K}^{l}$-module\r\nof rank $d$.\r\n\r\n2. The natural map $\\B_{\\dR}^{+}\\otimes_{K_{\\infty}[[t_{K}]]}\\D_{\\dif,K}^{+}(V)\\rightarrow\\B_{\\dR}^{+}\\otimes_{K}V$\r\nis an isomorphism, and $\\D_{\\dif,K}^{+}(V)$ is a free $K_{\\infty}[[t_{K}]]$-module\r\nof rank $d$.\r\n\r\n3. The natural map $\\B_{\\dR}\\otimes_{K_{\\infty}\\left(\\left(t_{K}\\right)\\right)}\\D_{\\dif,K}(V)\\rightarrow\\B_{\\dR}\\otimes_{K}V$\r\nis an isomorphism, and $\\D_{\\dif,K}(V)$ is a $K_{\\infty}\\left(\\left(t_{K}\\right)\\right)$-vector\r\nspace of dimension $d$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nRecall that $\\D_{\\dif,K}^{+,l}(V)=W_{+,l}^{K-\\la}$. By Lemma 3.1,\r\nproving (1) reduces to showing that the natural map $\\widehat{K}_{\\infty}\\otimes_{K_{\\infty}}W_{+,l}^{K-\\la}\\rightarrow W_{+,l}$\r\nis an isomorphism and that $W_{+,l}^{K-\\la}$ is a free $K_{\\infty}[t_{K}]/t_{K}^{l}$-module\r\nof rank $d$. By Theorem 2.3, this is true if $l=1$. For $l\\geq2$,\r\nwe have a short exact sequence\r\n\\[\r\n0\\rightarrow W_{+,1}^{K-\\la}(l-1)\\rightarrow W_{+,l}^{K-\\la}\\rightarrow W_{+,l-1}^{K-\\la}.\r\n\\]\r\nBy the case $l=1$, we know that $W_{+,1}^{K-\\la}(l-1)$ contains\r\nlinearly independent elements $e_{1},...,e_{d}$ which are all divisible\r\nby $t_{K}^{l-1}$. Writing $f_{i}=t_{K}^{1-l}e_{i}$ for $1\\leq i\\leq d$,\r\nthe elements $f_{1},...,f_{d}$ span a free submodule $W_{+,l}^{'}$\r\nof $W_{+,l}$ which surjects onto $W_{+,l-1}$ and which contains\r\n$W_{+,1}$; so $W_{+,l}^{'}=W_{+,l}$. It now suffices to show that\r\nthe $f_{i}$ are locally $K$-analytic, and this follows from Lemma\r\n3.2. This concludes the proof of (1).\r\n\r\nAs each $W_{+,l}^{K-\\la}$ is a free $K_{\\infty}[t_{K}]/t_{K}^{l}$-module\r\nof rank $d$, we have that $W_{+}^{K-\\pa}=\\underset{\\leftarrow}{\\lim}W_{+,l}^{K-\\la}$\r\nis a free $K_{\\infty}[[t_{K}]]$-module of rank $d$, and the chain\r\nof isomorphisms\r\n\r\n\\[\r\n\\begin{aligned}\\B_{\\dR}^{+}\\otimes_{K_{\\infty}[[t_{K}]]}\\D_{\\dif,K}^{+}(V) & \\cong\\B_{\\dR}^{+}\\otimes_{K_{\\infty}[[t_{K}]]}W^{K-\\pa}\\\\\r\n & \\cong\\underset{\\leftarrow}{\\lim}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K_{\\infty}[t_{K}]/t_{K}^{l}}W_{l}^{K-\\la}\\right)\\\\\r\n & \\cong\\underset{\\leftarrow}{\\lim}\\left(\\B_{\\dR}^{+}/t_{K}^{l}\\otimes_{K}V\\right)\\\\\r\n & \\cong\\B_{\\dR}^{+}\\otimes_{K}V,\r\n\\end{aligned}\r\n\\]\r\nwhose composition is the natural map $\\B_{\\dR}^{+}\\otimes_{K_{\\infty}[[t_{K}]]}\\D_{\\dif,K}^{+}(V)\\rightarrow\\B_{\\dR}^{+}\\otimes_{K}V$.\r\nThis proves (2), and (3) follows immediately since $\\D_{\\dif,K}(V)=\\mathrm{colim}_{i}\\D_{\\dif,K}^{+}(V\\left(i\\right))$.\r\n\\end{proof}\r\nRecall from $\\mathsection2$ that the modules $\\D_{\\Sen,K}$ and $\\D_{\\dif,K}$\r\nare both endowed with a canonical differential operator. We write\r\n$\\Theta_{\\Sen,K}$,$\\nabla_{\\dif,K}$ respectively for the operators\r\nacting on $\\D_{\\Sen,K}$,$\\D_{\\dif,K}$. The operator $\\Theta_{\\Sen,K}$\r\nis $K_{\\infty}$-linear, while $\\nabla_{\\dif,K}$ is a derivation\r\nover $\\nabla_{K_{\\infty}\\left(\\left(t_{K}\\right)\\right)}=t_{K}\\frac{\\partial}{\\partial t_{K}}$.\r\n\r\nThe following result serves to complete the analogy with the usual\r\n$\\D_{\\mathrm{Sen}}$.\r\n\\begin{prop}\r\nThe following are equivalent.\r\n\r\n1. $\\C_{p}\\otimes_{K}V\\cong\\oplus_{i=1}^{d}\\C_{p}(\\chi_{\\pi}^{n_{i}})$,\r\nwhere the $n_{i}\\in\\Z$.\r\n\r\n2. $\\D_{\\Sen,K}(V)\\cong\\oplus_{i=1}^{d}K_{\\infty}(\\chi_{\\pi}^{n_{i}})$,\r\nwhere the $n_{i}\\in\\Z$.\r\n\r\n3. $\\Theta_{\\Sen,K}$ is semisimple with integer eigenvalues $\\left\\{ n_{i}\\right\\} _{i=1}^{d}$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nSuppose $v_{1},...,v_{d}$ is a basis of $\\C_{p}\\otimes_{K}V$ for\r\nwhich $g(v_{i})=\\chi_{\\pi}^{n_{i}}(g)v_{i}$ for $g\\in G_{K}$. The\r\naction of $G_{K}$ on each $v_{i}$ factors through $\\Gamma_{K}$\r\nand is locally $K$-analytic, so $v_{i}\\in\\D_{\\Sen,K}(V)$, which\r\nshows (1) implies (2). Next, (2) implies (3) because the action of\r\n$\\Theta_{\\Sen,K}$ on $K_{\\infty}(\\chi_{\\pi}^{n_{i}})$ is given by\r\nmultiplication with $n_{i}$. Finally, suppose that (3) holds, and\r\nlet $v_{1},...,v_{d}$ be a basis of $\\D_{\\Sen,K}(V)$ for which $\\Theta_{\\Sen,K}(v_{i})=n_{i}v_{i}$.\r\nBy integrating the action of $\\Gamma_{K}$, we see that $g\\in\\Gamma_{K}$\r\nacts by $g(v_{i})=\\eta_{i}(g)\\chi_{\\pi}^{n_{i}}(g)v_{i}$, where $\\eta_{i}$\r\nis a finite order character of $\\Gamma_{K}$. Then $\\C_{p}(\\eta_{i}\\chi_{\\pi}^{n_{i}})\\cong\\C_{p}(\\chi_{\\pi}^{n_{i}})$,\r\nso\r\n\r\n\\[\r\n\\begin{aligned}\\C_{p}\\otimes_{K}V & \\cong\\C_{p}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\\\\r\n & \\cong\\oplus_{i=1}^{d}\\C_{p}(\\eta_{i}\\chi_{\\pi}^{n_{i}})\\\\\r\n & \\cong\\oplus_{i=1}^{d}\\C_{p}(\\chi_{\\pi}^{n_{i}}).\r\n\\end{aligned}\r\n\\]\r\n\\end{proof}\r\nIf the conditions of Proposition 3.4 hold for some $n_{i}\\in\\Z$,\r\nthe $n_{i}$ are called the $K$-Hodge-Tate weights of $V$.\r\n\r\n\\subsection{The modules $\\protect\\D_{\\protect\\HT,K}$ and $\\protect\\D_{\\protect\\dR,K}$}\r\n\r\nLet $\\B_{\\HT,K},\\B_{\\dR,K},\\B_{\\dR,K}$ respectively be the rings\r\n$\\C_{p}[t_{K},t_{K}^{-1}],\\B_{\\dR}^{+}$ and $\\B_{\\dR}$. We set $\\D_{\\HT,K}(V)=\\left(\\B_{\\HT,K}\\otimes_{K}V\\right)^{G_{K}}$,\r\n$\\D_{\\dR,K}^{+}(V)=\\left(\\B_{\\dR,K}^{+}\\otimes_{K}V\\right)^{G_{K}}$\r\nand $\\D_{\\dR,K}(V)=\\left(\\B_{\\dR,K}\\otimes_{K}V\\right)^{G_{K}}$.\r\nWe say that $V$ is $K$-Hodge-Tate (resp. positive $K$-de Rham,\r\nresp. $K$-de Rham) if $\\dim_{K}\\D_{\\HT,K}(V)=d$ (resp. $\\dim_{K}\\D_{\\dR,K}^{+}(V)=d$,\r\nresp. $\\dim_{K}\\D_{\\dR,K}(V)=d$).\r\n\\begin{lem}\r\n$(\\C_{p}\\otimes_{K}V)^{G_{K}}=\\left(\\D_{\\Sen,K}(V)\\right)^{\\Gamma_{K}}$.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nBy Proposition 3.3, we have \r\n\\[\r\n\\left(\\C_{p}\\otimes_{K}V\\right)^{G_{K}}=\\left(\\C_{p}\\otimes\\D_{\\Sen,K}(V)\\right)^{G_{K}}=\\left(\\hat{K}_{\\infty}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\right)^{\\Gamma_{K}}.\r\n\\]\r\nAs $\\left(\\hat{K}_{\\infty}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\right)^{\\Gamma_{K}}$\r\nis fixed by the action of $\\Gamma_{K}$, it is also locally $K$-analytic\r\non $\\Gamma_{K}$, so it is contained in $\\left(\\hat{K}_{\\infty}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\right)^{K-\\la}$.\r\nBut according to Lemma 2.1, \r\n\\[\r\n\\left(\\hat{K}_{\\infty}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\right)^{K-\\la}=\\D_{\\Sen,K}(V).\r\n\\]\r\n\\end{proof}\r\n\\begin{prop}\r\n1. $\\D_{\\HT,K}(V)=\\oplus_{l\\in\\Z}\\left(\\D_{\\Sen,K}(V)t_{K}^{l}\\right)^{\\Gamma_{K}}$.\r\n\r\n2. The natural map $\\B_{\\HT,K}\\otimes_{K}\\D_{\\HT,K}(V)\\rightarrow\\B_{\\HT,K}\\otimes_{K}V$\r\nis an isomorphism if $V$ is $K$-Hodge-Tate.\r\n\r\n3. $V$ is $\\C_{p}$-admissible if and only if $\\Theta_{\\Sen,K}=0$\r\non $\\D_{\\Sen,K}(V)$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nWe have $\\D_{\\HT,K}(V)=\\oplus_{l\\in\\Z}\\left(\\C_{p}t_{K}^{l}\\otimes_{K}V\\right)^{G_{K}}$,\r\nso (upon twisting $V$ with an appropriate power of $\\chi_{\\pi}$)\r\nthe equality $\\D_{\\HT,K}(V)=\\oplus_{l\\in\\Z}\\left(\\D_{\\Sen,K}(V)t_{K}^{l}\\right)^{\\Gamma_{K}}$\r\nreduces to the verification that $(\\C_{p}\\otimes_{K}V)^{G_{K}}=\\left(\\D_{\\Sen,K}(V)\\right)^{\\Gamma_{K}}$,\r\nwhich was done in the previous lemma. This proves (1). To prove (2),\r\nsuppose $V$ is $K$-Hodge-Tate. Then by (1) and Proposition 3.4 we\r\nhave $\\D_{\\Sen,K}(V)\\cong\\oplus_{i=1}^{d}K_{\\infty}(\\chi_{\\pi}^{n_{i}})$,\r\nwhich gives the second isomorphism in\r\n\r\n\\[\r\n\\begin{aligned}\\B_{\\HT,K}\\otimes_{K}\\D_{\\HT,K}(V) & \\cong\\B_{\\HT,K}\\otimes_{K}\\left(\\oplus_{l\\in\\Z}\\left(\\D_{\\Sen,K}(V)t_{K}^{l}\\right)^{\\Gamma_{K}}\\right)\\\\\r\n & \\cong\\B_{\\HT,K}\\otimes_{K_{\\infty}}\\D_{\\Sen,K}(V)\\\\\r\n & \\cong\\B_{\\HT,K}\\otimes_{K}V.\r\n\\end{aligned}\r\n\\]\r\n\r\nFinally, (3) follows from Proposition 3.4.\r\n\\end{proof}\r\nBy the same logic one obtains similar results for $\\D_{\\dR,K}$.\r\n\\begin{prop}\r\n1. $\\D_{\\dR,K}(V)=\\D_{\\dif,K}(V)^{\\Gamma_{K}}$.\r\n\r\n2. The natural map $\\B_{\\dR,K}\\otimes_{K}\\D_{\\dR,K}(V)\\rightarrow\\B_{\\dR,K}\\otimes_{K}V$\r\nis an isomorphism if $V$ is $K$-de Rham.\r\n\r\n3. $V$ is $K$-de Rham if and only if $\\nabla_{\\dif,K}$ has a full\r\nset of sections on $\\D_{\\dif,K}(V)$.\r\n\\end{prop}\r\n\r\n\r\n\\subsection{The modules $\\protect\\D_{\\protect\\cris,K}$ and $\\protect\\D_{\\protect\\st,K}$ }\r\n\r\nRecall that $\\B_{\\max}^{+}$ is a period ring similar to Fontaine's\r\n$\\B_{\\cris}^{+}$. The element\\footnote{It is $\\log_{\\mathcal{F}}u$ for the element $u$ introduced in $\\mathsection4.1$\r\nbelow.} $t_{K}$ introduced in $\\mathsection2.3$ actually lies in $\\B_{\\max}^{+}\\otimes_{K_{0}}K$.\r\nDenote by $\\B_{\\max,K}^{+}$, $\\B_{\\st,K}^{+}$, $\\B_{\\max,K}$, $\\B_{\\st,K}$\r\nrespectively the rings $\\B_{\\max}^{+}\\otimes_{K_{0}}K$, $\\B_{\\st}^{+}\\otimes_{K_{0}}K$,\r\n$\\B_{\\max,K}^{+}\\left[\\frac{1}{t_{K}}\\right]$ and $\\B_{\\st,K}^{+}\\left[\\frac{1}{t_{K}}\\right]$.\r\nThese rings carry a $\\varphi_{q}=\\varphi^{f}$-action, and the usual\r\nmonodromy operator $N$ of $\\B_{\\st}^{+}$ extends to $\\B_{\\st,K}$\r\nwith $\\B_{\\st,K}^{N=0}=\\B_{\\max,K}$. If $L$ is a finite extension\r\nof $K$, we set $\\D_{\\cris,K}^{+}(V)$, $\\D_{\\st,K}^{+}(V)$, $\\D_{\\cris,K}(V)$,\r\n$\\D_{\\st,K}(V)$ respectively to be $\\D_{\\cris,K}^{+}(V)=\\left(\\B_{\\max,K}^{+}\\otimes_{K}V\\right)^{G_{L}}$,\r\n$\\D_{\\st,K}^{+}(V)=\\left(\\B_{\\st,K}^{+}\\otimes_{K}V\\right)^{G_{L}}$,\r\n$\\D_{\\cris,K}(V)=\\left(\\B_{\\max,K}\\otimes_{K}V\\right)^{G_{L}}$ and\r\n$\\D_{\\st,K}(V)=\\left(\\B_{\\st,K}\\otimes_{K}V\\right)^{G_{L}}$.\r\n\r\nTo a filtered $(\\varphi_{q},N)$-module $\\D$ over $L_{0}\\otimes_{K_{0}}K$\r\none can associate two polygons. The Hodge polygon $P_{H}(\\D)$, whose\r\nslopes have lengths according to the jumps in the filtration; and\r\nthe Newton polygon $P_{N}(\\D)$, whose slopes match the slopes of\r\n$\\varphi_{q}$ with respect to the valuation $\\val_{\\pi}$. We say\r\n$\\D$ is admissible if the endpoints of $P_{H}(\\D)$ and $P_{N}(D)$\r\nare the same and if $P_{H}(\\D_{0})$ lies below $P_{N}(\\D_{0})$ for\r\nevery subobject $\\D_{0}$ of $\\D$.\r\n\r\nIf $\\D$ is a filtered $(\\varphi_{q},N)$-module over $L_{0}\\otimes_{K_{0}}K$,\r\nthen \r\n\\[\r\n\\mathrm{I}_{\\Q_{p}}^{K}(\\D):=\\left(L_{0}\\otimes_{\\Q_{p}}K\\right)\\left[\\varphi\\right]\\otimes_{\\left(L_{0}\\otimes_{K_{0}}K\\right)\\left[\\varphi_{q}\\right]}\\D\r\n\\]\r\nis a filtered $\\left(\\varphi,N\\right)$-module over $L_{0}\\otimes_{\\Q_{p}}K$.\r\nThe following is proved in $\\mathsection3$ of \\cite{KR09} under\r\nthe assumption that $N=0$, but the proof in the general case is the\r\nsame. Note that in loc. cit. this statement is actually proved for\r\n$\\left(\\B_{\\max}\\otimes_{K_{0}}V\\right)^{G_{L}}$ instead of $\\D_{\\cris,K}(V)=\\left(\\B_{\\max,K}^{+}\\left[\\frac{1}{t_{K}}\\right]\\otimes_{K_{0}}V\\right)^{G_{L}}$,\r\nbut these coincide for $K$-analytic representations.\r\n\\begin{prop}\r\nLet $L$ be a finite extension of $K$, and suppose that $V\\in\\mathrm{Rep}_{K}(G_{L})$\r\nis $K$-analytic. Then\r\n\\[\r\n\\mathrm{I}_{\\Q_{p}}^{K}(\\D_{\\st,K}(V))=\\D_{\\st,\\Q_{p}}(V).\r\n\\]\r\nFurthermore, $\\D_{\\st,K}(V)$ is admissible if and only if $\\D_{\\st,\\Q_{p}}(V)$\r\nis admissible.\r\n\\end{prop}\r\n\r\nWe say that $V$ is $K$-potentially semistable if for some finite\r\nextension $L$ of $K$ and for some $n\\in\\Z$ we have $\\rank_{L_{0}\\otimes_{K_{0}}K}\\D_{\\st,K}(V)=d$.\r\n\r\n\\begin{cor}\r\nSuppose that $V\\in\\mathrm{Rep}_{E}(G_{K})$ is $K$-analytic for $K\\subset E$.\r\nThen the following are equivalent.\r\n\r\n1. $V$ is de Rham.\r\n\r\n2. $V$ is $K$-de Rham.\r\n\r\n3. $V$ is potentially semistable.\r\n\r\n4. $V$ is $K$-potentially semistable.\r\n\\end{cor}\r\n\r\n\\begin{proof}\r\nThe equivalence between (1) and (3) is the $p$-adic monodromy theorem,\r\nwhich is Theorem 0.7 of \\cite{Be02}. The equivalence between (3)\r\nand (4) follows from Proposition 3.8. It remains to prove that (1)\r\nand (2) are equivalent. Indeed, we have $\\D_{\\dR}(V)\\cong\\oplus_{\\tau\\in\\Sigma_{K}}\\D_{\\dR,K}(V^{\\tau})$,\r\nwith $V^{\\tau}$ being the $\\tau$-twist of $V$. Since $V$ is assumed\r\n$K$-analytic, the representation $V^{\\tau}$ is $\\C_{p}$-admissible\r\nfor $\\tau\\neq\\Id$, so it also $K$-de Rham. This implies that $\\dim_{K}\\D_{\\dR,K}(V^{\\tau})=d$,\r\nso $\\dim_{K}\\D_{\\dR}(V)=\\dim_{\\Q_{p}}V$ if and only if $\\dim_{K}\\D_{\\dR,K}(V)=\\dim_{K}V$,\r\nas required.\r\n\\end{proof}\r\nWe conclude with a lemma that will be used in the proof of Theorem\r\n6.8. \r\n\\begin{lem}\r\nSuppose that $V\\in\\mathrm{Rep}_{E}(G_{K})$ is $K$-analytic for $K\\subset E$\r\nand that $L=K$, and let $\\alpha\\in E^{\\times}$. Then $\\mathrm{I}_{\\Q_{p}}^{K}(\\D_{\\cris,\\Q_{p}}(V))^{\\varphi_{q}=\\alpha}=(K_{0}\\otimes_{\\Q_{p}}E)\\D_{\\cris,K}(V))^{\\varphi_{q}=\\alpha}.$\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nIn general, if $\\D$ is a filtered $\\varphi_{q}$-module over $E$,\r\nthen $\\mathrm{I}_{\\Q_{p}}^{K}(\\D)^{\\varphi_{q}=\\alpha}=(K_{0}\\otimes E)\\D^{\\varphi_{q}=\\alpha}$\r\nbecause the $\\varphi_{q}$ action is $K_{0}\\otimes_{\\Q_{p}}E$-linear.\r\nThe lemma now follows from Proposition 3.8.\r\n\\end{proof}\r\n\r\n\\section{Big period rings}\r\n\r\nIf $\\mathcal{F}$ is the formal $\\mathcal{O}_{K}$-module associated\r\nto $\\pi$ as in $\\mathsection1.2$, we choose a coordinate $T$ for\r\n$\\mathcal{F}$ so that for $a\\in\\mathcal{O}_{K}$ we have a power\r\nseries $[a]=[a](T)$ corresponding to the action of $a$ on $\\mathcal{F}$.\r\nFor $n\\geq0$ we choose elements $u_{n}\\in\\mathcal{O}_{\\C_{p}}$ such\r\nthat $u_{0}=0$, $u_{1}\\neq0$ and $[\\pi](u_{n})=u_{n-1}$.\r\n\r\n\\subsection{The rings $\\widetilde{\\protect\\B}_{\\protect\\rig}^{\\dagger}$ and\r\n$\\widetilde{\\protect\\B}_{\\log}^{\\dagger}$}\r\n\r\nThis subsection provides ramified counterparts for the constructions\r\ngiven in $\\mathsection2$ of \\cite{Be02} in the case $K=K_{0}$.\r\nRecall the notations from $\\mathsection1.2$ and set $\\mathcal{O}_{\\C_{p}^{\\flat}}=\\lim\\left(\\mathcal{O}_{\\C_{p}}/\\pi\\xleftarrow{x\\mapsto x^{q}}\\mathcal{O}_{\\C_{p}}/\\pi\\xleftarrow{x\\mapsto x^{q}}...\\right)$.\r\nWe equip $\\mathcal{O}_{\\C_{p}^{\\flat}}$ with the valuation $\\left|\\left(\\overline{x}_{n}\\right)_{n\\geq0}\\right|=\\underset{n\\rightarrow\\infty}{\\lim}\\left|x_{n}\\right|^{q^{n}}$\r\nwhere $x_{n}\\in\\mathcal{O}_{\\C_{p}}$ is a lift of $\\overline{x}_{n}$.\r\nDenote by $\\widetilde{\\A}_{0}^{+}$, $\\widetilde{\\A}^{+}$ respectively\r\nthe rings $W\\left(\\mathcal{O}_{\\C_{p}^{\\flat}}\\right)$ and $\\widetilde{\\A}_{0}^{+}\\otimes_{\\mathcal{O}_{K_{0}}}\\mathcal{O}_{K}$.\r\nThen $\\overline{u}=\\left(\\overline{u}_{n}\\right)_{n\\geq0}$ lies in\r\n$\\in\\mathcal{O}_{\\C_{p}^{\\flat}}$, and by $\\mathsection8$ of \\cite{Co02}\r\nthere exists an element $u\\in\\widetilde{\\A}^{+}$ which lifts $\\overline{u}$\r\nand which satisfies $\\varphi_{q}(u)=[\\pi](u)$ and $g(u)=[\\chi_{\\pi}(g)](u)$\r\nfor $g\\in\\Gamma_{K}$.\r\n\r\nLet $\\varpi\\in\\mathcal{O}_{\\C_{p}^{\\flat}}$ be any element with $|\\varpi|=p^{-p/p-1}$.\r\nGiven $r,s\\in\\Z_{\\geq0}[1/p]$ with $r\\leq s$, and given $\\mathrm{A}\\in\\left\\{ \\widetilde{\\A}_{0},\\widetilde{\\A}\\right\\} $,\r\nwe set\r\n\\[\r\n\\mathrm{A}^{\\left[r,s\\right]}=\\mathrm{A}^{+}\\left\\langle \\frac{p}{\\left[\\varpi\\right]^{r}},\\frac{\\left[\\varpi\\right]^{s}}{p}\\right\\rangle ,\r\n\\]\r\nthe completion of $\\mathrm{A}^{+}\\left[\\frac{p}{\\left[\\varpi\\right]^{r}},\\frac{\\left[\\varpi\\right]^{s}}{p}\\right]$\r\nwith respect to the $\\left(p,\\left[\\varpi\\right]\\right)$-adic topology.\\footnote{In some references the completion is taken with respect to the $p$-adic\r\ntopology, but this makes no difference because $p$ divides a power\r\nof $\\left[\\varpi\\right]$.} We write $\\widetilde{\\B}_{0}^{[r,s]}=\\widetilde{\\A}_{0}^{[r,s]}[1/p]$\r\nand $\\widetilde{\\B}^{[r,s]}=\\widetilde{\\A}^{[r,s]}[1/\\pi]$.\r\n\\begin{lem}\r\n1. $\\widetilde{\\A}_{0}^{[r,s]}\\otimes_{\\mathcal{O}_{K_{0}}}\\mathcal{O}_{K}=\\widetilde{\\A}^{[r,s]}$.\r\n\r\n2. $\\widetilde{\\B}_{0}^{[r,s]}\\otimes_{K_{0}}K=\\widetilde{\\B}^{[r,s]}.$\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\n(2) follows from (1). To prove (1), we write\r\n\\[\r\n\\widetilde{\\A}^{+}\\left[\\frac{p}{\\left[\\varpi\\right]^{r}},\\frac{\\left[\\varpi\\right]^{s}}{p}\\right]=\\oplus_{i=0}^{e-1}\\pi^{i}\\widetilde{\\A}_{0}^{+}\\left[\\frac{p}{\\left[\\varpi\\right]^{r}},\\frac{\\left[\\varpi\\right]^{s}}{p}\\right]\r\n\\]\r\nas $\\widetilde{\\A}_{0}^{+}$-modules. Now take the $\\left(p,\\left[\\varpi\\right]\\right)$-adic\r\ncompletion of both sides.\r\n\\end{proof}\r\nWe denote by $\\widetilde{\\B}_{\\rig,0}^{\\dagger,r}$,$\\widetilde{\\B}_{\\rig}^{\\dagger,r}$,\r\n$\\widetilde{\\B}_{\\rig,0}^{\\dagger}$ and $\\widetilde{\\B}_{\\rig}^{\\dagger}$\r\nrespectively the rings $\\cap_{r\\leq s}\\widetilde{\\B}_{0}^{[r,s]},\\cap_{r\\leq s}\\widetilde{\\B}^{[r,s]},\\cup_{r>0}\\widetilde{\\B}_{\\rig,0}^{\\dagger,r}$\r\nand $\\cup_{r>0}\\widetilde{\\B}_{\\rig}^{\\dagger,r}$. The $\\varphi$\r\nand $G_{K}$ actions on $\\widetilde{\\A}_{0}^{+}$ (resp. the $\\varphi_{q}$\r\nand $G_{K}$ actions on $\\widetilde{\\A}^{+}$) extend to $\\widetilde{\\B}_{\\rig,0}^{\\dagger}$\r\n(resp. to $\\widetilde{\\B}_{\\rig}^{\\dagger}$). The following is proved\r\nin Proposition 2.23 of \\cite{Be02} in the case $K=\\Q_{p}$, but the\r\nsame proof works in the general case.\r\n\\begin{prop}\r\nThere exists a unique map $\\log:\\widetilde{\\A}^{+}\\rightarrow\\widetilde{\\B}_{\\rig}^{\\dagger}$$\\left[X\\right]$\r\nsatisfying $\\log(\\pi)=0$, $\\log\\left[\\overline{u}\\right]=X$, $\\log\\left[x\\right]=0$\r\nfor $x\\in\\overline{\\mathbb{F}}_{q}$ and $\\log(xy)=\\log(x)+\\log(y)$,\r\nsuch that if $\\left[x\\right]-1$ is sufficiently close to $1$, we\r\nhave\r\n\\[\r\n\\log\\left[x\\right]=\\sum_{n\\geq1}\\left(-1\\right)^{n-1}\\frac{\\left(\\left[x\\right]-1\\right)^{n}}{n}.\r\n\\]\r\n\r\nMoreover, if $x\\in\\mathcal{O}_{\\C_{p}^{\\flat}}^{\\times}$ then $\\log\\left[x\\right]\\in\\widetilde{\\B}_{\\rig}^{\\dagger}$. \r\n\\end{prop}\r\n\r\nWrite $p^{\\flat}$ and $\\pi^{\\flat}$ for the elements $\\left(\\overline{p},\\overline{p^{1/q}},...\\right)$\r\nand $\\left(\\overline{\\pi},\\overline{\\pi^{1/q}},...\\right)$ of $\\mathcal{O}_{\\C_{p}^{\\flat}}$.\r\nWe set $\\widetilde{\\B}_{\\log,0}^{\\dagger}=\\widetilde{\\B}_{\\rig,0}^{\\dagger}\\left[\\log\\left[p^{\\flat}\\right]\\right]$\r\nand $\\widetilde{\\B}_{\\log}^{\\dagger}=\\widetilde{\\B}_{\\rig}^{\\dagger}\\left[\\log\\left[\\pi^{\\flat}\\right]\\right]$.\r\nSince $u/\\left[\\overline{u}\\right]\\equiv1\\mod\\pi$, we have $\\log\\left(u/\\left[\\overline{u}\\right]\\right)\\in\\widetilde{\\B}_{\\rig}^{\\dagger}$;\r\non the other hand, $\\overline{u}^{q-1}/\\left(\\pi^{\\flat}\\right)^{q}$\r\nis a unit of $\\mathcal{O}_{\\C_{p}^{\\flat}}^{\\times}$, so $\\log\\left[\\overline{u}\\right]^{q-1}/\\left[\\pi^{\\flat}\\right]^{q}\\in\\widetilde{\\B}_{\\rig}^{\\dagger}$\r\nas well. Combining these two observations, we see that in $\\widetilde{\\B}_{\\log}^{\\dagger}$\r\nwe have\r\n\\[\r\nq\\log\\left[\\pi^{\\flat}\\right]=(q-1)\\log u-(q-1)\\log\\left(u/\\left[\\overline{u}\\right]\\right)-\\log\\left[\\overline{u}\\right]^{q-1}/\\left[\\pi^{\\flat}\\right]^{q}\r\n\\]\r\n\\[\r\n\\equiv(q-1)\\log u\\mod\\widetilde{\\B}_{\\rig}^{\\dagger},\r\n\\]\r\n so we also have $\\widetilde{\\B}_{\\log}^{\\dagger}=\\widetilde{\\B}_{\\rig}^{\\dagger}\\left[\\log u\\right]$.\r\n\r\nThe $\\varphi$ (resp. $\\varphi_{q}$) action on $\\widetilde{\\B}_{\\rig,0}^{\\dagger}$\r\n(resp. on $\\widetilde{\\B}_{\\rig}^{\\dagger}$) extends to $\\widetilde{\\B}_{\\log,0}^{\\dagger}$\r\n(resp. to $\\widetilde{\\B}_{\\log}^{\\dagger}$) by setting $\\varphi(\\log\\left[p^{\\flat}\\right])=p\\log\\left[p^{\\flat}\\right]$\r\nand $g(\\log\\left[p^{\\flat}\\right])=\\log\\left[g\\left(p^{\\flat}\\right)\\right]$\r\n(resp. $\\varphi_{q}(\\log\\left[\\pi^{\\flat}\\right])=q\\log\\left[\\pi^{\\flat}\\right]$\r\nand $g(\\log\\left[\\pi^{\\flat}\\right])=\\log\\left[g\\left(\\pi^{\\flat}\\right)\\right]$).\r\nWe have a monodromy operator $N$ which acts on $\\widetilde{\\B}_{\\log,0}^{\\dagger}$\r\n(resp. on $\\widetilde{\\B}_{\\log}^{\\dagger}$) by $-\\frac{d}{d\\log\\left[p^{\\flat}\\right]}$\r\n(resp. by $-\\frac{1}{e}\\frac{d}{d\\log\\left[\\pi^{\\flat}\\right]}$),\r\nand $N\\varphi=p\\varphi N$ (resp. $N\\varphi_{q}=q\\varphi_{q}N$).\r\n\\begin{prop}\r\n1. $\\widetilde{\\B}_{\\rig,0}^{\\dagger}\\otimes_{K_{0}}K=\\widetilde{\\B}_{\\rig}^{\\dagger}$.\r\n\r\n2. $\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}K=\\widetilde{\\B}_{\\log}^{\\dagger}$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nFor $r\\leq s$ we have by Lemma 4.1 that $\\widetilde{\\B}_{0}^{[r,s]}\\otimes_{K_{0}}K=\\widetilde{\\B}^{[r,s]}$.\r\nAs $K$ is finite free over $K_{0}$, this implies \r\n\r\n\\[\r\n\\begin{aligned}\\widetilde{\\B}_{\\rig,0}^{\\dagger}\\otimes_{K_{0}}K & =\\left(\\cap_{r\\leq s}\\widetilde{\\B}_{0}^{[r,s]}\\right)\\otimes_{K_{0}}K\\\\\r\n & =\\cap_{r\\leq s}\\left(\\widetilde{\\B}_{0}^{[r,s]}\\otimes_{K_{0}}K\\right)\\\\\r\n & =\\cap_{r\\leq s}\\widetilde{\\B}^{[r,s]}\\\\\r\n & =\\widetilde{\\B}_{\\rig}^{\\dagger}.\r\n\\end{aligned}\r\n\\]\r\nFor (2), we write $\\pi^{e}=pv$ with $v\\in\\mathcal{O}_{K}^{\\times}$.\r\nWe can find $v^{\\flat}=\\left(\\overline{v},\\overline{v^{1/q}},...\\right)\\in\\mathcal{O}_{\\C_{p}^{\\flat}}$\r\nsuch that $\\left[\\pi^{\\flat}\\right]^{e}=\\left[p^{\\flat}\\right]\\left[v^{\\flat}\\right]$,\r\nso $e\\log\\left[\\pi^{\\flat}\\right]\\equiv\\log\\left[p^{\\flat}\\right]\\mod\\widetilde{\\B}_{\\rig}^{\\dagger}$,\r\nand\r\n\r\n\\[\r\n\\begin{aligned}\\widetilde{\\B}_{\\log}^{\\dagger} & =\\widetilde{\\B}_{\\rig}^{\\dagger}\\left[\\log\\left[p^{\\flat}\\right]\\right]\\\\\r\n & =\\left(\\widetilde{\\B}_{\\rig,0}^{\\dagger}\\otimes_{K_{0}}K\\right)\\left[\\log\\left[p^{\\flat}\\right]\\right]\\\\\r\n & =\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}K.\r\n\\end{aligned}\r\n\\]\r\n.\r\n\\end{proof}\r\n\r\n\\subsection{Pro $K$-analytic vectors}\r\n\r\nLet $\\B_{\\rig,K}^{\\dagger}$ be the Robba ring, i.e. the ring of power\r\nseries $f(T)=\\sum_{k\\in\\Z}a_{k}T^{k}$ with $a_{k}\\in K$ and such\r\nthat $f(T)$ converges on some nonempty annulus $r<|T|<1$. The ring\r\n$\\B_{\\rig,K}^{\\dagger}$ can be viewed as a subring of $\\widetilde{\\B}_{\\rig,K}^{\\dagger}=\\left(\\widetilde{\\B}_{\\rig}^{\\dagger}\\right)^{H_{K}}$\r\nby identifying $T$ with the element $u$ of $\\mathsection4.1$. It\r\nhas induced $\\varphi_{q}$ and $\\Gamma_{K}$ actions.\r\n\r\nRecall the following result (Theorem B of \\cite{Be16}), which determines\r\nthe ring of pro $K$-analytic vectors in $\\widetilde{\\B}_{\\rig,K}^{\\dagger}$.\r\n\\begin{thm}\r\n$\\left(\\widetilde{\\B}_{\\rig,K}^{\\dagger}\\right)^{K-\\pa}=\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\rig,K}^{\\dagger}\\right).$\r\n\\end{thm}\r\n\r\nOn the other hand, we can also write $\\widetilde{\\B}_{\\log,K}^{\\dagger}=\\left(\\widetilde{\\B}_{\\log}^{\\dagger}\\right)^{H_{K}}$.\r\nThe goal of this subsection is to obtain an analogous result for $\\widetilde{\\B}_{\\log,K}^{\\dagger}$.\r\n\\begin{prop}\r\nWe have $\\log u\\in\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\right)^{K-\\pa}$.\r\n\\end{prop}\r\n\r\nBefore we give a proof of Proposition 4.5, we record the following\r\nconsequence. Let $\\B_{\\log,K}^{\\dagger}=\\B_{\\rig,K}^{\\dagger}\\left[\\log T\\right]$,\r\nthought of as a subring of $\\widetilde{\\B}_{\\log,K}^{\\dagger}$. The\r\n$\\varphi_{q}$ action on $\\log T$ is given by $\\varphi_{q}(\\log T)=q\\log T+\\log\\left(\\left[\\pi\\right](T)/T^{q}\\right)$,\r\nwhere $\\log\\left(\\left[\\pi\\right](T)/T^{q}\\right)\\in\\B_{\\rig,K}^{\\dagger}$.\r\n\\begin{thm}\r\n$\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\right)^{K-\\pa}=\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\log,K}^{\\dagger}\\right)$.\r\n\\end{thm}\r\n\r\n\\begin{proof}\r\nFix $d\\geq0$. As $g\\left(\\log u\\right)=\\log u+\\log\\frac{g(u)}{u}$\r\nfor $g\\in\\Gamma_{K}$, the submodule $\\oplus_{i=0}^{d}\\widetilde{\\B}_{\\rig,K}^{\\dagger}\\cdot\\left(\\log u\\right)^{i}$\r\nis closed under the $\\Gamma_{K}$-action. By Proposition 4.5, the\r\nelements $1,\\log u,...,\\left(\\log u\\right)^{i}$ from a $\\widetilde{\\B}_{\\rig,K}^{\\dagger}$-basis\r\nof this submodule for which the action is pro $K$-analytic. Combining\r\nLemma 2.1 and Theorem 4.4, we obtain\r\n\r\n\\[\r\n\\begin{aligned}\\left(\\oplus_{i=0}^{d}\\widetilde{\\B}_{\\rig,K}^{\\dagger}\\cdot\\left(\\log u\\right)^{i}\\right)^{K-\\pa} & =\\oplus_{i=0}^{d}\\left(\\widetilde{\\B}_{\\rig,K}^{\\dagger}\\right)^{K-\\pa}\\cdot\\left(\\log u\\right)^{i}\\\\\r\n & =\\oplus_{i=0}^{d}\\left(\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\rig,K}^{\\dagger}\\right)\\right)\\left(\\log u\\right)^{i}.\r\n\\end{aligned}\r\n\\]\r\nTaking the colimit as $d\\rightarrow\\infty$ shows that $\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\right)^{K-\\pa}=\\left(\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\rig,K}^{\\dagger}\\right)\\right)[\\log u]$.\r\nIt remains to show that $\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\log,K}^{\\dagger}\\right)$\r\nis contained $\\left(\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\rig,K}^{\\dagger}\\right)\\right)[\\log u]$,\r\nas the inclusion in the other direction is obvious. Assume the opposite\r\nand let $f=\\sum_{i=0}^{d}a_{i}\\left(\\log u\\right)^{i}$ be an element\r\nof $\\varphi_{q}^{-n}\\left(\\B_{\\log,K}^{\\dagger}\\right)$ with $a_{i}\\in\\widetilde{\\B}_{\\rig,K}^{\\dagger}$\r\nand $d$ minimal such that $f$ is not contained in $\\left(\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\rig,K}^{\\dagger}\\right)\\right)[\\log u]$.\r\nAs $\\varphi_{q}^{n}\\left(f\\right)\\in\\B_{\\log,K}^{\\dagger}$ and $\\varphi_{q}(\\log u)\\equiv q\\log u$\r\n$\\mod\\B_{\\rig,K}^{\\dagger}$, examining the coefficient of $\\left(\\log u\\right)^{d}$\r\nreveals that $\\varphi_{q}^{n}(a_{d})\\in\\B_{\\rig,K}^{\\dagger}$, providing\r\na contradiction. \r\n\\end{proof}\r\nWe now proceed to prove Proposition 4.5 (compare with $\\mathsection4$\r\nof \\cite{Be16}). We do so in several steps. If $t\\geq1$, we denote\r\nby $\\mathrm{LA}_{t}(\\mathcal{O}_{K})$ the space functions of $\\mathcal{O}_{K}$\r\nwhich are analytic on closed discs of radius $|\\pi|^{t}$. For $a\\in\\mathcal{O}_{K}$,\r\nwrite $[a](T)=\\sum_{n\\geq1}c_{n}(a)T^{n}$. Each $c_{n}(a)$ is a\r\npolynomial of degree at most $n$ in $a$, and $c_{n}(\\mathcal{O}_{K})\\subset\\mathcal{\\mathcal{O}}_{K}$.\r\n\\begin{lem}\r\n$\\left|\\left|c_{n}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq|\\pi|^{-\\frac{n}{q^{t}(q-1)}}$.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nRecall that de Shalit has constructed in \\cite{dS16} a Mahler basis\r\n$\\left\\{ g_{n}(T)\\right\\} _{n\\geq0}^{\\infty}$ such that $g_{n}(T)$\r\nis a polynomial in $K[T]$ of degree $n$ and and such that $||\\pi^{w_{n,t}}g_{n}||_{\\mathrm{LA}_{t}}=1$,\r\nwhere $w_{n,t}$ is an integer satisfying $w_{n,t}\\leq\\frac{n}{q^{t}(q-1)}$.\r\nAs $c_{n}$ has degree at most $n$, we can write $c_{n}=\\sum_{i=0}^{n}b_{n,i}g_{i}$\r\nfor some $b_{n,i}\\in\\mathcal{O}_{K}$, and so $\\left|\\left|c_{n}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq\\sup_{1\\leq i\\leq n}\\left|\\left|g_{i}\\right|\\right|\\leq|\\pi|^{-\\frac{n}{q^{t}(q-1)}}$.\r\n\\end{proof}\r\nRecall that $g(\\log u)=\\log u+\\log\\left(\\frac{[a](u)}{u}\\right)$,\r\nwhere $a=\\chi_{\\pi}(g)$. We write \r\n\\[\r\n\\log\\left(\\frac{[a](u)}{u}\\right)=\\sum_{n=1}^{\\infty}d_{n}(a)u^{n}.\r\n\\]\r\n\r\n\\begin{lem}\r\n$\\left|\\left|d_{n}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq|\\pi|^{-\\frac{2n}{q^{t}(q-1)}+o(n)}$.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nWrite $\\frac{[a](u)}{u}-1=\\sum_{n\\geq0}e_{n}(a)u^{n}$, where $e_{0}(a)=a-1$\r\nand $e_{n}(a)=c_{n+1}(a)$ for $n\\geq1$. Then $d_{n}$ is a sum of\r\nfunctions of the form\r\n\\[\r\n\\frac{\\left(-1\\right)^{m-1}}{m}\\sum_{\\substack{\\left(k_{1},...,k_{m}\\right)\\in\\Z_{\\geq0}^{m}\\\\\r\nk_{1}+...+k_{m}=n\r\n}\r\n}\\prod_{i=1}^{m}e_{k_{i}},\r\n\\]\r\nand it suffices to bound each such function by $|\\pi|^{-\\frac{2n}{q^{t}(q-1)}+o(n)}$,\r\nwhere $o(n)$ does not depend on $m$.\r\n\r\nFix $\\left(k_{1},...,k_{m}\\right)\\in\\Z_{\\geq0}^{m}$ with $k_{1}+...+k_{m}=n$.\r\nLet $h$ be the number of $1\\leq i\\leq m$ such that $k_{i}\\geq1$.\r\nThen by Lemma 4.7 we have\r\n\\[\r\n\\left|\\left|\\prod_{i:1\\leq k_{i}}e_{k_{i}}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq\\left|\\pi\\right|^{-\\left(n+h\\right)/q^{t}(q-1)}\\leq|\\pi|^{-2n/q^{t}(q-1)}.\r\n\\]\r\nOn the other hand, $\\left|\\left|e_{0}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq\\left|\\pi\\right|^{t}$,\r\nso\r\n\\[\r\n\\left|\\left|\\frac{1}{m}\\prod_{i:k_{i}=0}e_{k_{i}}\\right|\\right|_{\\mathrm{LA}_{t}}\\leq\\left|\\frac{1}{m}\\right|\\left|\\pi\\right|^{t(m-h)}\\leq p^{\\left[v_{p}(m)-t/e\\max\\left\\{ 0,m-n\\right\\} \\right]}=\\left|\\pi\\right|^{o(n)}.\r\n\\]\r\nCombining the two inequalities we obtain the claim.\r\n\\end{proof}\r\n\\emph{Proof of Proposition 4.5. }Write $r_{n}=p^{nf-1}(p-1)$ and\r\nlet $s\\leq t$. It is enough to show that $\\log u$ is $K$-analytic\r\non $\\Gamma_{K_{t+1}}$ as a vector of $\\widetilde{\\B}_{K}^{[r_{s},r_{t}]}=\\left(\\widetilde{\\B}^{[r_{l},r_{t}]}\\right)^{H_{K}}$.\r\nSince $g(\\log u)=\\log u+\\log\\left(\\frac{[a](u)}{u}\\right)$ for $a=\\chi_{\\pi}(g)$,\r\nwe need to verify that $\\left|\\left|d_{n}\\right|\\right|_{\\mathrm{LA}_{t+1}}\\left|\\left|u^{n}\\right|\\right|_{[r_{s},r_{t}]}\\rightarrow0$\r\nas $n\\rightarrow0$. By the maximum principle, we have $\\left|\\left|u\\right|\\right|_{[r_{s},r_{t}]}=\\left|\\left|u\\right|\\right|_{r_{t}}=\\left|\\pi\\right|^{1/q^{t-1}(q-1)}$,\r\nand so by Lemma 4.7\r\n\\[\r\n\\left|\\left|d_{n}\\right|\\right|_{\\mathrm{LA}_{t+1}}\\left|\\left|u^{n}\\right|\\right|_{[r_{s},r_{t}]}\\leq|\\pi|^{n\\left[\\frac{1}{q^{t-1}(q-1)}-\\frac{2}{q^{t+1}(q-1)}\\right]+o(1)},\r\n\\]\r\nwhich approaches $0$, as required.$\\hfill\\ensuremath{\\Box}$\r\n\r\n\\section{Lubin-Tate $(\\varphi_{q},\\Gamma_{K})$-modules }\r\n\r\nIn this section we recall how to attach a $(\\varphi_{q},\\Gamma_{K})$-module\r\nover $\\B_{\\rig,K}^{\\dagger}$ to a $K$-analytic $p$-adic representation\r\nof $G_{K}$, and we express the invariants of $\\mathsection3$ in\r\nterms of these $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules.\r\n\r\n\\subsection{$K$-analytic $(\\varphi_{q},\\Gamma_{K})$-modules}\r\n\r\nLet $\\A_{K}$ be the ring of power series $f(T)=\\sum_{k\\in\\Z}a_{k}T^{k}$\r\nwith $a_{k}\\in\\mathcal{O}_{K}$ such that $\\val_{p}(a_{k})\\rightarrow0$\r\nas $k\\rightarrow-\\infty$, and let $\\B_{K}=\\A_{K}[1/\\pi]$. These\r\nrings have a $\\varphi_{q}$-action given by $\\varphi_{q}(T)=\\left[\\pi\\right](T)$\r\nand a $\\Gamma_{K}$-action given by $g(T)=\\left[\\chi_{\\pi}(g)\\right](T)$\r\nfor $g\\in\\Gamma_{K}$. A $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\nis then a finite-dimensional $\\B_{K}$ vector space $\\D_{K}$ which\r\nhas commuting semilinear $\\varphi_{q}$ and $\\Gamma_{K}$ actions.\r\nWe say it is \u00e9tale if there exists a basis of $\\D_{K}$ for which\r\n$\\Mat(\\varphi)\\in\\GL_{d}(\\A_{K})$.\r\n\r\nKisin and Ren have shown in $\\mathsection1$ of \\cite{KR09} how to\r\nassociate to any $V\\in\\mathrm{Rep}_{E}(G_{K})$ an \u00e9tale $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\n$\\B_{K}$ which we denote $\\D_{K}(V)$. Furthermore, one has the following\r\nresult.\r\n\\begin{thm}\r\nThe functor $V\\mapsto\\D_{K}(V)$ induces an equivalence of categories\r\n\\[\r\n\\left\\{ E\\text{-representations of }G_{K}\\right\\} \\longleftrightarrow\\left\\{ \\text{\u00e9tale }\\left(\\varphi_{q},\\Gamma_{K}\\right)\\text{-modules over }\\B_{K}\\otimes_{K}E\\right\\} .\r\n\\]\r\n\\end{thm}\r\n\r\nNow let $\\B_{K}^{\\dagger}$ be the subring of $\\B_{K}$ which consists\r\nof power series which converge on some nonempty annulus $r\\leq|T|<1$.\r\nWe say that a $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module over $\\B_{K}\\otimes_{K}E$\r\nis \\emph{overconvergent }if $\\D_{K}=\\D_{K}^{\\dagger}\\otimes_{\\B_{K}^{\\dagger}}\\B_{K}$\r\nwhere $\\D_{K}^{\\dagger}$ is a $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\nover $\\B_{K}^{\\dagger}\\otimes_{K}E$, and a representation $V\\in\\mathrm{Rep}_{E}(G_{K})$\r\nis said to be overconvergent if $\\D_{K}(V)$ is. As $\\B_{K}^{\\dagger}$\r\nis a subring of $\\B_{\\rig,K}^{\\dagger}$, for such a $(\\varphi_{q},\\Gamma_{K})$-module\r\nwe can form $\\D_{\\rig,K}^{\\dagger}=\\D_{K}^{\\dagger}\\otimes_{\\B_{K}^{\\dagger}}\\B_{\\rig,K}^{\\dagger}$\r\nand $\\D_{\\log,K}^{\\dagger}=\\D_{K}^{\\dagger}\\otimes_{\\B_{K}^{\\dagger}}\\B_{\\log,K}^{\\dagger}$. \r\n\r\nIn the case $K=\\Q_{p}$, Cherbonnier and Colmez have proven in \\cite{CC98}\r\nthat $\\D_{K}(V)$ is always overconvergent. Unfortunately, this is\r\nno longer true whenever $K\\neq\\Q_{p}$ (see Theorem 0.6 of \\cite{FX13}).\r\nHowever, the analogue of the Cherbonnier-Colmez theorem does hold\r\nfor $K$-analytic representations, and, even better, we can characterize\r\nthe $(\\varphi_{q},\\Gamma_{K})$-modules which arise in this way. More\r\nprecisely, a $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module $\\D_{\\rig,K}^{\\dagger}$\r\nover $\\B_{\\rig,K}^{\\dagger}$ is called $K$-analytic if $\\D_{\\rig,K}^{\\dagger}=\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{K-\\pa}$.\r\nThen one has the following result (Theorems C and D of \\cite{Be16}).\r\n\\begin{thm}\r\n1. If $V\\in\\mathrm{Rep}_{E}(G_{K})$ is $K$-analytic, then $\\D_{K}(V)$\r\nis overconvergent.\r\n\r\n2. The functor $V\\mapsto\\D_{\\rig,K}^{\\dagger}(V)$ gives an equivalence\r\nof categories\r\n\\[\r\n\\left\\{ K\\text{-analytic }E\\text{-linear representations of }G_{K}\\right\\} \r\n\\]\r\n\\[\r\n\\longleftrightarrow\\left\\{ \\text{\u00e9tale }K\\text{-analytic }\\left(\\varphi_{q},\\Gamma_{K}\\right)\\text{-modules over }\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right\\} \r\n\\]\r\n\r\n3. If $V\\in\\mathrm{Rep}_{E}(G_{K})$ is $K$-analytic, then there\r\nexists a natural $G_{K}$-equivariant isomorphism $\\widetilde{\\B}_{\\rig}^{\\dagger}\\otimes_{K}V\\cong\\widetilde{\\B}_{\\rig}^{\\dagger}\\otimes_{\\B_{\\rig,K}^{\\dagger}}\\D_{\\rig,K}^{\\dagger}(V)$.\r\n\\end{thm}\r\n\r\nAll characters are overconvergent, so split $2$-dimensional representation\r\nare always overconvergent. For nonsplit representations, Theorem 5.2\r\nimplies the following.\r\n\\begin{cor}\r\nLet $V\\in\\mathrm{Rep}_{E}(G_{K})$ be a nonsplit $2$-dimensional\r\nrepresentation. The following are equivalent.\r\n\r\n1. $V$ is overconvergent.\r\n\r\n2. Either $V$ is $K$-analytic up to a character twist or $V$ is\r\nan extension of the trivial representation by itself.\r\n\\end{cor}\r\n\r\n\\begin{proof}\r\n If $V\\left(\\delta\\right)$ is $K$-analytic then it is overconvergent\r\nby Theorem 5.2. In addition, Theorem 0.3 of \\cite{FX13} shows that\r\nevery extension of the trivial representation by itself is overconvergent,\r\nso (2) implies (1). In the converse direction, let $V$ be an overconvergent\r\nrepresentation.\r\n\r\n\\textbf{Case 1: }$V$ is absolutely irreducible. Then Corollary 4.3\r\nof \\cite{Be13} implies that $V\\left(\\delta\\right)$ is $K$-analytic\r\nfor some character $\\delta$. Corollary 4.3 of \\cite{Be13} is proved\r\nthere in the setting where $K$ is an unramified extension of $\\Q_{p}$;\r\nit is a consequence of Theorem 4.2 of ibid. This assumption can be\r\nremoved, because Theorem 4.2 of ibid is reproven in \\cite{Be16} without\r\nassuming $K$ is unramified. \r\n\r\n\\textbf{Case 2: }After extending scalars, which does not matter for\r\nthe question of overconvergence, we may assume $V$ is reducible and\r\nnonsplit, and after performing a character twist we may further assume\r\nit is an extension of $1$ by $E(\\delta)$ with $\\det\\left(V\\right)=\\delta$.\r\nIf $\\delta=1$, we are done. Otherwise, by Theorem 0.4 of \\cite{FX13}\r\na nontrivial extension of $1$ by $E\\left(\\delta\\right)$ can only\r\noccur if $\\delta$ is $K$-analytic, and since $\\delta\\neq1$ this\r\nimplies that $V$ is also $K$-analytic by Theorem 0.3 of \\cite{FX13}.\r\n\\end{proof}\r\n\r\n\\subsection{The modules $\\protect\\D_{*,K}$ and the extended dictionary}\r\n\r\nRecall that for $n\\geq0$ we set $r_{n}=p^{nf-1}(p-1)$. For $r>0$\r\nwe let $n(r)$ be the minimal $n$ such that $r_{n}\\geq r$. If $I$\r\nis a closed interval and $r_{0}=\\frac{p-1}{p}\\in I$, then for $\\widetilde{\\B}^{I}$\r\nas in $\\mathsection4$ the usual completion map $\\widetilde{\\A}^{+}\\rightarrow\\B_{\\dR}^{+}$\r\nextends to a map $\\iota_{0}:\\widetilde{\\B}^{I}\\rightarrow\\B_{\\dR}^{+}$.\r\nMore generally if $r_{n}\\in I$ then one has the map $\\iota_{0}\\circ\\varphi_{q}^{-n}:\\widetilde{\\B}^{I}\\rightarrow\\B_{\\dR}^{+}$.\r\nNow let $\\B_{\\rig,K}^{\\dagger,r}=\\widetilde{\\B}_{\\rig,K}^{\\dagger,r}\\cap\\B_{\\rig,K}^{\\dagger}$,\r\nthen for $n\\geq n(r)$ the map above restricts to give $\\iota_{0}\\circ\\varphi_{q}^{-n}:\\B_{\\rig,K}^{\\dagger,r}\\rightarrow K_{n}\\left(\\left(t_{K}\\right)\\right)\\subset\\B_{\\dR}$.\r\nAs $\\B_{\\rig,K}^{\\dagger}=\\cup_{r>0}\\B_{\\rig,K}^{\\dagger,r}$, each\r\n$\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module $\\D_{\\rig,K}^{\\dagger}$\r\nover $\\B_{\\rig,K}^{\\dagger}$ descends to $\\D_{\\rig,K}^{\\dagger,r}$\r\nover $\\B_{\\rig,K}^{\\dagger,r}$ for some $r>0$. Finally, let $t_{K}=\\log_{\\mathcal{F}}(T)\\in\\B_{\\rig,K}^{\\dagger}$;\r\nit belongs to $\\B_{\\rig,K}^{\\dagger,r_{0}}$ and $\\iota_{0}(t_{K})$\r\ncoincides with the usual $t_{K}$ of $\\B_{\\dR}^{+}$ as in $\\mathsection2$\r\nand $\\mathsection3$. We set\r\n\r\n\\[\r\n\\begin{aligned} & \\mathrm{D}_{\\mathrm{Sen},K}\\left(\\mathrm{D}_{\\mathrm{rig},K}^{\\dagger}\\right)=\\left(D_{\\mathrm{rig},K}^{\\dagger,r}\\otimes_{\\theta\\circ\\varphi_{q}^{-n}}K_{n}\\right)\\otimes_{K_{n}}K_{\\infty},\\\\\r\n & \\D_{\\dif,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\left(\\D_{\\rig,K}^{\\dagger,r}\\otimes_{\\iota_{0}\\circ\\varphi_{q}^{-n}}K_{n}\\left(\\left(t_{K}\\right)\\right)\\right)\\otimes_{K_{n}}K_{\\infty}\\left(\\left(t_{K}\\right)\\right),\\\\\r\n & \\D_{\\dR,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\D_{\\dif,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\Gamma_{K}},\\\\\r\n & \\D_{\\cris,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\left(\\D_{\\rig,K}^{\\dagger}\\left[1/t_{K}\\right]\\right)^{\\Gamma_{K}},\\\\\r\n & \\D_{\\st,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\left(\\D_{\\log,K}^{\\dagger}\\left[1/t_{K}\\right]\\right)^{\\Gamma_{K}}.\r\n\\end{aligned}\r\n\\]\r\n\r\nOne verifies that $\\D_{\\Sen,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$\r\nand $\\D_{\\dif,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$ are independent\r\nof the choice of $n$. The main theorem of this section is the following.\r\n\\begin{thm}\r\nLet $V$ be $K$-analytic representation of $G_{K}$. For $*\\in\\left\\{ \\Sen,\\dif,\\dR,\\cris,\\st\\right\\} $,\r\nwe have a natural isomorphism\r\n\\[\r\n\\D_{*,K}(V)\\cong\\D_{*,K}\\left(\\D_{\\rig,K}^{\\dagger}(V)\\right).\r\n\\]\r\n\\end{thm}\r\n\r\n\\begin{proof}\r\nSet $\\D_{\\rig,K}^{\\dagger}=\\D_{\\rig,K}^{\\dagger}(V)$. For $r,n\\gg0$,\r\nwe have a natural map $\\D_{\\rig,K}^{\\dagger,r}\\xrightarrow{\\theta\\circ\\varphi_{q}^{-n}}W$,\r\nwhere $W=\\left(\\C_{p}\\otimes_{K}V\\right)^{H_{K}}$. The image of $\\theta\\circ\\varphi_{q}^{-n}$\r\nis by definition $\\D_{\\Sen,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$,\r\nwhich is a $K_{\\infty}$-submodule of rank $d=\\dim_{K}V$. As $\\theta\\circ\\varphi_{q}^{-n}$\r\nis $\\Gamma_{K}$ equivariant, it maps pro $K$-analytic vectors to\r\nlocally $K$-analytic vectors, so the image lands in $W^{K-\\la}=\\D_{\\Sen,K}(V)$.\r\nComparing ranks we get the desired isomorphism for $*=\\mathrm{Sen}$\\@.\r\nReplacing $\\theta\\circ\\varphi_{q}^{-n}$ by $\\iota_{0}\\circ\\varphi_{q}^{-n}$\r\nwe similarly get a map $\\D_{\\dif,K}^{+}\\left(V\\right)\\rightarrow\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger,r}\\right)$\r\nof two $K_{\\infty}\\left[\\left[t_{K}\\right]\\right]$-modules of rank\r\n$d$, whose reduction mod $t_{K}$ is the isomorphism $\\D_{\\Sen,K}(V)\\xrightarrow{\\sim}\\D_{\\Sen,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$.\r\nThus by Nakayama's lemma we have $\\D_{\\dif,K}^{+}(V)\\cong\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}(V)\\right)$\r\nand we deduce $\\D_{\\dif,K}(V)\\cong\\D_{\\dif,K}\\left(\\D_{\\rig,K}^{\\dagger}(V)\\right)$\r\nby passing to colimits.\r\n\r\nAs $\\D_{\\cris,K}=\\D_{\\st,K}^{N=0}$, it remains to prove the comparison\r\nfor $*=\\st$. Twisting $V$ by an appropriate power of $\\chi_{\\pi}$,\r\nwe further reduce to proving that $\\D_{\\st,K}^{+}\\left(V\\right)=\\left(\\D_{\\log,K}^{\\dagger}\\right)^{\\Gamma_{K}}$.\r\nBy Lemma 5.5 below, we have\r\n\r\n\\[\r\n\\begin{aligned}\\D_{\\st,K}^{+}\\left(V\\right) & =\\left(\\widetilde{\\B}_{\\log}^{\\dagger}\\otimes_{K}V\\right)^{G_{K}}\\\\\r\n & =\\left(\\widetilde{\\B}_{\\log}^{\\dagger}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{G_{K}}\\\\\r\n & =\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{\\Gamma_{K}}.\r\n\\end{aligned}\r\n\\]\r\nOn the one hand, this implies that $\\D_{\\st,K}^{+}\\left(V\\right)\\subset\\left(\\D_{\\log,K}^{\\dagger}\\right)^{\\Gamma_{K}}$.\r\nOn the other hand, vectors which are fixed by $\\Gamma_{K}$ are also\r\npro $K$-analytic on $\\Gamma_{K}$, so\r\n\r\n\\[\r\n\\begin{aligned}\\D_{\\st,K}^{+}\\left(V\\right) & =\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{\\Gamma_{K},K-\\pa}\\\\\r\n & =\\left(\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{K-\\pa}\\right)^{\\Gamma_{K}}.\r\n\\end{aligned}\r\n\\]\r\nSince $V$ is $K$-analytic, Theorem 5.2 implies that $\\D_{\\log,K}^{\\dagger}(V)$\r\nis pro $K$-analytic, and so by Lemma 2.1 we have \r\n\\[\r\n\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{K-\\pa}=\\left(\\widetilde{\\B}_{\\log,K}^{\\dagger}\\right)^{K-\\pa}\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V).\r\n\\]\r\nApplying Theorem 4.6, we deduce\r\n\\[\r\n\\D_{\\st,K}^{+}\\left(V\\right)\\subset\\left(\\cup_{n\\geq0}\\varphi_{q}^{-n}\\left(\\B_{\\log,K}^{\\dagger}\\right)\\otimes_{\\B_{\\log,K}^{\\dagger}}\\D_{\\log,K}^{\\dagger}(V)\\right)^{\\Gamma_{K}}.\r\n\\]\r\nThus $\\varphi_{q}^{n}\\left(\\D_{\\st,K}^{+}\\left(V\\right)\\right)\\subset\\left(\\D_{\\log,K}^{\\dagger}\\right)^{\\Gamma_{K}}$\r\nfor some $n\\gg0$. If $e_{1},...,e_{l}$ is a basis of $\\D_{\\st,K}^{+}\\left(V\\right)$\r\nthen $\\varphi_{q}^{n}(e_{1}),...,\\varphi_{q}^{n}(e_{l})$ gives another\r\nbasis of $\\D_{\\st,K}^{+}\\left(V\\right)$ which lies in $\\left(\\D_{\\log,K}^{\\dagger}\\right)^{\\Gamma_{K}}$.\r\nThis concludes the proof.\r\n\\end{proof}\r\nThe following lemma was used in the proof of Theorem 5.4.\r\n\\begin{lem}\r\nLet $V\\in\\mathrm{Rep}_{E}(G_{K})$. Then \r\n\\[\r\n\\D_{\\st,K}^{+}(V)=\\left(\\widetilde{\\B}_{\\log}^{\\dagger}\\otimes_{K}V\\right)^{G_{K}}.\r\n\\]\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nGiven an automorphism $\\sigma:K_{0}\\rightarrow K_{0}$, let $V^{\\sigma}$\r\nbe the $\\sigma$-twist of $V$. Then we have $G_{K}$-compatible identifications\r\n$\\B_{\\st}^{+}\\otimes_{\\Q_{p}}V\\cong\\oplus_{\\sigma}\\B_{\\st}^{+}\\otimes_{K_{0}}V^{\\sigma}$\r\nand $\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{\\Q_{p}}V\\cong\\oplus_{\\sigma}\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}V^{\\sigma}$.\r\nNow by Proposition 3.4 of \\cite{Be02} we have $\\left(\\B_{\\st}^{+}\\otimes_{\\Q_{p}}V\\right)^{G_{K}}=\\left(\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{\\Q_{p}}V\\right)^{G_{K}}$\r\nand hence by projecting to the $\\sigma=\\Id$ component\r\n\\[\r\n\\D_{\\st,K}^{+}(V)=\\left(\\B_{\\st}^{+}\\otimes_{K_{0}}V\\right)^{G_{K}}=\\left(\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}V\\right)^{G_{K}}.\r\n\\]\r\nFinally, by Proposition 4.3 we have $\\widetilde{\\B}_{\\log}^{\\dagger}=\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}K$\r\nso $\\left(\\widetilde{\\B}_{\\log,0}^{\\dagger}\\otimes_{K_{0}}V\\right)^{G_{K}}=\\left(\\widetilde{\\B}_{\\log}^{\\dagger}\\otimes_{K}V\\right)^{G_{K}}$. \r\n\\end{proof}\r\n\\begin{rem}\r\nThe definitions given in this section for $\\D_{\\Sen,K},\\D_{\\dif,K},\\D_{\\dR,K},\\D_{\\cris,K},\\D_{\\st,K}$\r\nmake sense for non \u00e9tale $K$-analytic $(\\varphi_{q},\\Gamma_{K})$-modules.\r\nThe properties of these modules which were proved in $\\mathsection3$\r\ncarry over with no difficulty to this more general case.\r\n\\end{rem}\r\n\r\n\r\n\\section{Lubin-Tate trianguline representations of dimension 2}\r\n\r\nWe continue with the convention that $E$ is a finite extension of\r\n$\\Q_{p}$ which contains $K$.\r\n\\begin{defn}\r\n1. A $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module over $\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E$\r\nis called Lubin-Tate trianguline if it can be written as a successive\r\nextension of $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules of rank\r\n1.\r\n\r\n2. An $E$-linear $K$-analytic representation $V$ is called Lubin-Tate\r\ntrianguline if $\\D_{\\rig,K}^{\\dagger}(V)$ is Lubin-Tate trianguline.\r\n\\end{defn}\r\n\r\nIn the case $K=\\Q_{p}$, trianguline $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules\r\nof dimension 2 were first studied by Colmez in \\cite{Co08}. We shall\r\nbe concerned with Lubin-Tate trianguline $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules\r\nof dimension 2 which were studied by Fourquaux and Xie in \\cite{FX13}.\r\n\r\n\\subsection{Characters of the Weil group}\r\n\r\nRecall that if $W_{K}$ is the Weil group of $K$, local class field\r\ntheory gives a natural isomorphism $W_{K}^{\\mathrm{ab}}\\cong K^{\\times}$.\r\nThis allows us to identify characters $\\delta:K^{\\times}\\rightarrow E^{\\times}$\r\nwith characters $W_{K}^{\\mathrm{ab}}\\rightarrow E^{\\times}$, the\r\nidentification given by \r\n\\[\r\n\\delta(\\mathrm{Frob}_{\\pi}^{-n}g)=\\delta(\\pi)^{n}\\delta(\\chi_{\\pi}(g))\r\n\\]\r\n for $g\\in\\Gal(K^{\\mathrm{ab}}/K^{\\mathrm{un}})$ and $n\\in\\Z$. To\r\nsuch characters $\\delta$ we associate the $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\n$\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)$. It is a\r\n$\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module of rank 1 with a basis\r\n$e_{\\delta}$, where $\\varphi_{q}(e_{\\delta})=\\delta(\\pi)e_{\\delta}$\r\nand $g(e_{\\delta})=\\delta(\\chi_{\\pi}(g))$ for $g\\in\\Gamma_{K}$.\r\nNote that this $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module is \u00e9tale\r\nexactly when $\\delta$ is unitary; in this case, if $\\delta$ is locally\r\n$K$-analytic, the module $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)$\r\ncorresponds under the equivalence of categories in $\\mathsection5.1$\r\nto the extension of $\\delta$ to $\\Gal(\\overline{K}/K)$. Proposition\r\n1.9 of \\cite{FX13} shows that all $K$-analytic $(\\varphi_{q},\\Gamma_{K})$-modules\r\nof rank 1 over $\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E$ are obtained in\r\nthis way. We write $\\mathscr{I}_{\\mathrm{an}}=\\mathscr{I}_{\\mathrm{an}}(E)$\r\nfor the set of locally $K$-analytic Weil characters. There are two\r\ncharacters in $\\mathscr{I}_{\\mathrm{an}}$ of particular interest:\r\nthe inclusion character $x:K^{\\times}\\rightarrow E^{\\times}$ and\r\nthe character $\\mu_{\\lambda}(z)=\\lambda^{\\val_{\\pi}\\left(z\\right)}$\r\n. To $\\delta\\in\\mathscr{I}_{\\mathrm{an}}$ we associate to the weight\r\n$w(\\delta)=\\frac{\\log_{p}\\delta(u)}{\\log_{p}u}$ where $u\\in\\mathcal{O}_{K}^{\\times}$\r\nis any element with $\\log_{p}u\\neq0$, and then $w(\\delta)$ does\r\nnot depend on $u$. If $\\delta$ is unitary and $w(\\delta)\\in\\Z$\r\nthen $w(\\delta)$ is the $K$-Hodge-Tate weight of the associated\r\ncharacter of $\\Gal(\\overline{K}/K)$ (see $\\mathsection3$).\r\n\r\n\\subsection{Extensions}\r\n\r\nGiven $\\delta_{1},\\delta_{2}\\in\\mathscr{I}_{\\mathrm{an}}$ we consider\r\nthe set of extensions \r\n\\[\r\n0\\rightarrow\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{1})\\rightarrow\\D_{\\rig,K}^{\\dagger}\\rightarrow\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{2})\\rightarrow0\r\n\\]\r\nin the category of $K$-analytic $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules.\r\nThese extensions are classified by a finite-dimensional $E$-vector\r\nspace $\\H_{\\an}^{1}\\left(\\delta_{1}\\delta_{2}^{-1}\\right)$, whose\r\ndimension is determined in Theorem 0.3 of \\cite{FX13} as follows.\r\n\\begin{thm}\r\n$\\dim_{E}\\H_{\\an}^{1}\\left(\\delta_{1}\\delta_{2}^{-1}\\right)=2$ if\r\n$\\delta_{1}\\delta_{2}^{-1}=x^{-i}$ for $i\\in\\Z_{\\geq1}$ or if $\\delta_{1}\\delta_{2}^{-1}=\\mu_{q^{-1}}x^{i}$\r\nfor $i\\in\\Z_{\\geq0}$. Otherwise, $\\dim_{E}\\H_{\\an}^{1}\\left(\\delta_{1}\\delta_{2}^{-1}\\right)=1$.\r\n\\end{thm}\r\n\r\n\r\n\\subsection{Spaces of Lubin-Tate trianguline $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules\r\nof dimension 2}\r\n\r\nThere is an action of $\\mathbb{G}_{m}(E)=E^{\\times}$ on $\\H_{\\an}^{1}\\left(\\delta_{1}\\delta_{2}^{-1}\\right)$,\r\nand extensions which lie in the same orbit of this action give rise\r\nto isomorphic $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules. Following\r\n$\\mathsection6$ of \\cite{FX13} we write \r\n\\[\r\n\\mathscr{S}^{\\an}=\\mathscr{S}^{\\an}(E)=\\left\\{ s=(\\delta_{1},\\delta_{2},\\mathcal{L}):\\delta_{1},\\delta_{2}\\in\\mathscr{I}_{\\mathrm{an}}\\left(E\\right),\\mathcal{L}\\in\\H_{\\an}^{1}(\\delta_{1}\\delta_{2}^{-1})\\backslash\\left\\{ 0\\right\\} \\right\\} /\\mathbb{G}_{m}(E).\r\n\\]\r\nBy Theorem 6.2, each pair of characters $\\delta_{1},\\delta_{2}\\in\\mathscr{I}_{\\mathrm{an}}$\r\ngive rise either to a unique point $(\\delta_{1},\\delta_{2},\\infty)$\r\nof $\\mathscr{S}^{\\an}$ in the generic case or a $\\P^{1}(E)$-family\r\nof points of $\\mathscr{S}^{\\an}$ in the non generic case. To each\r\nsuch $s$ we associate the correspnding $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\n$\\D_{\\rig,K}^{\\dagger}(s)$ which is an extension of $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{1})$\r\nby $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{2})$. \r\n\r\nInside $\\mathscr{S}^{\\an}$, we consider the subset $\\mathscr{S}_{+}^{\\an}$\r\nof real interest given by these $s\\in\\mathscr{S}^{\\an}$ such that\r\n\\[\r\n\\val_{\\pi}(\\delta_{1}\\delta_{2})=0\\text{ and }\\val_{\\pi}(\\delta_{1}(\\pi))\\geq0.\r\n\\]\r\nFor example, all \u00e9tale $K$-analytic Lubin-Tate trianguline $(\\varphi_{q},\\Gamma_{K})$-modules\r\nappear in $\\mathscr{S}_{+}^{\\an}$.\r\n\r\nFor an element $s\\in\\mathscr{S}_{+}^{\\an}$ we associate two invariants:\r\nthe slope $u(s)=\\val_{\\pi}(\\delta_{1}(\\pi))$ and the weight $w(s)=w(\\delta_{1}\\delta_{2}^{-1})=w(\\delta_{1})-w(\\delta_{2})$.\r\nWe then have the following partition \r\n\\[\r\n\\mathscr{S}_{+}^{\\an}=\\mathscr{S}_{+}^{\\mathrm{ng}}\\amalg\\mathscr{S}_{+}^{\\cris}\\amalg\\mathscr{S}_{+}^{\\mathrm{\\st}}\\amalg\\mathscr{S}_{+}^{\\mathrm{\\mathrm{ord}}}\\amalg\\mathscr{S}_{+}^{\\mathrm{ncl}},\r\n\\]\r\nwhere\r\n\\[\r\n\\begin{aligned} & \\mathscr{S}_{+}^{\\mathrm{ng}}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:w(s)\\notin\\Z_{\\geq1}\\right\\} ,\\\\\r\n & \\mathscr{S}_{+}^{\\cris}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:w(s)\\in\\Z_{\\geq1},u(s)<w(s),\\mathcal{L}=\\infty\\right\\} ,\\\\\r\n & \\mathscr{S}_{+}^{\\mathrm{\\st}}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:w(s)\\in\\Z_{\\geq1},u(s)<w(s),\\mathcal{L}\\neq\\infty\\right\\} ,\\\\\r\n & \\mathscr{S}_{+}^{\\mathrm{\\mathrm{ord}}}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:w(s)\\in\\Z_{\\geq1},u(s)=w(s)\\right\\} ,\\\\\r\n & \\mathscr{S}_{+}^{\\mathrm{ncl}}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:w(s)\\in\\Z_{\\geq1},u(s)>w(s)\\right\\} .\r\n\\end{aligned}\r\n\\]\r\n\r\n(Here $\\mathrm{ng}$ and $\\mathrm{ncl}$ are abbreviations for ``non-geometric''\r\nand ``non-classical''). We also write $\\mathscr{S}_{0}^{\\an}=\\left\\{ s\\in\\mathscr{S}_{+}^{\\an}:u(s)=0\\right\\} $\r\nand $\\mathscr{S}_{0}^{*}=\\mathscr{S}_{+}^{*}\\cap\\mathscr{S}_{0}^{\\an}$.\r\nEach subset $\\mathscr{S}_{+}^{*}$ above is named according to the\r\nbehaviour that the $s\\in\\mathscr{S}_{+}^{*}$ exhibit. For example,\r\n$s\\in\\mathscr{S}_{+}^{\\an}$ is \u00e9tale if and only if $s\\notin\\mathscr{S}_{+}^{\\mathrm{ncl}}$,\r\nand in that case if $s\\in\\mathscr{S}_{+}^{\\cris}$ (resp. $s\\in\\mathscr{S}_{+}^{\\mathrm{\\st}}$,\r\n$s\\in\\mathscr{S}_{+}^{\\mathrm{\\mathrm{ord}}}$) then $\\D_{\\rig,K}^{\\dagger}(s)$\r\ncomes from a potentially crystalline (resp. semistable but non-crystalline,\r\npotentially ordinary) $E$-representation up to a twist. See $\\mathsection6$\r\nof \\cite{FX13} for more details.\r\n\\begin{lem}\r\nLet $\\D_{\\rig,K}^{\\dagger}$ be a $K$-analytic $(\\varphi_{q},\\Gamma_{K})$-module\r\nover $\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E$. Then \r\n\\[\r\n\\nabla\\left(t_{K}\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)\\right)\\subset t_{K}\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right).\r\n\\]\r\n.\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nUse the identity $\\nabla(t_{K}x)=t_{K}x+t_{K}\\nabla(x)=t_{K}(x+\\nabla(x))$.\r\n\\end{proof}\r\nThe following shows that if $s\\in\\mathscr{S}_{+}^{\\an}\\backslash\\left(\\mathscr{S}_{+}^{\\mathrm{ng}}\\cup\\mathscr{S}_{+}^{\\mathrm{ncl}}\\right)$\r\nthen $\\D_{\\rig,K}^{\\dagger}(s)$ is comes from a de Rham $E$-representation\r\nup to a twist (see Corollary 3.9).\r\n\\begin{cor}\r\nLet $s=(\\delta_{1},\\delta_{2},\\mathcal{L})\\in\\mathscr{S}_{+}^{\\an}$\r\nand suppose that $w(\\delta_{1}),w(\\delta_{2})\\in\\Z$ with $w(\\delta_{1})>w(\\delta_{2})$.\r\nThen $\\D_{\\rig,K}^{\\dagger}(s)$ is $K$-de Rham.\r\n\\end{cor}\r\n\r\n\\begin{proof}\r\nWe may assume that $\\delta_{1}=1$. Write $\\delta=\\delta_{2}$ so\r\nthat and $w(\\delta)<0$. Then $\\D_{\\dif,K}^{+}=\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$\r\nis an extension of the form \r\n\\[\r\n0\\rightarrow K_{\\infty}[[t_{K}]]\\otimes_{K}E\\rightarrow\\D_{\\dif,K}^{+}\\rightarrow\\D_{\\dif,K}^{+}\\left(\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)\\right)\\rightarrow0.\r\n\\]\r\nTake $e_{\\delta}\\in\\D_{\\dR,K}^{+}\\left(\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)\\right)=\\D_{\\dif,K}^{+}\\left(\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)\\right)^{\\Gamma_{K}=1}$\r\nand lift it to $\\D_{\\dif,K}^{+}$. If we take $e=1\\in K_{\\infty}[[t_{K}]]\\otimes_{K}E$\r\nthen $e,e_{\\delta}$ is a basis of $\\D_{\\dif,K}^{+}$, and the action\r\nof $\\nabla_{\\dif,K}$ on $\\D_{\\dif,K}^{+}$ in the basis $e,e_{\\delta}$\r\nis given by\r\n\\[\r\n\\Mat(\\nabla_{\\dif,K})=\\left(\\begin{array}{cc}\r\n0 & f\\\\\r\n0 & 0\r\n\\end{array}\\right),\r\n\\]\r\nwhere $f\\in K_{\\infty}[[t_{K}]]\\otimes_{K}E$. As $w(\\delta)<0$,\r\nwe have that $e_{\\delta}$ is divisible by $t_{K}$ so by Lemma 6.3\r\nwe have that $f$ is divisible by $t_{K}$. As $\\nabla_{\\dif,K}=t_{K}\\frac{\\partial}{\\partial t_{K}}$\r\non $K_{\\infty}[[t_{K}]]$ we may find an $h\\in K_{\\infty}[[t_{K}]]\\otimes_{K}E$\r\nwith $\\nabla_{\\dif,K}(h)=f$. Then $e$ and $e_{\\delta}-he$ give\r\na full set of sections for $\\nabla_{\\dif,K}$ on $\\D_{\\dif,K}^{+}$.\r\nBy Proposition 3.7 (which applies according to Remark 5.6) we are\r\ndone.\r\n\\end{proof}\r\n\\begin{rem}\r\nThe argument of Corollary 6.4 can be generalized to show that if $\\D_{\\rig,K}^{\\dagger}$\r\nis a $K$-analytic Lubin-Tate trianguline $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\nwhich is a successive extension of $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{i})$\r\nfor $i=1,...,d$ with $w(\\delta_{i})$ integers satisfying $w(\\delta_{1})>...>w(\\delta_{d})$,\r\nthen $\\D_{\\rig,K}^{\\dagger}$ is $K$-de Rham.\r\n\\end{rem}\r\n\r\n\r\n\\subsection{Lubin-Tate triangulation of a $p$-adic representation of dimension\r\n2}\r\n\r\nThe following generalizes Proposition 2.4.2 of \\cite{BC08}.\r\n\\begin{prop}\r\nLet $\\D_{\\rig,K}^{\\dagger}$ be a $K$-analytic $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module\r\nover $\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E$. Then for $\\alpha\\in E^{\\times}$\r\nand $i\\in\\Z$ we have\r\n\\[\r\n\\Fil^{i}\\left(\\D_{\\cris,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)\\right)\\cap\\D_{\\cris,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\varphi_{q}=\\alpha}=t_{K}^{i}\\D_{\\rig,K}^{\\dagger}\\cap\\D_{\\cris,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\varphi_{q}=\\alpha}.\r\n\\]\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nWe may reduce to the case $i=0$ by twisting. Since $\\D_{\\cris,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\Gamma_{K}}$\r\nand $\\D_{\\dR,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)=\\D_{\\dif,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\Gamma_{K}}$,\r\nfor $n\\gg0$ we have \r\n\\[\r\n\\varphi_{q}^{n}\\left(\\D_{\\cris,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)\\right)=\\left(\\iota_{0}\\circ\\varphi_{q}^{-n}\\right)^{-1}\\left(\\D_{\\dR,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)\\right).\r\n\\]\r\nIf $x\\in\\D_{\\cris,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$ satisfies\r\n$\\varphi_{q}(x)=x\\alpha$, then $x=\\alpha^{-n}\\varphi_{q}^{n}(x)$,\r\nso $\\left(\\iota_{0}\\circ\\varphi_{q}^{-n}\\right)\\left(x\\right)$ lies\r\nin $\\D_{\\dR,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$ for $n\\gg0$,\r\nwhence $x\\in\\D_{\\rig,K}^{\\dagger}$. Conversely, if $x\\in\\D_{\\rig,K}^{\\dagger}\\cap\\D_{\\cris,K}\\left(\\D_{\\rig,K}^{\\dagger}\\right)^{\\varphi_{q}=\\alpha}$\r\nwe have $\\left(\\iota_{0}\\circ\\varphi_{q}^{-n}\\right)(x)\\in\\D_{\\dR,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$\r\nfor $n\\gg0$, so $x\\in\\varphi_{q}^{n}\\left(\\D_{\\cris,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)\\right)$\r\nand the relation $x=\\alpha^{n}\\varphi_{q}^{-n}(x)$ implies $x\\in\\D_{\\cris,K}^{+}\\left(\\D_{\\rig,K}^{\\dagger}\\right)$.\r\n\\end{proof}\r\nFollowing $\\mathsection3$ of \\cite{Ch08}, we compute the triangulation\r\nof a representation of dimension $2$ in terms of a crystalline period.\r\n\\begin{prop}\r\nLet $V$ be a 2-dimensional $E$-linear $K$-analytic representation\r\nof $G_{K}$. Then $V$ is Lubin-Tate trianguline if and only if there\r\nexists a $K$-analytic character $\\eta:G_{K}\\rightarrow\\mathcal{O}_{E}^{\\times}$\r\nand $\\alpha\\in E^{\\times}$ such that $\\D_{\\cris,K}(V(\\eta))^{\\varphi_{q}=\\alpha}\\neq0$.\r\nMoreover, if $i$ is the largest integer such that $\\Fil^{i}\\D_{\\cris,K}(V(\\eta))^{\\varphi_{q}=\\alpha}\\nsubseteq\\Fil^{i+1}\\D_{\\cris,K}(V(\\eta))^{\\varphi_{q}=\\alpha}$,\r\nthen $\\D_{\\rig,K}^{\\dagger}(V)$ is an extension of $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{1})$\r\nby $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta_{2})$ where\r\n$\\delta_{1}=\\eta^{-1}\\mu_{\\alpha}x^{-i}$ and $\\delta_{2}=\\eta\\mu_{\\alpha^{-1}}x^{i}\\det(V)$.\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nIf $V$ is Lubin-Tate trianguline, then $\\D_{\\mathrm{rig,K}}^{\\dagger}(V)$\r\ncontains a submodule of rank 1 isomorphic to $\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)(\\delta)$\r\nfor some $\\delta\\in\\mathscr{I}_{\\mathrm{an}}$. Taking $\\eta:G_{K}\\rightarrow\\mathcal{O}_{E}^{\\times}$\r\ndefined by $\\eta(g)=\\delta^{-1}(\\chi_{\\pi}(g))$ we have $\\D_{\\cris,L}^{+}(V(\\eta))^{\\varphi_{q}=\\delta(\\pi)}=\\D_{\\mathrm{rig}}^{\\dagger}(V(\\eta))^{\\Gamma_{L}=1,\\varphi_{q}=\\delta(\\pi)}\\neq0$.\r\nConversely, suppose that such an $\\alpha$ and $\\eta$ exist. We shall\r\nshows $V$ is Lubin-Tate trianguline with the described triangulation.\r\nTwisting by a power of $\\chi_{\\pi}$, we may assume that $i=0$ and\r\nthat $\\D_{\\cris,K}^{+}(V(\\eta))^{\\varphi_{q}=\\alpha}$ contains an\r\nelement $f\\notin\\Fil^{1}\\D_{\\cris,K}(V(\\eta))^{\\varphi_{q}=\\alpha}$.\r\nBy what we have proven in $\\mathsection5$, we have\r\n\\[\r\n\\D_{\\cris,K}^{+}(V(\\eta))^{\\varphi_{q}=\\alpha}=\\D_{\\mathrm{rig},K}^{\\dagger}(V(\\eta))^{\\Gamma_{K}=1,\\varphi_{q}=\\alpha},\r\n\\]\r\nso $f\\in\\D_{\\mathrm{rig},K}^{\\dagger}(V(\\eta))^{\\Gamma_{K}=1,\\varphi_{q}=\\alpha}$.\r\nBy taking its span and twisting by $\\eta^{-1}$ we get a rank 1 sub\r\n$\\left(\\varphi_{q},\\Gamma_{K}\\right)$-module of $\\D_{\\mathrm{rig},K}^{\\dagger}(V)$.\r\nThe ideal $I$ generated by the coefficients of $f$ in a basis of\r\nin $\\D_{\\mathrm{rig},K}^{\\dagger}(V(\\eta))$ is stable under the actions\r\nof $\\varphi_{q}$ and $\\Gamma_{K}$. As $\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E$\r\nis a B\u00e9zout domain and $I$ is finitely generated, it is principal,\r\nand we conclude from Lemma 1.1 of \\cite{FX13} that $I=\\left(t_{K}^{n}\\right)$\r\nfor $n\\in\\Z_{\\geq0}$. Proposition 6.6 shows that $n=0$, and this\r\nmeans that \r\n\\[\r\n\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)\\cdot f(\\eta^{-1})\\cong\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)\\left(\\eta^{-1}\\mu_{\\alpha}\\right)\r\n\\]\r\n is a rank 1 saturated submodule of $\\D_{\\rig,K}^{\\dagger}(V)$. We\r\nthen have \r\n\\[\r\n\\D_{\\rig,K}^{\\dagger}(V)/\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)\\left(\\eta^{-1}\\mu_{\\alpha}\\right)\\cong\\left(\\B_{\\rig,K}^{\\dagger}\\otimes_{K}E\\right)\\left(\\eta\\mu_{\\alpha^{-1}}\\det(V)\\right)\r\n\\]\r\n by the classification of $\\left(\\varphi_{q},\\Gamma_{K}\\right)$-modules\r\nof rank 1.\r\n\\end{proof}\r\nFinally, we conclude with the proof of Theorem B from the introduction.\r\nTo do so, we first recall what are cyclotomic trianguline representations.\r\nLet $K_{\\infty}^{\\cyc}=K(\\mu_{p^{\\infty}})$ be the cyclotomic extension\r\nof $K$ and let $K_{0}'$ be the maximal unramified extension of $K_{0}$\r\nin $K_{\\infty}^{\\cyc}$. The ring $\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}$\r\nis the ring of power series $\\sum_{n\\in\\Z}a_{n}T^{n}$ with $a_{n}\\in K_{0}'$\r\nand such that $f(T)$ converges on some nonempty annulus $r<|T|<1$.\r\nThe ring is endowed with a $\\Frob_{p}$-semilinear $\\varphi$ action\r\nand a semilinear $\\Gamma_{K}^{\\mathrm{cyc}}$-action. If $K=K_{0}$\r\nthen $\\varphi(T)=(1+T)^{p}-1$ and $\\gamma(T)=(1+T)^{\\chi_{\\mathrm{cyc}}(\\gamma)}-1$,\r\nbut in general the action has to do with the theory of lifting the\r\nfield of norms and is more complicated.\r\n\r\nWe can then define a notion of a $\\left(\\varphi,\\Gamma_{K}^{\\mathrm{cyc}}\\right)$-module\r\nover $\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E$ analogous\r\nto the notion of a $(\\varphi,\\Gamma_{K})$-module over $\\B_{\\rig,K}^{\\dagger}\\otimes_{\\Q_{p}}E$.\r\nIf $V$ is an $E$-linear representation of $G_{K}$, one can associate\r\nto $V$ a $\\left(\\varphi,\\Gamma_{K}^{\\mathrm{cyc}}\\right)$-module\r\n$\\D_{\\rig,K}^{\\dagger,\\cyc}(V)$ over $\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E$.\r\nNow let $\\delta:K^{\\times}\\rightarrow E^{\\times}$ a continuous character;\r\nwe can define a $\\left(\\varphi,\\Gamma_{K}^{\\mathrm{cyc}}\\right)$-module\r\n$\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)$\r\nin the following way. If $\\delta$ is unitary, then it corresponds\r\nto a character $\\delta:G_{K}\\rightarrow E^{\\times}$, and we set $\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)=\\D_{\\rig,K}^{\\dagger,\\cyc}(V)(E(\\delta))$.\r\nIf $\\delta|_{\\mathcal{O}_{K}^{\\times}}=1$, set \r\n\\[\r\n\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)=\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left[\\varphi\\right]\\otimes_{\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left[\\varphi_{q}\\right]}Ee_{\\delta},\r\n\\]\r\nwhere $\\varphi_{q}(e_{\\delta})=\\delta(\\pi)e_{\\delta}$. For general\r\n$\\delta$, write $\\delta=\\delta_{1}\\delta_{2}$ where $\\delta_{1}$\r\nis unitary and $\\delta_{2}|_{\\mathcal{O}_{K}^{\\times}}$ and set $\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)=\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta_{1}\\right)\\otimes\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta_{2}\\right)$.\r\n\r\nAn an $E$-linear representation $V$ of $G_{K}$ is said to be cyclotomic\r\ntrianguline if $\\D_{\\rig,K}^{\\dagger,\\cyc}(V)$ is a successive extension\r\n$\\left(\\varphi,\\Gamma_{K}^{\\cyc}\\right)$-modules of the form $\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)$.\r\nThis is the same notion of triangulinity which appears in \\cite{Na09,KPX14,Li12},\r\nbut we give it a different name here to distinguish it from Lubin-Tate\r\ntriangulinity.\r\n\\begin{thm}\r\nLet $V$ be a 2-dimensional $E$-linear $K$-analytic representation\r\nof $G_{K}$. The following are equivalent.\r\n\\end{thm}\r\n\r\n\\begin{enumerate}\r\n\\item \\emph{$V$ is cyclotomic trianguline.}\r\n\\item \\emph{There exists a $K$-analytic character $\\eta:\\mathcal{O}_{K}^{\\times}\\rightarrow E^{\\times}$\r\nand $\\alpha\\in E^{\\times}$ such that $\\D_{\\cris,\\Q_{p}}(V(\\eta))^{\\varphi_{q}=\\alpha}$\r\nis nonzero.}\r\n\\item \\emph{There exists a $K$-analytic character $\\eta:\\mathcal{O}_{K}^{\\times}\\rightarrow E^{\\times}$\r\nand $\\alpha\\in E^{\\times}$ such that $\\D_{\\cris,K}(V(\\eta))^{\\varphi_{q}=\\alpha}$\r\nis nonzero.}\r\n\\item $V$ \\emph{is Lubin-Tate trianguline.}\r\n\\end{enumerate}\r\n\\begin{proof}\r\nThe equivalence between 3 and 4 was proven in Proposition 6.7, while\r\nthe equivalence between 2 and 3 follows from Lemma 3.10. It remains\r\nto prove the equivalence of 1 and 2. This equivalence seems to be\r\nwell known but due to a lack of suitable reference when $K\\neq\\Q_{p}$\r\nwe give a proof here.\r\n\\begin{proof}\r\nIf $V$ is cyclotomic trianguline, then $\\D_{\\rig,K}^{\\dagger,\\cyc}(V)$\r\ncan be written as an extension \r\n\\[\r\n0\\rightarrow\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta_{1}\\right)\\rightarrow\\D_{\\rig,K}^{\\dagger,\\cyc}(V)\\rightarrow\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta_{2}\\right)\\rightarrow0.\r\n\\]\r\nSince $V$ is $K$-analytic, $\\delta_{1}$ is also $K$-analytic.\r\nTwisting by $\\delta_{1}|_{\\mathcal{O}_{K}^{\\times}}^{-1}$, we may\r\nassume $\\delta_{1}|_{\\mathcal{O}_{K}^{\\times}}=1$. It then follows\r\nfrom \\cite[Example 6.2.6]{KPX14} that \r\n\\[\r\n\\D_{\\cris}\\left(\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta_{1}\\right)\\right)=\\mathrm{I}_{\\Q_{p}}^{K}\\left(Ee_{\\delta_{1}}\\right),\r\n\\]\r\nwhere $\\varphi_{q}(e_{\\delta_{1}})=\\delta_{1}(\\pi)e_{\\delta_{1}}$.\r\nIt follows that $\\D_{\\cris,\\Q_{p}}(V)^{\\varphi_{q}=\\delta_{1}(\\pi)}\\neq0$.\r\n\\end{proof}\r\nConversely, suppose that 2 holds. By replacing $V$ with a $K$-analytic\r\ntwist, we may assume that $\\D_{\\cris,\\Q_{p}}^{+}(V)^{\\varphi_{q}=\\alpha}=\\D_{\\cris,\\Q_{p}}(V)^{\\varphi_{q}=\\alpha}\\neq0$.\r\nIt follows from Berger's dictionary that\r\n\\[\r\n\\D_{\\rig,K}^{\\dagger,\\cyc}(V)^{\\Gamma_{K}^{\\cyc},\\varphi_{q}=\\alpha}=\\D_{\\cris,\\Q_{p}}^{+}(V)^{\\varphi_{q}\\neq0},\r\n\\]\r\nso that $\\D_{\\rig,K}^{\\dagger,\\cyc}(V)^{\\Gamma_{K}^{\\cyc},\\varphi_{q}=\\alpha}$\r\ncontains a $(\\varphi_{q},\\Gamma_{K}^{\\cyc})$ invariant $E$-line,\r\nand hence $\\text{\\ensuremath{\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta\\right)}}$\r\nwhere $\\delta|_{\\mathcal{O}_{K}^{\\times}}=1$ and $\\delta(\\pi_{K})=\\alpha$.\r\nThis sub $\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E$-module\r\nmay not be saturated, but it follows from \\cite[Corollary 6.2.9]{KPX14}\r\nthat $\\D_{\\rig,K}^{\\dagger,\\cyc}(V)$ contains a saturated module\r\nof the form $\\left(\\B_{\\rig,K}^{\\dagger,\\mathrm{cyc}}\\otimes_{\\Q_{p}}E\\right)\\left(\\delta'\\right)$.\r\nIn particular, $\\D_{\\rig,K}^{\\dagger,\\cyc}(V)$ is an extension of\r\ntwo rank 1 $(\\varphi_{q},\\Gamma_{K}^{\\cyc})$-modules, so $V$ is\r\ncyclotomic trianguline.\r\n\\end{proof}\r\n\r\n\\section{Overconvergent Hilbert modular forms}\r\n\r\n\\subsection{Overconvergent Hilbert eigenforms}\r\n\r\nWe briefly recall what we need about the cuspidal Hilbert eigenvariety\r\nof Andreatta, Iovita and Pilloni (see \\cite{AIP16}). \r\n\r\nLet $F$ be a totally real number field, $\\Sigma$ the set of embeddings\r\nof $F$ in $\\overline{\\Q}$ and $N\\in\\Z_{\\geq4}$. A choice of an\r\nembedding $\\overline{\\Q}\\hookrightarrow\\overline{\\Q}_{p}$ determines\r\na decomposition $\\Sigma=\\amalg_{v:v|p}\\Sigma_{F_{v}}$ where each\r\n$v$ is a place of $F$ lying over $p$. Let $L$ be a finite extension\r\nof $\\Q_{p}$ which contains $F^{\\Gal}$. The weight space for the\r\nalgebraic group $\\Res_{\\mathcal{O}_{F}/\\Z}\\GL_{2}$ is $\\mathcal{W}=\\mathrm{Spf}\\left(\\mathcal{O}_{L}\\left[\\left[\\left(\\mathcal{O}_{F}\\otimes_{\\Z}\\Z_{p}\\right)^{\\times}\\times\\Z_{p}^{\\times}\\right]\\right]\\right)^{\\rig}$.\r\nIf $f$ is a classical Hilbert eigenform on $F$ of tame level $N$,\r\nits weight is a tuple $\\mathrm{wt}(f)=\\left(\\left\\{ k_{\\tau}\\right\\} _{\\tau\\in\\Sigma},w\\right)\\in\\Z_{\\geq1}^{\\Sigma}\\times\\Z$\r\nsatisfying $k_{\\tau}\\equiv w\\mod2$ for each $\\tau\\in\\Sigma$. It\r\nis then identified with the point in $\\mathcal{W}$ corresponding\r\nto the character $(z_{1},z_{2})\\mapsto\\left(\\prod_{\\tau\\in\\Sigma}\\tau(z_{1})^{k_{\\tau}}\\right)z_{2}^{w}$.\r\nThe cuspidal Hilbert eigenvariety of tame level $N$ is a certain\r\nrigid analytic space $\\mathcal{E}$ which gives a $p$-adic interpolation\r\nof classical Hilbert eigenforms. More precisely, it is a rigid analytic\r\nspace together with a weight map $\\mathrm{wt}:\\mathcal{E}\\rightarrow\\mathcal{W}$\r\nwhose points parametrize overconvergent Hilbert modular forms of finite\r\nslope together with a choice of Hecke eigenvalues at places $v|p$.\r\nWe summarize its properties below (see $\\mathsection5$ of \\cite{AIP16}).\r\n\\begin{thm}\r\n1. The map $\\mathrm{wt}:\\mathcal{E}\\rightarrow\\mathcal{W}$ is, locally\r\non $\\mathcal{E}$ and $\\mathcal{W}$, finite and surjective.\r\n\r\n2. For each $\\kappa\\in\\mathcal{W}(\\C_{p})$, the fiber $\\mathrm{wt}^{-1}(\\mathcal{\\kappa})$\r\nis in bijection with finite slope Hecke eigenvalues appearing in the\r\nspace of overconvergent cusp forms of weight $\\kappa$, level $N$\r\nand coefficients in $\\C_{p}$.\r\n\r\n3. There exists a universal Hecke character $\\lambda:\\mathcal{H}^{Np}\\otimes\\mathcal{U}_{p}\\rightarrow\\mathcal{O}_{\\mathcal{E}}$.\r\nHere, $\\mathcal{H}^{Np}$ is the abstract Hecke algebra away from\r\n$Np$, and $\\mathcal{U}_{p}$ is the $\\Q_{p}$-algebra generated by\r\nthe $U_{v}$-operators for $v|p$.\r\n\r\n4. There is a universal pseudo-character $T:\\Gal(\\overline{F}/F)\\rightarrow\\mathcal{O}_{\\mathcal{E}}$\r\nwhich is unramified for $\\mathfrak{l}\\nmid Np$ such that $T(\\Frob_{\\mathfrak{l}})=\\lambda\\left(T_{\\mathfrak{l}}\\right)$\r\nfor the arithmetic Frobenius $\\Frob_{\\mathfrak{l}}$.\r\n\r\n5. For each $x\\in\\mathcal{E}$ there exists a semisimple Galois representation\r\n$\\rho_{x}:\\Gal(\\overline{F}/F)\\rightarrow\\GL_{2}\\left(\\overline{k}(x)\\right)$\r\nwhich is unramified for $\\mathfrak{l}\\nmid Np$ and which is characterized\r\nby $\\Tr(\\rho_{x})=T_{x}$ and $\\det(\\rho_{x})=\\mathrm{Nm}_{F/\\Q}\\left(\\mathfrak{l}\\right)\\lambda_{x}(S_{\\mathfrak{l}})$.\r\n\r\n6. The generalized Hodge-Tate weights of $\\rho_{x}|_{G_{F_{v}}}$\r\nare $\\left\\{ \\frac{w-k_{\\tau}}{2},\\frac{w+k_{\\tau}-2}{2}\\right\\} _{\\tau\\in\\Sigma_{F_{v}}}$.\r\n\\end{thm}\r\n\r\nWe fix a place $v|p$ in $F$ and place ourselves in the setting of\r\n$\\mathsection1.2$ with $K=F_{v}$, $\\pi=\\pi_{v}$ a uniformizer of\r\n$F_{v}$, etc.  We extend scalars if necessary so that $\\rho_{x}|_{G_{F_{v}}}$\r\nis $F_{v}^{\\Gal}$-linear.\r\n\\begin{prop}\r\nFor $x\\in\\mathcal{E}$, we have\r\n\\[\r\n\\D_{\\cris,F_{v}}^{+}\\left(\\rho_{x}^{\\vee}|_{G_{F_{v}}}\\left(\\prod_{\\tau\\in\\Sigma_{F_{v}}}\\left(\\tau\\circ\\chi_{\\pi_{v}}\\right)^{\\frac{w-k_{\\tau}}{2}}\\right)\\right)^{\\varphi_{q}=\\prod_{\\tau\\in\\Sigma_{F_{v}}}\\tau(\\pi_{v})^{\\frac{k_{\\tau}-w}{2}}U_{v}}\\neq0.\r\n\\]\r\n\\end{prop}\r\n\r\n\\begin{proof}\r\nFor classical Hilbert modular forms of cohomological weights this\r\nis known by Saito's local-global compatibility results in \\cite{Sa09}.\r\nThe regular classical points are Zariski dense in $\\mathcal{E}$ by\r\nthe classicality criterion in \\cite{Bi16}, so the claim follows from\r\nthe global triangulation results in Theorem 6.3.13 of \\cite{KPX14}\r\nor in Theorem 4.4.2 of \\cite{Li12}.\r\n\\end{proof}\r\n\r\n\\subsection{Lubin-Tate triangulation}\r\n\r\nLet $x\\in\\mathcal{E}$ and and consider $\\rho_{x}|_{G_{F_{v}}}$ as\r\nan $E$-linear representation for some finite extension $\\Q_{p}\\subset E$\r\nwhich contains $F_{v}^{\\Gal}$ and $\\overline{k}(x)$. In this section\r\nwe shall assume $\\rho_{x}|_{G_{F_{v}}}$ is nonsplit. The split case\r\nis less interesting and can be easily dealt with. By Corollary 5.3\r\nwe get the following.\r\n\\begin{prop}\r\n$\\rho_{x}|_{G_{F_{v}}}$ is overconvergent if and only it is $F_{v}$-analytic\r\nup to a twist.\r\n\\end{prop}\r\n\r\nLet us assume then that $\\rho_{x}|_{G_{F_{v}}}$ is s $F_{v}$-analytic\r\nup to a twist, so that that the weights at $\\Sigma_{F_{v}}$ are $(k,1,...,1)$\r\nwhere $k=k_{\\Id}$. Let $a_{v}$ be eigenvalue of $U_{v}$ for the\r\ncorresponding Hecke operator of $v$. Then $\\alpha_{v}=\\pi_{v}^{\\frac{k-1}{2}}\\left(\\N_{F_{v}/\\Q_{p}}(\\pi_{v})\\right)^{\\frac{1-w}{2}}a_{v}$\r\ninterpolates to a function on $\\mathcal{E}$ (see Remark 4.7 of \\cite{AIP16}).\r\nUpon writing\r\n\\[\r\nV=\\rho_{x}^{\\vee}|_{G_{F_{v}}}\\left(\\chi_{\\pi_{v}}^{\\frac{1-k}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ\\chi_{\\pi_{v}}\\right)^{\\frac{w-1}{2}}\\right),\r\n\\]\r\nProposition 7.2 becomes the statement $\\D_{\\cris,F_{v}}^{+}(V)^{\\varphi_{q}=\\alpha_{v}}\\neq0$.\r\nThe representations $\\rho_{x}|_{G_{F_{v}}}$ and $V$ differ by a\r\ndual and a character twist, so according to Corollary 5.3 their overconvergence\r\nand Lubin-Tate triangulinity are equivalent. However, $V$ is $F_{v}$-analytic\r\nwith $F_{v}$-Hodge-Tate weights $0$ and $k-1$ which makes it nicer\r\nto work with. \r\n\r\nThe following is a generalization of Proposition 5.2 of \\cite{Ch08}. \r\n\\begin{thm}\r\nThe representation $V$ is Lubin-Tate trianguline. We have $\\D_{\\rig,F_{v}}^{\\dagger}\\left(V\\right)=\\D_{\\rig,F_{v}}^{\\dagger}(s)$\r\nfor $s=\\left(\\delta_{1},\\delta_{1}^{-1}\\det(V),\\mathcal{L}\\right)\\in\\mathscr{S}_{+}^{\\an}$,\r\nwhere\r\n\\end{thm}\r\n\r\n\\begin{enumerate}\r\n\\item If $k\\notin\\Z_{\\geq1}$ then $\\delta_{1}=\\mu_{\\alpha_{v}}$, $\\mathcal{L}=\\infty$\r\nand $s\\in\\mathscr{S}_{+}^{\\mathrm{ng}}$.\r\n\\item If $k\\in\\Z_{\\geq1}$ and $\\val_{\\pi_{v}}(\\alpha_{v})<k-1$ then $\\delta_{1}=\\mu_{\\alpha_{v}}$\r\nand either \r\n\\begin{enumerate}\r\n\\item $\\mathcal{L}=\\infty$, in which case $s\\in\\mathscr{S}_{+}^{\\cris}$. \r\n\\item $\\mathcal{L}\\neq\\infty$, in which case $s\\in\\mathscr{S}_{+}^{\\st}$.\r\nThis is only possible if $2\\val_{\\pi_{v}}(\\alpha_{v})+\\left[F_{v}:\\Q_{p}\\right]=k-1$.\r\n\\end{enumerate}\r\n\\item If $k\\in\\Z_{>1}$ and $\\val_{\\pi_{v}}(\\alpha_{v})=k-1$, then $\\delta_{1}=\\mu_{\\alpha_{v}}$,\r\n$\\mathcal{L}=\\infty$ and $s\\in\\mathscr{S}_{+}^{\\mathrm{ord}}$.\r\n\\item If $k\\in\\Z_{\\geq1}$ and $\\val_{\\pi_{v}}(\\alpha_{v})>k-1$ then $\\delta_{1}=x^{1-k}\\mu_{\\alpha_{v}}$,\r\n$\\mathcal{L}=\\infty$ and $s\\in\\mathscr{S}_{+}^{\\mathrm{ng}}$.\r\n\\end{enumerate}\r\n\\begin{proof}\r\nBy Proposition 6.7, we know $V$ is Lubin-Tate trianguline and a triangulation\r\nis determined the by largest $i\\in\\Z$ with $\\Fil^{i}\\D_{\\cris,F_{v}}(V)^{\\varphi_{q}=\\alpha_{v}}\\nsubseteq\\Fil^{i+1}\\D_{\\cris,F_{v}}(V)^{\\varphi_{q}=\\alpha_{v}}$.\r\nIt remains to determine $i$ in each case; it is a nonnegative $F_{v}$-Hodge-Tate\r\nweight of $V$. If $k\\notin\\Z_{>1}$ then $i=0$, so (1) is settled\r\nand we may assume $k\\in\\Z_{>1}$.  \r\n\r\nAssume that $\\val_{\\pi_{v}}(\\alpha_{v})<k-1$ and suppose by contradiction\r\nthat $i=k-1$. Then $\\D_{\\rig,F_{v}}^{\\dagger}\\left(V\\right)$ has\r\n$\\left(\\B_{\\rig,F_{v}}^{\\dagger}\\otimes_{F_{v}}E\\right)(x^{1-k}\\mu_{\\alpha_{v}})$\r\nas a subobject, and the latter has slope $\\val_{\\pi_{v}}(\\alpha_{v})-(k-1)<0$\r\nwhich contradicts Kedlaya's slope filtration theorem. Thus $i=0$.\r\nFor the equality in part (b) of (2), observe that $\\mathcal{L}\\neq\\infty$\r\ncan only occur if $\\dim_{E}\\H_{\\an}^{1}\\left(\\delta_{1}\\delta_{2}^{-1}\\right)>1$,\r\nwhich by Theorem 6.2 implies $\\delta_{1}\\delta_{2}^{-1}=\\mu_{q^{-1}}x^{k-1}$.\r\nThis proves (2).\r\n\r\nFor (3), suppose by contradiction that $i=k-1$. Then $\\delta_{1}=x^{1-k}\\mu_{\\alpha_{v}}$\r\nand $s\\in\\mathscr{S}_{0}^{\\mathrm{cris}}\\amalg\\mathscr{S}_{0}^{\\st}$,\r\nso by Corollary 6.4 we have that $V$ is de Rham. A similar argument\r\nto Lemma 6.7 of \\cite{Ki03} shows that $V$ must be split, contradicting\r\nour assumption that $\\rho_{x}|_{G_{F_{v}}}$ is nonsplit.\r\n\r\nFinally, suppose that $\\val_{\\pi_{v}}(\\alpha_{v})>k-1$ and suppose\r\nby contradiction that $i=0$. Then $\\D_{\\rig,F_{v}}^{\\dagger}\\left(V\\right)$\r\nis an extension of $\\left(\\B_{\\rig,F_{v}}^{\\dagger}\\otimes_{F_{v}}E\\right)(\\delta_{1})$\r\nby $\\left(\\B_{\\rig,F_{v}}^{\\dagger}\\otimes_{F_{v}}E\\right)(\\delta_{2})$\r\nwith $w(\\delta_{1})=0$ and $w(\\delta_{2})=1-k$. This implies by\r\nCorollary 6.4 that $V$ is $F_{v}$-de Rham, and hence also $F_{v}$-potentially\r\nsemistable by Corollary 3.9. But this contradicts admissiblity because\r\n$\\val_{\\pi_{v}}(\\alpha_{v})>k-1$.\r\n\\end{proof}\r\n\\begin{rem}\r\n$\\ $\r\n\\end{rem}\r\n\r\n\\begin{enumerate}\r\n\\item If $k,w\\in\\Z$ then $\\val_{\\pi_{v}}(\\alpha_{v})=\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right]+\\val_{\\pi_{v}}(a_{v})$.\r\nThe small slope condition $0\\leq\\val_{\\pi_{v}}(\\alpha_{v})\\leq k-1$\r\ncan then be rewritten as\r\n\\[\r\n\\frac{1-k}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right]\\leq\\val_{\\pi_{v}}(a_{v})\\leq\\frac{k-1}{2}+\\frac{w-1}{2}\\left[F_{v}:\\Q_{p}\\right].\r\n\\]\r\n\\item The parameter $\\mathcal{L}\\neq0$ appearing in the case 2(b) is described\r\nin the work of Ding (Corollary 2.3 of \\cite{Di17}) in the following\r\nway. Upon considering these points of $\\mathcal{E}$ with weights\r\n$(\\kappa,1,...,1)$ in a small affinoid neighborhood of $x$, one\r\nhas\r\n\\[\r\n\\mathcal{L}(x)=-2\\frac{d\\log\\alpha_{v}}{d\\kappa}|_{\\kappa=k}.\r\n\\]\r\n\\item When $F=\\Q$ and $k\\geq2$, Coleman's classicality theorem (\\cite{Co97})\r\nsays that $f$ is classical if and only if $\\val_{p}(a_{p})<k-1$\r\nor $\\val_{p}(a_{p})=k-1$ and $f$ is not in the image of $\\Theta^{k-1}$,\r\nwhere $\\Theta$ is the operator which acts on $q$-expansions by $q\\frac{d}{dq}$.\r\nAnalogously, we can give a prediction in general when $p$ is an inert\r\nprime in $F$. We expect that an $F_{p}$-analytic form $f$ is classical\r\nif and only if $\\val_{p}(\\alpha_{p})<k-1$ or $\\val_{p}(\\alpha_{p})=k-1$\r\nand $f$ is not in the image of $\\Theta_{\\Id}^{k-1}$. Here $\\Theta_{\\mathrm{Id}}$\r\nis the Theta operator in the direction of the identity embedding,\r\nas constructed in $\\mathsection15$ of \\cite{AG05}. If such a classicality\r\nstatement were known, one could argue as in $\\mathsection6$ of \\cite{Ki03}\r\nand deduce the Fontaine-Mazur conjecture for the representations attached\r\nto $F_{p}$-analytic finite slope Hilbert eigenforms.\r\n\\item If we allow $\\rho_{f}|_{G_{F_{v}}}$ to be split, it is also possible\r\nthat $k\\in\\Z_{\\geq1}$, $\\val_{\\pi_{v}}(\\alpha_{v})=k-1$ and $\\Fil^{k-1}\\D_{\\cris,F_{v}}(V)^{\\varphi_{q}=\\alpha_{v}}\\neq0$.\r\nOur expectation is that if $f$ itself is not classical then $f=\\Theta_{\\Id}^{k-1}g$\r\nfor some eigenform $g$, so that this is the only case where $\\rho_{f}|_{G_{F_{v}}}$\r\ncan be de Rham without $f$ itself being classical. In the case of\r\n$F=\\Q$, this is known by $\\mathsection6$ of \\cite{Ki03}.\r\n\\end{enumerate}\r\n\r\n\\subsection{Example: the eigenform of Moy and Spencer}\r\n\r\nIn this section we shall test our results for a classical Hilbert\r\neigenform. It is not too easy to find \\emph{explicit} classical Hilbert\r\neigenforms for which Theorem 7.4 gives any new information beyond\r\nthat which already exists in the literature. The case where $v$ splits\r\nin $F$ is well understood, and for CM Hilbert eigenforms of $F$\r\nthe local representation at $F_{v}$ splits so Theorem 7.4 is rather\r\ntrivial. That's why we shall consider in this subsection the non-CM\r\nHilbert eigenform of partial weight 1 found by Moy and Spencer in\r\n\\cite{MS15}. To the best of the author's knowledge, it is the only\r\nexample in the literature of a non-CM classical Hilbert eigenform\r\nof partial weight 1. \r\n\r\nRecall that if $f$ is a classical Hilbert eigenform of level $\\Gamma_{1}(N)$\r\nand nebentypus $\\varepsilon$, the Hecke polynomial $P_{v}(X)$ at\r\na place $v$ with $a_{v}\\neq0$ is given by\r\n\\[\r\nP_{v}(X)=\\begin{cases}\r\nX-a_{v} & \\text{if }v\\mid N\\\\\r\nX^{2}-c(v,f)X+\\varepsilon(v)\\N_{F/\\Q}(v)^{w-1} & \\text{if }v\\nmid N\r\n\\end{cases},\r\n\\]\r\nwhere $c(v,f)$ is the $T_{v}$-eigenvalue. When $v\\nmid N$, raising\r\nthe level of $f$ gives two eigenforms $f_{1},f_{2}$ whose attached\r\n$p$-adic representations $\\rho_{f}$ coincide and such that $\\left\\{ a_{v}(f_{1}),a_{v}(f_{2})\\right\\} $\r\nare the two roots of $P_{v}(X)$. Using Theorem 7.4, this gives rise\r\nto two different triangulations of $V=\\rho_{x}^{\\vee}|_{G_{F_{v}}}\\left(\\chi_{\\pi_{v}}^{\\frac{1-k}{2}}\\left(\\N_{F_{v}/\\Q_{p}}\\circ\\chi_{\\pi_{v}}\\right)^{\\frac{w-1}{2}}\\right)$.\r\nWhenever local-global compatibility holds, the Hecke polynomial is\r\nequal to the characteristic polynomial of the action of $\\varphi_{q}$\r\non $\\D_{\\cris}^{+}\\left(\\rho_{f}|_{G_{F_{v}}}^{\\vee}\\right)$. Thus\r\nthe valuation of $c(v,f)$ determines the valuations of the eigenvalues\r\nof $\\varphi_{q}$ by the method of the Newton polygon. This observation\r\nis used in the computations below.\r\n\r\nNext recall that the main theorem of \\cite{MS15} finds for $F=\\Q(\\sqrt{5})$\r\na non CM cuspidal Hilbert eigenform $f$ of weights $(k_{1},k_{2},w)=(5,1,5)$,\r\nlevel $\\Gamma_{1}(14)$, nebentypus $\\varepsilon$ with conductor\r\n$7\\left(\\infty_{1}\\right)\\left(\\infty_{2}\\right)$. For the following\r\nexamples, we let $p$ be a prime in the range $[2,11]$, $v$ a place\r\nof $F$ lying over that prime and $\\rho_{f}$ the associated $p$-adic\r\nGalois representation of $f$. We set\r\n\\[\r\nV=\\rho_{x}^{\\vee}|_{G_{F_{v}}}\\left(\\chi_{\\pi_{v}}^{-2}\\left(\\N_{F_{v}/\\Q_{p}}\\circ\\chi_{\\pi_{v}}\\right)^{2}\\right),\r\n\\]\r\nwhich differs from $\\rho_{f}|_{G_{F_{v}}}$ only by a dual and a crystalline\r\ntwist. We shall examine the behaviour of $V$ for different $v$.\r\nWhen $v\\neq(2)$ local-global compatibility holds by Remark 1.5 of\r\n\\cite{Ne15}, while in $v=(2)$ we shall assume it holds, though it\r\nseems to be still conjectural in this case. Local-global compatibility\r\nimplies that $\\rho_{f}|_{G_{F_{v}}}$ is de-Rham, and since its Hodge-Tate\r\nweights at each nontrivial embedding of $F_{v}$ are $\\{0,0\\}$, it\r\nis also $F_{v}$-analytic. Given an eigenvalue $a_{v}$ of $U_{v}$,\r\nTheorem 7.4 produces a point $s\\in\\mathscr{S}_{+}^{\\an}$. The table\r\nin $\\mathsection3$ of \\cite{MS15} computes the values of $a_{v}$\r\nfor such $v$. It has to lie in the range given by Remark 7.5(1).\r\n\r\n\\textbf{Examples.}\r\n\r\n1. The place $v=\\left(2\\right)$ lies over the inert prime $p=2$\r\nand the valuation bound is $\\val_{v}(a_{v})\\in\\left[2,6\\right]$.\r\nSince the character has conductor prime to $2$ and the level at $2$\r\nis $\\Gamma_{0}(2)$, the local component $\\pi_{2}(f)$ is Steinberg\r\n(up to an unramified quadratic twist). A suitable local-global compatibility\r\ntheorem predicts that $V$ is semistable noncrystalline and $s\\in\\mathscr{S}_{+}^{\\st}$.\r\nIn particular, the condition of case 2(b) of Theorem 7.4 predicts\r\nthat $\\val_{2}(a_{2})=3$, which is confirmed by $\\mathsection3$\r\nof \\cite{MS15}.\r\n\r\n2. The place $v=\\left(3\\right)$ lies over the inert prime $p=3$\r\nand the valuation bound is $\\val_{v}(a_{v})\\in\\left[2,6\\right]$.\r\nThe place $v$ is coprime to the level, so the local component $\\pi_{3}(f)$\r\nis unramified principal series. By local-global compatibility, $V$\r\nis crystalline. By $\\mathsection3$ of \\cite{MS15}, we have $\\val_{3}\\left(c(3,f)\\right)=2$,\r\nso that the two $U_{v}$-eigenvalues have valuations $2$ and $4$.\r\nThen $V$ has two triangulations, giving rise to $s_{1}\\in\\mathscr{S}_{0}^{\\cris}$\r\nand $s_{2}\\in\\mathscr{S}_{+}^{\\mathrm{ord}}$.\r\n\r\n3. The place $v=\\left(\\sqrt{5}\\right)$ lies over the ramified prime\r\n$p=5$ and the valuation bound is $\\val_{v}(a_{v})\\in\\left[2,6\\right]$.\r\nBy $\\mathsection3$ of \\cite{MS15}, we have $\\val_{v}\\left(c(v,f)\\right)=2$,\r\nand the triangulations in this case behave similar to the case of\r\n$v=(3)$.\r\n\r\n4. The place $v=\\left(7\\right)$ lies over the inert prime $p=7$\r\nand the valuation bound is $\\val_{v}(a_{v})\\in\\left[2,6\\right]$.\r\nThe character has conductor divisible by $7$ and the level at $7$\r\nis $\\Gamma_{0}(7)$, so the local component $\\pi_{7}(f)$ is ramified\r\nprinicpal series. After an abelian extension it becomes unramified\r\nprincipal series, so by local-global compatibility $V$ is crystabelline.\r\nBy $\\mathsection3$ of \\cite{MS15}, we have $\\val_{7}\\left(a_{7}\\right)=3$,\r\nso $V$ gives rise to $s\\in\\mathscr{S}_{+}^{\\cris}\\backslash\\mathscr{S}_{0}^{\\cris}$.\r\n\r\n5. The place $v=\\left(\\frac{7+\\sqrt{5}}{2}\\right)$ lies over the\r\nsplit prime $p=11$ and the valuation bound is $\\val_{v}(a_{v})\\in\\left[0,4\\right]$.\r\nBy $\\mathsection3$ of \\cite{MS15}, we have $\\val_{v}\\left(c(v,f)\\right)=0$,\r\nand the triangulations in this case behave similar to the case of\r\n$v=(3)$ and $v=\\left(\\sqrt{5}\\right)$.\r\n\r\n.\r\n\\begin{thebibliography}{AIP16}\r\n\\bibitem[AG05]{AG05}Andreatta F., Goren E.,\\emph{ Hilbert modular\r\nforms: mod $p$ and $p$-adic aspects}, Memoirs of Amer. Math. Soc.\r\n819, 2005.\r\n\r\n\\bibitem[AIP16]{AIP16}Andreatta F., Iovita A., Pilloni V., \\emph{On\r\noverconvergent hilbert modular cusp forms}, Ast\u00e9risque 382 (2016):\r\n163-193.\r\n\r\n\\bibitem[BC09]{BC09}Bella\u00efche J., Chenevier G., F\\emph{amilies of\r\nGalois Representations and Selmer Groups,} Ast\u00e9risque 324, Soc. Math.\r\nFrance, 314 p. (2009).\r\n\r\n\\bibitem[Be02]{Be02}Berger L., \\emph{Repr\u00e9sentations p-adiques et\r\n\u00e9quations diff\u00e9rentielles}, Invent. Math. 148 (2002), no. 2, 219-{}-284.\r\n\r\n\\bibitem[Be13]{Be13}Berger L., \\emph{Multivariable Lubin-Tate $\\left(\\varphi,\\Gamma\\right)$-modules\r\nand filtered $\\varphi$-modules}, Math. Res. Lett. 20 (2013), no.\r\n3, 409-{}-428.\r\n\r\n\\bibitem[Be16]{Be16}Berger L., \\emph{Multivariable $(\\varphi,\\Gamma)$-modules\r\nand locally analytic vectors}, Duke Math. J. 165 (2016), no. 18, 3567-{}-3595.\r\n\r\n\\bibitem[BC08]{BC08}Berger L., Colmez P., \\emph{Familles de repr\u00e9sentations\r\nde de Rham et monodromie $p$-adique}, Ast\u00e9risque No. 319 (2008),\r\n303-{}-337.\r\n\r\n\\bibitem[BC16]{BC16}Berger L., Colmez P., \\emph{Th\u00e9orie de Sen et\r\nvecteurs localement analytiques}, Ann. Sci. \u00c9cole Norm. Sup. 49 (2016),\r\nno. 4, 947-{}-970.\r\n\r\n\\bibitem[Bi16]{Bi16}Bijakowski S., \\emph{Arithmetique p-adique des\r\nformes de Hilbert}, Asterisque 382 (2016), 49-71.\r\n\r\n\\bibitem[Br10]{Br10}Breuil C., \\emph{Conjectures de classicit\u00e9 sur\r\nles formes de Hilbert surconvergentes de pente finie}, unpublished\r\nnote.\r\n\r\n\\bibitem[Ch08]{Ch08}Chenevier G., \\emph{Quelques courbes de Hecke\r\nse plongent dans l\\textquoteright espace de Colmez}, J. Number Theory\r\n128 (2008), no. 8, p. 2430\\textendash 2449.\r\n\r\n\\bibitem[CC98]{CC98} Cherbonnier F., Colmez P., \\emph{Repr\u00e9sentations\r\np-adiques surconvergentes}, Invent. Math. 133 (1998), no. 3, p. 581\\textendash 611.\r\n\r\n\\bibitem[Co97]{Co97}Coleman, R. Classical and overconvergent modular\r\nforms of higher level. J. Th\u00e9or. Nombres Bordx. 9 (1997), 395\\textendash 403.\r\n\r\n\\bibitem[Co02]{Co02}Colmez P., \\emph{Espaces de Banach de dimension\r\nfinie}, J. Inst. Math. Jussieu 1 (2002), no. 3, p. 331\\textendash 439.\r\n\r\n\\bibitem[Co08]{Co08}Colmez P., \\emph{Repr\u00e9sentations triangulines\r\nde dimension 2}, Ast\u00e9risque (2008), no. 319, p. 213\\textendash 258.\r\n\r\n\\bibitem[Co10]{Co10}Colmez P., \\emph{La s\u00e9rie principale unitaire\r\nde $\\GL_{2}(\\Q_{p})$}, Ast\u00e9risque (2010), no. 330, p. 213\\textendash{}\r\n262. \r\n\r\n\\bibitem[Di17]{Di17}Ding, Yiwen. $\\mathcal{L}$-\\emph{invariants,\r\npartially de Rham families, and local-global compatibility.} Annales\r\nde l'Institut Fourier, Volume 67 (2017) no. 4, pp. 1457-1519.\r\n\r\n\\bibitem[dS16]{dS16}de Shalit E., \\emph{Mahler bases and elementary\r\n$p$-adic analysis}, J. de Theorie de Nombres Bordeaux, vol. 28 (2016),\r\n597-620.\r\n\r\n\\bibitem[Em11]{Em11}Emerton M., \\emph{Local-global compatibility\r\nin the $p$-adic Langlands programme for $\\GL_{2/\\Q}$}, preprint\r\n2011.\r\n\r\n\\bibitem[Fo09]{Fo09}Fourquaux L., \\emph{Applications $\\Q_{p}$-lin\u00e9aires,\r\ncontinues et Galois-\u00e9quivariantes de $\\C_{p}$ dans lui-m\u00eame}, J.\r\nNumber Theory 129 (2009), no. 6, p. 1246\\textendash 1255.\r\n\r\n\\bibitem[FX13]{FX13}Fourquaux L., Xie B., \\emph{Triangulable $\\mathcal{O}_{F}$\r\n-analytic $\\left(\\varphi_{q},\\Gamma\\right)$-modules of rank $2$},\r\nAlgebra Number Theory 7 (2013), no. 10, p. 2545\\textendash 2592.\r\n\r\n\\bibitem[Ki03]{Ki03}Kisin M., \\emph{Overconvergent modular forms\r\nand the Fontaine-Mazur conjecture}, Invent. Math. 153 (2003), no.\r\n2, p. 373\\textendash 454.\r\n\r\n\\bibitem[KR09]{KR09}Kisin M., Ren W., \\emph{Galois Representations\r\nand Lubin-Tate Groups}. Documenta Mathematica 14 (2009) 441-461.\r\n\r\n\\bibitem[KPX14]{KPX14} Kedlaya K., Pottharst J., Xiao L., \\emph{Cohomology\r\nof arithmetic families of $\\left(\\varphi,\\Gamma\\right)$-modules},\r\nJournal of the American Mathematical Society Vol. 27, No. 4 (2014),\r\npp. 1043-1115.\r\n\r\n\\bibitem[Li12]{Li12}Liu R., \\emph{Triangulation of refined families}.\r\nCommentarii Mathematici Helvetici 90 (2012): 831-904.\r\n\r\n\\bibitem[MS15]{MS15}Moy R., Spencer J., \\emph{There Exist Non-CM\r\nHilbert Modular Forms of Partial Weight 1}. International Mathematics\r\nResearch Notices, vol. 2015, no. 24, pp. 13047-13061\r\n\r\n\\bibitem[Na09]{Na09}Nakamura K., \\emph{Classification of two-dimensional\r\nsplit trianguline representations of $p$-adic field}. Compos. Math.\r\n145, 2009, no. 4, 865-914.\r\n\r\n\\bibitem[Ne15]{Ne15}Newton J., \\emph{Towards local-global compatibility\r\nfor Hilbert modular forms of low weight}. Algebra Number Theory 9\r\n(2015), no. 4, 957-{}-980.\r\n\r\n\\bibitem[Sa09]{Sa09}Saito T., \\emph{Hilbert modular forms and $p$-adic\r\nHodge theory}. Compositio Mathematica 145, (2009) 1081-1113.\r\n\\end{thebibliography}\r\n\r\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:03:07", "yymm": "2010", "arxiv_id": "2010.14574", "url": "https://arxiv.org/abs/2010.14574", "source": "arxiv"}}
{"text": "\\documentclass[12pt]{article}\n\\usepackage{hyperref}\n\\usepackage{framed}\n\\usepackage{graphicx}\n\\usepackage{color}\n\\usepackage{subfig}\n\\usepackage{appendix}\n\\usepackage{amsmath}\n\\usepackage{amssymb,amsfonts}\n\\usepackage[utf8]{inputenc}\n%\\usepackage[T1]{fontenc}\n%\\usepackage{polski}\n\n\\addtolength{\\oddsidemargin}{-.875in}\n\\addtolength{\\evensidemargin}{-.875in}\n\\addtolength{\\textwidth}{1.75in}\n\n\\addtolength{\\topmargin}{-.875in}\n\\addtolength{\\textheight}{1.75in}\n\n\\newcommand{\\tr}{\\mbox{$\\mathrm{tr}$}}\n\\newcommand{\\bra}[1]{\\ensuremath{\\langle #1 |}}\n\\newcommand{\\ket}[1]{\\ensuremath{| #1\\rangle}}\n\\newcommand{\\bbra}[1]{\\ensuremath{\\langle #1 ||}}\n\\newcommand{\\kket}[1]{\\ensuremath{|| #1\\rangle}}  \n\\newcommand{\\bk}[2]{\\ensuremath{\\langle #1 | #2\\rangle}}\n\\newcommand{\\kb}[2]{\\ensuremath{| #1\\rangle\\!\\langle #2 |}}\n\\newcommand{\\kbb}[2]{\\ensuremath{|| #1\\rangle\\!\\langle #2 ||}}\n\\newcommand{\\brk}[2]{\\ensuremath{( #1 | #2)}}\n\n%opening\n\\title{Quantum chaos in the spin coherent state representation}\n\\author{  Robert Przybycie\\'n\\footnote{email: wprzybycien@cft.edu.pl}   \\hskip 5pt and Marek Ku\\'s\\footnote{email: marek.kus@cft.edu.pl} \\\\\n\\textit{Center for Theoretical Physics, Polish Academy of Sciences} \\\\ \n\\textit{Al. Lotnik\\'ow 32/46, 02-668 Warszawa, Poland}}\n\n\\begin{document}\n%\\renewcommand{\\figurename}{Fig.}\n\n\\maketitle\n\n\\begin{abstract}\nWe use spin coherent states to compare classical and quantum evolution of a simple paradigmatic, discrete-time quantum dynamical system exhibiting chaotic behavior in the classical limit. The spin coherent states are employed to define a phase-space quasidistribution for quantum states ($P$-representation). It can be, in principle, used for a direct comparison of the quantum and classical dynamics, where on the classical level one deals with the classical distribution function on the classical phase space. In the paper, we presented a different way by comparing evolution of appropriately defined moments of classical and quantum distributions, in particular the one-step propagators of the moments.      \n\\end{abstract}\n\\section{Introduction}\nHarmonic oscillator coherent states were introduced in 1926 by Schr\\\"odinger in the context of transition from quantum to classical physics \\cite{schroedinger26}. After more than three decades they were rediscovered by John Klauder who used them to represent the Feynman path propagator as an introductory example to his treatment of Feynman quantization of fermionic fields \\cite{klauder60} and later, again to compare classical and quantum dynamics \\cite{klauder63,klauder63a}. They came to real prominence with seminal papers by Roy Glauber\\footnote{who, actually, seems to introduced the name ``coherent states''} in early sixties of the past century, devoted to cornerstones of the laser theory and modern quantum optics in general, namely photon correlations \\cite{glauber63a} and coherence of light \\cite{glauber63,glauber63b}.  One of the remarkable outputs of the theory of coherent states was a possibility to give a ``phase-space'' description to quantum phenomena in terms of quasi-probability distributions, playing role analogous to ordinary probability distributions in classical statistical physics. The main difference is that the so-called Glauber-Sudarshan $P$ representation \\cite{sudarshan63,glauber63a} need not to be positive. \n\nHarmonic oscillator (also called canonical) coherent states have several important properties\n\\begin{enumerate}\n\t\\item they are eigenstates of the annihilation operator\n\t\\item they minimize the uncertainty relations\n\t\\item they form a particular orbit of a group (in this case, the Heisenberg group)\n\t\\item they form a continuous overcomplete family of states\n \\end{enumerate}\nTo generalize the concept of a coherent state one can follow directions preserving one or more of the above enumerated properties. Since, in general, it not possible to keep them all in a reasonable way, several kinds of generalized coherent states were proposed \\cite{klauder85}. As it should be clear, one of the dominant motivation to use the coherent state representation was to investigate quantum-classical correspondence or, more generally, quantum-classical transition. From this point of view minimizing the uncertainty relations, or, more generally, being the ``closest to classical'' \\cite{perelomov12} seems to be most relevant. In our investigations concerning classical-quantum correspondence for a model chaotic system we put, however, more emphasis on comparison of quantum and classical phase-space representation  via an adapted $P$-representation, although minimizing the uncertainty, in a certain sense \\cite{delbourgo77,delbourgo77a}, will be preserved by the states used to construct the phase-space density $P$.\n\nThe kicked top is a paradigmatic and astonishingly simple model used in the past to investigate various aspects of quantum systems exhibiting chaos on the classical level \\cite{haake87,haake19}. Its Hamiltonian is constructed from the angular momentum operators, hence the relevant generalized coherent states are the so-called \\textit{coherent spin states}. They were introduced by Radcliffe \\cite{radcliffe71} and, under the name of ``atomic coherent states'' by Arecchi \\textit{et al.}  \\cite{arecchi72}, although a general idea can be traced to the cited paper of Klauder \\cite{klauder60}.  Coherent spin states can be treated as a particular orbit of $SU(2)$ group generalizing thus the property 3.\\ of the canonical coherent states. In fact, this construction can be extended to other groups as presented independently by Perelomov \\cite{perelomov72} and Gilmore \\cite{gilmore72}. Again, the Gilmore-Perelomov coherent states are useful in investigations of classical-quantum transition for chaotic systems\\cite{gk98,ghk00} where an ambiguity of the classical limit was exhibited in the $SU(3)$ case.\n\nIn 1976 Glauber and Haake \\cite{glauber76} applied atomic coherent states and the ensuing phase-space representation to a concrete and at that time acute and intensively investigated problem of fluctuation in superradiant pulses emitted by systems of many atoms. The techniques developed in this paper we will use in the following.            \n\n\\section{Angular momentum coherent states}\n\n\nLet us start with a short description of construction and properties of spin coherent states. The details can be found in the cited literature; here we give only the relevant formulas accompanied by sketches of reasonings that lead to them. \n\nAs already mentioned in the Introduction, spin coherent states are an particular instance of the general construction, valid, in principle, for arbitrary Lie group. Here the underlying group is $SU(2)$ with its Lie algebra spanned by the angular momentum operators $J_x,J_y,J_z$ fulfilling the well know commutation relations $[J_x,J_y]=iJ_z$ etc.  \n\nTo define coherent states let's consider the irreducible, unitary, spin $j$ representation $\\pi$ of $SU(2)$\\footnote{in the following, it if does not lead to confusion, we will use the same notation for  $U$ and $\\pi(U)$ for $U\\in SU(3)$, remembering, however, that $U$ is the $N\\times N$ representative of a corresponding $SU(3)$ element. The same applies to the elements of the corresponding Lie algebra and its representation induced by $\\pi$} It is given in terms of unitary $(N\\times N$, $N=2j+1)$ unitary matrices acting in an $n$ dimensional complex linear space which is the Hilbert space of the quantum system in question. The set of coherent states is now defined as an orbit $\\left\\{\\psi:\\psi=\\pi(U), U\\in SU(2)\\right\\}$ of the group through the highest-weight vector $\\ket{j,j}$, defined \\textit{via} $J_z\\ket{j,j}=j\\ket{j,j}$. The highest-weight state $\\ket{j,j}$ is annihilated by the the rising operator $J_+\\ket{j,j}=0$. \n\nAs we know, it is easier to work with the complexification of $SU(2)$, i.e the complex group $SL(2)$ and its algebra spanned by $J_z$ and $J_\\pm=J_x\\pm iJy$\n\\begin{equation}\\label{Jcom}\n\\left[J_z,J_\\pm\\right]=J_\\pm, \\quad \\left[J_+,J_-\\right]=2J_z\n\\end{equation} \nThe $SU(2)$ group can be parameterized by two angles $\\theta$ and $\\phi$ in terms of which a group element reads \n\\begin{equation}\\label{U}\nU(\\theta, \\phi)=\\exp\\left(i\\theta(J_x\\sin\\phi-J_y\\cos\\phi)\\right)=\\exp(\\gamma J_-)\\exp(-J_z\\log(1+\\gamma\\gamma^\\ast))\\exp(-\\gamma^\\ast J_+):=U(\\gamma),\n\\end{equation} \nwhere $\\gamma=e^{i\\phi}\\tan\\frac{\\theta}{2}$. Thus coherent states are parameterized by a complex number $\\gamma$\n\\begin{equation}\\label{cohstate}\n\\ket{\\gamma}=U(\\gamma)\\ket{j,j}.\t\n\\end{equation}\nUsing (\\ref{U}) and the fact that $\\ket{j,j}$ is an eigenvector of $J_z$ we obtain, explicitly,\n\\begin{equation}\n\\ket{\\gamma}=\\frac{1}{(1+\\gamma\\gamma^\\ast)^j}\\,e^{\\gamma J_-}\\ket{j,j}\n\\end{equation}\nOne can easily find that the coherent-state expectation values of the angular momentum operators read as,\n\\begin{equation}\n\\left\\langle {J_+}\\right\\rangle =\\frac{2\\gamma}{1+\\gamma\\gamma^\\ast}=\\left\\langle {J_+}\\right\\rangle^\\ast, \\quad \\left\\langle {J_z}\\right\\rangle=\\frac{1-\\gamma\\gamma^\\ast}{1+\\gamma\\gamma^\\ast} \n\\end{equation} \n\nIf the state $\\ket{j.j}$ is normalized (what we assume), so is $\\ket{\\gamma}$ obtained by a unitary transformation. As observed by Glauber and Haake \\cite{glauber76} it is easier to work with the normalizing factor $(1+\\gamma\\gamma^*)^{-j}$ skipped\\footnote{This ingenious albeit simple trick has a deeper meaning. The newly defined unnormalized states are holomorphic functions of the complex variable $\\gamma$, or, in practical terms they do not depend on $\\gamma^*$}, defining\n\\begin{equation}\\label{ucohstate}\n|\\ket{\\gamma}=e^{\\gamma J_-}\\ket{j,j}.\n\\end{equation}  \nThe next step is an observation that the action of the angular momentum operators \n$J_\\pm$ and $J_z$ on $|\\ket{\\gamma}$ can be expressed in form of first order differential operators. The simples case is that of $J_-$\n\\begin{equation}\\label{Jmgamma}\nJ_-|\\ket{\\gamma}=J_-e^{\\gamma J_-}\\ket{j,j}=\\frac{\\partial}{\\partial\\gamma}e^{\\gamma J_-}\\ket{j,j}=\\frac{\\partial}{\\partial\\gamma}|\\ket{\\gamma}.\n\\end{equation} \nusing the following formulas, both stemming directly from the commutation relations (\\ref{Jcom}),\n\\begin{equation}\\label{ser}\ne^{-\\gamma J_-}J_+\\;e^{\\gamma J_-}=J_++2\\gamma J_z-\\gamma^2 J_-, \\quad\ne^{-\\gamma J_-}J_z\\;e^{\\gamma J_-}=J_z-\\gamma J_-\\,,\n\\end{equation} \nwe get\n\\begin{equation}\\label{Jpgamma}\nJ_+|\\ket{\\gamma}\n=J_+e^{\\gamma J_-}\\ket{j,j}\n=e^{\\gamma J_-}\\left(J_++2\\gamma J_z-\\gamma^2 J_-\\right)\\ket{j,j}\n=\\left(2j\\gamma-\\gamma^2\\right)e^{\\gamma J_-}\\ket{j,j}\n=\\left(2j\\gamma-\\gamma^2\\frac{\\partial}{\\partial\\gamma}\\right) |\\ket{\\gamma}\n\\end{equation}\nand\n\\begin{equation}\\label{Jzgamma}\nJ_z|\\ket{\\gamma}\n=J_+e^{\\gamma J_z}\\ket{j,j}\n=e^{\\gamma J_-}\\left(J_z-\\gamma J_-\\right)\\ket{j,j}\n=\\left(j-\\gamma J_-\\right)e^{\\gamma J_-}\\ket{j,j}\n=\\left( j-\\gamma\\frac{\\partial}{\\partial\\gamma}\\right)|\\ket{\\gamma}, \n\\end{equation}\nwhere we again used the fact that $\\ket{j,j}$ is an eigenstate of $J_z$ annihilated by $J_+$.\n\nIn the following we will need also formulas for the right actions of $J_\\pm$ and $J_z$ on the form $\\bra{\\gamma}|$. Let us start from the above derived formulas involving differential operators in the form $J_A|\\ket{\\gamma}=D_{J_A}(\\gamma)|\\ket{\\gamma}$, where $A=\\pm,z$. We have\n\\begin{equation}\\label{bras}\n\\bra{\\gamma}|J_A=\\left(J_A^\\dagger|\\ket{\\gamma}\\right)^\\dagger=\\left(D^{J_A^\\dagger}|\\ket{\\gamma}\\right)^\\dagger={D_{J_A^\\dag}^\\ast}\\bra{\\gamma}|,\n\\end{equation}  \nwhere the asterix denotes the complex conjugation of variables and derivations,  $\\gamma\\rightarrow\\gamma^\\ast$,  $\\partial/\\partial\\gamma\\rightarrow\\partial/\\partial\\gamma^\\ast$.\nExplicitly:\n\\begin{equation}\\label{bras1}\n\\bra{\\gamma}|J_-=\\left(2j\\gamma^\\ast-\\gamma^{\\ast 2}\\frac{\\partial}{\\partial\\gamma^\\ast}\\right)\\bra{\\gamma}|, \\quad \\bra{\\gamma}|J_z=\\left(j-\\gamma^\\ast\\frac{\\partial}{\\partial\\gamma^\\ast}\\right)\\bra{\\gamma}|, \\quad\n\\bra{\\gamma}|J_+=\\frac{\\partial}{\\partial\\gamma^\\ast}\\bra{\\gamma}|.\n\\end{equation}\nFinally for actions of product of operators we have\n\\begin{equation}\\label{prod}\nJ_A J_B |\\ket{\\gamma} = J_A D_{J_B}|\\ket{\\gamma}  = D_{J_B}J_A|\\ket{\\gamma} = D_{J_B}D_{J_A}|\\ket{\\gamma}, \n\\end{equation}\nsince $J_A$, $J_B$ do not depend on $\\gamma$. Observe the inverted order of operators $D_{J_A}$ and $D_{J_A}$. \n\n\\subsection{$P$-representation }\nCoherent states for a continuous (and consequently, overcomplete) family of states in $2j+1$-dimensional Hilbert space of a spin $j$ system. The (over)completeness means that the following resolution of identity holds,\n\\begin{equation}\\label{overcompletness}\nI=\\int \\frac{d^2\\gamma}{ {(1+\\gamma\\gamma^\\ast)^2}}\\kb{\\gamma}{\\gamma}, \\quad d^2\\gamma=\n \\frac{2j+1}{\\pi}d\\,\\mathrm{Re}\\gamma\\; d\\,\\mathrm{Im}\\gamma . \n\\end{equation} \nDue to the overcompleteness, a density matrix can be written in terms of projectors on coherent states (``diagonal operators'') \n\\begin{equation}\n\\rho(t)=\\int \\frac{d^2\\gamma}{ {(1+\\gamma\\gamma^\\ast)^2}} P(\\gamma,\\gamma^\\ast,t)\\kb{\\gamma}{\\gamma},\n\\end{equation}\nwith a time dependent weight function $P$ (Glauber-Sudarshan $P$-representation of $\\rho$). Knowing $P$ we can calculate the time evolution of an arbitrary operator. If $\\ket{m}$ is an arbitrary orthonormal basis (e.g. the usual basis of eigenvectors of $J_z$ ), thus $\\sum_m\\kb{m}{m}=I$ then, \n \n\\begin{eqnarray}\\label{average}\n\\nonumber\n\\left\\langle A \\right\\rangle &=& \\tr(\\rho A) \n=\\sum_m\\bra{m}\\int d^2\\gamma (1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\\kb{\\gamma}{\\gamma}A\\ket{m} \\\\ \n&=&\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\\sum_m\\bk{m}{\\gamma}\n\\bra{\\gamma}A\\ket{m} \\nonumber \\\\\n&=&\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\\sum_m\n\\bra{\\gamma}A\\ket{m}\\bk{m}{\\gamma}=\n\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\n\\bra{\\gamma}A\\sum_m\\ket{m}\\bk{m}{\\gamma} \\nonumber \\\\\n&=&\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\n\\bra{\\gamma}A\\ket{\\gamma}=\\int d^2\\gamma\n P(\\gamma,\\gamma^\\ast,t)(1+\\gamma\\gamma^\\ast)^{-2(j+1)}\n\\bra{\\gamma}|A|\\ket{\\gamma}. \n\\end{eqnarray}\n  \nThe density matrix $\\rho(t)$ is a solution of the von Neumann equation\n\\begin{equation}\\label{vN}\ni\\hbar\\frac{\\partial\\rho}{\\partial t}=\\left[H,\\rho \\right], \n\\end{equation}\nwhere $H$ is the Hamiltonian of the system. Eq.(\\ref{vN}) translates to an equation for $P$\n\\begin{equation}\\label{vNP} \ni\\hbar\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} \\frac{\\partial P(\\gamma,\\gamma^\\ast,t)}{\\partial t}\\kb{\\gamma}{\\gamma}=\\int d^2\\gamma(1+\\gamma\\gamma^\\ast)^{-2} P(\\gamma,\\gamma^\\ast,t)\\left(H\\kb{\\gamma}{\\gamma}-\\kb{\\gamma}{\\gamma}H\\right),\n\\end{equation}  \nor, in terms of unnormalized states $|\\ket{\\gamma}$,\n\\begin{equation}\\label{vNPu} \ni\\hbar\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)} \\frac{\\partial P(\\gamma,\\gamma^\\ast,t)}{\\partial t}|\\kb{\\gamma}{\\gamma}|\n=\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)} P(\\gamma,\\gamma^\\ast,t)\\Big[H,|\\kb{\\gamma}{\\gamma}|\\Big]\n\\end{equation}\n\n\n\n\\section{Kicked top}\n\nThe kicked-top model, introduced in \\cite{haake87}, is a simple, paradigmatic model of a spin system, exhibiting rich chaotic behavior on the classical level and perfectly conforming to various quantum-mechanical criteria of chaos, in particular those that are based on statistical properties of spectra and eigenfunctions (for details consult\\cite{haake87}, \\cite{kus93} and \\cite{haake19}). It can be also realized experimentally in a trapped cold atom system \\cite{chaudhury09}.\n\nThe evolution of the kicked top is periodic and consist of two pieces, a free rotation around one axis followed by a nonlinear kick i.e instantaneous nonlinear rotation around a perpendicular axis. Explicitly, the Hamiltonian of the kicked top reads\n\\begin{equation}\\label{kichedtop}\nH = \\frac{{\\hbar p}}{T}J_y  + \\frac{{\\hbar k}}{{2j}}J_z^2 \\sum\\limits_{n =  - \\infty }^\\infty  {\\delta \\left( {t - nT} \\right)}, \n\\end{equation}    \nwhere $T$ is the period and $2j$ is the (conserved) total angular momentum (spin). In the following we will put $\\hbar=1$.\n\nDue to the kicked character of the second part of the evolution, it is easy to find the propagator over the period $T$\n\\begin{equation}\\label{topropagator}\nU=\\exp\\left(-i\\frac{k}{2j}J_z^2\\right)\\,\\exp(-ip J_y)\n\\end{equation} \n\nIn the following we will put $p=\\pi/2$. Such a choice simplifies the calculations. It introduces an additional symmetry which, however, is not relevant for the whole reasoning we present. \n\nObserve, that at this point, the kicked character of the evolution becomes irrelevant. We may look at (\\ref{topropagator}) as a propagator describing combined evolution again consisting of two pieces, e.g. one described by the Hamiltonian $H_1:=\\omega J_z$ with the duration of $t=p/\\omega$ and the second with the Hamiltonian $H_2=k/2j$ acting during the time $t=1$.\n\nThe Heisenberg-picture time evolution of the angular momentum operators over one period of the evolution is given for by $J_{x,y,z}^{\\prime \\prime}=U^\\dagger J_{x,y,z}U$. After short calculations, we get for $p=\\pi/2$ \\cite{haake87}\n\\begin{align}\nJ_x ^{\\prime \\prime }  &= \\frac{1}{2}\\left( {J_x  + iJ_y } \\right)e^{ - i\\frac{k}{j}\\left( {J_x  - \\frac{1}{2}} \\right)}+h.c. \\label{heisenberg1} \\\\ \nJ_y ^{\\prime \\prime }  &= \\frac{1}{{2i}}\\left( {J_x  + iJ_y } \\right)e^{ - i\\frac{k}{j}\\left( {J_x  - \\frac{1}{2}} \\right)}+h.c. \\label{heisenberg2} \\\\\nJ_z^{\\prime\\prime}&=-J_x \\label{heisenberg3}\n\\end{align}\n\n\n\\subsection{Quantum evolution. Coherent states representation}\n\n\\subsubsection{Free rotation}\n\nThe first part of the evolution, i.e. the free rotation around the $y$-axis with the Hamiltonian $H=\\omega J_y$\nFrom (\\ref{Jmgamma}), (\\ref{Jpgamma}), and (\\ref{bras1}) we get,\n\\begin{equation}\n\\Big[J_y,\\kbb{\\gamma}{\\gamma}\\Big]=\\frac{1}{2i}\\Big[J_+-J_-,\\,\\kbb{\\gamma}{\\gamma}\\Big]\n=\\frac{1}{2i}\\left(\n2j\\gamma  - \\left( {1 + \\gamma ^2 } \\right)\\frac{\\partial }{{\\partial \\gamma }} + 2j\\gamma ^*  - \\left( {1 + \\gamma ^{*2} } \\right)\\frac{\\partial }{{\\partial \\gamma ^* }}\n\\right)\\kbb{\\gamma}{\\gamma}.\n\\end{equation} \nHence, from (\\ref{vNPu})\n\\begin{align*}\n&\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)}\\frac{\\partial P}{\\partial t}\\kbb{\\gamma}{\\gamma}=\n\\\\\n&\\frac{\\omega}{2}\n\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)}P(\\gamma,\\gamma^*,t)\\Bigg(\\frac{\\partial}{\\partial \\gamma^*}-2j\\gamma+\\gamma^2\\frac{\\partial}{\\partial\\gamma}+\\frac{\\partial}{\\partial\\gamma}-2j\\gamma^*+\\gamma^{*2}\\frac{\\partial}{\\partial \\gamma^*}\\Bigg)\\kbb{\\gamma}{\\gamma}.\n\\end{align*}\nIntegrating by parts the right-hand-side we get,\n\\begin{align*}\n\\int d^2\\gamma &(1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\\frac{\\partial P}{\\partial t}= \\\\\n&-\\frac{\\omega}{2}\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\n\\Bigg(\\left(1+\\gamma^2\\right)\n\\frac{\\partial}{\\partial\\gamma}+\\left(1+\\gamma^{*2}\\right)\n\\frac{\\partial}{\\partial\\gamma^{*}}\\Bigg)P,\n\\end{align*}\nwhich gives an equation for $P$\n\\begin{equation}\\label{Prot}\n\\frac{\\partial P}{\\partial t}=-\\frac{\\omega}{2}\\left(1+\\gamma^2\\right)\n\\frac{\\partial P}{\\partial\\gamma}-\\frac{\\omega}{2}\\left(1+\\gamma^{*2}\\right)\n\\frac{\\partial P}{\\partial\\gamma^{*}}.\n\\end{equation}\nThis first order, linear, partial differential equation can be easily solved by the standard method of characteristics,\n\\begin{equation}\nP(\\gamma,\\gamma^{*},t)=P\\left(\\frac{\\gamma\\cos\\frac{\\omega t}{2}-\\sin\n\t\\frac{\\omega t}{2}}{\\cos\\frac{\\omega t}{2}+\\gamma\\sin\\frac{\\omega t}{2}},\n\\frac{\\gamma^{*}\\cos\\frac{\\omega t}{2}-\\sin\\frac{\\omega t}{2}}{\\cos\n\t\\frac{\\omega t}{2}+\\gamma^{*}\\sin\\frac{\\omega t}{2}},0\\right).\n\\end{equation}\nHence for $\\omega t=\\pi/2$ we obtain\nfor $P^\\prime\\left(\\gamma,\\gamma^{*}\\right):=\nP\\left(\\gamma,\\gamma^{*},\\pi/2\\omega\\right)$ with  $P\\left(\\gamma,\\gamma^{*}\\right):=\nP\\left(\\gamma,\\gamma^{*},0\\right)$\n\\begin{equation}\\label{Protint}\nP^\\prime\\left(\\gamma,\\gamma^{*}\\right)=P\\left(\\frac{\\gamma -1}{\\gamma +1},\\frac{\\gamma^{*}-1}{\\gamma^{*}+1}\\right).\n\\end{equation}\nFor the average of an arbitrary function $f(\\gamma,\\gamma^*)$ we have,\n\\begin{equation}\n\\left\\langle f(\\gamma,\\gamma^{*})\\right\\rangle^\\prime=\\int\nd^2\\gamma(1+\\gamma\\gamma^*)^{-2} P^\\prime(\\gamma,\\gamma^{*})f(\\gamma,\\gamma^{*})=\\int\nd^2\\gamma(1+\\gamma\\gamma^*)^{-2} P\\left(\\frac{\\gamma\n\t-1}{\\gamma +1},\n\\frac{\\gamma^{*}-1}{\\gamma^{*}+1}\\right)f(\\gamma,\\gamma^{*}),\n\\end{equation}\nwhere primed quantities are calculated for $\\omega t=\\pi/2$.\nChanging the variables\n\\begin{equation}\n\\eta=\\frac{\\gamma -1}{\\gamma +1},\\quad\\eta^{*}=\\frac{\\gamma^{*}-1}\n{\\gamma^{*}+1},\\quad d^2\\gamma=\\frac{4d^2\\eta}{{(1-\\eta)}^2{(1-\\eta^{*})}^2},\n\\end{equation}\nwe obtain finally\n\\begin{equation}\\label{rotaver}\n\\left\\langle f(\\gamma,\\gamma^{*})\\right\\rangle^\\prime=\\int d^2\\eta(1+\\eta\\eta^*)^{-2}\nf\\left(\\frac{1+\\eta}{1-\\eta},\\frac{1+\\eta^{*}}{1-\\eta^{*}}\\right)\nP(\\eta,\\eta^{*})=\\left\\langle f\\left(\\frac{1+\\gamma}{1-\\gamma},\n\\frac{1+\\gamma^{*}}{1-\\gamma^{*}}\\right)\\right\\rangle.\n\\end{equation}\n  \n\\subsubsection{Kick}\nThe Hamiltonian of the kicked evolution reads $H=\\frac{k}{2j}J_z^2$. As already announced we will derive an equation for the continuous-time evolution of $P$ and then integrate it over the unit time to obtain the propagator for the kicked part of the whole evolution. Using  (\\ref{Jzgamma}), (\\ref{bras1}), and (\\ref{prod}) we obtain for the commutator,\n \\begin{equation}\n\\Big[J_z^2,\\kbb{\\gamma}{\\gamma}\\Big]\n=\\Bigg(\\left(1-2j\\right)\\left(\\gamma\\frac{\\partial}{\\partial\\gamma}-\\gamma^\\ast\\frac{\\partial}{\\partial\\gamma^\\ast}\\right)+\\gamma^2\\frac{\\partial^2}{\\partial\\gamma^2}-\\gamma^{\\ast 2}\\frac{\\partial^2}{\\partial\\gamma^{\\ast 2}}\\Bigg)\\kbb{\\gamma}{\\gamma},\n \\end{equation} \nhence, the equation for $P$ reads\n \n\\begin{align*}\n\\int d^2\\gamma &(1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\\frac{\\partial P}{\\partial t}= \\\\\n&-\\frac{ik}{2j}\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\n\\Bigg(\\left(1-2j\\right)\\left(\\gamma\\frac{\\partial}{\\partial\\gamma}-\\gamma^\\ast\\frac{\\partial}{\\partial\\gamma^\\ast}\\right)+\\gamma^2\\frac{\\partial^2}{\\partial\\gamma^2}-\\gamma^{\\ast 2}\\frac{\\partial^2}{\\partial\\gamma^{\\ast 2}}\\Bigg)\\kbb{\\gamma}{\\gamma}.\n\\end{align*}\n  \nIntegration by parts of the right-hand side gives,\n \n{\\small\n\\begin{align*}\n\\int d^2\\gamma &(1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\\frac{\\partial P}{\\partial t}= \\\\ \n&-\\frac{ik}{2j}\\int d^2\\gamma (1+\\gamma\\gamma^*)^{-2(j+1)}\\kbb{\\gamma}{\\gamma}\\left(\\left(-(2j+1)+\\frac{4(j+1)}{1+\\gamma\\gamma^{\\ast}}\\right)\\left(\\gamma\\frac{\\partial}\n{\\partial\\gamma}-\\gamma^{*}\\frac{\\partial}{\\partial\\gamma^{*}}\\right)\n+\\left(\\gamma^2\\frac{\\partial}{\\partial\\gamma^2}-\n\\gamma^{\\ast 2}\\frac{\\partial^2}{\\partial\\gamma^{\\ast 2}}\\right)\\right)P. \n\\end{align*}\n}\n  \nHence, finally\n \n\\begin{equation}\\label{Pkick}\n\\frac{\\partial P}{\\partial(ikt)}=-\\frac{1}{2j}\\left[\\left(-(2j+1)+\\frac{4(j+1)}{1+\\gamma\\gamma^{\\ast}}\\right)\\left(\\gamma\\frac{\\partial}\n{\\partial\\gamma}-\\gamma^{\\ast}\\frac{\\partial}{\\partial\\gamma^{\\ast}}\\right)\n+\\left(\\gamma^2\\frac{\\partial}{\\partial\\gamma^2}-\n\\gamma^{\\ast 2}\\frac{\\partial^2}{\\partial\\gamma^{\\ast 2}}\\right)\\right]P=:LP\n\\end{equation}\n  \nThe second order partial differential operator $L$ defined above has variable coefficients and it is hard to expect that we can find a closed formula for $P$. Fortunately, we are interested not in $P$ itself but rather in the evolution of expectation values\n \n\\[\n\\frac{\\partial}{\\partial(ikt)}\\left\\langle f\\right\\rangle \n=\\frac{\\partial}{\\partial(ikt)}\\int \\frac{d^2\\gamma}{(1+\\gamma\\gamma^*)^{2}}f\\, P\n=\\int \\frac{d^2\\gamma}{(1+\\gamma\\gamma^*)^{2}} f\\,\\frac{\\partial P}{\\partial(ikt)}\n\\]\n\\begin{equation}\n=\\int \\frac{d^2\\gamma}{(1+\\gamma\\gamma^*)^{2}} f\\,LP\n=\\int \\frac{d^2\\gamma}{(1+\\gamma\\gamma^*)^{2}} P\\,L^\\dagger f=\\left\\langle L^\\dagger f\\right\\rangle =L^\\dagger\\left\\langle f\\right\\rangle.\n\\end{equation}\n  \n%Finally thus\n%\\begin{equation}\n%\\frac{\\partial}{\\partial t}\\left\\langle f\\right\\rangle \n%\\end{equation}\nwhere the dual (``adjoint'') operator $L^\\dagger$ is defined by  $=\\int d^2\\gamma{(1+\\gamma\\gamma^*)^{-2}} P\\,L^\\dagger f=\\int d^2\\gamma{(1+\\gamma\\gamma^*)^{-2}} f\\,LP $.   \nSubstituting to this equality $L$ given by (\\ref{Prot}) and integrating by parts we find\n \n\\begin{equation}\\label{Ladjoint}\nL^\\dagger\n= \\frac{1}{2j}\\left[\\left(2j+1-\\frac{4j}{1+\\gamma\\gamma^{\\ast}}\\right) \n\\left(\\gamma\\frac{\\partial}{\\partial\\gamma}\n-\\gamma^{\\ast}\\frac{\\partial}{\\partial\\gamma^{\\ast}}\\right)\n+\\left(\\gamma^2\\frac{\\partial}{\\partial\\gamma^2}-\n\\gamma^{\\ast 2}\\frac{\\partial^2}{\\partial\\gamma^{\\ast 2}}\\right)\\right].\n\\end{equation}\n  \nA short calculation reveals that functions \n\\begin{equation}\\label{eigenf}\nf_{nm}(\\gamma,\\gamma^\\ast)=\\frac{\\gamma^n\\gamma^{\\ast m}}{(1+\\gamma\\gamma\\ast)^{2j}}\n\\end{equation}\nare eigenfunctions of $L^\\dagger$,\n\\begin{equation}\\label{eigenv}\nL^\\dagger f_{nm}(\\gamma,\\gamma^\\ast)=-\n\\frac{1}{2j}\\left[(j-n)^2-(j-m)^2\\right]f(\\gamma,\\gamma^\\ast)=\\frac{\\lambda_{nm}}{2j}f_{nm}(\\gamma,\\gamma^\\ast),\n\\end{equation}\nhence for $t=1$ corresponding to a single kick,\n\\begin{equation}\\label{kickaver}\n\\left\\langle f_{nm}\\right\\rangle^{\\prime\\prime}=\\exp\\left(i\\frac{k}{2j}\\lambda_{nm}\n\\right)\\left\\langle f_{nm}\\right\\rangle^\\prime=K^{Q}_{nm}\n\\langle f_{nm}\\rangle^\\prime,\n\\end{equation}\nwhere\n\\begin{equation}\\label{KQ}\nK^{Q}_{nm}=\\exp\\left(i\\frac{k}{2j}\\lambda_{nm}\n\\right)\n\\end{equation}\n\nTo find the evolution over one period consisting of the free rotation and the kick we have to combine (\\ref{rotaver}) and (\\ref{kickaver}), i., substitute to \n\\begin{eqnarray}\n\\langle f_{nm}\\rangle^{\\prime}&=&\n\\left\\langle\n\\frac{\\gamma ^n\\gamma ^{*m}}{(1+\\gamma \\gamma ^{*})^{2j}}\\right\\rangle\n^{\\prime }=\\left\\langle \\frac{\\left( \\frac{1+\\gamma }{1-\\gamma }\n\t\\right) ^n\\left( \\frac{1+\\gamma ^{*}}{1-\\gamma ^{*}}\\right) ^m}{\\left[\n\t1+\\left( \\frac{1+\\gamma }{1-\\gamma }\\right) \\left( \\frac{1+\\gamma ^{*}}{\n\t\t1-\\gamma ^{*}}\\right) \\right] ^{2j}}\\right\\rangle = \\sum\\limits_{r,s=0}^{2j}R_{nm}^{\\,rs}\\langle f_{rs} \\rangle\n\t \\nonumber \n%\\\\\n%&=&\\frac{1}{2j}\n%\\left\\langle \\frac{(1+\\gamma )^n(1+\\gamma ^{*})^m(1-\\gamma)^{2j-n}(1+\\gamma ^{*})^{2j-m}}{(1+\\gamma \\gamma ^{*})^{2j}}\\right\\rangle,\n \\label{qmap}\n\\end{eqnarray}\nwhere\n\n\\begin{equation}\\label{R}\nR_{nm}^{\\,rs}=2^{-2j}\n\\sum_{a=0}^{k}\\sum_{b=0}^{l}\n{m \\choose r}\n{n \\choose s}\n{2j-m \\choose k-r}\n{2j-n \\choose l-s} {\\left( -1\\right) }^{\\left(k+l-r-s \\right) }\n\\end{equation}\n%It is convenient to renormalize $f_{nm}$ in the following manner\n%\\begin{equation}\\label{renorm}\n%l_{nm}:=\\left[{2j\\choose n}{2j\\choose m}\\right]^{1/2}\\left\\langle\n%f_{nm}\\right\\rangle,\n%\\end{equation}\n%and rewrite (\\ref{qmap}) in the new variables. After some straightforward calculations we get\n%\\begin{equation}\n%l_{nm}^{\\prime \\prime }=\\sum\\limits_{r,s=0}^{2j}C_{nm,rs}l_{rs}.\n%\\end{equation}\n%Matrix $C$ can be written as a tensor product\n%\\begin{equation}\n%C=F\\otimes F^{\\dagger }, \\quad F=DR\n%\\end{equation}\n%with\n%\\begin{equation}\n%D_{mm^{\\prime }}=\\delta _{mm^{\\prime }}e^{-ikm^2/2j}\n%\\end{equation}\n%and $R_{mm^{\\prime }}$ is the Wigner rotation matrix\n%\\begin{equation}\n%R_{mm^{\\prime }}=d_{mm^{\\prime }}^j.\n%\\end{equation}\n%In the last two equations I changed the indices to run from $-j$ to $j$, as it is customary in calculations involving spin variables.\n\n%  Panie Robercie. Ju\u017c mi si\u0119 wydawa\u0142o, \u017ce ca\u0142e wyprowadzenie jest wyczyszczone, ale sprawdzi\u0142am dzi\u015b raz jeszcze i do tej chwili nie uda\u0142o mi si\u0119 inkorporowa\u0107 Pana oblicze\u0144, co by\u0142oby ze wszech miar po\u017c\u0105dane, bo wtedy nic nie wyskakuje jak deus ex machina. Ot\u00f3\u017c w swoich ostatnich notatkach pisze Pan na samym dole str. 1: $ \\langle f\\rangle^\\prime=\\tilde{R}\\langle f\\rangle$.  Jaki to jest iloczyn mi\u0119dzy $\\tilde{R}$ a $\\langle f\\rangle$?. Czy tu $\\langle f\\rangle$ jest ju\u017c zwektoryzowan\u0105 macierz\u0105 $\\langle f_{nm}\\rangle$? Czym jest, w takim razie $\\tilde{R}$ w stosunku do $R_{nm}^{rs}$, kt\u00f3rego u\u017cywa\u0142em powy\u017cej?}    \n\n\\subsection{Classical evolution} \n\nThe classical limit of the presented quantum kicked top model is obtained as a stroboscopic map of the unit sphere by rescaling the angular momentum operators,  $ (X,Y,Z)=(J_x/j,J_y/j,J_z/j)$. The operators $X$, $Y$ and $Z$ fulfill then the commutator relations $[X,Y] =Z/j$, \\textit{etc}., and in the limit $j\\to\\infty$ can be degraded to c-number (commuting) variables. The fact that the quantum evolution preserves the total angular momentum $ \\mathbf{J}^2=J_x^2+J_y^2+J_z^2 $ translates to $ X^2+Y^2+Z^2=1 $, so indeed, the classical evolution takes place on the unit sphere \\cite{haake87}. \n\nThe $j\\to\\infty$ transition is a particular case of constructing classical limit for systems on Lie algebras (in this case the $ \\mathfrak{su}(2) $ algebra) by increasing the dimension of representation \\cite{gk98, ghk00, schaefer06}. It is an embodiment of the old prescription of reconstructing the classical evolution by going to \"large quantum numbers\" (in this case the total angular momentum $ j $).\n\nApplying the above outlined procedure to the Heisenberg of equations of motion (\\ref{heisenberg1}--\\ref{heisenberg3}) we get \\cite{haake87},\n\\begin{eqnarray}\nX^{\\prime\\prime}&=&Z\\cos(kX)+Y\\sin(kX)  \\label{cl1}\\\\\nY^{\\prime\\prime}&=&-Z\\sin(kX)+Y\\cos(kX) \\label{cl2}\\\\\nZ^{\\prime\\prime}&=&-X\t\t\t\t\t\\label{cl3}.\n\\end{eqnarray}      \nUsing the stereographic projection of the unit sphere $X^2+Y^2+Z^2=1$ onto the complex plane\n\\begin{equation}\\label{stereogr}\n\\gamma=\\frac{X+iY}{1+Z},\n\\end{equation}\nthe equations (\\ref{cl1}--\\ref{cl3}) can be cast to a single one describing a mapping on the complex plane\n\\begin{equation}\\label{classicalmap}\n\\gamma ^{\\prime \\prime }=\\frac{1+\\gamma }{1-\\gamma }\\exp \\left( -ik\\frac{%\n\t\\gamma +\\gamma ^{*}}{1+\\gamma \\gamma ^{*}}\\right)\n\\end{equation}\t\n\nThe classical map (\\ref{classicalmap}) can be used to compare classical and quantum evolution from a different point of view, namely by quantizing the classical map \\cite{kus93}.\n\nReturning to the main line of reasoning, using (\\ref{classicalmap}) we can write a closed system of equations for functions\n\\begin{equation}\nf_{nm}=\n%\\left[{2j\\choose n}{2j\\choose m}\\right]^{1/2}\n\\frac{\\gamma^n\\gamma^{\\ast m}}{(1+\\gamma\\gamma^\\ast)^{2j}},\n\\end{equation}\n%(observe that the scaling (\\ref{renorm})) has been already incorporated to the definition of $r_{mn}  $). \nThe resulting equations read,\n\\begin{eqnarray}\\label{kickcl}\nf_{nm}^{\\prime\\prime}=K^{C}_{nm}f_{nm}^\\prime, \\quad\\quad\nf_{nm}^\\prime=\\sum\\limits_{r,s=0}^{2j}R_{nm}^{\\,rs}f_{rs}\n\\end{eqnarray}\nwith\n\\begin{equation}\\label{KC}\nK^C_{nm}=\\exp \\left( -ik\\frac{\\gamma +\\gamma\n\t^{*}}{1+\\gamma \\gamma ^{*}}\\frac{(m-n)}{2j}\\right),\n\\end{equation}\nand $R_{nm}^{\\,rs}$ given by (\\ref{R}). The classical evolution has the same structure consisting of the $\\pi/2$ rotation and a kick. The fact that in both cases the rotation is given by the same formula involving $R$ is not so astonishing, rotations are linear transformations from the point of view of the action of $SU(2)$ group and ``look the same'' in all finite-dimensional representations, so it is to be expected that we recover this also in the limiting classical case, i.e., going with dimensions of representations to infinity.\n\nBoth $K^Q$ and $K^C$ can be written as tensor products\n\\begin{equation}\\label{Ktens}\nK^Q=k^Q\\otimes k^{Q\\dagger}, \\quad K^C=k^C\\otimes k^{C\\dagger},\n\\end{equation} \nwhere $k^Q$ and $k^C$ are diagonal matrices with entries\n \n\\begin{eqnarray} \nk^Q_m &=& \\exp\\left(ik\\frac{{(m-j)}^2}{2j}\\right) \n\\label{kQ}\\\\\nk^C_m &=& \\exp\\left(-ikm\\frac{\\gamma+\\gamma^\\ast}{1+\\gamma\\gamma^\\ast}\\right) = \\exp\\left(-ikm\\cos(\\phi)\\sin(\\theta)\\right) \\label{kC}\n\\end{eqnarray}\n  \n\\section{Conclusions and outlook}\nThe presented approach treats the classical and quantum evolution of a paradigmatic nonlinear system in a way that allows for a direct comparison of the two. In principle such a direct comparison is possible once we use the so called phase-space distributions in description of quantum dynamics, like the above discussed $P$- representation (or similar) that mimic classical probability distributions. Here we chose a different approach and used phase-space methods to compare quantum and classical propagators. For the presented model, the kicked, discrete-time dynamics consisted of a nonlinear and linear part. Since the linear part, in terms of an appropriately defined one-step operator is, basically, the same on the quantum and classical level, the only difference appears on the level of the nonlinear part of the propagator, clearly visible in Eqs.(\\ref{kQ}) and (\\ref{kC}). A direct comparison is meaningful when the total angular momentum number $j$ goes to infinity, since in this limit the classical dynamics is expected to be recovered from the quantum one.            \n \n%\\begin{equation}\n%f_{nm}^{\\prime \\prime\n%}=\\sum\\limits_{r,s=0}^{2j}\\widetilde{C}_{nm,rs}r_{rs}.\n%\\end{equation}\n%As in the quantum case, $\\widetilde{C}$ is a tensor product\n%\\begin{equation}\n%\\widetilde{C}=\\widetilde{F}\\otimes \\widetilde{F}^{\\dagger },\\quad\n%\\widetilde{F}=\\widetilde{D}R,\n%\\end{equation}\n%with the same rotation matrix $R$ as above, but with the kick matrix in\n%the form\n%\\begin{equation}\n%\\widetilde{D}=diag(1,a,a^2,\\ldots,a^{2j}),\\quad a:=\\exp \\left( -ik\\frac{\\gamma +\\gamma\n%\t^{*}}{1+\\gamma \\gamma ^{*}}\\right).\n%\\end{equation}\n%Finally thus, the classical and quantum evolution of the phase-space functions (\\ref{eigenv}) differ by a diagonal matrix $D$  ($\\tilde{D}$), which in the classical case can be treated as corresponding to a rotation with a position-dependent\n%angular velocity.\n\n\\section*{Acknowledgments}\n\nThe authors acknowledge a financial support of the the Polish National Science Centre \\\\ grant 2017/27/B/ST2/02959.\n\n%\\bibliographystyle{unsrt}\n%\\bibliography{roy}\n\n\\begin{thebibliography}{10}\n\t\n\t\\bibitem{schroedinger26}\n\tE.~Schr{\\\"o}dinger.\n\t\\newblock Der stetige \\\"{U}bergang von der {M}ikro- zur {M}akromechanik.\n\t\\newblock {\\em Naturwissenschaften}, 14(28):664--666, 1926.\n\t\n\t\\bibitem{klauder60}\n\tJ.~R. Klauder.\n\t\\newblock {The action option and a Feynman quantization of spinor fields in\n\t\tterms of ordinary c-numbers}.\n\t\\newblock {\\em Ann. Phys.}, 11(2):123--168, 1960.\n\t\n\t\\bibitem{klauder63}\n\tJ.~R. Klauder.\n\t\\newblock {Continuous-Representation Theory. I. Postulates of\n\t\tContinuous-Representation Theory}.\n\t\\newblock {\\em J. Math. Phys.}, 4(8):1055--1058, 1963.\n\t\n\t\\bibitem{klauder63a}\n\tJ.~R. Klauder.\n\t\\newblock {Continuous-Representation Theory. II. Generalized Relation between\n\t\tQuantum and Classical Dynamics}.\n\t\\newblock {\\em J. Math. Phys.}, 4(8):1058--1073, 1963.\n\t\n\t\\bibitem{glauber63a}\n\tR.~J. Glauber.\n\t\\newblock {Photon Correlations}.\n\t\\newblock {\\em Phys. Rev. Lett.}, 10(3):84--86, 1963.\n\t\n\t\\bibitem{glauber63}\n\tR.~J. Glauber.\n\t\\newblock {Coherent and Incoherent States of the Radiation Field}.\n\t\\newblock {\\em Phys. Rev.}, 131(6):2766--2788, 1963.\n\t\n\t\\bibitem{glauber63b}\n\tR.~J. Glauber.\n\t\\newblock {The Quantum Theory of Optical Coherence}.\n\t\\newblock {\\em Phys. Rev.}, 130(6):2529--2539, 1963.\n\t\n\t\\bibitem{sudarshan63}\n\tE.~C.~G. Sudarshan.\n\t\\newblock {Equivalence of Semiclassical and Quantum Mechanical Descriptions of\n\t\tStatistical Light Beams}.\n\t\\newblock {\\em Phys. Revi. Lett.}, 10(7):277--279, 1963.\n\t\n\t\\bibitem{klauder85}\n\tJ.~R. Klauder and B.-S. Skagerstam.\n\t\\newblock {\\em {Coherent States. Applications in Physics nad Mathematical\n\t\t\tPhysics}}.\n\t\\newblock World Scientific, Singapore, 1985.\n\t\n\t\\bibitem{perelomov12}\n\tA.~M. Perelomov.\n\t\\newblock {\\em {Generalized Coherent States and their Applications}}.\n\t\\newblock Springer Science \\& Business Media, Berlin, 2012.\n\t\n\t\\bibitem{delbourgo77}\n\tR.~Delbourgo.\n\t\\newblock Minimal uncertainty states for the rotation and allied groups.\n\t\\newblock {\\em J. Phys. A: Math. Gen.}, 10(11):1837--1846, 1977.\n\t\n\t\\bibitem{delbourgo77a}\n\tR.~Delbourgo and J.~R. Fox.\n\t\\newblock Maximum weight vectors possess minimal uncertainty.\n\t\\newblock {\\em J. Phys. A: Math. Gen.}, 10(12):L233--L235, 1977.\n\t\n\t\\bibitem{haake87}\n\tF.~Haake, M.~Ku\\'s, and R.~Scharf.\n\t\\newblock {C}lassical and {Q}uantum {C}haos for a {K}icked {T}op.\n\t\\newblock {\\em Z. Phys. B}, 65:381, 1987.\n\t\n\t\\bibitem{haake19}\n\tF.~Haake, S.~Gnutzmann, and M.~Ku\\'s.\n\t\\newblock {\\em Quantum Signatures of Chaos}.\n\t\\newblock Springer, International Publishing, 2019.\n\t\n\t\\bibitem{radcliffe71}\n\tJ.~M. Radcliffe.\n\t\\newblock Some properties of coherent spin states.\n\t\\newblock {\\em J. Phys. A: Gen. Phys.}, 4(3):313, 1971.\n\t\n\t\\bibitem{arecchi72}\n\tF.~T. Arecchi, E.~Courtens, R.~Gilmore, and H.~Thomas.\n\t\\newblock Atomic coherent states in quantum optics.\n\t\\newblock {\\em Phys. Rev. A}, 6(6):2211, 1972.\n\t\n\t\\bibitem{perelomov72}\n\tA.~M. Perelomov.\n\t\\newblock {Coherent states for arbitrary Lie group}.\n\t\\newblock {\\em Comm. Math. Phys.}, 26(3):222--236, 1972.\n\t\n\t\\bibitem{gilmore72}\n\tR.~Gilmore.\n\t\\newblock Geometry of symmetrized states.\n\t\\newblock {\\em Ann. Phys.}, 74(2):391--463, 1972.\n\t\n\t\\bibitem{gk98}\n\tS.~Gnutzmann and M.~Ku\\'s.\n\t\\newblock {C}oherent states and the classical limit on irreducible ${SU}_3$\n\trepresentations.\n\t\\newblock {\\em J. Phys. A: Math. Gen.}, 31(49):9871--9896, 1998.\n\t\n\t\\bibitem{ghk00}\n\tS.~Gnutzmann, F.~Haake, and M.~Ku\\'s.\n\t\\newblock {Q}uantum chaos of ${SU}_{3}$ observables.\n\t\\newblock {\\em J. Phys. A: Math. Gen.}, 33(1):143--161, 2000.\n\t\n\t\\bibitem{glauber76}\n\tR.~J. Glauber and F.~Haake.\n\t\\newblock Superradiant pulses and directed angular momentum states.\n\t\\newblock {\\em Phys. Rev. A}, 13(1):357--366, 1976.\n\t\n\t\\bibitem{kus93}\n\tM.~Ku\\'s, F.~Haake, and B.~Eckhardt.\n\t\\newblock {Q}uantum effects of periodic orbits for the kicked top.\n\t\\newblock {\\em Z. Phys B}, 92:221--233, 1993.\n\t\n\t\\bibitem{chaudhury09}\n\tS.~Chaudhury, A.~Smith, B.~E. Anderson, S.~Ghose, and P.~S. Jessen.\n\t\\newblock Quantum signatures of chaos in a kicked top.\n\t\\newblock {\\em Nature}, 461(7265):768, 2009.\n\t\n\t\\bibitem{schaefer06}\n\tI.~Sch\\\"afer and M.~Ku\\'s.\n\t\\newblock {C}onstructing the classical limit for quantum systems on compact\n\tsemisimple {L}ie algebras.\n\t\\newblock {\\em J. Phys. A: Math. Gen.}, 39:9779\u2013\u20139796, 2006.\n\t\n\\end{thebibliography}\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:00:11", "yymm": "2010", "arxiv_id": "2010.14509", "url": "https://arxiv.org/abs/2010.14509", "source": "arxiv"}}
{"text": "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n% file gwmag11.tex (27 October 2020) final version\n% \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\documentclass[prd,showpacs,showkeys,nofootinbib,twocolumn]{revtex4-1}\n% \\documentclass[prd,showpacs,showkeys,nofootinbib,preprint]{revtex4-1}\n\\usepackage{amsmath,amsfonts,amssymb,color}\n\\usepackage{bm}% bold math\n\\usepackage{pgfplots}\n\\usepackage[colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}\n\\usepackage{color}\n%%%%%%%%%%%%%%%%%%% \n\\newcommand{\\aQ}{\\nearrow\\!\\!\\!\\!\\!\\!\\!Q}\n\\newcommand{\\aZ}{\\nearrow\\!\\!\\!\\!\\!\\!\\!Z}\n\\newcommand{\\pW}{\\stackrel {(+)}W}\n\\newcommand{\\pmW}{\\stackrel {(\\pm)}W}\n\\newcommand{\\pOm}{\\stackrel {(+)}\\Omega}\n\\newcommand{\\mOm}{\\stackrel {(-)}\\Omega}\n\\newcommand{\\pmOm}{\\stackrel {(\\pm)}\\Omega}\n\n\\begin{document} \n\n\n\\title{Gravitational waves in metric-affine gravity theory}\n\n\n\\author{Alejandro Jim\\'enez-Cano}\n\\email{alejandrojc@ugr.es}\n\\affiliation{Departamento de F\\'{\\i}sica Te\\'orica y del Cosmos and CAFPE\nUniversidad de Granada, 18071, Granada, Spain}\n\n\\author{Yuri N. Obukhov}\n\\email{obukhov@ibrae.ac.ru}\n\\affiliation{Theoretical Physics Laboratory, Nuclear Safety Institute, \nRussian Academy of Sciences, B.Tulskaya 52, 115191 Moscow, Russia}\n\n%\\date{file ``gwmag11.tex'' \\today}\n\n\\begin {abstract}\nWe derive the exact gravitational wave solutions in a general class of quadratic metric-affine gauge gravity models. The Lagrangian includes all possible linear and quadratic invariants constructed from the torsion, nonmetricity and the curvature. The ansatz for the gravitational wave configuration and the properties of the wave solutions are patterned following the corresponding ansatz and the properties of the plane-fronted electromagnetic wave. \n\\end{abstract}\n\n\\pacs{04.50.-h, 04.20.Jb, 04.30.-w}\n\n\\maketitle\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Introduction}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\nIn contrast to Newton's gravity with its absolute space and time, the modern understanding of relativistic gravitational phenomena is based on the idea that the structure and the dynamics of the geometry of the spacetime continuum is determined by the physical matter. As Einstein wrote in \\cite{Ein}:   ``...The question whether this continuum has a Euclidean, Riemannian, or any other structure is a question of physics proper which must be answered by experience, and not a question of a convention to be chosen on grounds of mere expediency.'' Classical experimental tests in terrestrial laboratories and observations in the solar system demonstrate the validity of Einstein's general relativity (GR) theory on the macroscopic scales when the matter is characterised by its mass and energy. \n\nSuch a satisfactory status of GR as a macroscopic theory of gravity, however, is not a guarantee that it also correctly describes the gravitational phenomena at extremely small scales when one takes into account that matter is characterized not only by the energy-momentum current but also by other intrinsic properties known as microstructure (spin, shear and dilaton current, in particular). In this respect, an alternative viable description of the gravitational interaction in the microworld (and at earliest stages of universe's evolution) is provided by the gauge approach to gravity \\cite{MAG,Blag,reader,PBO}. The gauge principle is one of the cornerstones of the modern physics, which explains the nature of all physical interactions in a consistent field-theoretic Yang-Mills-Higgs framework that is solidly substantiated by high-energy experiments.\n\nFor gravity, the corresponding gauge-theoretic formalism can be developed \\cite{Sciama,Kibble} along the same lines as for the electroweak and strong interactions by replacing the underlying non-Abelian group of {\\it internal} symmetries with a group of {\\it spacetime} symmetries, e.g., translational, Lorentz, Poincar\\'e, conformal, general linear, or affine one. In particular, the metric-affine gravity (MAG) arises as a gauge theory based on the general affine group $GA(4,R) = T_4\\,\\rtimes\\,GL(4,R)$, a semidirect product of the translation group $T_4$ times the general linear group $GL(4,R)$, when the matter is characterized by the three Noether currents: the canonical energy-momentum current, the canonical hypermomentum current, and the metric energy-momentum current \\cite{MAG}. These matter sources are minimally coupled to the corresponding gravitational field potentials: the coframe, the linear connection and the metric, respectively. It is worthwhile to mention that Einstein's GR can be consistently interpreted as a gauge theory under the assumption of a nonminimal coupling of a certain form \\cite{grpg}. \n\nIn MAG, the geometrical structure of spacetime is extended from the Riemannian geometry of Einstein's GR to include nontrivial post-Riemannian structures such as the torsion and the nonmetricity. The resulting metric-affine geometry is of interest, both mathematically and physically, for a number of reasons \\cite{Goenner,Coley1,Coley2,Coley3,mccrea:1992,Vitagliano}. A strong motivation comes from the geometrical approach to the physics of hadrons in terms of extended structures \\cite{nee1,nee2,nee3,MAG}, and from the efforts to construct a consistent quantum gravity theory \\cite{lee1,lee2,per1,per2}. The theory of continuous media with microstructure \\cite{frank} gives rise to a realistic model of classical matter with hypermomentum \\cite{hyper} which is widely used for the study of the early universe's evolution, also relating the post-Riemannian structures to the dark matter problem \\cite{dirk3,dirk4,dirk5}. It is worthwhile to mention that certain special MAG models may arise as the effective theories in the dilaton-axion-metric low-energy limit of the string theory \\cite{dil1,dil2,dil3,dil4}. It is important to notice that it is possible to detect the post-Riemannian spacetime geometry only with the help of the matter with microstructure \\cite{nee,yass,Puetz,eom2}.\n\nThe study of the exact solutions of the MAG field equations is important for understanding and development of the physical aspects mentioned above, in order to fix the structure of the basic Lagrangian of the theory, as well as for the detailed analysis of possible new physical effects. The derivation of new exact solutions for these models would bring new insight to the understanding of gravitational physics on microscopic scales, under an important condition of consistency with Einstein's GR at large distances which should be recovered in a certain limit \\cite{pono,Gronwald:1997,hehl:1999}. The earlier results include the construction of the spherically and axially symmetric solutions, including the black hole configurations which can carry nontrivial shear and dilaton charges, in addition to the mass \\cite{tres1,tres2,wang,vlach:1996,obukhov:1996,Garcia:1998,obukhov:1997,Delhom:2019}. Among other methods, the so-called triplet ansatz technique has proven to be an effective method of deriving exact solutions in MAG \\cite{obukhov:1997}.\n\nWave is a fundamental physical phenomenon, and the gravitational wave research became a rapidly developing subject after the recent experimental discovery of the first gravitational wave signals \\cite{Abbott1,Abbott2}. The plane-fronted gravitational waves represent an important class of exact solutions which generalize the basic properties of electromagnetic waves in flat spacetime to the case of curved spacetime geometry. In the framework of GR, the theoretical study of the gravitational waves has a long and rich history \\cite{flan,schutz,CNN,Brink1,Brink2,Brink3,rosen1937,einrosen,rosen1956,rosen1958,Virb1,Virb2,bondi0,bondi1,peres,pen1,pen2,Kom1,Kom2,Jordan1,Jordan2,kundt,curr,schim,AT,piran,MashQ,torre,cropp1,cropp2,coley12,mcnutt,Barnett,griff,vdz,exact}. A wide variety of exact gravitational plane wave solutions was obtained in the Poincar\\'e gauge gravity \\cite{adam,chen,sippel,vadim,singh,babu,BC1,BC2,BC3,BC4,BC5,yno:2017,BCO}, in teleparallel gravity \\cite{tele,Conroy:2018,Hohmann:2018,Hohmann:2019,Capozziello:2020,Cai:2016}, in a number of modified gravity theories \\cite{gurses,lovelock,Baykal,Mohseni}, as well as in supergravity \\cite{sg1,sg2,sg3,sg4,sg5} and in superstring theories \\cite{gimon,ark1,ark2,str1,str2,str3,str4}. The higher-dimensional generalizations of the gravitational wave solutions were discussed in \\cite{sokol,coley1,coley2,hervik,ndim}.\n\nA critical analysis of the gravitational wave criteria \\cite{vdz} was performed in the recent work \\cite{AJC}, and an appropriate extension was proposed for the metric-affine spacetimes. The earlier studies \\cite{ppmag,dirk1,dirk2,king,vas1,vas2,vas3,pasic1,pasic2} had demonstrated the existence of the gravitational wave solutions in the metric-affine theory of gravity with the propagating torsion and nonmetricity fields. In many cases, however,  either the torsion waves were revealed, or the wave field configurations were found for a special class of the MAG Lagrangian by means of the triplet technique \\cite{obukhov:1997,hehl:1999} with a specific ansatz for torsion and nonmetricity. \n\nThe aim of this paper is to describe the plane gravitational waves for the general Yang-Mills type quadratic MAG Lagrangian with nontrivial torsion and nonmetricity configurations that do not belong to the triplet ansatz. The motivations are as follows. Quite generally, the systematic study of the space of solutions represents a significant aspect of the development of any field-theoretic model. At the same time, since the wave phenomena are of fundamental importance as such, the construction and comparison of the wave solutions in different models may help to establish their physical contents and clarify the relations between the microscopic and macroscopic gravitational theories (in particular, general relativity, Poincar\\'e gauge gravity and MAG). Moreover, the analysis of the plane wave solutions can provide a good understanding of the particle spectrum for the general quadratic MAG models, extending the earlier results \\cite{Karananas,BC6,Baikov:1992,Percacci:2020}. \n\nThe structure of the paper is as follows. In the next Sec.~\\ref{MAG}, we give a short overview of the general structure of the MAG theory. Then in Sec.~\\ref{GW} we formulate the corresponding ansatz for a gravitational plane wave in MAG. The properties of the resulting curvature, torsion and nonmetricity in terms of their irreducible parts are discussed in Sec.~\\ref{irreps}, and the explicit field equations are derived in Sec.~\\ref{MAGE} for the general quadratic MAG model (\\ref{lagrV}). Finally, in Sec.~\\ref{FE} we derive the exact solutions of the MAG field equations for the proposed ansatz. The conclusions are outlined in Sec~\\ref{DC}.\n\n\n\\subsection{Notations}\n\n\nOur basic notation and conventions are consistent with \\cite{MAG}. In particular, Greek indices $\\alpha, \\beta, \\dots = 0, \\dots, 3$, denote the anholonomic components (for example, of a coframe $\\vartheta^\\alpha$), while the Latin indices $i,j,\\dots =0,\\dots, 3$, label the holonomic components ($dx^i$, e.g.). The anholonomic vector frame basis $e_\\alpha$ is dual to the coframe basis in the sense that $e_\\alpha\\rfloor\\vartheta^\\beta = \\delta_\\alpha^\\beta$, where $\\rfloor$ denotes the interior product. The volume 4-form is denoted $\\eta$, and the $\\eta$-basis in the space of exterior forms is constructed with the help of the interior products as $\\eta_{\\alpha_1 \\dots\\alpha_p}:= e_{\\alpha_p}\\rfloor\\dots e_{\\alpha_1}\\rfloor\\eta$, $p=1,\\dots,4$. They are related to the $\\theta$-basis via the Hodge dual operator $^*$, for example, $\\eta_{\\alpha\\beta} = {}^*\\!\\left(\\vartheta_\\alpha\\wedge\\vartheta_\\beta\\right)$. We will mark the parity-odd variables by the overline in order to distinguish them from the parity-even objects (for example, $\\overline{T}$ denotes the axial trace 1-form of the torsion, whereas $T$ is the torsion trace 1-form). \n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{MAG: brief overview}\\label{MAG}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\nThe metric-affine gravity (MAG) is constructed as the gauge theory for the general affine spacetime symmetry group \\cite{MAG}. The gravitational field potentials are the metric $g_{\\alpha\\beta}$, the coframe $\\vartheta^\\alpha = e^\\alpha_i dx^a$ and connection $\\Gamma_\\alpha{}^\\beta = \\Gamma_{i\\alpha}{}^\\beta dx^i$ 1-forms. The corresponding gauge field strengths are identified with the nonmetricity 1-form, the torsion 2-form, and the curvature 2-form, respectively:\n\\begin{eqnarray}\nQ_{\\alpha\\beta} &=& -\\,Dg_{\\alpha\\beta} = -\\,dg_{\\alpha\\beta} + 2\\Gamma_{(\\alpha\\beta)},\\label{nonm}\\\\\nT^\\alpha &=& D\\vartheta^\\alpha = d\\vartheta^\\alpha +\\Gamma_\\beta{}^\\alpha\\wedge\n\\vartheta^\\beta,\\label{Tor}\\\\ \\label{Cur}\nR_\\alpha{}^\\beta &=& d\\Gamma_\\alpha{}^\\beta + \\Gamma_\\gamma{}^\\beta\\wedge\\Gamma_\\alpha{}^\\gamma.\n\\end{eqnarray}\nAs usual, the covariant differential is denoted $D$.\n\nThe gravitational Lagrangian 4-form \n\\begin{equation}\nV = V(\\vartheta^{\\alpha}, Q_{\\alpha\\beta}, T^{\\alpha}, R_{\\alpha}{}^{\\beta})\\label{lagrV}\n\\end{equation}\nis an arbitrary function of the gravitational field variables. The MAG field equations are derived from the variational derivatives with respect to the coframe and connection. They read explicitly (with the canonical energy-momentum $\\Sigma_\\alpha$ and the hypermomentum $\\Delta^\\alpha{}_\\beta$ currents as the matter sources):\n\\begin{eqnarray}\n{\\frac{\\delta V}{\\delta\\vartheta^{\\alpha}}} = \n- DH_{\\alpha}  + E_{\\alpha} &=& \\Sigma_\\alpha, \\label{dVt}\\\\ \n{\\frac{\\delta V}{\\delta\\Gamma_\\alpha{}^\\beta}} \n= - DH^\\alpha{}_\\beta + E^\\alpha{}_\\beta &=& \\Delta^\\alpha{}_\\beta.\\label{dVG}\n\\end{eqnarray}\nThese are the 1st, and the 2nd MAG field equations \\cite{MAG}. We do not write down the 0th field equation (which arises from the variation with respect to the metric) because it is identically satisfied in view of (\\ref{dVt}) and (\\ref{dVG}) and the Noether identities. Here the partial derivatives of the Lagrangian with respect to the generalized ``velocities''\n\\begin{eqnarray}\nM^{\\alpha\\beta} &=& -\\,2{\\frac {\\partial V}{\\partial Q_{\\alpha\\beta}}},\\label{Mab}\\\\\nH_{\\alpha} &=& -\\,{\\frac {\\partial V}{\\partial T^{\\alpha}}},\\label{Ha}\\\\\nH^{\\alpha}{}_{\\beta} &=& -\\,{\\frac {\\partial V}{\\partial R_{\\alpha}{}^{\\beta}}},\\label{Hab}\n\\end{eqnarray}\nare identified as the gravitational field momenta, and\n\\begin{eqnarray}\nE_{\\alpha} &=& e_{\\alpha}\\rfloor V + (e_{\\alpha}\\rfloor T^{\\beta})\\wedge H_{\\beta}\n+ (e_{\\alpha}\\rfloor R_{\\beta}{}^{\\gamma})\\wedge H^{\\beta}{}_{\\gamma}\\nonumber\\\\\n&& + \\,{\\frac 12}(e_{\\alpha}\\rfloor Q_{\\beta\\gamma})M^{\\beta\\gamma},\\label{Ea}\\\\\nE^{\\alpha}{}_{\\beta} &=& - \\,\\vartheta^{\\alpha}\\wedge H_{\\beta} - M^{\\alpha}{}_{\\beta}.\\label{Eab}\n\\end{eqnarray}\nare the canonical gauge field currents of the gravitational energy-momentum and hypermomentum, respectively. \n\n\\subsection{Quadratic metric-affine gravity models} \n\n\nThe 1-form of nonmetricity can be decomposed into 4 irreducible parts, the torsion 2-form can be decomposed into the 3 irreducible parts, whereas the curvature 2-form has 11 irreducible pieces. Their definition is presented in Appendices~\\ref{irrtor}-\\ref{irrcur}.\n\nThe general quadratic model is described by the Lagrangian 4-form that contains all possible quadratic invariants of the nonmetricity, the torsion and the curvature:\n\\begin{eqnarray}\nV &=& {\\frac {1}{2\\kappa c}}\\Big\\{a_0\\eta_{\\alpha\\beta}\\wedge R^{\\alpha\\beta}\n-\\,T^\\alpha\\wedge\\sum_{I=1}^3 a_I\\,{}^*({}^{(I)}T_\\alpha)\\nonumber\\\\\n&& \\qquad -\\,Q_{\\alpha\\beta}\\wedge \\sum_{I=1}^{4}b_{I}\\,^*({}^{(I)}Q^{\\alpha\\beta}) \\nonumber\\\\\n&& \\qquad -\\,2b_5({}^{(3)}Q_{\\alpha\\gamma}\\wedge\\vartheta^{\\alpha})\\wedge\n{}^*({}^{(4)}Q^{\\beta\\gamma}\\wedge\\vartheta_{\\beta})\\nonumber\\\\\n&& \\qquad -\\,2\\vartheta^\\alpha\\wedge ^*\\!T^\\beta\\wedge \\sum_{I=1}^{3}c_{I}\n\\,{}^{(I+1)}Q_{\\alpha\\beta}\\,\\Bigr\\}\\nonumber\\\\\n&& - \\,{\\frac 1{2\\rho}}R^{\\alpha\\beta}\\wedge {}^*\\Bigl[\\sum_{I=1}^6 w_I\\,{}^{(I)}\\!W_{\\alpha\\beta} \n + \\sum_{I=1}^5 z_I\\,{}^{(I)}\\!Z_{\\alpha\\beta} \\nonumber\\\\\n&& \\qquad +\\,v_1\\,\\vartheta_\\alpha\\wedge (e_\\gamma\\rfloor{}^{(5)}\\!W^\\gamma{}_\\beta)\n+ v_2\\,\\vartheta_\\gamma\\wedge (e_\\alpha\\rfloor{}^{(2)}\\!Z^\\gamma{}_\\beta)\\nonumber\\\\\n&& \\qquad +\\,\\sum_{I=3}^5 v_I\\,\\vartheta_\\alpha\\wedge (e_\\gamma\\rfloor{}^{(I)}\\!Z^\\gamma{}_\\beta)\\Bigr].\\label{LRT}\n\\end{eqnarray}\nWe do not use topological invariants to simplify the Lagrangian. In this relation it is worthwhile to notice that the metric-affine Gauss-Bonnet term is not a boundary term in the presence of nonmetricity \\cite{JanssenJC:2019}, and hence it cannot be used to eliminate quadratic curvature terms. For completeness, we included in (\\ref{LRT}) the dimensionless constant $a_0$. This allows for the special case $a_0 = 0$ of the purely quadratic model without the Hilbert-Einstein linear term in the Lagrangian. In the Einstein-Cartan model, one puts $a_0 = 1$. Here we assume that the cosmological constant is zero. The analysis of a possibly nonvanishing cosmological term would require a different (more general) wave ansatz. \n\nThe structure of the quadratic part of the general Lagrangian (\\ref{LRT}) is determined by 27 dimensionless coupling constants: $a_1, a_2, a_3$, $b_1, \\dots, b_5$, $c_1, c_2, c_3$, $w_1, \\dots, w_6$, $z_1, \\dots, z_5$, $v_1, \\dots, v_5$. The coupling constant $\\rho$ has the dimension of an inverse action: $[\\rho] = [{\\frac 1\\hbar}]$. It is worthwhile to notice that this Lagrangian contains only parity-even invariants. For the most general case (to be analysed elsewhere) one should also take into account the parity-odd sector. \n\nThe contribution of the curvature square terms in the Lagrangian (\\ref{LRT}) to the gravitational field dynamics in the field equations is characterized by the parameter\n\\begin{equation}\n\\ell_\\rho^2 := {\\frac {\\kappa c}{\\rho}}.\\label{lr}\n\\end{equation}\nSince $[{\\frac 1\\rho}] = [\\hbar]$, this new coupling parameter has the dimension of the area, $[\\ell_\\rho^2] = [\\ell^2]$.\n\n\n\\section{Gravitational waves in MAG}\\label{GW}\n\n\nLet us now describe the plane wave ansatz in metric-affine gravity for the gravitational field potentials $(g_{\\alpha\\beta}, \\vartheta^\\alpha, \\Gamma_\\alpha{}^\\beta)$. We will do it by extending the approach \\cite{ppmag,yno:2017,BCO} in which the gravitational waves are patterned by the electromagnetic waves on a curved spacetime. \n\nAs a first step, we divide the local coordinates into two groups: $x^i= (x^a, x^A)$, where $x^a = (x^0 = \\sigma, x^1 = \\rho)$ and $x^A = (x^2,x^3)$. Hereafter the indices from the beginning of the Latin alphabet $a,b,c... = 0,1$, whereas the capital Latin indices run $A,B,C... = 2,3$. \n\nTo begin with, we fix the metric as the Minkowski tensor\n\\begin{equation}\\label{gab}\ng_{\\alpha\\beta} = \\left(\\begin{array}{crrr} 1 & 0 & 0 & 0\\\\ 0 & -1 & 0 & 0\\\\\n0 & 0 & -1 & 0\\\\ 0 & 0 & 0 & -1\\end{array}\\right). \n\\end{equation}\nThis can always be done by making use of the local general linear transformations of the coframe. Although it is common to use the so-called null (or semi-null) Minkowski metric for the discussion of the gravitational waves, however, throughout this paper we make use of the standard diagonal metric (\\ref{gab}).\n\nAs the next step, we have to specify the ansatz for the coframe and the linear connection $(\\vartheta^\\alpha, \\Gamma_\\alpha{}^\\beta)$. The coframe 1-form is chosen as\n\\begin{eqnarray}\n\\vartheta^{\\widehat 0} &=& {\\frac 12}(U + 1)d\\sigma + {\\frac 12}\\,d\\rho,\\label{cof0}\\\\ \n\\vartheta^{\\widehat 1} &=& {\\frac 12}(U - 1)d\\sigma + {\\frac 12}\\,d\\rho,\\label{cof1}\\\\\n\\vartheta^{\\widehat A} &=& dx^A,\\qquad A = 2,3.\\label{cof23}\n\\end{eqnarray}\nHere $U = U(\\sigma, x^A)$. As a result, the line element reads\n\\begin{equation}\\label{ds_2}\nds^2 = g_{\\alpha\\beta}\\vartheta^\\alpha\\vartheta^\\beta = d\\sigma d\\rho + Ud\\sigma^2 - \\delta_{AB}dx^Adx^B.\n\\end{equation}\n\nFollowing the analogy with the electromagnetism, we now introduce a crucial object: the wave 1-form $k$. We define the latter as \n\\begin{equation}\nk := d\\sigma = \\vartheta^{\\widehat 0} - \\vartheta^{\\widehat 1}.\\label{kdef}\n\\end{equation}\nBy construction, we have $k\\wedge{}^\\ast\\!k = 0$. The wave covector $k_\\alpha = e_\\alpha\\rfloor k$ then has (anholonomic) components $k_\\alpha = (1, -1, 0, 0)$ and $k^\\alpha = (1, 1, 0, 0)$. Hence, this is a null vector field, $k_\\alpha k^\\alpha = 0$. \n\nFor the local Lorentz connection 1-form, we assume\n\\begin{equation}\\label{conW}\n\\Gamma_\\alpha{}^\\beta = -\\,k\\left(k_\\alpha V^\\beta + k^\\beta W_\\alpha\\right) + k_\\alpha k^\\beta\\,u,\n\\end{equation}\nwhere the two new vector variables are introduced: $W_\\alpha = W_\\alpha(\\sigma, x^A)$, and $V^\\alpha = V^\\alpha(\\sigma, x^A)$. The 1-form $u = u_\\alpha(\\sigma, x^A)\\,\\vartheta^\\alpha$ is assumed to be orthogonal to the wave covector,\n\\begin{equation}\nk\\wedge{}^*\\!u = 0,\\qquad k^\\alpha u_\\alpha = 0.\\label{ku}\n\\end{equation}\nIn addition, we assume the orthogonality \n\\begin{equation}\nk_\\alpha W^\\alpha = 0,\\qquad k_\\alpha V^\\alpha = 0.\\label{kW0}\n\\end{equation}\nThis is guaranteed if we choose \n\\begin{equation}\\label{Wa0}\nW^\\alpha = \\begin{cases}W^a = 0,\\qquad\\qquad\\qquad a = 0,1, \\\\\nW^A = W^A(\\sigma, x^B),\\qquad A = 2,3.\\end{cases}\n\\end{equation}\nHere $W^2(\\sigma, x^B)$ and $W^3(\\sigma, x^B)$ are the two unknown functions. The same applies to $V^\\alpha$:\n\\begin{equation}\\label{Va0}\nV^\\alpha = \\begin{cases}V^a = 0,\\qquad\\qquad\\qquad a = 0,1, \\\\\nV^A = V^A(\\sigma, x^B),\\qquad A = 2,3,\\end{cases}\n\\end{equation}\nand to the components of $u_\\alpha$:\n\\begin{equation}\\label{ua0}\nu_\\alpha = \\begin{cases}u_a = 0,\\qquad\\qquad\\qquad a = 0,1, \\\\\nu_A = u_A(\\sigma, x^B),\\qquad A = 2,3,\\end{cases}\n\\end{equation}\n\nIn other words, the ansatz for the MAG gauge potentials -- coframe (\\ref{cof0})-(\\ref{cof23}) and the linear connection (\\ref{conW}) -- is described by 7 variables: $U = U(\\sigma, x^B)$, $W^A = W^A(\\sigma, x^B)$, $V^A = V^A(\\sigma, x^B)$, and $u_A = u_A(\\sigma, x^B)$. These functions determine wave's profile and their explicit form should be found from the gravitational field equations.\n\nOne immediately verifies that the wave 1-form is closed, and the wave covector is constant:\n\\begin{equation}\ndk = 0,\\qquad dk_\\alpha = 0,\\qquad Dk_\\alpha = 0.\\label{dk0}\n\\end{equation}\nTaking this into account, we straightforwardly compute nonmetricity 1-form and the torsion and the curvature 2-forms:\n\\begin{eqnarray}\nQ_{\\alpha\\beta} &=& -\\,k\\,(k_\\alpha\\!\\pW_\\beta + k_\\beta\\!\\pW_\\alpha) + 2k_\\alpha k_\\beta\\,u,\\label{nonW}\\\\\nT^\\alpha &=& -\\,k\\wedge k^\\alpha\\,\\Theta,\\label{torW}\\\\\nR_\\alpha{}^\\beta &=& k\\wedge\\left(k_\\alpha \\underline{d}\\,V^\\beta\n+ k^\\beta \\underline{d}\\,W_\\alpha\\right) + k_\\alpha k^\\beta du,\\label{curW}\n\\end{eqnarray}\nwhere we introduced \n\\begin{eqnarray}\n\\Theta &:=& {\\frac 12}\\,\\underline{d}\\,U + W_\\alpha\\vartheta^\\alpha + u,\\label{THW}\\\\\n\\pmW{\\!}_\\alpha &:=& W_\\alpha \\pm V_\\alpha.\\label{pmW}\n\\end{eqnarray}\nThe differential $\\underline{d}$ acts in the transversal 2-space spanned by $x^A = (x^2, x^3)$:\n\\begin{equation}\n \\underline{d} := \\vartheta^Ae_A\\rfloor d = dx^A\\partial_A,\\qquad A = 2,3.\\label{ud}\n\\end{equation}\nAlthough the geometry of the transversal 2-space spanned by $x^A = (x^2, x^3)$ is fairly simple, it is convenient to describe it explicitly. It is a flat Euclidean space with the volume 2-form $\\underline{\\eta} = {\\frac 12}\\eta_{AB}\\vartheta^A\\wedge\\vartheta^B = dx^2\\wedge dx^3$, where $\\eta_{AB} = -\\,\\eta_{BA}$ is the 2-dimensional Levi-Civita tensor (with $\\eta_{23} = 1$). The volume 4-form of the spacetime manifold then reads $\\eta = \\vartheta^{\\widehat 0}\\wedge \\vartheta^{\\widehat 1}\\wedge\\vartheta^{\\widehat 2}\\wedge\\vartheta^{\\widehat 3} = {\\frac 12}k\\wedge d\\rho\\wedge\\underline{\\eta}$. For the wave 1-form we find the remarkable relation \n\\begin{equation}\n{}^*k = -\\,k\\wedge\\underline{\\eta}.\\label{dualk}\n\\end{equation}\nWe will denote the geometrical objects on the transversal 2-space by underlining them; for example, a 1-form $\\underline{\\phi} = \\phi_A\\vartheta^A$. The Hodge duality on this space is defined as usual via ${}^{\\underline{*}}\\vartheta_A = \\underline{\\eta}_A = e_A\\rfloor \\underline{\\eta} = \\eta_{AB}\\vartheta^B$. With the help of (\\ref{dualk}), we can verify\n\\begin{equation}\n{}^*(k\\wedge\\underline{\\phi}) = k\\wedge{}^{\\underline{*}}\\underline{\\phi}.\\label{kphi}\n\\end{equation}\n\nFrom (\\ref{curW}) we immediately find\n\\begin{eqnarray}\nW^{\\alpha\\beta} &=& R^{[\\alpha\\beta]} = -\\,k\\wedge k^{[\\alpha}\\mOm{\\!}^{\\beta]},\\label{WW}\\\\\nZ^{\\alpha\\beta} &=& R^{(\\alpha\\beta)} = k\\wedge k^{(\\alpha}\\pOm{\\!}^{\\beta)} + k^\\alpha k^\\beta du,\\label{ZW}\n\\end{eqnarray}\nwhere we denoted\n\\begin{eqnarray}\n\\pmOm{\\!}^\\alpha := \\underline{d}\\pmW{\\!}^\\alpha. \\label{OMW}\n\\end{eqnarray}\nThe new objects (\\ref{THW}) and (\\ref{OMW}) have the obvious properties:\n\\begin{equation}\nk\\wedge{}^*\\Theta = 0,\\quad k\\wedge{}^*\\pmOm{\\!}^\\alpha = 0,\\quad \nk_\\alpha\\pmOm{\\!}^\\alpha = 0.\\label{kTOM}\n\\end{equation}\nIn accordance with (\\ref{Wa0})-(\\ref{ua0}), we have explicitly: $\\pmOm{\\!}^a = 0$ ($a = 0,1$) and \n\\begin{equation}\n\\Theta = \\vartheta^A\\!\\left({\\frac 12}\\partial_AU - \\delta_{AB}W^B + u_A\\!\\right),\\\n\\!\\pmOm{\\!}^A = \\vartheta^B\\partial_B\\!\\pmW{\\!}^A.\\label{THOMa}\n\\end{equation}\nApplying the transversal differential to (\\ref{THW}), and making use of (\\ref{OMW}), we find\n\\begin{equation}\n\\underline{d}\\Theta = {\\frac 12}(\\pOm{\\!}_\\alpha + \\mOm{\\!}_\\alpha)\\wedge\\vartheta^\\alpha\n+ \\underline{d}u.\\label{dTHW}\n\\end{equation}\nIn essence, this is equivalent to the Bianchi identity $DT^\\alpha = R_\\beta{}^\\alpha\\wedge\\vartheta^\\beta$ which is immediately checked by applying the covariant differential $D$ to (\\ref{torW}) and using (\\ref{curW}). It is worthwhile to notice that\n\\begin{equation}\\label{du}\ndu = k\\wedge\\dot{u} + \\underline{d}u,\\qquad \\dot{u} = (\\partial_\\sigma u_\\alpha)\\,\\vartheta^\\alpha.\n\\end{equation}\n\nLet us discuss the properties of the torsion and the curvature for the wave ansatz (\\ref{cof0})-(\\ref{cof23}) and (\\ref{conW}). To begin with, it is worthwhile to notice that the 2-forms of the gravitational gauge field strengths (\\ref{torW}) and (\\ref{curW}) have the same structure as the electromagnetic field strength of a plane wave, when $u = 0$. Indeed, we then have\n\\begin{equation}\nQ_{\\alpha\\beta} = k\\,q_{\\alpha\\beta},\\quad T^\\alpha = k\\wedge a^\\alpha,\\quad R_\\alpha{}^\\beta = k\\wedge a_\\alpha{}^\\beta,\\label{poinW}\n\\end{equation}\nwhere $q_{\\alpha\\beta} = -(k_\\alpha\\!\\!\\pW_\\beta + k_\\beta\\!\\!\\pW_\\alpha)$, $a^\\alpha = -\\, k^\\alpha\\Theta$ and $a_\\alpha{}^\\beta = k_\\alpha \\underline{d}\\,V^\\beta + k^\\beta \\underline{d}\\,W_\\alpha$ play the role of the gravitational ``polarization'' 1-forms, in complete analogy to the polarization 1-form $a$ in the electromagnetic plane wave field $F = k\\wedge a$, which is orthogonal to the wave covector $k\\wedge {}^*a = 0$. Similarly, the polarization 1-forms satisfy the orthogonality relations\n\\begin{eqnarray}\nk\\wedge{}^\\ast a^\\alpha = 0,\\qquad k\\wedge{}^\\ast a_\\alpha{}^\\beta = 0,\\label{aka1}\\\\\nk^\\alpha q_{\\alpha\\beta} = 0,\\qquad k_\\alpha a^\\alpha = 0,\\label{aka0}\\\\\nk_\\beta a_\\alpha{}^\\beta = 0,\\qquad k^\\alpha a_\\alpha{}^\\beta = 0.\\label{aka2}\n\\end{eqnarray}\nClearly, the gravitational field strengths of a wave have the properties\n\\begin{eqnarray}\nk\\wedge{}^\\ast\\!Q_{\\alpha\\beta} = 0,\\ k\\wedge{}^\\ast\\!T^\\alpha = 0,\\ k\\wedge{}^\\ast\\!R_\\alpha{}^\\beta = 0,\\label{kTW}\\\\\nk\\wedge Q_{\\alpha\\beta} = 0,\\ k\\wedge T^\\alpha = 0,\\ k\\wedge R_\\alpha{}^\\beta = 0,\\label{kRW}\\\\\nQ_{\\alpha\\beta}\\wedge{}^\\ast\\!Q_{\\rho\\sigma} = 0,\\ T^\\alpha\\wedge{}^\\ast\\!T^\\beta = 0,\\ R_\\alpha{}^\\beta\\wedge{}^\\ast\\!R_\\rho{}^\\sigma = 0,\\label{kTRW}\n\\end{eqnarray}\nin complete analogy to the electromagnetic plane wave, $k\\wedge F = 0$, $F\\wedge {}^*F = 0$.\n\nIn addition, however, the gravitational field strengths satisfy \n\\begin{equation}\nk^\\alpha Q_{\\alpha\\beta} = 0,\\quad k_\\alpha T^\\alpha = 0,\\quad k_\\beta R_\\alpha{}^\\beta = 0,\\quad k^\\alpha R_\\alpha{}^\\beta = 0,\\label{kTRW2}\n\\end{equation}\nin view of (\\ref{kW0}) and (\\ref{kTOM}). \n\n\n\\subsection{Irreducible decomposition of gravitational field strengths}\\label{irreps}\n\n\nIt is straightforward to find the irreducible parts of the nonmetricity, the torsion and the curvature.\n\nDirectly from (\\ref{torW}), with an account of (\\ref{kW0}), we find $e_\\alpha\\rfloor T^\\alpha = 0$ and $\\vartheta_\\alpha\\wedge T^\\alpha = 0$. Hence the second (trace) and third (axial trace) irreducible parts of the torsion are trivial, ${}^{(2)}\\!T^\\alpha = 0$ and ${}^{(3)}\\!T^\\alpha = 0$, and \n\\begin{equation}\n{}^{(1)}\\!T^\\alpha = T^\\alpha = -\\,k\\wedge k^\\alpha\\,\\Theta.\\label{torW1}\n\\end{equation}\n\nIn a similar way, we derive $e^\\alpha\\rfloor\\!\\aQ_{\\alpha\\beta} = 0$ and $Q_\\alpha{}^\\alpha = 0$ from (\\ref{nonW}) and (\\ref{kW0}). Hence the third and the fourth irreducible parts of the nonmetricity are trivial, ${}^{(3)}\\!Q_{\\alpha\\beta} = 0$ and ${}^{(4)}\\!Q_{\\alpha\\beta} = 0$, and we are left with\n\\begin{eqnarray}\n{}^{(1)}\\!Q_{\\alpha\\beta} &=& -\\,{\\frac 43}kk_{(\\alpha}\\!\\pW_{\\beta)}\n- {\\frac 23}k_\\alpha k_\\beta\\!\\pW_\\gamma\\!\\vartheta^\\gamma\\nonumber\\\\\n&& +\\,{\\frac 43}kk_{(\\alpha}u_{\\beta)} + {\\frac 23}k_\\alpha k_\\beta\\,u,\\label{nonW1}\\\\\n{}^{(2)}\\!Q_{\\alpha\\beta} &=& -\\,{\\frac 23}kk_{(\\alpha}\\!\\pW_{\\beta)} \n+ {\\frac 23}k_\\alpha k_\\beta\\!\\pW_\\gamma\\!\\vartheta^\\gamma\\nonumber\\\\\n&& -\\,{\\frac 43}kk_{(\\alpha}u_{\\beta)} + {\\frac 43}k_\\alpha k_\\beta\\,u.\\label{nonW2}\n\\end{eqnarray}\n\nFinally, the structure of the curvature $R^{\\alpha\\beta} = W^{\\alpha\\beta} + Z^{\\alpha\\beta}$ is as follows. Five irreducible pieces are trivial, ${}^{(3)}\\!W^{\\alpha\\beta} = {}^{(5)}\\!W^{\\alpha\\beta} = {}^{(6)}\\!W^{\\alpha\\beta} = 0$, and ${}^{(3)}\\!Z^{\\alpha\\beta} = {}^{(5)}\\!Z^{\\alpha\\beta} = 0$, whereas for $I = 1,2,4$ we derive\n\\begin{eqnarray}\n{}^{(I)}\\!W^{\\alpha\\beta} &=& k\\wedge {}^{(I)}\\!\\!\\mOm{\\!}^{[\\alpha}k^{\\beta]},\\label{curW124}\\\\\n{}^{(1)}\\!Z^{\\alpha\\beta} &=& {\\frac 12}k\\wedge {}^{(1)}\\!\\!\\pOm{\\!}^{(\\alpha}k^{\\beta)}\n+ {\\frac 14}k^\\alpha k^\\beta\\, \\vartheta_\\gamma\\wedge\\pOm{\\!}^\\gamma \\nonumber\\\\\n&& +\\,{\\frac 12}k\\,\\wedge\\pOm{\\!}^{(\\alpha}k^{\\beta)}\\nonumber\\\\\n&& +\\,{\\frac 12}k\\wedge k^{(\\alpha}e^{\\beta)}\\rfloor du + {\\frac 12}k^\\alpha k^\\beta du,\\label{ZW1}\\\\\n{}^{(2)}\\!Z^{\\alpha\\beta} &=& {\\frac 12}k\\wedge {}^{(2)}\\!\\!\\pOm{\\!}^{(\\alpha}k^{\\beta)}\n-  {\\frac 14}k^\\alpha k^\\beta\\, \\vartheta_\\gamma\\wedge\\pOm{\\!}^\\gamma\\nonumber\\\\\n&& -\\,{\\frac 12}k\\wedge k^{(\\alpha}e^{\\beta)}\\rfloor du + {\\frac 12}k^\\alpha k^\\beta du,\\label{ZW2}\\\\\n{}^{(4)}\\!Z^{\\alpha\\beta} &=& {\\frac 12}k\\wedge {}^{(4)}\\!\\!\\pOm{\\!}^{(\\alpha}k^{\\beta)}.\\label{ZW4}\n\\end{eqnarray}\nThese are constructed in terms of the irreducible parts\n\\begin{equation}\\label{Omm}\n\\pmOm{\\!}^\\alpha = {}^{(1)}\\!\\!\\pmOm{\\!}^\\alpha + {}^{(2)}\\!\\!\\pmOm{\\!}^\\alpha + {}^{(4)}\\!\\!\\pmOm{\\!}^\\alpha,\n\\end{equation}\nwhich read explicitly: \n\\begin{eqnarray}\n{}^{(1)}\\!\\!\\pmOm{\\!}^\\alpha &:=& {\\frac 12}\\left(\\pmOm{\\!}^\\alpha - \\vartheta^\\alpha e_\\beta\\rfloor\n\\pmOm{\\!}^\\beta + \\vartheta^\\beta e^\\alpha\\rfloor\\pmOm{\\!}_\\beta\\right),\\label{OM1}\\\\\n{}^{(2)}\\!\\!\\pmOm{\\!}^\\alpha &:=& {\\frac 12}\\left(\\pmOm{\\!}^\\alpha - \\vartheta^\\beta e^\\alpha\\rfloor\n\\pmOm{\\!}_\\beta\\right),\\label{OM2}\\\\\n{}^{(4)}\\!\\!\\pmOm{\\!}^\\alpha &:=& {\\frac 12}\\,\\vartheta^\\alpha e_\\beta\\rfloor\\pmOm{\\!}^\\beta.\\label{OM4}\n\\end{eqnarray}\nThe transversal components of these objects are symmetric traceless part, skew-symmetric part and the trace of the $2\\times 2$ matrix $\\partial_B\\!\\pmW{\\!}^A$, respectively. Using (\\ref{THOMa}), we derive ${}^{(I)}\\!\\!\\pmOm{\\!}^A = {}^{(I)}\\!\\!\\pmOm{\\!}^A{}_B\\,\\vartheta^B$, with\n\\begin{eqnarray}\n{}^{(1)}\\!\\!\\pmOm{\\!}^A{}_B &=& {\\frac 12}\\!\\left(\\!\\partial_B\\!\\pmW{\\!}^A + \\partial^A\\!\\pmW{\\!}_B\n- \\delta^A_B\\,\\partial_C\\!\\pmW{\\!}^C\\!\\right)\\!,\\label{OMAB1}\\\\\n{}^{(2)}\\!\\!\\pmOm{\\!}^A{}_B &=& {\\frac 12}\\!\\left(\\!\\partial_B\\!\\pmW{\\!}^A - \\partial^A\\!\\pmW{\\!}_B\\!\\right)\\!,\\label{OMAB2}\\\\\n{}^{(4)}\\!\\!\\pmOm{\\!}^A{}_B &=& {\\frac 12}\\,\\delta^A_B\\,\\partial_C\\!\\pmW{\\!}^C.\\label{OMAB4}\n\\end{eqnarray}\n\nOne can demonstrate the following properties of these 1-forms:\n\\begin{eqnarray}\\label{vOM}\n\\vartheta_\\alpha\\wedge{}^{(1)}\\!\\Omega^\\alpha = 0,\\quad \\vartheta_\\alpha\\wedge{}^{(2)}\\!\\Omega^\\alpha \n= \\vartheta_\\alpha\\wedge\\Omega^\\alpha,\\\\\n\\vartheta_\\alpha\\wedge{}^{(4)}\\!\\Omega^\\alpha = 0,\\quad\ne_\\alpha\\rfloor{}^{(1)}\\!\\Omega^\\alpha = -\\,e_\\alpha\\rfloor\\Omega^\\alpha,\\\\ \ne_\\alpha\\rfloor{}^{(2)}\\!\\Omega^\\alpha = 0,\\quad e_\\alpha\\rfloor{}^{(4)}\\!\\Omega^\\alpha = \n2e_\\alpha\\rfloor\\Omega^\\alpha,\\label{eOM}\\\\\nk_\\alpha{}^{(1)}\\!\\Omega^\\alpha = -\\,{\\frac 12}\\,k\\,e_\\alpha\\rfloor\\Omega^\\alpha,\\quad\nk_\\alpha{}^{(2)}\\!\\Omega^\\alpha = 0,\\label{kOM1}\\\\\nk_\\alpha{}^{(4)}\\!\\Omega^\\alpha = {\\frac 12}\\,k\\,e_\\alpha\\rfloor\\Omega^\\alpha,\n\\quad k\\wedge{}^*{}^{(2)}\\!\\Omega^\\alpha = 0,\\label{kOM4}\\\\\nk\\wedge{}^*{}^{(1)}\\!\\Omega^\\alpha = -\\, k\\wedge{}^*{}^{(4)}\\!\\Omega^\\alpha = \n-\\,{\\frac 12}\\,k^\\alpha\\,\\vartheta_\\beta\\wedge{}^*\\Omega^\\beta.\\label{kdOM}\n\\end{eqnarray}\nTo make formulas more compact, we omit the $^{(\\pm)}$ labels because the above properties hold for both types of $\\Omega$'s.\n\nIt is worthwhile to notice that although some of the irreducible parts (\\ref{OM1})-(\\ref{OM4}) are not orthogonal to the wave covector, in view of (\\ref{kOM1}) and (\\ref{kOM4}), all irreducible parts of the curvature and nonmetricity satisfy\n\\begin{equation}\nk_\\alpha {}^{(I)}\\!W^{\\alpha\\beta} = 0,\\quad k_\\alpha {}^{(I)}\\!Z^{\\alpha\\beta} = 0,\\quad\nk_\\alpha {}^{(I)}\\!Q^{\\alpha\\beta} = 0,\\label{kWZQ}\n\\end{equation}\nin full agreement with (\\ref{kTRW2}). \n\n\n\\section{Explicit field equations}\\label{MAGE}\n\n\nFor the Lagrangian (\\ref{LRT}) from the definitions (\\ref{Mab}) and (\\ref{Ha}), we find explicitly the gravitational field momenta\n\\begin{eqnarray}\nM^{\\alpha\\beta} &=& {\\frac {2}{\\kappa c}}\\,m^{\\alpha\\beta},\\qquad\nH_\\alpha = {\\frac {1}{\\kappa c}}\\,h_\\alpha,\\label{MH}\\\\\nm^{\\alpha\\beta} &=& \\sum_{I=1}^4 b_I\\,{}^*({}^{(I)}Q^{\\alpha\\beta})\\nonumber\\\\\n&& +\\,b_5\\Bigl[ \\vartheta^{(\\alpha}\\wedge e^{\\beta)}\\rfloor {}^*Q - {\\frac 14}g^{\\alpha\\beta}\\,{}^*(\\Lambda + 3Q)\\Bigr]\\nonumber\\\\\n&& -\\,c_1\\vartheta^{(\\alpha}\\wedge {}^*T^{\\beta)} \n+ {\\frac {c_1 + c_2}{3}}\\vartheta^{(\\alpha}\\wedge e^{\\beta)}\\rfloor {}^*T\\nonumber\\\\\n&& +\\, {\\frac {2c_1 - c_2 - c_3}{4}}g^{\\alpha\\beta}\\,{}^*T,\\label{LMab}\\\\\nh_{\\alpha} &=& \\sum_{I=1}^3 a_I\\,{}^*({}^{(I)}T_\\alpha)\\nonumber\\\\\n&& +\\,\\sum_{I=1}^3 c_I\\,{}^*(\\vartheta^\\beta\\wedge {}^{(I+1)}Q_{\\alpha\\beta}).\\label{LHa}\n\\end{eqnarray}\nFor the MAG wave ansatz, these are reduced to \n\\begin{eqnarray}\nm^{\\alpha\\beta} &=& {}^*\\!\\Bigl[b_1{}^{(1)}Q^{\\alpha\\beta} \n+ b_2{}^{(2)}Q^{\\alpha\\beta} + c_1e^{(\\alpha}\\rfloor T^{\\beta)}\\Bigr],\\label{GWMab}\\\\\nh_{\\alpha} &=& {}^*\\!\\Bigl[a_1\\,T_\\alpha\n- c_1\\,{}^{(2)}Q_{\\alpha\\beta}\\wedge\\vartheta^\\beta\\Bigr].\\label{GWHa}\n\\end{eqnarray}\nA direct computation from the definition (\\ref{Hab}) for the Lagrangian (\\ref{LRT}) yields, by inserting the MAG wave ansatz:\n\\begin{equation}\nH^\\alpha{}_\\beta = -\\,{\\frac {a_0}{2\\kappa c}}\\,\\eta^\\alpha{}_\\beta\n+ {\\frac 1\\rho}\\,h^\\alpha{}_\\beta,\\label{HH}\n\\end{equation}\nwhere $h_{\\alpha\\beta} = h_{[\\alpha\\beta]} + h_{(\\alpha\\beta)}$ explicitly read\n\\begin{widetext}\n\\begin{eqnarray}\nh_{[\\alpha\\beta]} &=& {}^*\\Bigl[w_1{}^{(1)}\\!W_{\\alpha\\beta} + w_2{}^{(2)}\\!W_{\\alpha\\beta}\n  + w_4{}^{(4)}\\!W_{\\alpha\\beta}\n  + {\\frac {v_2}{2}}\\,\\vartheta_\\gamma\\wedge e_{[\\alpha}\\rfloor {}^{(2)}\\!Z^\\gamma{}_{\\beta]} + \n{\\frac {v_4}{2}}\\,\\vartheta_{[\\alpha}\\wedge e_{|\\gamma|}\\rfloor {}^{(4)}\\!Z^\\gamma{}_{\\beta]}\\Bigr],\\label{HAGW}\\\\\nh_{(\\alpha\\beta)} &=& {}^*\\Bigl[z_1{}^{(1)}\\!Z_{\\alpha\\beta}\n+ (z_2 - v_2){}^{(2)}\\!Z_{\\alpha\\beta} + (z_4 + 2v_4){}^{(4)}\\!Z_{\\alpha\\beta} \n+ {\\frac {v_2}{2}}\\,\\vartheta_\\gamma\\wedge e_{(\\alpha}\\rfloor {}^{(2)}\\!W^\\gamma{}_{\\beta)} + \n{\\frac {v_4}{2}}\\,\\vartheta_{(\\alpha}\\wedge e_{|\\gamma|}\\rfloor {}^{(4)}\\!W^\\gamma{}_{\\beta)}\\Bigr].\\label{HSGW}\n\\end{eqnarray}\nSplitting the Lagrangian (\\ref{LRT}) into the linear Hilbert-Einstein term and the purely quadratic part, $V = {\\frac {a_0}{2\\kappa c}}\\,\\eta_{\\alpha\\beta}\\wedge R^{\\alpha\\beta} + {\\frac {1}{\\kappa c}}\\,V^{(q)}$, we derive from (\\ref{Ea})\n\\begin{equation}\\label{Ea1}\nE_\\alpha = {\\frac {a_0}{2\\kappa c}}\\,\\eta_{\\alpha\\beta\\gamma}\\wedge R^{\\beta\\gamma}\n+ {\\frac {1}{\\kappa c}}\\,q_\\alpha,\n\\end{equation}\nwhere we introduced\n\\begin{eqnarray}\nq_{\\alpha} := e_{\\alpha}\\rfloor V^{(q)} + (e_{\\alpha}\\rfloor T^{\\beta})\\wedge h_{\\beta}\n+ \\ell_\\rho^2\\,(e_{\\alpha}\\rfloor R_{\\beta}{}^{\\gamma})\\wedge h^{\\beta}{}_{\\gamma}\n + (e_{\\alpha}\\rfloor Q_{\\beta\\gamma})\\,m^{\\beta\\gamma}.\\label{qa}\n\\end{eqnarray}\n\\end{widetext}\nWith an account of (\\ref{MH}), (\\ref{HH}), and (\\ref{Ea1}), the MAG field equations (\\ref{dVt}) and (\\ref{dVG}) in vacuum (assuming the vanishing matter sources $\\Sigma_\\alpha = 0$ and $\\Delta^\\alpha{}_\\beta = 0$) are recast into the following form:\n\\begin{eqnarray}\n{\\frac {a_0}{2}}\\,\\eta_{\\alpha\\beta\\gamma}\\wedge R^{\\beta\\gamma} + q_\\alpha - Dh_\\alpha = 0,\\label{1st}\\\\\n{\\frac {a_0}{2}}\\,D\\eta^\\alpha{}_\\beta - \\vartheta^\\alpha\\wedge h_\\beta\n- 2m^\\alpha{}_\\beta - \\ell_\\rho^2\\,Dh^\\alpha{}_\\beta = 0.\\label{2nd}\n\\end{eqnarray}\nThe first term in (\\ref{2nd}) is straightforwardly evaluated\n\\begin{eqnarray}\nD\\eta^\\alpha{}_\\beta = D(g^{\\alpha\\gamma}\\eta_{\\gamma\\beta}) = \\eta^\\alpha{}_{\\beta\\gamma}\\wedge T^\\gamma\\nonumber\\\\\n+ \\,Q^{\\alpha\\gamma}\\wedge\\eta_{\\gamma\\beta} - 2Q\\wedge\\eta^\\alpha{}_\\beta.\\label{deta}\n\\end{eqnarray}\n\nIn view of (\\ref{kWZQ}), we verify the orthogonality properties for (\\ref{MH}), (\\ref{HAGW}) and (\\ref{HSGW}):\n\\begin{equation}\nk_\\alpha m^{\\alpha\\beta} = 0,\\quad k^\\alpha h_\\alpha = 0,\\quad k^\\alpha h_{[\\alpha\\beta]} = 0,\n\\quad k^\\alpha h_{(\\alpha\\beta)} = 0.\\label{kmhh}\n\\end{equation}\nAs a result, for (\\ref{qa}) we derive\n\\begin{equation}\nq_\\alpha = 0\\label{qaW}\n\\end{equation}\nfor the MAG wave field strengths (\\ref{nonW})-(\\ref{curW}). Moreover, substituting (\\ref{curW124})-(\\ref{ZW4}) into (\\ref{HAGW}) and (\\ref{HSGW}), we recast the latter into\n\\begin{eqnarray}\nh_{[\\alpha\\beta]} &=& {}^*(k\\wedge{\\stackrel {(w)}\\Sigma}{}_{[\\alpha})\\,k_{\\beta]},\\label{HAGW1}\\\\\nh_{(\\alpha\\beta)} &=& {}^*(k\\wedge{\\stackrel {(z)}\\Sigma}{}_{(\\alpha})\\,k_{\\beta)}\n+ {\\frac 14}\\,k_\\alpha k_\\beta\\,{}^*\\!\\Sigma,\\label{HSGW1}\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\n{\\stackrel {(w)}\\Sigma}{}_\\alpha &:=& w_1{}^{(1)}\\!\\!\\mOm{\\!}_\\alpha + w_2{}^{(2)}\\!\\!\\mOm{\\!}_\\alpha\n+ w_4{}^{(4)}\\!\\!\\mOm{\\!}_\\alpha \\nonumber\\\\\n&& - \\,{\\frac {v_2}2}{}^{(2)}\\!\\!\\pOm{\\!}_\\alpha + {\\frac {v_4}2}{}^{(4)}\\!\\!\\pOm{\\!}_\\alpha\n+ {\\frac {v_2}2}e_\\alpha\\rfloor\\underline{d}u,\\label{Lw}\\\\\n{\\stackrel {(z)}\\Sigma}{}_\\alpha &:=& z_1{}^{(1)}\\!\\!\\pOm{\\!}_\\alpha\n+ \\,{\\frac {z_1 + z_2 - v_2}2}{}^{(2)}\\!\\!\\pOm{\\!}_\\alpha\\nonumber\\\\\n&& + {\\frac {z_1 + z_4 + 2v_4}2}{}^{(4)}\\!\\!\\pOm{\\!}_\\alpha \\nonumber\\\\\n&& -\\,{\\frac {v_2}2}{}^{(2)}\\!\\!\\mOm{\\!}_\\alpha + {\\frac {v_4}2}{}^{(4)}\\!\\!\\mOm{\\!}_\\alpha\\nonumber\\\\\n&& +\\,{\\frac {z_1 - z_2 + v_2}2}\\,e_\\alpha\\rfloor\\underline{d}u,\\label{Lz}\\\\\n\\Sigma &:=& \\vartheta^\\gamma\\wedge [(z_1 - z_2 + v_2)\\pOm{\\!}_\\gamma + v_2\\mOm{\\!}_\\gamma]\\nonumber\\\\\n&& + \\,4z_1k\\wedge\\dot{u} + 2(z_1 + z_2 - v_2)\\underline{d}u.\\label{L}\n\\end{eqnarray}\nIn a similar way, substituting (\\ref{torW}) and (\\ref{nonW1})-(\\ref{nonW2}) into (\\ref{GWMab}) and (\\ref{GWHa}), we recast the latter into\n\\begin{eqnarray}\nm^{\\alpha\\beta} &=& {}^*(k\\wedge\\mu^{(\\alpha})\\,k^{\\beta)} - k^\\alpha k^\\beta\\,{}^*\\!\\mu,\\label{GWMab1}\\\\\nh_{\\alpha} &=& -\\,k_\\alpha\\,{}^*\\!\\Bigl[k\\wedge(a_1\\,\\Theta - c_1\\,{\\stackrel {(+)}W}{}_\\beta\n\\vartheta^\\beta - 2c_1\\,u)\\Bigr],\\label{GWHa1}\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\n\\mu_\\alpha &:=& c_1\\,e_\\alpha\\rfloor\\Theta - {\\frac {4b_1 + 2b_2}{3}}{\\stackrel {(+)}W}{}_\\alpha\n+ {\\frac {4(b_1 - b_2)}{3}}u_\\alpha,\\label{mua}\\\\\n\\mu &:=& c_1\\,\\Theta + {\\frac {2b_1 - 2b_2}{3}}{\\stackrel {(+)}W}{}_\\beta\\vartheta^\\beta\n- {\\frac {2b_1 + 4b_2}{3}}\\,u.\\label{mu}\n\\end{eqnarray}\nIn view of (\\ref{kphi}), the structure of the 2-forms (\\ref{HAGW1}), (\\ref{HSGW1}) and (\\ref{GWHa1}) guarantees that\n\\begin{equation}\n\\Gamma_\\alpha{}^\\beta\\wedge h_\\beta = 0,\\quad \\Gamma_\\alpha{}^\\beta\\wedge h_{[\\beta\\gamma]} = 0,\\quad\n\\Gamma_\\alpha{}^\\beta\\wedge h_{(\\beta\\gamma)} = 0,\\label{Ghh}\n\\end{equation}\nfor the connection (\\ref{conW}), and therefore the covariant derivatives are reduced to the ordinary ones:\n\\begin{equation}\nDh_\\alpha = dh_\\alpha,\\qquad Dh^\\alpha{}_\\beta = dh^\\alpha{}_\\beta.\\label{Dhdh}\n\\end{equation}\nWith an account of (\\ref{qaW}), (\\ref{deta}) and (\\ref{Dhdh}), we can recast the MAG field equations (\\ref{1st}) and (\\ref{2nd}) into the final form\n\\begin{eqnarray}\n{\\frac {a_0}{2}}\\,\\eta_{\\alpha\\beta\\gamma}\\wedge R^{\\beta\\gamma} - dh_\\alpha &=& 0,\\label{1stF}\\\\\n{\\frac {a_0}{2}}\\,(\\eta_{\\alpha\\beta\\gamma}\\wedge T^\\gamma + Q_{[\\alpha}{}^\\gamma\\wedge\\eta_{|\\gamma|\\beta]})&&\\nonumber\\\\\n- \\,\\vartheta_{[\\alpha}\\wedge h_{\\beta]} - \\ell_\\rho^2\\,dh_{[\\alpha\\beta]} &=& 0,\\label{2nd1}\\\\\n{\\frac {a_0}{2}}\\,Q_{(\\alpha}{}^\\gamma\\wedge\\eta_{|\\gamma|\\beta)} - \\vartheta_{(\\alpha}\\wedge h_{\\beta)}&&\\nonumber\\\\\n- \\,2m_{\\alpha\\beta} - \\ell_\\rho^2\\,dh_{(\\alpha\\beta)} &=& 0.\\label{2nd2}\n\\end{eqnarray}\nAfter making use of (\\ref{Dhdh}), we have lowered the upper index and split the resulting equation into the symmetric and skew-symmetric equations to derive (\\ref{2nd1}) and (\\ref{2nd2}).\n\nIt thus remains to plug (\\ref{HAGW1})-(\\ref{mu}) into the field equations (\\ref{1stF})-(\\ref{2nd2}) and solve the system of coupled equations. It is worthwhile to notice the remarkable fact that the final system is a set of {\\it linear} differential equations for the unknown functions $U = U(\\sigma, x^B)$, $W^A = W^A(\\sigma, x^B)$, $V^A = V^A(\\sigma, x^B)$, and $u_A = u_A(\\sigma, x^B)$.\n\n\n\\subsection{First field equation}\\label{mag1}\n\n\nMaking use of (\\ref{WW}) we find\n\\begin{eqnarray}\n\\eta_{\\alpha\\beta\\gamma}\\wedge R^{\\beta\\gamma} &=& \\eta_{\\alpha\\beta\\gamma}\\wedge W^{\\beta\\gamma} = \n\\eta_{\\alpha\\beta\\gamma}\\wedge k\\,\\wedge \\mOm{\\!}^\\beta k^\\gamma \\nonumber\\\\\n&=& k_\\alpha\\,{}^*k\\,e_\\beta\\rfloor \\mOm{\\!}^\\beta.\\label{HE}\n\\end{eqnarray}\nOn the other hand, we have, see (\\ref{GWHa1}), $h_{\\alpha} = -\\,k_\\alpha\\,{}^*(k\\wedge\\Xi)$ with\nthe {\\it transversal} 1-form\n\\begin{equation}\n\\Xi := a_1\\,\\Theta - c_1\\,{\\stackrel {(+)}W}{}_\\beta \\vartheta^\\beta - 2c_1\\,u,\\label{XI}\n\\end{equation}\nand in view of (\\ref{kphi}), we evaluate the exterior differential \n\\begin{equation}\ndh_\\alpha = k_\\alpha k\\wedge \\underline{d}\\,{}^{\\underline{*}}\\Xi.\\label{dh}\n\\end{equation}\nIt is worthwhile to note that although $\\Xi$ depends on $\\sigma$, we have for the total differential\n\\begin{equation}\nd\\,{}^{\\underline{*}}\\Xi = d\\sigma\\wedge\\partial_\\sigma({}^{\\underline{*}}\\Xi)\n+ \\underline{d}\\,{}^{\\underline{*}}\\Xi,\\label{dXi}\n\\end{equation}\nand thus the first term drops out from (\\ref{dh}) since $d\\sigma = k$, cf. (\\ref{kdef}).\n\nFinally, by using the dual (\\ref{dualk}), we recast the first MAG field equation (\\ref{1stF}) into\n\\begin{equation}\n-\\,k_\\alpha k\\wedge \\Bigl\\{{\\frac {a_0}{2}}\\,\\underline{\\eta}\\,e_\\beta\\rfloor\\!\\mOm{\\!}^\\beta\n+ \\underline{d}\\,{}^{\\underline{*}}\\Xi\\Bigr\\} = 0.\\label{1stF1}\n\\end{equation}\n\n\n\\subsection{Second field equation}\\label{mag2}\n\n\nSince $\\vartheta_\\alpha\\wedge h_\\beta = {}^*(e_\\alpha\\rfloor{}^*h_\\beta)$, a direct computation yields,\nwith the help of (\\ref{nonW}) and (\\ref{torW}):\n\\begin{eqnarray}\n{\\frac {a_0}{2}}\\,\\eta_{\\alpha\\beta\\gamma}\\wedge T^\\gamma &=& a_0\\,{}^*k\\,e_{[\\alpha}\\rfloor\\Theta\\,k_{\\beta]},\\label{etaT}\\\\\n{\\frac {a_0}{2}}Q_\\alpha{}^\\gamma\\wedge\\eta_{\\gamma\\beta} - \\vartheta_\\alpha\\wedge h_\\beta\n&=& {}^*(k\\nu_\\alpha) k_\\beta - k_\\alpha k_\\beta {}^*\\nu\\nonumber\\\\\n&& +\\,a_0\\,{}^*k\\,k_\\alpha u_\\beta,\\label{Qeta}\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\n\\nu_\\alpha &:=& a_1\\,e_\\alpha\\rfloor\\Theta - ({\\frac {a_0}{2}} + c_1)\\,{\\stackrel {(+)}W}{}_\\alpha\n- 2c_1 u_\\alpha,\\label{nua}\\\\\n\\nu &:=& a_1\\,\\Theta + ({\\frac {a_0}{2}} - c_1)\\,{\\stackrel {(+)}W}{}_\\beta\\vartheta^\\beta\n- 2c_1\\,u.\\label{nu}\n\\end{eqnarray}\nAs a result, for the second MAG field equations (\\ref{2nd1}) and (\\ref{2nd2}) we find \n\\begin{eqnarray}\n{\\frac {a_0}{2}}\\,(\\eta_{\\alpha\\beta\\gamma}\\wedge T^\\gamma + Q_{[\\alpha}{}^\\gamma\\wedge\\eta_{|\\gamma|\\beta]})\n- \\,\\vartheta_{[\\alpha}\\wedge h_{\\beta]} \\nonumber\\\\\n= {}^*k\\left(a_0\\,e_{[\\alpha}\\rfloor\\Theta + \\nu_{[\\alpha} - a_0u_{[\\alpha}\\right)k_{\\beta]},\\label{etaT1}\\\\\n{\\frac {a_0}{2}}\\,Q_{(\\alpha}{}^\\gamma\\wedge\\eta_{|\\gamma|\\beta)} - \\vartheta_{(\\alpha}\\wedge h_{\\beta)}\\nonumber\\\\\n= {}^*k\\,(\\nu_{(\\alpha} + a_0u_{(\\alpha})\\, k_{\\beta)} - k_\\alpha k_\\beta {}^*\\nu.\\label{Qeta1}\n\\end{eqnarray}\n\nFinally, the differentials of (\\ref{HAGW1}) and (\\ref{HSGW1}) read\n\\begin{eqnarray}\ndh_{[\\alpha\\beta]} &=& -\\,k\\wedge \\underline{d}\\,{}^{\\underline{*}}\n{\\stackrel {(w)}\\Sigma}{}_{[\\alpha}\\,k_{\\beta]},\\label{dha}\\\\\ndh_{(\\alpha\\beta)} &=& d\\,{}^*(k\\wedge{\\stackrel {(z)}\\Sigma}{}_{(\\alpha})\\,k_{\\beta)}\n+ {\\frac 14}\\,k_\\alpha k_\\beta\\,d\\,{}^*\\!\\Sigma,\\label{dhS}\n\\end{eqnarray}\nwhere we used (\\ref{kphi}) once again. Note that in (\\ref{dhS}) we have the full differential, unlike the transversal one in (\\ref{dha}), and evaluation of the latter is somewhat nontrivial. \n\nWhen writing down the field equations, we have to specialize to the subsets of the indices: $\\alpha = (a, A)$, with lower case Latin indices $a = 0,1$ and the upper case indices $A = 2,3$.\n\nAs a preliminary step, we recall that\n\\begin{equation}\nk_A = 0,\\label{kA0}\n\\end{equation}\nand notice that\n\\begin{eqnarray}\n{}^{(1)}\\!\\pmOm{\\!}^a &=& -\\,{\\frac 12}\\,\\vartheta^a\\,e_\\beta\\rfloor\\!\\pmOm{\\!}^\\beta,\\label{pmOm1}\\\\\n{}^{(2)}\\!\\pmOm{\\!}^a &=& 0,\\label{pmOm2}\\\\\n{}^{(4)}\\!\\pmOm{\\!}^a &=& {\\frac 12}\\,\\vartheta^a\\,e_\\beta\\rfloor\\!\\pmOm{\\!}^\\beta,\\label{pmOm4}\n\\end{eqnarray}\nwhereas ${}^{(I)}\\!\\!\\pmOm{\\!}^A$ are purely transversal for all $I = 1,2,4$.\n\nAs a result, from (\\ref{Lw}) and (\\ref{Lz}) we conclude that ${\\stackrel {(w)}\\Sigma}{}_A$ and ${\\stackrel {(z)}\\Sigma}{}_A$ are purely transversal, while\n\\begin{eqnarray}\n{\\stackrel {(w)}\\Sigma}{}_a = {\\frac 14}\\,\\vartheta_a{\\stackrel {(w)}\\varphi},\\qquad\n{\\stackrel {(z)}\\Sigma}{}_a = {\\frac 14}\\,\\vartheta_a{\\stackrel {(z)}\\varphi},\\label{Lwza}\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\n{\\stackrel {(w)}\\varphi} &:=& 2(w_4 - w_1)\\,e_\\beta\\rfloor\\!\\mOm{\\!}^\\beta\n+ v_4\\,e_\\beta\\rfloor\\!\\pOm{\\!}^\\beta,\\label{phiw}\\\\\n{\\stackrel {(z)}\\varphi} &:=& (z_4 - z_1 + 2v_4)\\,e_\\beta\\rfloor\\!\\pOm{\\!}^\\beta\n+ v_4\\,e_\\beta\\rfloor\\!\\mOm{\\!}^\\beta.\\label{phiz}\n\\end{eqnarray}\n\nThen, for (\\ref{HAGW1}) we find\n\\begin{eqnarray}\nh_{[ab]} &=& 0,\\qquad h_{[AB]} = 0,\\label{habA1}\\\\\nh_{[Ab]} &=& {\\frac 12}\\,{}^*(k\\wedge{\\stackrel {(w)}\\Sigma}{}_A)k_b = \n{\\frac 12}\\,k\\wedge{}^{\\underline{*}}{\\stackrel {(w)}\\Sigma}{}_A\\,k_b.\\label{habA2}\n\\end{eqnarray}\nThe structure of (\\ref{HSGW1}) is more nontrivial:\n\\begin{eqnarray}\nh_{(ab)} &=& {}^*(k\\wedge{\\stackrel {(z)}\\Sigma}{}_{(a})\\,k_{b)} + {\\frac 14}\\,k_a k_b\\,{}^*\\Sigma\\nonumber\\\\\n&=& {\\frac 14}\\,k_a k_b\\Bigl\\{{}^*\\Sigma - {\\stackrel {(z)}\\varphi}\\,\\underline{\\eta}\\Bigr\\},\\label{habS1}\\\\\nh_{(Ab)} &=& {\\frac 12}\\,{}^*(k\\wedge{\\stackrel {(z)}\\Sigma}{}_A)\\,k_b = \n{\\frac 12}\\,k\\wedge{}^{\\underline{*}}{\\stackrel {(z)}\\Sigma}{}_A\\,k_b.\\label{habS2}\\\\\nh_{(AB)} &=& 0.\\label{habS3}\n\\end{eqnarray}\nHere we used (\\ref{Lwza}) and  \n\\begin{equation}\n{}^*(k\\wedge\\vartheta_a) = e_a\\rfloor{}^*k = -\\,k_a\\,\\underline{\\eta}.\\label{kaeta}\n\\end{equation}\n\nAfter these preparations, we are in a position to write down the second MAG field equations. The skew-symmetric part (\\ref{2nd1}) has only only ``$[Ab]$'' nontrivial component which reads explicitly\n\\begin{equation}\nk\\wedge\\Bigl\\{\\underline{\\eta}\\left(a_0\\,e_A\\rfloor\\Theta + \\nu_A - a_0u_A\\right) - \\ell_\\rho^2\n\\,\\underline{d}\\,{}^{\\underline{*}}{\\stackrel {(w)}\\Sigma}{}_A\\Bigr\\} k_b = 0.\\label{2nd10}\n\\end{equation}\nHowever, the symmetric part (\\ref{2nd2}) encompasses two nontrivial components, ``$(ab)$'' and\n``$(Ab)$'', respectively:\n\\begin{eqnarray}\nk_ak_b\\Bigl\\{ {}^*(2\\mu - \\nu) - {\\frac {\\ell_\\rho^2}4}\\,d\\,({}^*\\Sigma - {\\stackrel {(z)}\\varphi}\n\\,\\underline{\\eta})\\Bigr\\} &=& 0,\\label{2nd21}\\\\\nk\\wedge\\Bigl\\{\\underline{\\eta}\\left(\\nu_A - 2\\mu_A + a_0\\,u_A\\right) - \\ell_\\rho^2\n\\,\\underline{d}\\,{}^{\\underline{*}}{\\stackrel {(z)}\\Sigma}{}_A\\Bigr\\} k_b &=& 0.\\label{2nd22}\n\\end{eqnarray}\n\n\n\\subsection{Explicit MAG field equations in components}\\label{magc}\n\n\nTo begin with, let us fix the notation. Namely, we choose the {\\it original} position of indices for the vector objects as upper position for $W^\\alpha$ and $V^\\alpha$, and lower position for $u_\\alpha$. In other words, the basic variables will be chosen as\n\\begin{equation}\nW^A,\\qquad V^A,\\qquad u_A.\\label{WVu0}\n\\end{equation}\nThen we denote these objects with the indices moved to a different position as\n\\begin{equation}\n\\underline{W}_A := \\delta_{AB}W^B,\\quad \\underline{V}_A := \\delta_{AB}V^B,\n\\quad \\underline{u}^A := \\delta^{AB}u_B.\\label{WVu1}\n\\end{equation}\nIn addition, we denote the differential operator\n\\begin{equation}\n\\underline{\\partial}^A := \\delta^{AB}\\partial_B.\\label{dA}\n\\end{equation}\nThis convention is extremely important when we recast the 4-dimensional expressions in the formulas of the sections above into the 2-dimensional transversal ones. In particular, one should be always careful with $\\partial^\\alpha$, $W_\\alpha$, $V_\\alpha$, and $u^\\alpha$, when we specialize to $\\alpha = A$, since then\n\\begin{equation}\n\\partial^A = -\\,\\underline{\\partial}^A,\\quad W_A = -\\,\\underline{W}_A,\\quad \nV_A = -\\,\\underline{V}_A,\\quad u^A = -\\,\\underline{u}^A.\\label{dWVu}\n\\end{equation}\n\nAs a preliminary step, we observe the Hodge duals\n\\begin{equation}\\label{hodge}\n{}^*\\underline{\\eta} = \\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}},\\qquad {}^*\\underline{\\phi}\n= \\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}}\\wedge{}^{\\underline{*}}\\underline{\\phi},\n\\end{equation}\nwhere the latter is true for any transversal 1-form $\\underline{\\phi}$. It is also worthwhile to notice that $\\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}} = {\\frac 12}\\,d\\sigma\\wedge d\\rho$ and thus the exterior differential vanishes: $d\\left(\\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}}\\right) = 0$.\n\nLet us analyse (\\ref{2nd21}). Since from (\\ref{L}) we have\n\\begin{equation}\\label{Sigma}\n\\Sigma = \\chi\\,\\underline{\\eta} + k\\wedge\\xi,\n\\end{equation}\nthen by making use of (\\ref{hodge}) and (\\ref{kphi}) we obtain for the Hodge dual ${}^*\\Sigma = \\chi\\,\\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}} + k\\wedge {}^{\\underline{*}}\\xi$, and thus\n\\begin{equation}\\label{dSigma}\nd\\,{}^*\\Sigma = \\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}}\\wedge\\underline{d}\\chi\n- k\\wedge \\underline{d}\\,{}^{\\underline{*}}\\xi.\n\\end{equation}\nComparing (\\ref{Sigma}) with (\\ref{L}), we explicitly have for the transversal 1-form $\\xi = 4z_1\\dot{u}$, and \n\\begin{widetext}\n\\begin{equation}\n\\chi = (z_1 - z_2 + 2v_2)\\,\\eta^{AB}\\partial_A\\underline{W}_B + \n(z_1 - z_2)\\,\\eta^{AB}\\partial_A\\underline{V}_B\n+ 2(z_1 + z_2 - v_2)\\,\\eta^{AB}\\partial_Au_B.\\label{chi}\n\\end{equation}\nAs a result, with the help of (\\ref{hodge}) and (\\ref{dSigma}) we recast (\\ref{2nd21}) into\n\\begin{equation}\n\\vartheta^{\\hat{0}}\\wedge\\vartheta^{\\hat{1}}\\wedge\\Bigl\\{ 2{}^{\\underline{*}}\\mu - {}^{\\underline{*}}\\nu\n- {\\frac {\\ell_\\rho^2}4}\\,\\underline{d}\\,\\chi\\Bigr\\} + {\\frac {\\ell_\\rho^2}4}\\,k\\wedge\\Bigl\\{\n\\underline{\\eta}\\,\\partial_\\sigma{\\stackrel {(z)}\\varphi} + \\underline{d}\\,{}^{\\underline{*}}\\xi\n\\Bigr\\} = 0.\\label{2nd21A}\n\\end{equation}\nTherefore, in components this yields two equations:\n\\begin{eqnarray}\n{\\frac {2c_1 - a_1}{2}}\\partial_AU + \\Bigl[ {\\frac {a_0 + 2a_1}{2}} - 3c_1 - {\\frac {4b_1 - 4b_2}{3}}\n\\Bigr]\\underline{W}_A + \\Bigl[ {\\frac {a_0}{2}} - c_1 - {\\frac {4b_1 - 4b_2}{3}} \\Bigr]\n\\underline{V}_A  + \\Bigl[4c_1 - a_1 - {\\frac {4b_1 + 8b_2}{3}}\\Bigr] u_A\\nonumber\\\\\n+ \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\eta_{AB}\\,\\underline{\\partial}^B\\Bigl[(z_1 - z_2 + 2v_2)\\,\n\\eta^{CD}\\partial_C\\underline{W}_D + (z_1 - z_2)\\,\\eta^{CD}\\partial_C\\underline{V}_D\n+ 2(z_1 + z_2 - v_2)\\,\\eta^{CD}\\partial_Cu_D \\Bigr] = 0,\\label{2nd211}\\\\ \n\\partial_\\sigma\\Bigl[(z_4 - z_1 + 3v_4)\\partial_AW^A + (z_4 - z_1 + v_4)\\partial_AV^A \n- 4z_1\\partial_A\\underline{u}^A\\Bigr] = 0.\\label{2nd212}\n\\end{eqnarray}\nIn addition, the two more field equations (\\ref{2nd10}) and (\\ref{2nd22}) read in components:\n\\begin{eqnarray}\n{\\frac {a_0 + a_1}{2}}\\partial_AU + \\Bigl[ c_1 - {\\frac {a_0 + 2a_1}{2}}\\Bigr]\\underline{W}_A\n+ \\Bigl[ {\\frac {a_0}{2}} + c_1\\Bigr]\\underline{V}_A  + \\Bigl[a_1 - 2c_1\\Bigr] u_A\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\Bigl[2w_1\\Delta\\underline{W}_A - 2w_1\\Delta\\underline{V}_A \n+ (2w_4 + v_4)\\partial_A\\partial_BW^B + (-2w_4 + v_4)\\partial_A\\partial_BV^B \\Bigr]\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\eta_{AB}\\,\\underline{\\partial}^B\\Bigl[(- 2w_2 + v_2)\\,\n\\eta^{CD}\\partial_C\\underline{W}_D + (2w_2 + v_2)\\,\\eta^{CD}\\partial_C\\underline{V}_D\n- 2v_2\\,\\eta^{CD}\\partial_Cu_D \\Bigr] & = 0,\\label{2nd11}\n\\end{eqnarray}\n\\begin{eqnarray}\n{\\frac {a_1 - 2c_1}{2}}\\partial_AU + \\Bigl[ {\\frac {a_0}{2}} - a_1 + 3c_1 - {\\frac {8b_1 + 4b_2}{3}}\n\\Bigr]\\underline{W}_A + \\Bigl[ {\\frac {a_0}{2}} + c_1 - {\\frac {8b_1 + 4b_2}{3}}\n\\Bigr]\\underline{V}_A  + \\Bigl[a_0 + a_1 - 4c_1 - {\\frac {8b_1 - 8b_2}{3}}\\Bigr] u_A\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\Bigl[2z_1\\Delta\\underline{W}_A + 2z_1\\Delta\\underline{V}_A \n+ (z_1 + z_4 + 3v_4)\\partial_A\\partial_BW^B + (z_1 + z_4 + v_4)\\partial_A\\partial_BV^B \\Bigr]\\qquad\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\eta_{AB}\\,\\underline{\\partial}^B\\Bigl[(- z_1 - z_2 + 2v_2)\\,\n\\eta^{CD}\\partial_C\\underline{W}_D - (z_1 + z_2)\\,\\eta^{CD}\\partial_C\\underline{V}_D\n- 2(z_1 - z_2 + v_2)\\,\\eta^{CD}\\partial_Cu_D \\Bigr] = 0.\\nonumber\\\\ \\label{2nd12}\n\\end{eqnarray}\nFinally, to make the system complete, we write explicitly the first MAG field equation (\\ref{1stF1}):\n\\begin{equation}\n-\\,{\\frac {a_1}{2}}\\,\\Delta U + \\Bigl[{\\frac {a_0}{2}} - c_1 + a_1\\Bigr]\\partial_AW^A\n- \\Bigl[{\\frac {a_0}{2}} + c_1\\Bigr]\\partial_AV^A - \\Bigl[a_1 - 2c_1\\Bigr]\\partial_A\\underline{u}^A\n = 0.\\label{1stF2}\n\\end{equation}\nThe total number of equations (\\ref{2nd211}), (\\ref{2nd11})-(\\ref{1stF2}) is 7 which is equal to the number unknown variables $U, W^A, V^A, u_A$, so we expect that one can find the latter as functions of transversal coordinates $x^A$. An additional equation (\\ref{2nd212}) does not make the system over-determined, since it merely fixes the dependence on $\\sigma$. \n\\end{widetext}\n\n\n\\section{Solving field equations}\\label{FE}\n\n\nWe are now in a position to solve the field equations. The system (\\ref{2nd211})-(\\ref{1stF2}) always admits a nontrivial solution for the arbitrary quadratic MAG model with any choice of coupling constants. There are some interesting special cases. \n\n\n\\subsection{Riemannian gravitational waves}\n\n\nThe nonmetricity (\\ref{nonW}) and the torsion (\\ref{torW}) vanish when $u = 0$, $\\pW{\\!}^\\alpha = 0$, and $\\Theta = 0$ which is realized for \n\\begin{equation}\nW^A = -\\,V^A = {\\frac 12}\\delta^{AB}\\partial_BU.\\label{notorW}\n\\end{equation}\nSubstituting this into (\\ref{2nd211})-(\\ref{1stF2}), we find that (\\ref{2nd211}) \nis identically satisfied, the first MAG equation (\\ref{1stF2}) reduces to\n\\begin{equation}\n{\\frac {a_0}{2}}\\,\\Delta\\,U = 0,\\label{notW1}\n\\end{equation}\nwhereas (\\ref{2nd212})-(\\ref{2nd12}) reduce to \n\\begin{eqnarray}\nv_4\\,\\partial_\\sigma\\,\\Delta\\,U &=& 0,\\label{notW0}\\\\\n-\\,2(w_1 + w_4)\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\partial_A\\,\\Delta\\,U &=& 0,\\label{notW2}\\\\\n-\\,v_4\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\partial_A\\,\\Delta\\,U &=& 0.\\label{notW3}\n\\end{eqnarray}\nAccordingly, we conclude that the well-known plane wave solution of GR with the function $U$ satisfying the Laplace equation is an exact solution of the generic quadratic MAG model. This is consistent with our earlier results on the torsion-free solutions in Poincar\\'e gauge theory \\cite{selected,Obukhov:1989,yno:2019}.\n\nMoreover, the Riemannian wave (\\ref{notorW})-(\\ref{notW1}) represents a general solution for the purely torsion + nonmetricity quadratic class of MAG models, since this is the only configuration admitted by the system (\\ref{2nd211})-(\\ref{1stF2}) for $w_I = 0$, $z_I = 0$, $v_I = 0$. This is true generically when the curvature square terms are absent, with an exception of a special choice of the coupling constants \\cite{obukhov:1997}:\n\\begin{eqnarray}\n-\\,a_1 = {\\frac {a_2}{2}} = 2a_3 = 2c_1 = - c_2 = - c_3 = a_0,\\label{acex}\\\\\n4b_1 = 2b_2 = - 8b_3 = {\\frac {8b_4}{3}} = 2b_5  = a_0.\\label{bex}\n\\end{eqnarray}\n\n\n\\subsection{Teleparallel gravitational waves}\n\n\nQuite generally, the space of distant parallelism (or the teleparallel space) is defined by the condition of zero curvature, $R_\\alpha{}^\\beta = 0$. In the framework of MAG, the two other gravitational field strengths, torsion and nonmetricity, are nontrivial, and therefore the general teleparallel gravitational waves are characterized by the superposition of propagating torsion and nonmetricity waves, provided the curvature is trivial.\n\nThe curvature (\\ref{curW}) vanishes when $\\underline{d}W^\\alpha = 0$ and $\\underline{d}V^\\alpha = 0$, i.e., both $W^\\alpha = W^\\alpha(\\sigma)$ and $V^\\alpha = V^\\alpha(\\sigma)$ are independent of the transversal coordinates, and in addition $du = 0$. The latter means that the components of $u$ do not depend on $\\sigma$, and\n\\begin{equation}\\label{udU}\nu_A = {\\frac 12}\\,\\partial_A\\,{\\mathcal U}\n\\end{equation}\nis a gradient of a potential ${\\mathcal U} = {\\mathcal U}(x^A)$.\n\nThen (\\ref{2nd212}) is identically fulfilled, and the three equations (\\ref{2nd211}), (\\ref{2nd11}), and (\\ref{2nd12}) after a long but straightforward derivation are recast into an equivalent algebraic system\n\\begin{eqnarray}\n(a_0 - 4b_1)\\,\\Phi_A = 0.\\label{e1}\\\\\n3(a_0 + 2c_1)\\Theta_A + 2(a_0 + 2b_2)\\,\\Psi_A = 0,\\label{e2}\\\\\n2(a_0 + a_1)\\,\\Theta_A + (a_0 + 2c_1)\\,\\Psi_A = 0,\\label{e3}\n\\end{eqnarray}\nwhere we denoted \n\\begin{eqnarray}\n\\Theta_A=e_A\\rfloor\\Theta &=& {\\frac 12}\\partial_AU - \\underline{W}_A + u_A,\\label{thA}\\\\\n\\Phi_A &:=& \\underline{W}_A + \\underline{V}_A + u_A,\\label{phA}\\\\\n\\Psi_A &:=& \\underline{W}_A + \\underline{V}_A - 2u_A.\\label{psA}\n\\end{eqnarray}\n\nIn addition, the equation (\\ref{1stF2}) is reduced to\n\\begin{equation}\na_1\\,\\Delta\\,U + (a_1 - 2c_1)\\,\\Delta\\,{\\mathcal U} = 0.\\label{teleW0}\n\\end{equation}\n\nWriting the system (\\ref{e1})-(\\ref{e3}) in the matrix form,\n\\begin{equation}\n\\left(\\begin{array}{ccc} 0 & (a_0 - 4b_1) & 0 \\\\\n2(a_0 + a_1) & 0 & (a_0 + 2c_1) \\\\\n3(a_0 + 2c_1) & 0 & 2(a_0 + 2b_2) \\end{array}\\right)\n\\left(\\begin{array}{c}\\Theta_A \\\\ \\Phi_A \\\\ \\Psi_A\\end{array}\\right) =  0,\\label{matrix}\n\\end{equation}\nwe conclude that a nontrivial solution exists when the determinant is zero:\n\\begin{equation}\\label{det}\n(a_0 - 4b_1)\\left[3(a_0 + 2c_1)^2 - 4(a_0 + a_1)(a_0 + 2b_2)\\right] = 0.\n\\end{equation}\nThis imposes the restriction on the coupling constants of the general Lagrangian (\\ref{LRT}) and determines the class of MAG models which admit the teleparallel gravitational waves. \n\nThe explanation of the condition (\\ref{det}) is as follows. If the determinant is not zero, then the system (\\ref{e1})-(\\ref{e3}) yields a trivial solution $\\Theta_A = \\Phi_A = \\Psi_A = 0$ which means that all the gravitational field strengths are zero: the curvature $R_\\alpha{}^\\beta = 0$, the nonmetricity $Q_{\\alpha\\beta} = 0$, and the torsion $T^\\alpha =  0$. Therefore such a solution describes the flat Minkowski spacetime. \n\n\n\\subsection{Standard teleparallel waves: no nonmetricity}\n\n\nThe nonmetricity (\\ref{nonW}) vanishes when $u = 0$ and $\\pW{\\!}^\\alpha = 0$, i.e. $W^\\alpha = - V^\\alpha$. This means that $\\Phi_A = \\Psi_A = 0$, and the system (\\ref{e1})-(\\ref{e3}) is greatly simplified. As a result, such a solution only exists in a class of quadratic models restricted by the conditions on the coupling constants\n\\begin{equation}\na_0 + a_1 = 0,\\qquad c_1 + {\\frac {a_0}{2}} = 0.\\label{teleW}\n\\end{equation}\nThe system (\\ref{2nd211})-(\\ref{1stF2}) then reduces to\n\\begin{equation}\n{\\frac {a_1}{2}}\\,\\Delta\\,U = 0,\\label{teleW1}\n\\end{equation}\nAccordingly, the metric structure turns out to be the same for the Riemannian (no torsion and nonmetricity) and for the teleparallel gravitational wave solutions.\n\\bigskip\n\n\\subsection{Symmetric teleparallel waves: no torsion}\n\n\nSymmetric teleparallel geometry is characterized by the vanishing curvature and torsion, along with a nontrivial nonmetricity \\cite{Nester:1999,Adak:2006a,Adak:2006b,Jimenez:2018,Conroy:2018,Hohmann:2018,Hohmann:2019}. This case arises when $du = 0$ and both $W^\\alpha = W^\\alpha(\\sigma)$ and $V^\\alpha = V^\\alpha(\\sigma)$ are independent of the transversal coordinates, whereas $\\Theta = 0$. The latter means that, by making use of (\\ref{thA}) and (\\ref{udU}), we have\n\\begin{equation}\n\\partial_A(U + {\\mathcal U}) - 2\\underline{W}_A = 0.\\label{udUW}\n\\end{equation}\nAs a result, the algebraic system (\\ref{e1})-(\\ref{e3}) is simplified to \n\\begin{equation}\\label{Xu1}\n(a_0 - 4b_1)\\,\\Phi_A = 0,\\ (a_0 + 2b_2)\\,\\Psi_A = 0,\\ (a_0 + 2c_1)\\,\\Psi_A = 0,\n\\end{equation}\nwhereas (\\ref{1stF2}) reduces to\n\\begin{equation}\n-\\,c_1\\,\\Delta\\,U = 0.\\label{teleS1}\n\\end{equation}\n\nConsequently, nontrivial symmetric teleparallel wave solutions exist for the class of MAG models restricted by the conditions on the coupling constants\n\\begin{equation}\na_0 - 4b_1 = 0,\\quad a_0 + 2b_2 = 0,\\quad c_1 + {\\frac {a_0}{2}} = 0.\\label{teleS}\n\\end{equation} \nOtherwise, solutions reduce to the flat Minkowski spacetime. The conditions (\\ref{teleS}) allow for the general solution with both $\\Psi_A$ and $\\Phi_A$ nonvanishing. Special symmetric teleparallel wave solutions with $\\Phi_A = 0$ or $\\Psi_A = 0$ exist under the milder conditions when one drops one of the restriction in (\\ref{teleS}).\n\n\n\\subsection{General MAG gravitational waves}\n\n\nThe torsion-free ansatz (\\ref{notorW}) can be generalized to \n\\begin{eqnarray}\nW^A &=& {\\frac 12}\\left(\\delta^{AB}\\partial_B{\\mathcal W} + \\eta^{AB}\\partial_B\\overline{\\mathcal W}\\right),\\label{pW}\\\\\nV^A &=& {\\frac 12}\\left(\\delta^{AB}\\partial_B{\\mathcal V} + \\eta^{AB}\\partial_B\\overline{\\mathcal V}\\right),\\label{pV}\\\\\nu_A &=& {\\frac 12}\\left(\\partial_A{\\mathcal U} + \\eta_{AB}\\,\\underline{\\partial}^B\\,\\overline{\\mathcal U}\\right),\\label{pu}\n\\end{eqnarray}\nPhysically, six new variables ${\\mathcal W}, {\\mathcal V}, {\\mathcal U}$ and $\\overline{\\mathcal W}, \\overline{\\mathcal V}, \\overline{\\mathcal U}$ are analogs of the well-known Hertz potentials in classical electrodynamics. The overline denotes the three {\\it parity-odd} variables $\\overline{\\mathcal W}, \\overline{\\mathcal V}, \\overline{\\mathcal U}$ to distinguish them from the {\\it parity-even} variables $U, {\\mathcal W}, {\\mathcal V}, {\\mathcal U}$.\n\n\\begin{widetext}\nSubstituting this into (\\ref{2nd211})-(\\ref{1stF2}), we derive\n\\begin{equation}\n(2c_1 - a_1)\\,U + \\Bigl[ {\\frac {a_0 + 2a_1}{2}} - 3c_1 - {\\frac {4b_1 - 4b_2}{3}}\\Bigr]\\,{\\mathcal W}\n+ \\Bigl[ {\\frac {a_0}{2}} - c_1 - {\\frac {4b_1 - 4b_2}{3}} \\Bigr]\\,{\\mathcal V}\n+ \\Bigl[4c_1 - a_1 - {\\frac {4b_1 + 8b_2}{3}}\\Bigr]\\,{\\mathcal U} = 0,\\label{eq1}\n\\end{equation}\n\\begin{eqnarray}\n\\Bigl[ {\\frac {a_0 + 2a_1}{2}} - 3c_1 - {\\frac {4b_1 - 4b_2}{3}}\\Bigr]\\,\\overline{\\mathcal W}\n+ \\Bigl[ {\\frac {a_0}{2}} - c_1 - {\\frac {4b_1 - 4b_2}{3}} \\Bigr]\\,\\overline{\\mathcal V}\n+ \\Bigl[4c_1 - a_1 - {\\frac {4b_1 + 8b_2}{3}}\\Bigr]\\,\\overline{\\mathcal U}&& \\nonumber\\\\\n-\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[(z_1 - z_2 + 2v_2)\\,\\Delta\\,\\overline{\\mathcal W}\n+ (z_1 - z_2)\\,\\Delta\\,\\overline{\\mathcal V}\n+ 2(z_1 + z_2 - v_2)\\,\\Delta\\,\\overline{\\mathcal U} \\Bigr] &=& 0,\\label{eq2}\\\\ \n\\partial_\\sigma\\,\\Bigl[(z_4 - z_1 + 3v_4)\\,\\Delta\\,{\\mathcal W} + (z_4 - z_1 + v_4)\\,\\Delta\\,{\\mathcal V}\n- 4z_1\\,\\Delta\\,{\\mathcal U}\\Bigr] &=& 0,\\label{eq3}\n\\end{eqnarray}\n\\begin{eqnarray}\n(a_0 + a_1)\\,U + \\Bigl[ c_1 - {\\frac {a_0 + 2a_1}{2}}\\Bigr]\\,{\\mathcal W}\n+ \\Bigl[ {\\frac {a_0}{2}} + c_1\\Bigr]\\,{\\mathcal V}  + \\Bigl[a_1 - 2c_1\\Bigr]\\,{\\mathcal U}&&\\nonumber\\\\ \n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[(2w_1 + 2w_4 + v_4)\\,\\Delta\\,{\\mathcal W}\n- (2w_1 + 2w_4 - v_4)\\,\\Delta\\,{\\mathcal V}\\Bigr] &=& 0,\\label{eq4}\\\\\n\\Bigl[ c_1 - {\\frac {a_0 + 2a_1}{2}}\\Bigr]\\,\\overline{\\mathcal W} + \\Bigl[ {\\frac {a_0}{2}} + c_1\\Bigr]\n\\,\\overline{\\mathcal V} + \\Bigl[a_1 - 2c_1\\Bigr]\\,\\overline{\\mathcal U}&&\\nonumber\\\\ \n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[(2w_1 + 2w_2 - v_2)\\,\\Delta\\,\\overline{\\mathcal W}\n- (2w_1 + 2w_2 + v_2)\\,\\Delta\\,\\overline{\\mathcal V} + 2v_2\\,\\Delta\\,\\overline{\\mathcal U}\\Bigr] &=& 0,\\label{eq5}\n\\end{eqnarray}\n\\begin{eqnarray}\n(a_1 - 2c_1)\\,U + \\Bigl[ {\\frac {a_0}{2}} - a_1 + 3c_1 - {\\frac {8b_1 + 4b_2}{3}}\\Bigr]\\,{\\mathcal W}\n+ \\Bigl[ {\\frac {a_0}{2}} + c_1 - {\\frac {8b_1 + 4b_2}{3}}\\Bigr]\\,{\\mathcal V}&&\\nonumber\\\\\n+ \\Bigl[a_0 + a_1 - 4c_1 - {\\frac {8b_1 - 8b_2}{3}}\\Bigr]\\,{\\mathcal U}\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\Bigl[(3z_1 + z_4 + 3v_4)\\,\\Delta\\,{\\mathcal W}  \n+ (3z_1 + z_4 + v_4)\\,\\Delta\\,{\\mathcal V}\\Bigr] &=& 0,\\label{eq6}\\\\\n\\Bigl[ {\\frac {a_0}{2}} - a_1 + 3c_1 - {\\frac {8b_1 + 4b_2}{3}}\\Bigr]\\,\\overline{\\mathcal W}\n+ \\Bigl[ {\\frac {a_0}{2}} + c_1 - {\\frac {8b_1 + 4b_2}{3}}\\Bigr]\\,\\overline{\\mathcal V}\n+ \\Bigl[a_0 + a_1 - 4c_1 - {\\frac {8b_1 - 8b_2}{3}}\\Bigr]\\,\\overline{\\mathcal U}&&\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[(3z_1 + z_2 - 2v_2)\\,\\Delta\\,\\overline{\\mathcal W} + (3z_1 + z_2)\n\\,\\Delta\\,\\overline{\\mathcal V} + 2(z_1 - z_2 + v_2)\\,\\Delta\\,\\overline{\\mathcal U}\\Bigr] &=& 0,\\label{eq7}\n\\end{eqnarray}\n\\begin{equation}\n-\\,a_1\\,\\Delta U + \\Bigl[{\\frac {a_0}{2}} - c_1 + a_1\\Bigr]\\,\\Delta\\,{\\mathcal W}\n- \\Bigl[{\\frac {a_0}{2}} + c_1\\Bigr]\\,\\Delta\\,{\\mathcal V}\n- \\Bigl[a_1 - 2c_1\\Bigr]\\,\\Delta\\,{\\mathcal U}  = 0.\\label{eq8}\n\\end{equation}\n\\end{widetext}\n\nThe analysis of this system is considerably simplified by a convenient choice of variables. The key to this is discovered when we substitute (\\ref{pW})-(\\ref{pu}) into (\\ref{thA})-(\\ref{psA}), which yields\n\\begin{eqnarray}\n\\Theta_A &=& {\\frac 12}\\left(\\partial_A{\\mathcal X}_1 + \\eta_{AB}\\,\\underline{\\partial}^B\n\\,\\overline{\\mathcal X}_1\\right),\\label{thA1}\\\\\n\\Phi_A &=& {\\frac 12}\\left(\\partial_A{\\mathcal X}_2 + \\eta_{AB}\\,\\underline{\\partial}^B\n\\,\\overline{\\mathcal X}_2\\right),\\label{psA1}\\\\\n\\Psi_A &=& {\\frac 12}\\left(\\partial_A{\\mathcal X}_3 + \\eta_{AB}\\,\\underline{\\partial}^B\n\\,\\overline{\\mathcal X}_3\\right),\\label{phiA1}\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\n{\\mathcal X}_1 = U - {\\mathcal W} + {\\mathcal U},&\\quad& \\overline{\\mathcal X}_1 =\n- \\overline{\\mathcal W} + \\overline{\\mathcal U},\\label{X1}\\\\\n{\\mathcal X}_2 = {\\mathcal W} + {\\mathcal V} + {\\mathcal U},&\\quad& \\overline{\\mathcal X}_2 =\n\\overline{\\mathcal W} + \\overline{\\mathcal V} + \\overline{\\mathcal U},\\label{X2}\\\\\n{\\mathcal X}_3 = {\\mathcal W} + {\\mathcal V} - 2{\\mathcal U},&\\quad& \\overline{\\mathcal X}_3 =\n\\overline{\\mathcal W} + \\overline{\\mathcal V} - 2\\overline{\\mathcal U}.\\label{X3}\n\\end{eqnarray}\nWe choose (\\ref{X1})-(\\ref{X3}) as the new set of variables, to which we add one more:\n\\begin{equation}\n{\\mathcal X}_0 = {\\mathcal W} - {\\mathcal V}.\\label{X0}\n\\end{equation}\nFor the inverse relations we derive\n\\begin{eqnarray}\nU &=& {\\frac 12}{\\mathcal X}_0 + {\\mathcal X}_1 + {\\frac 12}{\\mathcal X}_3,\\label{UX}\\\\\n{\\mathcal W} &=& {\\frac 12}{\\mathcal X}_0 + {\\frac 13}{\\mathcal X}_2 + {\\frac 16}{\\mathcal X}_3,\\label{WX}\\\\\n{\\mathcal V} &=& - \\,{\\frac 12}{\\mathcal X}_0 + {\\frac 13}{\\mathcal X}_2 + {\\frac 16}{\\mathcal X}_3,\\label{VX}\\\\\n{\\mathcal U} &=& {\\frac 13}{\\mathcal X}_2 - {\\frac 13}{\\mathcal X}_3,\\label{uX}\n\\end{eqnarray}\nand similarly we find\n\\begin{eqnarray}\n\\overline{\\mathcal W} &=& -\\,\\overline{\\mathcal X}_1 + {\\frac 13}\\overline{\\mathcal X}_2 - {\\frac 13}\\overline{\\mathcal X}_3,\\label{oWX}\\\\\n\\overline{\\mathcal V} &=& \\overline{\\mathcal X}_1 + {\\frac 13}\\overline{\\mathcal X}_2 + {\\frac 23}\\overline{\\mathcal X}_3,\\label{oVX}\\\\\n\\overline{\\mathcal U} &=& {\\frac 13}\\overline{\\mathcal X}_2 - {\\frac 13}\\overline{\\mathcal X}_3.\\label{ouX}\n\\end{eqnarray}\n\nSubstituting (\\ref{UX})-(\\ref{uX}) into the field equations, we recast (\\ref{eq1}), (\\ref{eq4}), (\\ref{eq6}), (\\ref{eq8}), (\\ref{eq3}), respectively, into\n\\begin{widetext}\n\\begin{eqnarray}\n(2c_1 - a_1)\\,{\\mathcal X}_1 + {\\frac 13}(a_0 - 4b_1)\\,{\\mathcal X}_2 + \n\\Bigl[ - \\,{\\frac {a_0}{2}} - c_1 + {\\frac 23}(a_0 + 2b_2)\\Bigr]\\,{\\mathcal X}_3 &=& 0,\\label{Xeq1}\\\\\n(a_0 + a_1)\\,{\\mathcal X}_1 + \\Bigl({\\frac {a_0}{2}} + c_1\\Bigr)\\,{\\mathcal X}_3\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[2(w_1 + w_4)\\,\\Delta\\,{\\mathcal X}_0 + {\\frac 23}\\,v_4\n\\,\\Delta\\,{\\mathcal X}_2 + {\\frac 13}\\,v_4\\,\\Delta\\,{\\mathcal X}_3 \\Bigr] &=& 0,\\label{Xeq4} \\\\\n(a_1 - 2c_1)\\,{\\mathcal X}_1 + {\\frac 23}(a_0 - 4b_1)\\,{\\mathcal X}_2 + \n\\Bigl[ {\\frac {a_0}{2}} + c_1 - {\\frac 23}(a_0 + 2b_2)\\Bigr]\\,{\\mathcal X}_3 &&\\nonumber\\\\\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\Bigl[ v_4\\,\\Delta\\,{\\mathcal X}_0 + {\\frac 23}\n\\,(3z_1 + z_4 + 2v_4)\\,\\Delta\\,{\\mathcal X}_2 + {\\frac 13}\\,(3z_1 + z_4 + 2v_4)\n\\,\\Delta\\,{\\mathcal X}_3\\Bigr] &=& 0,\\label{Xeq6}\\\\\n{\\frac {a_0}{2}}\\,\\Delta\\,{\\mathcal X}_0 - a_1\\,\\Delta\\,{\\mathcal X}_1 - c_1\\,\\Delta\\,{\\mathcal X}_3 \n&=& 0,\\label{Xeq8}\\\\\n\\partial_\\sigma\\Bigl\\{v_4\\,\\Delta\\,{\\mathcal X}{}_0 + {\\frac 23}(z_4 - 3z_1 + 2v_4)\\,\\Delta\\,{\\mathcal X}{}_2\n+ {\\frac 13}(z_4 + 3z_1 + 2v_4)\\,\\Delta\\,{\\mathcal X}{}_3\\Bigr\\} &=& 0.\\label{Xeq3}\n\\end{eqnarray}\nSimilarly, substituting (\\ref{oWX})-(\\ref{ouX}) into the field equations, we recast (\\ref{eq2}), (\\ref{eq5}), and (\\ref{eq7}), respectively, into\n\\begin{eqnarray}\n(2c_1 - a_1)\\,\\overline{\\mathcal X}_1 + {\\frac 13}(a_0 - 4b_1)\\,\\overline{\\mathcal X}_2 + \n\\Bigl[ -\\,{\\frac {a_0}{2}} - c_1 + {\\frac 23}(a_0 + 2b_2)\\Bigr]\\,\\overline{\\mathcal X}_3&& \\nonumber\\\\\n-\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[ -2v_2\\,\\Delta\\,\\overline{\\mathcal X}_1 + {\\frac 43}\\,z_1\n\\,\\Delta\\,\\overline{\\mathcal X}_2 - {\\frac 13}\\,(z_1 + 3z_2)\\,\\Delta\\,\\overline{\\mathcal X}_3\n\\Bigr] &=& 0,\\label{Xeq2}\\\\ \n(a_0 + a_1)\\,\\overline{\\mathcal X}_1 + \\Bigl({\\frac {a_0}{2}} + c_1\\Bigr)\\,\\overline{\\mathcal X}_3\n- \\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[-\\,4(w_1 + w_2)\\,\\Delta\\,\\overline{\\mathcal X}_1\n- (2w_1 + 2w_2 + v_2)\\,\\Delta\\,\\overline{\\mathcal X}_3 \\Bigr] &=& 0,\\label{Xeq5}\\\\\n(a_1 - 2c_1)\\,\\overline{\\mathcal X}_1 + {\\frac 23}(a_0 - 4b_1)\\,\\overline{\\mathcal X}_2 + \n\\Bigl[ {\\frac {a_0}{2}} + c_1 - {\\frac 23}(a_0 + 2b_2)\\Bigr]\\,\\overline{\\mathcal X}_3 &&\\nonumber\\\\\n-\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Bigl[ 2v_2\\,\\Delta\\,\\overline{\\mathcal X}_1 + {\\frac 83}\\,z_1\n\\,\\Delta\\,\\overline{\\mathcal X}_2 + {\\frac 13}\\,(z_1 + 3z_2)\\,\\Delta\\,\\overline{\\mathcal X}_3\n\\Bigr] &=& 0.\\label{Xeq7}\n\\end{eqnarray}\n\nIt is remarkable that the parity-even (\\ref{Xeq1})-(\\ref{Xeq3}) and the parity-odd (\\ref{Xeq2})-(\\ref{Xeq7}) sectors are completely decoupled.\n\nBoth are second order differential systems with constant coefficients, for which solutions are sought in the form\n\\begin{equation}\\label{XX}\n{\\mathcal X}_I = {\\mathcal X}_I^{(0)}(\\sigma)\\,e^{i\\,q_A\\,x^A},\\quad I = 0,1,2,3,\\qquad\n\\overline{\\mathcal X}_J = \\overline{\\mathcal X}{}_J^{(0)}(\\sigma)\\,e^{i\\,\\overline{q}_A\\,x^A},\\quad J = 1,2,3,\n\\end{equation}\nwhere  $q_A$ and  $\\overline{q}_A$ are not necessarily equal.\n\n{\\it Parity-even sector}. Substituting the ansatz (\\ref{XX}) into (\\ref{Xeq1})-(\\ref{Xeq8}) we obtain the algebraic system for the amplitudes ${\\mathcal X}_I^{(0)}$. In matrix form, the latter reads as\n\\renewcommand\\arraystretch{1.5}\n\\begin{equation}\n\\left(\\begin{array}{cccc} -{\\frac {a_0}{2}} & a_1 & 0 & c_1 \\\\\n0 & 2c_1 - a_1 & {\\frac 13}(a_0 - 4b_1) & - {\\frac {a_0}{2}} - c_1 + {\\frac 23}(a_0 + 2b_2) \\\\\n2(w_1 + w_4){\\mathcal Q}^2 & a_0 + a_1 & {\\frac 23}v_4{\\mathcal Q}^2 &\n{\\frac {a_0}{2}} + c_1 + {\\frac 13}v_4{\\mathcal Q}^2 \\\\\n{\\mathcal Q}^2v_4 & 0 & a_0 - 4b_1 + {\\frac 23}{\\mathcal Q}^2\\Lambda_0 &\n {\\frac 13}{\\mathcal Q}^2\\Lambda_0 \\end{array}\\right)\n\\left(\\begin{array}{c}{\\mathcal X}_0^{(0)} \\\\ {\\mathcal X}_1^{(0)} \\\\\n{\\mathcal X}_2^{(0)} \\\\ {\\mathcal X}_3^{(0)}\\end{array}\\right) =  0.\\label{algX}\n\\end{equation}\n\\renewcommand\\arraystretch{1}\nHere we denoted ${\\mathcal Q}^2  :=  {\\frac {\\ell^2}{4}q_Aq_B\\delta^{AB}}$, and $\\Lambda_0 := 3z_1 + z_4 + 2v_4$. Nontrivial solutions exist when the determinant of the $4\\times 4$ matrix in (\\ref{algX}) vanishes. Interestingly, despite being $4\\times 4$, the matrix has a very special structure that yields just a quadratic equation for ${\\mathcal Q}^2$. This equation determines the eigenvalues of the two propagating massive wave modes.\n\nIt is worthwhile to notice the existence of a special solution: ${\\mathcal X}_2 = 0$ and ${\\mathcal X}_3  = 0$. This means that ${\\mathcal U} = 0$ and ${\\mathcal W} = -\\, {\\mathcal V}$. The remaining system for ${\\mathcal X}_0$ and ${\\mathcal X}_1$ can be recast into\n\\begin{equation}\nv_4\\,\\Delta {\\mathcal X}_0 = 0,\\qquad (2c_1 - a_1)\\,{\\mathcal X}_1 = 0.\\label{X01}\n\\end{equation}\nRecalling the definitions (\\ref{X1})-(\\ref{X0}), and assuming $v_4\\neq 0$ and $a_1\\neq 2c_1$, we thus conclude that this solution describes the massless graviton mode, for which the 4 potentials satisfy\n\\begin{equation}\\label{mass0}\n\\Delta U = 0,\\qquad {\\mathcal W} = -\\,{\\mathcal V} = U,\\qquad {\\mathcal U} = 0.\n\\end{equation}\n\n\n{\\it Parity-odd sector}. A peculiar property of the system  (\\ref{Xeq2})-(\\ref{Xeq7}) is that the variable $\\overline{\\mathcal X}_2$ is decoupled from the pair $\\overline{\\mathcal X}_1, \\overline{\\mathcal X}_3$. Indeed, the sum of (\\ref{Xeq2}) and (\\ref{Xeq7}) yields an equation for $\\overline{\\mathcal X}_2$,\n\\begin{equation}\\label{DX2}\n(a_0 - 4b_1)\\,\\overline{\\mathcal X}_2 - \\ell_\\rho^2\\,z_1\\,\\Delta\\,\\overline{\\mathcal X}_2 = 0,\n\\end{equation}\nwhereas by taking the sum of (\\ref{Xeq2}) and (\\ref{Xeq5}) we derive\n\\begin{equation}\n(a_0 + 2c_1)\\,\\overline{\\mathcal X}_1 + {\\frac 23}(a_0 + 2b_2)\\,\\overline{\\mathcal X}_3 \n-\\,{\\frac {\\ell_\\rho^2}{4}}\\,\\Biggl\\{ - 2\\left[2w_1 + 2w_2 + v_2\\right]\\,\\Delta\n\\,\\overline{\\mathcal X}_1 - \\Bigl[2w_1 + 2w_2 + v_2 + {\\frac 13}\\,(z_1 + 3z_2)\\Bigr]\n\\,\\Delta\\,\\overline{\\mathcal X}_3\\Biggr\\} = 0,\\label{Xeq2a}\n\\end{equation}\nwhich in combination with (\\ref{Xeq5}) determines $\\overline{\\mathcal X}_1$ and $\\overline{\\mathcal X}_3$.\n\nSubstituting the ansatz (\\ref{XX}) into (\\ref{DX2}), (\\ref{Xeq2a}), and (\\ref{Xeq5}), we obtain the algebraic system for the amplitudes $\\overline{\\mathcal X}{}_I^{(0)}$. In matrix form, the latter reads as\n\\renewcommand\\arraystretch{1.5}\n\\begin{equation}\n\\left(\\begin{array}{ccc} 0 & a_0 - 4b_1 + 4z_1\\overline{\\mathcal Q}{}^2 & 0 \\\\\na_0 + 2c_1 - 2\\overline{\\mathcal Q}{}^2\\Lambda_2 & 0 & {\\frac 23}(a_0 + 2b_2)\n- \\overline{\\mathcal Q}{}^2(\\Lambda_2 + \\Lambda_3)\\\\\na_0 + a_1 - \\overline{\\mathcal Q}{}^2\\Lambda_1 & 0 & {\\frac {a_0}{2}} + c_1\n- \\overline{\\mathcal Q}{}^2\\Lambda_2\\end{array}\\right)\n\\left(\\begin{array}{c}\\overline{\\mathcal X}{}_1^{(0)} \\\\\n\\overline{\\mathcal X}{}_2^{(0)} \\\\ \\overline{\\mathcal X}{}_3^{(0)}\\end{array}\\right) =  0.\\label{algXo}\n\\end{equation}\n\\renewcommand\\arraystretch{1}\nHere we denoted $\\overline{\\mathcal Q}{}^2 := {\\frac {\\ell^2}{4}\\overline{q}_A\\overline{q}_B\\delta^{AB}}$, and $\\Lambda_1 := 4(w_1 + w_2)$, $\\Lambda_2 := 2(w_1 + w_2) + v_2$, $\\Lambda_3 := {\\frac 13}(z_1 + 3z_2)$.\n\nThe system (\\ref{algXo}) shows that there are three propagating parity-odd modes which are determined by\n\\begin{equation}\na_0 - 4b_1 + 4z_1\\overline{\\mathcal Q}{}^2 = 0,\\qquad {\\mathcal A}\\overline{\\mathcal Q}{}^4 +\n {\\mathcal B}\\overline{\\mathcal Q}{}^2 +  {\\mathcal C} = 0,\\label{oddQ}\n\\end{equation}\nwhere we denoted the combinations of the coupling constants\n\\begin{eqnarray}\n{\\mathcal A} &:=& 2\\Lambda_2^2 + \\Lambda_1(\\Lambda_2 + \\Lambda_3),\\label{oddA}\\\\\n{\\mathcal B} &:=& -\\,4\\left({\\frac {a_0}{2}} + c_1\\right)\\Lambda_2 + (a_0 + a_1)(\\Lambda_2 + \\Lambda_3) \n- {\\frac 23}(a_0 + 2b_2)\\Lambda_1,\\label{oddB}\\\\\n{\\mathcal C} &:=& 2\\left({\\frac {a_0}{2}} + c_1\\right)^2 - {\\frac 23}(a_0 + 2b_2)(a_0 + a_1).\\label{oddC}\n\\end{eqnarray}\n\n \nThe parity-odd amplitudes $\\overline{\\mathcal X}{}_I^{(0)} = \\overline{\\mathcal X}{}_I^{(0)}(\\sigma)$,  $J = 1,2,3$, are arbitrary functions of $\\sigma$. However, the field equation (\\ref{Xeq3}) imposes a relation between the three parity-even amplitudes,\n\\begin{equation}\\label{Xeq30}\nv_4\\,\\partial_\\sigma{\\mathcal X}{}_0^{(0)} + {\\frac 23}(z_4 - 3z_1 + 2v_4)\\,\\partial_\\sigma\n{\\mathcal X}{}_2^{(0)} + {\\frac 13}(z_4 + 3z_1 + 2v_4)\\,\\partial_\\sigma{\\mathcal X}{}_3^{(0)} = 0,\n\\end{equation}\nwhereas ${\\mathcal X}_1^{(0)} = {\\mathcal X}_1^{(0)}(\\sigma)$ depends arbitrarily on $\\sigma$.\n\\end{widetext}\n\n\n\\subsection{``Pseudo-instanton'' solutions}\n\n\nVassiliev \\cite{vas1} considered the class of models in which the Lagrangian depends only on the curvature (with $a_1 = a_2 = a_3 = 0$, $b_1 = \\dots = b_5 = 0$, $c_1 = c_2 = c_3 = 0$)\\footnote{To be precise, Vassiliev's Lagrangian \\cite{vas1} did not include the curvature quadratic terms with nontrivial $v_I$.} and defined ``pseudo-instantons'' as {\\it metric-compatible gravitational field configurations with an irreducible curvature}, which solve the vacuum MAG field equations. The former condition means that the nonmetricity is trivial $Q_{\\alpha\\beta} = 0$ which for our wave ansatz means that $u = 0$ and $W^A = -\\,V^A$. In terms of potentials this is translated into\n\\begin{equation}\n{\\mathcal U} = \\overline{\\mathcal U} = 0,\\qquad {\\mathcal W} = -\\,{\\mathcal V},\\qquad\n\\overline{\\mathcal W} = -\\,\\overline{\\mathcal V},\\label{noQ1}\n\\end{equation}\nor equivalently\n\\begin{eqnarray}\n{\\mathcal X}_0 = 2{\\mathcal W},\\quad {\\mathcal X}_1 = U - {\\mathcal W},\\quad\n{\\mathcal X}_2 = {\\mathcal X}_3 = 0,\\\\ \n\\overline{\\mathcal X}{}_1 = -\\,\\overline{\\mathcal W},\\quad\n\\overline{\\mathcal X}{}_2 = \\overline{\\mathcal X}{}_3 = 0.\\label{noQ2}\n\\end{eqnarray}\nIn the pure quadratic model, $a_0 = 0$, whereas $w_I$, $z_J$, and $v_K$ are nonvanishing. Under the conditions (\\ref{noQ1}), the field equations (\\ref{eq1})-(\\ref{eq8}) then reduce to\n\\begin{equation}\n\\Delta{\\mathcal W} = 0,\\qquad \\Delta\\overline{\\mathcal W} = 0.\\label{DWW}\n\\end{equation}\nBy making use of (\\ref{pW}), we thus find $\\partial_A W^A = 0$ and $\\eta^{AB}\\partial_A\\underline{W}_B = 0$, and consequently from (\\ref{OMAB1})-(\\ref{OMAB4}) and (\\ref{noQ1}) we conclude that \n\\begin{equation}\\label{nOm}\n{}^{(2)}\\!\\!\\mOm{\\!}^\\alpha = 0,\\quad {}^{(4)}\\!\\!\\mOm{\\!}^\\alpha = 0,\\quad {}^{(I)}\\!\\!\\pOm{\\!}^\\alpha = 0.\n\\end{equation}\nIn other words, the curvature is indeed irreducible (i.e., represented by just one irreducible part)\n\\begin{equation}\nR_\\alpha{}^\\beta = {}^{(1)}\\!W_\\alpha{}^\\beta,\\label{Rir} \n\\end{equation}\nand we thus recover the pseudo-instanton solution in the sense of \\cite{vas1}. It should be noted that the resulting gravitational waves are different from the ``torsion wave'' configurations described by Vassiliev. \n\n\n\\section{Discussion and conclusions}\\label{DC}\n\n\nIn this paper we have studied the gravitational waves in the framework of the metric-affine theory for the class of models with the most general Lagrangian constructed from all possible parity-even quadratic invariants of the curvature, torsion and nonmetricity (\\ref{LRT}). We have derived exact solutions with the help of the $pp$-wave type ansatz for the coframe (\\ref{cof0})-(\\ref{cof23}) and the linear connection (\\ref{conW}). This ansatz gives rise to a very special structure for the curvature, torsion and nonmetricity which was clarified in Sec.~\\ref{irreps}. \n\nWe have solved the MAG field equations (\\ref{dVt}) and (\\ref{dVG}) in vacuum, i.e. under the assumption that the energy-momentum $\\Sigma_\\alpha = 0$ and the hypermomentum $\\Delta^\\alpha{}_\\beta = 0$ matter currents are both vanishing.\n\nIt was shown that the plane-fronted wave solutions of GR and also of the teleparallel gravity arise as special cases of our solutions. For the latter theory, the resulting wave geometries are of the general type (with the vanishing curvature) and they encompass the two special subcases either with zero nonmetricity or with zero torsion (the standard teleparallel and the so-called symmetric teleparallel case, respectively).\n\nThe general gravitational wave solution in the class of quadratic MAG models is described by the fundamental transversal vectors $W^A$, $V^A$ and $u^A$, or equivalently, by the corresponding six scalar potentials ${\\mathcal W}, {\\mathcal V}, {\\mathcal U}$ and $\\overline{\\mathcal W}, \\overline{\\mathcal V}, \\overline{\\mathcal U}$. Together with the function $U$ from the $pp$-wave metric ansatz, they constitute seven unknown functions which satisfy the system of eight equations (\\ref{eq1})-(\\ref{eq8}). Quite remarkably, the structure of the field equations demonstrates the complete decoupling of the parity-even and the parity-odd variables which satisfy the two separate sets of equations. Furthermore, one of the field equations, (\\ref{2nd212}) (equivalently (\\ref{eq3}) in terms of the potentials), fixes the dependence on the coordinate $\\sigma$, whereas the remaining  system of seven Helmholtz or screened Laplace equations determines the seven unknown potentials as the functions of transversal coordinates $x^A$.\n\nThis system can be solved by making a standard exponential substitution (\\ref{XX}) for the seven variables, which recasts the system into an algebraic form for the wave amplitudes. At this point, the parity-odd sector admits a more straightforward general analysis, whereas for the parity-even sector we have focused on certain particular physically interesting solutions to demonstrate the structure of the corresponding mode spectrum. Of special interest is the class of Yang-Mills type models in which the Lagrangian is constructed only from the curvature invariants, whereas the quadratic in torsion and nonmetricity terms are set to zero. Then the gravitational wave solutions represent the MAG ``pseudo-instantons'' in the sense of \\cite{vas1}. It is worthwhile to stress that most of our results were obtained without or under very mild restrictions imposed on the parameters (coupling constants) of the action, so that the resulting geometries are exact solutions for large families of MAG models and not for specific sets of parameters.\n\nFinally, it is important to remark that in our analysis we assumed the vanishing cosmological constant, the inclusion of which would require a serious modification of the plane wave ansatz for the coframe (along the lines of \\cite{ndim} and \\cite{BCO}), and the parity-odd sector in the gravitational action was not included here, despite the fact that possible violation of parity is widely discussed in the current literature \\cite{Chen,Ho1,Ho2,Ho3,Diakonov,Baekler1,Baekler2,Iosifidis}. These issues remain open at the present stage of our research. We also have to postpone for the future the study of (possibly, simplified) models with a realistic matter distributions such as an in-falling dust or collapsing spheres of relativistic particles, e.g.\n\n\n\\begin{acknowledgments}\nThe work of AJC is supported by the Spanish Ministry of Economy and Competitiveness through the PhD contract FPU15/02864 and the project FIS2016-78198-P. YNO is grateful to Friedrich W.\\ Hehl (Cologne) for the constant support and encouragement, deep questions and helpful comments. For YNO this work was partially supported by the Russian Foundation for Basic Research (Grant No. 18-02-40056-mega).\n\\end{acknowledgments}\n\n\n\\appendix\n\n\n\\section{Irreducible decompositions of the torsion}\\label{irrtor}\n\nThe torsion 2-form can be decomposed into the three irreducible pieces, $T^{\\alpha}={}^{(1)}T^{\\alpha} + {}^{(2)}T^{\\alpha} + {}^{(3)}T^{\\alpha}$:\n\\begin{eqnarray}\n{}^{(1)}T^{\\alpha}&:=& T^{\\alpha}-{}^{(2)}T^{\\alpha} - {}^{(3)}T^{\\alpha},\\label{iT1}\\\\\n{}^{(2)}T^{\\alpha} &:=& {\\frac 13}\\vartheta^{\\alpha}\\wedge T,\\label{iT2}\\\\\n{}^{(3)}T^{\\alpha}&:=& -\\,{\\frac 13}{}^*(\\vartheta^{\\alpha}\\wedge\\overline{T}),\\label{iT3}\n\\end{eqnarray}\nwhere the 1-forms of the torsion {\\it trace} and {\\it axial trace} are defined as\n\\begin{equation}\\label{TT}\nT := e_\\nu\\rfloor T^\\nu,\\qquad \\overline{T} := {}^*(T^{\\nu}\\wedge\\vartheta_{\\nu}).\n\\end{equation}\n\n\n\\section{Irreducible decomposition of the nonmetricity}\\label{irrnon}\n\nThe nonmetricity 1-form can be decomposed into the four \nirreducible pieces,\n\\begin{eqnarray}\n{}^{(2)}Q_{\\alpha\\beta}&:=&{2\\over 3}\\,{}^*\\!(\\vartheta_{(\\alpha}\\wedge\n\\overline{\\Lambda}{}_{\\beta)}),\\label{Q2}\\\\\n{}^{(3)}Q_{\\alpha\\beta}&:=&{4\\over 9}\n\\left(\\vartheta_{(\\alpha}e_{\\beta)}\n\\rfloor\\Lambda - {1\\over 4}g_{\\alpha\\beta}\\Lambda\\right),\\label{Q3}\\\\\n{}^{(4)}Q_{\\alpha\\beta}&:=&g_{\\alpha\\beta}Q,\\label{Q4}\\\\\n{}^{(1)}Q_{\\alpha\\beta}&:=&Q_{\\alpha\\beta}-{}^{(2)}Q_{\\alpha\\beta}-\n{}^{(3)}Q_{\\alpha\\beta}-{}^{(4)}Q_{\\alpha\\beta}.\\label{Q1}\n\\end{eqnarray}\nHere the Weyl covector 1-form is $Q:={1\\over 4}g^{\\alpha\\beta}Q_{\\alpha\\beta}$, whereas $\\aQ_{\\alpha\\beta}=Q_{\\alpha\\beta} - Qg_{\\alpha\\beta}$ is the traceless piece of the nonmetricity; and we denoted\n\\begin{eqnarray}\\label{Lam}\n\\Lambda_\\alpha &:=& e^{\\beta}\\rfloor\\aQ_{\\alpha\\beta},\\quad \\Lambda:=\\Lambda_\\alpha\\vartheta^{\\alpha},\\\\\n\\overline{\\Lambda}{}_\\alpha &:=& {}^*\\!\\left(\\aQ_{\\alpha\\beta}\\wedge\\vartheta^{\\beta} - {\\frac 13}\n\\vartheta_\\alpha\\wedge\\Lambda\\right).\\label{oLam}\n\\end{eqnarray}\nIt seems worthwhile to notice that the 2-form $\\overline{\\Lambda}{}_\\alpha$ which describes ${}^{(2)}Q_{\\alpha\\beta}$, has precisely the same symmetry properties as the 2-form ${}^{(1)}T^{\\alpha}$. \n\n\n\\section{Irreducible decompositions of the curvature}\\label{irrcur}\n\nWe start by splitting the general curvature 2-form as $R^{\\alpha\\beta}= W^{\\alpha\\beta} + Z^{\\alpha\\beta}$ into the skew-symmetric $W^{\\alpha\\beta} := R^{[\\alpha\\beta]}$ and symmetric $Z^{\\alpha\\beta} := R^{(\\alpha\\beta)}$ parts, and then we decompose the latter separately. The skew-symmetric piece is decomposed $W^{\\alpha\\beta} = \\sum_{I=1}^6\\,{}^{(I)}\\!W^{\\alpha\\beta}$ into the 6 irreducible parts:\n\\begin{eqnarray}\n{}^{(2)}\\!W^{\\alpha\\beta} &:=& -\\,{}^*(\\vartheta^{[\\alpha}\\wedge\n\\overline{\\Psi}{}^{\\beta]}),\\label{curv2}\\\\\n{}^{(3)}\\!W^{\\alpha\\beta} &:=& -\\,{\\frac 1{12}}\\,{}^*(\\overline{X}\n\\,\\vartheta^\\alpha\\wedge\\vartheta^\\beta),\\label{curv3}\\\\\n{}^{(4)}\\!W^{\\alpha\\beta} &:=& -\\,\\vartheta^{[\\alpha}\\wedge\\Psi^{\\beta]},\\label{curv4}\\\\\n{}^{(5)}\\!W^{\\alpha\\beta} &:=& -\\,{\\frac 12}\\vartheta^{[\\alpha}\\wedge e^{\\beta]}\n\\rfloor(\\vartheta^\\gamma\\wedge X_\\gamma),\\label{curv5}\\\\\n{}^{(6)}\\!W^{\\alpha\\beta} &:=& -\\,{\\frac 1{12}}\\,X\\,\\vartheta^\\alpha\\wedge\n\\vartheta^\\beta,\\label{curv6}\\\\\n{}^{(1)}\\!W^{\\alpha\\beta} &:=& W^{\\alpha\\beta} -  \n\\sum\\limits_{I=2}^6\\,{}^{(I)}W^{\\alpha\\beta},\\label{curv1}\n\\end{eqnarray}\nwhere we denoted\n\\begin{eqnarray}\nX^\\alpha := e_\\beta\\rfloor W^{\\alpha\\beta},\\qquad X := e_\\alpha\\rfloor X^\\alpha,\\label{WX1}\\\\\n\\overline{X}{}^\\alpha := {}^*(W^{\\beta\\alpha}\\wedge\\vartheta_\\beta),\\qquad\n\\overline{X} := e_\\alpha\\rfloor \\overline{X}{}^\\alpha,\\label{WX2}\\\\\n\\Psi_\\alpha := X_\\alpha - {\\frac 14}\\,\\vartheta_\\alpha\\,X - {\\frac 12}\n\\,e_\\alpha\\rfloor (\\vartheta^\\beta\\wedge X_\\beta),\\label{Psia}\\\\\n\\overline{\\Psi}{}_\\alpha := \\overline{X}{}_\\alpha - {\\frac 14}\\,\\vartheta_\\alpha\n\\,\\overline{X} - {\\frac 12}\\,e_\\alpha\\rfloor (\\vartheta^\\beta\\wedge \n\\overline{X}{}_\\beta).\\label{Phia}\n\\end{eqnarray}\n\nFor the symmetric curvature, at first we split it into the trace $Z = Z_\\alpha{}^\\alpha$ and the traceless piece $\\aZ^{\\alpha\\beta} = Z^{\\alpha\\beta} - {\\frac 14}Zg_{\\alpha\\beta}$. As a result, we obtain five irreducible parts\n\\begin{eqnarray}\n{}^{(2)}\\!Z^{\\alpha\\beta} &:=& -\\,{\\frac 12}{}^*(\\vartheta^{(\\alpha}\\wedge\\overline{\\Phi}{}^{\\beta)}),\n\\label{curZ2}\\\\\n{}^{(3)}\\!Z^{\\alpha\\beta} &:=& {\\frac 13}\\,\\vartheta^{(\\alpha}\\wedge e^{\\beta)}\\rfloor\n(\\vartheta^\\gamma\\wedge Y_\\gamma)\\nonumber\\\\\n&& -\\,{\\frac 16}\\,g^{\\alpha\\beta}(\\vartheta^\\gamma\\wedge Y_\\gamma),\\label{curZ3}\\\\\n{}^{(4)}\\!Z^{\\alpha\\beta} &:=& {\\frac 12}\\,\\vartheta^{(\\alpha}\\wedge\\Phi^{\\beta)},\\label{curZ4}\\\\\n{}^{(5)}\\!Z^{\\alpha\\beta} &:=& {\\frac 1{4}}\\,Z\\,g^{\\alpha\\beta},\\label{curZ5}\\\\\n{}^{(1)}\\!Z^{\\alpha\\beta} &:=& Z^{\\alpha\\beta} -  \n\\sum\\limits_{I=2}^5\\,{}^{(I)}Z^{\\alpha\\beta},\\label{curZ1}\n\\end{eqnarray}\nwhere \n\\begin{eqnarray}\nY^\\alpha := e_\\beta\\rfloor \\aZ^{\\alpha\\beta},\\quad Y := e_\\alpha\\rfloor Y^\\alpha = 0,\\label{ZY1}\\\\\n\\overline{Y}{}^\\alpha := {}^*(\\aZ^{\\beta\\alpha}\\wedge\\vartheta_\\beta),\\quad \\overline{Y} := e_\\alpha\\rfloor \\overline{Y}{}^\\alpha = 0,\\label{ZY2}\n\\end{eqnarray}\nand \n\\begin{eqnarray}\n\\Phi_\\alpha &:=& Y_\\alpha - {\\frac 12}\\,e_\\alpha\\rfloor (\\vartheta^\\beta\\wedge Y_\\beta),\\label{ZPsia}\\\\\n\\overline{\\Phi}{}_\\alpha &:=& \\overline{Y}{}_\\alpha \n- {\\frac 12}\\,e_\\alpha\\rfloor (\\vartheta^\\beta\\wedge \\overline{Y}{}_\\beta)\\label{ZPhia}.\n\\end{eqnarray}\n\nAn important notice: the notations used here are different from \\cite{MAG} in that ${}^{(4)}\\!Z^{\\alpha\\beta}$ and ${}^{(5)}\\!Z^{\\alpha\\beta}$ are exchanged, however, the components of irreducible parts match in a consistent way. \n\n\n\\begin{thebibliography}{99}\n\n\n\\bibitem{Ein}\nA.~Einstein, Geometrie und Erfahrung.\nSitzungsber. preuss. Akad. Wiss. {\\bf 1}, 123-130 (1921).\n  \n\\bibitem{MAG} \nF. W. Hehl, J. D. McCrea, E. W.  Mielke, and Y. Ne'eman,\nMetric-affine gauge theory of gravity: field equations, Noether identities, world spinors.\nand breaking of dilation invariance. Phys. Rep. {\\bf 258}, 1-177 (1995). \n\\url{https://doi.org/10.1016/0370-1573(94)00111-F}\n\n\\bibitem{Blag}\nM. Blagojevi\\'c, {\\it Gravitation and Gauge Symmetries} (Institute of Physics, Bristol, 2002).\n\n\\bibitem{reader}\nM. Blagojevi\\'c and F. W. Hehl (eds.), {\\it Gauge Theories of Gravitation.\nA Reader with Commentaries} (Imperial College Press, London, 2013).\n\n\\bibitem{PBO}\nV. N. Ponomarev, A. O. Barvinsky, and Yu. N. Obukhov, {\\it Gauge Approach and Quantization\nMethods in Gravity Theory} (Nauka, Moscow, Russia, 2017).\n\n\\bibitem{Sciama}  \nD. W. Sciama, The analogy between charge and spin in general relativity. In:\n{\\it ``Recent Developments in General Relativity, Festschrift for Infeld''}\n(Pergamon Press, Oxford; PWN, Warsaw, 1962) pp. 415-439.\n\n\\bibitem{Kibble}\nT. W. B. Kibble, Lorentz invariance and the gravitational field. J. Math. Phys.\n{\\bf 2}, 212-221 (1961). \\url{https://doi.org/10.1063/1.1703702}\n\n\\bibitem{grpg}\nYu. N. Obukhov and F. W. Hehl, General relativity as a special case of Poincar\\'e gauge gravity.\nPhys. Rev. D {\\bf 102}, 044058 (2020). % (10 pages). % arXiv:2007.00043 (gr-qc)\n\\url{https://doi.org/10.1103/PhysRevD.102.044058}\n\n\\bibitem{Goenner}\nH. F. M. Goenner, On the history of unified field theories.\nLiving Rev. Relativity {\\bf 7}, 2 (2004). \n\\url{http://www.livingreviews.org/lrr-2004-2}.\n\n\\bibitem{Coley1}\nA. Coley, Analysis of nonmetric theories of gravity. I. Electromagnetism.\nPhys. Rev. D {\\bf 27}, 728-739 (1983).\n\\url{https://doi.org/10.1103/PhysRevD.27.728}\n\n\\bibitem{Coley2}\nA. Coley, Analysis of nonmetric theories of gravity. II. The weak \nequivalence principle. Phys. Rev. D {\\bf 28}, 1829-1843 (1983).\n\\url{https://doi.org/10.1103/PhysRevD.28.1829}\n\n\\bibitem{Coley3}\nA. Coley, Analysis of nonmetric theories of gravity. III. Summary of\nthe analysis and its application to theories in the literature.\nPhys. Rev. D {\\bf 28}, 1844-1852 (1983).\n\\url{https://doi.org/10.1103/PhysRevD.28.1844}\n\n\\bibitem{mccrea:1992}\nJ. D. McCrea, Irreducible decompositions of non-metricity, torsion, curvature\nand Bianchi identities in metric affine space-times.\nClass. Quantum Grav. {\\bf 9}, 553-568 (1992).\n\\url{https://doi.org/10.1088/0264-9381/9/2/018}\n\n\\bibitem{Vitagliano}\nV. Vitagliano, T. P. Sotiriou, and S. Liberati, The dynamics of metric-affine gravity.\nAnn. Phys. (USA) {\\bf 326}, 1259-1273 (2011).\n\\url{https://doi.org/10.1016/j.aop.2011.02.008}\n\n\\bibitem{nee1}\nY. Ne'eman and Dj. \\v{S}ija\\v{c}ki, Unified affine gauge theory of gravity and\nstrong interactions with finite and infinite $GL(4,R)$ spinor fields.\nAnn. Phys. (USA) {\\bf 120}, 292-315 (1979).\n\\url{https://doi.org/10.1016/0003-4916(79)90392-0}\n\n\\bibitem{nee2}\nY. Ne'eman and Dj. \\v{S}ija\\v{c}ki, Hadrons in an $\\overline{SL}(4,R)$ classification.\nPhys. Rev. D {\\bf 37}, 3267-3283 (1988).\n\\url{https://doi.org/10.1103/PhysRevD.37.3267}\n\n\\bibitem{nee3}\nY. Ne'eman and Dj. \\v{S}ija\\v{c}ki, Gravity from symmetry breakdown of a\ngauge affine theory. Phys. Lett. B {\\bf 200}, 489-494 (1988).\n\\url{https://doi.org/10.1016/0370-2693(88)90157-8}\n\n\\bibitem{lee1}\nC.-Y. Lee and Y. Ne'eman, Renormalization of gauge-affine  gravity.\nPhys. Lett. B {\\bf 242}, 59-63 (1990).\n\\url{https://doi.org/10.1016/0370-2693(90)91594-2}\n\n\\bibitem{lee2}\nC.-Y. Lee, Renormalization of quantum gravity with local $GL(4,R)$ symmetry.\nClass. Quantum Grav. {\\bf 9}, 2001-2020 (1992).\n\\url{https://doi.org/10.1088/0264-9381/9/9/006}\n\n\\bibitem{per1}\nC. Pagani and R. Percacci, Quantum gravity with torsion and non-metricity.\nClass. Quantum Grav. {\\bf 32}, 195019 (2015). % (17 pages).\n\\url{https://doi.org/10.1088/0264-9381/32/19/195019}\n\n\\bibitem{per2}\nR. Percacci, Towards metric-affine quantum gravity. Int. J. Geom. Meth. Mod. Phys.\n{\\bf 17}, No. supp01, 2040003 (2020). % (12 pages).\n\\url{https://doi.org/10.1142/S0219887820400034}\n\n\\bibitem{frank}\nF. Gronwald and F. W. Hehl, Stress and hyperstress as fundamental \nconcepts in continuum mechanics and in relativistic field theory. In: {\\it\n``Advances in Modern Continuum Dynamics'', International Conference in Memory \nof Antonio Signorini, Isola d'Elba, June 1991}, Ed. G. Ferrarese (Pitagora Editrice,\nBologna,1993) 1-32.\n\n\\bibitem{hyper}\nYu. N. Obukhov and R. Tresguerres, Hyperfluid: A Model of classical matter with hypermomentum.\nPhys. Lett. A {\\bf 184}, 17-22 (1993).\n\\url{https://doi.org/10.1016/0375-9601(93)90339-2}\n\n\\bibitem{dirk3}\nD. Puetzfeld and X. Chen, Testing non-standard cosmological models with supernovae.\nClass. Quantum Grav. {\\bf 21}, 2703-2722 (2004).\n\\url{https://doi.org/10.1088/0264-9381/21/11/013}\n \n\\bibitem{dirk4}\nD. Puetzfeld, Status of non-Riemannian cosmology.  New Astron. Rev. {\\bf 49}, 59-64 (2005).\n\\url{https://doi.org/10.1016/j.newar.2005.01.022}\n\n\\bibitem{dirk5}\nD. Puetzfeld, M. Pohl, and Z.-H. Zhu, Complementary constraints from Fanaroff-Riley IIb\nradio galaxies and X-ray gas mass fractions in clusters on non-standard cosmological models.\nAstrophys. J. {\\bf 619}, 657-666 (2005).\n\\url{https://doi.org/10.1086/426665}\n\n\\bibitem{dil1}\nT. Dereli and R. W. Tucker, An Einstein-Hilbert action for axi-dilaton gravity in four dimensions.\nClass. Quantum Grav. {\\bf 12}, L31-L36 (1995).\n\\url{https://doi.org/10.1088/0264-9381/12/4/002}\n\n\\bibitem{dil2}\nA. Saa, A geometrical action for dilaton gravity.\nClass. Quantum Grav. {\\bf 12}, L85-L88 (1995).\n\\url{https://doi.org/10.1088/0264-9381/12/8/004}\n\n\\bibitem{dil3}\nR. Scipioni, Isomorphism between non-Riemannian gravity and Einstein-Proca-Weyl\ntheories extended to a class of scalar gravity theories.\nClass. Quantum Grav. {\\bf 16}, 2471-2478 (1999).\n\\url{https://doi.org/10.1088/0264-9381/16/7/320}\n\n\\bibitem{dil4}\nB. Sazdovic, {\\it Torsion and nonmetricity in the stringy geometry},\ne-Print ArXiv: hep-th/0304086 (32 pages).\n\\url{https://arxiv.org/abs/hep-th/0304086}\n\n\\bibitem{nee}\nY. Ne'eman and F. W. Hehl, Test matter in a spacetime with nonmetricity.\nClass. Quantum Grav. {\\bf 14}, A251-A259 (1997).\n\\url{https://doi.org/10.1088/0264-9381/14/1A/020}\n\n\\bibitem{yass}\nP. B. Yasskin and W. R. Stoeger, Propagating equations for test bodies with\nspin and rotation in theories of gravity with torsion.\nPhys. Rev. D {\\bf 21}, 2081-2094 (1980).\n\\url{https://doi.org/10.1103/PhysRevD.21.2081}\n\n\\bibitem{Puetz} \nD. Puetzfeld and Yu. N. Obukhov, Propagation equations for deformable test \nbodies with microstructure in extended theories of gravity. \nPhys. Rev. D {\\bf 76}, 084025 (2007). % (20 pages). \n\\url{http://dx.doi.org/10.1103/PhysRevD.76.084025}\n\n\\bibitem{eom2}\nYu.~N. Obukhov and D. Puetzfeld, Multipolar test body equations of motion in\ngeneralized gravity theories. In: {\\it ``Equations of Motion in Relativistic\nGravity''}, eds. D. Puetzfeld, C. L\\\"ammerzahl, and B. Schutz, Fundamental\nTheories of Physics, Vol. {\\bf 179} (Springer, Cham, Switzerland, 2015) pp. 67-119.\n\n\\bibitem{pono} \nV. N. Ponomariev and Yu N. Obukhov, The generalized Einstein-Maxwell theory of gravitation.\nGen. Relat. Grav. {\\bf 14}, 309-330 (1982).\n\\url{https://doi.org/10.1007/BF00756267}\n\n\\bibitem{Gronwald:1997}\nF. Gronwald, Metric-affine gauge theory of gravity I. Fundamental structure and field\nequations. Int. J. Mod. Phys. D {\\bf 6}, 263-304 (1997). % arXiv:9702034\n\\url{https://doi.org/10.1142/S0218271897000157}\n\n\\bibitem{hehl:1999}\nF. W. Hehl, and A. Mac\\'{\\i}as, Metric-affine gauge theory of gravity II. Exact solutions.\nInt. J. Mod. Phys. D {\\bf 8}, 399-416 (1999).\n\\url{https://doi.org/10.1142/S0218271899000316}\n\n\\bibitem{tres1}\nR. Tresguerres, Exact vacuum solutions of four-dimensional metric-affine\ngauge theories of gravitation. Z. Phys. C {\\bf 65}, 347-354 (1995).\n\\url{https://doi.org/10.1007/BF01571892}\n\n\\bibitem{tres2}\nR. Tresguerres, Exact static vacuum solution of four-dimensional metric-affine\ngravity with nontrivial torsion. Phys. Lett. A {\\bf 200}, 405-410 (1995).\n\\url{https://doi.org/10.1016/0375-9601(95)00206-I}\n\n\\bibitem{wang}\nR. W. Tucker and C. Wang, Black holes with Weyl charge and non-Riemannian waves.\nClass. Quantum Grav. {\\bf 12}, 2587-2605 (1995).\n\\url{https://doi.org/10.1088/0264-9381/12/10/016}\n\n\\bibitem{vlach:1996}\nE. J. Vlachynsky, R. Tresguerres, Yu. N. Obukhov, and F. W. Hehl, An axially symmetric solution\nof metric-affine gravity. Class. Quantum Grav. {\\bf 13}, 3253-3259 (1996).\n\\url{https://doi.org/10.1088/0264-9381/13/12/016}\n\n\\bibitem{obukhov:1996}\nYu. N. Obukhov, E. J. Vlachynsky, R. Tresguerres, W. Esser, and F. W. Hehl,\nAn exact solution of the metric-affine gauge theory with dilation, shear, and spin charges,\nPhys. Lett. A {\\bf 220}, 1-9 (1996).\n\\url{https://doi.org/10.1016/0375-9601(96)00531-2}\n\n\\bibitem{Garcia:1998}\nA. Garc\\'{\\i}a, F.~W. Hehl, C. L\\\"ammerzahl, A. Mac\\'{\\i}as, and J. Socorro,\nPlebanski-Demianski-like solutions in metric-affine gravity.\nClass. Quantum Grav. {\\bf 15}, 1793 (1998).\n\\url{https://doi.org/10.1088/0264-9381/15/6/025}\n\n\\bibitem{obukhov:1997}\nYu. N. Obukhov, E. J. Vlachynsky, W. Esser, and F. W. Hehl, Effective Einstein theory\nfrom metric-affine gravity models via irreducible decompositions.\nPhys. Rev. D {\\bf 56}, 7769-7778 (1997). % gr-qc/9705039\n\\url{https://doi.org/10.1103/PhysRevD.56.7769}\n\n\\bibitem{Delhom:2019}\nA. Delhom, C. F. B. Macedo, G. J. Olmo, and L. C. B. Crispino,\nAbsorption by black hole remnants in metric-affine gravity.\nPhys. Rev. D {\\bf 100}, 024016 (2019). % (12 pages).\n\\url{https://doi.org/10.1103/PhysRevD.100.024016} \n\n\\bibitem{Abbott1}\nB. P. Abbott et al. (LIGO Scientific Collaboration and Virgo Collaboration),\nObservation of Gravitational Waves from a Binary Black Hole Merger.\nPhys. Rev. Lett. {\\bf 116}, 061102 (2016).\n\\url{https://doi.org/10.1103/PhysRevLett.116.061102}\n\n\\bibitem{Abbott2}\nB. P. Abbott et al. (LIGO Scientific Collaboration and Virgo Collaboration),\nGW151226: Observation of Gravitational Waves from a 22-Solar-Mass Binary\nBlack Hole Coalescence. Phys. Rev. Lett. {\\bf 116}, 241103 (2016).\n\\url{https://doi.org/10.1103/PhysRevLett.116.241103}\n\n\\bibitem{flan}\nE. E. Flanagan and S. A. Hughes, The basics of gravitational wave theory.\nNew J. Phys. {\\bf 7}, 204 (2005). % [50 pages].\n\\url{http://dx.doi.org/10.1088/1367-2630/7/1/204}\n\n\\bibitem{schutz}\nB. S. Sathyaprakash and B. F. Schutz, Physics, astrophysics and cosmology with \ngravitational waves. Living Rev. Relativity {\\bf 12}, 2 (2009). \n\\url{http://www.livingreviews.org/lrr-2009-2}\n\n\\bibitem{CNN}\nC.-M. Chen, J.M. Nester, and W.-T. Ni, A brief history of gravitational wave research.\nChin. J. Phys. {\\bf 55}, 142-169 (2017). \\url{https://doi.org/10.1016/j.cjph.2016.10.014}\n\n\\bibitem{Brink1} \nH. W. Brinkmann, On Riemann spaces conformal to Euclidean space.\nProc. Nat. Acad. Sci. {\\bf 9}, 1-3 (1923). \\url{https://doi.org/10.1073/pnas.9.1.1}\n\n\\bibitem{Brink2}\nH. W. Brinkmann, On Riemann spaces conformal to Einstein space.\nProc. Nat. Acad. Sci. {\\bf 9}, 172-174 (1923). \\url{https://doi.org/10.1073/pnas.9.5.172}\n\n\\bibitem{Brink3}\nH. W. Brinkmann, Einstein spaces which are mapped conformally on each other.\nMath. Ann. {\\bf 94}, 119-145 (1925). % Mathematische Annalen\n\\url{http://dx.doi.org/1010.1007/BF01208647}\n\n\\bibitem{rosen1937}\nN. Rosen, Plane polarized waves in the general theory of relativity.\nPhysikalische Zeitschrift der Sowjetunion {\\bf 12}, 366-372 (1937).\n\n\\bibitem{einrosen}\nA. Einstein and N. Rosen, On gravitational waves. J. Franklin Inst. {\\bf 223}, 43-54 (1937).\n\\url{http://dx.doi.org/10.1016/S0016-0032(37)90583-0}\n\n\\bibitem{rosen1956}\nN. Rosen, Gravitational waves. Helv. Phys. Acta {\\bf 29}, 171-175 (1956). \n\\url{http://dx.doi.org/10.5169/seals-112740}\n\n\\bibitem{rosen1958}\nN. Rosen, Energy and momentum of cylindrical gravitational waves.\nPhys. Rev. {\\bf 110}, 291-292 (1958). \\url{https://doi.org/10.1103/PhysRev.110.291}\n\n\\bibitem{Virb1}\nN. Rosen and K. S. Virbhadra, Energy and momentum of cylindrical gravitational waves.\nGen. Relat. Grav. {\\bf 25}, 429-433 (1993). \\url{https://doi.org/10.1007/BF00757123}\n\n\\bibitem{Virb2}\nK. S. Virbhadra, Energy and momentum of cylindrical gravitational waves II.\nPramana {\\bf 45}, 215-219 (1995). \\url{https://doi.org/10.1007/BF02848265}\n\n\\bibitem{bondi0}\nH. Bondi, Plane gravitational waves in general relativity. \nNature {\\bf 179}, 1072-1073 (1957). \\url{https://doi.org/10.1038/1791072a0}\n\n\\bibitem{bondi1}\nH. Bondi, F. A. E. Pirani, and I. Robinson, \nGravitational waves in general relativity. III. Exact plane waves.\nProc. Roy. Soc. London A {\\bf 281}, 519-533 (1959).\n\\url{https://doi.org/10.1098/rspa.1959.0124}\n\n\\bibitem{peres}\nA. Peres, Some gravitational waves. Phys. Rev. Lett. {\\bf 3}, 571-572 (1959). \n\\url{https://doi.org/10.1103/PhysRevLett.3.571}\n\n\\bibitem{pen1}\nR. Penrose, A remarkable property of plane waves in general relativity.\nRev. Mod. Phys. {\\bf 37}, 215-220 (1965).\n\\url{https://doi.org/10.1103/RevModPhys.37.215}\n\n\\bibitem{pen2}\nR. Penrose, Any spacetime has a plane wave as a limit.\nIn: {\\sl ``Differential geometry and relativity\" Festschrift for A. Lichnerowicz.}\nEds. M. Cahen and M.~Flato (D. Reidel: Dordrecht, 1976) 271-275. \n\n\\bibitem{Kom1}\nA. S. Kompaneets, Strong gravitational waves in vacuum. \nZh. Exp. Theor. Phys. {\\bf 34}, 953-955 (1958). \n\n\\bibitem{Kom2}\nA. S. Kompaneets, Propagation of a strong electromagnetic-gravitational wave in vacuum.\nZh. Exp. Theor. Phys. {\\bf 37}, 1722-1726 (1959). \n\n\\bibitem{Jordan1}\nP. Jordan, J. Ehlers, and W. Kundt, \nStrenge L\\\"osungen der Feldgleichungen der Allgemeinen Relativit\\\"atstheorie. \nAkademie der Wissenschaften und der Literatur, Abhandlungen der\nMathematisch-naturwissenschaftliche Klasse, Nr. 2 (1960) 21-105;\n{\\it English translation}: P. Jordan, J. Ehlers, and W. Kundt,\nExact solutions of the field equations of the general theory of relativity.\nGen. Rel. Grav. {\\bf 41}, 2191-2280 (2009).\n\\url{http://dx.doi.org/10.1007/s10714-009-0869-8}\n\n\\bibitem{Jordan2}\nP. Jordan, J. Ehlers, and R. K. Sachs, \nBeitr\\\"age zur Theorie der reinen Gravitationsstrahlung, Strenge L\\\"osungen \nder Feldgleichungen der Allgemeinen Relativit\\\"atstheorie II. \nAkademie der Wissenschaften und der Literatur, Abhandlungen der\nMathematisch-naturwissenschaftliche Klasse, Nr. 1 (1961) 1-62;\n{\\it English translation}: P. Jordan, J. Ehlers, and R. K. Sachs,\nContributions to the theory of pure gravitational radiation. \nExact solutions of the field equations of the general theory of relativity II.\nGen. Rel. Grav. {\\bf 45}, 2691-2753 (2013).\n\\url{http://dx.doi.org/10.1007/s10714-013-1590-1}\n\n\\bibitem{kundt}\nW. Kundt, The plane-fronted gravitational waves. \nZeits. Physik {\\bf 163}, 77-86 (1961). \\url{https://doi.org/10.1007/BF01328918}\n\n\\bibitem{curr}\nJ. Ehlers and W. Kundt, Exact solutions of the gravitational field equations.\nIn: {\\sl ``Gravitation: An introduction to current research''}, Ed. L. Witten \n(John Wiley \\& Sons, New York, 1962) pp. 49-101.\n\n\\bibitem{schim}\nR. Schimming, RIEMANNsche R\\\"aume mit ebenfrontiger und mit ebener Symmetrie.\nMathematische Nachrichten {\\bf 59}, 129-162 (1974).\n\\url{http://dx.doi.org/10.1002/mana.19740590111}\n\n\\bibitem{AT}\nA. Trautman, A class of null solutions to Yang-Mills equations.\nJ. Phys. A: Math. Gen. {\\bf 13}, L1-L4 (1980).\n\\url{https://doi.org/10.1088/0305-4470/13/1/001}\n\n\\bibitem{piran}\nT. Piran, P. N. Safier, and J. Katz, Cylindrical gravitational waves with two \ndegrees of freedom: An exact solution. Phys. Rev. D {\\bf 34}, 331-332 (1986).\n\\url{https://doi.org/10.1103/physrevd.34.331}\n\n\\bibitem{MashQ}\nB. Mashhoon and H. Quevedo, Rotating gravitational waves.\nPhys. Lett. A {\\bf 151}, 464-468 (1990).\n\\url{https://doi.org/10.1016/0375-9601(90)90462-W}\n\n\\bibitem{torre}\nC. G. Torre, Gravitational waves: just plane symmetry.\nGen. Rel. Grav. {\\bf 38}, 653-662 (2006). \n\\url{http://dx.doi.org/10.1007/s10714-006-0255-8}\n\n\\bibitem{cropp1}\nB. Cropp and M. Visser, \nGeneral polarization modes for the Rosen gravitational wave.\nClass. Quantum Grav. {\\bf 27}, 165022 (2010). % (9 pages).\n\\url{http://dx.doi.org/10.1088/0264-9381/27/16/165022}\n\n\\bibitem{cropp2}\nB. Cropp and M. Visser, Polarization modes for strong-field gravitational waves.\nJ. Phys.: Conf. Ser. {\\bf 314}, 012073 (2011). % [4 pages].\n\\url{http://dx.doi.org/10.1088/1742-6596/314/1/012073}\n\n\\bibitem{coley12}\nA. Coley, D. McNutt, and R. Milson,\nVacuum plane waves: Cartan invariants and physical interpretation.\nClass. Quantum Grav. {\\bf 29}, 235023 (2012). % (11 pages).\n\\url{http://dx.doi.org/10.1088/0264-9381/29/23/235023}\n\n\\bibitem{mcnutt}\nD. McNutt, R. Milson, and A. Coley, Vacuum Kundt waves.\nClass. Quantum Grav. {\\bf 30}, 055010 (2013). % (29pp).\n\\url{http://dx.doi.org/10.1088/0264-9381/30/5/055010}\n\n\\bibitem{Barnett}\nS. M. Barnett, Maxwellian theory of gravitational waves and their mechanical properties.\nNew J. Phys. {\\bf 16}, 023027 (2014). % (23 pages).\n\\url{http://dx.doi.org/10.1088/1367-2630/16/2/023027}\n\n\\bibitem{griff}\nJ. B. Griffiths, {\\it Colliding plane waves in general relativity} \n(Clarendon Press, Oxford, 1991). \n\n\\bibitem{vdz}\nV. D. Zakharov, {\\it Gravitational waves in Einstein's theory} \n(Halsted Press, New York, 1973) 183 pp.\n\n\\bibitem{exact}\nH. Stephani, D. Kramer, M. MacCallum, C. Hoenselaers, and E. Herlt, \n{\\it Exact solutions of Einstein's field equations}, 2nd ed. (Cambridge\nUniversity Press, Cambridge, 2003) Secs. 24 and 31. \n\n\\bibitem{adam}\nW. Adamowicz, Plane waves in gauge theories of  gravitation. \nGen. Rel. Grav. {\\bf 12}, 677-691 (1980). \\url{https://doi.org/10.1007/BF00771860}\n\n\\bibitem{chen}\nM.-Q. Chen, D.-C. Chern, R. R. Hsu, and W. B. Yeung,  Plane-fronted torsion waves\nin a gravitational gauge theory with a  quadratic Lagrangian. Phys. Rev. D {\\bf 28},\n2094-2095 (1983). \\url{https://doi.org/10.1103/PhysRevD.28.2094}\n\n\\bibitem{sippel}\nR. Sippel and H. Goenner, Symmetry classes of $pp$-waves. Gen. Rel. Grav. {\\bf 18},\n1229-1243 (1986). \\url{https://doi.org/10.1007/BF00763448}\n\n\\bibitem{vadim}\nV. V. Zhytnikov, Wavelike exact solutions of $R+R^{2}+Q^{2}$ gravity.\nJ. Math. Phys. {\\bf 35}, 6001-6017 (1994). \\url{https://doi.org/10.1063/1.530724}\n\n\\bibitem{singh}\nP. Singh and J. B. Griffiths, A new class of exact solutions of the vacuum quadratic\nPoincar\\'e gauge field theory. Gen. Rel. Grav. {\\bf 22}, 947-956 (1990).\n\\url{https://doi.org/10.1007/BF00763233}\n\n\\bibitem{babu}\nO. V. Babourova, B. N. Frolov, and E. A. Klimova, Plane torsion waves in quadratic\ngravitational theories in Riemann-Cartan space. Class. Quantum Grav. {\\bf 16}, 1149-1162 (1999).\n\\url{https://doi.org/10.1088/0264-9381/16/4/005}\n\n\\bibitem{BC1}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, Gravitational waves with torsion in $3D$.\nPhys. Rev. D {\\bf 90}, 044006 (2014). % (9 pages).\n\\url{https://doi.org/10.1103/PhysRevD.90.044006}\n\n\\bibitem{BC2}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, Siklos waves with torsion in $3D$.\nJHEP {\\bf 11}, 141 (2014). % (17 pages).\n\\url{https://doi.org/10.1007/JHEP11(2014)141}\n\n\\bibitem{BC3}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, Vaidya-like exact solutions with torsion.\nJHEP {\\bf 05}, 101 (2015). % (16 pages).\n\\url{https://doi.org/10.1007/JHEP05(2015)101}\n\n\\bibitem{BC4}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, Siklos waves in Poincar\\'e gauge theory.\nPhys. Rev. D {\\bf 92}, 024047 (2015). % (9 pages).\n\\url{https://doi.org/10.1103/PhysRevD.92.024047}\n\n\\bibitem{BC5}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, Generalized $pp$ waves in Poincar\\'e gauge theory.\nPhys. Rev. D {\\bf 95}, 104018 (2017). % (10 pages).\n\\url{https://doi.org/10.1103/PhysRevD.95.104018}\n\n\\bibitem{yno:2017}\nYu. N. Obukhov, Gravitational waves in Poincar\\'e gauge gravity theory. \nPhys. Rev. D {\\bf 95}, 084028 (2017). % (12 pages). \n\\url{https://doi.org/10.1103/PhysRevD.95.084028}\n\n\\bibitem{BCO} \nM. Blagojevi\\'c, B. Cvetkovi\\'c, and Yu. N. Obukhov, Generalized plane \nwaves in Poincar\\'e gauge theory of gravity. Phys. Rev. D {\\bf 96}, \n064031 (2017). % (14 pages).\n\\url{https://doi.org/10.1103/PhysRevD.96.064031}\n\n\\bibitem{tele}\nF. M\\\"uller-Hoissen and J. Nitsch, Teleparallelism - a viable  theory of gravity?\nPhys. Rev. D {\\bf 28}, 718-728 (1983). \\url{https://doi.org/10.1103/PhysRevD.28.718}\n\n\\bibitem{Conroy:2018}\nA. Conroy and T. Koivisto, The spectrum of symmetric teleparallel gravity.\nEur. Phys. J. C {\\bf 78}, 923 (2018). % (6 pages).\n\\url{https://doi.org/10.1140/epjc/s10052-018-6410-z}\n\n\\bibitem{Hohmann:2018}\nM. Hohmann, M. Kr\\v{s}\\v{s}\\'ak, C. Pfeifer, and U. Ualikhanova,\nPropagation of gravitational waves in teleparallel gravity theories.\nPhys. Rev. D {\\bf 98}, 124004 (2018). % (9 pages).\n\\url{https://doi.org/10.1103/PhysRevD.98.124004}\n\n\\bibitem{Hohmann:2019}\nM. Hohmann, C. Pfeifer, U. Ualikhanova, and J. L. Said, Propagation\nof gravitational waves in symmetric teleparallel gravity theories.\nPhys. Rev. D {\\bf 99}, 024009 (2019). % (9 pages).\n\\url{https://doi.org/10.1103/PhysRevD.99.024009}\n\n\\bibitem{Capozziello:2020}\nS. Capozziello, M. Capriolo, and L. Caso, Weak field limit and\ngravitational waves in $f(T, B)$ teleparallel gravity.  Eur. Phys. J. C\n{\\bf 80}, 156 (2020).  % (11 pages).\n\\url{https://doi.org/10.1140/epjc/s10052-020-7737-9}\n\n\\bibitem{Cai:2016}\nY.-F. Cai, S. Capozziello, M. De Laurentis, and E. N. Saridakis,\n$f(T)$ teleparallel gravity and cosmology. Rep. Prog. Phys.\n{\\bf 79}, 106901 (2016). % (121 pages). \n\\url{http://dx.doi.org/10.1088/0034-4885/79/10/106901}\n\n\\bibitem{gurses}\nM. G\\\"urses and M. Halil, $PP$-waves in the generalized Einstein theories,\nPhys. Lett. A {\\bf 68}, 182-184 (1978). \\url{https://doi.org/10.1016/0375-9601(78)90797-1}\n\n\\bibitem{lovelock}\nR. J. Gleiser and G. Dotti, Plane fronted gravitational waves in\nLovelock-Yang-Mills theory. Phys. Rev. D {\\bf 71}, 124029 (2005). % (7 pages).\n\\url{http://dx.doi.org/10.1103/PhysRevD.71.124029}\n% gr-qc/0505094. \n\n\\bibitem{Baykal}\nA. Baykal, $pp$-waves in modified gravity. Turk. J. Phys. {\\bf 40}, 77-112 (2016). \n\n\\bibitem{Mohseni}\nM. Mohseni, Gravitational waves in ghost free bimetric gravity.\nJCAP {\\bf 11}, 023 (2012). % (11 pages).\n\\url{https://doi.org/10.1088/1475-7516/2012/11/023} \n\n\\bibitem{sg1}\nP. C. Aichelburg and T. Dereli, Exact plane-wave solutions of supergravity field\nequations. Phys. Rev. D {\\bf 18}, 1754-1756 (1978).\n\\url{https://doi.org/10.1103/PhysRevD.18.1754}\n\n\\bibitem{sg2}\nT. Dereli and R. W. Tucker, A class of exact supergravity solutions.\nPhys. Lett. B {\\bf 97}, 396-400 (1981).\n\\url{https://doi.org/10.1016/0370-2693(80)90627-9}\n\n\\bibitem{sg3}\nL. F. Urrutia, A new exact solution of classical supergravity.\nPhys. Lett. B {\\bf 102}, 393-396 (1981). \n\\url{https://doi.org/10.1016/0370-2693(81)91239-9}\n\n\\bibitem{sg4}\nC. M. Hull, Killing spinors and exact plane-wave solutions of extended supergravity.\nPhys. Rev. D {\\bf 30}, 334-338 (1984).\n\\url{https://doi.org/10.1103/PhysRevD.30.334}\n\n\\bibitem{sg5}\nF. Embacher, A new class of exact pp-wave solutions in simple supergravity.\nJ. Math. Phys. {\\bf 25}, 1484-1488 (1984). \n\\url{https://doi.org/10.1063/1.526319}\n\n\\bibitem{gimon}\nE. Gimon and A. Hashimoto, Black holes in G\\\"odel universes and $pp$-waves.\nPhys. Rev. Lett. {\\bf 91}, 021601 (2003). % (4 pages).\n\\url{https://doi.org/10.1103/PhysRevLett.91.021601}\n\n\\bibitem{ark1}\nG. T. Horowitz and A. A. Tseytlin, New class of exact solutions in string theory.\nPhys. Rev. D {\\bf 51}, 2896-2917 (1995).\n\\url{https://doi.org/10.1103/PhysRevD.51.2896}\n\n\\bibitem{ark2}\nA. A. Tseytlin, Exact solutions of closed string theory. Class. Quantum Grav.\n{\\bf 12}, 2365-2410 (1995).\n\\url{https://doi.org/10.1088/0264-9381/12/10/003}\n\n\\bibitem{str1}\nA. Chamblin and G. W. Gibbons, Nonlinear supergravity on a brane without\ncompactification. Phys. Rev. Lett. {\\bf 84}, 1090-1093 (2000).\n\\url{https://doi.org/10.1103/PhysRevLett.84.1090}\n\n\\bibitem{str2}\nJ. Michelson, A $pp$-wave with 26 supercharges.\nClass. Quantum Grav. {\\bf 19}, 5935-5949 (2002).\n\\url{https://doi.org/10.1088/0264-9381/19/23/304}\n\n\\bibitem{str3}\nD.~Marolf and S. F. Ross, Plane waves: to infinity and beyond!\nClass. Quantum Grav. {\\bf 19}, 6289-6302 (2002).\n\\url{https://doi.org/10.1088/0264-9381/19/24/302}\n\n\\bibitem{str4}\nE. G. Gimon, A. Hashimoto, V. E. Hubeny, O. Lunin, and M. Rangamani, \nBlack strings in asymptotically plane wave geometries. JHEP {\\bf 08}, 035 (2003).\n% (15 pages). % hep-th/0306131}\n\\url{https://doi.org/10.1088/1126-6708/2003/08/035}\n\n\\bibitem{sokol}\nL. M. Sokolowski, Multidimensional gravitational waves. I. Purely radiative spacetimes.\nGen. Rel. Grav. {\\bf 23}, 29-46 (1991). \\url{https://doi.org/10.1007/BF00766511}\n\n\\bibitem{coley1}\nA. Coley, R. Milson, N. Pelavas, V. Pravda, A. Pravdova, and R. Zalaletdinov,\nGeneralization of $pp$-waves in higher dimensions. Phys. Rev. D {\\bf 67}, 104020 (2003). % (4 pages). \n\\url{https://doi.org/10.1103/PhysRevD.67.104020}\n\n\\bibitem{coley2}\nV.~Pravda, A. Pravdova, A. Coley, and R. Milson, \nAll spacetimes with vanishing curvature invariants.\nClass. Quantum Grav. {\\bf 19}, 6213-6236 (2002). \n\\url{https://doi.org/10.1088/0264-9381/19/23/318}\n\n\\bibitem{hervik}\nS. Hervik, Vacuum plane waves in $4+1 D$ and exact solution to\nEinstein's equations in $3+1 D$. Class. Quantum Grav. {\\bf 20}, \n4315-4327 (2003). %{\\sl E-print: gr-qc/0210080}, 16 pp.  \n\\url{https://doi.org/10.1088/0264-9381/20/19/312}\n\n\\bibitem{ndim}\nYu. N. Obukhov, Generalized plane-fronted gravitational waves in any dimension.\nPhys. Rev. D {\\bf 69}, 024013 (2004). % (7 pages). % gr-qc/0310121\n\\url{http://dx.doi.org/10.1103/PhysRevD.69.024013}\n\n\\bibitem{AJC}\nA. Jim\\'enez-Cano, New metric-affine generalizations of gravitational wave geometries.\nEur. Phys. J. C {\\bf 80}, 672 (2020). % (18 pages). \n\\url{https://doi.org/10.1140/epjc/s10052-020-8239-5}\n\n\\bibitem{ppmag}\nYu. N. Obukhov, Plane waves in metric-affine gravity. Phys. Rev. D\n{\\bf 73}, 024025 (2006). % (6 pages). % gr-qc/0601074\n\\url{http://dx.doi.org/10.1103/PhysRevD.73.024025}\n\n\\bibitem{dirk1} \nD. Puetzfeld, A plane-fronted wave solution in metric-affine gravity.\nIn: {\\it ``Exact solutions and scalar field in gravity: Recent\nDevelopments.\"} Eds. A. Mac\\'{\\i}as, J.~Cervantes-Cota, and C. L\\\"ammerzahl \n(Kluwer: Dordrecht, 2001) pp. 141-151. %; gr-qc/0011116. \n\n\\bibitem{dirk2}\nA. Garc\\'{\\i}a, A. Mac\\'{\\i}as, D. Puetzfeld, and J. Socorro, \nPlane-fronted waves in metric-affine gravity. Phys. Rev. D {\\bf 62}, 044021 (2000).\n\\url{https://doi.org/10.1103/PhysRevD.62.044021}\n\n\\bibitem{king}\nA. D. King and D. Vassiliev, Torsion waves in metric-affine field theory.\nClass. Quantum Grav. {\\bf 18}, 2317-2329 (2001).\n\\url{https://doi.org/10.1088/0264-9381/18/12/307}\n\n\\bibitem{vas1}\nD. Vassiliev, Pseudoinstantons in metric-affine theory. \nGen. Rel. Grav. {\\bf 34}, 1239-1265 (2002).\n\\url{https://doi.org/10.1023/A:1019730602253}\n\n\\bibitem{vas2}\nD. Vassiliev, Quadratic metric-affine theory. Ann. Phys. (Leipzig)\n{\\bf 14}, 231-252 (2005). \\url{https://doi.org/10.1002/andp.200410118}\n\n\\bibitem{vas3}\nV. Pasic and D. Vassiliev, $PP$-waves with torsion and metric-affine gravity.\nClass. Quantum Grav. {\\bf 22}, 3961-3975 (2005). % gr-qc/0505157.\n\\url{https://doi.org/10.1088/0264-9381/22/19/010}\n\n\\bibitem{pasic1}\nV. Pasic and E. Barakovic, $PP$-waves with torsion: a metric-affine model \nfor the massless neutrino. Gen. Rel. Grav. {\\bf 46}, 1787 (2014). [27 pages].\n\\url{http://dx.doi.org/10.1007/s10714-014-1787-y}\n\n\\bibitem{pasic2}\nV. Pasic, E. Barakovic, and N. Okicic,\nA new representation of the field equations of quadratic metric-affine gravity.\nAdv. Math. Sci. J. {\\bf 3}, 1, 33-46 (2014). \n\n\\bibitem{Karananas}\nG. K. Karananas, The particle spectrum of parity-violating Poincar\\'e gravitational theory,\nClass. Quantum Grav. {\\bf 32}, 055012 (2015). % (38 pages).\n\\url{https://doi.org/10.1088/0264-9381/32/5/055012}\n\n\\bibitem{BC6}\nM. Blagojevi\\'c and B. Cvetkovi\\'c, General Poincar\\'e gauge theory: Hamiltonian structure\nand particle spectrum. Phys. Rev. D {\\bf 98}, 024014 (2018). % arXiv:1804.05556.\n\\url{https://doi.org/10.1103/PhysRevD.98.024014}\n\n\\bibitem{Baikov:1992}\nP. Baikov, M. Hayashi, N. Nelipa, and S. Ostapchenko, Ghost- and tachyon-free\ngauge-invariant, Poincar\\'e, affine and projective Lagrangians.\nGen. Relat. Grav. {\\bf 24}, 867-880 (1992). \\url{https://doi.org/10.1007/BF00759092}\n\n\\bibitem{Percacci:2020}\nR. Percacci and E. Sezgin, New class of ghost- and tachyon-free metric affine gravities.\nPhys. Rev. D {\\bf 101}, 084040 (2020). % (25 pages).\n\\url{https://doi.org/10.1103/PhysRevD.101.084040}\n\n\\bibitem{JanssenJC:2019}\nB. Janssen and A. Jim\\'enez-Cano, On the topological character of metric-affine\nLovelock Lagrangians in critical dimensions. Phys. Lett. B {\\bf 798}, 134996 (2019).\n\\url{https://doi.org/10.1016/j.physletb.2019.134996}\n\n\\bibitem{selected}\nYu. N. Obukhov, Poincar\\'e gauge gravity: Selected topics.\nInt. J. Geom. Meth. Mod. Phys. {\\bf 3}, 95-138 (2006).\n\\url{https://doi.org/10.1142/S021988780600103X}\n\n\\bibitem{Obukhov:1989}\nYu. N. Obukhov, V. N. Ponomariev, and V. V. Zhytnikov, Quadratic Poincar\\'e\ngauge theory of gravity: a comparison with the general relativity theory.\nGen. Relat. Grav. {\\bf 21}, 1107-1142 (1989). \\url{https://doi.org/10.1007/BF00763457}\n\n\\bibitem{yno:2019}\nYu. N. Obukhov, Exact solutions in Poincar\\'e gauge gravity theory.\nUniverse {\\bf 5(5)}, 127 (2019). % (13 pages).\n\\url{https://doi.org/10.3390/universe5050127}\n\n\\bibitem{Nester:1999}\nJ. M. Nester and H.-J. Yo, Symmetric teleparallel general relativity.\nChin. J. Phys. {\\bf 37}, 113-117 (1999). \n\n\\bibitem{Adak:2006a}\nM. Adak, The symmetric teleparallel gravity. Turk. J. Phys. {\\bf 30}, 379-390 (2006). \n\n\\bibitem{Adak:2006b}\nM. Adak, M. Kalay, and \\\"O. Sert, Lagrange formulation of the symmetric teleparallel gravity.\nInt. J. Mod. Phys. D {\\bf 15}, 619-634 (2006).\n\\url{https://doi.org/10.1142/S0218271806008474}\n\n\\bibitem{Jimenez:2018}\nJ. B. Jim\\'enez, L. Heisenberg, and T. Koivisto, Coincident general relativity.\nPhys. Rev. D {\\bf 98}, 044048 (2018).\n\\url{https://doi.org/10.1103/PhysRevD.98.044048}\n\n\\bibitem{Chen}\nH. Chen, F.-H. Ho, J. M. Nester, C.-H. Wang, and H.-J. Yo, Cosmological dynamics with\npropagating Lorentz connection modes of spin zero. JCAP {\\bf 10}, 027 (2009).\n\\url{https://doi.org/10.1088/1475-7516/2009/10/027}\n\n\\bibitem{Ho1}\nJ. K. Ho and J. M. Nester, Poincar\\'e gauge theory with even and odd parity dynamic connection\nmodes: isotropic Bianchi cosmological models. J. Phys.: Conf. Ser. {\\bf 330}, 012005 (2011).\n\\url{https://doi.org/10.1088/1742-6596/330/1/012005}\n\n\\bibitem{Ho2}\nF.-H. Ho and J. M. Nester, Poincar\\'e gauge theory with coupled even and odd parity\nspin-0 modes: cosmological normal modes. Annalen der Physik {\\bf 524}, 97-106 (2012).\n\\url{https://doi.org/10.1002/andp.201100101}\n\n\\bibitem{Ho3}\nF.-H. Ho and J. M. Nester, Poincar\\'e gauge theory with coupled even and odd parity\ndynamic spin-0 modes: dynamical equations for isotropic Bianchi cosmologies.\nInt. J. Mod. Phys. D {\\bf 20}, 2125 (2011).\n\\url{https://doi.org/10.1142/S0218271811020391}\n\n\\bibitem{Diakonov}\nD. Diakonov, A. G. Tumanov, and A. A. Vladimirov, Low-energy general relativity with\ntorsion: A systematic derivative expansion. Phys. Rev. D {\\bf 84}, 124042 (2011). % (16 pages).\n\\url{https://doi.org/10.1103/PhysRevD.84.124042}\n\n\\bibitem{Baekler1}\nP. Baekler, and F. W. Hehl, Beyond Einstein-Cartan gravity: quadratic torsion and curvature\ninvariants with even and odd parity including all boundary terms. Class. Quantum Grav. {\\bf 28},\n215017 (2011). \\url{https://doi.org/10.1088/0264-9381/28/21/215017}\n\n\\bibitem{Baekler2}\nP. Baekler, F. W. Hehl, and J. M. Nester, Poincar\\'e gauge theory of gravity: Friedman cosmology\nwith even and odd parity modes: Analytic part. Phys. Rev. D {\\bf 83}, 024001 (2011). % (23 pages).\n\\url{https://doi.org/10.1103/PhysRevD.83.024001}\n\n\\bibitem{Iosifidis}\nD. Iosifidis and L. Ravera, {\\it Parity violating metric-affine gravity theories},\ne-Print ArXiv: gr-qc/2009.03328 (38 pages).\n\\url{https://arxiv.org/abs/2009.03328}\n\n\\end{thebibliography}\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:00:35", "yymm": "2010", "arxiv_id": "2010.14528", "url": "https://arxiv.org/abs/2010.14528", "source": "arxiv"}}
{"text": "\\documentclass[]{llncs}\n\n\\usepackage{mdframed}\n\\usepackage{amsmath, amssymb}\n\\usepackage[scr=boondoxo]{mathalfa}\n\\usepackage{array, adjustbox}\n\\DeclareRobustCommand*{\\Dashv}{%\n  \\Relbar\\joinrel\\mathrel{|}%\n}\n\\usepackage{cancel}\n\\usepackage{subcaption}\n\\captionsetup{compatibility=false}\n\\usepackage{soul}\n\\usepackage{tikz}\n\\usetikzlibrary{arrows,shapes}\n\\usetikzlibrary{positioning}\n\\usepackage{tabularx, longtable}\n\\usepackage{bussproofs}\n\\usepackage{rotating}\n\\usepackage{longtable}\n\\usepackage{stmaryrd}\n% \\usepackage{enumitem}\n%\\setlist[enumerate]{nosep}\n%\\newtheorem{corollary}{Corollary}\n%\\newtheorem{conjecture}{Conjecture}\n\\newtheorem{observation}{Observation}\n\\newenvironment{scprooftree}[1]%\n  {\\gdef\\scalefactor{#1}\\begin{center}\\proofSkipAmount \\leavevmode}%\n  {\\scalebox{\\scalefactor}{\\DisplayProof}\\proofSkipAmount \\end{center} }\n\n\\newcommand{\\myeq}[2]{\\mathrel{\\stackrel{\\makebox[0pt]{\\mbox{\\normalfont\\tiny #2}}}{#1}}}\n\n\\newcommand{\\tuple}[1]{\\langle#1\\rangle}\n\\renewcommand{\\ul}{\\underline}\n\\newcommand{\\ttt}{\\texttt}\n\n\\newcommand{\\mtt}{\\mathtt}\n\\newcommand{\\mrm}{\\mathsf}\n\n\\newcommand{\\N}{\\mathbb{N}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\renewcommand{\\L}{\\mathbb{L}}\n\\newcommand{\\M}{\\mathbb{M}}\n\n\\newcommand{\\G}{\\mathcal{G}}\n\\newcommand{\\R}{\\mathcal{R}}\n\n\\renewcommand{\\a}{\\mathtt{a}}\n\\renewcommand{\\b}{\\mathtt{b}}\n\\renewcommand{\\c}{\\mathtt{c}}\n\\renewcommand{\\d}{\\mathtt{d}}\n\\newcommand{\\e}{\\mathtt{e}}\n\n\\newcommand{\\dder}{\\Rightarrow}\n\\newcommand{\\ldder}{\\Leftarrow}\n\\newcommand{\\der}{\\Rightarrow^*}\n\\newcommand{\\lder}{\\Leftarrow^*}\n\n\\newcommand{\\DSto}{\\mathop{\\to}\\limits}\n\\newcommand{\\DSsymto}{\\mathop{\\symto}\\limits}\n\n\\newcommand{\\Sem}[1]{\\llbracket{#1}\\rrbracket}\n\n\\newcommand{\\lst}{\\mathscr{l}}\n\\newcommand{\\mrk}{\\mathscr{m}}\n\\newcommand{\\blue}{\\mathtt{blue}}\n\\newcommand{\\none}{\\mathtt{none}}\n\\newcommand{\\red}{\\mathtt{red}}\n\\newcommand{\\green}{\\mathtt{green}}\n\\newcommand{\\any}{\\mathtt{any}}\n\\newcommand{\\dashed}{\\mathtt{dashed}}\n\\newcommand{\\grey}{\\mathtt{grey}}\n\\renewcommand{\\empty}{\\mathtt{empty}}\n\n\\newcommand{\\Sat}{\\vDash\\,}\n\\newcommand{\\Sata}{\\vDash^\\alpha\\,}\n\\newcommand{\\Implies}{\\Rightarrow\\,}\n\n\\newcommand{\\sou}{\\mrm{s}}\n\\newcommand{\\tar}{\\mrm{t}}\n\\newcommand{\\mV}{\\mrm{m_V}}\n\\newcommand{\\mE}{\\mrm{m_E}}\n\\newcommand{\\lV}{\\mrm{l_V}}\n\\newcommand{\\lE}{\\mrm{l_E}}\n\n\\newcommand{\\RG}{\\rho_g(G)}\n\\newcommand{\\RH}{\\rho_{g^*}(H)}\n\\newcommand{\\E}[1]{\\exists_{\\mrm{#1}}}\n\\newcommand{\\A}[1]{\\forall_{\\mrm{#1}}}\n\n\\newcommand{\\SLP}{\\small{\\text{SLP}}}\n\\newcommand{\\SUCCESS}{\\small{\\text{SUCCESS}}}\n\\newcommand{\\FAIL}{\\small{\\text{FAIL}}}\n\n\n\\newcommand{\\Def}[3]%\n\t{$~$\\begin{definition}[#1]\\label{#2}\\normalfont\n    #3\\hfill$\\square$\n\t\\end{definition}}%\n\\newcommand{\\Prop}[3]%\n\t{$~$\\begin{proposition}[#1]\\label{#2}\\normalfont\n    #3\n\t\\end{proposition}}%\n\\newcommand{\\Theo}[3]%\n\t{$~$\\begin{theorem}[#1]\\label{#2}\\normalfont\n    #3\n\t\\end{theorem}}%\n\\newcommand{\\Ex}[3]%\n\t{$~$\\begin{example}[#1]\\label{#2}\\normalfont\n    #3\n\t\\end{example}}%\n\\newcommand{\\Lemma}[2]%\n\t{\\begin{lemma}\\label{#1}\\normalfont\n    #2\n\t\\end{lemma}}%\n\\newcommand{\\Col}[2]%\n\t{$~$\\\\\\begin{corollary}\\label{#1}\\normalfont\n    #2\n\t\\end{corollary}}%\t\n\\newcommand{\\Obsv}[2]%\n\t{$~$\\\\\\begin{observation}\\label{#1}\\normalfont\n    #2\n\t\\end{observation}}%\t\n\n\\newcommand{\\pproof}[1]%\n\t{$~$\\begin{proof}\\normalfont #1 \\qedhere\n\t\\end{proof}}%\n\\newcommand{\\Remark}[1]%\n\t{\\begin{remark}\\normalfont #1\n\t\\end{remark}}%\n\t\n\\newcommand{\\lkr}{\\langle L\\leftarrow K\\rightarrow R,~\\Gamma\\rangle}\n\n\\DeclareUnicodeCharacter{2212}{-}\n\n\\begin{document}\n\n\\title{Verifying Graph Programs with\\\\First-Order Logic (Extended Version)}\n\n\\author{Gia S. Wulandari\\thanks{Supported by Indonesia Endowment Fund for Education (LPDP)}\\inst{1,2}\n\\and\nDetlef Plump\\inst{1}\n}\n\n\\authorrunning{G.S. Wulandari, D. Plump}\n\n\\institute{Department of Computer Science, University of York, UK\n\\and School of Computing, Telkom University, Indonesia\n}\n\n\\maketitle\n\\pagestyle{plain}\n\\begin{abstract}\nWe consider Hoare-style verification for the graph programming language GP\\,2. In previous work, graph properties were specified by so-called E-conditions which extend nested graph conditions. However, this type of assertions is not easy to comprehend by programmers that are used to formal specifications in standard first-order logic. In this paper, we present an approach to verify GP\\,2 programs with a standard first-order logic. We show how to construct a strongest liberal postcondition with respect to a rule schema and a precondition. We then extend this construction to obtain strongest liberal postconditions for arbitrary loop-free programs. Compared with previous work, this allows to reason about a vastly generalised class of graph programs. In particular, many programs with nested loops can be verified with the new calculus. \\end{abstract}\n\n\\section{Introduction}\n\\label{sec:introduction}\nVarious Hoare-style proof systems for the graph programming language GP\\,2 have been developed by Poskitt and Plump, see for example \\cite{PoskittP12,Poskitt13}. These calculi use so-called E-conditions as assertions which extend nested graph conditions \\cite{Pennemann09} with support for expressions. However, a drawback of E-conditions and nested graph conditions is that they are not easy to understand by average programmers who are typically used to write formal specifications in standard first-order logic. To give a simple example, the following  E-condition expresses that every node is labelled by an integer: $\\forall$(\\begin{tikzpicture}[scale=0.5, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left:\\scriptsize 1] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,,\\,\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left\n   :\\scriptsize 1] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,\\mid\\,\\mtt{int(a)}))$ $\\land\\,\\forall$(\\begin{tikzpicture}[scale=0.5, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left:\\scriptsize 1, fill=red!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,,\\,\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left\n   :\\scriptsize 1, fill=red!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,\\mid\\,\\mtt{int(a)}))$ $\\land\\,\\forall$(\\begin{tikzpicture}[scale=0.5, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left:\\scriptsize 1, fill=green!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,,\\,\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left\n   :\\scriptsize 1, fill=green!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,\\mid\\,\\mtt{int(a)}))$ $\\land\\,\\forall$(\\begin{tikzpicture}[scale=0.5, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left:\\scriptsize 1, fill=blue!40] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,,\\,\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left\n   :\\scriptsize 1, fill=blue!40] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,\\mid\\,\\mtt{int(a)}))$ $\\land\\,\\forall$(\\begin{tikzpicture}[scale=0.5, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left:\\scriptsize 1, fill=gray!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,,\\,\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n   \\node[circle, draw, label=left\n   :\\scriptsize 1, fill=gray!50] (a) at (0, 0) {$\\mtt{a}$};\n\\end{tikzpicture}$\\,\\mid\\,\\mtt{int(a)}))$. Having to write two quantifiers that refer to the \\emph{same} object appears unnatural from the perspective of standard predicate logic where a single universal quantifier would suffice. In the logic we introduce in this paper, the above condition is simply written as $\\mrm{\\forall_Vx(int(\\lV(x)))}$. Both E-conditions and first-order formulas tend to get lengthy in examples, but our concern with nested graph conditions is that they require a non-standard interpretation. We believe that programmers cannot be expected to think in terms of morphisms and commuting diagrams, but should be allowed to work with a type of logic that they are familiar with.\n\nIn this paper we use assertions which are conventional first-order formulas enriched with GP\\,2 expressions. We believe that these assertions are easier to comprehend by programmers than E-conditions and also offer the prospect of reusing the large range of tools available for first-order logic.\n\nTo use our assertions in Hoare-style verification, we show how to construct a strongest liberal postcondition Slp($c,r$) for a given rule schema $r$ and a precondition $c$. Based on this construction, we are able to construct a strongest liberal postcondition for any loop-free graph programs and preconditions. In addition, we are able to give syntactic conditions on host graphs which for any loop-free program express successful execution resp.\\ the existence of a failing execution. With these results we obtain a verification calculus that can handle considerably more programs than the calculi in \\cite{PoskittP12,Poskitt13}. In particular, many programs with nested loops can now be formally verified, which has been impossible so far.\n\nNevertheless, our proof calculus is not relatively complete because first-order logic is not powerful enough to express all necessary assertions. Therefore we present a semantic version of the calculus which turns out to be relatively complete. \n\nThe remainder of this paper is structured as follows. A brief review of the graph programming language GP\\,2 can be found in Section 2. In Section \\ref{sec:FOL}, we introduce first-order formulas for GP\\,2 programs. In Section \\ref{sec:SLP}, we outline the construction of a strongest liberal postcondition for a given rule schema and first-order formula. Section \\ref{sec:proofrules} presents the proof rules of a semantic and a syntactic verification calculus, and identifies the class of programs that can be verified with the syntactic calculus.\n%Section \\ref{sec:completeness} then discusses the soundness and completeness of our calculi. \nIn Section \\ref{sec:ex}, we demonstrate how to verify a graph program for computing a 2-colouring of an input graph. In Section \\ref{sec:completeness}, we discuss the soundness and completeness of our proof calculi. Section \\ref{sec:related_work} contains a comparison of our approach with other approaches in the literature. Finally, we conclude and give some topics for future work in Section \\ref{sec:conclusion}. \n\\section{Graph programming language GP\\,2}\n\\label{sec:GP2}\nGP\\,2 is a graph programming language using graph transformation systems with the double-pushout approach, which was introduced in \\cite{Plump09}. In this section, we briefly introduce graph transformation systems in GP\\,2. For more detail documentation of GP\\,2, we refer readers to \\cite{Bak15a}.\n\n\\subsection{GP\\,2 graphs}\n\nA graph is a flexible structure in representing objects and relations between them. Objects are usually represented by nodes, while edges represent relations between them. Additional information about the objects and the relations are usually written as a label of the nodes and edges. Also, sometimes rooted nodes are used to distinguish some nodes with others.\n\n\\begin{definition}[Label Alphabet]\\label{def:label}\n\\emph{A label alphabet} $\\mathcal{C}=\\langle \\mathcal{C}_V,\\mathcal{C}_E\\rangle$ is a pair comprising a set $\\mathcal{C}_V$ of node labels and a set $\\mathcal{C}_E$ of edge labels. \\qed\n\\end{definition}\n% \\Def{Label alphabet}{def:label}{\n% \\emph{A label alphabet} $\\mathcal{C}=\\langle \\mathcal{C}_V,\\mathcal{C}_E\\rangle$ is a pair comprising a set $\\mathcal{C}_V$ of node labels and a set $\\mathcal{C}_E$ of edge labels.\n% }\n\n\\Def{Graph over label alphabet; class of graphs}{def:graphs}{\n\\emph{A graph over label alphabet $\\mathcal{C}$} is a system $G = \\langle V_G, E_G, s_G, t_G, l_G, m_G, p_G\\rangle$ comprising a finite set $V_G$ of nodes, a finite set $E_G$ of edges, source and target functions $s_G, t_G : E_G \\rightarrow V_G$, a partial node labelling function $l_G : V_G \\rightarrow \\mathcal{C}_V$, an edge labelling function $m_G : E_G \\rightarrow \\mathcal{C}_E$, and a partial rootedness function $p_G : V_G \\rightarrow \\{0,1\\}$. A \\emph{totally labelled graph} is a graph where its node labelling and rootedness functions are total. We then denote by $\\mathcal{G(C_\\perp)}$ the set of all graphs over $\\mathcal{C}$, and $\\mathcal{G(C)}$ the set of all totally labelled graphs over $\\mathcal{C}$.\n}\n\nGraphically, in this paper, we represent a node with a circle, an edge with an arrow where its tail and head represent the source and target, respectively. The label of a node is written inside the node, while the label of an edge is written next to the arrow. The rootedness of a node $v$ is represented by the line of the circle representing $v$, that is, standard circle for an unrooted node ($p(v)=0$) and bold circle for a rooted node ($p(v)=1$). To represent a node $v$ with undefined rootedness  ($p(v)=\\perp$), we also use a standard circle. We use the same representation because nodes with undefined rootedness only exist in the interface of GP\\,2 rules, and the interface contains only this kind of nodes so that no ambiguity will arise even when we use the same representation.\n\nThere are two kinds of graphs in GP\\,2, that are host graphs and rule graphs. A label in a host graph is a pair of list and mark, while a label in a rule graph is a pair of expression and mark. Input and output of graph programs are host graphs, while graphs in GP\\,2 rules are rule graphs.\n\n\\Def{GP\\,2 labels}{def:GP2label}{\nA set of node marks, denoted by $\\mathbb{M}_V$, is the set $\\{\\none,$ $\\red, \\blue, \\green, \\grey\\}$, while a set of edge marks, denoted by $\\mathbb{M}_E$, is the set $\\{\\none,$ $\\red, \\blue, \\green, \\dashed\\}$. A set of lists, denoted by $\\mathbb{L}$, consists of all (list of) integers and strings that can be derived from the following abstract syntax:\n\\begin{center}\\small\n\\begin{tabular}{lcl}\n      $\\mathbb{L}$ & ::= & $\\mtt{empty}$ $\\mid$ GraphExp $\\mid$ $\\mathbb{L}$ `:' $\\mathbb{L}$ \\\\\n      GraphExp & ::= & [`-'] Digit \\{Digit\\} $\\mid$ GraphStr\\\\\n      GraphStr & ::= & `~``~' \\{Character\\} ' \" ' $\\mid$ GraphStr `.' GraphStr\n    \\end{tabular}    \n\\end{center}\n\\noindent where Character is the set of all printable characters except `\"' (i.e. ASCII characters 32, 33, and 35-126), while Digit is the digit set $\\{0,\\ldots,9\\}$. \n\n\\emph{A GP\\,2 node label} is a pair $\\tuple{\\lst^V, \\mrk^V}\\in\\mathbb{L}\\times\\mathbb{M}_V$, and a \\emph{GP\\,2 edge label} is a pair $\\tuple{\\lst^E, \\mrk^E}\\in\\mathbb{L}\\times\\mathbb{M}_E$. We then denote the set of GP\\,2 labels as $\\mathcal{L}=\\tuple{\\mathcal{L}_V,\\mathcal{L}_E}$.\n}\n\nThe colon operator `:' is used to concatenate atomic expressions while the dot operator `.' is used to concatenate strings. The empty list is signified by the keyword $\\mtt{empty}$, where it is displayed as a blank label graphically.\n\nBasically, in a host graph, a list consists of (list of) integers and strings which are typed according to hierarchical type system as below:\n\\begin{center}\n    \\begin{tikzpicture}[remember picture,\n        inner/.style={inner sep=0pt},\n        outer/.style={inner sep=2pt}, scale=0.9\n        ]\n    \\node[outer] (A1) at (0,0) {\n        \\begin{tikzpicture}[scale=1, transform shape]\n\t\t    \\node[inner] (Aa) at (4.5,-0.5) {\\footnotesize{$\\mtt{char}$}};\t\n\t\t    \\node[inner] (Ab) at (3,-0.5) {\\footnotesize{$\\mtt{string}$}};\t\n\t    \t\\node[inner] (Ac) at (3,0.5) {\\footnotesize{$\\mtt{int}$}};\t\n\t\t    \\node[inner] (Ad) at (1.5,0) {\\footnotesize{$\\mtt{atom}$}};\t\n\t\t    \\node[inner] (Ae) at (0,0) {\\footnotesize{$\\mtt{list}$}};\t\n    \t\t\\draw[white] (Aa) to node[black] {$\\supseteq$} (Ab);\n    \t\t\\draw[white] (Ab) to node[black,rotate=-45] {$\\supseteq$} (Ad);\n    \t\t\\draw[white] (Ac) to node[black,rotate=45] {$\\supseteq$} (Ad);\n    \t\t\\draw[white] (Ad) to node[black] {$\\supseteq$} (Ae);\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\\end{center}\nwhere the domain for $\\mtt{list, atom, int, string,}$ and $\\mtt{char}$ is $\\mathbb{Z}~\\cup$ Char$^*$)$^*, \\mathbb{Z}~\\cup$ Char$^*, \\mathbb{Z},$ \\{Char\\}$^*$, and Char respectively.\n\n\\Def{Labels of rules in GP\\,2}{def:RSlabel}{\nLet $\\mathbb{E}$ be the set of all expressions that can be derived from the syntactic class List in the following grammar:\n\\begin{center}\\small\n\\begin{tabular}{lcl}\n     $\\mathbb{E}$ & ::= & List\\\\\n      List & ::= & $\\mtt{empty}$ $\\mid$ Atom $\\mid$ List \\lq:' List $\\mid$ ListVar \\\\\n      Atom & ::= & Integer $\\mid$ String $\\mid$ AtomVar \\\\\n      Integer & ::= & [\\lq-']~Digit~\\{Digit\\}~$\\mid$~\\lq('Integer\\lq)'  $\\mid$ IntVar \\\\\n       & & $\\mid$ Integer (\\lq+' $\\mid$ \\lq-' $\\mid$ \\lq*' $\\mid$ \\lq/') Integer \\\\\n       & & $\\mid$ ($\\mtt{indeg}$ $\\mid$ $\\mtt{outdeg}$) \\lq('NodeId\\lq)' \\\\\n       & & $\\mid$ $\\mtt{length}$ \\lq('AtomVar $\\mid$ StringVar $\\mid$ ListVar\\lq)' \\\\\n      String & ::= & Char $\\mid$ String `.' String $\\mid$ StringVar\\\\\n      Char & ::= & ` `` '\\{Character\\}` \" ' $\\mid$ CharVar\\\\\n    \\end{tabular}\n\\end{center}\n\\noindent where ListVar, AtomVar, IntVar, StringVar, and CharVar represent variables of type $\\mtt{list, atom,}$ $\\mtt{int, string,}$ and $\\mtt{char}$ respectively. Also, NodeId represents node identifiers.\n\n\\emph{Label alphabet} for left and right-hand graphs of a GP\\,2 rule, denoted by $\\mathcal{S}$, contains all pairs node label $\\tuple{\\lst^V,\\mrk^V}\\in\\mathbb{E}\\times(\\mathbb{M}_V\\cup\\{\\any\\})$ and edge label $\\tuple{\\lst^E,\\mrk^E}\\in\\mathbb{E}\\times(\\mathbb{M}_E\\cup\\{\\any\\})$}\n\n\\Def{GP\\,2 host graphs and rule graphs}{def:GP2graphs}{\nA \\emph{host graph} $G$ is a graph over $\\mathcal{L}$, and a \\emph{rule graph} $H$ is a graph over $\\mathcal{S}$. A host graph (or rule graph) $G$ has a node labelling function $l^V_G=\\tuple{\\lst^V_G,\\mrk^V_G}$ such that for every node $v\\in V_G$, $\\lst^V_G(v)$ is defined if and only if $\\mrk^E_G(v)$ is defined. Similarly, for every edge $e\\in E_G$, $\\lst^E_G(e)$ is defined iff $\\mrk^E_G(e)$ is defined.\n}\n\nIf we consider the grammars of Definition \\ref{def:label} and Definition \\ref{def:RSlabel}, it is obvious that $\\mathbb{L}$ is part of expressions that can be derived in the latter grammar. Hence, $\\mathcal{L}\\subset\\mathcal{S}$, which means we can consider host graphs as special cases of rule graphs. From here, we may refer `rule graphs' simply as `graphs', which also means host graphs are included.\n\nSyntactically, a graph in GP\\,2 is written based on the following syntax:\n\\begin{center}\\small\n\\begin{tabular}{lcl}\n      Graph & ::= & [Position] `$\\mid$' {Nodes} `$\\mid$' {Edges}\\\\\n      Nodes & ::= & `(' NodeId [`(R)'] `,' Label [ `,' Position ] `)'\\\\\n      Edges & ::= & `(' EdgeId [`(B)']`,' NodeId `,' NodeId `,' Label `)'\\\\\n    \\end{tabular}\n\\end{center}\n\n\\noindent where Position is a set of floating-point cartesian coordinates to store layout information for graphical editors, NodeId and EdgeId are sets of node and edge identifiers, and Label is set of labels as defined in Definition \\ref{def:label} and Definition \\ref{def:RSlabel}. Also, (R) in Nodes is used for rooted nodes while (B) in Edges is used for bidirectional edges. Bidirectional edges may exist in rule graphs but not in host graphs.\n\nThe marks \\ttt{red}, \\ttt{green}, \\ttt{blue} and \\ttt{grey} are graphically represented by the obvious colours while \\ttt{dashed} is represented by a dashed line. The wildcard mark $\\mtt{any}$ is represented by the colour magenta. \n\nNode labels are undefined only in the interface graphs of rule schemata. This allows rules to relabel nodes. Similarly, the root function is undefined only for the nodes of interface graphs. The purpose of root nodes is to speed up the matching of rule schemata \\cite{Bak15a,PlumpB12}.\n\n\\Ex{A graph}{ex:graph}{Let $G$ be a graph with $V_G=\\{1,2,3\\}, E_G=\\{e1,e2\\}, s_G=\\{e1\\mapsto 1, e2\\mapsto 1\\}, t_G=\\{e1\\mapsto 2, e2\\mapsto 3\\}, l_G=\\{1\\mapsto \\tuple{a,\\none}, 2\\mapsto \\tuple{b,\\red}, 3\\mapsto \\tuple{a+2,\\none}\\}, m_G=\\{e1\\mapsto \\tuple{d,\\none}, e2\\mapsto \\tuple{e,\\dashed}\\},$ and $p_G=\\{1\\mapsto 0, 2\\mapsto 1, 3\\mapsto 0\\}$. Graphically, $G$ can be seen as the following graph:\n\\begin{center}\n    \\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=18pt},\n  outer/.style={inner sep=2pt}, scale=0.9\n  ]\n  \\node[outer] (A) at (0,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\node[inner, label=below:\\tiny 2, fill=red, ultra thick] (Ab) at (1.5,0) {$\\mtt{b}$};\t\n        \\node[inner, label=below:\\tiny 3] (Ac) at (-1.5,0) {$\\mtt{a+2}$};\t\n\t\t\\draw[-latex] (Aa) to node[above] {$\\mtt{d}$} (Ab);\n\t\t\\draw[-latex, dashed] (Aa) to node[above] {$\\mtt{e}$} (Ac);\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\\end{center}\nSyntactically in GP\\,2, $G$ is written as follows:\n\\[\n\\small{\\mtt{~\\mid~(1, a)~(2(R), b\\#red)~(3, a+2) \\mid~(e1, 1, 2, d)~(e2, 1, 3, e\\#dashed)}}\\]\n}        \n\nTo show a relation between graphs, which are what we do in graph transformations, we use graph morphism. In GP\\,2, in addition to graph morphism, we also have graph premorphisms which is similar to graph morphisms but not considering node and edge labels.\n\n\\Def{Graph morphisms}{def:morphisms}{\nGiven two graphs $G$ and $H$. A graph morphism $g:G\\rightarrow H$ is a pair of mapping $g=\\langle g_V:V_G\\rightarrow V_H, g_E:E_G\\rightarrow E_H\\rangle$ such that for all nodes and edges in $G$, sources, targets, labels, marks, and rootedness are preserved. That is: $g_V\\circ s_G = s_H\\circ g_E$, $g_V\\circ t_G = t_H\\circ g_E$, $l_H(g_V(x)) = l_G(x)$, $m_H(g_E(y)) = m_G(y)$ for all $x\\in V_G$ such that $l_G(x)\\neq\\perp$ and all $y\\in E_G$ such that $m_G(y)\\neq\\perp$. Also, for all $v\\in V_G,$ such that $p_G(v)\\neq\\perp$ $p_H(g_V(v))=p_G(v)$. A graph morphism $g$ is injective (surjective) if both $g_V$ and $g_E$ are injective (surjective). A graph morphism $g : G \\rightarrow H$ is an \\emph{isomorphism} if $g$ is both injective and surjective, also satisfies $l_H(g_V(v)) = \\perp$ for all nodes $v$ with $l_G(v) = \\perp$ and $v\\in r_G$ iff $g(v)\\in r_H$ for all $v\\in V_G$. Furthermore. we call a morphism $g$ as an \\emph{inclusion} if $g(x)=x$ for all $x$ in $G$.\n}\n\n\\Def{Premorphisms}{def:premorphism}{\nGiven a rule graph $L$ and a host graph $G$. A premorphism $g:L\\rightarrow G$ consists of two injective functions $g_V:V_L\\rightarrow V_G$ and $g_E:E_L\\rightarrow E_G$ that preserve sources, targets, and rootedness.\n}\n\n\\subsection{Conditional rule schemata}\nLike traditional rules in graph transformation that use double-pushout approach, rules in GP\\,2 (called rule schemata) consists of a left-hand graph, an interface graph, and a right-hand graph. In addition, GP\\,2 also allows a condition for the left-hand graph. When a condition exists, the rule is called a conditional rule schema.\n\n% \\Def{Rules}{def:rules}{\n% A \\emph{rule} $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$ comprises $L,R\\in\\mathcal{G(L)}$ and $K\\in\\mathcal{G(L_\\perp)}$, and inclusions $K\\rightarrow L$ and $K\\rightarrow R$. $L$ is called the \\emph{left-hand graph} of $r$, $R$ is the \\emph{right-hand graph} of $r$, and $K$ is the interface of $r$.\n% }\n\n% While the left and right-hand graphs of a rule are totally labelled host graph, a rule schema may have a rule graph as its left or right-hand graph. In addition, interface of a rule schema containing only unlabelled nodes with undefined rootedness.\n\n\\Def{Rule schemata}{def:RS}{\nA \\emph{rule schema} $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$ comprises totally labelled rule graphs $L$ and $R$, a graph $K$ containing only unlabelled nodes with undefined rootedness, also inclusions $K\\rightarrow L$ and $K\\rightarrow R$. All list expressions in $L$ are simple (i.e. no arithmetic operators, contains at most one occurrence of a list variable, and each occurrence of a string sub-expression contains at most one occurrence of a string variable). Moreover, all variables in $R$ must also occur in $L$, and every node and edge in $R$ whose mark is $\\mtt{any}$ has a preserved counterpart item in $L$. An \\emph{unrestricted rule schema} is a rule schema without restriction on expressions and marks in its left and right-hand graph.\n}\n\n\\Remark{\nNote that the left and right-hand graph of a rule schema can be rule graphs or host graphs since a host graph is a special case of rule graphs. In GP\\,2, we only consider rule schemata (with restrictions). In this paper, we use unrestricted rule schemata to be able to express the properties of the inverse of a rule schema.}  \n\nIn GP\\,2, a condition can be added to a rule schema. This condition expresses properties that must be satisfied by a match of the rule schema. The variables occur in a rule schema condition must also occur in the left-hand graph of the rule schema.\n\n\\Def{Conditional rule schemata}{def:CRS}{\nA conditional rule schema is a pair $\\langle r,\\Gamma\\rangle$ with $r$ a rule schema and $\\Gamma$ a condition that can be derived from Condition in the grammar below:\n\\begin{center}\\small\n    \\begin{tabular}{lcl}\n        Condition & ::= & ($\\mtt{int \\mid char \\mid string \\mid atom}$) `('Var`)' \\\\\n        && $\\mid$ List (`$\\mtt{=}$' $\\mid$ `\\ttt{!=}') List\\\\\n        && $\\mid$ Integer (`\\ttt{>}' $\\mid$ `\\ttt{>=}' $\\mid$ `\\ttt{<}' $\\mid$ `\\ttt{<=}') Integer\\\\\n        && $\\mid$ $\\mtt{edge}$ `(' NodeId `,' NodeId [`,' List [Mark]] `)'\\\\\n        && $\\mid$ $\\mtt{not}$ Condition\\\\\n        && $\\mid$ Condition ($\\mtt{and}$ $\\mid$ $\\mtt{or}$) Condition\\\\\n        && $\\mid$ `(' Condition `)'\\\\\n        Var & ::= & ListVar $\\mid$ AtomVar $\\mid$ IntVar $\\mid$ StringVar $\\mid$ CharVar\\\\\n        Mark & ::= & $\\mtt{red \\mid green \\mid blue \\mid dashed \\mid any}$\n    \\end{tabular}\n\\end{center}\nsuch that all variables that occur in $\\Gamma$ also occur in the left-hand graph of $r$.\n}\n\nLeft-hand graph of a rule schema consists of a rule graph, while a morphism is a mapping function from a host graph. To obtain a host graph from a rule graph, we can assign constants for variables in the rule graph. For this, here we define assignment for labels.\n\nA conditional rule schema $\\tuple{L\\gets K\\to R,\\, \\Gamma}$ is applied to a host graph $G$ in stages: (1) evaluate the expressions in $L$ and $R$ with respect to a premorphism $g\\colon L \\to G$ and a label assignment $\\alpha$, obtaining an instantiated rule $\\tuple{L^{g,\\alpha}\\gets K\\to R^{g,\\alpha}}$; (2) check that $g\\colon L^{g,\\alpha} \\to G$ is label preserving and that the evaluation of $\\Gamma$ with respect to $g$ and $\\alpha$ returns true; (3) construct two natural pushouts based on the instantiated rule and $g$.\n\n\\Def{Label assignment}{def:assign}{\nConsider a rule graph $L$ and the set $X$ of all variables occurring in $L$. For each $x\\in X$, let dom$(x)$ denotes the domain of $x$ associated with the type of $x$. A \\emph{label assignment} for $L$ is a triple $\\alpha=\\tuple{\\alpha_\\mathbb{L},\\, \\mu_V,\\, \\mu_E}$ where $\\alpha_\\mathbb{L}\\colon X\\rightarrow\\mathbb{L}$ is a function such that for each $x\\in X$, $\\alpha_\\mathbb{L}(x)\\in$\\,dom$(x)$, and $\\mu_V\\colon V_L\\to \\mathbb{M}_V\\backslash\\{\\mtt{none}\\}$ and $\\mu_E\\colon E_L\\to \\mathbb{M}_E\\backslash\\{\\mtt{none}\\}$ are partial functions assigning a mark to each node and edge marked with \\ttt{any}.\n}\n\nFor a conditional rule schema $\\lkr$ with the set $X$ of all list variables in $L$, set $Y$ (or $Z$) of all nodes (or edges) in $L$ whose mark is $\\any$, and label assignment $\\alpha_L$, we denote by $L^\\alpha$ the graph $L$ after the replacement of every $x\\in X$ with $\\alpha_\\mathbb{L}(x)$, every $\\mrk^V_L(i)$ for $i\\in Y$ with $\\mu_{V}(i)$, and every $\\mrk^E_L(i)$ for $i\\in Z$ with $\\mu_{E}(i)$. Then for an injective graph morphism $g:L^\\alpha\\rightarrow G$ for some host graph $G$, we denote by $\\Gamma^{g,\\alpha}$ the condition that is obtained from $\\Gamma$ by substituting $\\alpha_\\mathbb{L}(x)$ for every variable $x$, $g(v)$ for every $v\\in V_L$, and $g(e)$ for every $e\\in E_L$.\n\nThe satisfaction of $\\Gamma^{g,\\alpha}$ in $G$ is required for the application of a conditional rule schema. In addition, the application also depends on the dangling condition, which is a condition that asserts the production of a graph after node removal. \n\n\\Def{Dangling condition; match}{def:dang}{\nLet $r=L\\leftarrow K\\rightarrow R$ be a rule schema with host graphs $L$ and $R$. Let also $G$ be a host graph, and $g:L\\rightarrow G$ be an injective morphism. The \\emph{dangling condition} is a condition where no edge in $G-g(L)$ is incident to any node in $g(L-K)$. When the dangling condition is satisfied by $g$, we say that $g$ is a \\emph{match} for $r$.}\n\nSince a rule schema has an unlabelled graph as its interface, a natural pushout, i.e. a pushout that is also a pullback, is required in a rule schema application. This approach is introduced in \\cite{HabelPlump02c} for unrooted graph programming. The approach is the modified for rooted programming in \\cite{Bak15a,Campbell19}.\n\n\\Def{Direct derivation; comatch}{def:dder}{\nA \\emph{direct derivation} from a host graph $G$ to a host graph $H$ via a rule $r = \\tuple{L\\leftarrow K\\rightarrow R}$ consists of a natural double-pushout as in \\figurename~\\ref{fig:dder}, where $g:L\\rightarrow G$ and $g^*:R\\rightarrow H$ are injective morphisms. If there exists such direct derivation, we write $G \\Rightarrow_{r,g} H$, and we say that $g^*$ is a \\emph{comatch} for $r$.  \n\\begin{figure}\n    \\centering\n    \\begin{tikzpicture}[scale=0.7, transform shape]\n\t\\node (2) at (0.75, 0) {(1)};\n\t\\node (a) at (1.5, 0.75) {$K$};\n\t\\node (b) at (0, 0.75) {$L$};\n\t\\node (c) at (3, 0.75) {$R$};\n\t\\node (d) at (1.5, -0.75) {$D$};\n\t\\node (1) at (2.25, 0) {(2)};\n\t\\node (e) at (3, -0.75) {$H$};\n\t\\node (f) at (0, -0.75) {$G$};\n\t\\draw[->] (a) to node {} (b);\n\t\\draw[->] (a) to node {} (c);\n\t\\draw[->] (a) to node {} (d);\n\t\\draw[->] (d) to node {} (e);\n\t\\draw[->] (d) to node {} (f);\n\t\\draw[->] (c) to node [right]{$g^*$} (e);\n\t\\draw[->] (b) to node [left]{$g$} (f);\n    \\end{tikzpicture}\n    \\caption{A direct derivation for a rule $r=\\tuple{L\\leftarrow K\\rightarrow R}$}\n    \\label{fig:dder}\n\\end{figure}\n}\n\nNote that we require natural double-pushout in direct derivation. We use a natural pushout to have a unique pushout complement up to isomorphism in relabelling graph transformation\\cite{HabelPlump02c,HristakievP16}. In \\cite{Bak15a}, a graph morphism preserves rooted nodes while here we require a morphism to preserve unrooted nodes as well. We require the preservation of unrooted nodes to prevent a non-natural pushout as can be seen in \\figurename~\\ref{fig:NPOPO} \\cite{Campbell19}. In addition, we need a natural double-pushout because we want to have invertible direct derivations.\n\n\\begin{figure}\n    \\centering\n    \\begin{tikzpicture}[scale=0.9, transform shape]\n\t\\node (1) at (0.5, 0) {\\tiny{(NPO)}};\n\t\\node (2) at (1.5, 0) {\\tiny{\\cancel{(NPO)}}};\n\t\\node (K) at (1, 0.5) {\n\t\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}\n\t};\n\t\\node (L) at (0, 0.5) {\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}};\n\t\\node (R) at (2, 0.5) {\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt, ultra thick] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}};\n\t\\node (D) at (1, -0.5) {\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt,ultra thick] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}};\n\t\\node (H) at (2, -0.5) {\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt,ultra thick] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}};\n\t\\node (G) at (0, -0.5) {\\begin{tikzpicture}[scale=0.4, transform shape]\n\t\t\\node[circle,draw,minimum size=18pt,ultra thick] (Aa) at (0,0) {};\t\n\t\t\\end{tikzpicture}};\n\t\\draw[->] (K) to node {} (L);\n\t\\draw[->] (K) to node {} (R);\n\t\\draw[->] (K) to node {} (D);\n\t\\draw[->] (D) to node {} (H);\n\t\\draw[->] (D) to node {} (G);\n\t\\draw[->] (R) to node {} (H);\n\t\\draw[->] (L) to node {} (G);\n    \\end{tikzpicture}\n    \\caption{Non-natural double-pushout}\n    \\label{fig:NPOPO}\n\\end{figure}\n\nThe natural double-pushout construction such that we have natural double-pushout is described in \\cite{Bak15a,Campbell19}, that are:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item To obtain $D$, remove all nodes and edges in $g(L\u2212K)$ from $G$. For all $v\\in V_K$ with $l_K(v)=\\perp$, define $l_D(g_V(v))=\\perp$. Also, define $p_D(g_V(v))=\\perp$ for all $v\\in V_K$ where $p_K(v)=\\perp$.\n    \\item Add all nodes and edges, with their labels and rootedness, from $R \u2212 K$ to D. For $e\\in E_R \u2212E_K$, $s_H(e) = s_R(e)$ if $s_R(E) \\in V_R \u2212V_K$, otherwise $s_H(e) = g_V (s_R(e))$. Targets are defined analogously.\n    \\item For all $v \\in V_K$ with $l_K (v) = \\perp$, define $l_H (g_V (v)) = l_R(v)$. Also, for the injective morphism $R\\rightarrow H$ and $v\\in V_K$ where $p_K(v)=\\perp,$ define $p_H(g^*_V(v)) = p_R(v)$. The resulting graph is $H$.\n\\end{enumerate}\n\n\\noindent Direct derivations transform a host graph via a rule whose the left and right-hand graph are totally labelled host graphs. However, a conditional rule schema contains a condition, and its left or right-hand graph may not be a host graph. Hence, we need some additional requirements for the application of a conditional rule schema on a host graph.\n\n\\begin{definition}[Conditional rule schema application]\\label{def:ruleapp}\\normalfont\nGiven a conditional rule schema $r=\\lkr$, and host graphs $G, H$. $G$ directly derives $r$, denoted by $G\\Rightarrow_{r,g} H$ (or $G \\Rightarrow_r H$), if there exists a premorphism $g: L \\rightarrow G$ and a label assignment $\\alpha_L$ such that:\n\\vspace{-\\topsep}\\begin{enumerate}\n    \\item[(i)] $g:L^\\alpha\\rightarrow G$ is an injective morphism, \n    \\item[(ii)] $\\Gamma^{g,\\alpha}$ is true,\n    \\item[(iii)] $G \\Rightarrow_{r^{g,\\alpha},g} H$.\\qed\n\\end{enumerate}\\end{definition}\n\nA rule schema $r$ (without condition) can be considered as a conditional rule schema $\\tuple{r,\\mtt{true}}$, which means in its application, the point (ii) in the definition above is a valid statement for every unconditional rule schema $r$.\n\nSyntactically, a conditional rule schema in GP\\,2 is written as follows:\n\\begin{center}\\small\n\\begin{tabular}{lll}\nRuleDecl & ::= & RuleId `(' [ VarList \\{`:' VarList\\} ] `;' `)'\\\\\n&& Graphs Interface [\\ttt{where} Condition]\\\\\nVarList & ::= & Variable \\{`,' Variable\\} `:' Type\\\\\nGraphs & ::= & `[' Graph `]' `$=>$' `[' Graph `]'\\\\\nInterface & ::= & \\ttt{interface} `=' `\\{' [NodeId \\{`,' NodeId\\}]`\\}'\\\\\nType & ::= & $\\mtt{int~\\mid~char~\\mid~string~\\mid~atom~\\mid~list}$\n\\end{tabular}\n\\end{center}\n\n\\noindent where Condition is the set of GP\\,2 rule conditions as defined in Definition \\ref{def:CRS} and Variable represents variables of all types. Graph represent rule graphs, where bidirectional edges may exist. Bidirectional edges and $\\any$-marks are allowed in the right-hand graph if there exist preserved counterpart item in the left-hand graph. \n\nA rule schema with bidirectional edges can be considered as a set of rules with all possible direction of the edges. For example, a rule schema with one bidirectional edge between node $u$ and $v$ can be considered as two rule schemata, where one rule schema has an edge from $u$ to $v$ while the other has an edge from $v$ to $u$.\n\n\\subsection{Syntax and operational semantics of graph programs}\nA GP\\,2 graph program consists of a list of three declaration types: rule declaration, main procedure declaration, and other procedure declaration. A main declaration is where the program starts from so that there is only one main declaration allowed in the program, and it consists of a sequence of commands. For more details on the abstract syntax of GP 2 programs, see \\figurename$~$\\ref{fig:GP2syntax}, where RuleId and ProcId are identifiers that start with lower case and upper case respectively.\n\n\\begin{figure}[!h]\n\\centering\\small\n\\begin{tabular}{lll}\nProg & ::= & Decl \\{Decl\\}\\\\\nDecl & ::= & MainDecl $\\mid$ ProcDecl $\\mid$ RuleDecl\\\\\nMainDecl & ::= & $\\mtt{Main}$ `=' ComSeq\\\\\nProcDecl & ::= & ProcId `=' Comseq\\\\\nComSeq & ::= & Com \\{`;' Com\\}\\\\\nCom & ::= & RuleSetCall $\\mid$ ProcCall\\\\\n&& $\\mid~\\mtt{if}$ ComSeq $\\mtt{ then }$ ComSeq [$\\mtt{else }$ ComSeq]\\\\\n&& $\\mid~\\mtt{try }$ ComSeq [$\\mtt{ then }$ ComSeq] [$\\mtt{else }$ ComSeq]\\\\\n&& $\\mid~$ComSeq `!'\\\\\n&& $\\mid~$ComSeq $\\mtt{ or }$ ComSeq\\\\\n&& $\\mid~$`(' ComSeq `)'\\\\\n&& $\\mid~\\mtt{break}~\\mid~\\mtt{skip}~\\mid~\\mtt{fail}$\\\\\nRuleSetCall & ::= & RuleId $\\mid$ `\\{' [RuleId \\{ `,' RuleId\\}] `\\}'\\\\\nProcCall & ::= & ProcId\n\\end{tabular}\n\\caption{Abstract syntax of GP 2 programs}\n\\label{fig:GP2syntax}\n\\end{figure}\n\nOther than executing a set of rule schemata, a program can also execute some commands sequentially by using `;'. There also exist \\texttt{if} and \\texttt{try} as branching commands, where the program will execute command after \\texttt{then} when the condition is satisfied or \\texttt{else} if the condition is not satisfied. However, as we can see in the syntax of GP 2 in \\figurename~\\ref{fig:GP2syntax}, we have command sequence as the condition of branching commands instead of a Boolean expression. Here, we say that the condition is satisfied when the execution of command in the condition terminates with a result graph (that is, it neither diverges nor fails) and it is not satisfied if the execution yields failure. \n\nThe difference between \\texttt{if} and \\texttt{try} lies in the host graph that is used after the evaluation of conditions. For \\texttt{if}, the program will use the host graph that is used before the examination of the condition. Otherwise for \\texttt{try}, if the condition is satisfied, then the program will execute the graph obtained from applying the condition or the previous graph if the condition is not satisfied. Other than branching commands, there is also a loop command `!' (read as ``as long as possible\"). It executes the loop-body as long as the command does not yield failure. Like a loop in other programming languages, a !-construct can result in non-termination of a program.\n\nConfigurations in GP 2 represents a program state of program execution in any stage. Configurations are given by (\\texttt{ComSeq}$\\times\\mathcal{G}(\\mathcal{L})$)$~\\cup~\\mathcal{G}(\\mathcal{L})~\\cup~$(\\texttt{fail})), where $\\mathcal{G}(\\mathbb{L})$ consists of all host graphs. This means that a configuration consists either of unfinished computations, represented by command sequence together with current graph; only a graph, which means all commands have been executed; or the special element \\texttt{fail} that represents a failure state. A small step transition relation $\\rightarrow$ on configuration is inductively defined by inference rules shown in \\figurename~\\ref{fig:infRule-core} and \\figurename~\\ref{fig:infRule-derived} where $\\mathcal{R}$ is a rule set call; $C,P,P'$, and $Q$ are command sequences; and $G$ and $H$ are host graphs.\n\n\\begin{figure}[!h]\n\\centering\n\\scalebox{0.85}{\n%\\makebox[.7\\textwidth]{\n\\begin{tabular}{lll}\n~[Call$_1$]$\\displaystyle\\frac{G\\Rightarrow_RH}{\\langle R,G\\rangle\\rightarrow H}$&$~~~~~~~$&[Call$_2$]$\\displaystyle\\frac{G\\nRightarrow_R}{\\langle R,G\\rangle\\rightarrow \\texttt{fail}}$\\\\~\\\\\n~[Seq$_1$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow\\langle P',H\\rangle}{\\langle P;Q,G\\rangle\\rightarrow\\langle P';Q,H\\rangle}$&&[Seq$_2$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow H}{\\langle P;Q,G\\rangle\\rightarrow\\langle Q,H\\rangle}$\\\\~\\\\\n~[Seq$_3$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow\\texttt{fail}}{\\langle P;Q,G\\rangle\\rightarrow\\texttt{fail}}$&&[Break]$\\displaystyle\\frac{}{\\langle \\texttt{break};P,G\\rangle\\rightarrow\\langle \\texttt{break},G\\rangle}$\\\\~\\\\\n~[If$_1$]$\\displaystyle\\frac{\\langle C,G\\rangle\\rightarrow ^+ H}{\\langle \\texttt{if }C\\texttt{ then }P\\texttt{ else }Q,G\\rangle\\rightarrow\\langle P,G\\rangle}$&&[If$_2$]$\\displaystyle\\frac{\\langle C,G\\rangle\\rightarrow ^+ \\texttt{fail}}{\\langle \\texttt{if }C\\texttt{ then }P\\texttt{ else }Q,G\\rangle\\rightarrow\\langle Q,G\\rangle}$\\\\~\\\\\n~[Try$_1$]$\\displaystyle\\frac{\\langle C,G\\rangle\\rightarrow ^+ H}{\\langle \\texttt{try }C\\texttt{ then }P\\texttt{ else }Q,G\\rangle\\rightarrow\\langle P,H\\rangle}$&&[Try$_2$]$\\displaystyle\\frac{\\langle C,G\\rangle\\rightarrow ^+ \\texttt{fail}}{\\langle \\texttt{try }C\\texttt{ then }P\\texttt{ else }Q,G\\rangle\\rightarrow\\langle Q,G\\rangle}$\\\\~\\\\\n~[Loop$_1$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow ^+H}{\\langle P!,G\\rangle\\rightarrow\\langle P!,H\\rangle}$&&[Loop$_2$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow ^+\\texttt{fail}}{\\langle P!,G\\rangle\\rightarrow H}$\\\\~\\\\\n~[Loop$_3$]$\\displaystyle\\frac{\\langle P,G\\rangle\\rightarrow ^*\\langle\\texttt{break}, H\\rangle}{\\langle P!,G\\rangle\\rightarrow H}$&&\n\\end{tabular}}\n\\caption{Inference rules for core commands \\cite{Plump12a}}\n\\label{fig:infRule-core}\n\\end{figure}\n\n\\begin{figure}[!h]\n\\centering\n\\scalebox{0.85}{\n\\def\\arraystretch{2}\\tabcolsep=1.5pt\n\\begin{tabular}{lll}\n~[Or$_1$] $\\langle P\\texttt{ or }Q,G\\rangle\\rightarrow\\langle P,G\\rangle$&~~~~~&[Or$_2$] $\\langle P\\texttt{ or }Q,G\\rangle\\rightarrow\\langle Q,G\\rangle$\\\\\n~[Skip$_1$] $\\langle \\texttt{skip},G\\rangle\\rightarrow G$&&[Fail] $\\langle \\texttt{fail},G\\rangle\\rightarrow\\texttt{fail}$\\\\\n\\multicolumn{3}{l}{~[If$_3$] $\\langle\\texttt{if }C\\texttt{ then }P,G\\rangle\\rightarrow\\langle\\texttt{if }C\\texttt{ then }P\\texttt{ else skip},G\\rangle$}\\\\\n\\multicolumn{3}{l}{~[Try$_3$] $\\langle\\texttt{try }C\\texttt{ then }P,G\\rangle\\rightarrow\\langle\\texttt{try }C\\texttt{ then }P\\texttt{ else skip},G\\rangle$}\\\\\n\\multicolumn{3}{l}{~[Try$_4$] $\\langle\\texttt{try }C\\texttt{ else }Q,G\\rangle\\rightarrow\\langle\\texttt{try }C\\texttt{ then skip else }Q,G\\rangle$}\\\\\n\\multicolumn{3}{l}{~[Try$_4$] $\\langle\\texttt{try }C,G\\rangle\\rightarrow\\langle\\texttt{try }C\\texttt{ then skip else skip},G\\rangle$}\n\n\\end{tabular}\n}\n\\caption{Inference rules for derived commands \\cite{Plump12a}}\n\\label{fig:infRule-derived}\n\\end{figure}\n\nThe semantics of programs is given by the semantic function $\\llbracket\\_\\rrbracket$ that maps an input graph $G$ to the set of all possible results of executing a program $P$ on $G$. The application of $\\llbracket P\\rrbracket$ to $G$ is written $\\llbracket P\\rrbracket G$. The result set may contain proper results in the form of graphs or the special values \\textit{fail} and $\\perp$. The value \\texttt{fail} indicates a failed program run while $\\perp$ indicates a run that does not terminate or gets stuck. Program $P$ can diverge from $G$ if there is an infinite sequence $\\langle P,G\\rangle\\rightarrow\\langle P_1, G_1\\rangle\\rightarrow \\langle P_2, G_2\\rangle\\rightarrow\\ldots$. Also, $P$ can get stuck from $G$ if there is a terminal configuration $\\langle Q,H\\rangle$ such that $\\langle P,G\\rangle\\rightarrow^*\\langle Q,H\\rangle$.\n\n\\Def{Semantic function \\cite{Plump12a}}{def:semanticfunc}{\nThe semantic function $\\llbracket\\_\\rrbracket$: ComSeq $\\rightarrow(\\mathcal{G}(\\mathbb{L})\\rightarrow2^{\\mathcal{G}(\\mathbb{L})\\cup\\{fail,\\bot\\}})$ is defined by\n\\[\\footnotesize{\\llbracket P\\rrbracket G=\\{X\\in (\\mathcal{G}(\\mathbb{L})\\cup\\{\\mrm{fail}\\})|\\langle P,G\\rangle\\rightarrow^+X\\}\\cup\\{\\bot\\mid P \\text{ can diverge or get stuck from } G\\}.}\\] \n}\n\nA program $C$ can get stuck only in two situations, that is either $P$ contains a command \\texttt{if $A$ then $P$ else $Q$} or \\texttt{try $A$ then $P$ else $Q$} such that $A$ can diverge from a host graph $G$, or \n$P$ contains a loop $B!$ whose body $B$ can diverge from a host graph $G$. The evaluation of such commands gets stuck because none of the inference rules for if-then-else, try-then-else or looping is applicable. Getting stuck always signals some form of divergence.\n\nWe sometimes need to prove that a property holds for all graph programs. For this, we use structural induction on graph programs by having a general version of graph programs. That is, ignoring the context condition of the command $\\mtt{break}$ such that it can appear outside a loop. However, when $\\mtt{break}$ occur outside the context condition, we treat it as a $\\mtt{skip}$.\n\n\\begin{definition}[Structural induction on graph programs]\\label{def:gpinduction}\\normalfont\nProving that a property \\textit{Prop} holds for all graph programs by induction, is done by:\\\\\n\\begin{tabular}{lrp{11.3cm}}\n    \\multicolumn{3}{l}{Base case.}\\\\\n    ~~~~~& \\multicolumn{2}{p{11.7cm}}{\n    Show that \\textit{Prop} holds for $\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$, where $n\\geq 0$}\\\\\n    \\multicolumn{3}{l}{Induction case.}\\\\\n    ~~~~~& \\multicolumn{2}{p{11.7cm}}{\n    Assuming \\textit{Prop} holds for graph programs $C, P,$ and $Q$, show that \\textit{Prop} also holds for:}\\\\\n    & 1. & $P;Q$,\\\\\n    & 2. & $\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    & 3. & $\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$, and\\\\\n    & 4. & $P!$.\\qed\n\\end{tabular}\n\\end{definition}\n\nThe commands $\\mtt{fail}$ and $\\mtt{skip}$ can be considered (respectively) as a call of the ruleset $\\mathcal{R}=\\{\\}$ and a call of the rule schema where the left and right-hand graphs are the empty graphs. Also, the command $P \\mtt{~or~} Q$ can be replaced with the program $\\mtt{if\\, (Delete!;\\,\\{nothing, add\\};\\, zero)\\, then\\,} P\\mtt{\\, else\\,} Q$ where $\\mtt{Delete}$ is a set of rule schemata that deletes nodes and edges, including loops. $\\mtt{nothing}$ is the rule schema where the left and right-hand graphs are the empty graphs, $\\mtt{add}$ is the rule schema where the left-hand graph is the empty graph and the right- hand graph is a single 0-labelled unmarked and unrooted node, and $\\mtt{zero}$ is a rule schema that matches with a 0-labelled unmarked and unrooted node.\n\nAs mentioned before, the execution of a graph program may yield a proper graph, failure, or diverge/get stuck. The latter only may happen when a loop exists in the program. In some cases, we may want to not considering the possibility of diverging or getting stuck such that we only consider loop-free graph programs. To show that a property holds for a loop-free program, we also introduce structural induction on loop-free programs.\n\n\\begin{definition}[Structural induction on loop-free programs]\\label{def:noloopinduction}\\normalfont\nProving that a property \\textit{Prop} holds for all loop-free programs by induction, is done by:\\\\\n\\begin{tabular}{lrp{11.3cm}}\n    \\multicolumn{3}{l}{Base case.}\\\\\n    ~~~~~& \\multicolumn{2}{p{11.7cm}}{\n    Show that \\textit{Prop} holds for $\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$, where $n\\geq 0$}\\\\\n    \\multicolumn{3}{l}{Induction case.}\\\\\n    ~~~~~& \\multicolumn{2}{p{11.7cm}}{\n    Assuming \\textit{Prop} holds for loop-free programs $C, P,$ and $Q$, show that \\textit{Prop} also holds for:}\\\\\n    & 1. & $P\\mtt{~or~}Q$,\\\\\n    & 2. & $P;Q$,\\\\\n    & 3. & $\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$, and\\\\\n    & 4. & $\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$.\\qed\n\\end{tabular}\n\\end{definition}\n \n\\section{First-Order Formulas for Graph Programs}\n\\label{sec:FOL}\n\nIn this section, we define first-order formulas which are able to express properties of GP\\,2 graphs. Also, we define structural induction on the first-order formulas and replacement graphs which later can be used to show satisfaction of a first-order formula in a morphism.\n\n\\subsection{Syntax}\n\nOur first-order (FO) formulas have logical connectives, variables, constants, also auxiliary, predicate, and function symbols.\n\n\\Def{Alphabet of a first-order formula}{def:FOLabc}{\nThe alphabet of a first-order formula consists of the following sets of symbols:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item Logical connectives: $\\wedge$ (and), $\\vee$ (or), $\\neg$ (not), $\\mrm{true}$, $\\mrm{false}$, equality symbols $=,\\neq,>,\\geq,<,\\leq,$ and quantifiers $\\E{V},\\E{E},\\E{L}$ for nodes, edges, and labels respectively.\n    \\item Variables: a countably infinite set of lowercase letters.\n    % \\item Auxiliary symbols: ``('',``)'',``['',``]'',``$\\mid$'',``\\{'', and ``\\}''.\n     \\item Predicate symbols: $\\mrm{int, char, string, atom, edge, root}$.\n     \\item Function symbols: $\\sou$ (source), $\\tar$ (target), $\\lV$ (node label), $\\lE$ (edge label), $\\mV$ (node mark), $\\mE$ (edge mark), $\\mrm{indeg}$, $\\mrm{outdeg}$, $\\mrm{length}$, integer operators $+,-,*,/$, label operator $:$, and string operator $.$ (concatenation).\n    \\item Constants: all elements in $\\mathbb{L}$, $\\mrm{empty}$, $\\mrm{none, red, green, blue,}$ $\\mrm{green, dashed, grey,}$\\\\and $\\mrm{ any}$.\n   \n\\end{enumerate}\n}\n\nHere we differentiate variables in seven kinds, which are first-order variables (single variables) for nodes, edges, and labels where labels are typed as in GP\\,2. Table \\ref{tab:domkind} shows the seven kinds of variables and their domains in a graph $G$. Note that we assume that node, edge, and list variables are pairwise distinct, while list, atom, integer, string, and character variables have hierarchy based on their domain.\n\n\\begin{table}[]\n    \\centering\n    \\caption{Kinds of variables and their domain on a graph $G$}\n    \\begin{tabular}{|c|c|} \n    \\hline\n        \\textbf{kind of variables} & \\textbf{domain} \\\\\\hline\n        NodeVar & $V_G$ \\\\\n        EdgeVar & $E_G$ \\\\\n        ListVar & $(\\mathbb{Z}\\cup(\\text{Char})^*)^*$ \\\\\n        AtomVar & $\\mathbb{Z}\\cup\\text{Char}^*$ \\\\\n        IntVar & $\\mathbb{Z}$ \\\\\n        StringVar & $\\text{Char}^*$ \\\\\n        CharVar & Char \\\\\n        \\hline\n    \\end{tabular}\n    \\label{tab:domkind}\n\\end{table}\n\nThe syntax of FO formulas is given by the grammar of Figure \\ref{fig:mso}. In the syntax, NodeVar and EdgeVar represent disjoint sets of first-order node and edge variables, respectively. We use ListVar, AtomVar, IntVar, StringVar, and CharVar for sets of first-order label variables of type $\\mrm{list, atom, int, string}$, and $\\mrm{char}$ respectively. The nonterminals Character and Digit in the syntax represent the fixed character set of GP\\,2, and the digit set $\\{0,\\ldots,9\\}$ respectively.\n\n\\begin{figure}\n    \\centering\\footnotesize\n    \\begin{tabular}{lcl}\n      Formula & ::= & $\\mrm{true}~\\mid~\\mrm{false}~\\mid$ Cond $\\mid$ Equal\\\\\n        && $\\mid$ Formula~(`$\\mrm{\\wedge}$' $\\mid$ `$\\mrm{\\vee}$')~Formula $\\mid$ `$\\neg$'Formula $\\mid$ `('Formula`)'\\\\\n        && $\\mid$ `$\\exists_\\mathtt{V}$' (NodeVar)~`('Formula`)' \\\\\n        && $\\mid `\\exists_\\mathtt{E}$'~(EdgeVar)~`('Formula`)'       \\\\\n        && $\\mid$ `$\\exists_\\mathtt{L}$' (ListVar)~`('Formula`)' \\\\\n      Number & ::= & Digit~\\{Digit\\}\\\\\n      Cond & ::= & ($\\mrm{int \\mid char \\mid string \\mid atom}$) `('Var`)' \\\\\n        && $\\mid$ Lst (`$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') Lst $\\mid$ Int (`$\\mrm{>}$' $\\mid$ `$\\mrm{>=}$' $\\mid$ `$\\mrm{<}$' $\\mid$ `$\\mrm{<=}$') Int\\\\\n        && $\\mid$ $\\mrm{edge}$ `(' Node `,' Node [`,' Lst] [`,' EMark] `)' $\\mid$ $\\mrm{root}$ `(' Node `)'\\\\\n      Var & ::= & ListVar $\\mid$ AtomVar $\\mid$ IntVar $\\mid$ StringVar $\\mid$ CharVar\\\\\n      Lst & ::= & $\\mrm{empty}$ $\\mid$ Atm $\\mid$ Lst \\lq:' Lst $\\mid$ ListVar $\\mid$ $\\mrm{l_V}$ `('Node`)' $\\mid$ $\\mrm{l_E}$ `('EdgeVar`)'  \\\\\n      Atm & ::= & Int $\\mid$ String $\\mid$ AtomVar \\\\\n      Int & ::= & [\\lq-']~Number~$\\mid$~\\lq('Int\\lq)'  $\\mid$ IntVar $\\mid$ Int (\\lq+' $\\mid$ \\lq-' $\\mid$ \\lq*' $\\mid$ \\lq/') Int \\\\\n        && $\\mid$ ($\\mrm{indeg}$ $\\mid$ $\\mrm{outdeg}$) \\lq('Node\\lq)' $\\mid$ $\\mrm{length}$ \\lq('AtomVar $\\mid$ StringVar $\\mid$ ListVar\\lq)' \\\\\n      String & ::= & ` `` ' {Character} ` \" ' $\\mid$ CharVar $\\mid$ StringVar $\\mid$ String `.' String \\\\\n      Node & ::= & NodeVar $\\mid$ ($\\mrm{s}~\\mid \\mrm{t}$) `(' EdgeVar`)'\\\\\n      EMark & ::= & $\\mrm{none~\\mid~red~\\mid~green~\\mid~blue~\\mid~dashed~\\mid~any}$\\\\\n      VMark & ::= & $\\mrm{none~\\mid~red~\\mid~blue~\\mid~green~\\mid~grey~\\mid~any}$  \\\\\n      Equal & ::= & Node ('$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') Node $\\mid$ EdgeVar ('$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') EdgeVar\\\\\n        && $\\mid$ Lst ('$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') Lst $\\mid$ $\\mrm{m_V}$`('Node`)' ('$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') VMark \\\\\n        && $\\mid$ $\\mrm{m_E}$`('EdgeVar`)' ('$\\mrm{=}$' $\\mid$ `$\\mrm{\\neq}$') EMark\n    \\end{tabular}\n    \\caption{Syntax of first-order formulas}\n    \\label{fig:mso}\n\\end{figure}\n\nThe quantifiers $\\E{V}, \\E{E},$ and $\\E{L}$ in the grammar are reserved for variables of nodes, edges, and labels respectively. The function symbols $\\mrm{indeg, outdeg}$ and $\\mrm{length}$ work similar with functions with the same names in GP\\,2 rule schema conditions. In addition, we also have unary functions $\\mrm{s, t, l_V, l_E, m_V,}$ and ${m_{E}}$. These functions return the mapping result of the argument based on their functions as defined in Definition \\ref{def:graphs}. For example, the function $\\mrm{s}$ takes an edge variable in the argument and returns the node that is the source of the edge represented by the variable in a host graph. The predicate $\\mrm{edge}$ expresses the existence of an edge between two nodes. The predicates $\\mrm{int, char, string, atom}$ are typing predicates to specify the type of the variable in their argument. We have the predicate $\\mrm{root}$ to express rootedness of a node. For brevity, we sometimes write $\\mrm{c\\implies d}$ for $\\mrm{\\neg c\\vee d}$, $\\mrm{c\\iff d}$ for $\\mrm{(\\neg c\\vee d)\\wedge(c\\vee\\neg d)}$, $\\mrm{\\forall_Vx(c)}$ for $\\mrm{\\neg\\E{V}x(\\neg c)}$ and $\\mrm{\\E{V}x_1,\\ldots,x_n(c)}$ for $\\mrm{\\E{V}x_1(\\E{V}x_2(...\\E{V}x_n(c)\\ldots))}$ (also for edge and label quantifiers). Also, we define 'term' as the set of variables, constants, and functions in first-order formulas.\n\n\\subsection{Structural induction on first-order formulas}\nTo prove properties related to our first-order formulas, we classify first-order formulas into eight cases, based on their forms. To prove that some properties hold for these cases, we define structural induction on first-order formulas. Three cases are defined as base cases since they are formed from terms while the others are defined as inductive cases. As mentioned before, terms can exist as a variable, a constant, or a function (or an operators). For terms, we also define a structural induction on terms with variables and constants are its base cases.\n\n\\begin{definition}[Structural induction on terms]\\label{def:inductionterms}\\normalfont\nGiven a property \\textit{Prop}. Proving that \\textit{Prop} holds for all terms by \\textit{structural induction on terms} is done by:\n\\begin{itemize}[nosep]\n    \\item Base case.\\\\\n    Show that \\textit{Prop} holds for all nodes, edges, and lists that may be represented by variables and constants.\n    \\item Inductive case.\\\\\n    Assuming that \\textit{Prop} holds for lists represented by terms $\\mrm{x_1, x_2}$, integers represented by terms $\\mrm{i_1, i_2}$, strings represented by terms $\\mrm{s_1, s_2}$, a node represented by term $\\mrm{v}$, and an edge represented by term $\\mrm{e}$, show that \\textit{Prop} also holds for:\n     \\vspace{-\\topsep}\\begin{enumerate}\n        \\item integers represented by $\\mrm{length(x_1),}$ and $\\mrm{i_1\\oplus i_2}$ for $\\oplus\\in\\{_,-,*,/\\}$\n        \\item lists represented by $\\mrm{\\lE(e_1)}$ and  $\\mrm{\\lV(v_1)}$\n        \\item marks represented by $\\mrm{\\mE(e_1)}$ and $\\mrm{\\mV(v_1)}$\n        \\item strings represented by $\\mrm{s_1.s_2}$\\qed\n    \\end{enumerate}\n\\end{itemize}\n\\end{definition}\n\n\nFor simplicity, we do not consider a FO formula in the form $(c)$ as it is equivalent to FO formula $c$. We also do not include the predicate $\\mrm{edge}$ because we can express it as $\\mrm{\\E{E}z(s(z)=x\\wedge t(z)=y)}$. The optional arguments list and mark of the predicate $\\mrm{edge}$ can be conjunct inside the quantifier, e.g. the predicate $\\mrm{edge(x,y,5,\\mrm{none})}$ can be expressed as\n$\\mrm{\\E{E}z(s(z)=x\\wedge t(z)=y\\wedge l_E(z)=5\\wedge m_E{z}}$\\\\$\\mrm{=none})$.\n\n\\begin{definition}[Structural induction on first-order formulas]\\label{def:inductionFO}\\normalfont\nGiven a property \\textit{Prop}. Proving that \\textit{Prop} holds for all FO formulas by \\textit{structural induction on FO formulas} is done by:\n\\begin{itemize}[nosep]\n    \\item Base case.\\\\\n    Show that \\textit{Prop} holds for:\n     \\vspace{-\\topsep}\\begin{enumerate}\n        \\item the formulas $\\mrm{true}$ and $\\mrm{false}$\n        \\item predicates $\\mrm{int(z), char(z), string(z), atom(z)}$ for a list variable $z$, and $\\mrm{root(y)}$ for a term $y$ representing a node\n        \\item Boolean operations $\\mrm{x_1=x_2}$ and $\\mrm{x_1\\neq x_2}$ where both $x_1, x_2$ are terms representing nodes, edges, or lists, also $\\mrm{y_1\\ominus y_2},$ for terms $y_1, y_2$ representing integers and $\\ominus\\in\\{=,\\neq,<,\\leq,>,\\geq\\}$\n    \\end{enumerate}\n    \\item Inductive case.\\\\\n    Assuming that \\textit{Prop} holds for FO formulas $c_1, c_2$, show that \\textit{Prop} also holds for FO formulas $c_1\\wedge c_2$, $c_1\\vee c_2$, $\\neg c_1$, $\\E{V}x(c_1)$, $\\E{E}x(c_1)$, and $\\E{L}x(c_1)$.\n\\end{itemize}\n\\end{definition}\n\n\\subsection{Satisfaction of a first-order formula}\nThe satisfaction of a FO formula $c$ in a host graph $G$ relies on assignments. A formula assignment of $c$ on $G$ is defined in Definition \\ref{def:assignment}. Informally, a formula assignment is a function that maps free variables to constants in their own domain. When we have an assignment for a FO formula on a graph, we can check the satisfaction of the FO formula. The satisfaction of a FO formula on a graph is then defined in Definition \\ref{def:satisfaction}.\n\n\\Def{Formula assignment}{def:assignment}{\nLet $c$ be a FO formula, $X$ and $Y$ be the set of free node and edge variables in $c$ respectively, and $Z$ be the set of free list variables in $c$. For a free variable $x$, dom$(x)$ denotes the domain of variable's kind associated with $x$ as in \\tablename~\\ref{tab:domkind}. A \\emph{formula assignment} of $c$ on a host graph $G$ is a tuple $\\alpha=\\tuple{\\alpha_G,\\alpha_\\mathbb{L}}$  of functions $\\alpha_G=\\tuple{\\alpha_V:X\\rightarrow V_G, \\alpha_E:Y\\rightarrow E_G}$ and  $\\alpha_\\mathbb{L}=Z\\rightarrow\\mathbb{L}$ such that for each free variable $x$, $\\alpha(x)\\in$ dom$(x)$. We then denote by $c^{\\alpha}$ the FO formula $c$ after replacement of each term $\\mrm{y}$ to $\\mrm{y}^{\\alpha}$, where $\\mrm{y}^{\\alpha}$ is defined inductively:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $\\mrm{y}$ is a free variable, $\\mrm{y}^{\\alpha}=\\alpha(\\mrm{x})$;\n    \\item If $\\mrm{y}$ is a constant, $\\mrm{y}^{\\alpha}=y$;\n    \\item If $y=\\mrm{length(x)}$ for some variable $\\mrm{x}$, $y^{\\alpha}$ returns the number of characters in $\\mrm{x}^{\\alpha}$ if $\\mrm{x}$ is a string variable, 1 if $\\mrm{x}$ is an integer variable, or the number of atoms in $\\mrm{x}^{\\alpha}$ if $\\mrm{x}$ is a list variable;\n    \\item If $y$ is $\\mrm{s}(x), \\mrm{t}(x), \\mrm{l_E}(x), \\mrm{m_E}(x), \\mrm{l_V}(x), \\mrm{m_V}(x), \\mrm{indeg}(x)$, or $\\mrm{outdeg}(x)$ for some term $x$, $y^{\\alpha}$ is $s_G(x^{\\alpha})$, $t_G(x^{\\alpha})$, $\\lst^E_G(x^{\\alpha}), \\mrk^E_G(x^{\\alpha}), \\lst^V_G(x^{\\alpha}), \\mrk^V_G(x^{\\alpha}),$ indegree of $x^{\\alpha}$ in $G$ , or outdegree of $x^{\\alpha}$ in $G$, respectively;\n    \\item If $y=x_1\\oplus x_2$ for $\\oplus\\in\\{+,-,*,/\\}$ and terms $x_1, x_2$ represented integers, $y^{\\alpha}=x_1^{\\alpha}\\oplus_\\mathbb{Z} x_2^{\\alpha}$;\n    \\item If $y=x_1.x_2$ for some terms $x_1, x_2$ represented strings, $y^{\\alpha}$ is string concatenation $x_1^{\\alpha}$ and $x_2^{\\alpha}$;\n    \\item If $y=x_1:x_2$ for some terms $x_1, x_2$ represented lists, $y^{\\alpha}$ is list concatenation $x_1^{\\alpha}$ and $x_2^{\\alpha}$;\n\\end{enumerate}\n}\n\n\\begin{remark}\n\n\\end{remark}\n\n\\Def{Satisfaction}{def:satisfaction}{\nGiven a graph $G$ and a first-order formula $c$. $G$ satisfies $c$, written $G\\Sat c$, if there exists an assignment $\\alpha$ such that $c^{\\alpha}$ is true in $G$ (denotes by $G\\models^\\alpha c$), that is, for each Boolean sub-expression $b^{\\alpha}$ of $c^{\\alpha}$, the value of $b^{\\alpha}$ in $\\mathbb{B}$ is inductively defined:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $b^{\\alpha}=\\mrm{true}$ (or $b=\\mrm{false}$), then $b^{\\alpha}$ is true (or false);\n    \\item If $b^{\\alpha}=\\mrm{int(x), char(x), string(x), atom(x)}$, or $\\mrm{root(x)}$, $b^{\\alpha}$ is true if only if $\\mrm{x}^{\\alpha}\\in\\mathbb{Z}, \\mrm{x}^{\\alpha}\\in\\text{Char}, \\mrm{x}^{\\alpha}\\in\\text{Char}^*, \\mrm{x}^{\\alpha}\\in\\mathbb{Z}\\cup\\text{Char}^*,$ or $p_G(\\mrm{x}^{\\alpha})=1$ respectively.\n    \\item If $b^{\\alpha}$ has the form $t_1\\otimes t_2$ where $\\otimes\\in\\{\\mrm{>,>=,<,<=}\\}$ and $t_1,t_2\\in\\mathbb{Z}$, $b^{\\alpha}$ is true if and only if $t_1\\otimes_\\mathbb{Z} t_2$ where $\\otimes_\\mathbb{Z}$ is the integer relation on $\\mathbb{Z}$ represented by $\\otimes$. Then if $b^{\\alpha}$ has the form $t_1\\ominus t_2$ where $\\ominus\\in\\{=,\\neq\\}$ and $t_1,t_2\\in V_G\\cup E_G\\cup\\mathbb{L}\\cup\\mathbb{M}\\{\\mrm{any}\\}$, $b^{\\alpha}$ is true if and only if $t_1\\ominus_\\mathbb{B} t_2$ where $\\ominus_\\mathbb{B}$ is the Boolean relation represented by $\\ominus$. Then for $t_1=\\mrm{any}$, $b^{\\alpha}$ is true if and only if $\\mtt{blue}\\ominus_\\mathbb{B} t_2~\\vee~\\mtt{red}\\ominus_\\mathbb{B} t_2~\\vee~\\mtt{green}\\ominus_\\mathbb{B} t_2~\\vee~\\mtt{grey}\\ominus_\\mathbb{B} t_2~\\vee~\\mtt{dashed}\\ominus_\\mathbb{B} t_2$ is true (and analogously for $t_2=\\mtt{any}$).\n    \\item If $b^{\\alpha}$ has the form $b_1\\oslash b_2$ where $\\oslash\\in\\{\\vee,\\wedge\\}$ and $b_1,b_2$ are Boolean expressions, $b^{\\alpha}$ is true if and only if $b_1\\oslash_\\mathbb{B} b_2$ where $\\oslash_\\mathbb{B}$ is the Boolean operation on $\\mathbb{B}$ represented by $\\oslash$. \n    \\item If the form of $b^{\\alpha}$ is $\\neg b_1$ where $b_1$ is a Boolean expression, $b^{\\alpha}$ is true if and only if $b_1$ is false.\n    \\item If $b^{\\alpha}$ has the form $\\E{V}e_1(e_2)$ where $e_1$ is a first-order node variable and $e_2$ is a Boolean expression, $b^\\alpha$ is true if and only if there exists $v\\in V_G$ such that when we add $e_1\\mapsto v$ to assignment $\\alpha$, $e_2$ is true.\n    \\item If $b^{\\alpha}$ has the form $\\E{E}e_1(e_2)$ where $e_1$ is a first-order edge variable and $e_2$ is a Boolean expression, $b^{\\alpha}$ is true if and only if there exists $e\\in E_G$ such that when we add $e_1\\mapsto e$ to assignment $\\alpha$, $e_2$ is true.\n    \\item If $b^{\\alpha}$ is in the form $\\E{L}e_1(e_2)$ where $e_1$ is a first-order list variable and $e_2$ is a Boolean expression, $b^{\\alpha}$ is true if and only if there exists $l\\in \\mathbb{L}$ such that when we add $e_1\\mapsto l$  to assignment ${\\alpha}$, $e_2$ is true.\n\\end{enumerate}\n}\n\n\\subsection{First-order formulas in rule schema application}\nFO formulas we define in this Section does not have a node or edge constant because we want to be able to check the satisfaction of a FO formula on any graph. However, in a rule schema application, we sometimes need to express the properties of the images of the match or comatch, which is dependent on the left-hand graph or right-hand graph. To be able to express properties of the images of a match or comatch, we need to allow some node and edge constants in FO formulas. Hence, we define a condition over a graph.\n\n\\Def{Conditions over a graph}{def:condover}{\nGiven a graph $G$. A \\emph{condition over $G$} is obtained from a first-order formula by substituting node (or edge) identifiers in $G$ for free node (or edge) variables in the first-order formula.}\n\n\\begin{example}\nLet $G$ and $H$ be graphs where $V_G=\\{1,2\\}$ and $V_H=\\{1\\}$.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $c_1=\\mrm{\\E{E}x(s(x)=1)}$ is a condition over $G$, also over $H$\n    \\item $c_2=\\mrm{\\A{V}x(\\mrm{edge}(x,1)\\wedge\\mrm{indeg}(x)=2)}$ is a condition over $G$, but not over $H$\n\\end{enumerate}\n\\end{example}\n\nChecking if a graph satisfies a condition over a graph is similar with checking satisfaction of a FO formula in a graph. However, for a condition $c$ over a graph, the satisfaction of $c$ in a graph $G$ can be defined if only if $c$ is a condition over $G$.\n\nWith a condition over a graph, we can express properties of left and right-hand graphs with explicitly mentioning node/edge identifiers in the graphs. In graph program verification, we need to express the properties of the initial and output graph with respect to a given rule schema. In \\cite{Poskitt13,HP09}, they express them by showing the satisfaction of a condition on a morphism. Here, we define a replacement graph $H$ of a host graph $G$ with respect to an injective morphism $g$, where $H$ is isomorphic to $G$ and there exists an inclusion from the domain of $g$ to $H$.\n\n\\Def{Replacement graph}{def:rho}{\nGiven an injective (pre)morphism $g:L\\rightarrow G$ where $V_G\\cap V_L=\\{v_1,\\ldots,v_n\\}$ and $E_G\\cap E_L=\\{e_1,\\ldots,e_m\\}$. Let also $U=\\{u_1,\\ldots,u_n\\}$ be a set of identifiers not in $V_L$ and $V_G$, and $W=\\{w_1,\\ldots,w_n\\}$ be a set of identifiers not in $E_L$ and $E_G$. \\emph{Graph replacement} $\\rho_g(G)$ is is obtained from $G$ by renaming every item $g(i)$ to $i$ for $i\\in V_G$ and $i\\in E_G$, every $v_i$ to $u_i$ for $i=1,\\ldots,n$, and every $e_i$ to $w_i$ for $i=1,\\ldots,m$, such that $V_{\\RG}=V_G-g(V_L)\\cup V_L\\cup U$ and $E_{\\RG}=E_G-g(E_L)\\cup E_L\\cup W$.}\n\nFrom the definition above, it is obvious that a host graph and its replacement graph are isomorphic. For a host graph $G$, a host graph $L$, and a morphism $g:L\\rightarrow G$, it is also obvious that there exists an inclusion $f:L\\rightarrow\\RG$, because $g$ preserves identifiers, sources, targets, and labels of $L$.\n\n\\begin{example}\nGiven $g$, a morphism from $L$ to $G$ as follows:\\\\\n\\begin{minipage}{0.5\\textwidth}\n\\begin{center}\n\\begin{tikzpicture}[scale=0.7, \ninner/.style={circle,draw,inner sep=2.5pt}]\n\t\\node[label=below:\\footnotesize{$L$}] (A) at (0,0) {\n\t\t\\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\t\\node[inner, label=below:$1$] (Aa) at (0,0) {$a$};\n\t\t\t\\node[inner, label=below:$2$] (Ab) at (1.5,0) {$a$};\n\t\t\t\\draw[-latex] (Aa) to [out=210,in=150, looseness=8] node[left] {3} (Aa);\n\t\t\t\\draw[-latex] (Ab) to node[above] {$4$} (Aa);\t\t\t\n\t\t\\end{tikzpicture}};\n\t\\node[] (B) at (2.25,0) {\n\t\t\\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\t\\node[] (Ba) at (0,0.25) {};\t\n\t\t\t\\node[] (Bb) at (1,0.25) {};\n\t\t\t\\draw[->] (Ba) to node[above] {$g$} (Bb);\n\t\t\\end{tikzpicture}};\n\t\\node[label=below:\\footnotesize{$G$}] (C) at (4.25,0) {\n\t\t\\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\t\\node[inner, label=above:$v_1$] (Ca) at (0,0.5) {$b$};\n\t\t\t\\node[inner, label=below:$v_2$] (Cb) at (1.5,0) {$a$};\n\t\t\t\\node[inner, label=below:$v_3$] (Cc) at (0,-0.5) {$b$};\n\t\t\t\\draw[-latex] (Ca) to [out=210,in=150, looseness=8] node[left] {$e_1$} (Ca);\n\t\t\t\\draw[-latex] (Cb) to node[above] {$e_2$} (Ca);\n\t\t\t\\draw[-latex] (Cb) to node[below] {$e_3$} (Cc);\n\t\t\t\\draw[-latex] (Cc) to [out=210,in=150, looseness=8] node[left] {$e_4$} (Cc);\n\t\t\\end{tikzpicture}};\n\\end{tikzpicture}\n\n\\end{center}\n\n\\end{minipage}\n\\begin{minipage}{0.5\\textwidth}\\footnotesize\n\\[g=\\left\\langle g_V:\\left\\{\\begin{array}{l}\n    \t\t1\\mapsto v_3 \\\\\n    \t\t2\\mapsto v_2\n        \\end{array}, \n     \t\tg_E:\\right\\{ \\begin{array}{l}\n    \t\t3\\mapsto e_4 \\\\\n    \t\t4\\mapsto e_3\n        \\end{array} \\right\\rangle\\]\n\\end{minipage}\n\n\\noindent Then, $\\rho_g(G)$ is the graph\\begin{center}\n\n    \\begin{tikzpicture}[scale=0.7, \ninner/.style={circle,draw,inner sep=2.5pt}]\n\t\\node[] (C) at (0,0) {\n\t\t\\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\t\\node[inner, label=above:$v_1$] (Ca) at (0,0.5) {$b$};\n\t\t\t\\node[inner, label=below:$2$] (Cb) at (1.5,0) {$a$};\n\t\t\t\\node[inner, label=below:$1$] (Cc) at (0,-0.5) {$a$};\n\t\t\t\\draw[-latex] (Ca) to [out=210,in=150, looseness=8] node[left] {$e_1$} (Ca);\n\t\t\t\\draw[-latex] (Cb) to node[above] {$e_2$} (Ca);\n\t\t\t\\draw[-latex] (Cb) to node[below] {$4$} (Cc);\n\t\t\t\\draw[-latex] (Cc) to [out=210,in=150, looseness=8] node[left] {$3$} (Cc);\n\t\t\\end{tikzpicture}};\n\\end{tikzpicture}    \n\\end{center}\n\\end{example}\n\nNow we have defined a condition over a graph to express properties of a host graph w.r.t the left-hand graph or right-hand graph. Let $\\tuple{L\\leftarrow K\\rightarrow R}$ be a rule schema, and $ac_L$, $ac_R$ denote a condition over a rule graph $L$ and $R$ respectively. To associate $ac_L$ and $ac_R$ with the rule schema, we define a \\textit{generalised rule schema}. Unlike a rule schema, a generalised rule schema consists of an unrestricted rule schema that allows both left and right application condition.\n\n\\Def{Generalised rule schema}{def:genrule}{\nGiven an unrestricted rule schema $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$.\n\\emph{A generalised rule} is a tuple $w=\\langle r,ac_L,ac_R\\rangle$ where $ac_L$ is a condition over $L$ and $ac_R$ is a condition over $R$. We call $ac_L$ the left application condition and $ac_R$ the right application condition. The inverse of $w$, written $w^{-1}$, is then defined as the tuple $\\langle r^{-1},ac_R,ac_L\\rangle$ where $r^{-1}=\\langle R\\leftarrow K\\rightarrow L\\rangle$.\n}\n\nThe application of a generalised rule schema is essentially the same as the application of a rule schema. But here, we also check the satisfaction of both $ac_L$ and $ac_R$ in the replacement of input graph $G$ and final graph $H$ by match and comatch respectively.\n\n\\Def{Application of generalised rule schema}{def:generalisedrPO}{\nGiven a generalised rule schema $w=\\langle r, ac_L, ac_R\\rangle$ with an unrestricted rule schema $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$. There exists a direct derivation from $G$ to $H$ by $w$, written $G\\Rightarrow_{w,g,g^*} H$ (or $G\\Rightarrow_wH$) iff there exists premorphisms $g:L\\rightarrow G$ and $g^*:R\\rightarrow H$ and label assignments $\\alpha$ for $L$ and $\\beta$ for $R$ where $\\beta(i)=\\alpha(i)$ for every variable $i$ in $L$ such that $i$ is in $R$ and for every node/edge $i$ where $\\mrk_L(i)=\\mrk_R(i)=\\mtt{any}$, such that:\n \\vspace{-\\topsep}\\begin{enumerate}\n\\item[(i)] $g:L^\\alpha\\rightarrow G$ is an injective morphism\n\\item[(ii)] $g^*:R^\\beta\\rightarrow H$ is an injective morphism\n\\item[(iii)] $\\rho_g(G)\\Sat ac_L^\\alpha$,\n\\item[(iv)] $\\rho_{g^*}(H)\\Sat ac_R^\\beta$,\n\\item[(v)] $G \\Rightarrow_{r^{\\alpha,g},g} H$,\n\\end{enumerate}\nwhere $G \\Rightarrow_{r^{\\alpha},g} H$ denotes the existence of natural pushouts (1) and (2) as in the diagram of \\figurename~\\ref{fig:ddergenrule}.}\n\n\\begin{figure}\n    \\centering\n    \\begin{tikzpicture}[scale=0.9, transform shape]\n\t\\node (2) at (1, 0) {(1)};\n\t\\node (a) at (2, 0.75) {$K$};\n\t\\node (b) at (0, 0.75) {$L^\\alpha$};\n\t\\node (c) at (4, 0.75) {$R^\\beta$};\n\t\\node (d) at (2, -0.75) {$D$};\n\t\\node (1) at (3, 0) {(2)};\n\t\\node (e) at (4, -0.75) {$H$};\n\t\\node (f) at (0, -0.75) {$G$};\n\t\\node (g) at (-0.85, -0.75) {$\\RG\\cong$};\n\t\\node (i) at (-2.1, -0.75) {$ac_L^\\alpha\\Dashv$};\n\t\\node (h) at (4.95, -0.75) {$\\cong\\RH$};\n\t\\node (j) at (6.25, -0.75) {$\\Sat ac_R^\\beta$};\n\t\\draw[->] (b) to node[left] {$g$} (f);\n\t\\draw[->] (b) [bend right=40] to node[left] {incl} (g);\n\t\\draw[->] (c) to node[right] {$g^*$} (e);\n\t\\draw[->] (c) [bend left=40]to node[right] {incl} (h);\n    \\draw[->] (a) to node {} (b);\n\t\\draw[->] (a) to node {} (c);\n\t\\draw[->] (a) to node {} (d);\n\t\\draw[->] (d) to node {} (e);\n\t\\draw[->] (d) to node {} (f);\n\t\\draw[->] (c) to node {} (e);\n\t\\draw[->] (b) to node {} (f);\n\\end{tikzpicture}\n    \\caption{Direct derivation for generalised rule schema}\n    \\label{fig:ddergenrule}\n\\end{figure}\n\nRecall the application of conditional rule schema in Definition \\ref{def:ruleapp}. The condition of the rule schema is clearly can be considered as the left-application condition of the rule schema. Since there is no right-application condition in a conditional rule schema, there is no requirement about the condition such that we can always consider $\\mrm{true}$ as the right-application condition of a conditional rule schema.\n\n\\Def{Generalised version of a conditional rule schema}{def:rvee}{\nGiven a conditional rule schema $\\tuple{r,\\Gamma}$. The generalised version of $r$, denoted by $r^\\vee$, is the generalised rule schema $r^\\vee=\\tuple{r,\\Gamma^\\vee,\\mrm{true}}$ where $\\Gamma^\\vee$ is obtained from $\\Gamma$ by replacing the notations $\\mrm{not}, !=, \\mrm{and, or}, \\#$ with $\\neg, \\neq, \\wedge, \\vee, `,$' (comma symbol) respectively.\n}\n\n\\Lemma{lemma:rvee}{\nGiven a conditional rule schema $\\tuple{r,\\Gamma}$ with $r=\\tuple{L\\leftarrow K\\rightarrow R}$. Then for any host graphs $G,H$,\n\\[G\\Rightarrow_r\\,H \\text{ if and only if } G\\Rightarrow_{r^\\vee}\\!H.\\]\n}\n\n\\begin{proof}\n(Only if). Recall the restrictions about variables and any-mark of a rule schema. It is obvious that every variable in $R$ is in $L$ and every node/edge with mark $\\any$ in $R$ is marked $\\any$ in $L$ as well. From Definition \\ref{def:ruleapp}, we know that $G\\Rightarrow_rH$ asserts the existence of $\\alpha_L$ and premorphism $g:L\\rightarrow G$ such that: 1) $g:L^\\alpha\\rightarrow G$ is an injective morphism, 2) $\\Gamma^{\\alpha,g}$ is true in $G$, and 3) $G\\Rightarrow_{r^{\\alpha,g},g}H$. From 3) and the variable restrictions mentioned above, it is obvious that there exists morphism $g^*:R^\\alpha\\rightarrow H$, and $\\RH\\Sat ac_R$ because all graphs satisfy $\\mrm{true}$. Hence, (ii), (iv), and (v) of Definition \\ref{def:generalisedrPO} are satisfied. Point 1) then asserts (i) of Definition \\ref{def:generalisedrPO}. The fact that $\\Gamma^{\\alpha,g}$ is true in $G$ from point 2) is then asserts $\\RG\\Sat \\Gamma^\\vee$ because it is obvious that the change of symbols does not change the semantics of the condition. Moreover, $\\RG$ is a replacement graph w.r.t. $g$ such that evaluating $\\Gamma^{\\alpha,g}$ in $G$ is the same as evaluating $\\Gamma^\\alpha$ in $\\RG$.\\\\\n(If). Similarly, from Definition \\ref{def:generalisedrPO}, we know that $G\\Rightarrow_{r^\\vee}H$ asserts the existence of label assignment $\\alpha$ for $L$ and premorphism $g:L\\rightarrow G$ such that: 1) $g:L^\\alpha\\rightarrow G$ is an injective morphism; 2)$\\RG\\Sat\\Gamma^\\vee$; and 3)$G\\Rightarrow_{r^{\\alpha,g},g}H$. These obviously assert $G\\Rightarrow_rH$ from Definition \\ref{def:ruleapp} and the argument about $\\Gamma^\\vee$ above.\n\\end{proof}\n\n\\Remark{For morphism $g:L^\\alpha\\rightarrow G$, the semantics of $\\Gamma$ in $G$ with respect to $g$ and $\\Gamma^\\vee$ in $\\RG$ is identical. From here, $\\Gamma$ also refers to $\\Gamma^\\vee$ when it obviously refers to a condition over $L$.}\n\n\\Lemma{lemma:inverse}{\nGiven a generalised rule schema $w=\\langle r, ac_L, ac_R\\rangle$ with an unrestricted rule schema $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$ and label assignment $\\alpha$ for $L$. Then for host graphs $G$ and $H$ with premorphisms $g:L\\rightarrow G$ and $g^*:R\\rightarrow H$,\n\\[G\\Rightarrow_{w,g,g^*}\\!H \\text{ if and only if } H\\Rightarrow_{w^{-1},g^*,g}\\!G.\\]\n}\n\n\\begin{proof}$~$\\\\\n(Only if.) From Definition \\ref{def:generalisedrPO} we know that when $G\\Rightarrow_{w,g,g^*}\\!H$, it means that there exists label assignment $\\alpha$ for $L$ and $\\beta$ for $R$ where $\\alpha(i)=\\alpha(i)$ for every variable $i$ in $L$ such that $i$ is in $R$, and for every node/edge $i$ where $\\mrk_L(i)=\\mrk_R(i)=\\mtt{any}$, such that $g:L^\\alpha\\rightarrow G$ and $g^*:R^\\beta\\rightarrow H$ are injective morphisms where\n \\vspace{-\\topsep}\\begin{enumerate}\n\\item[(i)] $\\rho_g(G)\\Sat ac_L^\\alpha$\n\\item[(ii)] $\\rho_{g^*}(H)\\Sat ac_R^\\beta$\n\\item[(iii)] $G \\Rightarrow_{r^{\\alpha},g} H$.\n\\end{enumerate}\nThese are obviously defines direct derivation $H \\Rightarrow_{(r^-1)^{g^*,\\alpha},g^*}\\!G$ such that $H\\Rightarrow_{w^{-1},g^*,g}\\!G$.\\\\\n(If). We can apply the above proof analogously.\\qed\n\\end{proof}\n\nThe application of a rule depends on the existence of morphisms. Showing the existence of a morphism $L\\rightarrow G$ for host graphs $L, G$ can be done by checking the existence of the structure of $L$ in $G$. For this, we define a condition over a graph to specify the structure and labels of a graph.\n\n\\Def{Specifying a totally labelled graph}{def:spec}{\nGiven a totally labelled graph $L$ with $V_L=\\{v_1,\\ldots,v_n\\}$ and $E_L=\\{e_1,\\ldots,e_m\\}$. Let $X=\\{x_1,\\ldots,x_k\\}$ be the set of all list variables in $L$, and Type$(x)$ for $x\\in X$ is $\\mrm{int(x)}$, $\\mrm{char(x)}$, $\\mrm{string(x)}$, $\\mrm{atom(x)}$, or $\\mrm{true}$ if $x$ is an integer, char, string, atom, or list variable respectively. Let also Root$_L(v)$ for $v\\in V_L$ be a function such that Root$_L(v)=\\mrm{root(v)}$ if $p_L(v)=1$, and Root$_L(v)=\\mrm{\\neg root(v)}$ otherwise. \\emph{A specification of $L$}, denoted by Spec$(L)$, is the condition over $L$:\n\\[\\mrm{\\bigwedge_{i=1}^k} \\text{Type}(x_i) \\mrm{~\\wedge~\\bigwedge_{i=1}^n \\lV(v_i)}=\\lst_L(v_i)\\mrm{~\\wedge~\\mV(v_i)=}\\mrk_L(v_i)\\mrm{~\\wedge~} \\text{Root}_L(v_i)\\]\n\\[\\mrm{\\wedge~\\bigwedge_{i=1}^m s(e_i)=}s_L(e_i)\\mrm{~\\wedge~ t(e_i)=}t_L(e_i)\\mrm{~\\wedge~\\lE(e_i)}=\\lst_L(e_i)\\mrm{~\\wedge~\n\\mE(e_i)=}\\mrk_L(e_i)\\]\n}\n\nSince morphisms require the preservation of sources, targets, labels, and rootedness, we need to explicitly state rootedness and label of each node, source and target of each edge. Also, since we also want to specify rule graphs, the type of each variable needs to explicitly stated as well. Note that we only specify totally labelled graphs so that the label and rootedness of a node are always defined.\n\n\\Ex{Specification of $L$}{ex:spec}{\nLet us consider the graph $L$ below:\n\\begin{center}\n    \\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=18pt},\n  outer/.style={inner sep=2pt}, scale=0.9\n  ]\n  \\node[outer] (A) at (0,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a+b}$};\t\n\t\t\\node[inner, label=below:\\tiny 2, fill=red!50] (Ab) at (1.5,0) {$\\mtt{a}$};\t\n        \\node[inner, label=below:\\tiny 3, ultra thick] (Ac) at (-1.5,0) {$\\mtt{b}$};\t\n\t\t\\draw[-latex, dashed] (Aa) to node[above] {$\\mtt{d}$} (Ab);\n\t\t\\draw[-latex] (Aa) to node[above] {$\\mtt{7}$} (Ac);\n\t\t\\end{tikzpicture}};\\end{tikzpicture}\n\\end{center}\nwhere the edge incident to 1 and 2 is edge $e1$ and the other one is edge $e2$, and $a,b,$ are integer variables while $d$ is a list variable. Then, Spec$(L)$ is the condition over $L$:\n\\begin{small}\n\\[\\mrm{int(a)\\wedge\\,int(b)\\wedge\\, \\lV(1)=a+b\\wedge\\, \\lV(2)=a\\wedge\\, \\lV(3)=b}\\]\n\\[\\mrm{\\wedge\\, \\mV(1)=none\\wedge\\, \\mV(2)=red\\wedge\\, \\mV(3)=none\\wedge\\, \\neg root(1)\\wedge\\, \\neg root(2)\\wedge\\, root(3)}\\]\n\\[\\mrm{\\wedge\\, s(e1)=1\\wedge\\, t(e1)=2\\wedge\\, s(e2)=1\\wedge\\, t(e2)=3\\wedge\\, \\lE(e1)=d\\wedge\\, \\lE(e2)=7}\\]\n\\[\\mrm{\\wedge\\, \\mE(e1)=dashed\\wedge\\, \\mE(e2)=none}\\]\n\\end{small}}\n\nWhen a graph $G$ satisfying Spec$(L)$, it means $G$ has a subgraph $H$ with identical node and edge identifiers and with the same structure (sources, targets, and rootedness) as $L$. The labels of $H$ and $L$ should also be the same if both are host graphs, but not necessarily if at least one of them is a rule graph. However, if $G$ is a host graph satisfying Spec$(L)$, then there must exist label assignment $\\alpha$ for $L$ such that Spec$(L^\\alpha)$ is satisfied by $G$, yields to the existence of inclusion $L^\\alpha\\rightarrow G$.\n\n\\Prop{Spec$(L)$ and inclusion}{prop:specL}{\nGiven a rule graph $L$ and a host graph $G$ where $V_L\\subseteq V_G$ and $E_L\\subseteq E_G$. Then,\n$G \\Sat \\text{Spec}(L)$ if and only if there exists a label assignment $\\alpha$ for $L$ such that there exists inclusion $g:L^\\alpha\\rightarrow G$.\n}\n\n\\begin{proof}\nLet us consider the construction of Spec$(L)$. It is clear that there is no node or edge variables in the condition. Hence, $G$ satisfies Spec$(L)$ if and only if there exists an assignment $\\beta$ for all list variables in Spec($L$) and partial functions $\\mu_V:V_L\\rightarrow \\mathbb{M}_V\\backslash\\{\\none\\}$ and $\\mu_E:E_L\\rightarrow \\mathbb{M}_E\\backslash\\{\\none\\}$ for every item $i$ whose mark is $\\mtt{any}$  such that substituting $\\beta(x)$ for every variable $x$ and $\\mu_V(i)$ or $\\mu_E(i)$ for every $\\mtt{any}$-mark associated with $i$ in Spec$(L)$ resulting a valid statement in $G$. \nLet we denote by $V_L=\\{v_1,\\ldots,v_n\\}$, $E_L=\\{e_1,\\ldots,e_m\\}$, and $X=\\{x_1,\\ldots,x_p\\}$ the set of all nodes, edges, label variables in $L$. From the semantics of satisfaction, it is clear that  \n\\[ \\bigwedge_{i=1}^n \\lst^V_G(v_i)=(\\lst^V_L(v_i))^\\beta~\\wedge~\\mrk^V_G(v_i)=(\\mrk^V_L(v_i))^{\\mu_V}~\\wedge~ \\text{Root}_G(v_i)\\]\n\\[\\wedge~\\bigwedge_{i=1}^m s_G(e_i)=s_L(e_i)~\\wedge~ t_G(e_i)=t_L(e_i)~\\wedge~\\lst^E_G(e_i)=(\\lst^E_L(e_i))^\\beta~\\wedge~\n\\mrk^E_G(e_i)=(\\mrk^E_L(e_i))^{\\mu_E}\\]\nDefine $g(i)=i$ for every item $i\\in V_L\\cup E_L$ (such that identifiers are preserved by $g$), and $\\alpha=\\langle \\beta, \\mu_V, \\mu_E\\rangle$. It is clear that $g$ preserves sources, targets, lists, marks, and rootedness.\\qed\n\\end{proof}\n\nNote that Spec$(L)$ is a condition over $L$, so the a graph satisfying the condition must have node and edge identifiers of $L$ in the graph. It is obviously not practical, but we can make it more general by replacing the identifiers with fresh variables such that a graph satisfying the condition does not necessarily contain identifiers of $L$.\n\n\\Def{Variablisation of a condition over a graph}{def:var}{\nGiven a graph $L$ and a condition $c$ over $L$ where $\\{v_1,\\ldots,v_n\\}$ and $\\{e_1,\\ldots,e_m\\}$ represent the set of node and edge constants in $c$ respectively. Let $x_1,\\ldots,x_n$ be node variables not in $c$ and $y_1,\\ldots,y_m$ be edge variables not in $c$. \\emph{Variablisation of $c$}, denoted by Var$(c)$, is the FO formula\n\\[\\mrm{\\bigwedge_{i=1}^n\\bigwedge_{j\\neq i}x_i\\neq x_j~\\wedge~ \\bigwedge_{i=1}^m\\bigwedge_{j\\neq i}y_i\\neq y_j\n~\\wedge~c^{[v_1\\mapsto x_1]\\ldots[v_n\\mapsto x_n][e_1\\mapsto y_1]\\ldots[e_m\\mapsto y_m]}}\\]\nwhere $c^{[a\\mapsto b]}$ is obtained from $c$ by replacing every occurrence of $a$ with $b$, and $c^{[a\\mapsto b][d\\mapsto e]}=(c^{[a\\mapsto b]})^{[d\\mapsto e]}$.\n}\n\n\\Lemma{lemma:var}{\nGiven a graph $L$ and a condition $c$ over $L$. For every host graph $G$ and morphism $g:L\\rightarrow G$,\n\\[G\\Sat\\text{Var}(c)\\text{ if and only if }\\RG\\Sat c\\text.\\]\n}\n\n\\begin{proof}\nLet $V=\\{v_1,\\ldots,v_n\\}$ and $E=\\{e_1,\\ldots,e_m\\}$ represent the set of node and edge constants in $c$ respectively, and $X=x_1,\\ldots,x_n$ be node variables not in $c$ and $Y=y_1,\\ldots,y_m$ be edge variables not in $c$ such that Var$(c)$ is the FO formula shown in the definition above.\\\\\nLet $\\alpha$ be an assignment such that $\\alpha(x_i)=v_i$ and $\\alpha(y_i)=e_i$ for all $x_i\\in X$ and $y_i\\in Y$. It is obvious that (Var$(c)$)$^{\\alpha}\\equiv c$, since we only replace each node/edge variable with the constant that was replaced by the variable to obtain Var$(c)$. Therefore, $\\RG\\Sat c$ iff $\\RG\\Sat$Var$(c)^{\\alpha}$ iff $G\\Sat$Var$(c)^{\\alpha}$, which means that $G$ satisfies Var$(c)$.\\qed\n\\end{proof}$~~$\\\\\n\nIf we apply this variablisation to Spec$(L)$ for a rule graph $L$, morphism as in Proposition \\ref{prop:specL} should also exist but without necessarily preserves identifiers.\n\n\\Lemma{lemma:VarL}{\nGiven rule graph $L$ and host graph $G$. Then,\n$G \\Sat \\text{Var(Spec}(L))$ if and only if there exists a label assignment $\\alpha$ for $L$ such that there exists injective morphism $g:L^\\alpha\\rightarrow G$.\n}\n\n\\begin{proof}\n$G$ satisfying Form(Spec$(L)$) if and only if there exists formula assignment $\\gamma=\\tuple{\\gamma_V, \\gamma_L. \\gamma_\\mathbb{L}}$ and mappings $\\mu_V:V_L\\rightarrow \\mathbb{M}_V\\backslash\\{none\\}$ and $\\mu_E:E_L\\rightarrow \\mathbb{M}_E\\backslash\\{none\\}$ for every item $i$ whose mark is $\\mtt{any}$, such that (Form(Spec$(L))^{\\gamma})^{\\mu_V,\\mu_E}$ is true in $G$. \n\nIf we consider Form(Spec$(L))^{\\gamma_G}$, it clearly gives us a condition similar to Spec$(L)$, but with different identifiers. Let $X$ denotes the set of images of $\\gamma_G$, and $\\beta:(V_L\\cup G_L)\\rightarrow X$ be a bijective mapping such that Spec$(L)^\\beta =$Form(Spec$(L))^{\\gamma_G}$.\n\nLet we denote by $V_L=\\{v_1,\\ldots,v_n\\}$, $E_L=\\{e_1,\\ldots,e_m\\}$, and $X=\\{x_1,\\ldots,x_p\\}$ the set of all nodes, edges, label variables in $L$. From the semantics of satisfaction, it is clear that  \n\\begin{scriptsize}\n\\[ \\bigwedge_{i=1}^n \\lst^V_G(\\beta(v_i))=(\\lst^V_L(v_i))^{\\gamma_\\mathbb{L}}~\\wedge~\\mrk^V_G(\\beta(v_i))=(\\mrk^V_L(v_i))^{\\mu_V}~\\wedge~ \\text{Root}_G(\\beta(v_i))\\]\n\\[\\wedge~\\bigwedge_{i=1}^m s_G(\\beta(e_i))=s_L(e_i)~\\wedge~ t_G(\\beta(e_i))=t_L(e_i)~\\wedge~\\lst^E_G(\\beta(e_i))=(\\lst^E_L(e_i))^{\\gamma_\\mathbb{L}}~\\wedge~\n\\mrk^E_G(\\beta(e_i))=(\\mrk^E_L(e_i))^{\\mu_E}\\]\n\\end{scriptsize}\nDefine $g(i)=\\beta(i)$ for every item $i\\in V_L\\cup E_L$, and $\\alpha=\\langle \\gamma_\\mathbb, \\mu_V,\\mu_E\\rangle$. It is clear that $g:L^\\alpha\\rightarrow G$ preserves sources, targets, lists, marks, and rootedness.\\qed\n\\end{proof}\n\n\\subsection{Properties of first-order formulas}\n\n\\Lemma{lemma:isocond}{\nGiven a FO formula $c$ and two isomorphic host graphs $G$ and $H$ with isomorphism $f:G\\rightarrow H$. Let $\\alpha=\\tuple{\\alpha_G,\\alpha_\\mathbb{L}}$ and $\\beta=\\tuple{\\beta_H,\\beta_\\mathbb{L}}$ be formula assignments where $\\beta_H(x)=f(\\alpha_G(x))$ for every node and edge variable $x$ in $c$ and $\\beta_\\mathbb{L}(x)=\\alpha_\\mathbb{L}(x)$ for every list variable $x$ in $c$. Then,\n\\[G\\Sata c \\text{ if and only if } H\\vDash^\\beta c\\]\n}\n\n\\begin{proof} Here, we prove the Lemma inductively.\\\\\n(Base case).\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c=\\mrm{true}$ or $c=\\mrm{false}$, it is obvious that $G\\Sata c$ iff $H\\vDash^\\beta c$\n    \\item If $c$ is a predicate P$(x)$ for $P\\in\\{\\mrm{int,char,string,atom}\\}$ and some list variable $x$, the satisfaction of the predicate is independent on host graphs. Also, it is obvious that $x^\\alpha=x^\\beta$ such that P$(x^\\alpha)$ is true in every host graphs iff P$(x^\\beta)$ is true in every host graph\n    \\item If $c=\\mrm{root(x)}$ for some term $x$ representing a node, $x^\\beta=g(x^\\alpha)$. From Definition \\ref{def:morphisms}, we know that $p_G(x^\\alpha)=p_H(g(x^\\alpha))$. Hence, $\\mrm{root(x^\\alpha}$ is true in $G$ iff $\\mrm{root(x^\\beta)}$ is true in $H$\n    \\item If $c=x_1\\otimes x_2$ for $\\otimes\\in\\{=,\\neq\\}$ and terms $x_1,x_2$ representing edges or nodes, $x_1^\\beta=g(x_1^\\alpha)$ and $x_2^\\beta=g(x_2^\\alpha)$. It is clear that $x_1^\\alpha\\otimes x_2^\\alpha$ iff $g(x_1^\\alpha)\\otimes g(x_2^\\alpha)$ because $g$ is injective.\n    \\item If $c=x_1\\otimes x_2$ for $\\otimes\\in\\{=,\\neq,\\leq,\\geq\\}$ and terms $x_1,x_2$ representing lists, $x_1^\\alpha=x_1^\\beta$ and $x_2^\\alpha=x_2^\\beta$ (note that $l_V(x^\\alpha)=l_V(g(x^\\alpha))=l_V(x^\\beta)$ for all node variable $x$ in $c$, and analogously for $l_E(x)$). Since the truth value of $x_1^\\alpha\\otimes x_2^\\alpha$ does not depend on host graphs, $x_1^\\alpha\\otimes x_2^\\alpha$ is true in $G$ iff $x_1^\\beta\\otimes x_2^\\beta$ is true in $H$\n\\end{enumerate}\n(Inductive case).\nNext, we prove the Lemma for the inductive cases. Let $c_1, c_2$ be FO formulas such that $G\\Sata c_1$ iff $H\\vDash^\\beta c_1$ and $G\\Sata c_2$ iff $H\\vDash^\\beta c_2$. Also, let $c^{x\\mapsto v}$ for some variable $x$ and constant $v$ represents $c$ after replacement of every free variable $x$ in $c$ with $v$.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c=\\neg c_1,$ $G\\Sata \\neg c_1$ iff $c_1^\\alpha$ is false in $G$ iff $c_1^\\beta$ is false in $H$ iff $H\\vDash^\\beta\\neg c_1$\n    \\item If $c=c_1\\vee c_2,$ $G\\Sata c_1\\vee c_2$ iff $G\\Sata c_1 \\vee G\\Sata c_2$ iff $H\\vDash^\\beta c_1 \\vee H\\vDash^\\beta c_2$ iff $H\\vDash^\\beta c_1\\vee c_2$\n    \\item If $c=c_1\\wedge c_2,$ $G\\Sata c_1\\wedge c_2$ iff $G\\Sata c_1 \\wedge G\\Sata c_2$ iff $H\\vDash^\\beta c_1 \\wedge H\\vDash^\\beta c_2$ iff $H\\vDash^\\beta c_1\\wedge c_2$\n    \\item $G\\Sata\\E{V}x(c_1)$ iff $(c_1^\\alpha)^{[x\\mapsto v]}$ for some $v\\in V_G$ is true in $G$ iff $(c_1^\\beta)^{[x\\mapsto g(v)]}$ is true in $H$ iff $H\\vDash^\\beta\\E{V}x(c_1)$\n    \\item $G\\Sata\\E{E}x(c_1)$ iff $(c_1^\\alpha)^{[x\\mapsto e]}$ for some $e\\in E_G$ is true in $G$ iff $(c_1^\\beta)^{[x\\mapsto g(e)]}$ is true in $H$ iff $H\\vDash^\\beta\\E{E}x(c_1)$\n    \\item $G\\Sata\\E{L}x(c_1)$ iff $(c_1^\\alpha)^{[x\\mapsto i]}$ for some $i\\in \\mathbb{L}$ is true in $G$ iff $(c_1^\\beta)^{[x\\mapsto i]}$ is true in $H$ iff $H\\vDash^\\beta\\E{L}x(c_1)$\n\n\\end{enumerate}\\qed\n\\end{proof}\n\n\\begin{corollary}\\label{cor:isocond}\nGiven two isomorphic host graphs $G$ and $H$, and a FO formula $c$. It is true that\n\\[G\\models c \\text{ if and only if } H\\models c\\]\n\\end{corollary}\n\n\\begin{proof}\n$G\\Sat c$ iff there exists an assignment $\\alpha=\\tuple{\\alpha_G,\\alpha_\\mathbb{L}}$ such that $G\\Sata c$. By Lemma \\ref{lemma:isocond}, $G\\Sata c$ iff $H\\vDash^\\beta c$ for $\\beta=\\tuple{\\beta_H,\\alpha_\\mathbb{L}}$ where $\\beta_H(x)=g(\\alpha_G(x))$ for all node and edge variables $x$ iff $H\\Sat c$.\\qed\n\\end{proof}\n\n$~$\\\\\n\n\\Lemma{lemma:BolOperators}{\nGiven a host graph $G$ and FO formulas $c_1, c_2$. Then, the following holds:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $G\\Sat c_1\\vee c_2$ if and only if $G\\Sat c_1 \\vee G\\Sat c_2$\n    \\item $G\\Sat c_1\\wedge c_2$ if and only if $G\\Sat^\\alpha c_1 \\wedge G\\Sat^\\alpha c_2$ for some assignment $\\alpha$\n    \\item $G\\Sat\\neg c_1$ if and only if $\\neg(G\\Sat^\\alpha c_1)$ for some assignment $\\alpha$\n    \\item $V_G\\neq\\emptyset \\wedge G\\Sat\\E{V}x(c_1)$ if and only if $G\\Sat c_1$\n    \\item $E_G\\neq\\emptyset \\wedge G\\Sat\\E{E}x(c_1)$ if and only if $G\\Sat c_1$\n    \\item $G\\Sat\\E{L}x(c_1)$ if and only if $G\\Sat c_1$\n\\end{enumerate}\nFurthermore, the above properties also hold if $c_1, c_2$ are conditions over $G$.\n}\n\n\\begin{proof}$~$\\\\\nFor a condition $d$ over $G$, from the definition of condition over a graph we know that $d=c^{\\alpha_G}$ for some FO formula $c$ and node/edge assignment $\\alpha_G$. Also, there is no free node and edge variables in $d$ so that $G\\Sat^{\\alpha_\\mathbb{L}}d$ for some list assignment $\\alpha_\\mathbb{L}$ is equivalent to $G\\Sata c$ for $\\alpha=\\tuple{\\alpha_G,\\alpha_\\mathbb{L}}$. Hence, we can consider a condition over a graph as a FO formula with a fixed node/label assignment. Then for some FO formulas $c_1,c_2,$\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item (only if) $G\\Sat c_1\\vee c_2$ implies $G\\Sat^\\alpha c_1\\vee c_2$ for some assignment $\\alpha$ implies $G\\Sat^\\alpha c_1$ or $G\\Sat^\\alpha c_2$ implies $G\\Sat c_1\\vee G\\Sat c_2$\\\\\n    (if) $G\\Sat c_1 \\vee G\\Sat c_2$ implies $G\\Sat^\\alpha c_1 \\vee G\\Sat^\\beta c_2$ for some assignments $\\alpha,\\beta$. It implies $(G\\Sat^\\alpha c_1\\vee c_2) \\vee (G\\Sat^\\beta c_1\\vee c_2)$. Hence, $G\\Sat c_1\\vee c_2$\n    \\item $G\\Sat c_1\\wedge c_2$ iff $G\\Sat^\\alpha c_1\\wedge c_2$ for some assignment $\\alpha$ iff $G\\Sat^\\alpha c_1$ and $G\\Sat^\\alpha c_2$\n    \\item $G\\Sat\\neg c_1$ iff $c_1^\\alpha$ is false in $G$ for some assignment $\\alpha$ such that $G\\Sat^\\alpha c_1$ is false. Hence, $\\neg(G\\Sata c_1)$\n    \\item $G\\Sat \\E{V}x(c_1)$ iff $G\\Sat c_1^{[x\\mapsto v]}$ for some $v\\in V_G$ iff $G\\Sata c_1$ for some assignment $\\alpha$ such that $\\alpha(x)=v$ iff $G\\Sat c_1$\n    \\item $G\\Sat \\E{E}x(c_1)$ iff $G\\Sat c_1^{[x\\mapsto e]}$ for some $e\\in E_G$ iff $G\\Sata c_1$ for some assignment $\\alpha$ such that $\\alpha(x)=e$ iff $G\\Sat c_1$\n    \\item $G\\Sat \\E{L}x(c_1)$ iff $G\\Sat c_1^{[x\\mapsto k]}$ for some $k\\in \\mathbb{L}$ iff $G\\Sata c_1$ for some assignment $\\alpha$ such that $\\alpha(x)=k$ iff $G\\Sat c_1$\n\\end{enumerate}\\qed\n\\end{proof}\n\n\\Lemma{lemma:quantifier}{\nGiven a host graph $G$ and a condition $c$ over $G$. Let $\\{v_1,\\ldots,v_n\\}\\subseteq V_G$ and $\\{e_1,\\ldots,e_m\\}\\subseteq E_G$. Then,\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $\\mrm{\\E{V}x(c)\\equiv c^{[x\\mapsto v_1]}\\vee\\ldots\\vee c^{[x\\mapsto v_n]}\\vee\\E{V}x(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge c)}$\n    \\item $\\mrm{\\E{E}x(c)\\equiv c^{[x\\mapsto e_1]}\\vee\\ldots\\vee c^{[x\\mapsto e_m]}\\vee\\E{V}x(x\\neq e_1\\wedge\\ldots\\wedge x\\neq v_m\\wedge c)}$\n    \\item $\\mrm{\\E{E}x(c)\\equiv \\E{E}x(\\bigvee_{i=1}^n(\\bigvee_{j=1}^n s(x)=v_i\\wedge t(x)=v_j\\wedge c^{[s(x)\\mapsto v_i, t(x)\\mapsto v_j]})}$\\\\\n    $\\mrm{~~~~~~~~~~~~~~~~~~~~~~~~~~\\vee(s(x)=v_i\\wedge\\bigwedge_{j=1}^n t(x)\\neq v_j\\wedge c^{[s(x)\\mapsto v_i]})}$\\\\\n    $\\mrm{~~~~~~~~~~~~~~~~~~~~~~~~~~\\vee(\\bigwedge_{j=1}^n s(x)\\neq v_j\\wedge t(x)=v_i\\wedge c^{[t(x)\\mapsto v_i]})}$\\\\\n    $\\mrm{~~~~~~~~~~~~~~~~~~~~\\vee(\\bigwedge_{i=1}^n s(x)\\neq v_i\\wedge\\bigwedge_{i=1}^n t(x)\\neq v_i\\wedge c))}$\n\\end{enumerate}\n}\n\n\\begin{proof}$~$\\\\\n\\begin{tabular}{clcl}\n     1. & $\\mrm{\\E{V}x(c)}$ & $\\equiv$ & $\\mrm{\\E{V}x(((x=v_1\\vee\\ldots\\vee x=v_n)\\vee\\neg(x=v_1\\vee\\ldots\\vee x=v_n))\\wedge c)}$\\\\\n     & & $\\equiv$ & $\\mrm{\\E{V}x((x=v_1\\wedge c)\\vee\\ldots\\vee(x=v_n\\wedge c)\\vee(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge c))}$\\\\\n     & & $\\equiv$ & $\\mrm{\\E{V}x(c^{[x\\mapsto v_1]}\\vee\\ldots\\vee c^{[x\\mapsto v_n]}\\vee(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge c))}$\\\\\n     & & $\\equiv$ & $\\mrm{c^{[x\\mapsto v_1]}\\vee\\ldots\\vee c^{[x\\mapsto v_n]}\\vee\\E{V}x(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge c)}$\\\\\n     2. & \\multicolumn{3}{l}{Analogous to point 1}\\\\\n     3. & $\\mrm{\\E{E}x(c)}$ & $\\equiv$ & $\\mrm{\\E{E}x(((s(x)=v_1\\vee\\ldots\\vee s(x)=v_n)\\vee\\neg(s(x)=v_1\\vee\\ldots\\vee s(x)=v_n))}$\\\\\n     & & & $\\mrm{~~~~~~\\wedge (t(x)=v_1\\vee\\ldots\\vee t(x)=v_n\\vee\\neg(t(x)=v_1\\vee\\ldots\\vee t(x)=v_n)) \\wedge c)}$\\\\\n     & & $\\equiv$ & $\\mrm{\\E{E}x((s(x)=v_1\\wedge (t(x)=v_1\\vee\\ldots\\vee t(x)=v_n)\\wedge c)}$\\\\\n     & & & $~~~~~~~~~~~~~~~~\\ldots$\\\\\n     & & & $~~~~~~~\\mrm{(s(x)=v_n\\wedge (t(x)=v_1\\vee\\ldots\\vee t(x)=v_n)\\wedge c)}$\\\\\n     & & & $~~~~~~~\\mrm{(s(x)\\neq v_1\\wedge\\ldots\\wedge s(x)\\neq v_n\\wedge (t(x)=v_1\\vee\\ldots\\vee t(x)=v_n)\\wedge c)}$\\\\\n     & & & $~~~~~~~\\mrm{(s(x)=v_i\\wedge (t(x)\\neq v_1\\wedge\\ldots\\wedge t(x)\\neq v_n)\\wedge c)}$\\\\\n    & & & $~~~~~~~\\mrm{(s(x)\\neq v_1\\wedge\\ldots\\wedge s(x)\\neq v_n \\wedge (t(x)\\neq v_1\\wedge\\ldots\\wedge t(x)\\neq v_n)\\wedge c)}$\\\\\n    & & $\\equiv$ & $\\mrm{\\E{E}x(\\bigvee_{i=1}^n(\\bigvee_{j=1}^n s(x)=v_i\\wedge t(x)=v_j\\wedge c^{[s(x)\\mapsto v_i, t(x)\\mapsto v_j]})}$\\\\\n    & & & $\\mrm{~~~~~~~~~~~~~~\\vee(\\bigwedge_{j=1}^n s(x)\\neq v_j\\wedge t(x)=v_i\\wedge c^{[t(x)\\mapsto v_i]})}$\\\\\n    & & & $\\mrm{~~~~~~~~~~~~~~\\vee(s(x)=v_i\\wedge\\bigwedge_{j=1}^n t(x)\\neq v_j\\wedge c^{[s(x)\\mapsto v_i]})}$\\\\\n    & & & $\\mrm{~~~~~~\\vee(\\bigwedge_{i=1}^n s(x)\\neq v_i\\wedge\\bigwedge_{i=1}^n t(x)\\neq v_i\\wedge c))}$\n\\end{tabular}\\qed\\end{proof}\n\n \n\\section{Constructing a Strongest Liberal Postcondition}\n\\label{sec:SLP}\nIn this section, we introduce a way to construct a strongest liberal postcondition over a graph program. Here, conditions (including pre- and postconditions) refer to closed FO formulas.\n\n\\subsection{Calculating strongest liberal postconditions}\nA strongest liberal postcondition is one of predicate transformers \\cite{DijkstraS90} for forward reasoning. It expresses properties that must be satisfied by every graph result from the application of the input rule schema to a graph satisfying the input precondition. \n\n\\Def{Strongest liberal postcondition over a conditional rule schema}{def:slp}{\nAn assertion $d$ is a \\emph{liberal postcondition} w.r.t. a conditional rule schema $r$ and a precondition $c$, if for all host graphs $G$ and $H$,\n\\[G\\vDash c \\text{ and } G\\Rightarrow_r H \\text{ implies }H\\vDash d.\\]\nA \\emph{strongest liberal postcondition} w.r.t. $c$ and $r$, denoted by $\\text{SLP}(c,r)$, is a liberal postcondition w.r.t. $c$ and $r$ that implies every liberal postcondition w.r.t. $c$ and $r$.\n}\n$~$\\\\$~$\\\\\nOur definition of a strongest liberal postcondition is different with the definitions in \\cite{HP09,DijkstraS90,Cousot90} where they define $\\text{SLP}(c,r)$ as a condition such that for every host graph $H$ satisfying the condition, there exists a host graph $G$ satisfying $c$ where $G\\Rightarrow_rH$. Lemma \\ref{lemma:slp} shows that their definition and ours are equivalent.\n\n\\begin{lemma}\\normalfont\\label{lemma:slp}\nGiven a rule schema $r$, a precondition $c$. Let $d$ be a liberal postcondition w.r.t. $r$ and $c$. Then $d$ is a strongest liberal postcondition w.r.t. $r$ and $c$ if and only if for every graph $H$ satisfying $d$, there exists a host graph $G$ satisfying $c$ such that $G\\Rightarrow_{r}H$.\n\\end{lemma}\n\n\\begin{proof}$~$\\\\\n(If).\\\\\nLet $H$ be a host graph satisfying $d$. Then, there must exists a graph $G$ such that $G\\vDash c$ and $G\\Rightarrow_r H$. Hence, $H\\vDash a$ for any liberal postcondition $a$ from the definition of a liberal postcondition.\\\\\n(Only if).\\\\\nAssume that it is not true that for every host graph $H$, $H\\vDash d$ implies there exists a host graph $G$ satisfying $c$ such that $G\\Rightarrow_{r}H$. We show that a graph satisfying $d$ can not imply the graph satisfying any liberal postcondition w.r.t $r$ and $c$. From the assumption, there exists a host graph $H$ such that every host graph $G$ does not satisfy $c$ or does not derive $H$ by $r$. In the case of $G$ does not derive $H$ by $r$, we clearly can not guarantee characteristic of $H$ w.r.t. $c$. Then for the case where $G$ does not satisfy $c$ but derives $H$ by $r$, we also can not guarantee the satisfaction of any liberal postcondition $a$ over $c$ and $r$ in $H$ because $a$ is dependent of $c$. Hence, we can not guarantee that $H$ satisfying all liberal postcondition w.r.t. $r$ and $c$.\\qed\n\\end{proof}\n\nTo construct $\\text{SLP}(c,r)$, we use the generalised version of $r$ to open a possibility of constructing a strongest liberal postcondition over the inverse of a rule schema. Since a rule schema has some restriction on the existence of variables and $\\any$-mark, a rule schema may not be invertible. By using the generalised version of a rule schema, we omit this limitation so that the generalised version of the inverse of a rule schema is also a generalised rule schema so that we can use the construction for an inverse rule as well.\n\nIn this paper, $\\text{SLP}(c,r)$ is obtained by defining transformations Lift$(c,r^\\vee)$, Shift$(c,r^\\vee)$, and Post$(c,r^\\vee)$. The transformation Lift transforms the given condition $c$ into a left-application condition w.r.t. the given unrestricted rule schema $r$. Then, we transform the left-application condition to right-application condition by transformation Shift. Finally, the transformation Post transforms the right-application condition to a strongest liberal postcondition (see \\figurename~\\ref{fig:pretopost}).\n\n\\begin{figure}\n    \\centering\n    \\begin{tikzpicture}[scale=0.9, transform shape]\n\t\\node (a) at (4, 0.75) {$ac_R$};\n\t\\node (b) at (0, 0.75) {$ac_L$};\n%\t\\node (c) at (0, -0.25) {$r^\\alpha,c$};\n\t\\node (d) at (4, -1) {$\\text{SLP}(c,r)$};\n\t\\node (f) at (0, -1) {$c,r$};\n\t\\draw[->] (f) to node {} (d);\n\t\\draw[->] (f) to node[left] {Lift} (b);\n\t\\draw[->] (b) to node[above] {Shift} (a);\n\t\\draw[->] (a) to node[right] {Post} (d);\n%\t\\draw[dots] (f) to node[right] {} (c);\n\\end{tikzpicture}\n    \\caption{Constructing $\\text{SLP}(c,r)$}\n    \\label{fig:pretopost}\n\\end{figure}\n\nFor a conditional rule schema $\\tuple{r,\\Gamma}$ with rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$ and a precondition $c$, when a graph $G$ satisfying $c$ and there exists a label assignment $\\alpha_L$ such that $G\\Rightarrow_{r^\\alpha,g}H$ for some host graph $H$ and injective graph morphism $g:L^\\alpha\\hookrightarrow G$, $ac_L^\\alpha=(\\text{Lift}(c,r^\\vee))^\\alpha$ should be satisfied by $G$ w.r.t. $g$. The replacement graph $\\RG$ should satisfies $ac_L$ which means $ac_L$ should consist of the precondition $c$, rule schema condition $\\Gamma$, and the dangling condition.\n\n$G\\Rightarrow_{r^\\alpha,g}H$ with injective graph morphism $g:L^\\alpha\\hookrightarrow G$ and label assignment $\\alpha_L$ obviously assert the existence of injective morphism $g^*:R^\\beta\\rightarrow H$ for some label assignment $\\beta_R$ such that $\\alpha_L(i)=\\beta_R(i)$ for common element $i$ (see \\figurename~\\ref{fig:ddergenrule}). The graph replacement $\\RH$ then should satisfy $ac_R^\\beta=(\\text{Shift}(c,r^\\vee))^\\beta$. The graph condition $ac_R$ should describe the elements of the image of the comatch and some properties of $c$ that are still relevant after the rule schema application.\n\nBasically, $ac_R$ is already a strongest property that must be satisfied by a resulting graph. However, it has node/edge constants so that we need to change it into a closed formula so that we finally obtain a strongest liberal postcondition. This part is done by the transformation Post.\n\nTo give a better idea of the transformations we define in this chapter, we show examples after each definition. We use the conditional rule schemata $r_1=\\mtt{del}$ of \\figurename~\\ref{fig:ruledel} and $\\mtt{copy}$ of \\figurename~\\ref{fig:rulecopy} and the preconditions $q_1=\\mrm{\\neg\\E{E}x(m_V(s(x))\\neq none)}$ and  $q_2=\\mrm{\\E{V}x(\\neg root(x))}$ as running examples. We denote by $\\Gamma_1$ and $\\Gamma_2$ the GP\\,2 rule schema conditions $\\mrm{d\\geq e}$ and $\\mrm{outdeg(1)\\neq 0}$ respectively. Also, we denote by $r_1$ and $r_2$ the rule schema of $\\mtt{del}$ and $\\mtt{copy}$ respectively.\n\n\\begin{figure}\n\\subfloat{%\n\\begin{minipage}[c]{0.62\\textwidth}%\n\\centering  \n  \\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=18pt},\n  outer/.style={inner sep=2pt}, scale=0.9\n  ]\n  \\node[outer] (AA) at (0,1) {$\\mtt{del(a,b,c:list;~ d,e:int)}$};\n  \\node[outer] (A) at (0,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\node[inner, label=below:\\tiny 2] (Ab) at (1.5,0) {$\\mtt{b}$};\t\n        \\node[inner, label=below:\\tiny 3] (Ac) at (-1.5,0) {$\\mtt{c}$};\t\n\t\t\\draw[-latex] (Aa) to node[above] {$\\mtt{d}$} (Ab);\n\t\t\\draw[-latex] (Aa) to node[above] {$\\mtt{e}$} (Ac);\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,-1) {$\\mtt{where~d\\geq e}$};\n  \\node[outer] (B) at (2.25,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (3.75,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!50] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\node[inner, label=below:\\tiny 2] (Ab) at (1.75,0) {$\\mtt{b}$};\t\n        \\draw[-latex] (Aa) to node[above] {$\\mtt{d+e}$} (Ab);\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\\end{minipage}}\n\\subfloat{%\n\\fbox{\\begin{minipage}[c]{0.35\\textwidth}%\n            \\begin{tabular}{l}\n\\small{$\\mtt{del~(a,b,c:list; d,e:int;)}$}\\\\\n\\small{$\\mtt{[~\\mid~(1, a)~(2, b)~(3, c)}$}\\\\\n\\small{$\\mtt{~~~\\mid~(e1, 1, 2, d)~(e2, 1, 3, e)]}$}\\\\\n\\small{$\\mtt{=>}$}\\\\\n\\small{$\\mtt{[~\\mid~(1\\#red, a)~(2, b)}$}\\\\\n\\small{$\\mtt{~~~\\mid~(e1, 1, 2, d+e)]}$}\\\\\n\\small{$\\mtt{interface = \\{1, 2\\}}$}\\\\\n\\small{$\\mtt{where~d\\geq e}$}\n             \\end{tabular}\n\\end{minipage}}}\n\\caption{GP\\,2 conditional rule schema $\\mtt{del}$}\n\\label{fig:ruledel}\n\\end{figure}\n\n\n\\begin{figure}\n\\subfloat{%\n\\begin{minipage}[c]{0.62\\textwidth}%\n\\centering  \n  \\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=18pt},\n  outer/.style={inner sep=2pt}, scale=0.9\n  ]\n  \\node[outer] (AA) at (0,1) {$\\mtt{copy(a:list)}$};\n  \\node[outer] (A) at (0,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, ultra thick] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,-1) {$\\mtt{where~outdeg(1)~!\\!=~0}$};\n  \\node[outer] (B) at (1.5,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (3,0) {\n  \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\node[inner, ultra thick] (Ab) at (1.5,0) {$\\mtt{a}$};\t\n\t\t\\draw[-latex, dashed] (Aa) to node[above] {} (Ab);\n\t\t\\end{tikzpicture}};\n\\end{tikzpicture}\n\\end{minipage}}\n\\subfloat{%\n\\fbox{\\begin{minipage}[c]{0.35\\textwidth}%\n            \\begin{tabular}{l}\n\\small{$\\mtt{copy~(a:list;)}$}\\\\\n\\small{$\\mtt{[~\\mid~(1(R), a)~\\mid~]}$}\\\\\n\\small{$\\mtt{=>}$}\\\\\n\\small{$\\mtt{[~\\mid~(1, a)~(2(R), a)}$}\\\\\n\\small{$\\mtt{~~~\\mid~(e1, 1, 2, empty\\#dashed)]}$}\\\\\n\\small{$\\mtt{interface = \\{1\\}}$}\\\\\n\\small{$\\mtt{where~outdeg(1)~!\\!=~0}$}\n             \\end{tabular}\n\\end{minipage}}}\n\\caption{GP\\,2 conditional rule schema $\\mtt{copy}$}\n\\label{fig:rulecopy}\n\\end{figure}\n\n\n\n\n\\subsection{The dangling condition}\nThe dangling condition must be satisfied by an injective morphism $g$ if $G\\Rightarrow_{r,g}H$ for some rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$ and host graphs $G,H$. Since we want to express properties of $\\RG$ where such derivation exists, we need to express the dangling condition as a condition over the left-hand graph.\n\nRecall the dangling condition from Definition \\ref{def:dang}. $\\RG$ satisfies the dangling condition if every node $v\\in L-K$ does not incident to any edge outside $L$. This means that the indegree and outdegree of every node $v\\in L-K$ in $L$ represent the indegree and outdegree of $v$ in $G$ as well.\n\n\\Def{Condition Dang}{def:dang}{\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$ where $\\{v_1,\\ldots,v_n\\}$ is the set of all nodes in $L-K$. Let $indeg_L(v)$ and $outdeg_L(v)$ denotes the indegree and outdegree of $v$ in $L$, respectively. The condition Dang$(r)$ is defined as:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item if $V_L-V_K=\\emptyset$ then Dang$(r)=\\mrm{true}$\n    \\item if $V_L-V_K\\neq\\emptyset$ then \n    \\[\\text{Dang}(r)=\\mrm{\\bigwedge_{i=1}^n indeg(v_i)=}indeg_L(v_i)\\,\\wedge\\,\\mrm{outdeg(v_i)=}outdeg_L(v_i)\\]\n\\end{enumerate}\n}\n\n\\begin{example}[Condition Dang]\\label{ex:dang}$~$\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item Dang$(r_1) = \\mrm{indeg(3)=1\\wedge outdeg(3)=0}$\n    \\item Dang$(r_2) = \\mrm{true}$\n\\end{enumerate}\n\\end{example}\n\n\\Obsv{obsv:dang}{\nGiven an unrestricted rule schema $r=\\langle L\\leftarrow K\\rightarrow R\\rangle$. Let $G$ be a host graph and $g:L\\rightarrow G$ be a premorphism. The dangling condition is satisfied if and only if $\\rho_g(G)\\Sat$Dang$(r)$.\n}\n\n\\begin{proof}\nFrom the definition of the dangling condition (see Definition \\ref{def:dang}), the dangling condition is satisfied when no edge in $G-g(L)$ is incident to any node in $g(L-K)$. By the definition of replacement graph (see Definition \\ref{def:rho}), it is obvious that $G-g(L)$ is equivalent to $\\rho_g(G)-L$. Then, evaluating the construct of $g(L-K)$ in $G$ w.r.t. $g$ is the same as evaluating the $L-K$ in $\\rho_g(G)$. Hence, the dangling condition is satisfied iff no edge in $\\rho_g(G)-L$ incident to any node in $L-K$, which means all nodes in $L-K$ only incident to edges in $L$. Hence, Dang$(r)$ is true.\\qed\n\\end{proof}\n\n\\subsection{From precondition to left-application condition}\n\nNow, we start with transforming a precondition $c$ to a left-application condition with respect to a generalised rule $w=\\tuple{r,ac_L,ac_r}$. Intuitively, the transformation is done by: 1) Find all possibilities of variables in $c$ representing nodes/edges in an input and form a disjunction from all possibilities, denotes by Split$(c,r)$; 2) Express the dangling condition as a condition over $L$, denoted by Dang$(r)$; 3) Evaluate terms and Boolean expression we can evaluate in Split$(c,r)$, Dang$(r)$, and $\\Gamma$, then form a conjunction from the result of evaluation, and simplify the conjunction.\n\nA possibility of variables in $c$ representing nodes/edges in an input graph as mentioned above refers to how variables in $c$ can represent node or edge constants in the replacement of the input graph. A simple example would be for a precondition $c=\\E{V}x(c_1)$ for some FO formula $c_1$ with a free variable $x$, $c$ holds on a host graph $G$ if there exists a node $v$ in $G$ such that $c_1^{\\alpha}$ where $\\alpha(x)=v$ is true in $G$. The node $v$ can be any node in $G$. In the replacement graph of $G$, $v$ can be any node in the left-hand graph of the rule schema, or any node outside it. Split$(c,r)$ is obtained from the disjunction of all these possibilities.\n\n\\Def{Transformation Split}{def:split}{\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$. where $V_L=\\{v_1,\\ldots,v_n\\}$ and $E_L=\\{e_1,\\ldots,e_m\\}$. Let $c$ be a condition over $L$ sharing no variables with $r$ (note that it is always possible to replace the label variables in $c$ with new variables that are distinct from variables in $r$). We define the condition $\\text{Split}(c,r)$ over $L$ inductively as follows:\n\\begin{tabular}{ll}\n    \\multicolumn{2}{l}{- Base case.}  \\\\\n     $~$ &  If $c$ is $\\mrm{true}$, $\\mrm{false}$, a predicate $\\mrm{int(t), char(t), string(t), atom(t), root(t)}$ for \\\\&some term $\\mrm{t}$, or in the form $\\mrm{t_1\\ominus t_2}$ for $\\mrm{\\ominus\\in\\{=.\\neq.<,\\leq,>,\\geq\\}}$ and some\\\\& terms $\\mrm{t_1, t_2}$,\\\\\n     & \\multicolumn{1}{c}{\\text{Split$(c,r) = c$}}\\\\\n    \\multicolumn{2}{l}{- Inductive case.}  \\\\\n     & Let $c_1$ and $c_2$ be conditions over $L$.\\\\\n     & 1) $\\text{Split}(c_1\\vee c_2, r) = \\text{Split}(c_1, r)\\vee\\text{Split}(c_2, r)$,\\\\\n    & 2) $\\text{Split}(c_1 \\wedge c_2, r) = \\text{Split}(c_1, r)\\wedge\\text{Split}(c_2, r)$,\\\\\n    & 3) $\\text{Split}(\\neg c_1, r) = \\neg\\text{Split}(c_1, r)$,\\\\\n    & 4) $\\text{Split}(\\mrm{\\E{V}x}(c_1), r)= (\\mrm{\\bigvee_{i=1}^n}\\text{Split}(c_1^{[ x\\mapsto v_i]}, r))\\vee\\mrm{\\E{V} x(\\bigwedge_{i=1}^n x{\\neq}v_i\\,\\wedge\\,} \\text{Split}(c_1, r)$,\\\\\n    & 5) $\\text{Split}(\\mrm{\\E{E}x}(c_1), r)=\\mrm{(\\bigvee_{i=1}^m}\\text{Split}(c_1^{[x\\mapsto e_i]}, r))\\vee\\mrm{\\E{E}x(\\bigwedge_{i=1}^m x{\\neq}e_i\\,\\wedge\\,} \\text{inc}(c_1, r,x))$,\\\\\n   & ~~~~where\\\\\n   & $~~~~\\text{inc}(c_1, r,x)=\\mrm{\\bigvee_{i=1}^n (\\bigvee_{j=1}^n s(x)=v_i\\wedge t(x)=v_j\\,\\wedge\\,}\\text{Split}(c_1^{[\\mrm{s(x)\\mapsto v_i, t(x)\\mapsto v_j}]}, r))$\\\\\n   & $~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,\n   (s(x)=v_i\\,\\wedge\\,\\bigwedge_{j=1}^n t(x)\\neq v_j\\,\\wedge\\,}\\text{Split}(c_1^{[\\mrm{s(x)\\mapsto v_i}]}, r))$\\\\\n   & $~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,\n   (\\bigwedge_{j=1}^n s(x)\\neq v_j\\,\\wedge\\,t(x)= v_i\\,\\wedge\\,}\\text{Split}(c_1^{[\\mrm{t(x)\\mapsto v_i}]}, r))$\\\\\n   & $~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,\n   (\\bigwedge_{i=1}^n s(x)\\neq v_i\\,\\wedge\\,\\bigwedge_{j=1}^n t(x)\\neq v_j\\,\\wedge\\,}\\text{Split}(c_1\n   , r))$\\\\\n   & 6) $\\text{Split}(\\mrm{\\E{L}x}(c_1), r)=\\E{L}\\mrm{x}(\\text{Split}(c_1, r))$\n\\end{tabular}\\\\\n\\noindent where $c^{[a\\mapsto b]}$ for a variable $a$ and constant $b$ represents the condition $c$ after the replacement of all occurrence of $a$ with $b$. Similarly, $c^{[d\\mapsto b]}$ for $d\\in\\{\\mrm{s(x), t(x)}\\}$ is also a replacement $d$ with $b$.\n}\n$~$\\\\$~$\\\\\nAs can be seen in the definition above, Split of an edge quantifier is not as simple as Split of a node quantifier. For an edge variable $x$ in a precondition, $x$ can represent any edge in $G$. Moreover, the term $\\mrm{s(x)}$ or $\\mrm{t(x)}$ may represent a node in the image of the match. Hence, we need to check these possibilities as well. However, if the precondition does not contain a term $\\mrm{s(x)}$ or $\\mrm{t(x)}$ for some edge variable $x$, we do not need to consider nodes that can be represented by the functions.\n\n\\Obsv{obsv:eE}{\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$ where $V_L=\\{v_1,\\ldots,v_n\\}$ and $E_L=\\{e_1,\\ldots,e_m\\}$. Let $c=\\E{E}x(c_1)$ be a condition over $L$. Then, the following holds:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c_1$ does not contain the term $\\mrm{s(x)},$\\\\\n    $\\text{inc}(c_1, r)=\\mrm{\\bigvee_{i=1}^n (t(x)=v_i\\,\\wedge\\,}\\text{Split}(c_1^{[\\mrm{t(x)\\mapsto v_i}]}, r))\n   \\mrm{\\,\\vee\\,\n   \\bigwedge_{i=1}^n (t(x)\\neq v_i\\,\\wedge\\,}\\text{Split}(c_1\n   , r))$\n   \\item If $c_1$ does not contain the term $\\mrm{t(x)},$\\\\\n    $\\text{inc}(c_1, r)=\\mrm{\\bigvee_{i=1}^n (s(x)=v_i\\,\\wedge\\,}\\text{Split}(c_1^{[\\mrm{s(x)\\mapsto v_i}]}, r))\n   \\mrm{\\,\\vee\\,\n   \\bigwedge_{i=1}^n (s(x)\\neq v_i\\,\\wedge\\,}\\text{Split}(c_1\n   , r))$\n   \\item If $c_1$ does not contain the terms $\\mrm{s(x)}\\text{ and }\\mrm{t(x)},$\\\\\n    $\\text{inc}(c_1, r)=\\text{Split}(c_1\n   , r)$\n\\end{enumerate}\n}\n\n\\begin{proof}$~$\\\\\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c_1$ does not contain the term $\\mrm{s(x)},$ then for any $i,j$, $c_1^{[\\mrm{s(x)\\mapsto v_i, t(x)\\mapsto v_j}]}=c_1^{[\\mrm{t(x)\\mapsto v_j}]}$, and $c_1^{[\\mrm{s(x)}]}=c_1$. The first and the third line of inc$(c_1, r)$ is the disjunction of all possibilities of $\\mrm(t(x))$ is one of nodes in $L$ while the second and forth line is about $\\mrm(t(x))$ is outside the match.\n    \\item Analogously to above.\n    \\item If $c_1$ does not contain the terms $\\mrm{s(x)}\\text{ and }\\mrm{t(x)},$ it is obvious that\\\\ $c_1^{[\\mrm{s(x)\\mapsto v_i, t(x)\\mapsto v_j}]}$ $=\\,c_1^{[\\mrm{t(x)\\mapsto v_j}]}$ $=\\,c_1^{[\\mrm{s(x)\\mapsto v_j}]}$ $=\\,c_1$.\\qed\n\\end{enumerate}\n\\end{proof}\n\n\\Ex{Transformation Split}{ex:Split}{$~$\\\\\n\\begin{tabular}[t]{lcl}\n     Split$(q_1, r_1)$ & = & $\\neg$ Split$(\\mrm{\\E{E}x(s(x)= t(x))}, r_1)$  \\\\\n     & = & $\\mrm{\\neg(m_V(s(e1))\\neq none \\vee m_V(s(e2))\\neq none\\,\\vee}$\\\\\n     && $\\mrm{~~~\\E{E}x(x\\neq e1\\wedge x\\neq e2\\,\\wedge\\,((s(x)=1\\wedge m_V(1)\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)=2\\wedge m_V(2)\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)=3\\wedge m_V(3)\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge s(x)\\neq 3}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\wedge m_V(s(x))\\neq none))))}$\\\\\n     Split$(q_2, r_2)$& = & $\\mrm{\\neg root(1) \\vee \\E{V}x(x\\neq 1 \\wedge \\neg root(x))}$\\\\\n    \\end{tabular}\n}\n\nSince Split$(c,r)$ only disjunct all possibilities of nodes and edges that can be represented by node and edge variables in $c,$ it should not change the semantic of $c$. However, we transform a condition $c$ to a condition over $L$ such that we may not be able to check satisfaction of Split$(c,r)$ in $G$. However, we can always check its satisfaction in $\\RG$ for some premorphism $g:L\\rightarrow G$.\n\n\\Lemma{lemma:split}{\nGiven a condition $c$ and an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, sharing no variables with $c$. For a host graph $G$, let $g : L \\rightarrow G$ be a premorphism. Then,\n\\[G \\models c \\text{ if and only if } \\rho_g(G)\\models \\text{Split}(c, r).\\]\n}\n\n\\begin{proof}Here, we prove the lemma inductively on conditions. The texts above the symbol $\\Leftrightarrow$ bellow refer to lemmas that imply the associated implication, e.g. L4 refers to Lemma 4.\n\\begin{longtable}{llcp{10.5cm}}\n   \\multicolumn{4}{l}{(Base case).} \\\\\n    \\multicolumn{2}{l}{$G\\models c$} & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:isocond}}$ & $\\rho_g(G)\\models c$ \\\\\n    & & $\\Leftrightarrow$ & $\\rho_g(G)\\models \\text{Split}(c, r)$\\\\\n   \\multicolumn{4}{l}{(Inductive case).}\\\\\n   \\multicolumn{4}{l}{Assuming that for some conditions $c_1$ and $c_2$ over $L$, the lemma holds.} \\\\\n     1) & $G\\models c_1\\vee c_2$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $G\\models c_1\\vee G\\models c_2$ \\\\\n    & & $\\Leftrightarrow$ & $\\rho_g(G)\\models \\text{Split}(c_1, r)\\vee \\rho_g(G)\\models \\text{Split}(c_2, r)$\\\\\n     & & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $\\rho_g(G)\\models \\text{Split}(c_1, r)\\vee \\text{Split}(c_2, r)$ \\\\\n     2) & $G\\models c_1\\wedge c_2$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $G\\models^\\alpha c_1\\wedge G\\models^\\alpha c_2$ for some assignment $\\alpha$ \\\\\n    & & $\\Leftrightarrow$ & $\\rho_g(G)\\models^\\beta \\text{Split}(c_1, r)\\vee \\rho_g(G)\\models^\\beta \\text{Split}(c_2, r)$\\\\\n    &&& where $\\beta(x)=\\alpha(x)$ if $x\\notin V_L$; $\\beta(x)=g^{-1}(\\alpha(x))$ otherwise\\\\\n     & & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $\\rho_g(G)\\models \\text{Split}(c_1, r)\\vee \\text{Split}(c_2, r)$ \\\\\n     3) & $G\\models \\neg\\, c_1$  & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $\\neg(G\\Sata c_1)$ for some assignment $\\alpha$\\\\\n     && $\\Leftrightarrow$ & $\\neg(\\rho_g(G)\\models^\\beta \\text{Split}(c_1, r))$ \\\\\n     &&& where $\\beta(x)=\\alpha(x)$ if $x\\notin V_L$; $\\beta(x)=g^{-1}(\\alpha(x))$ otherwise\\\\\n     && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $\\rho_g(G)\\models \\neg\\text{Split}(c_1, r)$  \\\\\n     4) & $G\\models \\mrm{\\E{V}x}(c_1)$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:quantifier}}$ & $G\\models \\mrm{\\bigvee_{i=1}^n} {c_1}^{[ \\mrm{x\\mapsto v_i}]}\\vee\\mrm{\\E{V} x(\\bigwedge_{i=1}^n x\\neq v_i\\wedge} c_1)$  \\\\\n     & & $\\Leftrightarrow$ & $\\rho_g(G)\\models \\mrm{\\bigvee_{i=1}^n \\text{Split}(c_1^{[ x\\mapsto v_i]}, r)\\vee\\E{V} x(\\bigwedge_{i=1}^n x\\neq v_i\\wedge \\text{Split}(c_1, r))}$  \\\\\n     5) & $G\\models \\E{E} \\mrm{x}(c_1)$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:quantifier}}$ & $G\\models \\mrm{\\bigvee_{i=1}^m} {c_1}^{[ \\mrm{x\\mapsto e_i}]}\\mrm{\\vee\\E{V} x(\\bigwedge_{i=1}^m x\\neq e_i\\wedge} c_1)$  \\\\\n     & & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:quantifier}}$ & $\\rho_g(G)\\models \\mrm{\\bigvee_{i=1}^m \\text{Split}(c_1^{[ x\\mapsto e_i]}, r)\\vee\\E{V} x(\\bigwedge_{i=1}^m x\\neq v_i\\wedge \\text{Split}(c_1, r))}$  \\\\\n     & & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:quantifier}}$ & $\\rho_g(G)\\models \\mrm{\\bigvee_{i=1}^m \\text{Split}(c_1^{[ x\\mapsto e_i]}, r)\\vee\\E{V} x(\\bigwedge_{i=1}^m x\\neq v_i\\wedge \\text{inc}(c_1,r))}$  \\\\\n     6) & $G\\models \\E{L}\\mrm{x}(c_1)$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $G\\models c_1$ \\\\\n     &  & $\\Leftrightarrow$ & $\\rho_g(G)\\models \\text{Split}(c_1, r)$  \\\\\n     & & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:BolOperators}}$ & $\\rho_g(G)\\models \\E{L}\\mrm{x}(\\text{Split}(c_1, r))$\n\\end{longtable}\\qed\n\\end{proof}\n\nAfter splitting the precondition into all possibilities of representations, we check the value of some functions and Boolean operators to check if any possibility violates the precondition such that we can omit the possibility.\n\n\\Def{Valuation of $c$}{def:val}{\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, a condition $c$ over $L$, a host graph $G$, and premoprhism $g:L\\rightarrow G$. Let $c$ shares no variable with $L$ unless $c$ is a rule schema condition. Let also $F=\\{\\mrm{s,t,l_V,l_E,m_V,m_E}$,$\\mrm{indeg,outdeg,length}$ be the set of function syntax. Let also $y\\oplus_L z$ for $\\oplus\\in\\{+,-,*,/,:,.\\}$ and $y,z\\in\\mathbb{L}$ denotes the value of $y\\oplus z$ as desribed in Section 3.3, and $f_L(z)$ for a constant $z$ and $f\\in F$ denotes the value of $f(y)$ in $L$. \\emph{Valuation of $c$ w.r.t. $r$}, written Val$(c, r)$, is constructed by applying the following steps to $c$:\n \\vspace{-\\topsep}\\begin{enumerate}\\footnotesize\n    \\item Obtain $c'$ by changing every term $x$ in $c$ with $T(x)$, where\n    \\begin{enumerate}\n        \\item If $x$ is a constant or variable, $T(x)=x$\n        \\item If $x=f(y)$ for $f\\in F,$\\\\\n        $T(x)=\\begin{cases}\n        f_L(y)&\\text{if $f\\in F\\backslash\\{\\mrm{indeg,outdeg}\\}$ and $y$ is a constant}\\\\\n        & ~~\\text{or $f\\in\\{\\mrm{indeg,outdeg}\\}$ and $y\\in V_L-V_K$}\n        \\\\\n        f_L(T(x)) &\\text{if $f\\in\\{\\mrm{l_V,m_V}\\}$ and $(y=\\mrm{s(e)}$ or $y=\\mrm{t(e)})$ for $e\\in E_L$}\\\\\n        &~~\\text{or $f\\in\\{\\mrm{indeg,outdeg}\\}$ and $T(y)\\in V_L-V_K$}\\\\\n        incon(T(y))+f_L(T(y)) &\\text{if $f=\\mrm{indeg}$ and $y\\in V_K$}\\\\\n        outcon(T(y))+f_L(T(y)) &\\text{if $f=\\mrm{outdeg}$ and $y\\in V_K$}\\\\\nf(y) &\\text{otherwise}\n        \\end{cases}$\n    \\item If $x\\oplus z$ for $\\oplus\\in\\{+,-,/,*,:,.\\},$\\\\\n    $T(x)=\\begin{cases}\n    y\\oplus_L z & \\text{if $y,z\\in\\mathbb{L}$}\\\\\n    T(y)\\oplus T(z) &\\text{if $T(y)=\\notin\\mathbb{L}$ or $T(z)=\\notin\\mathbb{L}$}\\\\\n    T(T(y)\\oplus T(z)) &\\text{otherwise}\n    \\end{cases}$\n    \\end{enumerate}\n\\item Obtain $c\"$ by replacing predicates and Boolean operators $x$ in $c'$ with $B(x)$, where\\\\\n$B(x)=\\begin{cases}\ny\\otimes_\\mathbb{B} z & \\text{if $x=y\\otimes z$ for $\\otimes\\in \\{=,\\neq,\\leq,\\geq\\}$ and constants $y,z$}\\\\\n\\mrm{true} &\\text{if $x=\\mrm{root(v)}$ for $v\\in r_L$}\\\\\n\\mrm{false} &\\text{if $x=\\mrm{root(v)}$ for $v\\notin r_L$}\\\\\nx &\\text{otherwise}\n\\end{cases}$\n\\item Simplify $c\"$ such that there are no subformulas in the form $\\mrm{\\neg\\, true,} \\neg(\\neg\\,a)$ ${\\neg(a\\vee b),}$ ${\\neg(a\\wedge b)}$ for some conditions $a, b$. We can always simplify them to $\\mrm{false}, a, \\neg a\\wedge\\neg b, \\neg a\\vee\\neg b$ respectively.\n\\end{enumerate}\n}\n\n\\begin{example}[Valuation of a graph condition]\\label{ex:val}\\normalfont\nFor rules $r_1$ and $r_2$,\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item \\begin{tabular}[t]{lcl}\n    \\multicolumn{3}{l}{Val$(\\text{Split}(q, r_1), r_1)$}\\\\\n    & = & $\\mrm{\\neg(none\\neq none \\vee none\\neq none\\,\\vee}$\\\\\n     && $\\mrm{~~~\\E{E}x(x\\neq e1\\wedge x\\neq e2\\,\\wedge\\,((s(x)=1\\wedge none\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)=2\\wedge none\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)=3\\wedge none\\neq none)}$\\\\\n     && $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mrm{\\vee\\,(s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge s(x)\\neq 3\\wedge m_V(s(x))\\neq none))))}$\\\\\n    \n     & $\\equiv$ & $\\mrm{\\neg\\E{E}x(x\\neq e1\\wedge x\\neq e2\\wedge s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge s(x)\\neq 3\\wedge m_V(s(x))\\neq none)}$\n    \\end{tabular}\\\\\n    Here, we replace the terms $\\mrm{s(e1),s(e2)}$ with node constant $\\mrm{1}$, then replace $\\mrm{m_V(1), m_V(2), m_V(3)}$ with $\\mrm{none}$. Then, we simplify the resulting condition by evaluating $\\mrm{none\\neq none}$ which is equivalent to $\\mrm{false}$.\n    \n    \\item \\begin{tabular}[t]{lcl}\n    Val$(\\text{Split}(s, r_2), r_1)$ & = & $\\mrm{false \\vee \\E{V}x(x\\neq 1\\wedge\\neg root(x))}$\\\\\n    & $\\equiv$ & $\\mrm{\\E{V}x(x\\neq 1\\wedge\\neg root(x))}$\\end{tabular}\\\\\n     Here, we substitute $\\mrm{false}$ for $\\neg root(1)$ since the node 1 in $L$ is a rooted node.\n\n\\item \\begin{tabular}[t]{lcl}\n    Val$(\\Gamma_1, r_1)$ & = & $\\mrm{d\\geq e}$\\\\\n\\end{tabular}\\\\\nFor this case, we change nothing.\n\n\\item \\begin{tabular}[t]{lcl}\n    Val$(\\Gamma_2, r_2)$ & = & $\\mrm{outcon(1)\\neq 0}$\\\\\n\\end{tabular}\\\\\nIn this case, we change $\\mrm{outdeg(1)}$ with $\\mrm{outcon(1)+0}$ because the outdegree of node 1 in $L$ is 0.\n\\end{enumerate}\n\\end{example}\n\nIntuitively, Val gives some terms with node/edge constants their value in $L$. Recall that if there exists injective morphism $g:L^\\alpha\\rightarrow G$ for some label assignment $\\alpha_L$, then there must be an inclusion $L^\\alpha\\rightarrow \\RG$. This should assert that the value of terms we valuate in $L$ is equal to their value in $\\RG$.\n\n\\Lemma{lemma:val}{\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, a host graph $G$, and an injectiva morphism $g:L^\\alpha\\rightarrow G$ for a label assignment $\\alpha_L$. For a graph condition $c$,\n\\[\\rho_g(G)\\Sat c \\text{ if and only if } \\rho_g(G)\\Sat (\\text{Val}(c,r))^\\alpha\\]\n}\n\n\\begin{proof} \nLet us consider the construction of Val$(c)$ step by step. In step 1, we change terms $x$ in $c$ with $T(x)$. Here, we change functions $\\mrm{s(e),t(e),l_V(v),m_V(v)}$,\\\\$\\mrm{l_E(e),m_E(e),l_V(s(e)),l_V(t(e)),m_V(s(e)),m_V(t(e))}$ for $e\\in E_L$ and $v\\in V_L$ with their values in $L$. Since $L^\\alpha\\rightarrow\\RG$ is an inclusion, then $s_L(e)=s_{\\RG}(e)$ and $t_L(e)=t_{\\RG}(e)$. Also, $(\\lst_L(i))^\\alpha=\\lst_{\\RG}(i)$, $(\\mrk_L(i))^\\alpha=\\mrk_{\\RG}(i)$ for all $i\\in V_G$ and $i\\in E_G$ such that the replacement does not change the satisfaction of $c$ in $\\RG$. Then for function $\\mrm{indeg(v)}$ for $v\\in V_L-V_K$, we change it to $indeg_L(x)$ due to the dangling condition, and for $v\\in V_K$, we change it to $incon(v)+indeg_L(v)$ which is equivalent to $indeg_G(v)=indeg_{\\RG}(v)$ because $incon(v)=indeg_G(v)-indeg_L(v)$ (and analogously for $\\mrm{outdeg(v)}$).\nIn step 2, changing Boolean operators whose arguments are constants to their Boolean value clearly does not change the satisfaction in $\\RG$. Also, by the definition of morphism, $p_L(v)=p_{\\RG}(v)$ for all $v\\in V_L$ so that the Boolean value of $\\mrm{root(v)}$ in $L$ is equivalent to the Boolean value of $\\mrm{root(v)}$ in $\\RG$.\nFinally, in step 3, simplification clearly does not change satisfaction.\\qed\n\\end{proof}\n\nFinally, we define the transformation Lift, which takes a precondition and a generalised rule schema as an input and gives a left-application condition as an output. The output should express the precondition, the dangling condition, and the existing left-application condition of the given generalised rule schema.\n\n\\Def{Transformation Lift}{def:lift}{\nGiven a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$. Let $c$ be a precondition. A left application condition w.r.t. $c$ and $w$, denoted by Lift$(c,w)$, is the condition over $L$:\n\\[\\text{Lift}(c, w)=\\text{Val}(\\text{Split}(c\\wedge ac_L, r)\\wedge \\text{Dang}(r), r).\\]\n}\n\n\\begin{example}[Transformation Lift]$~$\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $\\text{Lift}(q_1, \\mtt{del}^\\vee)$ \\\\\n    =  $\\mrm{\\neg\\E{E}x(x\\neq e1\\wedge x\\neq e2\\wedge s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge s(x)\\neq 3\\wedge m_V(s(x))\\neq none)}$\\\\\n        $~~~\\wedge\\,\\mrm{d\\geq e}$\n         \n    \\item \\begin{tabular}[t]{lcl}\n        $\\text{Lift}(q_2, \\mtt{copy}^\\vee)$ & = & $\\mrm{\\E{V}x(x\\neq 1\\wedge\\neg root(x)) \\wedge outcon(1)\\neq 0  \\wedge true}$\\\\\n        & $\\equiv$ & $\\mrm{\\E{V}x(x\\neq 1\\wedge\\neg root(x)) \\wedge outcon(1)\\neq 0}$\n         \\end{tabular}\n\\end{enumerate}\n\\end{example}\n\n\\Prop{Left-application condition}{prop:lift}{\nGiven a host graph $G$ and a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$. Let $c$ be a precondition and $\\alpha_L$ be a label assignment such that there exists an injective morphism $g:L^\\alpha\\rightarrow G$. For some host graph $H$,\n\\[\\text{$G\\Sat c$ and $G\\Rightarrow_{w,g,g^*}H$ implies $\\RG\\Sat$(Lift$(c,w))^\\alpha$}\\]\n}\n\n\\begin{proof}From Lemma \\ref{lemma:split}, we know that $G\\Sat c$ implies $\\RG\\Sat$Split$(c,r)$. Then $G\\Rightarrow_{w,g,g^*}H$ implies $\\RG\\Sat ac_L$, which implies $\\RG\\Sat$Split$(ac_L,r)$, and the existence of natural double-pushout with match $g:L^\\alpha\\rightarrow G$. The latter implies the satisfaction of the dangling condition. The satisfaction of the dangling condition implies $\\RG\\Sat$Dang$(r)$ based on Observation \\ref{obsv:dang}, such that $\\RG\\Sat$Split$(c\\wedge ac_L,r)\\wedge$Dang$(r)$, and $\\RG\\Sat$Val(Split$(c,r)\\wedge ac_L\\wedge$Dang$(r),r)^\\alpha$ from Lemma \\ref{lemma:val}. \\qed\n\\end{proof}\n\nRecall the construction of Split$(c,r)$ for a precondition $c$ and an unrestricted rule schema $r$. A node/edge quantifier is preserved in the result of the transformation with additional restriction about $x$ not representing any node/edge in $L$. Hence in the resulting condition over $L$ from transformation Lift, every node/edge variable should not represent any node/edge in $L$.\n\n\\Obsv{obsv:lift}{\nGiven a host graph $G$ and a generalised rule $w=\\tuple{r^\\alpha,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, and a precondition $c$. For every node/edge variable $x$ in Lift$(c,w)$, $x$ does not represent any node/edge in $L$.\n}\n\n\\begin{proof}\nHere we show that for every node/edge variable $x$, there exists an existential quantifier over $x$ such that there exists constraint $\\bigwedge_{i\\in V_{L}x\\neq i}$ or $\\bigwedge_{i\\in E_{L}x\\neq i}$ inside the quantifier.\n\nLift$(c,w)$ is a conjunction of Val$(\\text{Split}(c,r), r)$, Dang$(r)$, and Val$(\\Gamma, r)$. The transformation Val clearly does not remove or change subformulas in the form $x\\neq i$ and does not add any new node/edge variable. Hence, we just need to show that for every node/edge variable $x$ in $\\text{Split}(c,r)$, Dang$(r)$, and $\\Gamma$, there exists constraint $\\bigwedge_{i\\in V_{L}x\\neq i}$ or $\\bigwedge_{i\\in E_{L}x\\neq i}$.\n\nIt is obvious that $\\Gamma$ does not have node and edge variable from its syntax. For Dang$(r)$, it clearly only has one edge variable and there exists constraint $\\bigwedge_{i\\in E_{L}x\\neq i}$ inside the existential quantifier for the variable. Finally for Split$(c,r)$, since $c$ is a closed formula, every node/edge variable must be bounded by existential quantifier, such that from Definition \\ref{def:split}, the variable must be bounded by existential quantifier with constraint $\\bigwedge_{i\\in V_{L}x\\neq i}$ or $\\bigwedge_{i\\in E_{L}x\\neq i}$ inside.\\qed\n\\end{proof}\n\n\\subsection{From left to right-application condition}\n\nTo obtain a right-application condition from a left-application condition, we need to consider what properties could be different in the initial and the result graphs. Recall that in constructing a left-application condition, we evaluate all functions with a node/edge constant argument and change them with constant, including the constant $\\mrm{incon(v)}$ and $\\mrm{outcon(v)}$ when evaluating $\\mrm{indeg(v)}$ and $\\mrm{outdeg(v)}$ for node $v$ in the interface. In the result graph $H$, $indeg_H(v)$ is clearly equal to $incon(v)+indeg_R(H)$, and analogous for $outdeg_H(v)$. \n\nThe Boolean value for $\\mrm{x=i}$ for any node/edge variable $x$ and node/edge constant $i$ not in $R$ must be false in the resulting graph. Analogously, $\\mrm{x=i}$ is always true. Also, all variables in the left-application condition should not represent any new nodes and edges in the right-hand side.\n\n\\begin{definition}[Adjusment]\\label{def:adj}\\normalfont\nGiven an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$ and a condition $c$ over $L$. Let $c'$ be a condition over $L$ that is obtained from $c$ by changing every term $\\mrm{incon(x)}$ (or $\\mrm{outcon(x)}$) for $x\\in V_K$ with $\\mrm{indeg(x)-}indeg_R(x)$ (or $\\mrm{outdeg(x)-}outdeg_R(x)$). Let also $\\{v_1,\\ldots,v_n\\}$ and $\\{e_1,\\ldots,e_m\\}$ denote the set of all nodes and edges in $R-K$ respectively. \nThe \\textit{adjusted} condition of $c$ w.r.t $r$, denoted by Adj$(c, r)$,  is a condition over $R$ that is defined inductively, where $c_1,c_2$ are conditions over $L$:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c$ is $\\mrm{true}$ or $\\mrm{false}$, Adj$(c,r)=c'$;\n    \\item If $c$ is the predicates $\\mrm{int(x),char(x),string(x)}$ or $\\mrm{atom(x)}$ for a list variable $x$, Adj$(c,r)=c'$;\n    \\item If $c=\\mrm{root(x)}$ for some term $x$ representing a node, Adj$(c,r)=c'$\n    \\item If $c=x_1\\ominus x_2$ for some terms $x_1, x_2$ and $\\ominus\\in\\{=,\\neq,<,\\leq,>,\\geq\\}$,\\\\\n    Adj$(c,r)$ =\n            $\\begin{cases} \n      \\mrm{false} & ,\\text{if $\\ominus\\in\\{=\\}$ and $x_1\\in V_L-V_K\\cup E_{L}$ or $x_2\\in V_L-V_K\\cup E_{L}$}, \\\\\n        \\mrm{true} & ,\\text{if $\\ominus\\in\\{\\neq\\}$ and $x_1\\in V_L-V_K\\cup E_{L}$ or $x_2\\in V_L-V_K\\cup E_{L}$}, \\\\\n      c' & ,\\text{otherwise}\n   \\end{cases}$\n    \\item Adj$(c_1\\vee c_2,r) = \\text{Adj}({c_1},r)\\vee\\text{Adj}({c_2},r)$\n    \\item  Adj$(c_1\\wedge c_2,r) = \\text{Adj}({c_1},r)\\wedge\\text{Adj}({c_2},r)$\n    \\item Adj$(\\neg c_1,r)=\\neg\\text{Adj}({c_1},r)$\n    \\item Adj$(\\E{V}\\mrm{x}(c_1),r)=\\E{V}\\mrm{x}(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge\\text{Adj}(c_1,r))$\n    \\item Adj$(\\E{E}\\mrm{x}(c_1),r)=\\E{E}\\mrm{x}(x\\neq e_1\\wedge\\ldots\\wedge x\\neq e_m\\wedge\\text{Adj}(c_1,r))$\n    \\item Adj$(\\E{L}\\mrm{x}(c_1),r)=\\E{L}\\mrm{x}(\\text{Adj}({c_1},r))$\\qed\n\\end{enumerate}\n\\end{definition}\n\n\\begin{example}$~$\\\\\nLet $p_1$ denotes Lift$(q_1,\\mtt{del^\\vee})$ and $p_2$ denotes Lift$(q_2,\\mtt{copy^\\vee})$.\\\\ \\begin{tabular}{lcp{10.5cm}}\n    1. Adj$(p_1,r_1)$ & = & $\\mrm{\\neg\\E{E}x(x\\neq e1\\wedge s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge m_V(s(x))\\neq none)\\wedge\\,\\mrm{d\\geq e}}$\\\\\n    2. Adj$(p_2,r_2)$ & = & $\\mrm{\\E{V}x(x\\neq 1\\wedge x\\neq 2\\wedge\\neg root(x)) \\wedge outdeg(1)\\neq 1}$\\\\\n\\end{tabular}\n\\end{example}\n         \nThe main purpose of transformation Adj is to adjust the obtained left-application condition such that it can be satisfied by the replacement graph of the resulting graph.\n\n\\Lemma{lemma:adj}{\nGiven a host graph $G$, a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, an injective morphism $g:L^\\alpha\\rightarrow G$ for some label assignment $\\alpha_L$, and a precondition $d$. Let $H$ be a host graph such that $G\\Rightarrow_{w,g,g^*}H$ for some injective morphism $g^*:R^\\beta\\rightarrow H$ where $\\beta_R(i)=\\alpha_L(i)$ for all common item $i$ in domain $\\beta_R$ and $\\alpha_L(i)$. Then,\n\\[\\text{$\\RG\\Sat($Lift$(d,w))^\\alpha$ implies $\\RH\\Sat$(Adj(Lift($d,w),r))^\\beta$}\\]\n}\n\n\\begin{proof}\nNote that Adj$(c,r)$ does not change any term representing label in $c$ such that Adj$(c^\\alpha,r)\\equiv$Adj$(c,r)^\\alpha$ for all label assignment $\\alpha_L$. Also, note that Adj$(c,r)$ does not contain any variable $x$ in $R$ that does not exist in $L$. Hence, Adj$(c,r)^\\alpha=$Adj$(c,r)^\\beta$.\nAssuming $\\RG\\Sat c^\\alpha$ for $c=$Lift$(c,w)$, we prove that $\\RH\\Sat$(Adj$(c,r))^\\beta$ inductively bellow:\\\\\n\\noindent Base case.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c$ is $\\mrm{true}$ or $\\mrm{false}$, it is obvious that the lemma holds as every graph satisfies $\\mrm{true}$ and no graph satisfies $\\mrm{false}$\n    \\item If $c$ is the predicate $\\mrm{int(x),char(x),string(x)}$ or $\\mrm{atom(x)}$ for a list variable $x$, $c'\\equiv c$ and satisfaction of $c$ is independent on the host graph such that $\\RG\\Sat c^\\alpha$ implies $\\RH\\Sat c'^\\alpha$ and $c'^\\alpha=c'^\\beta$.\n    \\item If $c$ is the predicate $\\mrm{root(x)}$ for some term $x$ representing a node, then $x\\notin V_L$ (see Definition $\\ref{def:val}$ point 2), $x$ is a variable representing $V_{\\RG}-(V_L)=V_{\\RH}-V_R$ (see Observation \\ref{obsv:lift}), or $x$ is the function $\\mrm{s(x)}$ or $\\mrm{t(x)}$ for some edge variable $x$ representing an edge in $E_{\\RG}-E_L=E_{\\RH}-E_R$ (see Definition $\\ref{def:val}$ point 1(b) and \\ref{obsv:lift}). Hence, $x$ representing a node in $\\RG-L$, which is also in $\\RH-R$ so that if $\\mrm{root(x)}$ is true in $\\RG$, $\\mrm{root(x)}$ must be true in $\\RH$, and label assignment has nothing to do with this.\n    \\item If $c=x_1\\ominus x_2$, if $x_1$ and $x_2$ are terms representing lists, then $x_1$ and $x_2$ independent to nodes and edges in $V_L$ unless $x_1$ or $x_2$ is in the form $\\mrm{incon(v)} or \\mrm{outcon(v)}$ for some $v\\in V_K$ (see Definition $\\ref{def:val}$ point 1(b) and \\ref{obsv:lift}). However, because $outcon(v)=outdeg_{\\RG}(v)-outdeg_L(v)=outdeg_{\\RH}(v)-outdeg_R(v)$, then semantics of $\\mrm{outcon(v)}$ in $\\RG$ is equivalent to semantics of $\\mrm{indeg(v)-}indeg_R(v)$ in $\\RH$. Hence, $c$ is either independent to nodes and edges in $V_L$ or contain $\\mrm{outcon(x)}$ or $\\mrm{incon(x)}$, $\\RG\\Sat c$ implies $\\RH\\Sat c'=$Adj$(c,r)$, or $c$. If $c$ is $x_1=x_2$ and $x_1$ or $x_2$ is a constant in $(V_L-V_K)$ or in $E_L$, it is obvious that there in no node/edge in $\\RH$ that is equal to the constant such that $\\RH\\Sat\\mrm{false}=$Adj$(c,r)$. Analogously, if $c$ is $x_1\\neq x_2$ and $x_1$ or $x_2$ is a constant in $(V_L-V_K)$ or in $E_L$, every node/edge in $\\RH$ does not equal to the node or edge such that $\\RH\\Sat\\mrm{true}=$Adj$(c,r)$.\n    \\end{enumerate}\n    Inductive case. Assuming $\\RG\\Sat c_1^\\alpha$ implies $\\RH\\Sat$Adj$(c_1,r)^\\beta$ and  $\\RG\\Sat c_2^\\alpha$ implies $\\RH\\Sat$Adj$(c_2,r)^\\beta$ for some conditions $c_1,c_2$ over $L$,\n    \\begin{enumerate}\n    \\item $\\RG\\Sat (c_1\\vee c_2)^\\alpha$ implies $\\RG\\Sat c_1^\\alpha$ or $\\RG\\Sat c_2^\\alpha$ implies \n    $\\RH\\Sat$Adj$(c_1,r)^\\beta$ or $\\RH\\Sat$Adj$(c_2,r)^\\beta$, implies $\\RH\\Sat$(Adj$(c_1,r)\\vee$Adj$(c_2,r))^\\beta$.\n    \\item $\\RG\\Sat (c_1\\wedge c_2)^\\alpha$ implies $\\RG\\Sat^{\\mu_V,\\mu_E} c_1^\\alpha$ and $\\RG\\Sat^{\\mu_V,\\mu_E} c_2^\\alpha$ for some assignments $\\mu_V,\\mu_E$ which implies \n    $\\RH\\Sat^{\\mu_V,\\mu_E}$Adj$(c_1,r)^\\beta$ and $\\RH\\Sat^{\\mu_V,\\mu_E}$Adj$(c_2,r)^\\beta$ implies $\\RH\\Sat$(Adj$(c_1,r)\\wedge$Adj$(c_2,r))^\\beta$\n    \\item $\\RG\\Sat \\neg c_1^\\alpha$ implies $\\neg(\\RG\\Sat{\\mu_V,\\mu_E} c_1^\\alpha)$ for some assignments $\\mu_V,\\mu_E$ which implies \n    $\\neg(\\RH\\Sat^{\\mu_V,\\mu_E}$(Adj$(c_1,r))^\\beta)$, implying $\\RH\\Sat\\neg$(Adj$(c_1,r))^\\beta$\n    \\item If $c=\\E{V}x(c_1)$, recall that every node variable $x$ in $c$ does not represent node in $L$. $\\RG\\Sat(\\E{V}x(c_1))^\\alpha$ implies $\\RG\\Sat (c_1^{x\\mapsto v})^\\alpha$ for some $v\\in V_{\\RG}-V_L=V_{\\RH}-V_R$ which implies $\\RH\\Sat$(Adj$(c_1^{[x\\mapsto v]}, r))^\\beta$. Since $v\\notin V_{R},$ $\\RH\\Sat(\\E{V}x(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge$Adj$(c_1, r)))^\\beta$\n    \\item If $c=\\E{V}x(c_1)$, the proof is analogous to above\n    \\item $\\RG\\Sat(\\E{L}x(c_1))^\\alpha$ implies $\\RG\\Sat (c_1^{x\\mapsto k})^\\alpha$ for some $k\\in \\mathbb{L}$ which implies $\\RH\\Sat$(Adj$(c_1^{[x\\mapsto k]}, r))^\\beta$=(Adj$(c_1, r)^{[x\\mapsto k]})^\\beta$, which means $\\RH\\Sat(\\E{L}x($Adj$(c_1, r)))^\\beta$.\\qed\n    \\end{enumerate}\n\\end{proof}\n\nNote that any unrestricted rule schema $r$ is invertible. The transformation Adj adjusts a left-application condition to the properties of the resulting graph w.r.t the given unrestricted rule schema. This means, adjusting the properties of the resulting graph w.r.t the inverse of the unrestricted rule schema should resulting in the initial left-application condition.\n\n\\Lemma{lemma:adj2}{\nGiven host graph $G$, a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, and a precondition $d$. Let $g:L^\\alpha\\rightarrow R$ for some label assignment $\\alpha_L$ be an injective morphism satisfying the dangling condition. Then\n\\[\\text{$\\RG\\Sat$ Adj(Adj$($Lift$(d,w),r),r^{-1})^\\alpha$ if and only if $\\RG\\Sat$Lift$(d,w)^\\alpha$}\\]\n}\n\n\\begin{proof}\nHere we prove that $\\RG\\Sat$ Adj(Adj$(c,r),r^{-1})$ if and only if $\\RG\\Sat c$ inductively, where $c=$Lift$(d,r)$:\\\\\nBase case.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $c$ is $\\mrm{true}$ or $\\mrm{false}$, Adj$(c,r)=c'=$Adj(Adj$(c,r),r^{-1})$\n    \\item If $c$ is the predicate $\\mrm{int(x),char(x),string(x)}$ or $\\mrm{atom(x)}$ for a list variable $x$, $c'\\equiv c$ such that Adj$(c,r)=c'=$Adj(Adj$(c,r),r^{-1})$\n    \\item If $c$ is the predicate $\\mrm{root(x)}$, $c'\\equiv c$ such that Adj$(c,r)=c'=$Adj(Adj$(c,r),r^{-1})$\n    \\item If $c$ is $x_1=x_2$ for $x_1$ or $x_2$ a node or edge constant in $L-K$, both $x_1$ and $x_2$ cannot be constants (see construction of Val which is used to construct $c$). Then, one of them must be a node or edge variable (which does not represent node in $L$ - see Observation \\ref{obsv:lift}), or the function $\\mrm{s(x)}$ or $\\mrm{t(x)}$ for some edge variable $x$. Observation \\ref{obsv:lift} shows us that $x$ does not representing edge in $L$, and $g$ satisfies the dangling condition implies $\\mrm{s(x)}$ and $\\mrm{t(x)}$ do not represent nodes in $\\RG-(L-K)$. Hence, $x_1=x_2$ is always false in $\\RG$. Otherwise for $c=x_1\\ominus x_2$, Adj$(c,r)=c'=$Adj(Adj$(c,r),r^{-1})$. \n    \\end{enumerate}\n    Inductive case.\\\\\n    Assume that $c_1\\equiv$Adj(Adj$(c_1,r),r^{-1})$ and $c_2\\equiv$Adj(Adj$(c_2,r),r^{-1})$ for conditions $c_1,c_2$ over $L$.\n    \\begin{enumerate}\n    \\item $\\RG\\Sat c_1\\vee c_2$ iff $\\RG\\Sat c_1$ or $\\RG\\Sat c_2$ iff $\\RG\\Sat$Adj(Adj$(c_1,r),r^{-1})$ or $\\RG\\Sat$Adj(Adj$(c_2,r),r^{-1})$ iff $\\RG\\Sat$Adj(Adj$(c_1,r),r^{-1})\\vee$\\\\ Adj(Adj$(c_2,r),r^{-1})\\equiv$Adj(Adj$(c,r),r^{-1})$\n    \\item $\\RG\\Sat c_1\\wedge c_2$ implies $\\RG\\Sat^\\beta c_1 \\wedge \\RG\\Sat^\\beta c_2$ for some assignment $\\beta$ iff \n    $\\RG\\Sat^\\beta$Adj(Adj$(c_1,r),r^{-1})\\wedge\\RG\\Sat^\\beta$Adj(Adj$(c_2,r),r^{-1}))$ iff $\\RG\\Sat$Adj(Adj$(c_1,r),r^{-1})\\wedge$Adj(Adj$(c_2,r),r^{-1}))\\equiv$Adj(Adj$(c,r),r^{-1})$\n    \\item $\\RG\\Sat \\neg c_1$ iff $\\neg(\\RG\\Sat\\beta c_1)$ for some assignment $\\beta$ iff\n    $\\neg(\\RG\\Sat^\\beta$Adj(Adj$(c_1,r),r^{-1})$, iff $\\RG\\Sat\\neg$Adj(Adj$(c_1,r),r^{-1})\\equiv$Adj(Adj$(c,r),r^{-1})$\n    \\item If $c=\\E{V}x(c_1)$, Adj$(c,r)=\\E{V}\\mrm{x}(x\\neq v_1\\wedge\\ldots\\wedge x\\neq v_n\\wedge\\text{Adj}(c_1,r))$, so that Adj(Adj$(c,r),r^{-1})=\\E{V}\\mrm{x}(\\text{Adj(Adj}(c_1,r),r^{-1}))$. Hence, $\\RG\\Sat$Adj(Adj$(c,r),r^{-1})$ iff $\\RG\\Sat\\E{V}\\mrm{x}(\\text{Adj(Adj}(c_1,r),r^{-1}))$ iff $\\RG\\Sat\\E{V}\\mrm{x}(c_1)=c$\n    \\item If $c=\\E{V}x(c_1)$, the proof is analogous to above\n    \\item If $c=\\E{L}x(c_1)$, $\\RG\\Sat$Adj(Adj$(c,r),r^{-1})$ iff $\\RG\\Sat\\E{L}\\mrm{x}(\\text{Adj(Adj}(c_1,r),r^{-1}))$ iff $\\RG\\Sat\\E{L}\\mrm{x}(c_1)=c$\n    \\end{enumerate}\nSince the construction of Adj(Adj($c,r),r^{-1})$ does not any term representing labels, Adj(Adj($c^\\alpha,r),r^{-1})\\equiv$Adj(Adj($c,r)^\\alpha,r^{-1})\\equiv$Adj(Adj($c,r),r^{-1})^\\alpha$. Hence, the lemma is valid.\\qed\n\\end{proof}\n\nActually, from the transformation Adj we already obtain a right-application condition. However, we want a stronger condition such that we add the specification of the right-hand graph. In addition, since the resulting graph should also satisfy the existing right-application of the given generalised rule schema, and the comatch should also satisfy the dangling condition.\n\n    \n\\Def{Shifting}{def:shift}{\nGiven a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, and a precondition $c$. Right application condition w.r.t. $c$ and $w$, denoted by Shift$(c,w)$, is defined as:\n\\[\\text{Shift$(c,w)=$Adj(Lift$(c,w),r)\\wedge\\, ac_R\\, \\wedge\\,$Spec$(R)\\,\\wedge\\,$Dang$(r^{-1})$}.\\]\n}\n\n\\begin{example}$~$\\\\\n\\begin{tabular}{lcp{10.5cm}}\n    Shift$(q_1,\\mtt{del}^\\vee)$&=&$\\mrm{\\neg\\E{E}x(x\\neq e1\\wedge s(x)\\neq 1\\wedge s(x)\\neq 2\\wedge m_V(s(x))\\neq none)\\wedge\\,\\mrm{d\\geq e}}$\\\\\n    &&$\\mrm{\\wedge\\, \\lV(1)=a\\wedge\\lV(2)=b\\wedge\\lE(e1)=d+e\\wedge\\mV(1)=red}$\\\\\n    &&$\\mrm{\\wedge\\mV(2)=none\\wedge\\mE(e1)=none\\wedge s(e1)=1\\wedge t(e1)=2}$\\\\\n    &&$\\mrm{\\wedge \\neg root(1)\\wedge\\neg root(2)\\wedge int(d)\\wedge int(e)}$\\\\\n    Shift$(q_2,\\mtt{del}^\\vee)$&=&$\\mrm{\\E{V}x(x\\neq 1\\wedge x\\neq 2\\wedge\\neg root(x)) \\wedge outdeg(1)\\neq 1}$\\\\\n    &&$\\mrm{\\wedge\\,\\lV(1)=a\\wedge\\lV(2)=a\\wedge\\lE(e1)=empty\\wedge\\mV(1)=none}$\\\\\n    &&$\\mrm{\\wedge\\,\\mV(2)=none\\wedge\\mE(e1)=dashed\\wedge s(e1)=1\\wedge t(e1)=2}$\\\\\n    &&$\\mrm{\\wedge\\,\\neg root(1)\\wedge root(2)\\wedge indeg(2)=1\\wedge outdeg(2)=0}$\n\\end{tabular}\n\\end{example}\n\n  \n  \n\\Prop{Shifting}{prop:shift}{\nGiven a host graph $G$, a generalised rule $w=\\tuple{r,ac_L,ac_R}$ an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, an injective morphism $g:L^\\alpha\\rightarrow G$ for some label assignment $\\alpha_L$, and a precondition $d$.\nThen for host graphs $H$ such that $G\\Rightarrow_{w,g,g^*}H$ with an right morphism $g^*:R^\\beta\\rightarrow H$ where $\\beta_R(i)=\\alpha_L(i)$ for every variable $i$ in $L$ such that $i$ in $R$, and for every node/edge $i$ where $\\mrk_L(i)=\\mrk_R(i)=\\mtt{any}$,\n\\[\\text{$\\RH\\Sat($Adj(Lift$(d,w)),r)^\\beta$ if and only if $\\RH\\Sat$(Shift$(d,w))^\\beta$}\\]\n}\n\n\\begin{proof}\nIt is obvious that Adj(Lift$(d,w)),r)^\\beta$ is implied by Shift$(d,w)^\\beta$, so now we show that Adj(Lift$(d,w)),r)^\\beta$ implies Shift$(d,w)^\\beta$. That is, $ac_R^\\beta\\, \\wedge\\,$Spec$(R)^\\beta\\,\\wedge\\,$ Dang$(r^{-1})^\\beta$ is satisfied by $\\RH$. From Definition \\ref{def:generalisedrPO}, $G\\Rightarrow_{w,g,g^*}H$ implies $\\RH\\Sat ac_R^\\beta$. From the construction of Spec$(R)$, Spec$(R)^\\beta\\equiv$Spec$(R^\\beta)$ such that $\\RH\\Sat$Spec$(R)^\\beta$ is implied by the injective morphism $g^*$. Finally, there is no label variable in Dang$(r^{-1})$ such that Dang$(r^{-1})\\equiv$Dang$(r^{-1})^\\beta$, which is implied by $G\\Rightarrow_{w,g,g^*}H$ because nodes in $R-K$ must not incident to any edge in $\\RH-R$ so that their indegree and outdegree in $R$ represents their indegree and outdegree in $\\RH$.\\qed\n\\end{proof}\n\n\\subsection{From right-application condition to postcondition}\n\nThe right-application condition we obtain from transformation Shift is strong enough to express properties of the replacement graph of any resulting graph. However, since we need a condition (without node/edge constant), we define transformation Post.\n\n\\Def{Formula Post}{def:post}{\nGiven a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule $r=\\tuple{L\\leftarrow K\\rightarrow R}$ and a precondition $c$. A postcondition w.r.t. $c$ and $w$, denoted by Post$(c,w)$, is the FO formula:\n\\[\\text{Post}(c, w)=\\E{V}x_1,\\ldots,x_n(\\E{E}y_1,\\ldots,y_m(\\E{L}z_1,\\ldots,z_k(\\text{Var(Shift}(c,w))))).\\]\nwhere $\\{x_1,\\ldots,x_n\\}$, $\\{y_1,\\ldots,y_m\\}$, and $\\{z_1,\\ldots,z_k\\}$ denote the set of free node, edge, and label (resp.) variables in Var(Shift$(c,w)$). We then denote by Slp$(c,r)$ the formula Post$(c,r^\\vee)$, and  Slp$(c,r^{-1})$ for the formula Post$(c,(r^\\vee)^{-1})$.}\n\nTo obtain a closed FO formula from the obtained right-application condition, we only need to variablise the node/edge constants in the right-application condition, then put an existential quantifier for each free variable in the resulting FO formula.\n\n\\begin{example}$~$\\\\\n\\begin{tabular}{lcp{10.5cm}}\n    Post$(q_1,\\mtt{del}^\\vee)$&=&$\\mrm{\\E{V}u,v(u\\neq v\\wedge \\E{E}w(\\E{L}a,b,d,e(}$\\\\\n    &&$\\mrm{\\neg\\E{E}x(x\\neq w\\wedge s(x)\\neq u\\wedge s(x)\\neq v\\wedge m_V(s(w))\\neq none)\\wedge\\,\\mrm{d\\geq e}}$\\\\\n    &&$\\mrm{\\wedge\\, \\lV(u)=a\\wedge\\lV(v)=b\\wedge\\lE(w)=d+e\\wedge\\mV(u)=red}$\\\\\n    &&$\\mrm{\\wedge\\mV(v)=none\\wedge\\mE(w)=none\\wedge s(w)=u\\wedge t(w)=v}$\\\\\n    &&$\\mrm{\\wedge \\neg root(u)\\wedge\\neg root(v)\\wedge int(d)\\wedge int(e))))}$\\\\\n    Post$(q_2,\\mtt{del}^\\vee)$&=&\n    $\\mrm{\\E{V}u,v(u\\neq v\\wedge\\E{E}w(\\E{L}a(}$\n    \\\\\n    &&$\\mrm{\\E{V}x(x\\neq u\\wedge x\\neq v\\wedge\\neg root(x)) \\wedge outdeg(u)\\neq 1}$\\\\\n    &&$\\mrm{\\wedge\\,\\lV(u)=a\\wedge\\lV(v)=a\\wedge\\lE(w)=empty\\wedge\\mV(u)=none}$\\\\\n    &&$\\mrm{\\wedge\\,\\mV(v)=none\\wedge\\mE(w)=dashed\\wedge s(w)=u\\wedge t(w)=v}$\\\\\n    &&$\\mrm{\\wedge\\,\\neg root(u)\\wedge root(v)\\wedge indeg(v)=1\\wedge outdeg(v)=0})))$\n\\end{tabular}\n\\end{example}\n\n\n\\Prop{Post}{prop:post}{\nGiven a host graph $G$, a generalised rule $w=\\tuple{r,ac_L,ac_R}$ for an unrestricted rule schema $r=\\tuple{L\\leftarrow K\\rightarrow R}$, and a precondition $c$. Then for all host graph $H$ such that there exists an injective morphism $g^*:R^\\beta\\rightarrow H$ for a label assignment $\\beta_R$,\n\\[\\text{$\\RH\\Sat$(Shift$(c,w))^\\beta$ if and only if $H\\Sat$Post$(c, w)^\\beta$}\\]}\n\n\\begin{proof}From Lemma \\ref{lemma:var}, $\\RH\\Sat$(Shift$(c,w))^\\beta$ iff $H\\Sat$Var(Shift$(c,w))^\\beta$. If there is no node (or edge) in $H$, then there is no node (or edge) constant in $\\RH$ since they are isomorphic. Hence, there is no free node (or edge) variable in Var(Shift$(c,w)))^\\beta$ so that there is no additional node (or edge) quantifier for Var(Shift$(c,w)))^\\beta$. If there exists a node (or edge) in $H$, then from Lemma \\ref{lemma:BolOperators}, adding an existential quantifier will not change its satisfaction on $H$. Hence, $H\\Sat$Var(Shift$(c,w)))^\\beta$ iff $H\\Sat$Post$(c, w)^\\beta$.\\qed\n\\end{proof}\n\n\nFinally, we show that Post$(c,r^\\vee)$ is a strongest liberal postcondition w.r.t. $c$ and $r$. That is, by showing that for all host graph $G$, $G\\Sat c$ and $G\\Rightarrow_rH$ implies $H\\Sat$Post$(c,r^\\vee)$, and showing that for all host graph $H$, $H\\Sat$Post$(c,r^\\vee)$ implies the existence of host graph $G$ such that $G\\Sat c$ and $G\\Rightarrow_rH$.\n\n\\Theo{Strongest liberal postconditions}{theo:slp}{\nGiven a precondition $c$ and a conditional rule schema $r=\\tuple{\\langle L \\leftarrow K\\rightarrow R\\rangle,\\Gamma}$. Then, Slp$(c,r)$ is a strongest liberal postcondition w.r.t. $c$ and $r$.}\n\n\\begin{proof}\nFrom Lemma \\ref{lemma:rvee}, $G\\Rightarrow_r H$ iff $G\\Rightarrow_{w,g,g*} H$ for some injective morphisms $g:L^\\alpha\\rightarrow G$ and $g^*:R^\\beta\\rightarrow H$ with label assignment $\\alpha_L$ and $\\beta_R$ where $\\beta_R(i)=\\alpha_L(i)$ for every variable $i$ in $L$ such that $i$ is in $R$, and for every node/edge $i$ where $\\mrk_L(i)=\\mrk_R(i)=\\mtt{any}$. From Proposition \\ref{prop:lift}, Lemma \\ref{lemma:adj}, Proposition \\ref{prop:shift}, and Proposition \\ref{prop:post},\n$G\\Sat c$ and $G\\Rightarrow_{r^\\vee,g,g^*} H$ implies $\\RG\\Sat$(Lift$(c,r^\\vee))^\\alpha$ implies $\\RH\\Sat$Shift$(c,r^\\vee)^\\beta$ implies $H\\Sat$Post$(c,r^\\vee)$. Hence, Post$(c,r^\\vee)$ is a liberal postcondition w.r.t. $c$ and $r$.\n\nTo show that Post$(c,r^\\vee)$ is a strongest liberal postcondition, based on Lemma \\ref{lemma:slp}, we need to show that  for every graph $H$ satisfying Post$(c,r^\\vee)$, there exists a host graph $G$ satisfying $c$ such that $G\\Rightarrow_{r}H$. \n\nRecall the construction of Shift$(c,r^\\vee)$. A graph satisfying Shift$(c,r^\\vee)$ must satisfying Spec$(R)$ such that $H\\Sat$(Post$(c,r^\\vee))$ implies $H\\Sat$(Post$(c,r^\\vee))^\\beta$  for some label assignment $\\beta_R$, which implies $H\\Sat$Var(Spec$(R))^\\beta\\equiv$Var(Spec$(R^\\beta))$. From Lemma \\ref{lemma:var}, this implies the existence of an injective morphism $g^*:R^\\beta\\rightarrow H$. \nFrom Proposition \\ref{prop:post}, $H\\Sat$Post$(c,r^\\vee)^\\beta$ implies $\\RH\\Sat$Shift$(c,r^\\vee)^\\beta$. From the construction of Shift$(c,r^\\vee)$, Dang$(r^{-1})$ asserts that the dangling condition is satisfied by $g^*$. Hence, there exists a natural double-pushout bellow where every morphism is inclusion:\n\n\\begin{center}\n        \\begin{tikzpicture}[scale=0.9, transform shape]\n\t\\node (2) at (1, 0) {(1)};\n\t\\node (a) at (2, 0.75) {$K$};\n\t\\node (b) at (0, 0.75) {$R^\\beta$};\n\t\\node (c) at (4, 0.75) {$L^\\alpha$};\n\t\\node (d) at (2, -0.75) {$D$};\n\t\\node (1) at (3, 0) {(2)};\n\t\\node (e) at (4, -0.75) {$A$};\n\t\\node (f) at (0, -0.75) {$\\RH$};\n    \\draw[->] (a) to node {} (b);\n\t\\draw[->] (a) to node {} (c);\n\t\\draw[->] (a) to node {} (d);\n\t\\draw[->] (d) to node {} (e);\n\t\\draw[->] (d) to node {} (f);\n\t\\draw[->] (c) to node {} (e);\n\t\\draw[->] (b) to node {} (f);\n\\end{tikzpicture}\\end{center}\n\nSince $\\RH\\Sat$Adj(Lift($c,r^\\vee),r)^\\beta$, from Lemma \\ref{lemma:adj} this implies $A$ satisfies Adj(Adj(Lift($c,r^\\vee),r),r^{-1})^\\alpha$. From Lemma \\ref{lemma:adj2}, this implies $A\\Sat c^\\alpha$. Since direct derivations are invertible, $A\\Rightarrow_{r^\\vee,g,g^*}H$. Hence, $A\\Rightarrow_r H$.\\qed\n\\end{proof}\n \n\\section{Proof Calculus}\n\\label{sec:proofrules}\nIn this section, we introduce semantic and syntactic partial correctness calculus. The former consider arbitrary assertion language as pre- and postconditions, while the latter consider conditions (i.e. closed firs-order formulas) as the pre- and postconditions.\n\n\\subsection{Semantic partial correctness calculus}\n\\label{sec:sem}\nFor a graph program $P$ and assertions $c$ and $d$, triple $\\{c\\}\\,P\\,\\{d\\}$ is partially correct iff for all graph satisfying $c$, $H\\in\\Sem{P}G$ implies $H\\Sat d$. \n\n\\begin{definition}[Partial correctness \\cite{PoskittP12}]\\normalfont \\label{def:par}\nA graph program $P$ is \\emph{partially correct} with respect to a precondition $c$ and a postcondition $d$, denoted by $\\vDash \\{c\\}~P~\\{d\\}$ if for every host graph $G$ and every graph $H$ in $\\llbracket P\\rrbracket G$, $G\\models c$ implies $H\\models d$. \\qed\n\\end{definition}  \n\nTo prove that $\\vDash \\{c\\}~P~\\{d\\}$ holds for some assertions $c,d$, and a graph program $P$, we use two methods: 1) finding a strongest liberal postcondition w.r.t $c$ and $P$ and prove that the strongest liberal postcondition implies $d$, and 2) using proof rules for graph programs, create a proof tree to show the partial correctness. The first method has been done in classical programming \\cite{DijkstraS90,Jones-Roscoe-Wood10a}, while the second has been done in graph programming \\cite{Poskitt13} but without the special command $\\mtt{break}$.\n\nIn the previous section, we have defined a strongest liberal postcondition w.r.t. a precondition and a conditional rule schema. In this section, we extend the definition from conditional rule schemata to graph programs. In addition, we also introduce a weakest liberal precondition over a graph program.\n\n\\Def{Strongest liberal postconditions}{def:slpP}{\nA condition $d$ is a \\emph{liberal postcondition} w.r.t. a precondition $c$ and a graph program $P$, if for all host graphs $G$ and $H$,\n\\[G\\vDash c \\text{ and } H\\in\\Sem{P}G \\text{ implies }H\\vDash d.\\]\nA \\emph{strongest liberal postcondition} w.r.t. $c$ and $P$, denoted by SLP$(c,P)$, is a liberal postcondition w.r.t. $c$ and $P$ that implies every liberal postcondition w.r.t. $c$ and $P$.\n}\n\n\\Def{Weakest liberal preconditions}{def:wlpP}{\nA condition $c$ is a \\emph{liberal precondition} w.r.t. a postcondition $d$ and a graph program $P$, if for all host graphs $G$ and $H$,\n\\[G\\vDash c \\text{ and } H\\in\\Sem{P}G \\text{ implies }H\\vDash d.\\]\nA \\emph{weakest liberal precondition} w.r.t. $d$ and $P$, denoted by WLP$(P,d)$, is a liberal precondition w.r.t. $d$ and $P$ that is implied by every liberal postcondition w.r.t. $d$ and $P$.\n}\n\n\\begin{lemma}\\normalfont\\label{lemma:slpP}\nGiven a graph program $P$ and a precondition $c$. Let $d$ be a liberal postcondition w.r.t. $c$ and $P$. Then $d$ is a strongest liberal postcondition w.r.t. $c$ and $P$ if and only if for every graph $H$ satisfying $d$, there exists a host graph $G$ satisfying $c$ such that $H\\in\\Sem{P}G$.\n\\end{lemma}\n\n\\begin{proof}$~$\\\\\n(If).\\\\\nAssuming it is true that for every graph $H$ satisfying $d$, there exists a host graph $G$ satisfying $c$ such that $H\\in\\Sem{P}G$.\nLet $H$ be a host graph satisfying $d$. From the assumption, there exists a graph $G$ such that $G\\vDash c$ and $H\\in\\Sem{P}G$. Since $H\\in\\Sem{P}G$, $H\\vDash a$ for all liberal postcondition $a$ over $c$ and $P$. Hence, $H\\Sat d$ implies $H\\Sat a$ for all liberal postcondition $a$ over $c, P$ such that $d$ is a strongest postcondition w.r.t. $c$ and $P$\\\\\n(Only if).\\\\\nAssume that it is not true that for every host graph $H$, $H\\vDash d$ implies there exists a host graph $G$ satisfying $c$ such that $H\\in\\Sem{P}G$. We show that a graph satisfying $d$ can not imply the graph satisfying all liberal postcondition w.r.t $r$ and $P$. From the assumption, there exists a host graph $H$ such that every host graph $G$ does not satisfy $c$ or $H\\notin\\Sem{P}G$. In the case of $H\\notin\\Sem{P}G$, we clearly can not guarantee characteristic of $H$ w.r.t. $P$. Then for the case where $G$ does not satisfy $c$, we also can not guarantee the satisfaction of any liberal postcondition $a$ over $c$ in $H$ because $a$ is dependent of $c$. Hence, we can not guarantee that $H$ satisfying all liberal postcondition w.r.t. $r$ and $c$.\\qed\n\\end{proof}\n\n\\begin{lemma}\\normalfont\\label{lemma:wlpP}\nGiven a graph program $P$ and a postcondition $d$. Let $c$ be a liberal precondition w.r.t. $P$ and $d$. Then $c$ is a weakest liberal precondition w.r.t. $P$ and $d$ if and only if for every graph $G$ $G\\Sat c$ if and only if for all host graphs $H$, $H\\in\\Sem{P}G$ implies $H\\Sat d$.\n\\end{lemma}\n\n\\begin{proof}\n(If).\\\\\nSuppose that $G\\Sat c$ iff for all host graphs $H$, $H\\in\\Sem{P}G$ implies $H\\Sat d$. It implies for all host graphs $H$, $G\\Sat c$ and $H\\in\\Sem{P}G$ implies $H\\Sat d$. From Definition \\ref{def:wlpP}, $c$ is a liberal precondition. Let $a$ be a liberal precondition w.r.t. $P$ and $d$ as well. From Definition \\ref{def:wlpP}, for all host graphs $H$, $H\\in\\Sem{P}G$ implies $H\\Sat d$, and from the premise, $G\\Sat c$. Hence, $c$ is a weakest liberal precondition.\n(Only if).\\\\\nSuppose that $c$ is a weakest liberal precondition. From Definition \\ref{def:wlpP}, if $G\\Sat c$ then $H\\in\\Sem{P}G$ implies $H\\Sat d$. Let $a$ be a liberal precondition w.r.t $P$ and $d$. From Definition \\ref{def:wlpP}, $G\\Sat a$ implies for all $H$, $H\\in\\Sem{P}G$ implies $H\\Sat d$. Since for all $a$, $G\\Sat a$ must imply $G\\Sat c$, then $H\\in\\Sem{P}G$ implies $H\\Sat d$ must imply $G\\Sat c$ as well.\n\\qed\n\\end{proof}\n\nSLP and WLP for a loop $P!$ is not easy to construct because $P!$ may get stuck or diverge. In \\cite{Pennemann09}, the divergence is represented by infinite formulas while in \\cite{Jones-Roscoe-Wood10a}, it is represented by recursive equation that is not well-defined. In this paper, for practical reason we only consider strongest liberal postconditions over loop-free graph programs.\n\nFor the conditional commands $\\mtt{if/try-then-else}$, the execution of the command depends on the existence of a proper host graph as a result of executing a graph program. In \\cite{Poskitt13}, there is an assertion representing a condition that must be satisfied by a graph such that there exists a path to successful execution, and there is also an assertion representing a condition that must be satisfied by a host graph such that there exist a path to a failure. Here, we define assertion SUCCESS for the former and FAIL for the latter.\n\n\\Def{Assertion SUCCESS}{def:assSE}{\nFor a graph program $P$, SUCCESS$(P)$ is the predicate on host graphs where for all host graph $G$,\n\\[G\\Sat\\text{SUCCESS}(P)\\text{~if and only if there exists a host graph $H$ with~} H\\in\\llbracket P\\rrbracket G.\\]\n}\n\n\\Def{Assertion FAIL}{def:assFE}{\nGiven a graph program $P$. FAIL$(P)$ is the predicate on host graphs where for all host graph $G$,\n\\[G\\Sat\\text{FAIL}(P)\\text{~if and only if~} \\text{fail}\\in\\llbracket P\\rrbracket G.\\qed\\]\n}\n\nNote that for a graph program $C$, $\\FAIL(C)$ does not necessarily equivalent to $\\neg\\SUCCESS(C)$, e.g. if $C=\\mtt{\\{nothing,add\\};zero}$ where\n$\\mtt{nothing}$ is the rule schema where the left and right-hand graphs are the empty graph, $\\mtt{add}$ is the rule schema where the left-hand graph is the empty graph and the right-hand graph is a single 0-labelled unmarked and unrooted node, and $\\mtt{zero}$ is a rule schema that match with the a 0-labelled unmarked and unrooted node.\nFor a host graph $G$ where there is no 0-labelled unmarked unrooted node, there is a derivation $\\tuple{C,G}\\rightarrow^* H$ for some host graph $H$ but also a derivation $\\tuple{C,G}\\rightarrow^* \\mtt{fail}$ such that $G\\Sat\\SUCCESS(C)$ and $G\\Sat\\FAIL(C)$.\n\nHaving a strongest liberal postcondition over a loop-free program $P$ w.r.t a precondition $c$ allows us to prove that the triple $\\{c\\}\\,P\\,\\{d\\}$ for an assertion $d$ is partially correct. That is, by showing that $d$ is implied by the strongest liberal postcondition. \n\n\\Prop{Strongest liberal postcondition for loop-free programs}{prop:slpP}{\nGiven a precondition $c$ and a loop-free program $S$. Then, the following holds:\\\\\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $S$ is a set of rule schemata $\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$,\\\\\n    SLP$(c,\\mathcal{R})=\\begin{cases}\n    \\SLP(c,r_1)\\vee\\ldots\\vee\\SLP(c,r_n) &, \\text{, if~}n>0,\\\\\n    \\mrm{false}&\\text{, otherwise}\\end{cases}$\n    \\item For loop-free programs $C, P,$ and $Q$,\n    \\begin{enumerate}\n        \\item[(i)] If $S=P\\mtt{~or~}Q,$\\\\\n        $\\SLP(c,S)=\\SLP(c,P)\\,\\vee\\,\\SLP(c,Q)$\n        \\item[(ii)] If $S=P;Q,$\\\\\n        $\\SLP(c,S)=\\SLP(\\SLP(c,P),Q)$\n        \\item[(iii)] If $S=\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q,$\\\\\n        $\\SLP(c,S)=\\SLP(c\\wedge \\SUCCESS(C),P)\\vee\\SLP(c\\wedge \\FAIL(C),Q)$\n        \\item[(iv)] If $S=\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q,$\\\\\n        $\\SLP(c,S)=\\SLP(c\\wedge \\SUCCESS(C),C;P)\\vee\\text{SLP}(c\\wedge \\FAIL(C),Q)$\n    \\end{enumerate}\n\\end{enumerate}\n}\n\nComputing SLP$(c,\\mathcal{R})$ for a set of rule schemata $\\mathcal{R}$ is basically disjunct all strongest liberal postcondition w.r.t $c$ and each rule schema in $\\mathcal{R}$. If the rule set is empty, then SLP$(c,\\mathcal{R})$ is $\\mrm{false}$ since there is nothing to disjunct. Computing SLP$(c,P;Q)$ is constructed by having SLP$(c,P)$ and then find strongest liberal postcondition w.r.t. $Q$ and the resulting formula. \n\nThe equation for program composition is the same with the equation for program composition in \\cite{DijkstraS90,Jones-Roscoe-Wood10a}. However, for $\\mtt{if-then-else}$ command, the command $\\mtt{if}$ in classical programming is followed by an assertion while in graph programs it is followed by a graph program. Hence, instead of checking the truth value of the assertion on the input graph, we check the check if the satisfaction of $\\SUCCESS$ and $\\FAIL$ of the associated program on the input graph. Then for $\\mtt{try-then-else}$ command, it does not exist in classical programming, but we have the equation for the command based on its similarity with $\\mtt{if-then-else}$.\n\nThe execution of if/try commands yields two possibilities of results, so we need to check the strongest liberal postcondition for both possibilities and disjunct them. For the graph program $\\mtt{if~}C\\mtt{~then~}P\\mtt{~else~}Q$, $P$ can be executed if $\\SUCCESS(C)$ holds and $Q$ can be executed if $\\FAIL(C)$ holds. Similarly for $\\mtt{try~}C\\mtt{~then~}P\\mtt{~else~}Q$, $C;P$ can be executed if $\\SUCCESS(C)$ holds and $Q$ can be executed if $\\FAIL(C)$ holds.\n\n\\begin{proof}[of Proposition \\ref{prop:slpP}]\nHere, we show that the proposition holds by induction on loop-free programs.\\\\\nBase case.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $S=\\mathcal{R}=\\{\\}$,\\\\\n        It is obvious that for all host graph $G$, $G\\nRightarrow$ such that every condition is a liberal postcondition w.r.t. $c$ and $\\mathcal{R}$, and $\\mrm{false}$ is the strongest among all.\n    \\item If $S=\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$ where $n>0$,\\\\\n        \\begin{tabular}{llcp{10cm}}\n            (a) & $H\\Sat\\SLP(c,\\mathcal{R})$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G. G\\Rightarrow_\\mathcal{R}H \\wedge G\\Sat c$\\\\\n             &&  $\\Leftrightarrow$ & $\\exists G. (G\\Rightarrow_{r_1}H\\vee\\ldots\\vee G\\Rightarrow_{r_n}H)\\wedge G\\Sat c$\\\\\n             &&  $\\Leftrightarrow$ & $(\\exists G. G\\Rightarrow_{r_1}H\\wedge G\\Sat c)\\vee\\ldots\\vee( \\exists G. G\\Rightarrow_{r_n}H\\wedge G\\Sat c)$\\\\\n             && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $H\\Sat\\text{SLP}(c,r_1)\\vee\\ldots\\vee\\text{SLP}(c,r_n)$\n        \\end{tabular}\n\\end{enumerate}\nInductive case. Assume the proposition holds for loop-free programs $C, P$, and $Q$.\n \\vspace{-\\topsep}\\begin{enumerate}\\small\n    \\item If $S=P\\mtt{~or~}Q,$\\\\\n    \\begin{tabular}{llcp{11cm}}\n            & $H\\Sat\\SLP(c,S)$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G. H\\in\\Sem{P\\mtt{~or~}Q}G \\wedge G\\Sat c$\\\\\n             &&  $\\Leftrightarrow$ & $\\exists G. (H\\in\\Sem{P}G \\vee H\\in\\Sem{Q}G)\\wedge G\\Sat c$\\\\\n             &&  $\\Leftrightarrow$ & $(\\exists G. H\\in\\Sem{P}G \\wedge G\\Sat c) \\vee (\\exists G. H\\in\\Sem{Q}G\\wedge G\\Sat c)$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $G\\Sat\\SLP(c,P)\\vee\\SLP(c,Q)$\n        \\end{tabular}\n    \\item If $S=P;Q$,\\\\\n        \\begin{tabular}{llcp{10cm}}\n            & $H\\Sat\\SLP(c,S)$ & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G.~ H\\in\\Sem{P;Q}G \\wedge G\\Sat c$\\\\\n             &&  $\\Leftrightarrow$ & $\\exists G,G'.~ G'\\in\\Sem{P}G \\wedge H\\in\\Sem{Q}G'\\wedge G\\Sat c$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G'.~G'\\Sat\\SLP(c,P) \\wedge H\\in\\Sem{Q}G'$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $H\\Sat\\SLP(\\SLP(c,P),Q)$\n        \\end{tabular}\n    \\item If $S=\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    \\begin{tabular}{llcp{10.7cm}}\n            & \\multicolumn{3}{l}{$H\\Sat\\SLP(c,S)$}\\\\\n            && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G.~ G\\Sat c\\wedge H\\in\\Sem{\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$\\\\\n             &&  $\\Leftrightarrow$ & $\\exists G.~ G\\Sat c\\wedge((G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G) \\vee (G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G))$\\\\\n             && $\\Leftrightarrow$ & $(\\exists G.~G\\Sat c\\wedge\\SUCCESS(C)\\wedge H\\in\\Sem{P}G) \\vee (\\exists G.~ G\\Sat c\\wedge\\FAIL(C)\\wedge H\\in\\Sem{Q}G)$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $G\\Sat\\SLP(c\\wedge\\SUCCESS(C),P)\\vee\\SLP(c\\wedge\\FAIL(C),Q)$\n        \\end{tabular}\n    \\item If $S=\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    \\begin{tabular}{llcp{10.7cm}}\n            & \\multicolumn{3}{l}{$H\\Sat\\SLP(c,S)$}\\\\\n            && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $\\exists G.~ G\\Sat c\\wedge H\\in\\Sem{\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$\\\\\n             && $\\Leftrightarrow$ & $(\\exists G,G'.~G\\Sat c\\wedge G'\\in\\Sem{C}G\\wedge H\\in\\Sem{P}G') \\vee (\\exists G.~ G\\Sat c\\wedge\\FAIL(C)\\wedge H\\in\\Sem{Q}G)$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $(\\exists G'.~G'\\Sat\\SLP(c,C)\\wedge H\\in\\Sem{P}G')\\vee\\SLP(c\\wedge\\FAIL(C),Q)$\\\\\n             &&  $\\myeq{\\Leftrightarrow}{L\\ref{lemma:slpP}}$ & $G\\Sat\\SLP(\\SLP(c,C),P)\\vee\\SLP(c\\wedge\\FAIL(C),Q)$\\qed\n        \\end{tabular}\n\\end{enumerate}\\end{proof}\n\nTo prove the triple $\\{c\\}~P~\\{d\\}$ is partially correct for a graph program $P$, we only need to show that SLP$(c,P)$ implies $d$. However for graph programs $P$ containing a loop, obtaining the assertion SLP$(c,P)$ is not easy. Alternatively, we can create a proof tree (see Definition \\ref{def:prooftree}) with proof rules to show that $\\{c\\}~P~\\{d\\}$ is partially correct. Before we define the proof rules for partial correctness, we define predicate Break which shows relation between a graph program and assertions.\n\n\\Def{Provability; proof tree\\cite{Poskitt13}}{def:prooftree}{\nGiven an proof system $I$, a triple $\\{c\\}~P~\\{d\\}$ is provable in $I$, denoted by $\\vdash_I\\{c\\}~P~\\{d\\}$, if one can construct a \\emph{proof tree} from the axioms and inference rules of $I$ with that triple as the root.\nIf $\\{c\\}~P~\\{d\\}$ is an instance of an axiom $X$ then \n\\[X~\\frac{}{\\{c\\}~P~\\{d\\}}\\]\nis a proof tree, and $\\vdash_I\\{c\\}~P~\\{d\\}$. If $\\{c\\}~P~\\{d\\}$ can be instantiated from the conclusion of an inference rule $Y$, and there are proof trees $T_1,\\ldots ,T_n$ with conclusions that are instances of the $n$ premises of $Y$, then \n\\[Y~\\frac{T_1~~~\\ldots~~~T_n}{\\{c\\}~P~\\{d\\}}\\]\nis a proof tree, and $\\vdash_I\\{c\\}~P~\\{d\\}$.}\n\n\n\\Def{Predicate Break}{def:Break}{\nGiven a graph program $P$ and assertions $c$ and $d$. Break$(c,P,d)$ is the predicate defined by:\n\\[\\small{\\text{Break$(c,P,d)$ holds iff for all derivations $\\langle P, G\\rangle\\rightarrow^*\\langle\\mtt{break},H\\rangle, G\\Sat c$ implies $H\\Sat d$}}.\\]\n}\n\nIntuitively, when Break$(c,P,d)$ holds, the execution of $\\mtt{break}$ that yields to termination of $P!$ will result a graph satisfying $d$.\n\n\\Lemma{lemma:breakno}{\nGiven a graph program $P$ with invariant $c$. If $P$ does not contain the command $\\mtt{break}$, then the following triple holds:\n\\[\\{c\\}~P!~\\{c\\wedge\\text{FAIL}(P)\\}\\]\n}\n\n\\begin{proof}\nIf $P$ does not contain the command $\\mtt{break}$, then the derivation $\\langle P, G\\rangle\\rightarrow^*\\langle\\mtt{break},H\\rangle$ must not exist for any host graphs $G$ and $H$. Hence, Break$(c,P,d)$ is true for any $c$ and $d$. Hence, Break$(c,P,\\mathrm{false})$ must be true. Since $c$ in an invariant, $\\{c\\}~P~\\{c\\}$ is true. If $\\tuple{P!,G}\\rightarrow^*H$ for some host graph $H$, from the semantics of graph programs, $\\tuple{P!,G}\\rightarrow\\tuple{P!,H}\\rightarrow^+\\mtt{fail}$. $H$ must satisfy $c$ because $c$ is the invariant of $P$, and $H$ must satisfy FAIL$(P)$ because $fail\\in\\Sem{P}H$. Hence, the triple holds.\\qed\n\\end{proof}\n\n\\Def{Semantic partial correctness proof rules}{def:semproofrule}{\nThe semantic partial correctness proof rules for core commands, denoted by \\textsf{SEM}, is defined in \\figurename~\\ref{fig:semprules}, where $c, d,$ and $d'$ are any assertions, $r$ is any conditional rule schema, $\\mathcal{R}$ is any set of rule schemata, and $C, P$, and $Q$ are any graph programs.}\n\n\\begin{figure}\n    \\centering\n    \\footnotesize\n\\def\\arraystretch{3}\\tabcolsep=2pt\n~[ruleapp]$_{\\text{slp}}~\\displaystyle\\frac{}{\\{c\\}~r~\\{\\text{SLP}(c,r)\\}}$\\\\$~$\\\\\n~[ruleapp]$_{\\text{wlp}}~\\displaystyle\\frac{}{\\{\\text{WLP}(r,d)\\}~r~\\{d\\}}$\\\\$~$\\\\\n~[ruleset]$~\\displaystyle\\frac{\\{c\\}~r~\\{d\\}\\text{ for each }r\\in\\mathcal{R}}{\\{c\\}~\\mathcal{R}~\\{d\\}}$\\\\$~$\\\\\n~[comp]$\\displaystyle\\frac{\\{c\\}~P~\\{e\\}~~~~\\{e\\}~P~\\{d\\}}{\\{c\\}~P;Q~\\{d\\}}$\n\\\\$~$\\\\\n~[cons]~$\\displaystyle\\frac{c\\text{ implies }c'~~~\\{c'\\}~P~\\{d'\\}~~~d'\\text{ implies }d}{\\{c\\}~P~\\{d\\}}$\\\\$~$\\\\\n{~[if]$~\\displaystyle\\frac{\\{c\\wedge\\text{SUCCESS}(C)\\}~P~\\{d\\}~~~\\{c\\wedge\\text{FAIL}(C)\\}~Q~\\{d\\}}{\\{c\\}~\\mtt{if~}C\\mtt{~then~}P\\mtt{~else~}Q~\\{d\\}}$}\\\\$~$\\\\\n{~[try]$~\\displaystyle\\frac{\\{c\\wedge\\text{SUCCESS}(C)\\}~C;P~\\{d\\}~~~\\{c\\wedge\\text{FAIL}(C)\\}~Q~\\{d\\}}{\\{c\\}~\\mtt{try~}C\\mtt{~then~}P\\mtt{~else~}Q~\\{d\\}}$}\n\\\\$~$\\\\\n~[alap]$~\\displaystyle\\frac{\\{c\\}~P~\\{c\\}~~~~~\\text{Break}(c,P,d)}{\\{c\\}~P!~\\{(c\\wedge\\text{FAIL}(P))\\vee d\\}}$\n    \\caption{Calculus \\textsf{SEM} of semantic partial correctness proof rules}\n    \\label{fig:semprules}\n\\end{figure}\n\nThe inference rule [ruleset] tells us about the application of a set of rule schemata $\\mathcal{R}$. The rule set $\\mathcal{R}$ is applied to a graph by nondeterministically choose an applicable rule schema from the set and apply it to the input graph. Hence, to derive a triple about $\\mathcal{R}$, we need to prove the same triple for each rule schema inside $\\mathcal{R}$.\n\nThe inference rule [comp] is similar to [comp] in traditional programming. In executing $P;Q$, the graph program $Q$ is not executed until after the execution of $P$ has terminated. So to show a triple about $P;Q$, we need to prove a triple about each $P$ and $Q$ and show that they are connected to some midpoint such that the midpoint is satisfied after the execution of $P$ and before the execution of $Q$.\n\nLike in conventional Hoare logic \\cite{Apt19}, the rule [cons] is aimed to strengthen the precondition and weaken the postcondition, or to replace the condition to another condition that semantically equivalent but syntactically different. To show that $c'$ can be strengthened to $c$, we only need to show that $c$ implies $c'$, and to weaken $d'$ to $d$, we need to show that $d'$ implies $d$.\n\nThe assertions SUCCESS and FAIL are needed to prove a triple about if command. Recall that in the execution of $\\mtt{if~}C\\mtt{~then~}P\\mtt{~else~}Q$, the program $C$ is first executed on a copy of $G$. If it terminates and yields a proper graph as a result, $P$ is executed on $G$. If $C$ terminates and results in a fail state, then $Q$ is executed on $G$. \n\nSimilarly, for a triple about try command, we use the two assertions. But for $\\mtt{try~}C\\mtt{~then~}P\\mtt{~else~}Q$, $C$ is not executed on a copy of $G$, but $G$ itself. When the execution of $C$ on $G$ terminates and yields a proper graph, $P$ is executed on the result graph. Hence, the difference with [if] is located in the first of the premises, where we use the sequential composition of $C$ and $P$.\n\nAs in traditional programming, we need an invariant to show a triple about loop $P!$. When we have proven the existence of an invariant for $P$, the invariant will hold after any number of successful executions of $P$. If $P!$ terminates, from the semantics of ``!\" we know that the last execution of $P$ either yields a fail state (see [Loop$_2$] of \\figurename~\\ref{fig:infRule-core}), such that FAIL$(P)$ must hold, or executing the command $\\mtt{break}$ (see [Loop$_3$] of \\figurename~\\ref{fig:infRule-core}). In the former case, it is clear that the invariant and FAIL$(P)$ must hold. Then in the latter case, we use Break$(c,P,d)$ which is defined in Definition \\ref{def:Break}. The triple for loops is then captured by the rule [alap].\n\n\n\\subsection{Syntactic partial correctness calculus}\n\nSection \\ref{sec:sem} introduces us to the semantic of partial correctness calculus. Now that we already have first-order formulas for some properties in graph programming, in this section we define the construction of SLP, SUCCESS, and FAIL in first-order formulas. In addition, we also define the syntactic version of partial correctness proof rules where possible (it will turn out that this is not always can be done). First, we define the first-order formula App$(r)$ which should represent the first-order formula of SUCCESS$(r)$.\n\n\\Def{App$(r)$}{def:appr}{\nGiven a conditional rule schema $r:\\lkr$. The formula App$(r)$ is defined as\n\\[\\text{App}(r)=\\text{Var}(\\text{Spec}(L)\\wedge\\text{Dang}(r)\\wedge{\\Gamma}).\\]\n}\n\nThe definition of Var$(c)$, Spec$(L)$, and Dang$(r)$ for a condition $c$, rule graph $L$, and rule schema $r$, can be found in Definition \\ref{def:var}, \\ref{def:spec}, and \\ref{def:dang} respectively.\n\n\\Lemma{lemma:appr}{\nGiven a conditional rule schema $r:\\lkr,$ and a host graph $G$,\n\\[G\\Sat\\text{SUCCESS}(r) \\text{ if and only if } G\\Sat\\text{App}(r).\\]\n}\n\n\\begin{proof}\n(If).\\\\\n$G\\Sat$App$(r)$ implies $G\\Sat$Var(Spec($L$)), such that from Lemma \\ref{lemma:VarL}, we know that there exists injective morphism $g:L^\\alpha\\rightarrow G$ for some label assignment $\\alpha_L$. Then from Lemma \\ref{lemma:var}, $G\\Sat$App$(r)$ implies $\\RG\\Sat$Dang$(r)$ and $\\RG\\Sat\\Gamma^\\alpha$. From Observation \\ref{obsv:dang}, $\\RG\\Sat$Dang$(r)$ implies $g$ satisfies the dangling condition, and $\\RG\\Sat\\Gamma^\\alpha$ clearly implies $\\Gamma^{\\alpha,g}$ is satisfied by $G$. Hence, from the definition of conditional rule schema application, we know that $G\\Rightarrow_{r,g}H$ for some host graph $H$ such that $G\\Sat$SUCCESS$(r)$.\\\\\n(Only if).\\\\\n$G\\Sat$SUCCESS$(r)$ implies $G\\Rightarrow H$ for some host graph $H$, which implies the existence of injective morphism $g:L^\\alpha\\rightarrow G$ for some label assignment $\\alpha_L$ such that $g$ satisfies the dangling condition and $G\\Sat \\Gamma^{\\alpha,g}$. The existence of the injective morphism implies $G\\Sat$Var(Spec$(L)$) from Lemma \\ref{lemma:VarL}, the satisfaction of the dangling condition implies $\\RG\\Sat$Dang$(r)$, and the $G\\Sat\\Gamma^{\\alpha,g}$ implies $\\RG\\Sat\\Gamma$. Hence, $\\RG\\Sat$Spec$(L)$ since $L^\\alpha\\rightarrow\\RG$ is inclusion (see Proposition \\ref{prop:specL}). Hence, $\\RG\\Sat$Spec$(L)\\wedge$Dang$(r)\\wedge\\Gamma$ so that from Lemma \\ref{lemma:var}, $G\\Sat$App$(r)$.\\qed\n\\end{proof}\n\nDefining a first-order formula for SUCCESS$(r)$ with a rule schema $r$ is easier than defining FO formula for SUCCESS$(P)$ with an arbitrary loop-free program $P$. This is because we need to express properties of the initial graph after checking the existence of derivations. To determine the properties of the initial graph, we introduce the condition Pre$(P,c)$ for a postcondition $c$ and a loop-free program $P$. \nIntuitively, Pre$(P,c)$ expresses the properties of the initial graph such that we can assert the existence of a host graph $H$ such that $H\\Sat c$ and $H\\in\\Sem{P}G$. For an example, if there exists host graphs $G'$ and $H$ for a given host graph $G$ and rule schemata $r_1$ and $r_2$ such that $G\\Rightarrow_{r_1}G'\\Rightarrow_{r_2}H$ and $H\\Sat\\mrm{true}$ (which also means that $G\\Sat\\SUCCESS(P)$), then $G'$ should satisfy Pre$(r_2, \\mrm{true})$ and $G$ should satisfy Pre($r_1$,Pre$(r_2,\\mrm{true})$) such that Pre($r_1$,Pre$(r_2,\\mrm{true})$) can be considered as SUCCESS$(r_1;r_2)$ in first-order formula. For more general cases, see Definition \\ref{def:slpnoloop}. In the definition, $(r^\\vee)^{-1}$ refers to the inverse of the generalised $r$ (see Definition \\ref{def:rvee}).\n\n\\Def{Slp, Success, Fail, Pre of a loop-free program}{def:slpnoloop}{\nGiven a condition $c$ and a loop-free program $S$. The first-order formulas Slp$(c,S)$, Pre$(c,S)$, Success$(S)$, and Fail$(S)$ are defined inductively:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item If $S$ is a set of rule schemata $\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$,\n    \\begin{enumerate}\n        \\item[(a)] Slp$(c,S)=\\begin{cases}\\text{Post}(c,r_1^\\vee)\\vee\\ldots\\vee\\text{Post}(c,r_n^\\vee)&\\text{if~} n>0,\\\\\n        \\mrm{false}&\\text{otherwise}\\end{cases}$\n        \\item[(b)] Pre$(S,c)=\\begin{cases}\\text{Post}(c,(r_1^\\vee)^{-1})\\vee\\ldots\\vee\\text{Post}(c,(r_n^\\vee)^{-1})&\\text{if~} n>0,\\\\\n        \\mrm{false}&\\text{otherwise}\\end{cases}$\n        \\item[(c)] Success$(S)=\\begin{cases}\\text{App}(r_1)\\vee\\ldots\\vee\\text{App}(r_n)&\\text{if~} n>0,\\\\\n        \\mrm{false}&\\text{otherwise}\\end{cases}$\n        \\item[(d)] Fail$(S)=\\begin{cases}\\neg(\\text{App}(r_1)\\vee\\ldots\\vee\\text{App}(r_n))&\\text{if~} n>0,\\\\\n        \\mrm{false}&\\text{otherwise}\\end{cases}$\n    \\end{enumerate}\n    \\item For loop-free programs $C, P,$ and $Q$,\n    \\begin{enumerate}\n    \\item[(i)] If $S=P\\mtt{~or~}Q$, \n        \\begin{enumerate}\n        \\item[(a)] Slp$(c,S)$=Slp$(c,P)\\vee$Slp$(c,Q)$\n        \\item[(b)] Pre$(S,c)$=Pre$(P,c)\\vee$Pre$(Q,c)$\n        \\item[(c)] Success$(S)=$Success$(P)\\vee$Success$(Q)$\n        \\item[(d)] Fail$(S)=$Fail$(P)\\vee$Success$(Q)$\n        \\end{enumerate}\n    \\item[(ii)] If $S=P;Q$,\n        \\begin{enumerate}\n        \\item[(a)] Slp$(c,S)$=Slp(Slp$(c,P),Q$)\n        \\item[(b)] Pre$(S,c)$=Pre($P$,Pre$(Q,c)$)\n        \\item[(c)] Success$(S)=$Pre$(P,\\text{Success}(Q))$\n        \\item[(d)] Fail$(S)=$Fail$(P)\\vee$Pre($P$,Fail$(Q)$)\n        \\end{enumerate}\n    \\item[(iii)] If $S=\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\n        \\begin{enumerate}\n        \\item[(a)] Slp$(c,S)$=Slp$(c\\wedge\\text{Success}(C),P)\\,\\vee\\,$Slp$(c\\wedge\\text{Fail}(C),Q)$\n        \\item[(b)] Pre$(S,c)$=(Success$(C)\\wedge$Pre($P,c))\\,\\vee\\,$(Fail$(C)\\wedge$Pre($Q,c))$\n        \\item[(c)] Success$(S)=($Success$(C)\\wedge$Success($P)\\,\\vee\\,$(Fail$(C)\\wedge$Success($Q))$\n        \\item[(d)] Fail$(S)$=(Success$(C)\\wedge$Fail$(P))\\,\\vee\\,$(Fail$(C)\\wedge$Fail$(Q))$\n        \\end{enumerate}\n    \\item[(iv)] If $S=\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\n        \\begin{enumerate}\n        \\item[(a)] Slp$(c,S)$=Slp$(c\\wedge\\text{Success}(C),C;P)\\,\\vee\\,$Slp$(c\\wedge\\text{Fail}(C),Q)$\n        \\item[(b)] Pre$(S,c)=$Pre($C,\\text{Pre}(P,c))\\,\\vee\\,$(Fail$(C)\\wedge$Pre($Q,c))$\n        \\item[(c)] Success$(S)=$Pre(C,Success($P))\\,\\vee\\,$(Fail$(C)\\wedge$Success($Q))$\n        \\item[(d)] Fail$(S)=$Pre(Fail$(P),C))\\,\\vee\\,$(Fail$(C)\\wedge$Fail$(Q))$\n    \\end{enumerate}\n    \\end{enumerate}\n\\end{enumerate}\n}\n\nFor a precondition $c$ and a loop-free program $S$, Slp$(c,S)$ is basically constructed based on Proposition $\\ref{prop:slpP}$. For Pre$(S,c)$, since we want to know the property of the initial graph based on $c$ that is satisfied by the final graph and $S$, it works similar with constructing a weakest liberal precondition from a given postcondition and a program. Here we use \\cite{Pennemann09} as a reference. However, in the reference the conditional part of $\\mtt{if-then-else}$ command contains an assertion instead of a graph program such that if $C$ is an assertion, following their setting we will have Pre$(C,c)=C\\implies$Pre$(P,c)\\wedge\\neg C\\implies$Pre$(Q,c)$. The difference between assertions and graph programs as condition of a conditional program is, the satisfaction of the assertion on the initial graph implies that $Q$ can not be executed, while in our case, $G\\Sat$Success$(C)$ does not always imply that $Q$ can not be executed. Hence, we change the equation to what we have in the definition above.\n\nSuccess$(S)$ should express the existence of a proper graph as a final result, which means it should express the property of the initial graph based on $S$ and the final graph satisfying $\\mrm{true}$. This is exactly what Pre$(\\mrm{true},S)$ should express. Finally, Fail$(S)$ should express the property of the initial graph where failure is a result of the execution of $S$. Since we can yield failure anywhere is the subprogram of $S$, we need to disjunct all possibilities.\n\n\\Theo{Slp, Pre, Success, and Fail}{theo:FOL}{\nFor all condition $c$ and loop-free program $S$, the following holds:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item[(a)] Slp$(c,S)$ is a strongest liberal postcondition w.r.t. $c$ and $S$\n    \\item[(b)] For all host graph $G$, $G\\Sat$Pre$(S,c)$ if and only if there exists host graph $H$ such that $H\\in\\Sem{S}G$ and $H\\Sat c$\n    \\item[(c)] $G\\Sat$Success$(S)$ if and only if $G\\Sat$SUCCESS$(S)$\n    \\item[(d)] $G\\Sat$Fail$(S)$ if and only if $G\\Sat$FAIL$(S)$\n\\end{enumerate}\n}\n\n\\begin{proof}\nHere, we prove the theorem by induction on loop-free graph programs.\\\\\nBase case.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item For $\\mathcal{R}=\\{\\}$,\\begin{enumerate}\n        \\item It is obvious that for all host graph $G$, $G\\nRightarrow$ such that every condition is a liberal postcondition w.r.t. $c$ and $\\mathcal{R}$, and $\\mrm{false}$ is the strongest among all.\n        \\item Statement (b) is valid because nothing satisfies $\\mrm{false}$.\n        \\item Both $G\\Sat$Success$(\\mathcal{R})$ and $G\\Sat$SUCCESS$(\\mathcal{R})$ always false such that $G\\Sat$Success$(\\mathcal{R})$ iff $G\\Sat$SUCCESS$(\\mathcal{R})$ holds.\n        \\item Similarly, this point holds because both $G\\Sat$Fail$(\\mathcal{R})$ and $G\\Sat$FAIL$(\\mathcal{R})$ always true.\n    \\end{enumerate}\n    \\item If $S=\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$ where $n>0$,\\\\\n        \\begin{tabular}{llcp{10cm}}\n            (a) & $H\\Sat\\SLP(c,\\mathcal{R})$ & $\\myeq{\\Leftrightarrow}{P\\ref{prop:slpP}}$ & $H\\Sat\\text{SLP}(c,r_1)\\vee\\ldots\\vee\\text{SLP}(c,r_n)$\\\\\n             && $\\myeq{\\Leftrightarrow}{T\\ref{theo:slp}}$ & $H\\Sat\\text{Post}(c,r_1^\\vee)\\vee\\ldots\\vee\\text{Post}(c,r_n^\\vee)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (b) & \\multicolumn{3}{l}{$\\exists H. H\\in\\Sem{\\mathcal{R}}G\\wedge H\\Sat c$}\\\\\n             &~~~~~& $\\Leftrightarrow$ & $\\exists H. (G\\Rightarrow_{r_1}H\\vee\\ldots\\vee G\\Rightarrow_{r_n}H)\\wedge H\\Sat c$ \\\\\n             && $\\Leftrightarrow$ & $(\\exists H. G\\Rightarrow_{r_1}H\\wedge H\\Sat c)\\vee\\ldots\\vee (\\exists H.G\\Rightarrow_{r_n}H\\wedge H\\Sat c$)\\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:generalisedrPO}}$ & $(\\exists H. G\\Rightarrow_{r_1^\\vee}H\\wedge H\\Sat c)\\vee\\ldots\\vee (\\exists H.G\\Rightarrow_{r_n^\\vee}H\\wedge H\\Sat c$)\\\\\n             && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:inverse}}$ & $(\\exists H. H\\Rightarrow_{(r_1^\\vee)^{-1}}H\\wedge H\\Sat c)\\vee\\ldots\\vee (\\exists H.H\\Rightarrow_{(r_n^\\vee)^{-1}}G\\wedge H\\Sat c$)\\\\\n             && $\\myeq{\\Leftrightarrow}{T\\ref{theo:slp}}$ & $G\\Sat\\text{Post}(c,(r_1^\\vee)^{-1})\\vee\\ldots\\vee \\text{Post}(c,(r_n^\\vee)^{-1})$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (c) & $H\\Sat\\SUCCESS(\\mathcal{R})$&$\\Leftrightarrow$&$\\exists H. H\\in\\Sem{\\mathcal{R}}G$\\\\\n             && $\\Leftrightarrow$ & $\\exists H. G\\Rightarrow_{r_1}H\\vee\\ldots\\vee G\\Rightarrow_{r_n}H$ \\\\\n             && $\\Leftrightarrow$ & $(\\exists H. G\\Rightarrow_{r_1}H)\\vee\\ldots\\vee (\\exists H.G\\Rightarrow_{r_n}H$)\\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE}}$ & $G\\Sat\\SUCCESS(r_1)\\vee\\ldots\\vee \\SUCCESS(r_n)$\\\\\n             && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:appr}}$& $G\\Sat\\text{App}(r_1)\\vee\\ldots\\vee \\text{App}(r_n)$\\\\\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (d) & $G\\Sat\\FAIL(\\mathcal{R})$&$\\Leftrightarrow$&$\\text{fail}\\in\\Sem{\\mathcal{R}}G$\\\\\n             && $\\Leftrightarrow$ & $(\\neg\\exists H. G\\Rightarrow_{r_1}H)\\wedge\\ldots\\wedge\\ (\\neg\\exists H.G\\Rightarrow_{r_n}H$)\\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE}}$ & $G\\Sat\\neg(\\SUCCESS(r_1)\\vee\\ldots\\wedge \\SUCCESS(r_n))$\\\\\n             && $\\myeq{\\Leftrightarrow}{L\\ref{lemma:appr}}$& $G\\Sat\\neg(\\text{App}(r_1)\\vee\\ldots\\vee \\text{App}(r_n))$\n        \\end{tabular}\n\\end{enumerate}\nInductive case. Assume (a), (b), (c), and (d) hold for loop-free programs $C, P$, and $Q$.\n \\vspace{-\\topsep}\\begin{enumerate}\\small\n    \\item If $S=P\\mtt{~or~}Q,$\\\\\n    \\begin{tabular}{llcp{11cm}}\n            (a) & $H\\Sat\\SLP(c,S)$ & $\\myeq{\\Leftrightarrow}{P\\ref{prop:slpP}}$ & $G\\Sat\\SLP(c,P)\\vee\\SLP(c,Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Slp}(c,P)\\vee\\text{Slp}(c,Q)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{11cm}}\n             (b) & {$\\exists H. H\\in\\Sem{S}G\\wedge H\\Sat c$} & $\\Leftrightarrow$ & $\\exists H. (H\\in\\Sem{P}G \\vee H\\in\\Sem{Q}G)\\wedge H\\Sat c$ \\\\\n             && $\\Leftrightarrow$ & $(\\exists H. H\\in\\Sem{P}G\\wedge H\\Sat c)\\vee(\\exists H.H\\in\\Sem{Q}G\\wedge H\\Sat c$)\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Pre}(P,c)\\vee\\text{Pre}(Q,c)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (c) & $G\\Sat\\SUCCESS(S)$\n             & $\\Leftrightarrow$ & $\\exists H. H\\in\\Sem{P\\mtt{~or~}Q}G$\\\\\n             && $\\Leftrightarrow$ & $\\exists H. H\\in\\Sem{P}G \\vee H\\in\\Sem{Q}G$ \\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE}}$ & $G\\Sat\\SUCCESS(P)\\vee\\SUCCESS(Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Success}(P)\\vee\\text{Success}(Q)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (d) & $G\\Sat\\FAIL(S)$\n             & $\\Leftrightarrow$ & $\\text{fail}\\in\\Sem{P\\mtt{~or~}Q}G$\\\\\n             && $\\Leftrightarrow$ & $\\text{fail}\\in\\Sem{P}G \\vee \\text{fail}\\in\\Sem{Q}G$ \\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assFE}}$ & $G\\Sat\\FAIL(P)\\vee\\FAIL(Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Fail}(P)\\vee\\text{Fail}(Q)$\n        \\end{tabular}\n    \\item If $S=P;Q$,\\\\\n        \\begin{tabular}{llcp{10cm}}\n            (a) & $H\\Sat\\SLP(c,S)$ & $\\myeq{\\Leftrightarrow}{P\\ref{prop:slpP}}$ & $H\\Sat\\SLP(\\SLP(c,P),Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $H\\Sat\\text{Slp}(\\text{Slp}(c,P),Q)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (b) & {$\\exists H. H\\in\\Sem{S}G\\wedge H\\Sat c$}& $\\Leftrightarrow$ & $\\exists H,G'.~G'\\in\\Sem{P}G \\wedge H\\in\\Sem{Q}G' \\wedge H\\Sat c$ \\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $\\exists G'.~ G'\\Sat\\text{Pre}(Q,c)\\wedge G'\\in\\Sem{P}G$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Pre}(P,\\text{Pre}(Q,c))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (c) & $G\\Sat\\SUCCESS(S)$ & $\\Leftrightarrow$ & $\\exists H. H\\in\\Sem{P;Q}G$\\\\\n             && $\\Leftrightarrow$ & $\\exists H,G'.~G'\\in\\Sem{P}G \\wedge H\\in\\Sem{Q}G'$ \\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE}}$ & $\\exists G'.~ G'\\Sat\\text{SUCCESS}(Q)\\wedge G'\\in\\Sem{P}G$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $\\exists G'.~ G'\\Sat\\text{Success}(Q)\\wedge G'\\in\\Sem{P}G$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Pre}(P,\\text{Success}(Q))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10cm}}\n             (d) & $G\\Sat\\FAIL(S)$ & $\\Leftrightarrow$ & $\\text{fail}\\in\\Sem{P;Q}G$\\\\\n             && $\\Leftrightarrow$ & $\\text{fail}\\in\\Sem{P}G \\vee \\exists H.~H\\in\\Sem{P}G \\wedge \\text{fail}\\in\\Sem{Q}H$ \\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assFE}}$ & $G\\Sat\\FAIL(P) \\vee \\exists H.~H\\in\\Sem{P}G \\wedge H\\Sat\\FAIL(Q)$ \\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Fail}(P) \\vee \\text{Pre}(P,\\text{Fail}(Q))$ \n        \\end{tabular}\n    \\item If $S=\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    \\begin{tabular}{llcp{10.7cm}}\n            (a) & \\multicolumn{3}{l}{$H\\Sat\\SLP(c,S)$}\\\\\n            && $\\myeq{\\Leftrightarrow}{P\\ref{prop:slpP}}$ &  $G\\Sat\\SLP(c\\wedge\\SUCCESS(C),P)\\vee\\SLP(c\\wedge\\FAIL(C),Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Slp}(c\\wedge\\text{Success}(C),P)\\vee\\text{SLP}(c\\wedge\\text{Fail}(C),Q)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (b) & \\multicolumn{3}{l}{$\\exists H. H\\in\\Sem{S}G\\wedge H\\Sat c$}\\\\\n             && $\\Leftrightarrow$ & $\\exists H.~((G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G) \\vee (G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G))\\wedge H\\Sat c$ \\\\\n             && $\\Leftrightarrow$ &$(\\exists H.~G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G\\wedge H\\Sat c)$\\\\\n             &&& $\\vee (\\exists H.~G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G))\\wedge H\\Sat c)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat(\\text{Success}(C)\\wedge\\text{Pre}(P,c))\\vee(\\text{Fail}(C)\\wedge\\text{Pre}(Q,c))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (c) & \\multicolumn{3}{l}{$G\\Sat\\SUCCESS(S)$}\\\\\n             && $\\Leftrightarrow$ & \n             $\\exists H. H\\in\\Sem{S}G$\\\\\n             && $\\Leftrightarrow$ & $\\exists H.~(G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G) \\vee (G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G)$ \\\\\n             && $\\Leftrightarrow$ &$(\\exists H.~G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G)\\vee (\\exists H.~G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G)))$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat(\\text{Success}(C)\\wedge\\text{Success}(P))\\vee(\\text{Fail}(C)\\wedge\\text{Success}(Q))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (d) & \\multicolumn{3}{l}{$G\\Sat\\FAIL(S)$}\\\\\n             && $\\Leftrightarrow$ & \n             $\\text{fail}\\in\\Sem{S}G$\\\\\n             && $\\Leftrightarrow$ & $(G\\Sat\\SUCCESS(C)\\wedge \\text{fail}\\in\\Sem{P}G) \\vee (G\\Sat\\FAIL(C)\\wedge \\text{fail}\\in\\Sem{Q}G)$ \\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat(\\text{Success}(C)\\wedge\\text{Fail}(P))\\vee(\\text{Fail}(C)\\wedge\\text{Fail}(Q))$\n        \\end{tabular}\n    \\item If $S=\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    \\begin{tabular}{llcp{10.7cm}}\n            (a) & \\multicolumn{3}{l}{$H\\Sat\\SLP(c,S)$}\\\\\n            && $\\myeq{\\Leftrightarrow}{P\\ref{prop:slpP}}$ &  $G\\Sat\\SLP(\\SLP(c,C),P)\\vee\\SLP(c\\wedge\\FAIL(C),Q)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Slp}(\\text{Slp}(c,C),P)\\vee\\text{Slp}(c\\wedge\\text{Fail}(C),Q)$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (b) & \\multicolumn{3}{l}{$\\exists H. H\\in\\Sem{S}G\\wedge H\\Sat c$}\\\\\n             && $\\Leftrightarrow$ & $(\\exists H,G'.~H\\Sat c\\wedge G'\\in\\Sem{C}G\\wedge H\\in\\Sem{P}G') \\vee (\\exists H.~ H\\Sat c\\wedge\\FAIL(C)\\wedge H\\in\\Sem{Q}G)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ &$(\\exists G'.~G'\\Sat\\text{Pre}(P,c)\\wedge G'\\in\\Sem{C}G) \\vee (\\exists H.~G\\Sat\\text{Fail}(C)\\wedge H\\in\\Sem{Q}G))\\wedge H\\Sat c)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Pre}(C,\\text{Pre}(P,c))\\vee(\\text{Fail}(C)\\wedge\\text{Pre}(Q,c))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (c) & \\multicolumn{3}{l}{$G\\Sat\\SUCCESS(S)$}\\\\\n             && $\\Leftrightarrow$ & \n             $\\exists H. H\\in\\Sem{S}G$\\\\\n             && $\\Leftrightarrow$ & $(\\exists H,G'.~G'\\in\\Sem{C}G\\wedge H\\in\\Sem{P}G') \\vee (\\exists H.~ \\FAIL(C)\\wedge H\\in\\Sem{Q}G)$\\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE}}$ &$(\\exists G'.~G'\\in\\Sem{C}G\\wedge G'\\Sat\\SUCCESS(P)) \\vee (\\exists H.~ \\FAIL(C)\\wedge H\\in\\Sem{Q}G)$\\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat\\text{Pre}(C,\\text{Success}(P))\\vee(\\text{Fail}(C)\\wedge\\text{Success}(Q))$\n        \\end{tabular}\n        \\begin{tabular}{llcp{10.7cm}}\n             (d) & \\multicolumn{3}{l}{$G\\Sat\\FAIL(S)$}\\\\\n             && $\\Leftrightarrow$ & \n             $\\text{fail}\\in\\Sem{S}G$\\\\\n             && $\\Leftrightarrow$ & $(\\exists G'.~G'\\in\\Sem{C}G\\wedge\\text{fail}\\in\\Sem{P}G)\\vee (G\\Sat\\FAIL(C)\\wedge \\text{fail}\\in\\Sem{Q}G)$ \\\\\n             && $\\myeq{\\Leftrightarrow}{D\\ref{def:assSE},\\ref{def:assFE}}$ & $G\\Sat(\\SUCCESS(C)\\wedge\\FAIL(P))\\vee(\\FAIL(C)\\wedge \\FAIL(Q))$ \\\\\n             && $\\myeq{\\Leftrightarrow}{Ind.}$ & $G\\Sat(\\text{Success}(C)\\wedge\\text{Fail}(P))\\vee(\\text{Fail}(C)\\wedge\\text{Fail}(Q))$\\qed\n        \\end{tabular}\n\\end{enumerate}\\end{proof}\n\nFor any loop-free program $P$, we now can find the first order formula of SLP, SUCCESS, and FAIL. However, constructing SLP and SUCCESS of a loop is a challenging task because a loop may diverge. However, constructing a FO formula for FAIL of a graph program with loops is not as challenging if we only consider some forms of graph programs. In \\cite{Bak15a}, Bak introduced a class of commands that cannot fail. Hence, we can always conclude that Fail$(P)=\\mrm{false}$ if $P$ is a command that cannot fail. Here, we introduce the class of non-failing commands.\n\n\\Def{Non-failing commands}{def:nofail}{\nThe class of \\emph{non-failing commands} is inductively defined as follows:\n\n\\noindent Base case:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $\\mtt{break}$ and $\\mtt{skip}$ are non-failing commands\n    \\item Every call of a rule schema with the empty graph as its left-hand graph is a non-failing command\n    \\item Every rule set call $\\{r_1,\\ldots,r_n\\}$ for $n\\geq 1$ where each $r_i$ has the empty graph as its left-hand graph, is a non-failing command\n    \\item Every command P! is a non-failing command\n\\end{enumerate}\n\\noindent Inductive case:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item $P;Q$ is a non-failing command if $P$ and $Q$ are non-failing commands\n    \\item $\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$ is a non-failing command if $P$ and $Q$ are non-failing commands\n    \\item $\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$ is a non-failing command if $P$ and $Q$ are non-failing commands\n\\end{enumerate}\n}\n\nRecall the inference rule [alap] of \\textsf{SEM}. To obtain a triple $\\{c\\}~P!~\\{d\\}$ for some precondition $c$, postcondition $d$, and a graph program $P!$, we need to find Fail$(P)$. We now can construct Fail($P$) if $P$ is a loo-free program as in Definition \\ref{def:slpnoloop}, or if $P$ is a non-failing command. \n\nNow, let us consider $P$ in the form $C;Q$. For any host graph $G$, $\\text{fail}\\in\\Sem{C;Q}G$ iff $\\text{fail}\\in\\Sem{C}G$ or $H\\in\\Sem{C}G\\wedge\\text{fail}\\in\\Sem{Q}H$ for some host graph $H$, which means $G\\Sat \\FAIL(C)\\vee(\\SUCCESS(C)\\wedge\\FAIL(Q))$. We can construct both Fail$(C)$ and Success$(C)$ if $C$ is a loop-free program, and we can construct Fail$(Q)$ if $Q$ is a loop-free program or a non-failing command. Here, we introduce the class of \\textit{iteration commands} which is the class of commands where we can obtain Fail of the commands.\n\n\\Def{Iteration commands}{def:iteration}{\nThe class of iteration commands is inductively defined as follows:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item Every loop-free program is an iteration command\n    \\item Every non-failing command is an iteration command\n    \\item A command of the form $C;P$ is an iteration command if $C$ is a loop-free program and $P$ is an iteration command \n\\end{enumerate}\n}\n\nIf $S$ is a loop-free program, we can construct Fail$(S)$ as defined in Definition \\ref{def:slpnoloop}. Meanwhile, if $S$ is a non-failing command, there is no graph $G$ such that fail$\\in\\Sem{S}G$ such that we can conclude that Fail$(S)\\equiv\\mrm{false}$. Finally, if $S$ is in the form of $C;P$ for a loop-free program $C$ and a non-failing program $P$, fail$\\in\\Sem{S}G$ for a graph $G$ only if fail$\\in\\Sem{C}G$ (because $P$ cannot fail), so that Fail$(S)\\equiv$fail$(C)$.\n\n\\begin{definition}[Fail of iteration commands]\\label{def:Failit}\\normalfont\nLet Fail$_{\\text{lf}}(C)$ denotes the formula Fail$(C)$ for a loop-free program $C$ as defined in Definition \\ref{def:slpnoloop}. For any iteration command $S$,\\\\\n\\footnotesize{Fail$(S)=\\begin{cases}\n\\mrm{false} & \\text{if $S$ is a non-failing command}\\\\\n\\text{Fail}_{\\text{lf}}(S) & \\text{if $S$ is a loop-free program}\\\\\n\\text{Fail}(C) & {\\text{if $S=C;P$ for a loop-free program $C$, a non-failing program $P$}}\\\\\n\\end{cases}$\\qed}\n\\end{definition}\n\n\\begin{theorem}\\normalfont\\label{theo:nofail}\nGiven an iteration command $S$. Then,\n\\[\\text{$G\\Sat\\text{Fail}(S)$ if and only if $G\\Sat\\text{FAIL}(S)$}.\\]\n\\end{theorem}\n\n\\begin{proof}\nHere, we prove the theorem case by case.\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item It is obvious that if $S$ is a non-failing command, then for any host graph $G$, $\\text{fail}\\notin\\Sem{S}G$. Hence, there is no graph satisfying FAIL$(S)$ such that $G\\Sat\\mrm{false}$ iff $G\\Sat\\FAIL(S)$ holds.\n    \\item If $S$ is a loop-free program, $G\\Sat\\text{Fail}(S)$ iff $G\\Sat\\FAIL(S)$ holds based on Theorem \\ref{theo:FOL}.\n    \\item If $S$ is in the form $C;P$ for a loop-free program $C$ and non-failing command $P$, then\\\\\n    \\begin{tabular}{lcl}\n    $G\\Sat\\FAIL(C;P)$ & iff & fail$\\in\\Sem{C;P}G$ \\\\\n     & iff & fail$\\in\\Sem{C}G \\vee \\exists G'. G'\\in\\Sem{C}G\\wedge$ fail$\\in\\Sem{P}G'$\\\\\n     & iff & fail$\\in\\Sem{C}G$\\\\\n     & iff & $G\\Sat\\FAIL(C)$\\\\\n     & iff & $G\\Sat\\text{Fail}(C)$\n\\end{tabular}\n\\end{enumerate}\n\\end{proof}\n\nNow let us consider the proof calculus \\textsf{SEM}. There is the assertion $\\SUCCESS(C)$ and $\\FAIL(C)$ where $C$ is the condition of a branching statement, and FAIL$(S)$ for a loop body $S$. Since we are only able to construct Success$(C)$ for a loop-free program $C$ and FAIL$(S)$ for an iteration command $S$, we do not define the syntactic version for arbitrary graph programs. Hence, we require a loop-free program as the condition of every branching statement and an iteration command as every loop body. For the axiom [ruleapp]$_\\text{wlp}$, we follow the construction in \\cite{HP09} where a weakest liberal precondition can be constructed using the construction of Slp.\n\n\\Def{Control programs}{def:controlprogram}{\nA \\emph{control command} is a command where the condition of every branching command is loop-free and every loop body is an iteration command. Similarly, a graph program is a \\emph{control program} if all its command are control commands.}\n\n\\begin{lemma}\\label{lemma:wlpr}\\normalfont\nGiven a conditional rule schema $r$ and a closed first-order formula $d$. Let Wlp$(r,d)=\\neg$Slp$(\\neg d,r^{-1})$. Then for all host graphs $G$,\\\\\n\\[G\\Sat \\text{Wlp}(r,d) \\text{ if and only if } G\\Sat\\text{WLP}(r,d).\\]\n\\end{lemma}\n\n\\begin{proof}$~$\\\\\n\\begin{tabular}{lclr}\n     $G\\Sat\\text{Wlp}(r,d)$ & iff & $G\\Sat\\neg\\text{Post}(\\neg d,(r^\\vee)^{-1})$ &\\\\\n     & iff & $\\neg(\\exists H,g,g^*. H\\Rightarrow_{(r^\\vee)^{-1},g^*,g}G \\wedge H\\Sat \\neg d)$ & (Lemma \\ref{lemma:slp})\\\\\n     & iff & $\\neg(\\exists H,g,g^*. G\\Rightarrow_{(r^\\vee),g,g^*}H \\wedge H\\Sat \\neg d)$ & (Lemma \\ref{lemma:inverse})\\\\\n     & iff & $\\neg(\\exists H. G\\Rightarrow_{r}H \\wedge H\\Sat \\neg d)$ & (Def. \\ref{def:generalisedrPO})\\\\\n     & iff & $\\forall H. G\\Rightarrow_{r}H \\text{ implies } H\\Sat d)$ & (Def. implication)\\\\\n     & iff & $G\\Sat$WLP$(r,d)$ & (Lemma \\ref{lemma:slpP})\\qed\n\\end{tabular}\n\\end{proof}\n\nNow we know the FO formula for WLP$(r,c)$, SLP$(c,r)$, also SUCCESS$(P)$ and FAIL$(P)$ for some form of $P$. Finally, we define a syntactic partial correctness proof for control programs.\n\n\\begin{figure}\n    \\centering\n    \\footnotesize\n\\def\\arraystretch{3}\\tabcolsep=2pt\n~[ruleapp]$_{\\text{slp}}~\\displaystyle\\frac{}{\\{c\\}~r~\\{\\text{Slp}(c,r)\\}}$\\\\$~$\\\\\n~[ruleapp]$_{\\text{wlp}}~\\displaystyle\\frac{}{\\{\\neg \\text{Slp}(\\neg d,r^{-1})\\}~r~\\{d\\}}$\\\\$~$\\\\\n~[ruleset]$~\\displaystyle\\frac{\\{c\\}~r~\\{d\\}\\text{ for each }r\\in\\mathcal{R}}{\\{c\\}~\\mathcal{R}~\\{d\\}}$\\\\$~$\\\\\n~[comp]$\\displaystyle\\frac{\\{c\\}~P~\\{e\\}~~~~\\{e\\}~P~\\{d\\}}{\\{c\\}~P;Q~\\{d\\}}$\n\\\\$~$\\\\\n~[cons]~$\\displaystyle\\frac{c\\text{ implies }c'~~~\\{c'\\}~P~\\{d'\\}~~~d'\\text{ implies }d}{\\{c\\}~P~\\{d\\}}$\\\\$~$\\\\\n{~[if]$~\\displaystyle\\frac{\\{c\\wedge\\text{Success}(C)\\}~P~\\{d\\}~~~\\{c\\wedge\\text{Fail}(C)\\}~Q~\\{d\\}}{\\{c\\}~\\mtt{if~}C\\mtt{~then~}P\\mtt{~else~}Q~\\{d\\}}$}\\\\$~$\\\\\n{~[try]$~\\displaystyle\\frac{\\{c\\wedge\\text{Success}(C)\\}~C;P~\\{d\\}~~~\\{c\\wedge\\text{Fail}(C)\\}~Q~\\{d\\}}{\\{c\\}~\\mtt{try~}C\\mtt{~then~}P\\mtt{~else~}Q~\\{d\\}}$}\n\\\\$~$\\\\\n~[alap]$~\\displaystyle\\frac{\\{c\\}~S~\\{c\\}~~~~~~~~~\\text{Break}(c,S,d)}{\\{c\\}~S!~\\{(c\\wedge\\text{Fail}(S))\\vee d\\}}$\n    \\caption{Calculus \\textsf{SYN} of syntactic partial correctness proof rules}\n    \\label{fig:synprules}\n\\end{figure}\n\n\\Def{Syntactic partial correctness proof rules}{def:synproofrule}{\nThe syntactic partial correctness proof rules, denoted by \\textsf{SYN}, is defined in \\figurename~\\ref{fig:synprules}, where $c, d,$ and $d'$ are any conditions, $r$ is any conditional rule schema, $\\mathcal{R}$ is any set of rule schemata, $C$ is any loop-free program, $P$ and $Q$ are any control commands, and $S$ is any iteration command. Outside a loop, we treat the command $\\mtt{break}$ as a $\\mtt{skip}$.}\n\nIn the following section, we give an example of graph program verification using the calculus \\textsf{SYN} we define above.\n \n\\section{Soundness and completeness of proof calculi}\n\\label{sec:completeness}\nIn this section, we show that our proof calculi are sound, in the sense that if some triple can be proven in a calculus, then the triple must be partially correct. In addition, we also show the relative completeness of the proof calculi. \n\n\\subsection{Soundness}\n\nTo proof the soundness, we use structural induction on proof tree as defined in Definition \\ref{def:indprooftree}.\n\n\\begin{definition}[Structural induction on proof trees]\\normalfont\\label{def:indprooftree}\nGiven a property \\textit{Prop}. To prove that \\textit{Prop} holds for all proof trees (that are created from some proof rules) by \\textit{structural induction on proof tree} is done by:\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item Show that \\textit{Prop} holds for each axiom in the proof rules\n    \\item Assuming that \\textit{Prop} holds for each premise $T$ of inference rules in the proof rules, show that \\textit{Prop} holds for the conclusion of each inference rules in the proof rules.\\qed\n\\end{enumerate}\n\\end{definition}\n\nWhen we prove that a triple $\\{c\\}P\\{d\\}$ for assertions $c, d$ and a graph program $P$ is partially correct by showing that SLP$(c,P)$ implies $d$, it is obviously sound because of the definition of a strongest liberal postcondition itself. Then if $c$ and $d$ are first-order formulas and $P$ is a loop-free program, showing that Slp$(c,P)$ implies $d$ implies that $\\{c\\}P\\{d\\}$ is partially correct from Theorem \\ref{theo:FOL}. Then we also need to prove the soundness of proof calculus as summarised in \\figurename~\\ref{fig:semprules} and \\figurename~\\ref{fig:synprules}. \n\n\\Theo{Soundness of \\textsf{SEM}}{theo:semsound}{\nGiven a graph program $P$ and assertions $c,d$. Then,\n\\[\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{d\\} \\text{~implies~} \\vDash \\{c\\}~P~\\{d\\}.\\]\n}\n\n\\begin{proof}\nTo prove the soundness, we show that the implication holds for each axiom and inference rule in the proof rule w.r.t. the semantics of graph programs by structural induction on proof trees.\n\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item Base case : \n    \\begin{enumerate}\n        \\item[(a)] [ruleapp]$_\\text{slp}$. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~r~\\{d\\}$ for a (conditional) rule schema $r$ where for all graphs $H$, $H\\Sat d$ iff $H\\Sat\\SLP(c,r)$. Suppose that $G\\Sat c$. From Definition \\ref{def:slp}, $G\\Rightarrow_rH$ implies $H\\Sat d$ so that $\\vDash\\{c\\}~P~\\{d\\}$. \n    \\item[(b)] [ruleapp]$_\\text{slp}$. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~r~\\{d\\}$ for a (conditional) rule schema $r$ where for all graphs $G$, $G\\Sat c$ iff $H\\Sat\\text{WLP}(r,c)$. Suppose that $G\\Sat c$. From Definition \\ref{def:wlpP}, $G\\Rightarrow_rH$ implies $H\\Sat d$ so that $\\vDash\\{c\\}~P~\\{d\\}$. \n    \\end{enumerate}\n    %\n    \\item Inductive case.\\\\\n    Assume that \\textit{Prop} holds for each premise of inference rules in Definition \\ref{def:semproofrule} for a set of rule schemata $\\mathcal{R}$, assertions $c,d,e,c',d',inv$, host graphs $G,G',H,H'$, and graph programs $C,P,Q$.\n    \\begin{enumerate}\n        \\item[(a)] [ruleset]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~\\mathcal{R}~\\{d\\}$ and $G\\Sat c$. Since we can have a proof tree where $\\{c\\}~\\mathcal{R}~\\{d\\}$ is the root, then $\\vdash_{\\mathsf{SEM}}\\{c\\}~r~\\{d\\}$ for all $r\\in\\mathcal{R}$. From point 1, this means that $\\vDash\\{c\\}~r~\\{d\\}$ for all $r\\in\\mathcal{R}$. From the semantics of graph programs, $H\\in\\Sem{R}G$ iff $H\\in\\Sem{r}G$ for some $r\\in\\mathcal{R}$. Since for any $r\\in\\mathcal{R}$, $H\\in\\Sem{r}G$ implies $H\\Sat d,$ $H\\in\\Sem{\\mathcal{R}}G$ implies $H\\Sat d$ as well so that $\\vDash\\{c\\}~\\mathcal{R}~\\{d\\}$.\n        \n        \\item[(b)] [comp]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~P;Q~\\{d\\}$ and $G\\Sat c$. $\\vdash_{\\mathsf{SEM}}\\{c\\}~P;Q~\\{d\\}$, implies $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{e\\}$ and $\\vdash_{\\mathsf{SEM}}\\{e\\}~Q~\\{d\\}$. From the semantic of graph programs, $H\\in\\Sem{P;Q}G$ iff there exists $G'$ such that $G'\\in\\Sem{P}G$ and $H\\in\\Sem{Q}G'$. In addition to the assumption, $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{e\\}$ implies $G'\\Sat e$, and $\\vdash_{\\mathsf{SEM}}\\{e\\}~Q~\\{d\\}$ implies $H\\Sat d$ so that $\\vDash \\{c\\}~P;Q~\\{d\\}$.\n        \n        \\item[(c)] [cons]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{d\\}$ and $G\\Sat c$. From the inference rule, we know that $\\vdash \\{c'\\}~P~\\{d'\\}$, $c$ implies $c'$ (so that $G\\Sat c')$, and $d'$ implies $d$. From $\\vdash \\{c'\\}~P~\\{d'\\}$, we get that for all host graphs $H$, $H\\in\\Sem{P}G$ implies $H\\Sat d'$ so that $H\\Sat d$. Hence, $\\vDash \\{c\\}~P~\\{d\\}$.\n    \n        \\item[(d)] [if]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$ and $G\\Sat c$. From $\\vdash_{\\mathsf{SEM}}\\{c\\}~\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$, we get $\\vdash_{\\mathsf{SEM}}\\{c\\wedge\\SUCCESS(C)\\}~P~\\{d\\}$ and $\\vdash_{\\mathsf{SEM}}\\{c\\wedge\\FAIL(C)\\}~Q~\\{d\\}$. From the former we know that for all host graphs $H$, if $G\\Sat\\SUCCESS(C)$ and $H\\in\\Sem{P}G$ then $H\\Sat d$, while from the latter we know that for all host graphs $H$, if $G\\Sat\\FAIL(C)$ and $H\\in\\Sem{Q}G$ then $H\\Sat d$. Recall that from the semantic of graph programs, $H\\in\\Sem{\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$ iff $G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G$ or $G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G$. Since both $G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G$ and $G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G$ implies $H\\Sat d$, $H\\in\\Sem{\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$ implies $H\\Sat d$ such that $\\vDash \\{c\\}~\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$.\n    \n        \\item[(e)] [try]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$ and $G\\Sat c$. $\\vdash_{\\mathsf{SEM}}\\{c\\}~\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$ implies $\\vdash_{\\mathsf{SEM}}\\{c\\wedge\\SUCCESS(C)\\}~C;P~\\{d\\}$ and $\\vdash_{\\mathsf{SEM}}\\{c\\wedge\\FAIL(C)\\}~Q~\\{d\\}$. From the former we know that for all host graphs $H$, if $G\\Sat\\SUCCESS(C)$ and $H\\in\\Sem{C;P}G$ then $H\\Sat d$, while from the latter we know that for all host graphs $H$, if $G\\Sat\\FAIL(C)$ and $H\\in\\Sem{Q}G$ then $H\\Sat d$. Recall that from the semantic of graph programs, $H\\in\\Sem{\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$ iff $G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{C;P}G$ or $G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G$. Since both $G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{C;P}G$ and $G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G$ implies $H\\Sat d$, $H\\in\\Sem{\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G$ implies $H\\Sat d$ such that $\\vDash \\{c\\}~\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q~\\{d\\}$.\n        \n         \\item[(f)] [alap]. Suppose that $\\vdash_{\\mathsf{SEM}}\\{c\\}~P!~\\{d\\}$ and $G\\Sat c$. From $\\vdash_{\\mathsf{SEM}}\\{c\\}~P!~\\{d\\}$, we know that $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{c\\}$ and Break$(c,P,d)$ holds. From $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{c\\}$, we get that for all host graph $H$, $H\\in\\Sem{P}G$ implies $H\\Sat c$, while from Definition \\ref{def:Break} and the true value of Break$(c,P,d)$ we know that for all hsot graphs $H$, $G\\Sat c$ and $\\tuple{P,G}\\rightarrow^*\\tuple{\\mtt{break;H}}$ implies $H\\Sat d$.\n         From the semantic of graph programs, $H\\in\\Sem{P!}G$ iff there exist derivation $\\tuple{P,G}\\rightarrow^*\\tuple{\\mtt{break;H}}$ or $\\tuple{P!,G}\\rightarrow^*\\tuple{P!,H}$ and $\\tuple{P!,H}\\rightarrow^+\\mtt{fail}$. The first case yields $H\\Sat d$ because of Break$(c,P,d)$. Note that $\\tuple{P!,G}\\rightarrow^*\\tuple{P!,H}$ is done by having (probably) multiple execution of $P$ on host graphs, so that from $\\vdash_{\\mathsf{SEM}}\\{c\\}~P~\\{c\\}$ we know that $H\\Sat c$. Then since $\\tuple{P!,H}\\rightarrow^+\\mtt{fail}$, $H\\Sat\\FAIL(P)$ so that $H\\Sat c\\wedge\\FAIL(C)$. Hence, $H\\in\\Sem{P!}G$ implies $H\\Sat d\\vee(c\\wedge\\FAIL(P))$ so that $\\vDash\\{c\\}~P!~\\{d\\}$.\\qed\n    \\end{enumerate}\n\\end{enumerate}\n\\end{proof}\n\n\\Theo{Soundness of \\textsf{SYN}}{theo:synsound}{\nLet $P$ be a restricted graph program i.e. graph programs where for every subprogram in the form $\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$, $\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$, or $C!$, $C$ is a loop-free program. Let also $c$ and $d$ be first-order formulas. Then,\n\\[\\vdash_{\\mathsf{SYN}}\\{c\\}~P~\\{d\\} \\text{~implies~} \\vDash \\{c\\}~P~\\{d\\}.\\]\n}\n\n\\begin{proof}\nThe soundness of [ruleapp]$_\\text{slp}$ follows from Theorem \\ref{theo:slp} and Theorem \\ref{theo:semsound}, while the soundness of [ruleapp]$_\\text{wlp}$ follows from Theorem \\ref{theo:slp} and Lemma \\ref{lemma:wlpr}. The soundness of [ruleset], [comp], [cons], [if], and [try] follows from Theorem \\ref{theo:semsound} and Theorem \\ref{theo:FOL} about defining SUCCESS and FAIL in first-order formulas. Finally, the soundness of the inference rule [alap] follows from Theorem \\ref{theo:semsound} and Theorem \\ref{theo:nofail}.\\qed\n\\end{proof}\n\n\\subsection{Relative completeness}\n\nA proof calculus is complete when anytime we can denote a triple is valid according to partial correctness, then we can prove the correctness with the proof calculus. However, a completeness really depends on assertions we used because the ability to prove that $d$ can be implied by $c$ for some assertions $c$ and $d$ depends on language of the assertions. Hence, here we show the relative completeness instead of completeness, where we can separate the incompleteness due to the axioms and inference rules from any incompleteness in deducing valid assertions \\cite{Cook78}. \n\nBefore showing that \\textsf{SEM} is relative complete, we first show that for any postcondition $d$ and graph program $P$, we can show that $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,d)\\}~P~\\{d\\}$.\n\n\\Lemma{lemma:provwlp}{\nGiven a graph program $S$ and a postcondition $d$. Then,\\\\\n\\[\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(S,d)\\}~S~\\{d\\}\\]\n}\n\n\\begin{proof}\nHere we prove the lemma by induction on graph programs.\\\\\n\\begin{longtable}{lcp{11cm}}\n\\multicolumn{3}{l}{Base case. If $S$ is a (conditional) rule schema $r$,}\\\\\n    ~~ & \\multicolumn{2}{p{11.7cm}}{$\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(S,d)\\}~S~\\{d\\}$ automatically follows from the axiom [ruleapp]$_{\\text{wlp}}$.}\\\\\n    \\multicolumn{3}{p{11.7cm}}{Inductive case.}\\\\\n    &\\multicolumn{2}{p{11.7cm}}{Assume that for graph programs $C, P,$ and $Q$, $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(C,d)\\}~C~\\{d\\}$, $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,d)\\}~P~\\{d\\}$, and $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(Q,d)\\}~Q~\\{d\\}$.}\\\\\n    & (a) & If $S=\\mathcal{R}$.\\\\\n    && If $\\mathcal{R}=\\{\\}$, then there is no premise to prove so that we can deduce $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(\\mathcal{R},d)\\}~\\mathcal{R}~\\{d\\}$ automatically. If $\\mathcal{R}=\\{r_1,\\ldots,r_n\\}$ for $n>0$, $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(r_1,d)\\}~r_1~\\{d\\},\\ldots,\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(r_n,d)\\}~r_n~\\{d\\}$ from [ruleapp]$_{\\text{slp}}$. Let $e$ be the assertion $\\text{WLP}(r_1,d)\\wedge\\ldots\\wedge\\text{WLP}(r_n,d)$, so that by [cons], $\\vdash_{\\mathsf{SEM}}\\{e\\}~r_1~\\{d\\},\\ldots,\\vdash_{\\mathsf{SEM}}\\{e\\}~r_n~\\{d\\}$. By [ruleset] we then get that $\\vdash_{\\mathsf{SEM}}\\{e\\}~\\mathcal{R}~\\{d\\}$. Then by [cons],\n    $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(\\mathcal{R},d)\\}~\\mathcal{R}~\\{d\\}$ because\\\\\n    &&\\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat\\text{WLP}(\\mathcal{R},d)$}\\\\\n        $~~~$& $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\forall H. H\\in\\Sem{\\mathcal{R}}G\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall H. (H\\in\\Sem{r_1}G\\vee\\ldots\\vee H\\in\\Sem{r_n}G)\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall H. (H\\in\\Sem{r_1}G\\Rightarrow H\\Sat d)\\wedge\\ldots\\wedge (H\\in\\Sem{r_n}G\\Rightarrow H\\Sat d)$\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $G\\Sat \\text{WLP}(r_1,d)\\wedge\\ldots\\wedge\\text{WLP}(r_n,d)$\n    \\end{tabular}\\\\\n    & (b) & If $S=P;Q$,\\\\\n    && From the assumption, $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,\\text{WLP}(Q,d))\\}\\,P\\,\\{\\text{WLP}(Q,d)\\}$ and $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(Q,d)\\}\\,Q\\,\\{d\\}$. Then by the inference rule [comp], we get that $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,\\text{WLP}(Q,d))\\}~P;Q~\\{d\\}$. Finally by [cons], we have $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P;Q,d)\\}~P;Q~\\{d\\}$ because\\\\\n    &&\\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat\\text{WLP}(P;Q,d)$}\\\\\n        $~~~$& $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\forall H. H\\in\\Sem{P;Q}G\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall H,G'. (G'\\in\\Sem{P}G \\wedge H\\in\\Sem{Q}G'\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall G'. (G'\\in\\Sem{P}G \\Rightarrow (\\forall H. H\\in\\Sem{Q}G'\\Rightarrow H\\Sat d)$\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\forall G'. (G'\\in\\Sem{P}G \\Rightarrow G'\\Sat\\text{WLP}(Q,d)$\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $G\\Sat \\text{WLP}(P,\\text{WLP}(Q,d))$\n    \\end{tabular}\\\\\n    & (c) & If $S=\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    && Both $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,d)\\}\\,P\\,\\{d\\}$ and $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(Q,d)\\}\\,Q\\,\\{d\\}$ follow from the assumption. By [cons], we have:\\\\\n    &&$\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,d)\\wedge(\\FAIL(C)\\Rightarrow\\text{WLP}(Q,d))\\}\\,P\\,\\{d\\}$ and \\\\\n    &&$\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(Q,d)\\wedge(\\SUCCESS(C)\\Rightarrow\\text{WLP}(P,d))\\}\\,Q\\,\\{d\\}$.\\\\\n    && Let $e$ denotes $(\\SUCCESS(C)\\Rightarrow\\text{WLP}(P,d))\\wedge(\\FAIL(C)\\Rightarrow\\text{WLP}(Q,d))$ so that by [cons], we have:\\\\\n    &&$\\vdash_{\\mathsf{SEM}}\\{e\\wedge\\SUCCESS(C)\\}\\,P\\,\\{d\\}$ and $\\vdash_{\\mathsf{SEM}}\\{e\\wedge\\FAIL(C)\\}\\,Q\\,\\{d\\}$.\\\\\n    &&By [if] we then get that $\\vdash_{\\mathsf{SEM}}\\{e\\}\\,S\\,\\{d\\}$, and finally by [cons] we have $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(S,d)\\}\\,S\\,\\{d\\}$ because\\\\\n    &&\\small{\\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat\\text{WLP}(\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q,d)$}\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\forall H.~ H\\in\\Sem{\\mtt{if\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall H.~ ((G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G)\\vee(G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G))\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $(\\forall H.~ (G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{P}G)\\Rightarrow H\\Sat d)$\\\\\n        &&$\\wedge(\\forall H.~(G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G)\\Rightarrow H\\Sat d)$\n        \\\\ \n        & $\\Leftrightarrow$ & $G\\Sat\\SUCCESS(C)\\Rightarrow(\\forall H.~  H\\in\\Sem{P}G\\Rightarrow H\\Sat d)$\\\\\n        &&$\\wedge G\\Sat\\FAIL(C)\\Rightarrow(\\forall H.~H\\in\\Sem{Q}G\\Rightarrow H\\Sat d)$\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $G\\Sat(\\SUCCESS(C)\\Rightarrow\\text{WLP}(P,d)\\wedge(\\FAIL(C)\\Rightarrow\\text{WLP}(Q,d)$\n    \\end{tabular}}\\\\\n    & (d) & If $S=\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q$,\\\\\n    && Let $e$ denotes \\begin{small}$\\SUCCESS(C)\\Rightarrow\\text{WLP}(C;P,d)\\wedge\\FAIL(C)\\Rightarrow\\text{WLP}(Q,d)$\\end{small}. Similar to point (c), from the assumption we have $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(Q,d)\\}\\,Q\\,\\{d\\}$, which imply $\\vdash_{\\mathsf{SEM}}\\{e\\wedge\\FAIL(C)\\}\\,Q\\,\\{d\\}$. Also from the assumption, we have both $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(C,\\text{WLP}(P,d))\\}\\,P\\,\\{\\text{WLP}(P,d)\\}$ and also $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,d)\\}\\,P\\,\\{d\\}$. By [comp] and [cons] as case $S=P;Q$,\n    $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(C;P,d)\\}\\,C;P\\,\\{d\\}$. Then by [cons] as in $\\mtt{if-then-try}$ case, $\\vdash_{\\mathsf{SEM}}\\{e\\wedge\\SUCCESS(C)\\}\\,C;P\\,\\{d\\}$ such that by the inference rule [try] we have $\\vdash_{\\mathsf{SEM}}\\{e\\}\\,S\\,\\{d\\}$. Finnaly by [cons], $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(S,d)\\}\\,S\\,\\{d\\}$ because\\\\\n    &&\\small{\\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat\\text{WLP}(\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q,d)$}\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\forall H.~ H\\in\\Sem{\\mtt{try\\,}C\\mtt{\\,then\\,}P\\mtt{\\,else\\,}Q}G\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $\\forall H.~ ((G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{C;P}G)\\vee(G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G))$\\\\\n        &&$~~~~~~~~\\Rightarrow H\\Sat d$\\\\\n        & $\\Leftrightarrow$ & $(\\forall H.~ (G\\Sat\\SUCCESS(C)\\wedge H\\in\\Sem{C;P}G)\\Rightarrow H\\Sat d)$\\\\\n        &&$\\wedge(\\forall H.~(G\\Sat\\FAIL(C)\\wedge H\\in\\Sem{Q}G)\\Rightarrow H\\Sat d)$\n        \\\\ \n        & $\\Leftrightarrow$ & $G\\Sat\\SUCCESS(C)\\Rightarrow(\\forall H.~  H\\in\\Sem{C;P}G\\Rightarrow H\\Sat d)$\\\\\n        &&$\\wedge G\\Sat\\FAIL(C)\\Rightarrow(\\forall H.~H\\in\\Sem{Q}G\\Rightarrow H\\Sat d)$\\\\\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $G\\Sat(\\SUCCESS(C)\\Rightarrow\\text{WLP}(C;P,d)\\wedge(\\FAIL(C)\\Rightarrow\\text{WLP}(Q,d)$\n    \\end{tabular}}\\\\\n     & (d) & If $S=P!$,\\\\\n     &&From the assumption, $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P,\\text{WLP}(P!,d))\\}\\,P\\,\\{\\text{WLP}(P!,d)\\}$. By [cons] as in $P;Q$ case, we get $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P;P!,d)\\}\\,P\\,\\{\\text{WLP}(P!,d)\\}$ such that by [cons] we know that $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P!,d)\\}\\,P\\,\\{\\text{WLP}(P!,d)\\}$. Note that from Theorem \\ref{theo:semsound}, this implies $\\vDash \\{\\text{WLP}(P!,d)\\}\\,P\\,\\{\\text{WLP}(P!,d)\\}$ such that for all host graphs $G_1,\\ldots,G_n,$ and $H$ where $G_2\\in\\Sem{P}G_1,\\ldots,G_n\\in\\Sem{P}G_{n-1},$ and $\\tuple{P,G_n}\\rightarrow^*\\tuple{\\mtt{break},H}$, $G\\Sat\\text{WLP}(P!.d)$ implies $G'\\Sat \\text{WLP}(P!.d)$ and $H\\Sat d$. Hence, Break($\\text{WLP}(P!.d),P,d$) holds. Then by the inference rule [alap], we have $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P!,d)\\}\\,P\\,\\{(\\text{WLP}(P!,d)\\wedge\\FAIL(P))\\vee d\\}$ such that by [cons], $\\vdash_{\\mathsf{SEM}}\\{\\text{WLP}(P!,d)\\}\\,P\\,\\{d\\}$ because\\\\\n     &&\\small{\\begin{tabular}{lcl}\n        $H\\Sat\\text{WLP}(P!,d)\\wedge\\FAIL(P)$\n        & $\\myeq{\\Leftrightarrow}{L\\ref{lemma:wlpP}}$ & $\\text{fail}\\in\\Sem{P}H\\wedge\\forall H'.~ H'\\in\\Sem{P!}H\\Rightarrow H'\\Sat d$\\\\\n        & $\\Rightarrow$ & $H\\in\\Sem{P!}H\\wedge\\forall H'.~ H'\\in\\Sem{P!}H\\Rightarrow H'\\Sat d$\\\\\n        & $\\Rightarrow$ & $H\\Sat d$.\n    \\end{tabular}}\\qed\n\\end{longtable}\n\\end{proof}\n\n\\Theo{Relative completeness of \\textsf{SEM}}{theo:syncomplete}{\nGiven a graph program $P$ and assertions $c,d$. Then,\n\\[\\vDash\\{c\\}~P~\\{d\\} \\text{~implies~} \\vdash_{\\mathsf{SEM}} \\{c\\}~P~\\{d\\}.\\]\n}\n\n\\begin{proof}\nFrom Lemma \\ref{lemma:provwlp}, we know that for all $\\vdash_{\\mathsf{SEM}} \\{\\text{WLP}(P,d)\\}~P~\\{d\\}$ and from Theorem \\ref{theo:semsound}, we get that $\\text{WLP}(P,d)$ is a weakest liberal precondition over $P$ and $d$. Hence, if $\\vDash\\{c\\}~P~\\{d\\}$, $c$ must imply $\\text{WLP}(P,d)$ so that by [cons] we get that $\\vdash_{\\mathsf{SEM}} \\{c\\}~P~\\{d\\}$.\\qed\n\\end{proof}\n\n\\begin{conjecture}\nThe proof calculus \\textsf{SYN} is not relative complete.\n\\end{conjecture}\n\nIn Theorem \\ref{theo:syncomplete}, we show the relative completeness of our semantic partial correctness calculus. This proof, however, assumes that the assertion language was expressive, i.e. able to express strongest liberal postcondition relative to arbitrary programs and preconditions. However, there are limitations in properties that can be expressed by first-order logic. We believe that FO logic can not express that a graph has an even number of nodes \\cite{Libkin04}. Although we do not have proof of the incompleteness of \\textsf{SYN}, we believe that the calculus is not relative complete due to the expressiveness of FO formulas.\n\nThere is strong evidence that this is impossible. For example, consider the triple $\\{c\\}~P~\\{d\\}$ with $c=\\mrm{\\A{V}x(m_V(x)=none\\land\\neg\\E{E}y(s(y)=x\\vee t(y)=x))}$ \n(all nodes are unmarked and isolated), $d=\\mrm{\\A{V}x(false)}$ (the graph is empty), and the following program:\\\\\n\\begin{samepage}\n\\begin{scriptsize}\n$~~~~~~~~~~~~~~~~~~\\mtt{Main = duplicate!; delete!}$\\\\[1ex]\n%\\noindent\\adjustbox{max width=0.9\\textwidth}{\n$~~~~~~~~~~~~~~~~~~~~~~~~$\\begin{tabular}{lll}\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.7\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{duplicate(a:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\tiny\\mtt{a}$};\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (1.5,0) {\n   \\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=gray!50] (Aa) at (0,0) {$\\tiny\\mtt{a}$};\t\n\t\t\\node[inner, fill=gray!50] (Aa) at (1,0) {$\\tiny\\mtt{a}$};\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n&\n$~~~~~~~~~~~~~~~~~~~~~~~~$&\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.7\n  ]\n  \\node[outer] (AA) at (-1,1) {$\\tiny\\mtt{delete(a:list)}$};\n  \\node[outer] (A) at (-1.5,0) {\n   \\begin{tikzpicture}[scale=0.7, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=gray!50] (Aa) at (0,0) {$\\tiny\\mtt{a}$};\t\n\t\t\\node[inner, label=below:\\tiny 2, fill=gray!50] (Aa) at (1,0) {$\\tiny\\mtt{a}$};\t\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (1,0) {$\\emptyset$};\n\t\\end{tikzpicture}\n\n\\end{tabular}\\end{scriptsize}\n\\end{samepage}\n\nIt is obvious that $\\vDash \\{c\\}~\\mtt{duplicate!; delete!}~\\{d\\}$ holds: $\\mtt{duplicate!}$ duplicates the number of nodes while marking the nodes grey, hence its result graph consists of an even number of isolated grey nodes. Then $\\mtt{delete!}$ deletes pairs of grey nodes as long as possible, so the overall result is the empty graph. Note that ``consists of an even number of isolated grey nodes\" is both the strongest postcondition with respect to $c$ and \\ttt{duplicate!}, and the weakest precondition with respect to \\ttt{delete!} and $d$.\n\nUsing \\textsf{SYN} one can prove $\\vdash \\{c\\}~\\mtt{duplicate!}~\\{e\\}$ where $e$ expresses that all nodes are grey and isolated. However, we believe that our logic cannot express that a graph has an even number of nodes. This is because pure first-order logic (without built-in operations) cannot express this property \\cite{Libkin04} and it is likely that this inexpressiveness carries over to our logic. As a consequence, one can only prove $\\vdash \\{e\\}~\\mtt{delete!}~\\{f\\}$ where $f$ expresses that the graph contains at most one node (because otherwise \\ttt{delete} would be applicable). But we cannot use \\textsf{SYN} to prove  $\\vdash \\{c\\}~\\mtt{duplicate!; delete!}~\\{d\\}$. \n\\section{Verification Example}\n\\label{sec:ex}\nIn this section, we show an example of graph program verification with first-order logic. Here we consider the program $\\mtt{2colouring}$ that can be seen in \\figurename~\\ref{fig:2col-prog}. Given a host graph where all nodes are unmarked and unrooted and all edges are unmarked. If the input graph is two-colourable, then all nodes in the resulting graph should marked with blue or red such that no two adjacent nodes have the same colour.\n\n\\begin{figure}\n\\begin{mdframed}\n\\begin{tabular}{l}\n\\small$\\mtt{Main = (init; Colour!)!; if~Illegal~then~unmark!}$\\\\\n$\\mtt{Colour = \\{col\\_\\,blue, col\\_\\,red\\}}$\\\\\n$\\mtt{Illegal = \\{ill\\_\\,blue, ill\\_\\,red\\}}$\\\\\n\\end{tabular}\\\\[1.5ex]\n%\\noindent\\adjustbox{max width=0.9\\textwidth}{\n\\begin{tabular}{lllll}\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{init(a:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!70] (Aa) at (0,0) {$\\mtt{a}$};\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\t\n\t&$~~~~~~~~~$&\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{col\\_\\,blue(a,b,c:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!70] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0.5,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (2,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!70] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=blue!50] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n&$~~~~~~~$&\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{col\\_\\,red(a,b,c:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=blue!50] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0.5,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (2,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=blue!50] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=red!70] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\\\\\n\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{unmark(a:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=magenta!70] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\t&&\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{ill\\_\\,blue(a,b,c:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=blue!50] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=blue!50] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0.5,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (2,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=blue!50] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=blue!50] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n&&\n\\begin{tikzpicture}[remember picture,\n  inner/.style={circle,draw,minimum size=16pt},\n  outer/.style={inner sep=2pt}, scale=0.6\n  ]\n  \\node[outer] (AA) at (0,1) {$\\tiny\\mtt{ill\\_\\,red(a,b,c:list)}$};\n  \\node[outer] (A) at (-1,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!70] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=red!70] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\n\t\t\\end{tikzpicture}};\n  \\node[outer] (B) at (0.5,0) {$\\Rightarrow$};\n  \\node[outer] (C) at (2,0) {\n   \\begin{tikzpicture}[scale=0.8, transform shape]\n\t\t\\node[inner, label=below:\\tiny 1, fill=red!70] (Aa) at (0,0) {$\\mtt{a}$};\n\t\t\\node[inner, label=below:\\tiny 2, fill=red!70] (Ab) at (1,0) {$\\mtt{b}$};\n\t\t\\draw (Aa) to node[above] {$\\mtt{c}$} (Ab);\t\n\t\t\\end{tikzpicture}};\n\t\\end{tikzpicture}\n\t\n\\end{tabular}\n\\end{mdframed}\n\\caption{Graph program $\\mtt{2colouring}$ for computing a 2-colouring graph}\n\\label{fig:2col-prog}\n\\end{figure}\n\nThen, let us consider the following pre- and postcondition:\\\\\n\\noindent\\textbf{Precondition} ``every node and edge is unmarked and every node is unrooted\"\\\\\n\\textbf{Postcondition} ``the precondition holds or every node is marked with blue or red, and no two adjacent nodes marked with the same colour\"\n\nLet $c$ and $c\\vee d$ be the FO formulas expressing pre- and postcondition respectively. We define $c$ and $d$ as follows:\\\\\n\\begin{footnotesize}\\begin{tabular}{rcl}\n    $c$ & $\\equiv$ & $\\mrm{\\A{V}x(\\mV(x)= none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n    $d$ & $\\equiv$ & $\\mrm{\\A{V}x((\\mV(x)=red\\vee\\mV(x)=blue))\\wedge\\neg\\E{E}x(s(x)\\neq t(x)\\wedge\\mV(s(x))=\\mV(t(x)))}$\n\\end{tabular}\\end{footnotesize}\n\nA proof tree for the partial correctness for $\\mtt{2-colouring}$ with respect to $c$ and $c\\vee d$ is provided in \\figurename~\\ref{fig:2col-proof}. The conditions in the tree are defined in Table \\ref{tab:2col-cond}. \n\n\\begin{figure}\n    \\centering\\begin{scriptsize}\n    \\begin{mdframed}\n\n\\begin{prooftree}\n\\AxiomC{Subtree I}\n\\AxiomC{Subtree II}\n\\LeftLabel{[comp]}\n\\BinaryInfC{\\{$f$\\}$~\\mtt{2colouring}~$\\{$c\\vee d$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$c$\\}$~\\mtt{2colouring}~$\\{$c\\vee d$\\}}\n\\end{prooftree}\n$~$\\\\$~$\\\\\n\nwhere subtree I is:\n\\begin{prooftree}\n\\AxiomC{}\n\\LeftLabel{[ruleapp]$_\\text{slp}$}\n\\UnaryInfC{\\{$f$\\}$\\mtt{init}$\\{Slp$(f,\\mtt{init})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$\\mtt{init}$\\{$f$\\}}\n\n\\AxiomC{subtree I.a}\n\\LeftLabel{[comp]}\n\\BinaryInfC{\\{$f$\\}$~\\mtt{init;Colour!}~$\\{$f$\\}}\n\\LeftLabel{[alap]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{(init; Colour!)!~}$\\{$f\\wedge\\text{Fail}(\\mtt{init;Colour!})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{(init;Colour!)!}~$\\{$e$\\}}\n\n\\end{prooftree}\nwith subtree I.a:\n\\begin{prooftree}\n\\AxiomC{}\n\\LeftLabel{[ruleapp]$_\\text{slp}$}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{c\\_\\,blue}~$\\{Slp$(f,\\mtt{c\\_\\,blue})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{c\\_\\,blue}~$\\{$f$\\}}\n\n\\AxiomC{}\n\\LeftLabel{[ruleapp]$_\\text{slp}$}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{c\\_\\,red}~$\\{Slp$(f,\\mtt{c\\_\\,red})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{c\\_\\,red}~$\\{$f$\\}}\n\n\\LeftLabel{[cons]}\n\\BinaryInfC{\\{$f$\\}$~\\mtt{Colour}~$\\{$f$\\}}\n\\LeftLabel{[alap]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{Colour!}~$\\{$f\\wedge\\text{Fail}(\\mtt{Colour})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{Colour!}~$\\{$f$\\}}\n\\end{prooftree}\n\n$~$\\\\$~$\\\\\nand subtree II is:\n\\begin{prooftree}\n\\AxiomC{}\n\\LeftLabel{[ruleapp]$_\\text{slp}$}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{unmark}~$\\{Slp$(f,\\mtt{unmark})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{unmark}~$\\{$f$\\}}\n\\LeftLabel{[alap]}\n\\UnaryInfC{\\{$f$\\}$~\\mtt{unmark!}~$\\{$f\\wedge\\text{Fail}(\\mtt{unmark})$\\}}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$e\\wedge\\text{Success}(\\mtt{Illegal})$\\}$~\\mtt{unmark!}~$\\{$c\\vee d$\\}}\n\n\\AxiomC{}\n\\LeftLabel{[ruleapp]$_\\text{slp}$}\n\\UnaryInfC{\\{$d$\\}$~\\mtt{skip}~$\\{$d$\\})}\n\\LeftLabel{[cons]}\n\\UnaryInfC{\\{$e\\wedge\\text{Fail}(\\mtt{Illegal})$\\}$~\\mtt{skip}~$\\{$c\\vee d$\\}}\n\n\\LeftLabel{[if]}\n\\BinaryInfC{\\{$e$\\}$~\\mtt{if~Illegal~then~umark!}~$\\{$c\\vee d$\\}}\n\\end{prooftree}\n\\end{mdframed}\\end{scriptsize}\n    \\caption{Proof tree for partial correctness of $\\mtt{2colouring}$}\n    \\label{fig:2col-proof}\n\\end{figure}\n\n\n\\begin{table}[]\n    \\caption{Assertions inside proof tree of $\\mtt{2-colouring}$}\n    \\label{tab:2col-cond}\n    \\centering\\begin{scriptsize}\n    \\begin{tabular}{|p{11.5cm}|}\n        \\hline\n        \\multicolumn{1}{|c|}{\\textbf{symbol and its first-order formulas}}\\\\\\hline\n        \n        $c\n        \\equiv\n        \\mrm{\\A{V}x(\\mV(x)=none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n        \n        $d\\equiv\n        \\mrm{\\A{V}x((\\mV(x)=red\\vee\\mV(x)=blue))\\wedge\\neg\\E{E}x(s(x)\\neq t(x)\\wedge\\mV(s(x))=\\mV(t(x)))}$\\\\\\hline\n        \n        $e\n        \\equiv\n        \\mrm{\\A{V}x((\\mV(x)=red\\vee\\mV(x)=blue)\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n        \n        $f\n        \\equiv\n        \\mrm{\\A{V}x((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none))\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n       \n        Slp$(f,\\mtt{init})$\\\\\n        $\\equiv\n        \\mrm{\\E{V}y(\\A{V}x(x=y\\vee((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none)\\wedge\\neg root(x)))}$\\\\\n        $\\mrm{~~~~~~~~~\\wedge \\mV(y)=red\\wedge\\neg root(y))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n        \n        Slp$(f,\\mtt{c\\_blue})=$Slp$(f,\\mtt{c\\_red})$\\\\\n        $\\equiv\n        \\mrm{\\E{V}u,v(\\A{V}x(x=u\\vee x=v\\vee((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none)\\wedge\\neg root(x)))}$\\\\\n       $\\mrm{~~~~~~~~~~~~\\wedge \\mV(u)=red\\wedge\\mV(v)=blue\\wedge\\neg root(u)\\wedge\\neg root(v)}$\\\\\n        $\\mrm{~~~~~~~~~~~~\\wedge\\E{E}y((s(y)=u\\wedge t(y)=v)\\vee(t(y)=u\\wedge s(y)=v)))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n        \n        Slp$(f,\\mtt{unmark})$\\\\\n        $\\equiv\n        \\mrm{\\E{V}y(\\A{V}x(x=y\\vee((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none)\\wedge\\neg root(x)))}$\\\\\n        $\\mrm{~~~~~~~~~\\wedge\\mV(y)=none\\wedge\\neg root(y))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\\hline\n        \n        Fail$(\\mtt{Colour})$\\\\\n        $\\equiv\n        \\mrm{\\neg\\E{E}x((((\\mV(s(x))=red\\vee\\mV(s(x))=blue)\\wedge \\mV(t(x))=none)}$\\\\\n        $\\mrm{~~~~~~~~~~~~\\vee((\\mV(t(x))=red\\vee\\mV(t(x))=blue)\\wedge \\mV(s(x))=none))}$\\\\\n        $\\mrm{~~~~~~~~~~~~\\wedge \\neg root(s(x))\\wedge\\neg root(t(x))})$\\\\\\hline\n        \n        Fail$(\\mtt{init;Colour!})\n        \\equiv\n        \\mrm{\\neg\\E{V}x(\\mV(x)=none\\wedge\\neg root(x))}$\\\\\\hline\n\n        Fail$(\\mtt{unmark})\n        \\equiv\n        \\mrm{\\neg\\E{V}x(\\mV(x)\\neq none\\wedge\\neg root(x))}$\\\\\\hline\n\n        Fail$(\\mtt{Illegal})$\\\\\n        $\\equiv\n        \\mrm{\\neg\\E{E}x(s(x)\\neq t(x)}$\\\\\n        $\\mrm{~~~~~~~~~~~~\\wedge((\\mV(s(x))=red\\wedge\\mV(t(x))=red)\\vee(\\mV(s(x))=blue\\wedge\\mV(t(x))=blue)))}$\\\\\\hline\n\n        Success$(\\mtt{Illegal})$\\\\\n        $\\equiv\n        \\mrm{\\E{E}x(s(x)\\neq t(x)}$\\\\\n        $\\mrm{~~~~~~~~~~\\wedge((\\mV(s(x))=red\\wedge\\mV(t(x))=red)\\vee(\\mV(s(x))=blue\\wedge\\mV(t(x))=blue)))}$\\\\\\hline\n\n    \\end{tabular}\\end{scriptsize}\n\\end{table}\n\nNote that there is no command $\\mtt{break}$ in the program, so Break$(c,P,\\mrm{false})$ holds for any precondition $c$ and sub-command $P$ of the program $\\mtt{2colouring}$. For this reason and for simplicity, we omit premise Break$(c,P,\\mrm{false})$ in the inference rule [alap] of the proof tree.\n\nAs we can see in the proof tree of \\figurename~\\ref{fig:2col-proof}, we apply some inference rule [cons] which means we need to give proof of implications applied to the rules. Some implications are obvious, e.g. $c$ implies $c\\vee d$, so that for those obvious implications, we do not give any argument about them. Otherwise, we show that the implications hold:\n\n \\vspace{-\\topsep}\\begin{enumerate}\n    \\item \\textit{Proof of} $c$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        $G\\Sat c$ & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\A{V}x(\\mV(x)=none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$  \\\\\n        & $\\Rightarrow$ &  $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} Slp$(f,\\mtt{init})$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat$Slp$(f,\\mtt{init})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\E{V}y(\\A{V}x(x=y\\vee(\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none))}$\\\\\n`       &&$\\mrm{~~~~~~~~~~~~\\wedge \\mV(y)=red\\wedge\\neg root(y))}$  \\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=red\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~\\vee(\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none))}$ \\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & \n        $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} Slp$(f,\\mtt{c\\_blue})$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat$Slp$(f,\\mtt{c\\_blue})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\E{V}u,v(u\\neq v\\wedge\\A{V}x(x=u\\vee x=v}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~~~~~~~~~~\\vee((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x)))}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~~~~\\wedge \\mV(u)=red\\wedge\\mV(v)=blue\\wedge\\neg root(u)\\wedge\\neg root(v)}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~~~~\\wedge\\E{E}y((s(y)=u\\wedge t(y)=v)\\vee(t(y)=u\\wedge s(y)=v)))}$  \\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=red\\wedge\\neg root(x))\\vee (\\mV(x)=blue\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~\\vee(\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & \n        $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} Slp$(f,\\mtt{col\\_red})$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat$Slp$(f,\\mtt{c\\_red})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat$Slp$(f,\\mtt{c\\_blue})$\\\\\n        & $\\Rightarrow$ & \n        $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n\n    \\item \\textit{Proof of} Slp$(f,\\mtt{unmark})$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat$Slp$(f,\\mtt{unmark})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\E{V}y(\\A{V}x(x=y\\vee((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none)\\wedge\\neg root(x)))}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~\\wedge\\mV(y)=none\\wedge\\neg root(y))}$  \\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & \n        $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~\\vee((\\mV(x)=red\\vee\\mV(x)=blue\\vee\\mV(x)=none)\\wedge\\neg root(x)))}$\\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & \n        $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$ \\\\\n        && $\\mrm{~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} $f\\wedge$Fail$(\\mtt{init;Colour!})$ \\textit{implies} $e$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat f\\wedge$Fail$(\\mtt{init;Colour!})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~\\wedge\\neg\\E{V}x(\\mV(x)=none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$ \\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} $f\\wedge$Fail$(\\mtt{unmark})$ \\textit{implies} $c\\vee d$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat f\\wedge$Fail$(\\mtt{unmark})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~\\wedge\\neg\\E{V}x(\\mV(x)\\neq none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$ \\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x(\\mV(x)=none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & $G\\Sat (\\mrm{\\A{V}x(\\mV(x)=none\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)})\\vee d$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} $e\\wedge$Fail$(\\mtt{Illegal})$ \\textit{implies} $d$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat e\\wedge$Fail$(\\mtt{Illegal})$}\\\\\n        & $\\Leftrightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        &&$\\mrm{~~~~~~\\wedge\\neg\\E{E}x(((\\mV(s(x))=red\\wedge\\mV(t(x))=red)}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~~~~\\vee(\\mV(s(x))=blue\\wedge\\mV(t(x))=blue))\\wedge s(x)\\neq t(x))}$ \\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x(\\mV(x)=blue\\vee\\mV(x)=red)}$\\\\\n        &&$\\mrm{~~~~~~\\wedge\\neg\\E{E}x(((\\mV(s(x))=red\\wedge\\mV(t(x))=red)}$\\\\\n        &&$\\mrm{~~~~~~~~~~~~~~~~\\vee(\\mV(s(x))=blue\\wedge\\mV(t(x))=blue))\\wedge s(x)\\neq t(x))}$ \\\\\n        & $\\Rightarrow$ & $G\\Sat \\mrm{\\A{V}x((\\mV(x)=red\\vee\\mV(x)=blue))}$\\\\\n        &&$~~~~~~~\\mrm{\\wedge\\neg\\E{E}x(\\mV(s(x))=\\mV(t(x))\\wedge s(x)\\neq t(x))}$\n    \\end{tabular}\\end{small}\\\\\n    \n    \\item \\textit{Proof of} $e\\wedge$Success$(\\mtt{Illegal})$ \\textit{implies} $f$.\\\\\n    \\begin{small}\n    \\begin{tabular}{lcl}\n        \\multicolumn{3}{l}{$G\\Sat e\\wedge$Success$(\\mtt{Illegal})$}\\\\\n        & $\\Rightarrow$ &\n        $G\\Sat e$\\\\\n        & $\\Rightarrow$ &$G\\Sat\\mrm{\\A{V}x((\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))\\wedge\\A{E}x(\\mE(x)=none)}$\\\\\n        & $\\Rightarrow$ & $G\\Sat\\mrm{\\A{V}x((\\mV(x)=none\\vee\\mV(x)=blue\\vee\\mV(x)=red)\\wedge\\neg root(x))}$\\\\\n        &&$\\mrm{~~~~~~\\wedge\\A{E}x(\\mE(x)=none)}$\n    \\end{tabular}\\end{small}\\\\\n\\end{enumerate}\n\n \n\\section{Related Work}\n\\label{sec:related_work}\nHoare-style verification of graph programs with attributed rules was introduced in \\cite{PoskittP12,Poskitt13}, using E-conditions which generalise the nested graph conditions of Habel and Pennemann \\cite{HP09,Pennemann09}. E-conditions do not cover rooted rules or the $\\mtt{break}$ command, which are considered in our first-order formulas. More importantly, the approach of \\cite{PoskittP12,Poskitt13} can only handle programs in which the conditions of branching commands and loop bodies are rule set calls. Our syntactic calculus \\textsf{SYN} covers a larger class of graph programs, viz.\\ programs where the condition of each branching command is a loop-free program, and each loop body is an iteration command. This allows us, in particular, to verify many programs with nested loops. Besides this increased power, we believe that assertions in the form of first-order formulas are easier to comprehend by programmers than nested graph conditions of some form. \n\n% The ability to specify marks in the text is also an advantage to express a property in a straightforward way. For an example, if we want to express ``all nodes are unmarked\", we can express it as $\\mrm{\\forall_Vx(\\mV(x)=none)}$ by our first-order formula. However in \\cite{PoskittP12,Poskitt13}, the simplest way to express it is: $\\neg\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n%   \\node[circle, draw, fill=grey!40] (a) at (0, 0) {$\\mtt{a}$};\n% \\end{tikzpicture}) $\\wedge \\neg\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n%   \\node[circle, draw, fill=red!70] (a) at (0, 0) {$\\mtt{a}$};\n% \\end{tikzpicture}) $\\wedge\\neg\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n%   \\node[circle, draw, fill=green!70] (a) at (0, 0) {$\\mtt{a}$};\n% \\end{tikzpicture}) $\\wedge\\neg\\exists$(\\begin{tikzpicture}[scale=0.6, transform shape, minimum size=.1cm,baseline,thick]\n%   \\node[circle, draw, fill=blue!50] (a) at (0, 0) {$\\mtt{a}$};\n% \\end{tikzpicture}).\n\nAs argued at the end of the previous section, we cannot express SLP$(c,P)$ or WLP$(P,c)$ for arbitrary assertions $c$ and graph programs $P$ as first-order formulas. In \\cite{HP09,Pennemann09}, there is a construction of Wlp$(c,P!)$ by using an infinite formula. Here, we do not use a similar trick but stick to standard finitary logic. The papers \\cite{DijkstraS90,Jones-Roscoe-Wood10a} do not give constructions for syntactic strongest liberal postconditions or weakest liberal postconditions either. Instead, similar to the consequent of our inference rule [alap], the conjunction of a loop invariant and a negated loop condition is considered as an ``approximate\" strongest liberal postcondition. \n\nIn \\cite{Brenas-Echahed-Strecker18b}, the authors design an imperative programming language for manipulating graphs and give a Hoare calculus based on weakest preconditions. Programs manipulate the graph structure only and do not contain arithmetic. Assertions are formulas of the so-called guarded fragment of first-order logic, which is decidable. This relatively weak logic makes the correctness of programs decidable. \n\nOur goal is different in that we want a powerful assertion language that can specify many practical algorithms on graphs. (In fact, we plan to extend our logic to monadic second-order logic in order to express non-local properties such as connectedness, colourability, etc.) In our setting, it is easily seen that correctness is undecidable in general, even for trivial programs. For example, consider Hoare triples of the form $\\{\\mrm{true}\\} \\mtt{skip} \\{d\\}$ where d is an arithmetic formula (without references to nodes or edges). Such a triple is partially (and totally) correct if and only if d is true on the integers. But our formulas include Peano arithmetic and hence are undecidable in general \\cite{Monk76a}. Thus, even for triples of the restricted form above, correctness is undecidable.\n \n\\section{Conclusion and Future Work}\n\\label{sec:conclusion}\nWe have shown how to construct a strongest liberal postcondition for a given conditional rule schema and a precondition in the form of a first-order formula. Using this construction, we have shown that we can obtain a strongest liberal postcondition over a loop-free program, and construct a first-order formula for SUCCESS$(C)$ for a loop-free program $C$. Moreover, we can construct a first-order formula for FAIL$(P)$ for an iteration command $P$. Altogether, this gives us a proof calculus that can handle more programs than previous calculi in the literature, in particular we can now handle certain nested loops.\n\nHowever, the expressiveness of first-order formulas over the domain of graphs is quite limited. For example, one cannot specify that a graph is connected by a first-order formula. Hence, in the near future, we will extend our formulas to monadic second-order formulas to overcome such limitations \\cite{Cou12}. \n\nAnother limitation in current approaches to graph program verification is the inability to specify isomorphisms between the initial and final graphs \\cite{WP18}. Monadic second-order transductions can link initial and final states by expressing the final state through elements of the initial state \\cite{Cou12}. We plan to adopt this technique for graph program verification in the future.  \n\\bibliographystyle{abbrv}\n\\bibliography{firstorder}\n\n\\end{document}", "meta": {"timestamp": "2020-11-04T01:09:04", "yymm": "2010", "arxiv_id": "2010.14549", "url": "https://arxiv.org/abs/2010.14549", "source": "arxiv"}}
{"text": "%\\documentclass[10pt]{amsart}\n%% \\documentclass[a4paper,UKenglish]{lipics-v2016}\n%%[a4paper,UKenglish]{lipics-v2016}\n%%This is a template for producing LIPIcs articles. \n%%See lipics-manual.pdf for further information.\n%%for A4 paper format use option \"a4paper\", for US-letter use option \"letterpaper\"\n%%for british hyphenation rules use option \"UKenglish\", for american hyphenation rules use option \"USenglish\"\n%% for section-numbered lemmas etc., use \"numberwithinsect\"\n% \\textwidth 14.5cm\n%\\textheight 20.6cm\n%\\oddsidemargin 0.85cm\n%\\evensidemargin 0.37cm\n%\n%\\usepackage{microtype}%if unwanted, comment out or use option \"draft\"\n%\n%%\\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory\n%\\usepackage{amsmath}\n%%\\usepackage{hyperref}\n%%\\usepackage{microtype}\n%\\usepackage{amsmath}\n%\\usepackage{amssymb}\n%\\usepackage{tikz}\n%\n%%\\usepackage[mathscr]{euscript}\n%%\\usepackage{amsthm}\n%%\\usepackage{amsfonts}\n%%\\usepackage{empheq}\n%%\\usepackage{newlfont}\n%%\\usepackage{tikz}\n%%   \\usetikzlibrary{circuits.logic.US,circuits.logic.CDH}\n%%\\usepackage{calc}\n%%\\usepackage{stmaryrd}\n%\\usepackage{color}\n%%\\usepackage{epsfig}\n%%\\usepackage{subfigure}\n%%\\setcounter{MaxMatrixCols}{30}%\n%%\\usepackage{graphicx}\n%%\n%\n%%\\newcommand{\\ga}{\\alpha}\n%%\\newcommand{\\gb}{\\beta}\n%%\\newcommand{\\gc}{\\gamma}\n%%\\newcommand{\\gd}{\\delta}\n%%\\newcommand{\\gep}{\\varepsilon}\n%%\\newcommand{\\gz}{\\zeta}\n%%\\newcommand{\\geta}{\\eta}\n%%\\newcommand{\\tauh}{\\theta}\n%%\\newcommand{\\gi}{\\iota}\n%%\\newcommand{\\gv}{\\nu}\n%%\\newcommand{\\gk}{\\kappa}\n%%\\newcommand{\\gl}{\\lambda}\n%%\\newcommand{\\gm}{\\mu}\n%%\\newcommand{\\gn}{\\nu}\n%%\\newcommand{\\gx}{\\xi}\n%%\\newcommand{\\pi}{\\pi}\n%%\\newcommand{\\gr}{\\rho}\n%%\\newcommand{\\sigma}{\\sigma}\n%%\\newcommand{\\tau}{\\tau}\n%%\\newcommand{\\pih}{\\varphi}\n%%\\newcommand{\\gch}{\\chi}\n%%\\newcommand{\\pis}{\\psi}\n%%\\newcommand{\\go}{\\omega}\n%%\\newcommand{\\sigma}{\\Sigma}\n%%\\newcommand{\\gL}{\\Lambda}\n%\\newcommand{\\e}{\\mathsf e}\n%%\\newcommand{\\dd}{\\mathsf d}\n%\\newcommand\\TTTT{\n% \\textsf{T\\kern-0.15em\\raisebox{-0.55ex}T\\kern-0.15emT\\kern-0.15em\\raisebox{-0.55ex}2}}\n%\n%\\newtheorem{fact}{Fact}\n%\\newtheorem{proposition}{Proposition}\n%\\newtheorem{corollary}{Corollary}\n%\\newtheorem{theorem}{Theorem}\n%\\newtheorem{lemma}{Lemma}\n%\\newtheorem{definition}{Definition}\n%\\newtheorem{example}{Example}\n%\\newtheorem{remark}{Remark}\n%\\newtheorem{claim}{Claim}\n%\\newcommand{\\blue}[1]{ {\\color{blue}#1}}\n%\\newcommand{\\red}[1]{ {\\color{red}#1}}\n%\\newcommand{\\purple}[1]{ {\\color{purple}#1}}\n%\n%\\input macro-salibra\n%\n%\n%\\title{%On a question of Birkhoff and Maltsev\n%%Clone Algebras and Lattices of Equational Theories\\\\\n%An algebraic theory of clones\\\\  and %with an application\n%\\\\  a question of Birkhoff and Maltsev\\\\\n%%The lattice of equational theories problem\\\\\n%%{\\tiny 29 Agosto 2020}%\\footnote{This work was partially supported by someone.}\n%}\n%\n%\n%\n%%% Please provide for each author the \\author and \\affil macro, even when authors have the same affiliation, i.e. for each author there needs to be the  \\author and \\affil macros\n%\\author[1]{Antonio Bucciarelli}\n%\\author[2]{Antonino Salibra}\n%\n%\\begin{document}\n%\n%\n%\\maketitle\n\n\\documentclass[10pt]{amsart}\n\\textwidth 15.5cm\n\\textheight 21.6cm\n\\oddsidemargin 0.85cm\n\\evensidemargin 0.37cm\n\\usepackage{kantlipsum}\n\\usepackage{microtype}%if unwanted, comment out or use option \"draft\"\n\n%\\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory\n\\usepackage{amsmath}\n%\\usepackage{hyperref}\n%\\usepackage{microtype}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage{tikz}\n\n%\\usepackage[mathscr]{euscript}\n%\\usepackage{amsthm}\n%\\usepackage{amsfonts}\n%\\usepackage{empheq}\n%\\usepackage{newlfont}\n%\\usepackage{tikz}\n% \\usetikzlibrary{circuits.logic.US,circuits.logic.CDH}\n%\\usepackage{calc}\n%\\usepackage{stmaryrd}\n\\usepackage{color}\n%\\usepackage{epsfig}\n%\\usepackage{subfigure}\n%\\setcounter{MaxMatrixCols}{30}%\n%\\usepackage{graphicx}\n%\n\n%\\newcommand{\\ga}{\\alpha}\n%\\newcommand{\\gb}{\\beta}\n%\\newcommand{\\gc}{\\gamma}\n%\\newcommand{\\gd}{\\delta}\n%\\newcommand{\\gep}{\\varepsilon}\n%\\newcommand{\\gz}{\\zeta}\n%\\newcommand{\\geta}{\\eta}\n%\\newcommand{\\tauh}{\\theta}\n%\\newcommand{\\gi}{\\iota}\n%\\newcommand{\\gv}{\\nu}\n%\\newcommand{\\gk}{\\kappa}\n%\\newcommand{\\gl}{\\lambda}\n%\\newcommand{\\gm}{\\mu}\n%\\newcommand{\\gn}{\\nu}\n%\\newcommand{\\gx}{\\xi}\n%\\newcommand{\\pi}{\\pi}\n%\\newcommand{\\gr}{\\rho}\n%\\newcommand{\\sigma}{\\sigma}\n%\\newcommand{\\tau}{\\tau}\n%\\newcommand{\\pih}{\\varphi}\n%\\newcommand{\\gch}{\\chi}\n%\\newcommand{\\pis}{\\psi}\n%\\newcommand{\\go}{\\omega}\n%\\newcommand{\\sigma}{\\Sigma}\n%\\newcommand{\\gL}{\\Lambda}\n\\newcommand{\\e}{\\mathsf e}\n%\\newcommand{\\dd}{\\mathsf d}\n\\newcommand\\TTTT{\n\\textsf{T\\kern-0.15em\\raisebox{-0.55ex}T\\kern-0.15emT\\kern-0.15em\\raisebox{-0.55ex}2}}\n\n\\DeclareRobustCommand{\\subtitle}[1]{\\\\#1}\n\\newtheorem{fact}{Fact}\n\\newtheorem{proposition}{Proposition}\n\\newtheorem{corollary}{Corollary}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n\\newtheorem{definition}{Definition}\n\\newtheorem{example}{Example}\n\\newtheorem{remark}{Remark}\n\\newtheorem{claim}{Claim}\n\\newcommand{\\blue}[1]{ {\\color{blue}#1}}\n\\newcommand{\\red}[1]{ {\\color{red}#1}}\n\\newcommand{\\purple}[1]{ {\\color{purple}#1}}\n\n%\\input macro-salibra\n\n\n\\title{An algebraic theory of clones\\subtitle{\\small with an application to a question of Birkhoff and Maltsev}}\n%Clone Algebras and Lattices of Equational Theories\\\\\n%An algebraic theory of clones with an application\\\\ to a question of Birkhoff and Maltsev\\\\\n%The lattice of equational theories problem\\\\\n%{\\tiny 29 Agosto 2020}%\\footnote{This work was partially supported by someone.}\n\n\n\n\n%% Please provide for each author the \\author and \\affil macro, even when authors have the same affiliation, i.e. for each author there needs to be the \\author and \\affil macros\n\\author{Antonio Bucciarelli}\n\\address{Institut de Recherche en Informatique Fondamentale,\nUniversit\\'e de Paris, 8 Place Aur\\'elie Nemours, 75205 Paris Cedex 13, France}\n\\email{buccia@irif.fr}\n\\urladdr{www.irif.fr/$\\sim$buccia} % Delete if not wanted.\n\n\\author{Antonino Salibra}\n\n\\address{Department of Environmental Sciences, Informatics and Statistics,\nUniversit\\`a Ca'Foscari Venezia, Via Torino 155, 30173 Venezia, Italia}\n\\email{salibra@unive.it}\n\\urladdr{www.dsi.unive.it/$\\sim$salibra}\n\n\\subjclass[2020]{08A40, 08A05, 08B05, 08B15}\n\\keywords{clones, clone algebras, functional clone algebras, $\\omega$-clones, representation theorem, lattices of equational theories}\n\n\\begin{document}\n\n\n\n\n\\begin{abstract}\n%are designed to algebraize\n%\n%Clone algebras constitute a purely one-sorted algebraic theory of clones in the same spirit as  Boolean algebras constitute an algebraic theory of classical propositional logic. \n%Like combinatory algebras they can be defined by true identities and thus form a variety in the sense of universal algebra. The most natural LAAs are obtained by coordinatizing environment models of the lambda calculus. This gives rise to two classesof LAAs of functions of finite arity: functional LAAs (FLA) and point-relatiuized functional LAAs (RFA). It is shown that RFA is a variety and is the smallest variety including FLA.\n%Dimension-complemented LAAs constitute the widest classof LAAs that can be representedas an algebra of functions and are known to have a natural intrinsic characterization. We prove that every dimension-complemented LAA is isomorphic to RFA. This is the crucial step in showing that RFA is a variety.\n%\n%Clones are sets of finitary operations on a given set that contain all the projections and are closed under composition.\n%They play an important role in universal algebra. Comparing clones of algebras is much more suitable than comparing their signatures, in order to classify algebras according to essentially different behaviours. In this paper we introduce an algebraic theory of clones. Indeed, the variety of clone algebras introduced here constitutes a purely one-sorted algebraic theory of clones in the same spirit as Boolean algebras constitute an algebraic theory of classical propositional logic.\n\n   We introduce the notion of clone algebra, intended to found a \none-sorted, purely algebraic theory of clones. Clone algebras are defined by true identities and thus form a variety in the sense of universal algebra.\nWe prove a representation \ntheorem establishing the pertinence of our proposal. Moreover, we use \nclone algebras\n  to answer a classical question about the lattices of\n  equational theories, and we sketch some other applications.\n  \n\n%  The problem of characterising the lattices of equational theories is still unsolved. In this paper we describe a class K of monoids enriched by two unary operations and show that a lattice L is a lattice of equational theories if and only if L is isomorphic to a lattice of congruences of some enriched monoid belonging to K.\n\\end{abstract}\n\n\\maketitle\n\n\\renewcommand{\\subtitle}[1]{}\n\n\n\n%q(0,x,y)=y.\n%q(1,x,y)=x.\n%q(x,1,0)=x.\n%q(q(x,y,z),y1,z1)=q(x,q(y,y1,z1),q(z,y1,z1)).\n%x ^ y = q(x,y,0).\n%x v y = q(x,1,y).\n%x'=q(x,0,1).\n%q(x,q(x,y,z),z) = q(x,y,z).\n%q(x,y,z) = q(x,y,q(x,y,z)).\n%x ^ x = x.\n%x v x = x.\n%q(y,x,x)=x.\n\n%\\aggiunta{problema ortografico: ``a $n$-tuple...'' vs  ``an $n$-tuple...'' (per esempio, ma anche ``a $n$-Church Algebra'' vs ``an $n$-Church Algebra''...). Usiamo a volte uno a volte l'altro, non \u00e9 chiaro quale sia giusto perche' la regola e' fonetica.}\n  \n%[representable functions should be representable operations?]\n\n%[Le operazioni di una RCA forse sarebbe meglio scriverle come quelle delle FCA]\n\\section{Introduction}\\label{sec:intro}\n%Clones are sets of finitary operations on a fixed  set that contain all projection operations and are closed under composition. They play an important role in universal algebra due to the fact that the set of all term operations of an algebra, always forms a clone. Moreover, important properties of algebras, like whether a subset forms a subalgebra, or a map is a homomorphism, depend only on the clone of term operations of an algebra, not on its specific fundamental operations. In this way comparing clones of algebras is much more suitable for classifying algebras according to essentially different behaviour than comparing algebras themselves (see \\cite{SZ86,T93}).\n\nClones are sets of finitary operations on a given set that contain all the projections and are closed under composition. They play an important role in universal algebra due to the fact that the set of all term operations of an algebra, always forms a clone. Moreover, important properties, like whether a given subset forms a subalgebra, or whether a given map is a homomorphism, do not depend on the specific fundamental operations of the considered algebra, but rather on the clone of its term operations. Hence, comparing clones of algebras is much more suitable than comparing their signatures, in order to classify them according to essentially different behaviours (see \\cite{SZ86,T93}).\n\n\n%Some attempts to have been made to encode clones into algebras  (see \\cite{T93}). The most important and well done is the concept of abstract clones  \\cite{Co65,T93}, which are many-sorted algebras axiomatising composition of finitary functions and projections. Every abstract clone has a concrete representation as an isomorphic clone of finitary operations  \\cite{Co65}. Modulo a caveat about nullary operations, we remark that abstract clones are in turn just a slight reformulation of the concept of Lawvere's algebraic theories \\cite{Law63}. The latter constitutes a common category theoretic means to capture equational theories invariantly of their presentation (i.e. of the chosen similarity type).\n\nSome attempts  have been made to encode clones into algebras. A particularly important one led to  the concept of abstract clones  \\cite{Co65,T93}, which are many-sorted algebras axiomatising composition of finitary functions and projections. Every abstract clone has a concrete representation as an isomorphic clone of finitary operations. Modulo a caveat about nullary operations, we remark that abstract clones may be recasted as a reformulation of the concept of Lawvere's algebraic theories \\cite{Law63}.\nThe latter constitutes a common category theoretic means to capture equational theories independently of their presentation (i.e. of the chosen similarity type).\n\n\n%There is a thriving literature on abstract treatments of the if-then-else construct of computer science, starting with McCarthy's seminal investigations \\cite{MC}. On the algebraic side, one of the most influential approaches originated with Dicker's axiomatisation of Boolean algebras in the language with the if-then-else as primitive \\cite{D63}. Accordingly, this construct was treated as a proper algebraic operation $q_2^\\mathbf A$ of arity three on algebras $\\mathbf A$ whose type contains, besides the ternary term $q_2$, two constants $0$ and $1$, and having the property that for every $a, b\\in A$, $q_2^\\mathbf A(1^\\mathbf A, a, b) = a$ and $q_2^\\mathbf A(0^\\mathbf A, a, b) = b$. Such algebras, called Church algebras of dimension $2$ in \\cite{Bucciasali}, will be termed here $2$-Church algebras.\n%This approach was generalised in \\cite{BLPS18} (see also \\cite{Bucciasali,SBLP20}) to algebras $\\mathbf A$ having $n$ designated elements $\\e_1,\\dots, \\e_n$ ($n\\geq  2$) and an $n + 1$-ary operation $q_n$ (a sort of ``generalised if-then-else'') satisfying the identities $q_n(\\e_i,a_1,\\dots,a_n)=a_i$. These algebras will be called here $n$-Church algebras.\n\n\nSomehow unexpectedly, some recent work at the frontier of theoretical computer science and universal algebra provides  tools for\ngiving an alternative algebraic account of clones.\nThere is a thriving literature on abstract treatments of the if-then-else construct of computer science, starting with McCarthy's seminal investigations \\cite{MC}. On the algebraic side, one of the most influential approaches originated with Dicker's axiomatisation of Boolean algebras in the language with the if-then-else as primitive \\cite{D63}. Accordingly, this construct was treated as a proper algebraic operation $q_2^\\mathbf A$ of arity three on algebras $\\mathbf A$ whose type contains, besides the ternary term $q_2$, two constants $0$ and $1$, and having the property that for every $a, b\\in A$, $q_2^\\mathbf A(1^\\mathbf A, a, b) = a$ and $q_2^\\mathbf A(0^\\mathbf A, a, b) = b$. Such algebras, called Church algebras of dimension $2$ in \\cite{Bucciasali}, will be termed here $2$-Church algebras.\nThis approach was generalised in \\cite{BLPS18} (see also \\cite{Bucciasali,SBLP20}) to algebras $\\mathbf A$ having $n$ designated elements $\\e_1,\\dots, \\e_n$ ($n\\geq  2$) and a $(n + 1)$-ary operation $q_n$ (a sort of ``generalised if-then-else'') satisfying the identities $q_n(\\e_i,a_1,\\dots,a_n)=a_i$. These algebras will be called here $n$-Church algebras.\n\n\n\n\nAt the root of the most important results in the theory of Boolean algebras (including Stone's representation theorem) there is the simple observation that every element $c\\neq 0, 1$ of a Boolean algebra $B$ decomposes $B$ as a Cartesian product $[0, c]\\times [c, 1]$ of two nontrivial Boolean algebras. In the more general context of $n$-Church algebras, we say that an element $c$ of an $n$-Church algebra $\\mathbf A$ is $n$-central if $\\mathbf A$ can be decomposed as the product $\\mathbf A/\\theta(c, \\e_1)\\times\\dots\\times \\mathbf A/\\theta(c, \\e_n)$, where $\\theta(c, \\e_i)$ is the smallest congruence on $\\mathbf A$ that collapses $c$ and $\\e_i$. An $n$-Church algebra where every element is $n$-central, called Boolean-like algebra of dimension $n$ in \\cite{BLPS18}, will be termed here $n$-Boolean-like algebra ($n$BA, for short). \nVarieties of nBAs share many remarkable properties with the variety of Boolean algebras. In particular, any variety of nBAs is generated by the nBAs of finite cardinality $n$. In the pure case (i.e., when the type includes just the generalised if-then-else $q_n$ and the $n$ constants), the variety is generated by a unique algebra $\\mathbf n$ of universe $\\{\\e_1,\\dots, \\e_n \\}$, so that any pure nBA is, up to isomorphism, a subalgebra of $\\mathbf n^X$, for a suitable set $X$. The variety of all $2$BAs in the type $(q_2,0,1)$ is term-equivalent to the variety of Boolean algebras. \n\n%Let $\\mathbf F_\\mathcal V$ be the free algebra over the generators $v_1,\\dots,v_n,\\dots$ in the variety $\\mathcal V$. Following \\cite[Definition 3.2]{mac2},  we define  an $n+1$-ary operation $q_n^\\mathbf F$ on $\\mathbf{F}_\\mathcal{V}$ as follows:\n%\\begin{equation}\\label{eq:qqq} q_n^\\mathbf F(a,b_1,\\dots,b_n)=s(a)\\quad\\text{for all $a,b_1,\\dots,b_n\\in F_\\mathcal{V}$,}\\end{equation}\n%where $s$ is the unique endomorphism of $\\mathbf{F}_\\mathcal{V}$ which sends the generator $ v_i$ to $b_i$ ($1\\leq i\\leq n$). More suggestively, $q_n^\\mathbf F(a,b_1,\\dots,b_n)$ is the element of $F_\\mathcal V$ obtained by substituting $b_i$ for $v_i$ into $a$ ($1\\leq i\\leq n$). Then, the algebra $(\\mathbf F_\\mathcal V,q_n^\\mathbf F, v_1,\\dots,v_n)$ is an $n$-Church algebra.\n\n\n%In this paper we introduce  a one-sorted purely algebraic theory of clones. \n%By abstracting variables and term-for-variable substitution in free algebras and,  projections and functional composition in clones, \n%we introduce the variety of clone algebras  ($\\mathsf{CA}$) which constitutes a purely algebraic theory of clones in the same spirit that Boolean algebras constitute an algebraic theory of classical propositional logic. \n%Clone algebras of a given similarity type $\\tau$ ($\\mathsf{CA}_\\tau$s) are defined by universally quantified equations and thus form a variety in the universal algebraic sense. \n%%The type of clone $\\tau$-algebras, besides the operators of $\\tau$, include countable infinite  nullary operators $\\e_i$, abstracting variables in free algebras and projections in ,  and, for every $n\\geq 0$, an operator $q_n$ of arity $n+1$.\n%The operators of type $\\tau$ are taken as fundamental operations in $\\mathsf{CA}_\\tau$s.\n%A crucial feature of our approach is connected with the role variables (or projections) play in clone algebras as place holders. In a $\\mathsf{CA}_\\tau$ this is also abstracted. It takes the form of a system of fundamental elements (nullary operations) $\\e_1,\\e_2,\\dots,\\e_n,\\dots$ of the algebra. This is a crucial feature of $\\mathsf{CA}_\\tau$s that is borrowed from algebraic logic, namely cylindric and polyadic algebras and lambda abstraction algebras. One important consequence of the abstraction of variables is the abstraction of term-for-variable substitution in $\\mathsf{CA}_\\tau$s by introducing an $n+1$-ary operator $q_n$, for every $n\\geq 0$.\n%Roughly speaking, $q_n(a,b_1,\\dots,b_n)$ abstracts both the operation of substitution of $b_i$ for $\\e_i$ into $a$ ($i=1,\\dots, n$), and the composition of the ``function''  $a$ by the ``functions'' $b_1,\\dots,b_n$. \n%Thus every clone algebra is an $n$-Church algebra, for every $n$.\n%We point out that each element of a clone algebra can be assigned a finite or infinite dimension that abstracts the notion of the arity of a function. \n%A $\\mathsf{CA}$ is  finite-dimensional if each of its elements is finite-dimensional. \n\nIn the framework of  $n$-Church and $n$-Boolean like  algebras, the constants \n$\\e_i$ and the $n+1$-ary operation $q_n$ represent the generalised truth-values and the generalised conditional operation, respectively.\nMore generally, these constants and operation allow to express neatly other fundamental algebraic concepts as one-sorted,  purely algebraic theories.\nThese include in particular: (i) variables and term-for-variable substitution in free algebras on one side, and (ii) projections and functional composition in clones on the other.\n\nBuilding up on this observation, we introduce  in this paper an algebraic theory of clones. \n%In this paper we introduce  a one-sorted purely algebraic theory of clones. \n%By abstracting\n%\n% \n% - variables and term-for-variable substitution in free algebras on one side, and\n%\n%  - projections and functional composition in clones on the other, \nIndeed, the variety of clone algebras  ($\\mathsf{CA}$) introduced here  constitutes a purely one-sorted algebraic theory of clones in the same spirit as  Boolean algebras constitute an algebraic theory of classical propositional logic. \nClone algebras of a given similarity type $\\tau$ ($\\mathsf{CA}_\\tau$s) are defined by universally quantified equations and thus form a variety in the universal algebraic sense. \n%The type of clone $\\tau$-algebras, besides the operators of $\\tau$, include countable infinite  nullary operators $\\e_i$, abstracting variables in free algebras and projections in ,  and, for every $n\\geq 0$, an operator $q_n$ of arity $n+1$.\nThe operators of type $\\tau$ are taken as fundamental operations in $\\mathsf{CA}_\\tau$s.\n%A crucial feature of our approach is connected with the role variables (or projections) play in clone algebras as placeholders. In a $\\mathsf{CA}_\\tau$ this is also abstracted. It takes the form of a system of fundamental elements (nullary operations) $\\e_1,\\e_2,\\dots,\\e_n,\\dots$ of the algebra. This is an important feature of $\\mathsf{CA}_\\tau$s that is borrowed from algebraic logic, namely cylindric and polyadic algebras and lambda abstraction algebras (see \\cite{HMT,SG99}).\nA crucial feature of our approach is connected with the role played by variables in algebras (resp. by projections in clones)  as placeholders. In clone algebras this is abstracted out, and takes the form of a system of fundamental elements (nullary operations) $\\e_1,\\e_2,\\dots,\\e_n,\\dots$ of the algebra.This  important feature is borrowed from algebraic logic, namely cylindric and polyadic algebras and from lambda abstraction algebras (see \\cite{HMT,SG99}).\nOne important consequence of the abstraction of variables is the abstraction of term-for-variable substitution (or functional composition) in $\\mathsf{CA}_\\tau$s, obtained by introducing an $n+1$-ary operator $q_n$ for every $n\\geq 0$.\nRoughly speaking, $q_n(a,b_1,\\dots,b_n)$  represents\nthe substitution of $b_i$ for $\\e_i$ into $a$ for $1\\leq i\\leq n$ (or the composition of  $a$ with  $b_1,\\dots,b_n$). \nEvery clone algebra is an $n$-Church algebra, for every $n$.\n\n The most natural $\\mathsf{CA}$s, the ones the axioms are intended to characterise, are algebras of functions, called \\emph{functional clone algebras}. \n The elements of a functional clone algebra are infinitary operations from $A^\\omega$ into $A$, for a given set $A$. In this framework  $q_n(f,g_1,\\dots,g_n)$ represents the $n$-ary composition of $f$ with $g_1,\\dots,g_n$, acting on the first $n$ coordinates:\n $$q_n(f,g_1,\\dots,g_n)(s)= f(g_1(s),\\dots,g_n(s),s_{n+1},s_{n+2},\\dots),\\ \\text{for every $s\\in A^\\omega$}$$\n and the nullary operators are the projections $p_i$ defined by $p_i(s)=s_i$ for every $s\\in A^\\omega$.\nHence, the universe of a functional clone algebra is a set of infinitary operations containing the projection $p_i$ and closed under finitary compositions, called hereafter \\emph{$\\omega$-clone}. We show that there exists a bijective correspondence between clones (of finitary operations) and a suitable subclass of functional clone algebras, called \\emph{block algebras}.  Given a clone $C$, the corresponding block algebra is obtained by extending the operations of the clone by countably many dummy arguments.\nIf $f\\in C$ has arity $k$, then the top expansion  of $f$ is an infinitary operation $f^\\top:A^\\omega\\to A$:\n$$f^\\top(s_1,s_2,\\dots,s_k,s_{k+1},\\dots)=f(s_1,\\dots,s_k),\\quad \\text{for every $(s_1,s_2,\\dots,s_k,s_{k+1}\\dots)\\in S^\\omega$}.$$ \nBy collecting all these top expansions in a set $C^\\top=\\{f^\\top: f\\in C\\}$, we get a functional clone algebra, called block algebra.\nIn the first representation theorem of the paper we show that the ``concrete'' notion of block algebra coincides, up to isomorphism, with  the abstract notion of finite-dimensional clone algebra, where a clone algebra is finite-dimensional if each of its elements can be assigned a finite dimension, generalising the notion of arity to infinitary functions.\n\n%that abstracts the notion of the arity of a function.\n\nThe axiomatisation of functional clone algebras is a central issue in the algebraic approach to clones.\n We say that a clone algebra is functionally representable if it is isomorphic to a functional clone algebra. One of the main results of this paper is the general representation theorem, where it is shown that every $\\mathsf{CA}$ is functionally representable. \n Therefore, the  clone algebras are the full algebraic counterpart of $\\omega$-clones, while the block algebras are the algebraic counterpart of clones.\n%Therefore, the theory of $\\omega$-clones is equationally axiomatisable through the finite schema of identities defining the variety of clone algebras. \n In another result of the paper we prove that  the variety of clone algebras is generated by the class of block algebras. This implies that every $\\omega$-clone is algebraically generated by a suitable family of clones by using direct products, subalgebras and homomorphic images.\n\nWe conclude the paper with two applications. The first one is to the lattice of equational theories problem stated by Birkhoff \\cite{bir2} in 1946: Find an algebraic characterisation of those lattices which can be isomorphic to  a lattice of equational theories. Maltsev \\cite{mal} was instrumental in attracting attention to this problem, which is sometimes referred to as Maltsev's Problem. This problem is still open, but work on it has led to many results described in \\cite[Section 4]{nulty}.\n\nThe problem of characterising the lattices of equational theories as the congruence lattices of a class of algebras was tackled by Newrly \\cite{newrly} and Nurakunov \\cite{nur}. \n%Newrly shows that a lattice of equational theories is the congruence lattice of an algebra whose fundamental operations consist of one monoid operation with right zero and one unary operation. In \\cite{nur} Nurakunov describes a class of monoids enriched by two unary operations, the so-called Et-monoids, and proves that a lattice of equational theories is  the congruence lattice of some Et-monoid. \n%Nevertheless there is no equational axiomatisation of the varieties of algebras generated by Newrly's monoids and by  Nurakunov's Et-monoids.\nIn this paper we propose an alternative  answer to the lattice of equational theories problem. We prove that a lattice is isomorphic to a lattice of equational theories if and only if it is isomorphic to the lattice of all congruences of a finite dimensional clone algebra. Unlike in Newrly's and Nurakunov's approaches, we are able to provide  the equational axiomatisation of the variety whose congruence lattices are exactly the lattices of equational theories, up to isomorphisms.\nWe also show that a lattice is isomorphic to a lattice of subclones if and only if it is isomorphic to the lattice of subalgebras of a finite dimensional clone algebra.\n\n\nThe second application is to the study of the category $\\mathcal{VAR}$ of all varieties. \nWe say that a clone algebra is \\emph{pure} if it is an algebra in the type of  the nullary operators $\\e_1,\\e_2,\\dots$ and of the operators $q_n$ ($n\\geq 0$).\nThe \\emph{pure reduct} of a clone algebra of type $\\tau$ is a pure clone algebra. It is worth mentioning that  \nimportant properties of a variety depend on the pure reduct of the clone algebra associated to its free algebra.\nAfter characterising central elements in clone algebras, we introduce the concept of a minimal clone algebra.  We show that a clone  algebra $\\mathbf C$ of type $\\tau$ is minimal if and only if the $\\tau$-reduct $\\mathbf C_\\tau$ of $\\mathbf C$  is the free algebra over a countable set of generators in the variety generated by $\\mathbf C_\\tau$. We introduce the category $\\mathcal{CA}$ of all clone algebras (of arbitrary similarity types) with pure homomorphisms (i.e., preserving only the nullary operators $\\e_i$ and the operators $q_n$) as arrows and show that $\\mathcal{CA}$ is equivalent both to the full subcategory $\\mathcal{MCA}$ of minimal clone algebras and, more to the point, to the full subcategory $\\mathcal{CA}_0$ of pure clone algebras.\nMoreover, we show that $\\mathcal{MCA}$ is isomorphic to $\\mathcal{VAR}$ as a category. This result allows us to directly use $\\mathcal{MCA}$ to get results in $\\mathcal{VAR}$. We conclude the paper by showing  that the category $\\mathcal{MCA}$ is closed under categorical products and use this result and central elements to provide a generalisation of the theorem on independent varieties presented by Gr\\\"atzer et al. in \\cite{GLP}.\n\n\n\\subsection{Plan of the work}\nIn Section \\ref{sec:prelim} we present some preliminary notions, \nincluding those of factor congruence and decomposition operator, and  those of \nChurch and Boolean-like algebra, less well known; we also expose the Birkhoff and Maltsev's \nproblem and sketch some related work. In Section \\ref{sec:clo} we introduce the notion of a clone with nullary operations;\nwe also recall abstract clones.\nSection \\ref{sec:clonAlg} introduces the clone algebras, that we propose as an algebraic one-sorted\ncounterpart of clones. In Sections \\ref{sec:dueuno} and \\ref{sec:clones} we present two prototypical classes \nof clone algebras: functional clone algebras, whose carriers are named $\\omega$-clones, and block algebras. Those are algebras of infinitary operations. The former are uncostrained, and in particular they may be sensible to countably many arguments, whereas the latter are finite dimensional, since they are obtained by suitable extensions, called top extensions, of finitary operations.\nWe show that there is a bijection between clones and block algebras.\nIn Section \\ref{sec:rep} we introduce the representable (finitary) operations\ninside a clone algebra, which are those operations whose behaviour is univocally determined by an element of the algebra, via the operators $q_n$.\nThe representable operations of $\\mathbf C$ turn out to be a clone and the top extension of this clone is a block algebra, \nisomorphic to a finite dimensional subalgebra of $\\mathbf C$. \nThis subalgebra coincides with $\\mathbf C$ whenever $\\mathbf C$ is finite dimensional. \nSince all the basic operation of a clone algebra are representable, there is no loss of information in replacing each of them \nwith the corresponding element: we show in Section \\ref{sec:nullary} that the variety \nof clone $\\tau$-algebras and that of clone algebras with $\\tau$-constants are term equivalent.\nIn Section \\ref{sec:GRT} we prove the main representation theorem, \nindicating the pertinence of our approach to the theory of clones.\nIt can be summarized as follows:\nthe variety of clone algebras is the algebraic counterpart of $\\omega$-clones, \nthe class of block algebras is the algebraic counterpart of clones, and the $\\omega$-clones\nare algebraically generated by clones through direct products, subalgebras and \nhomomorphic images. In other words, the variety of clone algebras is generated by the class of block algebras.\nSection \\ref{sec:eqth} presents an application of clone algebras to the Birkhoff and Maltsev's \nproblem: we prove that a lattice is isomorphic to a lattice of equational theories if and only if it is isomorphic \nto the lattice of all congruences of a finite dimensional clone algebra.\nThe last section of the paper is devoted to some applications of the theory of clone algebras to the study of the category of all varieties. In the conclusions we present some directions for future work.\n\n\n\n\n\\section{Preliminaries}\\label{sec:prelim}\n\nThe notation and terminology in this paper are pretty standard. For\nconcepts, notations and results not covered hereafter, the reader is\nreferred to \\cite{BS,Co65,mac} for universal algebra and to \\cite{L06,SZ86,T93} for the theory of clones. \n\n\\bigskip\n\nIn this paper $\\omega=\\{1,2,\\dots\\}$ denotes the set of positive natural numbers.\n\nBy an \\emph{operation} on a set $A$ we will always mean a finitary operation (i.e., a function $f:A^n\\to A$ for some $n\\geq 0$), and by an \\emph{infinitary operation} on $A$ we mean a function from $A^\\omega$ into $A$.\nAs a matter of notation, operations will be denoted by the letters $f,g,h,\\dots$ and infinitary operations by the greek letters $\\varphi,\\psi,\\chi,\\dots$.\n\n\n\nWe denote by $\\mathcal{O}_A$  the set of all operations on a set $A$, and by $\\mathcal{O}_A^{(\\omega)}$ the set of all infinitary operations on $A$. If \n$F\\subseteq\\mathcal{O}_A $, then $F^{(n)}= \\{f:A^n\\to A\\ |\\ f\\in  F\\}$. \n\nIn the following we fix a countable infinite set $I=\\{v_1, v_2,\\dots,  v_n,\\dots\\}$ of \\emph{indeterminates or variables} that we assume totally ordered: $v_1 < v_2 <\\dots < v_n<\\dots$.\n\n%Let $A$ be a set and $m=(m_{ij})\\in A^{\\omega\\times\\omega}$ be a  matrix. In the following we denote by \n%$m_i\\in A^\\omega$ the row sequence defined by $m_i(k)=m_{ik}$\n%and by  $m^j\\in A^\\omega$ the column sequence defined by $m^j(k)=m_{kj}$.\n\n\\subsection{Algebras}\\label{sec:alg}\nIf $\\tau$ is an algebraic type, an algebra $\\mathbf{A}$ of type $\\tau $ is\ncalled \\emph{a }$\\tau $\\emph{-algebra}, or simply an algebra when $\\tau $ is\nclear from the context. An algebra is \\emph{trivial} if its carrier set is a singleton set.\n\nSuperscripts that mark the difference between operations and operation symbols will be dropped whenever the context is sufficient for a disambiguation. \n\nIf $t$ is a $\\tau$-term, then we write $t=t(v_1,\\dots,v_n)$ if $t$ can be built up starting from variables $v_1,\\dots,v_n$.\nNot all variables $v_1,\\dots,v_n$ may occur in $t$. If $t=t(v_1,\\dots,v_n)$, then $t=t(v_1,\\dots,v_m)$ for every $m\\geq n$.\nA term is \\emph{ground} if no variable occurs in it. \n\nWe denote by $T_{\\tau}(\\omega)$ the set of  $\\tau$-terms over the countable infinite set $I$ of variables.\n\n\n\n$\\mathrm{Con}\\,\\mathbf{A}$ is the lattice of all\ncongruences on $\\mathbf{A}$, whose bottom and top elements are,\nrespectively, $\\Delta =\\{(a,a):a\\in A\\}$ and $\\nabla =A\\times A$. \nGiven $a,b\\in A$, we write $\\theta(a,b)$ for the smallest congruence $\\theta$\nsuch that $( a,b) \\in \\theta $.\n\nWe say that an algebra $\\mathbf{A}$ is \\emph{directly indecomposable} if $\\mathbf{A}$ is not isomorphic to a direct product of two nontrivial algebras.\n\nClosure under  homomorphic images, direct products, subalgebras and  isomorphic images is denoted by $\\mathbb{H}$, $\\mathbb{P}$, $\\mathbb{S}$ and $\\mathbb{I}$ respectively.\nWe denote by $\\mathbb{U}_p$ the closure under ultraproducts.\n\nA class $\\mathcal{V}$ of $\\tau$-algebras is a \\emph{variety} if it is closed\nunder subalgebras, direct products and homomorphic images, i.e., $\\mathcal{V}= \\mathbb{HSP}(\\mathcal{V})$.\nThe variety $\\mathrm{Var}(K)$ generated by a class $K$ of $\\tau$-algebras is the smallest variety including $K$: $\\mathrm{Var}(K)= \\mathbb{HSP}(K)$.\n If $K=\\{\\mathbf A\\}$ we write $\\mathrm{Var}(\\mathbf A)$ for $\\mathrm{Var}(\\{\\mathbf A\\})$.\nBy Birkhoff's theorem $\\mathrm{Var}(K)$ coincides with the class of algebras  satisfying all the identities satisfied by $K$.\n\nIf $\\mathcal V$ is a variety, then we denote by $\\mathbf F_\\mathcal V$ its free algebra over the countable infinite set\n$I$ of generators.\n\n\nRecall that $n$ subvarieties $\\mathcal V_1,\\dots,\\mathcal V_n$ of a variety $\\mathcal V$ of type $\\tau$ are said to be\n%\\begin{itemize}\n%\\item \\emph{disjoint}, if their intersection is the trivial algebra of type $\\tau$;\n \\emph{independent}, if there exists a term $t(v_1,\\dots,v_n)$ of type $\\tau$, containing at most the\nindicated variables, such that $\\mathcal V_i\\models t(v_1,\\dots,v_n)=v_i$ ($i=1,\\dots,n$).\n%\\end{itemize}\nMoreover,  the \\emph{product of similar varieties} $\\mathcal V_1,\\dots,\\mathcal V_n$ is\ndefined as $\\mathcal V_1\\times\\dots\\times \\mathcal V_n =\\mathbb{I}\\,\\{\\mathbf A_1\\times\\dots\\times\\mathbf A_n  :\\mathbf A_i \\in \\mathcal V_i\\}$. We have $\\mathcal V_1\\times\\dots\\times \\mathcal V_n\\subseteq \\mathcal V_1\\lor\\dots\\lor \\mathcal V_n$.\n\n%In the same vein, we  define the \\emph{subdirect product of  similar varieties} $\\mathcal V_1,\\dots,\\mathcal V_n$ as the class $\\mathcal V_1\\times_s\\dots\\times_s \\mathcal V_n$ of all algebras that can be subdirectly embedded into a product $\\mathbf A_1\\times\\dots\\times \\mathbf A_n$, for some $\\mathbf A_1 \\in \\mathcal V_1,\\dots, \\mathbf A_n \\in \\mathcal V_n$.\n\nFollowing Blok and Pigozzi \\cite{BP}, $n$ elements ($n\\leq \\omega$) of an algebra $\\mathbf{A}$ are said to be \\emph{residually distinct} if they have distinct images in every non-trivial homomorphic image of $\\mathbf{A}$. \nA variety $\\mathcal V$ is \\emph{$n$-pointed} ($n\\leq \\omega$) if it has $n$ nullary operators  that are residually distinct in any nontrivial member of $\\mathcal V$. Boolean algebras are the main example of a double-pointed variety.\n\n\n%An algebra $\\mathbf A$ is said to have \\emph{factorable congruences} if whenever $\\mathbf A = \\mathbf B\\times \\mathbf C$ and $\\theta$ is a congruence on $\\mathbf A$, then $\\theta =\\theta_1 \\times \\theta_2$, where $\\theta_1$ is a congruence on $\\mathbf B$ and $\\theta_2$ is a congruence on $\\mathbf C$. Recall that $((b,c),(b',c'))\\in \\theta_1 \\times \\theta_2$ iff $(b,b')\\in \\theta_1$ and $(c,c')\\in \\theta_2$. \n\n%In other words, if $\\mathbf A = \\mathbf B\\times \\mathbf C$ and f is a homomorphism of $\\mathbf A$ onto an algebra $\\mathbf D$, there are homomorphisms $g$ of $\\mathbf B$ onto an algebra $\\mathbf E$ and $h$ of $\\mathbf C$ onto an algebra $F$ such that $\\mathbf D = \\mathbf E\\times  \\mathbf F$ and $f = i\\circ  (g, h)$, where $i$ is an isomorphism of $\\mathbf E\\times  \\mathbf F$ onto $\\mathbf D$; i.e., the operations of forming homomorphic images and finite Cartesian products permute. \n\n%\\blue{Varieties of  algebras in which every algebra has factorable congruences were characterised via Maltsev conditions by Fraser and Horn \\cite{FH}. \n%Examples of varieties with factorable congruences are congruence distributive varieties, congruence permutable varieties in which the universal congruences are\n%compact (varieties of rings with unit, for example) and Church varieties defined in Section \\ref{dobbiaco}.}\n\n\n%\\subsection{Free extensions} \n%Let $\\mathbf A$ be a $\\tau$-algebra and let $\\oa$ be a constant for each element $a \\in A$. \n%\n%We extend the similarity type $\\tau$ to $\\tau_A$ by adding a constant $\\oa$ for each element $a$ of $A$.\n%\n%\\begin{definition}\n%The {\\em equational diagram} $\\Delta_A$ of $\\mathbf A$ is defined as the set of equations $\\sigma(\\oa_1,\\dots,\\oa_k)=\\ob$ for all $a_1,\\dots,a_k,b \\in A$ such that $\\sigma^\\mathbf A(a_1,\\dots,a_k)=b$ holds in $\\mathbf A$. \n%\\end{definition}\n%\n%Free extensions of algebras by a set $I$ are characterised in the following proposition.\n%\n%\\begin{proposition} Let $\\mathcal V$ be a variety of $\\tau$-algebras and $\\mathbf A\\in \\mathcal V$.\n%Then the following conditions are equivalent:\n%\\begin{itemize}\n%\\item $\\mathbf A[I]$ is the free extension of $\\mathbf A$ by $I$ in the variety $\\mathcal V$;\n%\\item $\\mathbf A[I]$ is an expansion of $\\mathbf A$ defined up to isomorphism by the following conditions: $I \\subseteq A[I]$; \n%$\\mathbf A[I]\\in\\mathcal V$; \n%for every homomorphism $h: \\mathbf A \\to \\mathbf B\\in \\mathcal V$ and every mapping \n%$g: I \\to B$ there exists a unique homomorphism $f: \\mathbf A[I] \\to \\mathbf B$ extending both $h$ and $g$. \n%\\item $\\mathbf A[I]$ is the free algebra with a set $I$ of generators in the variety of $\\tau_A$-algebras axiomatised by $Eq(\\mathcal V) \\cup \\Delta_A$.\n%\\end{itemize}\n%\\end{proposition}\n%\n%\n%The elements of $\\mathbf A[I]$ are equivalence classes  of $\\tau_A$-terms. \n%We have that two $\\tau_A$-terms $t,u$ are equivalent iff $Eq(\\mathcal V) \\cup \\Delta_A\\vdash t=u$.\n%\n\n\n\\subsection{Factor Congruences and Decomposition}\\label{sec:fcd}\nDirectly indecomposable algebras play an important role in the characterisation of the structure of a variety of\nalgebras.\nFor example, if the class\nof  indecomposable algebras in a $2$-Church variety (see Section \\ref{dobbiaco}) is universal, then any algebra in the variety is\na weak Boolean product of  directly indecomposable algebras \\cite{first}.\nIn this section we summarize the basic ingredients of factorisation:\ntuples of complementary factor congruences\nand  decomposition operators (see  \\cite{mac}).\n\n\\begin{definition}\\label{def:cong} \nA sequence $(\\theta_{1},\\dots,\\theta_n)$ of congruences on a $\\tau$-algebra $\\mathbf{A}$ is an $n$-tuple of complementary factor congruences exactly when:\n\\begin{enumerate}\n\\item $\\bigcap_{1\\leq i\\leq n}\\theta_{i}=\\Delta$;\n\n\\item $\\forall (a_1,\\dots,a_n)\\in A^n$, there is a unique $u\\in A$ such that $a_i\\theta_{i}\\,u$,\nfor all $1\\leq i\\leq n$.\n\\end{enumerate}\n\\end{definition}\n%Such an element $u$ such that $a_i\\theta_{i}\\,u$ for every $i$ is unique by Definition \\ref{def:cong}(1).\n\n\nIf $(\\theta_{1},\\dots,\\theta_n)$  is an $n$-tuple of complementary factor congruences on $\\mathbf{A}\n$, then the function\n$f:\\mathbf{A}\\rightarrow \\prod\\limits_{i=1}^n\\mathbf{A}/\\theta _{i}$,\ndefined by $f(a) =(a/\\theta _{1},\\dots,a/\\theta _{n})$, is an\nisomorphism. Moreover, every factorisation of $\\mathbf A$ in $n$ factors univocally determines an $n$-tuple of complementary factor congruences.\n\n\nA pair  $(\\theta_{1},\\theta_{2})$ of congruences is a pair of complementary factor\ncongruences if and only if $\\theta_{1}\\cap\\theta_{2}=\\Delta$ and $\\theta_{1}\\circ\\theta_{2}=\\nabla$. \nThe pair $(\\Delta,\\nabla)$ corresponds to the product $\\mathbf{A}\\cong\\mathbf{A}\\times\\mathbf{1}$, where $\\mathbf{1}$ is a trivial algebra; obviously $\\mathbf{1}\\cong\\mathbf{A}/\\nabla$ and $\\mathbf{A}\\cong\\mathbf{A}/\\Delta$. \n\nA \\emph{factor congruence} is any congruence which belongs to a pair of\ncomplementary factor congruences. \nThe set of factor congruences of $\\mathbf A$ is not, in general, a sublattice of $\\mathrm{Con}\\,\\mathbf{A}$.\nAn algebra has \\emph{Boolean factor congruences} if the factor congruences form a Boolean sublattice of the congruence lattice. %Most known examples of varieties in which all algebras have Boolean factor congruences are those with factorable congruences.\n\n\n\nNotice that, if $(\\theta_{1},\\dots,\\theta_n)$ is an $n$-tuple of complementary factor congruences, then $\\theta_i$ is a factor congruence for each $1\\leq i\\leq n$, because\nthe pair $(\\theta_i, \\bigcap_{j\\neq i} \\theta_j)$ is a pair of complementary factor congruences. \n\nIt is possible to characterise $n$-tuples of complementary factor congruences in terms of certain algebra\nhomomorphisms called \\emph{decomposition operators} (see \\cite[Def.~4.32]{mac} for additional details). \n\n\\begin{definition}\n\\label{def:decomposition} \nAn \\emph{$n$-ary decomposition operator} on a $\\tau$-algebra $\\mathbf{A}$ is a function $f:A^{n}\\rightarrow A$ satisfying the following conditions: \n\\begin{description}\n\\item[D1] $f( x,x,\\dots,x) =x$;\n\\item[D2] $f( f( x_{11},x_{12},\\dots,x_{1n}),\\dots,f(x_{n1},x_{n2},\\dots,x_{nn}))=f(x_{11},\\dots,x_{nn})$;\n\\item[D3] $f$ is an algebra homomorphism from $\\mathbf{A}^n$ onto $ \\mathbf{A}$:\n\\end{description}\n$$f(\\sigma^\\mathbf A(x_{11},x_{12},\\dots,x_{1k}),\\dots, \\sigma^\\mathbf A(x_{n1},x_{n2},\\dots,x_{nk})) = \\sigma^\\mathbf A(f(x_{11},\\dots,x_{n1}),\\dots, f(x_{1k},\\dots,x_{nk})),$$ for every $\\sigma\\in \\tau$ of arity $k$.\n\\end{definition}\n\n\nThere is a bijective correspondence between $n$-tuples of complementary factor\ncongruences and $n$-ary decomposition operators, and thus, between $n$-ary decomposition\noperators and factorisations of an algebra in $n$ factors.\n\nIf $f:A^n\\to A$ is a function, then we denote by $f_i:A^2\\to A$ the binary function defined as follows:\n$$f_i(x,y)= f(y,\\dots,y,x,y,\\dots,y)\\quad\\text{$x$ at position $i$}.$$\n\n\\begin{theorem}\n\\label{prop:pairfactor} Any $n$-ary decomposition operator $f:A^{n}\\rightarrow A$ on an algebra $\\mathbf{A}$ induces an $n$-tuple of\ncomplementary factor congruences $\\theta _{1},\\dots,\\theta _{n}$, where each $\\theta _{i}\\subseteq A\\times A$ is defined by: \n\\begin{equation*}\na\\ \\theta _{i}\\ b\\ \\ \\text{iff}\\ \\ f_i(b,a)=a.\n\\end{equation*}\nMoreover, $f(x_1,\\dots,x_n)$ is the unique element such that $x_i \\theta_i f(x_1,\\dots,x_n)$ for all $i$.\nConversely, any $n$-tuple $\\theta _{1},\\dots,\\theta _{n}$ of complementary factor\ncongruences induces a decomposition operator $f$ on $\\mathbf{A}$: \n$f(a_1,\\dots,a_n)=u$ iff $a_{i}\\,\\theta _{i}\\,u$ for all $i$. \n\\end{theorem}\n\n%\\blue{\\begin{proof}  Let $f$ be an $n$-ary decomposition operator.\n% The kernel $\\phi$ of $f$ is a congruence on $\\mathbf A^n$ such that $\\mathbf A^n/\\phi \\cong \\mathbf A$. By (D1) the diagonal $\\{ (a,\\dots,a) \\in A^n: a \\in A\\}$ intersects each equivalence class in one element. By (D1)-(D2) the congruence $\\phi$ is the product of the $n$ congruences $\\phi _{1},\\dots,\\phi _{n}$ on $\\mathbf A$, because $f(a_1,\\dots,a_n)= f(b_1,\\dots,b_n)$ iff $f_i(b_i,a_i)= a_i$, for every $i$.\n%$$f_i(b_i,a_i)=_{(D2)} f_i(f(b_1,\\dots,b_n),a_i)=_{\\mathrm{Hyp}} f_i(f(a_1,\\dots,a_n),a_i)_{(D2)}=f(a_i,\\dots,a_i)=_{(D1)}a_i;$$\n%$$f(a_1,\\dots,a_n)=_{\\mathrm{Hyp}}f(f_1(b_1,a_1),\\dots,f_n(b_n,a_n))=_{(D2)}f(b_1,\\dots,b_n).$$\n%\\end{proof}\n%\n%\\begin{definition} \\cite[Definition 4.34]{mac}\n% We say that two functions $f:A^m\\to A$ and $g:A^n\\to A$ \\emph{commute} if\n%$$f(g(x_{11},\\dots,x_{1n}),\\dots,g(x_{m1},\\dots,x_{mn})) = g(f(x_{11},\\dots,x_{m1}),\\dots,f(x_{1n},\\dots,x_{mn})).$$\n%If $f=g$, then we say that $f$ is \\emph{self-commuting}.\n%\\end{definition}\n%\n%\n%\n%In this case, $f$ is a homomorphism from $(A,g)^m$ into $(A,g)$ and\n%$g$ is a homomorphism from $(A,f)^n$ into $(A,f)$.\n%\n%The following proposition is \\cite[Exercise 4.38(15)]{mac}.\n%\n%\\begin{proposition}\\label{commute} Let $f$ and $g$ be an $m$-ary and an $n$-ary decomposition operator  \n% of an algebra $\\mathbf A$. Then $f(g(x_{11},\\dots,x_{1n}),\\dots,g(x_{m1},\\dots,x_{mn}))$\n% is a decomposition operator of $\\mathbf A$ if and only if $f$ and $g$ commute.\n%\\end{proposition}\n%\n%The variables occurring in $f(g(x_{11},\\dots,x_{1n}),\\dots,g(x_{m1},\\dots,x_{mn}))$\n%may not all be  distinct, as explained in the following proposition.\n%\n%\\begin{proposition}\\label{commute2}\n%If $f$ is a $n$-ary decomposition operator and $d_1,\\dots,d_k$ ($k\\geq 2$) is a partition of $\\hat n=\\{1,\\dots,n\\}$, then the map $h$, defined by\n%$$h(y_1,\\dots, y_k)= f(z_1,\\dots,z_n),\\ \\text{where for all $1\\leq i\\leq n$, $z_i=y_j$ iff\n%$i\\in d_j$,}$$\n%is a $k$-ary decomposition operator.\n%\\end{proposition}\n%\n%\\begin{remark}\n% If the type $\\tau$ is empty then a $\\tau$-algebra is  a set. In this case a sequence $(\\phi_{1},\\dots,\\phi_n)$\n% satisfying the conditions of Definition \\ref{def:cong} will be called an $n$-tuple of complementary factor equivalence relations. Accordingly, an $n$-ary decomposition operator on a set $A$ is a function $f:A^{n}\\rightarrow A$ satisfying the above conditions (D1) and (D2). Condition (D3) is not applicable.\n%\\end{remark}\n%}\n%Let $\\mathbf A$ be an algebra and $f:A^n\\to A$ be a decomposition operator. Then every element of the block $\\langle f\\rangle$ is a decomposition operator. The generator of the block $\\langle f\\rangle$ is called a proper decomposition operator.\n\n\\subsection{Church algebras}\\label{dobbiaco}\nIn this section we recall from \\cite{BLPS18} the notion of an $n$-Church algebra. These algebras have $n$ nullary operations $\\e_1,\\dots, \\e_n$ ($n \\geq 2$) and an operation $q_n$ of arity $n + 1$ (a sort of ``generalised if-then-else'') satisfying the identities $q_n(\\e_i, x_1,\\dots, x_n) = x_i$. The operator $q_n$ induces, through the so-called $n$-central elements, a decomposition of the algebra into $n$ factors. \n\n\\begin{definition}\nAlgebras of type $\\tau$, equipped with at least $n$ nullary operations $\\e_1,\\dots,\\e_n$ and a term operation $q_n$ of arity $n+1$ satisfying $q_n(\\e_i,x_1,\\dots,x_n)=x_i$, are called \\emph{$n$-Church algebras} ($n\\mathrm{CH}$, for short); \n $n\\mathrm{CH}$s admitting only the $(n+1)$-ary $q_n$ operator and the $n$ constants $\\e_{1},\\dots ,\\e_{n}$ are called \\emph{pure} $n\\mathrm{CH}$s.\n\\end{definition}\n\n\n%If $\\mathbf{A}$ is an $n\\mathrm{CH}$, then $\\mathbf{A}_{0}=(A,q_n,\\e_{1},\\dots ,\\e_{n})$ is the \\emph{pure reduct} of $\\mathbf{A}$.\n\n$2$CHs were introduced as Church algebras in \\cite{MS08} and studied in \\cite{first}.  Examples of $2$CHs  are Boolean algebras (with $q_2(x,y,z) =(x\\wedge y)\\vee (\\lnot x\\wedge z)$) or rings with unit (with $q_2( x,y,z) =xy+z-xz$). Next, we present an example of $n$CH with $n>2$.\n\n\\begin{example}\n\\label{exa:nsets} (\\emph{$n$-Sets}) Let $X$ be a set.\nAn \\emph{$n$-subset} of $X$ is a sequence $(Y_{1},\\dots ,Y_{n})$ of subsets \n$Y_{i}$ of $X$. We denote by $\\mathrm{Set}_{n}(X)$ the family of all $n$-subsets of $X$.  $\\mathrm{Set}_{n}(X)$ becomes a pure $n\\mathrm{CH}$ if we define an operator $q_n$ and $n$ constants $\\e_1,\\dots,\\e_n$ as follows, for all $n$-subsets $\\mathbf{y}^{i}= (Y^i_{1},\\dots,Y^i_{n})$:\n$$\nq_n( \\mathbf{y}^0,\\mathbf{y}^1,\\dots ,\\mathbf{y}^n) =(\\bigcup\\limits_{i=1}^{n}Y^0_{i}\\cap Y_{1}^{i},\\dots,\\bigcup\\limits_{i=1}^{n}Y^0_{i}\\cap Y_{n}^{i});$$ \n$$\\e_1=(X,\\emptyset,\\dots,\\emptyset),\\dots, \\e_n=(\\emptyset,\\dots,\\emptyset,X).\n$$\n\\end{example}\n\n%\\begin{example}\\label{exa:uno} Example \\ref{exa:nsets} can be generalised as follows.\n%Let $L$ be a bounded lattice and $L^n=L\\times\\dots\\times L$ ($n$-times).\n%$L^n$ becomes a pure $n\\mathrm{CH}$ if we define an operator $q_n$ and $n$ constants $\\e_1,\\dots,\\e_n$ as follows, for all elements $y^i= (y^i_{1},\\dots,y^i_{n})\\in L^n$:\n%$$\n%q_n( y^0,y^1,\\dots ,y^n) =(\\bigvee\\limits_{i=1}^{n}(y^0_{i}\\land y_{1}^{i}),\\dots,\\bigvee\\limits_{i=1}^{n}(y^0_{i}\\land y_{n}^{i}));\\quad \\e_1=(1,0,\\dots,0),\\dots, \\e_n=(0,\\dots,0,1).\n%$$\n%\\end{example}\n\nIn \\cite{vaggione}, Vaggione introduced the notion\nof \\emph{central element} to study algebras whose complementary factor\ncongruences can be replaced by certain elements of their universes. \nCentral elements coincide with central idempotents in rings with\nunit and with members of the centre in ortholattices. \n\n\\begin{theorem} \\cite{BLPS18}\n\\label{thm:centrale} If $\\mathbf{A}$ is a $n\\mathrm{CH}$ of type $\\tau $\nand $c\\in A$, then the following conditions are equivalent:\n\n\\begin{enumerate}\n\n\\item the sequence of congruences $\\theta (c,\\e_{1}),\\dots\n,\\theta (c,\\e_{n})$ is an $n$-tuple of complementary factor congruences of $\\mathbf{A}$;\n\n\\item for all $a_{1},\\dots ,a_{n}\\in A$, $q_n(c,a_{1},\\dots ,a_{n})$ is the\nunique element such that $$a_{i}\\ \\theta (c,\\e_{i})\\ q(c,a_{1},\\dots ,a_{n}),$$\nfor all $1\\leq i\\leq n$;\n\n\\item The function $f_{c}$, defined by $f_{c}(a_{1},\\dots,a_{n})=q_n(c,a_{1},\\dots ,a_{n})$ for all $a_1,\\dots,a_n\\in A$, is an $n$-ary decomposition operator on $\\mathbf{A}$ such that \n$f_{c}(\\e_{1},\\dots ,\\e_{n})=c.$\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{definition}\n\\label{def:ncentral} If $\\mathbf{A}$ is an $n\\mathrm{CH}$, then $c\\in A$\nis called \\emph{$n$-central} if it satisfies one of the equivalent conditions of Theorem \\ref{thm:centrale}.\nAn $n$-central element $c$ is \\emph{nontrivial} if $c\\notin\\{\\e_{1},\\dots ,\\e_{n}\\}$.\n\\end{definition}\n\n\nEvery $n$-central element $c\\in A$ induces a decomposition of $\\mathbf{A}$ as a direct product of the \nalgebras $\\mathbf{A}/\\theta (c,\\e_{i})$, for $i\\leq n$.\n\n\nThe set of all $n$-central elements of a $n\\mathrm{CH}$ $\\mathbf{A}$ is a subalgebra of the pure reduct of $\\mathbf{A}$.\nWe denote by $\\mathbf{Ce}_{n}(\\mathbf{A})$ the algebra \n$(\\mathrm{Ce}_{n}(\\mathbf{A}),q_n,\\e_{1},\\dots ,\\e_{n})$ \nof all $n$-central elements of a \n$n\\mathrm{CH}$ $\\mathbf{A}$.\n\n\n%Factorisations of arbitrary algebras in $n$ factors may be studied in terms of $n$-central elements of suitable $n$CAs of functions, as explained in the following example.\n%\n%\\begin{example} \n%Let $\\mathbf A$ be an arbitrary algebra of type $\\tau$ and $F$ be a set of functions from $A^n$ into $A$, which includes the projections $\\e_i^\\mathbf F$ and all constant functions $f_b$ ($b\\in A$):\n%\\begin{enumerate}\n%\\item $\\e_i^\\mathbf F(a_1,\\dots,a_n)=a_i$, for every $a_1,\\dots,a_n\\in A$;\n%\\item $f_b(a_1,\\dots,a_n)=b$, for every $a_1,\\dots,a_n\\in A$;\n%\\end{enumerate}\n%and it is closed under the following operations (for all $f, h_i,g_j\\in F$ and all $a_1,\\dots,a_n\\in A$):\n%\\begin{enumerate}\n%\\item[(3)] $q^\\mathbf F(f,g_1\\dots,g_n)(a_1,\\dots,a_n) =f(g_1(a_1,\\dots,a_n)\\dots,g_n(a_1,\\dots,a_n))$.\n%\\item[(4)] $\\sigma^\\mathbf F(h_1,\\dots,h_k)(a_1,\\dots,a_n) = \\sigma^\\mathbf A(h_1(a_1,\\dots,a_n),\\dots, h_k(a_1,\\dots,a_n))$, for every $\\sigma\\in\\tau$ of arity $k$.\n%\\end{enumerate}\n%The algebra $\\mathbf F = (F,\\sigma^\\mathbf F,q^\\mathbf F,\\e_1^\\mathbf F,\\dots,\\e_n^\\mathbf F)_{\\sigma\\in\\tau}$ is a $n$CA.\n%It is possible to prove that a function $f\\in F$ is a $n$-central element of $\\mathbf F$ if and only if \n% $f$ is a $n$-ary decomposition operator on the algebra $\\mathbf A$ commuting (see Section \\ref{FCD}) with every function $g\\in F$.\n%The reader may consult \\cite{SLP18} for the case $n=2$.\n%\\end{example}\n\n\n\\subsection{Boolean-like algebras}\\label{sec:nba}\n\nBoolean algebras are $2$-CHs all of whose elements are \n$2$-central. It turns out that, among the $n$-CHs, those\nalgebras all of whose elements are $n$-central inherit many of the\nremarkable properties that distinguish Boolean algebras. \n\n\\begin{definition}\n\\label{mezzucci} \\cite{BLPS18,Bucciasali} An $n\\mathrm{CH}$ $\\mathbf{A}$ of type $\\tau$ is called an \\emph{$n$-Boolean-like algebra} ($n\\mathrm{BA}$, for short) if every element of $A$ is $n$-central.  An  $n\\mathrm{BA}$ of empty type is called a pure $n\\mathrm{BA}$.\n\\end{definition}\n\nIn an $n\\mathrm{BA}$ $q_n(x,-,\\dots,-)$ is an $n$-ary decomposition operator for every element $x$ of the universe of the algebra.\n\n%If $\\mathbf{A}$ is a $n\\mathrm{BA}$ of type $\\tau$, then $\\mathbf{A}_{0}=(A,q_n,\\e_{1},\\dots ,\\e_{n})$ is the \\emph{pure reduct} of $\\mathbf{A}$.\n\n\nThe class of all  $n\\mathrm{BA}$s of type $\\tau$ is a\nvariety axiomatised by the following identities:\n\\begin{itemize}\n\\item[$\\qquad (\\mathrm{B0})$]  $q_n(\\e_i,x_1,\\dots,x_n) = x_i$ ($i=1,\\dots,n$).\n\n\\item[$\\qquad (\\mathrm{B1})$]    $q_n(y,x,\\dots,x) = x$.\n\n\\item[$\\qquad (\\mathrm{B2})$] $q_n(y,\\e_1,\\dots,\\e_n) = y$.\n\n\\item[$\\qquad (\\mathrm{B3})$] $q_n(y, q_n(y, x_{11},x_{12},\\dots,x_{1n}),\\dots,q_n(y,x_{n1},x_{n2},\\dots,x_{nn}))= q_n(y,x_{11},\\dots,x_{nn})$.\n\n\\item[$\\qquad (\\mathrm{B4})$]  \n$q_n(y,q_n(x_{10},\\dots,x_{1n}),\\dots, q_n(x_{n0},\\dots,x_{nn})) = q_n(q_n(y, x_{10},\\dots,x_{n0}),\\dots, q_n(y, x_{1n},\\dots,x_{nn}))$.\n\n\\item[$\\qquad (\\mathrm{B5})$]  \n$q_n(y,\\sigma(x_{11},\\dots,x_{1k}),\\dots, \\sigma(x_{n1},\\dots,x_{nk})) = \\sigma(q_n(y, x_{11},\\dots,x_{n1}),\\dots, q_n(y, x_{1k},\\dots,x_{nk}))$, for every $\\sigma\\in\\tau$ of arity $k$.\n\\end{itemize}\nWe denote by $n\\mathsf{BA}_\\tau$  the variety of all $n\\mathrm{BA}$s of type $\\tau$.\nIf $\\tau$ is empty, then $n\\mathsf{BA}$ denotes the variety of all pure $n\\mathrm{BA}$s.\n\nThe constants $\\e_1,\\dots,\\e_n$ are pairwise residually distinct in every nontrivial $n\\mathrm{BA}$.\n\n$2\\mathrm{BA}$s were introduced in \\cite{first} with the\nname \\textquotedblleft Boolean-like algebras\\textquotedblright . \\emph{Inter\nalia}, it was shown in that paper that the variety of $2\\mathrm{BA}$s is term-equivalent to the variety of Boolean algebras.\n\n\\begin{example}\\label{exa:canonical}\nThe algebra $\\mathbf{Ce}_{n}(\\mathbf{A})$ of all $n$-central\nelements of an $n\\mathrm{CH}$ $\\mathbf{A}$ of type $\\tau$ is a canonical example of pure $n\\mathrm{BA}$.\n\\end{example}\n\n\n\n\n\\begin{example}\\label{exa:n}\nThe algebra \n$\\mathbf{n}=( \\{ \\mathsf \\e_{1},\\dots,\\mathsf \\e_{n}\\} ,q_n^{\\mathbf{n}},\\mathsf e^\\mathbf{n}_{1},\\dots,\\mathsf e^\\mathbf{n}_{n})$,\nwhere $q_n^{\\mathbf{n}}( \\mathsf \\e_{i}^{\\mathbf{n}},x_{1},\\dots,x_{n}) =x_{i}$ for every $i\\leq n$, is a pure $n\\mathrm{BA}$.\n\\end{example}\n\n%The algebra $\\mathbf n$ generates the variety $n\\mathsf{BA}$ of pure $n\\mathrm{BA}$s (see  \\cite{BLPS18}), while the variety $n\\mathsf{BA}_\\tau$ of $n\\mathrm{BA}$s of type $\\tau$ is generated by its finite members of cardinality $n$.\n\n\n\\begin{example}\\label{exa:parapa} (\\emph{$n$-Partitions}) Let $X$ be a set. An \\emph{$n$-partition} of $X$ is an $n$-subset $(Y^{1},\\ldots ,Y^{n})$ of $X$ such that $\\bigcup_{i=1}^{n}Y^{i}=X$ and $Y^{i}\\cap Y^{j}=\\emptyset $ for all $i\\neq j$.\nThe set of $n$-partitions of $X$ is closed under the $q_n$-operator defined in \nExample \\ref{exa:nsets} and constitutes  the algebra of all $n$-central\nelements of the pure $n\\mathrm{CH}$ $\\mathbf{Set}_{n}(X)$ of all $n$-subsets of $X$. \nNotice that the algebra  of $n$-partitions of $X$ can be proved isomorphic to the $n\\mathrm{BA}$ $\\mathbf{n}^X$  (the Cartesian product of $|X|$ copies of the algebra $\\mathbf{n}$).\n\\end{example}\n\n%\\begin{fact}\\label{exa:parapa2} Let $L$ be a bounded lattice and $L^n$ be  the $n\\mathrm{CH}$ defined in Example \\ref{exa:uno}. Then an element $y=(y_1,\\dots,y_n)\\in L^n$ is $n$-central  iff \n%$\\bigvee\\limits_{i=1}^{n} y_i=1$ and $y_i\\land y_j=0\\ \\text{for }i\\neq j$.\n%\\end{fact}\n\n\n\\begin{remark} \nIt is well known from \\cite{MS08} that the set of all $2$-central\nelements of a $2\\mathrm{CH}$ $\\mathbf{A}$ is a Boolean algebra with respect to the following operations:\n$$x\\land y=q_2(x,\\e_1,y);\\quad x\\lor y=q_2(x,y,\\e_2);\\quad \\neg x=q_2(x,\\e_2,\\e_1).$$\nThe correspondence $a\\in\\mathrm{Ce}_2(\\mathbf{A}) \\mapsto \\theta(a,\\e_1)$\ndetermines an isomorphism between the Boolean algebra of $2$-central elements and the Boolean algebra of factor congruences of $\\mathbf A$. Notice that the factor congruence $\\theta(a,\\e_2)$ is the complement of the factor congruence $\\theta(a,\\e_1)$.\n\\end{remark}\n\n%\\begin{fact} Every $n\\mathrm{CH}$ $\\mathbf A$ has factorable congruences, i.e., every congruence $\\theta$ of the algebra $\\mathbf A^n$ can be factorised as $\\theta = \\theta_1\\times\\dots\\times \\theta_n$, where $\\theta_i\\in \\mathrm{Con}\\,\\mathbf A$. In other words, $\\mathrm{Con}(\\mathbf A^n)=(\\mathrm{Con}\\,\\mathbf A)^n$ (see Section \\ref{sec:fcd}). By Example \\ref{exa:uno}  the lattice $\\mathrm{Con}(\\mathbf A^n)$ constitutes a $n\\mathrm{CH}$ and the map \n%$$a\\in \\mathrm{Ce}_n(\\mathbf A) \\mapsto \\theta(a,\\e_1)\\times\\dots\\times\\theta(a,\\e_n)\\in \\mathrm{Ce}_n(\\mathrm{Con}(\\mathbf A^n))$$\n%determines an isomorphism of $n\\mathrm{BA}$s.\n%\\end{fact}\n\n\nThe variety $\\mathsf{BA}$ of Boolean algebras is semisimple as every $\\mathbf{A}\\in \\mathsf{BA}$ is\nsubdirectly embeddable into a power of the $2$-element Boolean algebra, which\nis the only subdirectly irreducible (in fact, simple) member of $\\mathsf{BA}$. This property finds an analogue in the structure theory of $n\\mathsf{BA}$s.\n\n\\begin{theorem}\n\\label{lem:subirr} \\cite{BLPS18} \n\\begin{enumerate}\n\\item[(i)] The algebra $\\mathbf n$ is the unique simple pure $n\\mathrm{BA}$ and it generates the variety $n\\mathsf{BA}$.\n\\item[(ii)] the variety $n\\mathsf{BA}_\\tau$ of $n\\mathrm{BA}$s of type $\\tau$ is generated by its finite members of cardinality $n$.\n\\end{enumerate}\n\n\\end{theorem}\n\nThe next corollary shows that, for any $n\\geq 2$, the $n\\mathrm{BA}$ $\\mathbf{n}$ plays a role analogous to the Boolean algebra $\\mathbf{2}$ of truth values.\n\n\\begin{corollary}\n\\label{cor:stn} Every pure $n\\mathrm{BA}$ $\\mathbf{A}$ is isomorphic to a subdirect power of $\\mathbf{n}^{X}$, for some set $X$.\n\\end{corollary}\n\n\nOne of the most remarkable properties of the $2$-element Boolean algebra, called \\emph{primality} in universal algebra \\cite[ Sec. 7 in Chap. IV]{BS}, is the definability of all finite Boolean functions in terms of the connectives {\\sc and, or, not}. This property is inherited by $n$BAs. \n\n\n\n\\begin{theorem}\\label{prop:nbaprim} \\cite{BLPS18}\nThe variety $n\\mathsf{BA}=\\mathrm{Var}(\\mathbf n)$ is primal.\n\\end{theorem}\n\n\n\n\n\n\n\\subsection{Lattices of equational theories}\\label{sec:pre:leq}\nWe say that $L$ is a \\emph{lattice of equational theories} iff $L$ is isomorphic to the lattice $L(T )$ of all equational theories containing some equational theory $T$ (or dually, to the lattice of all subvarieties of some variety of algebras). \nThus, if $T$ were the equational theory of all groups, then $L(T)$ would be the lattice of all equational theories of groups and one of the members of $L(T)$ would be the equational theory of Abelian groups.\n\n\nThe lattice $L(T )$ is ordered by set-inclusion, the meet in this lattice is just intersection and the join of a collection $E$ of equational theories is just the equational theory based on $\\bigcup E$.\nA lattice of equational theories is algebraic and coatomic, possessing a compact top element; but no stronger property was known before Lampe's discovery that any lattice of equational theories obeys a weakening of semidistributivity called the Zipper condition, which is a nontrivial implication in the language of bounded lattices  (see Lampe \\cite{lampe}): \n$$\\text{If $\\bigvee_{i \\in I} a_i= 1$ and $x\\land a_i  = x\\land a_j$ for all $i,j\\in I$, then $x\\leq a_i$ for all $i$.}$$ \nLampe's Theorem suggests that the class of lattices of the form $L(T)$ might have interesting structural properties. %The Zipper condition is a weakening of semidistributivity: If $x a_i=x a_j$ for all $i,j\\in I$, then $x (\\sum_{i \\in I} a_i)= x a_i$.\n\nIn 1946 Birkhoff \\cite{bir2} stated the lattice of equational theories problem: Find an algebraic characterisation of those lattices which can be isomorphic to $L(T)$ for some equational theory $T$. Maltsev \\cite{mal} was instrumental in attracting attention to this problem, which is sometimes referred to as Maltsev's Problem, and this led to many interesting results summarised in \\cite[Section 4]{nulty}.\n \nTrying to characterise the lattices of equational theories as the congruence lattices of a class of algebras is a natural, though difficult, way of approaching the problem.\nIn \\cite{newrly} Newrly shows that a lattice of equational theories is the congruence lattice of an algebra whose fundamental operations consist of one monoid operation with right zero and one unary operation. In \\cite{nur} Nurakunov describes a class of monoids enriched by two unary operations, the so-called Et-monoids, and proves that a lattice $L$ is a lattice of equational theories if and only if $L$ is isomorphic to the congruence lattice of some Et-monoid. Nevertheless, the varieties of algebras generated by Newrly's monoids and by  Nurakunov's Et-monoids have not been thoroughly investigated, and in particular they do not admit an equational axiomatisation. Hence the problem of characterising the lattices of equational theories is still open.\n\n\n\n\n\\section{Clones of operations}\\label{sec:clo}\nGiven an algebra $\\mathbf A$ of type $\\tau$, one is often interested in the term operations of the algebra rather than in the basic operations $\\sigma^\\mathbf A$ itself ($\\sigma\\in\\tau$). In particular, if two algebras have the same set of term operations, then one might consider their difference as a mere question of representation. This motivates a notion that describes precisely those sets of operations that can arise as sets of term operations of an algebra and that is exactly what a clone is.\n\n\\bigskip\n\nA \\emph{$k$-ary projection} is a function $p^{(k)}_i: A^k\\to A$ ($k\\geq i$) defined by $p^{(k)}_i(a_1,\\dots,a_k)=a_i$. \nA \\emph{basic projection} is a projection $p^{(i)}_i$ ($i\\geq 1$). We denote a basic projection \nby $p_i=p^{(i)}_i$. We denote by $\\mathcal J_A$ the set of all projections.\n\nA \\emph{$k$-ary constant operation} is a function $c^{(k)}_a: A^k\\to A$ ($k\\geq 0$ and $a\\in A$) such that  \n$c^{(k)}_a(a_1,\\dots,a_k)=a$, for all $a_1,\\dots,a_k\\in A$.\n\n\\bigskip\n\nOne may consider various natural operations on  $\\mathcal{O}_A$, the set of all operations on $A$, and among them\nthe composition operation is of paramount importance. \nIn the following definition we formally define the composition.\n\n\\begin{definition}\\label{def:comp}\n The \\emph{composition}  of $f\\in  \\mathcal{O}_A^{(n)}$ with  $g_1,\\dots,g_n\\in   \\mathcal{O}_A^{(k)}$ is the operation $f(g_1,\\dots,g_n)_k\\in  \\mathcal{O}_A^{(k)}$ defined as follows: \n$$f(g_1,\\dots,g_n)_k(\\mathbf a)= f(g_1(\\mathbf a),\\dots, g_n(\\mathbf a))\\quad\\text{for all $\\mathbf a\\in A^k$}.$$\n\\end{definition}\nIn particular, if $f\\in  \\mathcal{O}_A^{(0)}$ then \n$f()_k(\\mathbf a)= f$ for all $\\mathbf a\\in A^k$.\n\nWhen there is no danger of confusion, we write $f(g_1,\\dots,g_n)$ for $f(g_1,\\dots,g_n)_k$.\n\n\n\\begin{definition} Let $A$ be a set and $n >0$. An $n$-ary operation $f:A^n\\to A$\n\\begin{itemize}\n\\item[(i)]   \\emph{depends on its $i$-th argument} ($1\\leq i\\leq n$) if there are $a_1,\\dots,a_n,b,c\\in A$ such that \n$$f(a_1,\\dots,a_{i-1},b,a_{i+1},\\dots,a_n)\\neq f(a_1,\\dots,a_{i-1},c,a_{i+1},\\dots,a_n).$$\n \\item[(ii)] is \\emph{fictitious in the $i$-th argument} if it does not depend on its $i$-th argument.\n \\item[(iii)] is \\emph{fictitious} if $f$ is fictitious in its $n$-th (i.e., last) argument.\n\\end{itemize}\n\\end{definition}\n\n\\begin{definition} Let $f$ be a fictitious $n$-ary operation on $A$ and $g$ be an $(n-1)$-ary operation on $A$.\nWe say that $g$ is the \\emph{restriction} of $f$ and $f$ is the \\emph{fictitious expansion} of $g$\n if  \n$$g(a_1,\\dots,a_{n-1})=f(a_1,\\dots,a_{n-1},b),\\quad\\text{for all $a_1,\\dots,a_{n-1},b\\in A$}.$$\n\\end{definition}\n\n\nWe say that a set $X$ of operations is \\emph{closed under restriction} if \n$X$ contains the restriction of every fictitious operation of $X$.\n\n\n\\begin{definition}\\label{def:clo}  A \\emph{clone on a set $A$} is a subset $F$ of $\\mathcal{O}_A$ containing all projections\n$p^{(n)}_i$ and closed under composition and restriction. \n\\end{definition}\n\nA \\emph{clone on a $\\tau$-algebra $\\mathbf A$} is a clone on $A$  containing \n the basic operations $\\sigma^\\mathbf A$ ($\\sigma\\in\\tau$) of $\\mathbf A$.\n \n\n\n\\begin{remark} The classical approach to clones, as evidenced by the standard monograph \\cite{SZ86}, considers clones only containing operations that are at least unary. However, with only minor modifications, most of the usual theory can be lifted to clones allowing nullary operations (see \\cite{B14}). \nTypically, clones as abstract clones (see below) and  Lawvere's algebraic theories \\cite{Law63} include nullary operations.\nThe full generality of some results in this paper requires clones allowing nullary operators.\n\\end{remark}\n\n\\begin{remark} Clones without nullary operations do not require the closure under restriction, because using projections  and composition it is possible to define the at least unary restriction of every fictitious operation.\nClones allowing nullary operations do require the closure under restriction. Using projections and composition it is not possible to define the nullary operator $c^{(0)}_a$ that is restriction of the constant unary operation $c^{(1)}_a$.\n\\end{remark}\n \n Clones on a set $A$ are closed under arbitrary intersection, so that they constitute a complete lattice denoted by $\\mathrm{Lat}(\\mathcal{O}_A)$. The clone generated by a set $F$ of operations will be denoted by $[F]$.\n If $F=\\{f\\}$ is a singleton, then we will write $[f]$ for $[\\{f\\}]$.\n \n\n\n\n\\subsection{Clone of the term operations}\\label{sec:to} The \\emph{clone of the term operations of a $\\tau$-algebra $\\mathbf A$}, denoted by  $\\mathrm{Clo} \\mathbf A$, is the smallest clone on $\\mathbf A$. It is constituted by the set of all term operations of $\\mathbf A$. The  definition of term operation must be carefully given.  \nEvery term $t$ determines an infinite set $T_t^\\mathbf A$ of \\emph{term operations} $t^{\\mathbf A,k}:A^k\\to A$, where $k$ is $\\geq r$ for a suitable $r$ depending on $t$. We define $T_t^\\mathbf A$ by induction as follows.\n\\begin{itemize}\n\\item $T_{v_i}^\\mathbf A=\\{ v_i^{\\mathbf A,k}: k\\geq i\\}$, where $v_i^{\\mathbf A,k}(a_1,\\dots,a_k)=a_i$ for every $a_1,\\dots,a_k\\in A$ and variable $v_i$.\n\\item If $t=\\sigma(t_1,\\dots,t_m)$ and $t_1^{\\mathbf A,k}  \\in T_{t_1}^\\mathbf A,\\dots,t_m^{\\mathbf A,k}\\in T_{t_m}^\\mathbf A$, then $t^{\\mathbf A,k}\\in T_{t}^\\mathbf A$ is defined as \n$t^{\\mathbf A,k}(a_1,\\dots,a_k)=\\sigma^\\mathbf A(t_1^{\\mathbf A,k}(a_1,\\dots,a_k),\\dots,t_m^{\\mathbf A,k}(a_1,\\dots,a_k))$ for every $a_1,\\dots,a_k\\in A$.\n\\item If $t^{\\mathbf A,k+1}\\in T_{t}^\\mathbf A$ is fictitious, then $t^{\\mathbf A,k}\\in T_{t}^\\mathbf A$ is  the restriction of $t^{\\mathbf A,k+1}$.\n\\end{itemize}\n\n\\begin{proposition}\n  $\\mathrm{Clo} \\mathbf A = \\bigcup_{t\\in T_\\tau(\\omega)} T_{t}^\\mathbf A$.\n\\end{proposition}\n\n\\subsection{Examples}\\label{exa:clo}\n\\begin{enumerate}\n\\item The set $\\mathcal O_A$ of all operations and the set $\\mathcal J_A$ of all projections are clones on $A$. \n$\\mathcal O_A$ and $\\mathcal J_A$ are respectively the top element and the bottom element of the lattice $\\mathrm{Lat}(\\mathcal{O}_A)$.\n%\\item The \\emph{clone of term operations of an algebra $\\mathbf A$}, denoted by  $\\mathrm{Clo} \\mathbf A$, is the smallest clone on $\\mathbf A$. %By \\cite[Theorem 4.3]{mac}  $\\mathrm{Clo} \\mathbf A^{(n)}$ is the smallest set of $n$-ary operations on $A$ including the $n$-ary projections $p^{(n)}_i$ and closed under composition by every basic operation $\\sigma^\\mathbf A$ of $\\mathbf A$.\n\\item The \\emph{clone of polynomial operations of an algebra $\\mathbf A$}, denoted by  $\\mathrm{Pol} \\mathbf A$, is the smallest clone on $\\mathbf A$ that contains the constant operations $c_a^{(k)}$ for every $a\\in A$ and $k\\geq 0$.\n\\item The \\emph{clone of  homomorphisms of an algebra $\\mathbf A$}, denoted by  $\\mathrm{Hom} \\mathbf A$, is the smallest clone containing all  homomorphisms $f: \\mathbf A^n\\to \\mathbf A$ ($n\\geq 1$). %The composition of homomorphisms is also a homomorphism.\n\\end{enumerate}\n% If $\\sigma^\\mathbf A:A^k\\to A$ ($k\\geq 0$) is a basic operation of $\\mathbf A$ and $g_1,\\dots,g_k\\in \\mathrm{Clo} \\mathbf A^{(n)}$, then $\\sigma^\\mathbf A(g_1,\\dots,g_k)\\in \\mathrm{Clo} \\mathbf A^{(n)}$.\n\n\n% and $k$ be an arbitrary natural number. We define by induction a subset $T_{\\mathbf A,k}$ of the set $T_\\tau(\\omega)$ of $\\tau$-terms.\n%\\begin{itemize}\n%\\item[(a)]  $v_1,\\dots,v_k\\in T_{\\mathbf A,k}$;\n%\\item[(b)] If $\\sigma \\in \\tau$ is an operation symbol of arity $m$ and $t_1,\\dots,t_m\\in T_{\\mathbf A,k}$, then $\\sigma(t_1,\\dots,t_m)\\in T_{\\mathbf A,k}$.\n%\\end{itemize}\n%\n%We define a $k$-ary operation $t^{\\mathbf A,k}$ on $A$ for every $t\\in T_{\\mathbf A,k}$:\n%\\begin{itemize}\n%\\item $v_i^{\\mathbf A,k}(a_1,\\dots,a_k)=a_i$ for every $a_1,\\dots,a_k\\in A$ and $1\\leq i\\leq k$.\n%\\item If $t=\\sigma(t_1,\\dots,t_m)\\in T_{\\mathbf A,k}$, then \n%$t^{\\mathbf A,k}(a_1,\\dots,a_k)=\\sigma^\\mathbf A(t_1^{\\mathbf A,k}(a_1,\\dots,a_k),\\dots,t_m^{\\mathbf A,k}(a_1,\\dots,a_k))$ for every $a_1,\\dots,a_k\\in A$.\n%\\end{itemize}\n\n\n%\\begin{example} Let $\\mathbb N$ be the set of natural numbers and $\\mathbb N^*=\\mathbb N\\cup \\{*\\}$. Every computable partial map $f:\\mathbb N^k\\to\\mathbb N$ can be extended to a total map $f^*:\\mathbb (N^*)^k\\to\\mathbb N^*$ as follows:\n%$$f^*(x_1,\\dots,x_k)=\\begin{cases}f(x_1,\\dots,x_k)&\\text{if $f$ is defined on $(x_1,\\dots,x_k)$}\\\\\n%\\omega&\\text{otherwise}\\end{cases}$$\n%The set $\\{f^*:\\ \\text{$f$ is a computable partial map}\\}$ determines a clone $\\mathfrak C$ on $\\mathbb N^*$, called the \\emph{computable clone}.\n%\\end{example}\n\n\n\n\n\\subsection{Abstract clones}\\label{sec:attempt}\nWe describe an attempt (among others) aiming to encode clones into algebras  (see \\cite{T93} and \\cite[p.\\,239]{evans}).\nAn \\emph{abstract clone} is a many-sorted algebra composed of  disjoint sets $B_n$ ($n\\geq 0$),\nelements $\\pi_i^{(n)}\\in B_n$ ($n\\geq 1$) for all $i\\leq n$, and\na family of operations $C^n_k: B_n\\times (B_k)^n \\to B_k$ for all $k$ and $n$\nsuch that\n\\begin{enumerate}\n\\item $C^n_k(C^m_n(x,y_1,\\dots,y_m),\\mathbf z)= C^m_n(x,C^n_k(y_1,\\mathbf z),\\dots,C^n_k(y_m,\\mathbf z))$, where $x$ is a variable of sort $m$, $y_1,\\dots,y_m$ are variables of sort $n$ and $\\mathbf z=z_1,\\dots,z_n$ are variables of sort $k$;\n\\item $C^n_n(x,\\pi_1^{(n)},\\dots,\\pi_n^{(n)})=x$, where $x$ is a variable of sort $n$;\n\\item $C^n_k(\\pi_i^{(n)},y_1,\\dots,y_n)=y_i$, where $y_1,\\dots,y_n$ are variables of sort $k$.\n\\end{enumerate}\nAny clone $F$ on a set $A$ determines an abstract clone \n$\\mathbf F=( F^{(n)},C^n_k,\\pi_i^{(k)})_{n\\geq 0,k\\geq 1}$, where the nullary operators $\\pi_i^{(k)}=p_i^{(k)}\\in F^{(k)}$ are the projections  and\n$C^n_k$ is the operator of composition introduced in Definition \\ref{def:comp}:\n$C^n_k(f,g_1,\\dots,g_n)=f(g_1,\\dots,g_n)_k$ is the composition of $f\\in \\mathcal F^{(n)}$ with $g_1,\\dots,g_n\\in \\mathcal F^{(k)}$.\n\n%Sangalli \\cite{sangalli} has shown that, for every abstract clone $C$, there exist a set $A$ and a suitable monoid $M$ of maps $f:A\\to A$ such that $C$ is isomorphic to the  clone of all finitary operations preserved by each map $f\\in M$. \n\n\n\\subsection{Neumann's abstract $\\aleph_0$-clones \\cite{neu70,T93}}\\label{sec:neu} The idea here is to regard an $n$-ary operation $f$ as an infinitary operation\nthat only depends on the first $n$ arguments (see Section \\ref{sec:blocktop}). The corresponding abstract definition is as follows.\nAn \\emph{abstract $\\aleph_0$-clone} is an infinitary algebra $(A,\\e_i,q_\\infty)_{1\\leq i<\\omega}$, where the $\\e_i$ are nullary operators and $q_\\infty$ is an $\\omega$-ary operation on $A$, satisfying the following axioms: \n\\begin{itemize}\n\\item[(i)] $q_\\infty(\\e_i,x_1,\\dots,x_n,\\dots)=x_i$;\n\\item[(ii)] $q_\\infty(x,\\e_1,\\dots,\\e_n,\\dots)=x$;\n\\item[(iii)] $q_\\infty(q_\\infty(x,\\mathbf  y),\\mathbf z)= q_\\infty(x,q_\\infty(y_1,\\mathbf z),\\dots,q_\\infty(y_n,\\mathbf z),\\dots)$,\nwhere  $\\mathbf y=y_1,\\dots,y_n,\\dots$ and\\\\ $\\mathbf  z=z_1,\\dots,z_n,\\dots$ are countable infinite sequences of variables.  \n\\end{itemize}\n\nThe most natural abstract $\\aleph_0$-clones, the ones the axioms are intended to characterise, are algebras of infinitary operations, called \\emph{functional $\\aleph_0$-clones}, containing the projections and closed under infinitary composition. \nMore precisely, a functional $\\aleph_0$-clone is an infinitary algebra $(F,\\e_i^\\omega,q_\\infty^\\omega)_{1\\leq i<\\omega}$ defined as follows, for all $\\varphi,\\psi_i\\in F$ and $s\\in A^\\omega$: \n\\begin{itemize}\n\\item[(a)]  $F\\subseteq \\mathcal O_A^{(\\omega)}$;\n\\item[(b)] $\\e_i^\\omega(s)=s_i$;\n\\item[(c)] $q_\\infty^\\omega(\\varphi,\\psi_1,\\dots,\\psi_n,\\dots)(s)=\\varphi(\\psi_1(s),\\psi_2(s),\\dots,\\psi_n(s),\\dots).$\n\\end{itemize}\nThere is a faithful functor from the category of clones to the category of abstract $\\aleph_0$-clone, but this functor is not onto. The problem is that these infinitary algebras may contain elements that correspond to operations essentially of infinite rank. Technical difficulties have caused this approach to be largely abandoned. \n\n%\\item \\emph{Maltsev-Post iterative algebras} (see \\cite{mal2}): Study of compositions of functions is important for the three branches of mathematics: the theory of many-valued logics, automata theory, and universal algebra. In the articles \\cite{post1,post2}, E. Post, one of the founders of the mathematical theory of many-valued logics, considered the problem of describing all composition-closed classes of functions on a fixed set $A$. He was able to describe the lattice of all clones on a two elements set.\n%Since composition is not an algebraic operation, A. I. Malcev \\cite{mal2} suggested to consider, instead of classes of functions with composition, special algebras whose underlying sets are composition closed sets of functions. A. I. Malcev called these algebras \\emph{iterative  algebras} and described them as follows.\n%An algebra $\\mathcal B=(B,*,\\xi,\\tau,\\Delta,\\nabla,p_1^{(2)})$ of type $(2,1,1,1,1,0)$, where $B\\subseteq \\mathcal O_A$, is an iterative algebra if it satisfies the following identities:\n%\\begin{itemize}\n%\\item $f*g(x_1,\\dots,x_m,x_{m+1},\\dots,x_{m+n-1})=f(g(x_1,\\dots,x_m),x_{m+1}\\dots,x_{n+m-1})$;\n%\\item $\\xi(f)(x_1,\\dots,x_n)=f(x_2,\\dots,x_n,x_1)$ if $f$ has arity $n \\geq 2$;\n%\\item $\\tau(f)(x_1,\\dots,x_n)=f(x_2,x_1,x_3,\\dots,x_n)$ if $f$ has arity $n \\geq 2$;\n%\\item $\\Delta(f)(x_1,\\dots,x_{n-1}) =f(x_1,x_1,x_2,\\dots,x_{n-1})$ if $f$ has arity $n \\geq 2$;\n%\\item $\\Delta(f)=\\xi(f)=\\tau(f)=f$ if $f$ has arity $1$;\n%\\item $\\nabla(f)(x_1,\\dots,x_{n+1})=f(x_2,x_3,\\dots,x_{n+1})$;\n%\\item $p_1^{(2)}(x,y)=x$.\n%\\end{itemize}\n%In \\cite{T93} it is stated the open problem to find a nice axiomatisation of the variety generated by the iterative algebras.\n%\\end{enumerate}\n\n\n\\section{Clone algebras}\\label{sec:clonAlg}\n We have described in Section \\ref{sec:attempt} an attempt that has been made to encode clones into algebras using  many-sorted algebras, and in Section \\ref{sec:neu}  an attempt based on infinitary algebras.  \nIn this section we introduce the variety of \\emph{clone algebras} as a more canonical algebraic account of clones using standard one-sorted algebras. % in order to use tools from Universal Algebra to prove results about clones.\nIn Sections \\ref{sec:dueuno} and \\ref{sec:clones} we will show how to encode clones inside clone algebras. \nThe algebraic type of clone algebras contains a countable infinite family of nullary operators $\\e_i$ and, for each $n\\geq 0$, an operator $q_n$ of arity $n+1$. Informally, the constant $\\e_i$ represents the $i$-th projection and the operator $q_n$ represents the $n$-ary functional composition. In the relevant example of free algebras the constants $\\e_i$  represent the variables and the operators $q_n$  the term-for-variable substitutions.\nEach operator $q_n$ embodies the countable infinite family of operators $C^n_k$ ($k\\geq 1$) of abstract clones described in Section \\ref{sec:clo}. \n\n%[Parlare delle algebre iterative di Maltsev-Post dicendo che sono algebre unisortali concrete di funzioni che non hanno gli operatori di composizione come operatori primitivi. Nessuna assiomatizzazione e' conosciuta della variet\u00e0 generata dalle algebre iterative.]\n\n\nIn the remaining part of this paper \n%$q_n$ ($n\\geq 0$) will be always an operator symbol of arity $n+1$ and $\\e_i$ ($i\\geq 1$) will be a nullary operator.\nwhen we write $q_n(x,\\mathbf y)$ it will be implicitly stated that  $\\mathbf y=y_1,\\dots,y_n$ is a sequence of length $n$.\n\nThe algebraic type of clone $\\tau$-algebras is $\\tau \\cup\\{ q_n: n\\geq 0\\} \\cup\\{ \\e_i : i\\geq 1\\}$. \n\n%$y\\cdot_k x = q_k(x,\\e_1,\\dots,\\e_{k-1},y)$\n%\n%$q_n(q_n(z,\\e_1,\\dots,\\e_{k-1},\\e_i,\\dots),\\e_1,\\dots,\\e_{i-1},x,\\dots)=\n%q_n(q_n(z,\\e_1,\\dots,\\e_{k-1},x,\\dots),\\e_1,\\dots,\\e_{i-1},x,\\dots)$\n\n\\begin{definition} \\label{def:clonealg}\n A \\emph{clone $\\tau$-algebra}   is an algebra \n $\\mathbf C = (\\mathbf C_\\tau, q^\\mathbf C_n,\\e^\\mathbf C_i)_{n\\geq 0,i\\geq 1}$ satisfying the following conditions:\n\\begin{enumerate}\n\\item[(C0)] $\\mathbf C_\\tau = (C,\\sigma^\\mathbf C)_{\\sigma\\in\\tau}$ is a $\\tau$-algebra;\n\\item[(C1)] $q_n(\\e_i,x_1,\\dots,x_n)=x_i$ $(1\\leq i\\leq n)$;\n\\item[(C2)] $q_n(\\e_j,x_1,\\dots,x_n)=\\e_j$ $(j>n)$;\n\\item[(C3)] $q_n(x,\\e_1,\\dots,\\e_n)=x$ $(n\\geq 0)$;\n\\item[(C4)] %$q_k(x,\\bar y)= q_n(x,\\bar y,\\e_{k+1},\\dots,\\e_n)$ ($n> k$);\nIf $n< k$, then\n$q_k(q_n(x,\\mathbf y),\\mathbf z) = q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z),z_{n+1},\\dots,z_k)$;\n \\item[(C5)] %$q_n(q_n(x,y_1,\\dots,y_n),z_1,\\dots,z_n)=q_n(x,q_n(y_1,z_1,\\dots,z_n),\\dots,q_n(y_n,z_1,\\dots,z_n))$;\n If $n\\geq k$,  then\n$q_k(q_n(x,\\mathbf y),\\mathbf z) = q_n(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z))$;\n\n\n\\item[(C6)]  $q_n(\\sigma(x_1,\\dots,x_k),y_1,\\dots,y_n) = \\sigma(q_n(x_1,y_1,\\dots,y_n),\\dots,q_n(x_k,y_1,\\dots,y_n))$ for every $\\sigma\\in\\tau$ of arity $k$ and every $n\\geq 0$.\n\\end{enumerate}\nIf $\\tau$ is empty, an algebra \nsatisfying (C1)-(C5) is called a \\emph{pure clone algebra}.\n\\end{definition}\n\nIn the following, when there is no danger of confusion,\nwe will write $\\mathbf C = (\\mathbf C_\\tau, q^\\mathbf C_n,\\e^\\mathbf C_i)$  for $\\mathbf C = (\\mathbf C_\\tau, q^\\mathbf C_n,\\e^\\mathbf C_i)_{n\\geq 0,i\\geq 1}$.\n\n\\begin{definition}\n  If $\\mathbf C$ is a clone $\\tau$-algebra, then $\\mathbf C_0=( C, q^\\mathbf C_n,\\e^\\mathbf C_i)$ is called the \\emph{pure reduct of $\\mathbf C$}.\n\\end{definition}\n\n\n\nThe class of clone $\\tau$-algebras  is denoted by $\\mathsf{CA}_\\tau$ and the class of all clone  algebras of any type by $\\mathsf{CA}$. $\\mathsf{CA}_0$ denotes the class of all pure clone algebras.\nWe also use $\\mathsf{CA}_\\tau$ as shorthand for the phrase ``clone $\\tau$-algebra'', and similarly for $\\mathsf{CA}$. \n\nThe variety $\\mathsf{CA}_\\tau$ is $\\omega$-pointed, because the constant $\\e_i$ are residually distinct in every clone $\\tau$-algebra.\nBy (C1) every $\\mathsf{CA}_\\tau$ is an $n\\mathrm{CH}$, for every $n$ (see Section \\ref{dobbiaco}).\n\nWe start the study of clone algebras with two simple lemmas.\n\n\\begin{lemma}\\label{lem:exc4}\n $q_n(x,\\mathbf y)= q_k(x,\\mathbf y,\\e_{n+1},\\dots,\\e_k)$ ($k> n$).\n\\end{lemma}\n\n\\begin{proof}\n$$\n\\begin{array}{lll}\nq_n(x,\\mathbf y)  & =_{(C3)}  & q_k(q_n(x,\\mathbf y),\\e_1,\\dots,\\e_k)   \\\\\n  &  =_{(C4)} &   q_k(x,q_k(y_1,\\e_1,\\dots,\\e_k),\\dots,q_k(y_n,\\e_1,\\dots,\\e_k),\\e_{n+1},\\dots,\\e_k)\\\\\n  &  =_{(C3)} & q_k(x,y_1,\\dots,y_n,\\e_{n+1},\\dots,\\e_k).\n\\end{array}\n$$\n\\end{proof}\n%Axiom (C5), generalising the associativity law of semigroups, was called \\emph{superassociativity} by Menger \\cite{menger1,menger2,menger3}. The reduct $(C,q_1,e_1)$ is a monoid.\n\n\n%\\begin{lemma}\\label{allungo} Let $\\mathbf y=y_1,\\dots,y_n$ and $\\mathbf z=z_1,\\dots,z_k$.\n%\\begin{enumerate}\n%\\item If $n\\geq k$,  then\n%$$q_k(q_n(x,\\mathbf y),\\mathbf z) =q_n(q_n(x,\\mathbf y),\\mathbf z,\\e_{k+1},\\dots,\\e_n)= q_n(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z)).$$\n%\\item If $n< k$, then\n%$$q_k(q_n(x,\\mathbf y),\\mathbf z) =q_k(q_k(x,\\mathbf y,\\e_{n+1},\\dots,\\e_k),\\mathbf z)=\n% q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z),z_{n+1},\\dots,z_k).$$\n%\\end{enumerate}\n%\\end{lemma}\n%\n%\\begin{proof} \\[\n%\\begin{array}{lll}\n%q_k(q_n(x,\\mathbf y),\\mathbf z)  & =_{(C4)}  &  q_n(q_n(x,\\mathbf y),\\mathbf z, \\e_{k+1},\\dots,\\e_n) \\\\\n%  & =_{(C5)}  & q_n(x,q_n(y_1,\\mathbf z, \\e_{k+1},\\dots,\\e_n),\\dots,q_n(y_n,\\mathbf z, \\e_{k+1},\\dots,\\e_n))  \\\\\n%  & =_{(C4)}  &  q_n(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z))\n%\\end{array}\n%\\]\n% \\[\n%\\begin{array}{lll}\n%q_k(q_n(x,\\mathbf y),\\mathbf z)  & =_{(C4)}  &  q_k(q_k(x,\\mathbf y, \\e_{n+1},\\dots,\\e_k),\\mathbf z) \\\\\n%  & =_{(C5)}  & q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z),q_k(\\e_{n+1},\\mathbf z),\\dots,q_k(\\e_k,\\mathbf z))  \\\\\n%  & =_{(C1)}  &  q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z), z_{n+1},\\dots,z_k)\\\\  \n%\\end{array}\n%\\]\n%\n%\\end{proof}\n\n\\begin{lemma}\\label{lem:24}\n Let $\\mathbf C= (\\mathbf C_\\tau,q_n^\\mathbf C,\\e_i^\\mathbf C)$ be a clone $\\tau$-algebra and $\\mathbf b= b_1,\\dots,b_n\\in C$. Then the map $s_\\mathbf b:C\\to C$, defined by\n $$s_\\mathbf b(a)=q_n(a,\\mathbf b)\\quad\\text{for every $a\\in C$},$$\n is an endomorphism of the $\\tau$-algebra $\\mathbf C_\\tau$, satisfying $s_\\mathbf b(\\e_i)=b_i$ for every $1\\leq i\\leq n$.\n\\end{lemma}\n\n\\begin{proof} By (C6).\n%Let $s(\\e_i^\\mathbf A)=b_i$ for $i=1,\\dots,n$. We extend $s$ to an endomap of $A$ as follows: $s(a)=q_n^\\mathbf A(a,b_1,\\dots,b_n)$.\n\\end{proof}\n\nIn the remaining part of this section we define the notions of independence and dimension in clone algebras.\n\n\\begin{definition}\n  An element $a$ of a clone algebra $\\mathbf  C$ \\emph{is independent of} $\\e_{n}$ if \n$q_{n}(a,\\e_1,\\dots,\\e_{n-1},\\e_{n+1})=a$. If $a$ is not independent of $\\e_{n}$, then we say that \n$a$ \\emph{is dependent on} $\\e_{n}$.\n\\end{definition}\n\n\\begin{lemma}\\label{lem:ind1} Let $\\mathbf C$ be a clone algebra and $\\mathbf b=b_1,\\dots, b_{n-1}\\in C$. \n%The following conditions hold for all $c\\in C$ and $\\mathbf b=b_1,\\dots, b_{n-1}\\in C$:\n %\\begin{itemize}\n%\\item[(i)]  If $a$ is independent of $\\e_n$, then  $q_{n}(a,\\mathbf b,c)=q_{n-1}(a,\\mathbf b)$.\n%\\item[(ii)] \nIf $n \\leq k$ and $a\\in C$ is independent of $\\e_n,\\e_{n+1}\\dots,\\e_k$, then\n$$q_k(a,\\mathbf b,b_n,\\dots,b_k)=q_{n-1}(a,\\mathbf b),\\quad\\text{for all $b_n,\\dots,b_k\\in C$}.$$\n%\\end{itemize}\n\\end{lemma}\n\n\\begin{proof} Let $\\mathbf e = \\e_1,\\dots,\\e_{n-1}$. First we analyse the case $k=n$.\n%(i)  $q_{n}(a,\\mathbf e,b)=_{(hyp)} q_{n}(q_{n}(a,\\mathbf e,\\e_{n+1}),\\mathbf e,b)=_{(C5,C1,C2)} q_{n}(a,\\mathbf e,\\e_{n+1})=a$.\nSince\n\\begin{equation}\\label{mah}\nq_n(a,\\mathbf b,b_n)=_{(hyp)} q_n(q_n(a,\\mathbf e,\\e_{n+1}),\\mathbf b,b_n)=_{(C5,C1,C2)} q_n(a,\\mathbf b,\\e_{n+1}),\n\\end{equation}\nthen \n\\begin{equation}\\label{mah2} q_{n-1}(a,\\mathbf b)=_{\\mathrm{Lem}\\, \\ref{lem:exc4}} q_n(a,\\mathbf b,\\e_n)=_{(\\ref{mah})}q_n(a,\\mathbf b,\\e_{n+1}) =_{(\\ref{mah})} q_n(a,\\mathbf b,b_n).\n\\end{equation}\nThe general case is obtained by applying several times (\\ref{mah2}) to $q_{n-1}(a,\\mathbf b)$.\n\\end{proof}\n\nLet $a$ be an element of a clone algebra $\\mathbf C$.  We define\n$$\\Gamma(a)= \\{i:\\ \\text{$a$ is dependent on $\\e_i$} \\};\\qquad\n\\gamma(a)=\\begin{cases}\n\\omega&\\text{if $\\Gamma(a)$ is infinite}\\\\ \n0&\\text{if $\\Gamma(a)$ is empty}\\\\ \n\\mathrm{max}(\\Gamma(a)) &\\text{otherwise}\\\\\n\\end{cases}$$\nAn element $a\\in C$ is said to be \\emph{$k$-dimensional} if $\\gamma(a)=k$. An element $a$ is \\emph{finite dimensional} if it is $k$-dimensional for some $k<\\omega$. \n\n\\begin{example}\n  The nullary operator\n$\\e_i$ is $i$-dimensional, because $\\Gamma(\\e_i)=\\{i\\}$ and $\\gamma(\\e_i)=i$.\n\\end{example}\n\n\n\nWe consider the following subsets of  $\\mathbf C$:\n\\begin{itemize}\n\\item The set $\\mathrm{Fi}_k\\,\\mathbf C$ of all elements of $\\mathbf C$ whose dimension is $\\leq k$;\n\\item  The set $\\mathrm{Fi}\\,\\mathbf C=\\bigcup \\mathrm{Fi}_k\\,\\mathbf C$ of all finite dimensional elements of $\\mathbf C$.\n%\\item The set  $\\mathrm{Zd}\\mathbf C$ of all $0$-dimensional elements of $\\mathbf C$. We have $\\mathrm{Zd}\\mathbf C= \\mathrm{Fi}_0\\,\\mathbf C$.\n\\end{itemize}\nWe say that $\\mathbf C$ is \\emph{finite dimensional} if $C=\\mathrm{Fi}\\,\\mathbf C$.\n\n\n\n\\begin{lemma}\\label{lem:preservare}\n\\begin{itemize}\n\\item[(i)]  If $a,\\mathbf b$ have dimension $\\leq k$, then $\\sigma(\\mathbf b)$ and $q_n(a,\\mathbf b)$ have dimension $\\leq k$.\n\\item[(ii)] If $h: \\mathbf C\\to \\mathbf D$ is a homomorphism of clone algebras and $a\\in C$ has dimension $\\leq k$, then $h(a)$ has dimension $\\leq k$ in $\\mathbf D$.\n\\end{itemize}\n\\end{lemma}\n\n\\begin{proof} (i) Let $m > k$,  $\\mathbf e =\\e_1,\\dots,\\e_{m-1},\\e_{m+1}$ and $\\mathbf d =\\e_1,\\dots,\\e_{m-1}$. Then\n $$q_m(\\sigma(\\mathbf b),\\mathbf e)   =_{(C6)}   \\sigma(q_m(b_1,\\mathbf  e),\\dots, q_m(b_n,\\mathbf e))\n  =_{b_i\\ \\text{ind.}\\ \\e_m} %\\sigma(q_{m-1}(b_1,\\mathbf  d),\\dots, q_{m-1}(b_n,\\mathbf  d)) =_{(C3)}\n     \\sigma(\\mathbf b).$$\n If $m > n$, then we have:\n    \\[\n\\begin{array}{lll}\nq_m(q_n(a,\\mathbf b),\\mathbf e)  & =_{(C4)}  &  q_m(a,q_m(b_1,\\mathbf e),\\dots,q_m(b_n, \\mathbf e),\\e_{n+1}\\dots,\\e_{m-1},\\e_{m+1})  \\\\\n  &  =_{b_i\\ \\text{ind.}\\ \\e_m} &  q_m(a,\\mathbf b,\\e_{n+1}\\dots,\\e_{m-1},\\e_{m+1}) \\\\\n  &  =_{a\\ \\text{ind.}\\ \\e_m,\\ \\mathrm{Lem}\\, \\ref{lem:ind1}} &  q_{m-1}(a,\\mathbf b,\\e_{n+1}\\dots,\\e_{m-1}) \\\\\n  & =_{\\text{Lem}\\,  \\ref{lem:exc4}}  &   q_n(a,\\mathbf b)\n\\end{array}\n\\]\nSimilarly, if $m\\leq n$.\n\n(ii) Trivial.\n%If $q_n^\\mathbf C(a,\\e_1,\\dots,\\e_{n-1},\\e_{n+1})=a$ then $h(a)= h(q^\\mathbf C_n(a,\\e_1^\\mathbf C,\\dots,\\e_{n-1}^\\mathbf C,\\e_{n+1}^\\mathbf C))=$\\\\ $=q_n^\\mathbf D(h(a),h(\\e_1^\\mathbf C),\\dots,h(\\e_{n-1}^\\mathbf C),h(\\e_{n+1}^\\mathbf C))=  q_n^\\mathbf D(h(a),\\e_1^\\mathbf D,\\dots,\\e_{n-1}^\\mathbf D,\\e_{n+1}^\\mathbf D).$\n\\end{proof}\n\n\n\\begin{proposition} Let $\\mathbf C$ be a clone $\\tau$-algebra. Then we have:\n\\begin{itemize}\n\\item[(i)]    $\\mathrm{Fi}\\,\\mathbf C$ is a subalgebra of $\\mathbf C$.\n\\item[(ii)]  $\\mathrm{Fi}_k\\,\\mathbf C$ is a subalgebra of $\\mathbf C_\\tau$ closed under all $q$-operators and containing $\\e_1,\\dots,\\e_k$.\n\\item[(iii)] $a\\in \\mathrm{Fi}_0\\,\\mathbf C\\ \\text{and}\\ \\mathbf b\\in C^n\\ \\Longrightarrow\\ q_n(a,\\mathbf b)=a$.\n\\item[(iv)] $a\\in \\mathrm{Fi}\\,\\mathbf C,  n\\geq \\gamma(a)\\ \\text{and}\\ \\mathbf b\\in (\\mathrm{Fi}_0\\,\\mathbf C)^n\\ \\Longrightarrow\\ q_n(a,\\mathbf b)\\in \\mathrm{Fi}_0\\,\\mathbf C$.\n%\\item[(v)] $\\mathrm{Fi}_0\\,\\mathbf C$ is a subalgebra of $\\mathbf C_\\tau$ closed under the $q$ operators.\n\\end{itemize}\n\\end{proposition}\n\n\\begin{proof}\n (i)-(ii) By Lemma \\ref{lem:preservare}.\n \n (iii) The proof is by induction on $n$. By (C3) $q_0(a)=a$.\nBy Lemma \\ref{lem:ind1} and by applying the induction hypothesis we get $q_n(a,b_1,\\dots,b_{n-1},b_n)=q_{n-1}(a,b_1,\\dots,b_{n-1})=a$.\n\n(iv) Let $\\mathbf e = \\e_1,\\dots,\\e_{k-1}$. If $k\\leq n$,  then\n\\[\n\\begin{array}{lll}\n q_k(q_n(a,\\mathbf b),\\mathbf e,\\e_{k+1}) & =_{(C5)}  & q_n(a,q_k(b_1,\\mathbf e,\\e_{k+1}),\\dots,q_k(b_n,\\mathbf e,\\e_{k+1}))  \\\\\n  & =_{b_i\\in \\mathrm{Fi}_0\\,\\mathbf C}  & q_n(a,\\mathbf b)  \\\\\n\\end{array}\n\\]\n If $k >n$, then\n \\[\n\\begin{array}{llll}\n q_k(q_n(a,\\mathbf b),\\mathbf e,\\e_{k+1}) & =_{(C4)}  & q_k(a,q_k(b_1,\\mathbf e,\\e_{k+1}),\\dots,q_k(b_n,\\mathbf e,\\e_{k+1}),\\e_{n+1},\\dots,\\e_{k-1},\\e_{k+1}) & \\\\\n  & =_{b_i\\in \\mathrm{Fi}_0\\,\\mathbf C}  & q_k(a,\\mathbf b,\\e_{n+1},\\dots,\\e_{k-1},\\e_{k+1}) & \\\\\n  & =_{\\gamma(a)<k}  & q_{k-1}(a,\\mathbf b,\\e_{n+1},\\dots,\\e_{k-1}) & \\\\\n    & =_{\\text{Lem}\\ \\ref{lem:exc4}}  & q_{n}(a,\\mathbf b). & \\\\\n\\end{array}\n\\]\n\n\\end{proof}\n\nWe conclude this section with an example. Other examples of clone algebras will be presented in  Section \\ref{sec:dueuno} and Section \\ref{sec:clones}.\n\n\\begin{example} \\label{exa:free} Let $\\mathcal V$ be a variety of algebras of type $\\tau$ and $\\mathbf F_\\mathcal V$ be its free algebra over a countable infinite set $I$ of generators. \n We define  an $n+1$-ary operation $q_n^\\mathbf F$ on $\\mathbf{F}_\\mathcal{V}$ as follows (see \\cite[Definition 3.2]{mac2}). For\n$a,b_1,\\dots,b_n\\in F_\\mathcal{V}$ we put \n$$ q_n^\\mathbf F(a,b_1,\\dots,b_n)=s(a),$$\nwhere $s$ is the unique endomorphism\nof $\\mathbf{F}_\\mathcal{V}$ which sends the generator $ v_i\\in I$ to $b_i$ ($1\\leq i\\leq n$). \nMore suggestively: $q_n^\\mathbf F(a,b_1,\\dots,b_n)$ is the equivalence class of the term \n$t[w_1/v_1,\\dots,w_n/v_n]$, where $t\\in a$ and $w_i\\in b_i$. \nIf we put $\\e_i^\\mathbf F=v_i$, then the algebra $(\\mathbf F_\\mathcal V,q_n^\\mathbf F, \\e_i^\\mathbf F)$ is a clone $\\tau$-algebra.\nWe remark that Lampe's proof of the Zipper condition described in Section \\ref{sec:pre:leq} uses the operator $q_2^\\mathbf F$  (see the proof of McKenzie Lemma in \\cite{lampe}).\n\\end{example}\n\n%\\begin{example}\\label{exa:elleomega} Let $L$ be a bounded lattice. \n%$L^\\omega$ becomes a pure clone algebra if we define the operator $q_n$ and the constants $\\e_i$ as follows, for all elements $x,y^1,\\dots,y^n\\in L^\\omega$:\n%$$\n%q_n( x,y^1,\\dots ,y^n) =(\\bigvee\\limits_{i=1}^{n}(x_{i}\\land y_{1}^{i}),\\dots,\\bigvee\\limits_{i=1}^{n}(x_{i}\\land y_{n}^{i}),x_{n+1},x_{n+2},\\dots);\\quad \\e_i=(0,\\dots,0,1,0,\\dots),$$\n%where $1$ is at position $i$. It is a simple exercise to verify  identities (C1)-(C5). \n%\\end{example}\n\n%\\begin{example} Let $R$ be a ring with unity. We define the finite dimensional clone algebra $\\mathbf L=(L,q_n^\\mathbf L,\\e_i^\\mathbf L)$ of all linear polynomials on $x_1,x_2,\\dots,x_n,\\dots$ as follows: \n%\\begin{enumerate}\n%\\item $L=\\{r_0+\\sum_{i=1}^\\omega r_ix_i : r_i\\in R, |\\{i: r_i\\neq 0\\}|< \\omega\\}$;\n%\\item $\\e^\\mathbf L_i=x_i$;\n%%\\item $q_n(\\sum_{i=1}^\\omega r_ix_i, \\sum_{j=1}^\\omega s^1_jx_j,\\dots,\\sum_{j=1}^\\omega s^n_jx_j)=\\sum_{i=1}^k r_i(\\sum_{j=1}^\\omega s^i_jx_j)$ if $k\\leq n$;\n%\\item $q_n^\\mathbf L(r_0+\\sum_{i=1}^\\omega r_ix_i, s^1_0+\\sum_{j=1}^\\omega s^1_jx_j,\\dots,s^n_0+\\sum_{j=1}^\\omega s^n_jx_j)=$\\\\\n%$\\qquad\\qquad r_0+\\sum_{i=1}^n r_i(s^i_0+\\sum_{j=1}^\\omega s^i_jx_j)+\\sum_{i=n+1}^\\omega r_ix_i$.\n%\\end{enumerate}\n%It is a simple exercise to verify  identities (C1)-(C5). \n%\\end{example}\n\n\n\n\n\n\\section{Functional Clone Algebras}\\label{sec:dueuno}\n The most natural $\\mathsf{CA}$s, the ones the axioms are intended to characterise, are algebras of functions, called \\emph{functional clone algebras}. They will be introduced in this section.\n The elements of a functional clone algebra are infinitary functions from $A^\\omega$ into $A$, for a given set $A$. In this framework  $q_n(\\varphi,\\psi_1,\\dots,\\psi_n)$ represents the $n$-ary composition of $\\varphi$ with $\\psi_1,\\dots,\\psi_n$, acting on the first $n$ coordinates:\n $$q_n(\\varphi,\\psi_1,\\dots,\\psi_n)(s)= \\varphi(\\psi_1(s),\\dots,\\psi_n(s),s_{n+1},s_{n+2},\\dots),\\ \\text{for every $s\\in A^\\omega$}$$\nand the nullary operators are the projections $p_i$ defined by $p_i(s)=s_i$ for every $s\\in A^\\omega$.\nHence, the universe of a functional clone algebra is a set of infinitary operations containing the projection $p_i$ and closed under finitary compositions, called hereafter \\emph{$\\omega$-clone}.\n We will see in Section \\ref{sec:clones}  that there exists a bijective correspondence between clones (of  operations) and a suitable class of functional clone algebras, called \\emph{block algebras}. \n Given a clone, the corresponding block algebra is obtained by extending the operations of the clone by countably many dummy arguments.\n % [Dire che l'omega clone di una block algebra proviene da un clone per espansione delle funzione finite del clone con  argomenti non essenziali]\n\n  A clone algebra is functionally representable if it is isomorphic to a functional clone algebra. One of the main results of this paper is the general representation theorem of Section \\ref{sec:GRT}, where it is shown that every $\\mathsf{CA}$ is functionally representable. \nTherefore, the clone algebras are the algebraic counterpart of $\\omega$-clones, while the block algebras are the algebraic counterpart of clones. By Corollary \\ref{cor:cablk}  the variety of clone algebras is generated by the class of block algebras. Then every $\\omega$-clone is algebraically generated by a suitable family of clones by using direct products, subalgebras and homomorphic images.\n%[This implies that every $\\omega$-clone is built from a suitable family of  clones .]\n\n\\bigskip\n\nLet $A$ be a set.  We denote by $\\mathcal O_A^{(\\omega)}$\n the set of all functions from $A^\\omega$ into $A$. If $r\\in A^\\omega$ and $a_1,\\dots,a_n\\in A$ then $r[a_1,\\dots,a_n]\\in A^\\omega$ is defined by\n $$r[a_1,\\dots,a_n](i)=\\begin{cases}a_i&\\text{if $i\\leq n$}\\\\ r_i&\\text{if $i > n$}\\end{cases}$$\n\n\n\\begin{lemma}\\label{lem:fun} Let $\\mathbf A$ be a $\\tau$-algebra.\nThe algebra ${\\mathbf O}_\\mathbf A^{(\\omega)}=(\\mathcal O_A^{(\\omega)},\\sigma^\\omega, q^\\omega_n,\\e^\\omega_i)$, where, for every $s\\in A^\\omega$ and $\\varphi,\\psi_1,\\dots,\\psi_n\\in \\mathcal O_A^{(\\omega)}$, \n\\begin{itemize}\n\\item $\\e^\\omega_i(s)=s_i$;\n\\item $q^\\omega_n(\\varphi,\\psi_1,\\dots,\\psi_n)(s)=\\varphi(s[\\psi_1(s),\\dots, \\psi_n(s)])$;\n\\item $\\sigma^\\omega(\\psi_1,\\dots,\\psi_n)(s)=\\sigma^\\mathbf A(\\psi_1(s),\\dots, \\psi_n(s))$ for every $\\sigma\\in\\tau$ of arity $n$;\n\\end{itemize}\n is a clone algebra of type $\\tau$, called the \\emph{full functional $\\mathsf{CA}$ with value domain $\\mathbf A$}. \\end{lemma}\n\n\\begin{proof} We prove (C5). The other identities  can be proved in a similar way.\n\\[\n\\begin{array}{lll}\n&&q_k^\\omega(q_n^\\omega(\\varphi,\\psi_1,\\dots,\\psi_n),\\chi_1,\\dots,\\chi_k)(s)  \\\\\n&  = &  q_n^\\omega(\\varphi,\\psi_1,\\dots,\\psi_n)(s[\\chi_1(s),\\dots, \\chi_k(s)]) \\\\\n  &  = & \\varphi(s[\\psi_1(s[\\chi_1(s),\\dots, \\chi_k(s)]),\\dots, \\psi_n(s[\\chi_1(s),\\dots, \\chi_k(s)])])  \\\\\n  &  = &   \\varphi(s[q_k^\\omega(\\psi_1,\\chi_1,\\dots,\\chi_k)(s),\\dots,q_k^\\omega(\\psi_n,\\chi_1,\\dots,\\chi_k)(s)])\\\\\n  &=&q_n^\\omega(\\varphi,q_k^\\omega(\\psi_1,\\chi_1,\\dots,\\chi_k),\\dots, q_k^\\omega(\\psi_n,\\chi_1,\\dots,\\chi_k))(s) \\\\\n\\end{array}\n\\] %We leave to the reader the proof of the other  axiomatising clone algebras.\n\\end{proof}\n\n\\begin{definition} \n A subalgebra of ${\\mathbf O}_\\mathbf A^{(\\omega)}$  is called a \\emph{functional clone algebra with value domain} $\\mathbf A$.\n\\end{definition}\n \n The class of  functional clone algebras is denoted by $\\mathsf{FCA}$.  $\\mathsf{FCA}_\\tau$  is the class of $\\mathsf{FCA}$s   whose value domain is a $\\tau$-algebra.\n We also use $\\mathsf{FCA}_\\tau$ as shorthand for the phrase ``functional clone algebra of type $\\tau$'', and similarly for $\\mathsf{FCA}$. \n \n \n%The universe of a $\\mathsf{FCA}$ with value domain $A$, which is a set of infinitary operations containing the projections $\\e_i^\\omega$ and closed under the finitary compositions $q_n^\\omega$, will be called \\emph{$\\omega$-clone on $A$}. In Section \\ref{sec:clones} we show that there exists a bijective correspondence between clones (of  operations) and a suitable class of $\\omega$-clones.\n \nIn the following lemma the algebraic and functional notions of independence  are shown equivalent.\n\n\\begin{lemma}\\label{lem:independent}\n  An infinitary operation  $\\varphi\\in \\mathcal O_A^{(\\omega)}$  is \\emph{independent of $\\e_n$} iff, for all $s,u\\in A^\\omega$, $u_i=s_i$ for all $i\\neq n$ implies $\\varphi(u) = \\varphi(s)$.\n\\end{lemma}\n\n\\begin{proof} Let $\\mathbf e=\\e_1,\\dots,\\e_{n-1}$ and $s,u\\in A^\\omega$ such that $u_i=s_i$ for all $i\\neq n$. Let \n$\\mathbf u=u_1,\\dots,u_{n-1}$ and $\\mathbf s=s_1,\\dots,s_{n-1}$.\n\n($\\Rightarrow$) If $\\varphi=q^\\omega_n(\\varphi,\\mathbf e,\\e_{n+1})$ then \n$\\varphi(u)= q^\\omega_n(\\varphi,\\mathbf e,\\e_{n+1})(u)= \\varphi(u[\\mathbf u,u_{n+1}])= \n \\varphi(s[\\mathbf s,s_{n+1}])=\\dots=\\varphi(s)$, because $u_i=s_i$ for all $i\\neq n$.\n \n($\\Leftarrow$) $\\varphi(s)=  \\varphi(s[\\mathbf s,s_n])= \\varphi(s[\\mathbf s,s_{n+1}])= q^\\omega_n(\\varphi,\\mathbf e,\\e_{n+1})(s)$, because\n$s_i=s[\\mathbf s,s_n]_i= s[\\mathbf s,s_{n+1}]_i$ for all $i\\neq n$.\n\\end{proof}\n\n%\\begin{corollary}\\label{cor:independent} $f\\in \\mathcal O_A^{(\\omega)}$ has dimension $k$ iff the following two conditions hold:\n%\\begin{itemize}\n%\\item[(i)] For every $n>k$ and every $s,u\\in A^\\omega$ such that $u_i=s_i$ for all $i\\neq n$, we have $f(s)=f(u)$;\n%\\item[(ii)] There exist $s,u\\in A^\\omega$ such that $u_i=s_i$ for all $i\\neq k$ and $f(s)\\neq f(u)$.\n%\\end{itemize}\n%\\end{corollary}\n\n%We define an equivalence relation on $A^\\omega$ as follows $r\\equiv s\\ \\text{iff}\\ |\\{i: r_i\\neq s_i\\}|<\\omega$.\n%Let $A^\\omega_r=\\{s\\in A^\\omega : s\\equiv r\\}$ be the equivalence class of $r$ and $A^\\top_r$ be the set of all functions from $A^\\omega_r$ to $A$. Since $A^\\omega_r\\subseteq A^\\omega$, then there is a restriction map from $A^\\top$ onto $A^\\top_r$ mapping \n%$f\\in A^\\top$ to its restriction $f_r: A^\\omega_r\\to A\\in A^\\top_r$ such that $f_r(s)=f(s)$ for every $s\\in A^\\omega_r$.\n\n\\begin{example}\\label{exa:semi}\n  We now provide an example of a zero-dimensional element of a $\\mathsf{FCA}$ that is not a constant function.\nA function $\\varphi:A^\\omega\\to A$ is \\emph{semiconstant} if it is not constant and, for every $r,s\\in A^\\omega$, $|\\{i: r_i\\neq s_i\\}|<\\omega$ implies $\\varphi(r)=\\varphi(s)$. Let $2=\\{0,1\\}$.\nThe function $\\varphi:2^\\omega\\to 2$, defined by \n$$\\varphi(s)=\\begin{cases}0&\\text{if $|\\{i:s_i=0\\}|<\\omega$}\\\\\n1&\\text{otherwise}\\end{cases}$$\nis an example of semiconstant function.\nIt is easy to see that every  semiconstant function  is zero-dimensional in the full $\\mathsf{FCA}$ $\\mathcal O_A^{(\\omega)}$.\n\n%[Commento: dire che forse FCA non e' la classe piu' adatta meglio sono le RCA]\n\\end{example}\n\n\\begin{example} Let $2=\\{0,1\\}$. The function $\\psi:2^\\omega\\to 2$, defined by \n$$\\psi(s)=\\begin{cases}0&\\text{if $|\\{i:s_i=0\\}|$ is finite and even }\\\\\n1&\\text{otherwise}\\end{cases}$$\nis infinite dimensional. If $s,r\\in 2^\\omega$, $s_i=r_i$ for every $i\\neq n$, $s_n=0$, $r_n=1$ and $|\\{i:s_i=0\\}|$ is finite and even, then $\\psi(s)=0$ and $\\psi(r)=1$. By Lemma \\ref{lem:independent} the function $\\psi$ depends on $\\e_n$ for every $n$.\n\\end{example}\n\nIn the following proposition we show that the notions of clone algebra and Neumann's abstract $\\aleph_0$-clone (see Section \\ref{sec:neu}) are distinct.\n\n\\begin{proposition} Every  abstract $\\aleph_0$-clone is a clone algebra, but there are functional clone algebras that are not functional $\\aleph_0$-clones.\n\\end{proposition}\n\n\\begin{proof} Every  abstract $\\aleph_0$-clone is a clone algebra because \n$$q_n(x,y_1,\\dots,y_n)=q_\\infty(x,y_1,\\dots,y_n,\\e_{n+1},\\e_{n+2},\\dots).$$\nWe now show that the subalgebra $\\{\\psi:2^\\omega \\to 2\\ |\\ \\text{$\\psi$ is semiconstant}\\}\\cup\\{\\e_i^\\omega\\ |\\  i\\geq 1\\}$  of the full $\\mathsf{FCA}$ $\\mathcal O_2^{(\\omega)}$ is not an abstract $\\aleph_0$-clone.\n  Let $s,r\\in 2^\\omega$ such that $s_i=0$ and $r_i=1$ for all $i$. \n If $\\varphi:2^\\omega\\to 2$ is any semiconstant function such that $\\varphi(s)=0$ and  $\\varphi(r)=1$, then $q_\\infty^\\omega(\\varphi,\\e_1^\\omega,\\e_1^\\omega,\\dots,\\e_1^\\omega,\\dots)$ is not a semiconstant function. \n %However, the set $\\{\\psi:2^\\omega \\to 2\\ |\\ \\text{$\\psi$ is semiconstant}\\}\\cup\\{\\e_i^\\omega\\ |\\  i\\geq 1\\}$ is a subalgebra of the full $\\mathsf{FCA}$ $\\mathcal O_2^{(\\omega)}$.\n\\end{proof}\n\n\n \\section{Clones of operations and block algebras}\\label{sec:clones}\n In this section we introduce an equivalence relation over the set $\\mathcal O_A$ of operations of a given set, in order to turn $\\mathcal O_A$ into a functional clone algebra. Roughly speaking, two operations are equivalent if the one having greater arity extends the other one by a bunch of dummy arguments.\nEach \\emph{block} (equivalence class) of this equivalence relation determines univocally an infinitary function that we call the\\emph{ top extension} of the block. The set of these top extensions is a $\\omega$-clone and it is exactly the functional clone algebra associated to $\\mathcal O_A$, called \\emph{full block algebra on $A$}.\n \n \\bigskip\n %The following partial order and equivalence relation were defined by Sangalli in \\cite{sangalli}.\n \nWe  define a partial order $\\preceq$ on the set $\\mathcal O_A$ of all operations (see \\cite{sangalli}). For all $f\\in \\mathcal O^{(k)}_A$ and $g\\in \\mathcal O^{(n)}_A$ we put\n$$f\\preceq g \\Leftrightarrow k\\leq n\\ \\text{and}\\ \\forall \\mathbf a\\in A^k\\ \\forall \\mathbf b\\in A^{n-k}:\\ f(\\mathbf a)=g(\\mathbf a,\\mathbf b).$$ \nUsing the terminology of Section \\ref{sec:clo}, the operation $g$ is fictitious in the last $n-k$ arguments.\n\n\n\\begin{definition}\\label{def:similar}\n We say that two operations $f,g\\in \\mathcal O_A$ are \\emph{similar}, and we write $f\\approx_{\\mathcal O_A} g$, if  either $f\\preceq g$ or $g\\preceq f$.\n\\end{definition}\n\n\\begin{lemma} \\cite[Lemma 1]{sangalli}\n \\begin{enumerate}\n\\item The relation $\\approx_{\\mathcal O_A}$ is an equivalence relation on $\\mathcal O_A$. \n\\item Each block (i.e., equivalence class) of the relation $\\approx_{\\mathcal O_A}$ is totally ordered by $\\preceq$. \n\\end{enumerate}\n\\end{lemma}\n\n%Sangalli \\cite{sangalli} has used the above equivalence to show that every abstract clone $C$ (see Section \\ref{sec:attempt}) is isomorphic to the clone of all operations on some set $X_C$, which are preserved by a monoid $M_C$ of transformations of $X_C$.\n\n%\\bigskip\n%In the following ``$B$ is block'' or ``$B$ is block on $A$'' means ``$B$ is a block (i.e., equivalence class) of the equivalence relation $\\approx_{\\mathcal O_A}$''. Every block $B$ is totally ordered w.r.t. $\\preceq$. \n\nWe denote by $\\mathcal{B}_A$ the set of all blocks of the relation $\\approx_{\\mathcal O_A}$.\n\nIf $f\\in\\mathcal O_A$ then $\\langle f\\rangle$ denotes the unique block containing $f$. \n\n\n\n\\begin{definition}\n\\begin{enumerate}\n\\item  An operation $f$ is said to be \\emph{a generator} if $f$ is the minimal element w.r.t. $\\preceq$ of the unique block $\\langle f\\rangle$ containing $f$.\n\\item A block $B$ \\emph{has arity} $k$ if the generator of the block $B$ has arity $k$.\n\\end{enumerate}\n\\end{definition}\n\n%We denote by $B^\\bullet$ the generator of the block $B$.\n\nIf $B$ is a block of arity $k$, then $|B \\cap \\mathcal O^{(n)}_A|= 1$ for every $n\\geq k$, and $|B \\cap \\mathcal O^{(n)}_A|= \\emptyset$ for every $n< k$.\n\nAs a matter of notation, if $B$ is a block of arity $k$, then we denote by $B^{(n)}$ ($n\\geq k$) the unique function in $B\\cap \\mathcal O^{(n)}_A$. Therefore, $B = \\{B^{(n)} : n\\geq k\\}$ and $B^{(k)}$ is the generator of the block $B$.\n\n\\begin{lemma}\\label{lem:generator}\n An operation $f:A^k\\to A$ is a generator if and only if either $k=0$ or there are $a_1,\\dots,a_{k-1}$, $b,c\\in A$ such that\n $f(a_1,\\dots,a_{k-1},b) \\neq f(a_1,\\dots,a_{k-1},c)$.\n\\end{lemma}\n\n\\begin{example} The constant operations of value $a$ are all equivalent: $c^{(n)}_a\\approx_{\\mathcal O_A} c^{(k)}_a$ for all $n$ and $k$. The block containing all $c^{(n)}_a$ has arity $0$, because it is generated by $c^{(0)}_a$. This block  will be denoted by $C_a$ and will be called \\emph{constant block (of value $a$)}.\n\\end{example}\n\n\\begin{example} We have $p^{(n)}_i\\approx_{\\mathcal O_A} p_i$ for every $n\\geq i$, where $p_i=p^{(i)}_i$.\nThe block generated by the basic projection $p_i$ contains all the projections $p^{(n)}_i$ ($n\\geq i$) and has arity $i$. This block will be denoted by $P_i$ and will be called \\emph{projection block}.\n\\end{example}\n\n\n\\begin{lemma}\\label{lemclone} Every clone  is union of blocks.\n\\end{lemma}\n\n\\begin{proof} Let $F$ be a clone on $A$, $f\\in  F$ be an operation of arity $n$ and $g:A^k\\to A$ be the generator of the block $\\langle f\\rangle$. If $f= c_a^{(n)}$ is a constant function, then by Definition \\ref{def:clo} the element $g=c_a^{(0)}$ of $A$ belongs to $F$ and $\\langle f\\rangle^{(m)}=g()_m\\in  F$ for all $m\\geq 0$.\n  If $f$ is not constant, then $g=f(p^{(k)}_1,\\dots,p^{(k)}_k, p^{(k)}_k,\\dots,p^{(k)}_k)_k\\in F$ and $\\langle f\\rangle^{(m)}=g(p^{(m)}_1,\\dots,p^{(m)}_k)_m\\in  F$ for all $m\\geq k$. In conclusion, $\\langle f\\rangle \\subseteq  F$. \n\\end{proof}\n\n\n\n\n\n\\subsection{Block algebras and top extensions of blocks}\\label{sec:blocktop}\nIn this section we study the properties that a family $G$ of blocks of the relation $\\approx_{\\mathcal O_A}$ must have \nfor  $\\bigcup G$ to be a clone on $A$.\nTo simplify the approach it is convenient to work with infinitary functions from $A^\\omega$ to $A$.\nWe recall  that  $\\mathcal O^{(\\omega)}_A=\\{\\varphi\\ |\\ \\varphi:A^\\omega\\to A\\}$.\n\n\\begin{definition} The \\emph{top operator} is a map $(-)^\\top:\\mathcal O_A\\to\\mathcal O^{(\\omega)}_A$\n defined as follows, for every $f\\in \\mathcal O_A^{(n)}$:\n $$f^\\top(s)=f(s_1,\\dots,s_n),\\quad \\text{for all $s\\in A^\\omega$}.$$ \n\\end{definition}\nThe infinitary operation  $f^\\top$, defined by Neumann \\cite{neu70} to formalise $\\aleph_0$-clones (see Section \\ref{sec:neu}), will be called\n \\emph{the top extension} of the operation $f\\in \\mathcal O_A$.\n \nThe proof of the following lemma is trivial.\n\n\\begin{lemma}\\label{lem:similar} Let $f,g\\in\\mathcal O_A$. Then\n  $f\\approx_{\\mathcal O_A} g$ iff $f^\\top = g^\\top$.\n\\end{lemma}\n\nIn other words, the kernel of the top operator coincides with the relation of similarity among operations. This means that the set $\\mathcal B_A$ of blocks of the relation $\\approx_{\\mathcal O_A}$ coincides with the set $\\mathcal O_A$ modulo the kernel of the top operator.\n\nBy Lemma \\ref{lem:similar} the \\emph{top extension $B^\\top$ of a block} $B$ can be well defined as  \n$B^\\top=f^\\top$ for some (and then all) $f\\in B$.\nThen the map $B\\mapsto B^\\top$ embeds the set $\\mathcal B_A$ of blocks into $\\mathcal O^{(\\omega)}_A$. Its\n image $\\{B^\\top: B\\in \\mathcal B_A\\}$ will be denoted by $\\mathcal B_A^\\top$. $\\mathcal B_A$ and $\\mathcal B_A^\\top$ are equipotent sets.\n\nIf $\\varphi$ is the top extension of a block, then we denote by $\\varphi_\\bot$ the unique block such that \n$(\\varphi_\\bot)^\\top=\\varphi$. By Lemma \\ref{lem:similar} the block $\\varphi_\\bot$ is well defined.\n\n\nNotice that the notion of dimension is an intrinsic property of a function $\\varphi\\in \\mathcal O^{(\\omega)}_A$: if $\\varphi$ has dimension $k$ in a $\\mathsf{FCA}$, then by Lemma \\ref{lem:independent} $\\varphi$ has dimension $k$ in every $\\mathsf{FCA}$ containing $\\varphi$.\n\n%Notice that, if $g:A^\\omega \\to A$ has dimension $k$ in some functional clone algebra $\\mathbf F$ with value domain $A$ such that $g\\in F$, then $g$ has dimension $k$ in every functional clone algebra with value domain $A$ containing $g$.\n\n\n\\begin{lemma}\\label{lem:ardim}\nA block $B\\in\\mathcal B_A$  has arity $r$  if and only if $B^\\top$ has dimension $r$.\n\\end{lemma}\n\n\\begin{proof} ($\\Rightarrow$) First we prove that, if $r$ is the arity of a block $B$, then $B^\\top$ is dependent on $\\e_r$.\nLet $a_1,\\dots, a_{r-1},b,c\\in A$ such that $B^{(r)}(a_1,\\dots,a_{r-1},b)\\neq B^{(r)}(a_1,\\dots,a_{r-1},c)$. Let $s,u\\in A^\\omega$ such that $s_r=b$,  $u_r=c$, $s_i=u_i=a_i$ for every $i=1,\\dots, r-1$  and $s_j=u_j$ for every $j > r$.\nThen $B^\\top(s)= B^{(r)}(s_1,\\dots,s_r)\\neq B^{(r)}(u_1,\\dots,u_r)=B^\\top(u)$. By Lemma \\ref{lem:independent}  $B^\\top$ is dependent on $\\e_r$, where $r$ is the arity of the block $B$.\n\nWe now show that $B^\\top$ is independent of $\\e_k$ for every $k > r$, the arity of $B$. \nFor every $s,u\\in A^\\omega$ such that $s_i=u_i$ for every $i\\neq k$ we have:\n$$B^\\top(s)= B^{(r)}(s_1,\\dots,s_r)=_{(\\text{$s_i=u_i$ for $i\\leq r$})}B^{(r)}(u_1,\\dots,u_r) =B^\\top(u).$$ \nThen by Lemma \\ref{lem:independent} $B^\\top$ is independent of $\\e_k$.\n\n($\\Leftarrow$) Let $k$ be the arity of the block $B$. Since $B^\\top(s)= B^{(k)}(s_1,\\dots,s_k)$ for all $s\\in A^\\omega$, then it is easy to verify that $k=r$.\n\\end{proof}\n\nThere exist finite dimensional elements of $\\mathcal O^{(\\omega)}_A$ that are not top extension of a block.\nThe semiconstant functions are defined in Example \\ref{exa:semi}.\n\n\\begin{lemma}\\label{lem:semiconstant}\nEvery semiconstant function $\\varphi\\in \\mathcal O^{(\\omega)}_A$  is zero-dimensional but it is not the top extension of any  operation. \n\\end{lemma}\n\n\\begin{proof} The function $\\varphi:\\{0,1\\}^\\omega\\to \\{0,1\\}$ defined in Example \\ref{exa:semi} is zero-dimensional but it is not the top extension of a constant.\n \\end{proof}\n \n We now are ready to define a structure of clone algebra on $\\mathcal B_A^\\top$.\n \n Recall that the full $\\mathsf{FCA}$ $\\mathbf O^{(\\omega)}_A$ with value domain $A$ was introduced in Lemma \\ref{lem:fun}.\n\n\\begin{lemma}\n $\\mathcal B_A^\\top$ is a finite dimensional subalgebra of the full $\\mathsf{FCA}$ $\\mathbf O^{(\\omega)}_A$ with value domain $A$.\n\\end{lemma}\n\n\\begin{proof}\n First $\\e_i^\\omega = P_i^\\top$, where $P_i$ is the block of all projections $p^{(k)}_i$. We now show that $\\mathcal B_A^\\top$ is closed under the operations $q_n^\\omega$. Let $B,G_1,\\dots,G_n$ be blocks and let $k\\geq n$ be greater than the arities of $B,G_1,\\dots,G_n$. We now show that $q_n^\\omega(B^\\top,G_1^\\top,\\dots,G_n^\\top)$ is the top extension of a suitable function of arity $k$. Let $s\\in A^\\omega$.\n \\[\n\\begin{array}{lll}\n  &   & q_n^\\omega(B^\\top,G_1^\\top,\\dots,G_n^\\top)(s)  \\\\\n  &  = & B^\\top(s[G_1^\\top(s),\\dots,G_n^\\top(s)])  \\\\\n  & =  &   B^\\top(s[G_1^\\top(s),\\dots,G_n^\\top(s),s_{n+1},\\dots,s_k])\\\\\n   & =  &B^{(k)}(G_1^\\top(s),\\dots,G_n^\\top(s),s_{n+1},\\dots,s_k)\\\\\n & =  &  B^{(k)}(G_1^{(k)}(s_{1},\\dots,s_k),\\dots, G_n^{(k)}(s_{1},\\dots,s_k),s_{n+1},\\dots,s_k)\\\\\n & =  &  B^{(k)}(G_1^{(k)}(s_{1},\\dots,s_k),\\dots, G_n^{(k)}(s_{1},\\dots,s_k),P_{n+1}^{(k)}(s_{1},\\dots,s_k),\\dots,P_{k}^{(k)}(s_{1},\\dots,s_k))\\\\\n & =  &  [B^{(k)}(G_1^{(k)},\\dots, G_n^{(k)},P_{n+1}^{(k)},\\dots,P_{k}^{(k)})]^\\top(s).\n\\end{array}\n\\]\n\\end{proof}\n\nThe $\\mathsf{FCA}$ $\\mathcal B_A^\\top$ will be called \\emph{the full block algebra on $A$}.\n\n\\begin{definition}\n A \\emph{block algebra on $A$} is a subalgebra of the full block algebra $\\mathcal B_A^\\top$.\n\\end{definition}\n\n A \\emph{block algebra on a $\\tau$-algebra $\\mathbf A$} is a block algebra on $A$ containing $\\langle\\sigma^\\mathbf A\\rangle^\\top$ for every $\\sigma\\in\\tau$.\n \n \n\\begin{remark} By Lemma \\ref{lem:semiconstant}\nnot every finite dimensional $\\mathsf{FCA}$  with value domain $A$ is a block algebra on $A$. However, we will show in Theorem \\ref{thm:firstrepresentation} below that every finite dimensional $\\mathsf{FCA}$ with value domain $A$ is isomorphic to a block algebra on a possibly different value domain. \n\\end{remark}\n\n%\\subsection{The lattice of all clones on a set $A$} [commento]\n\n If $F\\subseteq \\mathcal O_A$, then we define $F^\\top=\\{f^\\top: f\\in F\\}$. \n If $G\\subseteq \\mathcal B_A^\\top$ then we define $G_\\bot=\\{\\varphi_\\bot: \\varphi\\in G\\}$, where $\\varphi_\\bot$ is a block for every $\\varphi\\in G$.\n \n% The proof of the following three propositions is now standard.\n \n \\begin{proposition}\\label{prop:cloneblock}\n Let $F\\subseteq \\mathcal O_A$ and $\\mathbf A$ be an algebra. Then the following conditions are equivalent:\n\\begin{description}\n\\item[(i)] $F$ is a clone on $\\mathbf A$;\n%\\item[(ii)]  $\\langle F\\rangle=\\{\\langle f\\rangle: f\\in F\\}$ is a clone of blocks;\n\\item[(ii)] $F^\\top$ is a block algebra on $\\mathbf A$.\n\\end{description}\nMoreover,  $\\bigcup\\, (F^\\top)_\\bot=F$.\n\\end{proposition}\n\n\\begin{proof} (i) $\\Rightarrow$ (ii)\n First we have $(p^n_i)^\\top =\\e_i^\\omega$. We now check the closure under $q_n^\\omega$ by showing that\n$q_n^\\omega(f^\\top,g_1^\\top,\\dots,g_n^\\top)\\in F^\\top$ for all $f,g_1,\\dots,g_n\\in F$.\n Let $k\\geq n$ be greater than the arities of $f,g_1,\\dots,g_n$. \nFor every $s\\in A^\\omega$, we have:\n\\begin{equation}\\label{bbbbb}\n\\begin{array}{rll}\nq_n^\\omega(f^\\top,g_1^\\top,\\dots,g_n^\\top)(s)&  = &f^\\top(s[g_1^\\top(s),\\dots,g_n^\\top(s)])\\\\\n&  = &\\langle f\\rangle^{(k)}(g_1^\\top(s),\\dots,g_n^\\top(s),s_{n+1},\\dots,s_k)\\\\\n&  = &\\langle f\\rangle^{(k)}(\\langle g_1\\rangle^{(k)}(s_1,\\dots,s_k),\\dots, \\langle g_n\\rangle^{(k)}(s_1,\\dots,s_k),s_{n+1},\\dots,s_k)\\\\\n&  = &\\langle f\\rangle^{(k)}(\\langle g_1\\rangle^{(k)},\\dots, \\langle g_n\\rangle^{(k)},P^{(k)}_{n+1},\\dots,P_k^{(k)})_k(s_1,\\dots,s_k)\\\\\n\\end{array}\n\\end{equation}\nwhere $h=\\langle f\\rangle^{(k)}(\\langle g_1\\rangle^{(k)},\\dots, \\langle g_n\\rangle^{(k)},P^{(k)}_{n+1},\\dots,P_k^{(k)})_k\\in F$ because $F$ contains the blocks $\\langle f\\rangle$, $\\langle g_i\\rangle$ and $P_i$. Then $q_n^\\omega(f^\\top,g_1^\\top,\\dots,g_n^\\top)$ is the top expansion of the above function $h\\in F$.\n\n(ii) $\\Rightarrow$ (i) If $f\\in F^{(n)}$ and $g_1,\\dots,g_n\\in F^{(k)}$, then $ f( g_1,\\dots, g_n)_k\\in q_n^\\omega(f^\\top,g_1^\\top,\\dots,g_n^\\top)_\\bot.$\n\\end{proof}\n\nAs a consequence of the above proposition, there exists a bijection between the set of clones on  $A$ and the set of block algebras on $A$.\n\n% \\begin{proposition}\\label{prop:blockclone}\n% Let $G\\subseteq \\mathcal B_A^\\top$.\n% Then the following conditions are equivalent:\n%\\begin{description}\n%\\item[(i)] $G$ is a block algebra on $A$;\n%\\item[(ii)] $\\bigcup G_\\bot$ is a clone.\n%\\end{description}\n%Moreover,  $(G_\\bot)^\\top=G$.\n%\\end{proposition}\n\n \n \\begin{corollary}\\label{cor:cloneblock} Let $A$ be a set. Then the following lattices are isomorphic:\n\\begin{enumerate}\n\\item The lattice $\\mathrm{Lat}(\\mathcal O_A)$ of all clones on $A$;\n\\item The lattice of all subalgebras of the full block algebra $\\mathcal B_A^\\top$.\n%\\item The lattice of the clones of blocks on $A$;\n\\end{enumerate}\n\\end{corollary}\n\n%\\begin{proof} By Lemma \\ref{lemclone} a clone $F$ on $A$ is union of blocks and it closed under composition.\n%Then $F^\\top = \\{ B^\\top : B\\in F\\}$ is a block algebra on $A$. \n%If $F$ is a block algebra on $A$, then $\\{f\\in\\mathcal O_A: f^\\top\\in F\\}$ is a clone of  operations.  \n%\\end{proof}\n\n\n\n \n% \\begin{definition} A set $X$ of blocks is called \n% a \\emph{clone of blocks on $A$}  if $X^\\top = \\{ B^\\top : B\\in X\\}$ is a block algebra on $\\mathbf A$. \n%\\end{definition}\n\n \n\n\n%\\begin{lemma} \\label{lem:toptop}\n%Let $f\\in A^\\top_r$. Then the following conditions are equivalent:\n%\\begin{itemize}\n%\\item[(i)] $f=B^\\top_r$ for some block $B\\in\\mathcal B_A$;\n%\\item[(ii)] There exists $k$ such that $f(s)=f(r[s_1,\\dots,s_n])$ for every $s\\in A^\\omega_r$ and $n\\geq k$;\n%\\item[(iii)] $f$ is finite dimensional in the clone algebra $A^\\top_r$.\n%\\end{itemize} \n%\\end{lemma}\n%\n%\\begin{proof} (i) $\\Rightarrow$ (ii) If $B$ has arity $k$ then \n%$f(s)= B^\\top_r(s)=B^{(n)}(s_1,\\dots,s_n)=B^\\top_r(r[s_1,\\dots,s_n]) =f(r[s_1,\\dots,s_n])$ for every $s\\in A^\\omega_r$ and $n\\geq k$. \n%\n%(ii) $\\Rightarrow$ (iii) Let $f(s)=f(r[s_1,\\dots,s_n])$ for every $s\\in A^\\omega_r$ and $n\\geq k$. We now prove that \n%$f$ is independent of $\\e_n$ for every $n> k$. Let\n%$s,u\\in A^\\omega_r$ such that $s_i=u_i$ for every $i\\neq n$.\n%Then  $f(s)=f(r[s_1,\\dots,s_k]) = f(r[u_1,\\dots,u_k]) = f(u)$. Then by Lemma \\ref{lem:independent} $f$ is independent of $\\e_n$ for every $n>k$. In other words, $f$ is finite dimensional.\n% \n% (iii) $\\Rightarrow$ (i) Let $n$ be the dimension of $f$ and $g=f_{n,r}$ and $s\\in A^\\omega_r$. We have to show that  $f(s)=g^\\top_r(s)$. \n% Let $k$ be the minimal natural such that $s=r[s_1,\\dots,s_k]$. If $k \\leq n$ then $s_i=r_i$ for all $k+1\\leq i\\leq n$ and $s=r[s_1,\\dots,s_k]= r[s_1,\\dots,s_n]$. Hence, \n% $(f_{n,r})^\\top_r(s)= f_{n,r}(s_1,\\dots,s_n) = f(r[s_1,\\dots,s_n]) =f(s)$.\n% If $k> n$, then $(f_{n,r})^\\top_r(s)= f_{n,r}(s_1,\\dots,s_n) = f(r[s_1,\\dots,s_n]) =f(r[s_1,\\dots,s_n,s_{n+1}])=\\dots=f(r[s_1,\\dots,s_n,s_{n+1},\\dots,s_k])= f(s)$, because $f$ is independent of $\\e_{n+1},\\dots,\\e_k$.\n%\\end{proof}\n%\n\n\n\n\n%\\begin{remark} Since  the set $\\mathcal B_A$ of blocks and the set $\\mathcal B_A^\\top$ of top extensions are equipotent, then it is possible  to  define a structure of clone algebra directly over the set $\\mathcal B_A$ of blocks, by defining the function $q^\\mathcal B_n: (\\mathcal B_A)^{n+1}\\to \\mathcal B_A$ as follows, for all blocks $B,G_1,\\dots,G_n\\in \\mathcal B_A$:\n%$$\n%\\begin{array}{lll}\n% q^{\\mathcal B}_n(B, G_1,\\dots,G_n) &=& q^{\\omega}_n(B^\\top, G_1^\\top,\\dots,G_n^\\top)_\\bot \\\\\n% &= &\\text{the block of}\\ B^{(n)}(G_1^{(k)},\\dots, G_n^{(k)}),\\\\\n% &   &\\text{where $k$ is greater than the arity of $G_1,\\dots,G_n$}. \\\\\n%\\end{array}\n%$$\n%We prefer to work with infinitary functions rather than blocks because we have experimented that the proofs of our results are easier to develop by using block algebras.\n%\\end{remark}\n\n\n\n%\\begin{definition} A set $X$ of blocks is called \n% a \\emph{clone of blocks on a set $A$}  if it contains the projection blocks $P_i$ and is closed under $q^{\\mathcal B}_n$.\n% \\end{definition}\n%\n%The set $\\mathcal B_A$ of all blocks is called the \\emph{full clone of blocks on $A$}.\n%\n%A \\emph{clone of blocks on an algebra $\\mathbf A$} is a clone of blocks on $A$  containing  the blocks $\\langle\\sigma^\\mathbf A\\rangle$ of the basic operations  of $\\mathbf A$.\n%\n%It is trivial to show that $(\\mathcal B_A^\\top,q_n^\\top, \\e_i^\\top)$ is isomorphic to the algebra $(\\mathcal B_A,q^{\\mathcal B}_n,P_i)$.\n\n\n\n\n%\\begin{definition}\\label{def:clock} The  algebra $\\mathbf B_A=(\\mathcal B_A,q^\\mathcal B_n, P_i)$ is called the \\emph{full block algebra on set $A$}. Every subalgebra of $\\mathbf B_A$  is called a \\emph{block algebra on $ A$}. \n%\\end{definition}\n%\n%The proof of the following lemma is trivial.\n%\n%\\begin{lemma}\n% Every block algebra is a pure clone algebra.\n%\\end{lemma}\n%\n%\\begin{lemma} A block $B$ has dimension $k$ in the block algebra $\\mathbf B_A$ if and only if $B$ has arity $k$.\n%\\end{lemma}\n%\n%\\begin{proof}  ($\\Rightarrow$) Let $r$ be the arity of $B$. If $r<k$ then by (\\ref{block2}) we have:\n%$$q_k^\\mathcal B(B,P_1,\\dots,P_{k-1},P_{k+1})= \\langle B^{(r)}(p^{(k+1)}_1,\\dots,p^{(k+1)}_r)\\rangle= \\langle B^{(r)}(p^{(r)}_1,\\dots,p^{(r)}_r)\\rangle= B.$$ This contradicts that $k$ is the dimension of $B$. If $r > k$ then \n%$q_r^\\mathcal B(B,P_1,\\dots,P_{r-1},P_{r+1})= \\langle B^{(r+1)}(P^{(r+1)}_1,\\dots,P^{(r+1)}_{r-1},P^{(r+1)}_{r+1},P^{(r+1)}_{r+1})\\rangle= B= \\langle B^{(r+1)}\\rangle$.\n%\n%However, \n%$B^{(r+1)}(P^{(r+1)}_1,\\dots,P^{(r+1)}_{r-1},P^{(r+1)}_{r+1},P^{(r+1)}_{r+1})(a_1,\\dots,a_r,a_{r+1})=\n%B^{(r+1)}(a_1,\\dots,a_{r-1},a_{r+1},a_{r+1})=B^{(r)}(a_1,\\dots,a_{r-1},a_{r+1})\n%\\neq B^{(r+1)}(a_1,\\dots,a_{r-1},a_{r},a_{r+1}) = B^{(r)}(a_1,\\dots,a_{r-1},a_{r})$\n%\n%\n% This means that $B^{(n+1)}(P_1^{(n+1)},\\dots, P_{n-1}^{(n+1)}, P_{n+1}^{(n+1)}, P_{n+1}^{(n+1)})= B^{(n+1)}$.\n% \n% ($\\Leftarrow$) Let $f: A^k\\to A$ be the generator of the block $B$.\n%\\end{proof}\n\n%Every $h\\in \\mathcal O_A$ of arity $k$ determines a $k$-ary operation $h^\\mathcal B: (\\mathcal B_A)^k\\to \\mathcal B_A$  as follows:\n%$$h^\\mathcal B(G_1,\\dots,G_k)= q_k^\\mathcal B(\\langle h\\rangle,G_1,\\dots,G_k).$$\n%Since $h^\\mathcal B(P_1,\\dots,P_k)= \\langle h\\rangle$ then we have\n%$$h^\\mathcal B(G_1,\\dots,G_k)= q_k^\\mathcal B( h^\\mathcal B(P_1,\\dots,P_k),G_1,\\dots,G_k).$$\n%\n%The following lemma characterises the clones of blocks closed under $h^\\mathcal B$.\n%\n%\\begin{lemma}\\label{lem:clock} A clone of blocks $F$ is closed under $h^\\mathcal B$ iff $\\langle h\\rangle\\in F$.\n%\\end{lemma}\n%\n%\\begin{proof} \n%($\\Rightarrow$) By $h^\\mathcal B(P_1,\\dots,P_k)= \\langle h\\rangle$.\n%($\\Leftarrow$)  By $h^\\mathcal B(G_1,\\dots,G_k)= q_k^\\mathcal B(\\langle h\\rangle,G_1,\\dots,G_k)$.\n% \\end{proof}\n% \n\n\n\\section{The block algebra of representable functions}\\label{sec:rep}\nIn this section we introduce the notion of \\emph{representable function} in a clone algebra. \nRoughly speaking, every $k$-dimensional element $a$ of a clone algebra $\\mathbf C$ determines a block of representable functions $f_n$ ($n\\geq k$) through the operators $q_n$: $f_n(x_1,\\dots,x_n)=q_n^\\mathbf C(a,x_1,\\dots,x_n)$.\n%The set of all representable functions is the union of these blocks when $a$ ranges over the finite dimensional elements of $C$.\nThe set of representable functions includes the basic operations of $\\mathbf C$. The representable functions turn out to be a clone and  the top extension of this clone is isomorphic to  the subalgebra $\\mathrm{Fi}\\,\\mathbf C$ of all finite dimensional elements of $\\mathbf C$. $\\mathrm{Fi}\\,\\mathbf C$ coincides with $\\mathbf C$ whenever $\\mathbf C$ is finite dimensional. It follows that every finite dimensional clone algebra is isomorphic to a block algebra. \n\\bigskip\n\nLet $\\mathbf C$ be a clone $\\tau$-algebra and $\\sigma\\in\\tau$ be an operator of arity $k$.\nBy Lemma \\ref{lem:preservare} the element  $\\sigma(\\e_1,\\dots,\\e_k)$ has dimension $\\leq k$ and  it univocally determines the values $\\sigma(\\mathbf a)$,  for all $\\mathbf a=a_1,\\dots,a_k\\in C$:\n \\begin{equation}\\label{sigma-eq}q_k(\\sigma(\\e_1,\\dots,\\e_k),\\mathbf a) =_{(C6)} \\sigma(q_k(\\e_1,\\mathbf a),\\dots,q_k(\\e_k,\\mathbf a))=_{(C1)}\\sigma(\\mathbf a).\\end{equation}\n%This implies that, for any $k$-ary term operations $\\sigma_1^\\mathbf C$ and $\\sigma_2^\\mathbf C$, $\\sigma_1^\\mathbf C(\\e_1,\\dots,\\e_k)= \\sigma_2^\\mathbf C(\\e_1,\\dots,\\e_k)$ iff $\\forall \\mathbf a\\in C^k\\ \\sigma_1^\\mathbf C(\\mathbf a)=\\sigma_2^\\mathbf C(\\mathbf a)$.\n\nIn the following definition we characterise the operations on $C$ that have a  behaviour similar to the basic operations.\n\n\n\\begin{definition}\\label{def:representable} Let $\\mathbf C$ be a clone algebra and $f:C^k\\to C$ be a function.\n We say that $f$ is \\emph{$\\mathbf C$-representable}  if  $f(\\e_1,\\dots,\\e_k)$ has dimension $\\leq k$ and \n  $$ f(\\mathbf a)=q_k(f(\\e_1,\\dots,\\e_k),\\mathbf a),\\quad \\text{for all $\\mathbf a$}.$$\n We denote by $R_\\mathbf C$ the set of all $\\mathbf C$-representable functions.\n\\end{definition}\n\n%By (C3) it is immediate that $c_f=f(\\e_1,\\dots,\\e_k)$.\nAs usual, $R_\\mathbf C^{(n)}$ denotes the set of all $\\mathbf C$-representable functions of arity $n$.\n\n\\begin{lemma}\\label{cor:sigma}\n Let $\\mathbf C$ be a clone $\\tau$-algebra. Then every basic operation $\\sigma^\\mathbf C$ ($\\sigma\\in\\tau$) is $\\mathbf C$-representable.\n\\end{lemma}\n\n\\begin{proof}\n By (\\ref{sigma-eq}) and Definition \\ref{def:representable}.\n\\end{proof}\n\nIn the following lemma we show that a function is $\\mathbf C$-representable if and only if it satisfies an analogue of  identity (C6) in Definition \\ref{def:clonealg}.\n\n\\begin{lemma}\\label{12}\n Let $\\mathbf C$ be a clone algebra and $f:C^k\\to C$ be a function. Then the following conditions are equivalent:\n \\begin{itemize}\n\\item[(i)] $f$ is $\\mathbf C$-representable;\n% \\item[(ii)] $q_k(f(\\mathbf a), \\mathbf b) =f(q_k(a_1, \\mathbf b),\\dots,q_k(a_k, \\mathbf b))$ for all $\\mathbf a, \\mathbf b\\in C^k$;\n \\item[(ii)]  $q_n(f(\\mathbf a),\\mathbf c) = f(q_n(a_1,\\mathbf c),\\dots, q_n(a_k,\\mathbf c))$ for every $n\\geq 0$ and every $\\mathbf a\\in C^k$, $\\mathbf c\\in C^n$.\n %q_n(q_k(f(\\mathbf e),\\mathbf a),\\mathbf c)\n\\end{itemize}\n\\end{lemma}\n\n\\begin{proof}\n (ii) $\\Rightarrow$ (i) Let $\\mathbf e=\\e_1,\\dots,\\e_k$. Then\n$q_k(f(\\mathbf e),\\mathbf a)    =  \nf(q_k(\\e_1,\\mathbf a),\\dots, q_k(\\e_k,\\mathbf a)) \n   =   f(\\mathbf a)$. We now prove that $f(\\mathbf e)$ has dimension $\\leq k$.\nLet $n>k$ and $\\mathbf d=\\e_1,\\dots,\\e_{n-1},\\e_{n+1}$. Then $q_n(f(\\mathbf e),\\mathbf d)=\nf(q_n(\\e_1,\\mathbf d),\\dots, q_n(\\e_k,\\mathbf d))=\nf(\\mathbf e)$. It follows that $f(\\mathbf e)$ has dimension $\\leq k$.\n\n (i) $\\Rightarrow$ (ii) \n %$q_k(h(\\mathbf a), \\mathbf b)=  q_k(q_k(h(\\mathbf e),\\mathbf a), \\mathbf b)=_{(C5)} q_k(h(\\mathbf e), q_k(a_1,\\mathbf b),\\dots, q_k(a_k,\\mathbf b))=$\\\\ $h(q_k(a_1, \\mathbf b),\\dots,q_k(a_k, \\mathbf b))$.\n \\begin{itemize}\n\\item If $k\\geq n$,  then \n$$f(q_n(a_1,\\mathbf b),\\dots, q_n(a_k,\\mathbf b))=_{(i)} q_k(f(\\mathbf e),q_n(a_1,\\mathbf b),\\dots, q_n(a_k,\\mathbf b))=_{(C5)} q_n(q_k(f(\\mathbf e),\\mathbf a),\\mathbf b).$$\n\\item If $k< n$, then  by Lemma \\ref{lem:ind1} we obtain:\n\\[\n\\begin{array}{lll}\nf(q_n(a_1,\\mathbf b),\\dots, q_n(a_k,\\mathbf b))  & =_{(i)}  & q_k(f(\\mathbf e),q_n(a_1,\\mathbf b),\\dots, q_n(a_k,\\mathbf b))  \\\\\n  & =_{\\text{Lem}\\, \\ref{lem:ind1}}  &  q_n(f(\\mathbf e),q_n(a_1,\\mathbf b),\\dots, q_n(a_k,\\mathbf b),b_{k+1},\\dots,b_n) \\\\\n  & =_{(C4)}  &   q_n(q_k(f(\\mathbf e),\\mathbf a),\\mathbf b).\n\\end{array}\n\\]\n\\end{itemize}\n\\end{proof}\n\n\n\n\n\nLet $\\mathbf C$ be a clone algebra. For every $a\\in C$ of finite dimension, we consider\nthe family $$R(a)=\\bigcup_{n\\in \\omega} \\{f\\in R_\\mathbf C^{(n)}: a=f(\\e_1,\\dots,\\e_n)\\}$$ of the $\\mathbf C$-representable functions determined by $a$.\n\n\n\\begin{proposition}\\label{prop:rr} Let $\\mathbf C$ be a clone algebra and and $a,b$ be finite-dimensional elements of C. Then the following conditions hold: \n\\begin{enumerate}\n\\item For every $f\\in R_\\mathbf C^{(n)}$  and $g\\in R_\\mathbf C^{(k)}$, $f\\approx_{\\mathcal O_C} g$ iff $f(\\e_1,\\dots,\\e_n)=g(\\e_1,\\dots,\\e_k)$.\n\\item $R(a)$ is a block.\n\\item $R(a)= R(b) \\Rightarrow a=b$.\n\\item $R_\\mathbf C=\\bigcup_{a\\in C} R(a)$ is a clone on $\\mathbf C$.\n\\item The block $R(a)$ has arity $k$ iff the element $a$ has dimension $k$ in $\\mathbf C$.\n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof}  (1) ($\\Rightarrow$) If $n\\leq k$, then $f(\\e_1,\\dots,\\e_n)=g(\\e_1,\\dots,\\e_n,\\mathbf b)$ for every $\\mathbf b$. In particular for $\\mathbf b=\\e_{k+1},\\dots,\\e_n$ we get the conclusion. ($\\Leftarrow$) It is trivial by the hypotheses.\n \n (2) By (1).\n%If $n\\geq m\\geq \\gamma(a)$, then by Lemma \\ref{lem:ind}(3) $q_m(a,-)\\approx_{\\mathcal O_C} q_n(a,-)$:$$\\forall \\mathbf b\\in C^m\\forall \\mathbf c\\in C^{n-m}\\ q_m(a,\\mathbf b)=q_n(a,\\mathbf b,\\mathbf c).$$\n\n (3) If $R(a)=R(b)$ and $f\\in R(a)$ has arity $n$, then $a=f(\\e_1,\\dots,\\e_n)=b$.\n \n (4) The projection $p^{(n)}_i$ is $\\mathbf C$-representable:\n$$a_i=p^{(n)}_i(a_1,\\dots,a_n)=q_n(\\e_i,a_1,\\dots,a_n).$$\nIf $f$ of arity $n$ and $g_1,\\dots,g_n$ of arity $k$ are $\\mathbf C$-representable, then the function $h=f(g_1,\\dots,g_n)_k$ is also\n $\\mathbf C$-representable. Let $\\mathbf e=\\e_1,\\dots,\\e_k$ and $\\mathbf a=a_1,\\dots,a_k$. Then we have:\n \\[\n\\begin{array}{llll}\nq_k(h(\\e_1,\\dots,\\e_k),\\mathbf a)& =  &q_k(f(g_1(\\mathbf e),\\dots,g_n(\\mathbf e)),\\mathbf a) &\\\\\n & =  &f(q_k(g_1(\\mathbf e),\\mathbf a),\\dots,q_k(g_n(\\mathbf e),\\mathbf a))  &\\text{by Lemma \\ref{12}} \\\\\n  &  = &  f(g_1(\\mathbf a)),\\dots,g_n(\\mathbf a))   &\\text{by Lemma \\ref{12} and (C1)} \\\\\n   &  = & h(\\mathbf a)&\n\\end{array}\n\\]\nThe basic operations $\\sigma^\\mathbf C$ are also $\\mathbf C$-representable.\n\n (5) If $f$ is $\\mathbf C$-representable and $a=f(\\e_1,\\dots,\\e_k)$, then $a$ has dimension $\\leq k$.   The element $a$ is independent of $\\e_k$ iff (by Lemma \\ref{lem:ind1}), for every  $b_1,\\dots,b_{k-1},c\\in C$,\n $f(b_1,\\dots,b_{k-1},c)=q_k(a,b_1,\\dots,b_{k-1},c)=q_{k-1}(a,b_1,\\dots,b_{k-1})$ iff, for every  $b_1,\\dots,b_{k-1}$, $c,d\\in C$, $f(b_1,\\dots,b_{k-1},c)=f(b_1,\\dots,b_{k-1},d)$ iff (by Lemma \\ref{lem:generator}) \n $f$ is not a generator. \n\\end{proof}\n\n%The following corollary is trivial.\n%\n%\\begin{corollary} Let $\\mathbf C$ be a pure clone algebra, $X$ be a subalgebra of $\\mathbf C$, and $a\\in C$ of dimension $k<\\omega$. Then $X$ is closed under the $n$-ary function $q_n(a,-)$ ($n\\geq k$) if and only if $a\\in X$.\n%\\end{corollary}\n\n\n\n\n\n\n\n%$$f^n_a(\\mathbf b)=q^\\mathbf C_n(a,\\mathbf b),\\quad\\text{for every $\\mathbf b\\in C^n$}.$$\n%$R(a)=\\{q^\\mathbf C_n(a, -): C^n\\to C\\ |\\  n\\geq \\gamma(a)\\}$\n\n\\begin{lemma} \\label{lem:dim} Let $\\mathbf C=(\\mathbf C_\\tau,q_n,\\e_i)$ be a  clone $\\tau$-algebra. \nThen $R_\\mathbf C^\\top=\\{R(a)^\\top: a\\in \\mathrm{Fi}\\,\\mathbf C\\}$ is a block algebra on $\\mathbf C_\\tau$.\n\\end{lemma}\n\n\\begin{proof}  By Propositions \\ref{prop:cloneblock} and \\ref{prop:rr}.\n \\end{proof}\n\n\n%\\subsection{The representation of finite dimensional clone algebras by block algebras}\n\n\n\\begin{theorem}\\label{thm:firstrepresentation} Let $\\mathbf C$ be a  finite dimensional clone $\\tau$-algebra.\nThe function $(-)^\\top \\circ R$ mapping\n$$a\\in C \\mapsto\\ R(a)^\\top$$\nis an isomorphism from $\\mathbf C$ onto the block algebra $R_\\mathbf C^\\top$. \n\\end{theorem}\n\n\\begin{proof} $(-)^\\top \\circ R$ is trivially bijective and $\\e_i^\\mathbf C\\mapsto R(\\e_i^\\mathbf C)^\\top=\\e_i^\\omega$. The map $(-)^\\top \\circ R$ preserves the operators $q_n$:\n$$R(q_n^\\mathbf C(a,b_1,\\dots,b_n))^\\top= q_n^\\omega(R(a)^\\top,R(b_1)^\\top,\\dots,R(b_n)^\\top).$$\nLet $k\\geq n$ be greater than the arities of $R(a), R(b_1),\\dots,R(b_n)$ and the dimension of $q_n^\\mathbf C(a,b_1,\\dots,b_n)$. Let $s\\in C^\\omega$, $\\mathbf s=s_1,\\dots,s_k$, $A=R(a)$ and $B_i=R(b_i)$.\n\\[\n\\begin{array}{rll}\nq_n^\\omega(A^\\top,B_1^\\top,\\dots,B_n^\\top)(s)&  = &A^\\top(s[B_1^\\top(s),\\dots,B_n^\\top(s)])\\\\\n&  = &A^{(k)}(B_1^\\top(s),\\dots,B_n^\\top(s),s_{n+1},\\dots,s_k)\\\\\n&  = &A^{(k)}(B_1^{(k)}(\\mathbf s),\\dots,B_n^{(k)}(\\mathbf s),s_{n+1},\\dots,s_k)\\\\\n&  = &A^{(k)}(B_1^{(k)},\\dots,B_n^{(k)},p^{(k)}_{n+1},\\dots,p^{(k)}_k)(\\mathbf s)\\\\\n\\end{array}\n\\]\nLet $\\mathbf b= b_1,\\dots,b_n$ and  $f\\in R(q_n^\\mathbf C(a,\\mathbf b))$ of arity $k$. Then, we have\n  $$ f(\\mathbf a)=q_k (f(\\e_1,\\dots,\\e_k),\\mathbf s)=q_k (q_n (a,\\mathbf b),\\mathbf s)=q_k(a,q_k(b_1,\\mathbf s),\\dots,q_k(b_n,\\mathbf s),s_{n+1},\\dots,s_k)$$\n  $$= A^{(k)}(B_1^{(k)},\\dots,B_n^{(k)},p^{(k)}_{n+1},\\dots,p^{(k)}_k)(\\mathbf s).$$\n\nMoreover, for every $\\sigma\\in \\tau$ of arity $n$, it is not difficult to show that \n$$R(\\sigma^\\mathbf C(\\e_1,\\dots,\\e_n))^\\top= \\sigma^\\omega(\\e_1^\\omega,\\dots,\\e_n^\\omega).$$\n%\n%Let $\\sigma\\in \\tau$ of arity $n$ and let $\\mathbf e = \\e_1,\\dots,\\e_n$. Recall that $\\sigma^\\mathbf C\\in R(\\sigma^\\mathbf C(\\mathbf e))$.\n%\\begin{equation}\\label{erre}\n%\\sigma^\\mathcal B(R(b_1),\\dots,R(b_n))=R(\\sigma^\\mathbf C(b_1,\\dots,b_n)).\n%\\end{equation}\n% Let $k\\geq n$ be greater than the dimension of $b_1,\\dots,b_n$. \n%By definition  $\\sigma^\\mathcal B(R(b_1),\\dots,R(b_n))$ is equal to\n% the block of \n% $$R(\\sigma^\\mathbf C(\\mathbf e))^{(k)}(R(b_1)^{(k)},\\dots, R(b_n)^{(k)}, P_{n+1}^{(k)},\\dots,P_k^{(k)}).$$ \n%It is not difficult to show that the above map belongs to $R(\\sigma^\\mathbf C(b_1,\\dots,b_n))$:\n% \\[\n%\\begin{array}{rll}\n%q^\\mathbf C_k(\\sigma^\\mathbf C(b_1,\\dots,b_n),\\mathbf c)  & =  & \\sigma^\\mathbf C(q^\\mathbf C_k(b_1,\\mathbf c),\\dots,q^\\mathbf C_k(b_n,\\mathbf c)) \\\\\n%&=& q_k^\\mathbf C(\\sigma^\\mathbf C(\\mathbf e),q^\\mathbf C_k(b_1,\\mathbf c),\\dots,q^\\mathbf C_k(b_n,\\mathbf c),c_{n+1},\\dots,c_k)\\\\\n%  &  = &  R(\\sigma^\\mathbf C(\\mathbf e))^{(k)}(R(b_1)^{(k)}(\\mathbf c),\\dots, R(b_n)^{(k)}(\\mathbf c), p_{n+1}^{(k)}(\\mathbf c),\\dots,p_k^{(k)}(\\mathbf c))\\\\\n%  &  = & R(\\sigma^\\mathbf C(\\mathbf e))^{(k)}(R(b_1)^{(k)},\\dots, R(b_n)^{(k)}, P_{n+1}^{(k)},\\dots,P_k^{(k)})(\\mathbf c).\n%\\end{array}\n%\\]\n%%Moreover, $R(\\sigma^\\mathbf C(a_1,\\dots,a_k))=(\\sigma^\\mathbf C)^\\mathcal B(R(a_1),\\dots,R(a_k))= q_k^\\mathcal B(\\langle \\sigma^\\mathbf C\\rangle,R(a_1),\\dots,R(a_k))$\n%% \n\\end{proof}\n\n%It is not difficult to show that the above map belongs to $R(q^\\mathbf C_n(a,b_1,\\dots,b_n))$:\n% \\[\n%\\begin{array}{rll}\n%q^\\mathbf C_k(q^\\mathbf C_n(a,b_1,\\dots,b_n),\\mathbf c)  & =  &q^\\mathbf C_k(q^\\mathbf C_k(a,b_1,\\dots,b_n,\\e_{n+1},\\dots,\\e_k),\\mathbf c)   \\\\\n%  &  = & q^\\mathbf C_k(a, q^\\mathbf C_k(b_1,\\mathbf c),\\dots,q^\\mathbf C_k(b_n,\\mathbf c), c_{n+1},\\dots,c_k) \\\\\n%  &  = &  R(a)^{(k)}(R(b_1)^{(k)}(\\mathbf c),\\dots, R(b_n)^{(k)}(\\mathbf c), p_{n+1}^{(k)}(\\mathbf c),\\dots,p_k^{(k)}(\\mathbf c))\\\\\n%  &  = & R(a)^{(k)}(R(b_1)^{(k)},\\dots, R(b_n)^{(k)}, P_{n+1}^{(k)},\\dots,P_k^{(k)})(\\mathbf c).\n%\\end{array}\n%\\]\n%Since $\\sigma^\\mathbf C\\in R(\\sigma^\\mathbf C(\\e_1,\\dots,\\e_k))$, then  from Corollary \\ref{cor:sigma} it follows that $R_\\mathbf C^\\top$ is a block algebra on $\\mathbf C_\\tau$.\n% If $f=q_n(a,-):C^n\\to C$ and\n% $g_i=q_k(b_i,-):C^k\\to C$ ($i=1,\\dots,n$), then $f(g_1,\\dots,g_n)_k:C^k\\to C$ belongs to $R(q_n(a,b_1,\\dots,b_n))$. Let $\\mathbf c= c_1,\\dots,c_k\\in C$. Then we have:\n% \\[\n%\\begin{array}{rll}\n%k\\leq n &\\Rightarrow&\\\\\n%q_k(q_n(a,b_1,\\dots,b_n),\\mathbf c)  & =  & q_n(a,q_k(b_1,\\mathbf c),\\dots,q_k(b_n,\\mathbf c))  \\\\\n%  &  = & f(q_k(b_1,\\mathbf c),\\dots,q_k(b_n,\\mathbf c))  \\\\\n%  &  = &  f(g_1(\\mathbf c),\\dots,g_n(\\mathbf c))\\\\\n%  &  = &  f(g_1,\\dots,g_n)_k(\\mathbf c).\\\\\n%\\end{array}\n%\\]\n% \\[\n%\\begin{array}{rlll}\n%k> n &\\Rightarrow&\\\\\n%q_k(q_n(a,b_1,\\dots,b_n),\\mathbf c)  & =  & q_k(a,q_k(b_1,\\mathbf c),\\dots,q_k(b_n,\\mathbf c),c_{n+1},\\dots,c_k)  &\\\\\n%&=& q_n(a,q_k(b_1,\\mathbf c),\\dots,q_k(b_n,\\mathbf c))&\\text{by $\\gamma(a)\\leq n$}\\\\\n%  &  = & f(q_k(b_1,\\mathbf c),\\dots,q_k(b_n,\\mathbf c))  &\\\\\n%  &  = &  f(g_1(\\mathbf c),\\dots,g_n(\\mathbf c))&\\\\\n%  &  = &  f(g_1,\\dots,g_n)_k(\\mathbf c).&\\\\\n%\\end{array}\n%\\]\n%Let $\\sigma\\in \\tau$ of arity $k$, $\\mathbf e = \\e_1,\\dots,\\e_k$. \n%and $\\mathbf d = \\e_1,\\dots,\\e_{n-1},\\e_{n+1}$. First we show that the dimension of $\\sigma^\\mathbf C(\\mathbf e)$ is $\\leq k$: \n%$$n > k \\Rightarrow q_n(\\sigma^\\mathbf C(\\mathbf e),\\mathbf d)=\\sigma^\\mathbf C(q_n(\\e_1,\\mathbf d),\\dots, q_n(\\e_k,\\mathbf d))=\\sigma^\\mathbf C(\\mathbf e).$$\n%We have that \n%$\\sigma^\\mathbf C\\in R(\\sigma^\\mathbf C(\\mathbf e))$, because   $\\gamma(\\sigma^\\mathbf C(\\mathbf e))\\leq k$ and $q_k(\\sigma^\\mathbf C(\\mathbf e),c_1,\\dots,c_k)=\n%\\sigma^\\mathbf C(c_1,\\dots,c_k)$ for all $c_1,\\dots,c_k\\in C$.\n%It follows that $\\sigma^\\mathbf C$ belongs to the clone $\\bigcup_{a\\in C} R(a)$.\n\n\nWe denote by $\\mathsf{BLK}$ the class of all block algebras and by $\\mathsf{FiCA}$ the class of all finite dimensional clone algebras.\n \n\\begin{theorem}\\label{thm:fica}\n $\\mathsf{FiCA}_\\tau = \\mathbb I\\, \\mathsf{BLK}_\\tau$.\n\\end{theorem}\n\n\\begin{proof} By Theorem \\ref{thm:firstrepresentation} $\\mathsf{FiCA}_\\tau \\subseteq \\mathbb I\\, \\mathsf{BLK}_\\tau$.\nThe  inequality $\\mathsf{BLK}_\\tau\\subseteq \\mathsf{FiCA}_\\tau$ is trivial, because every block algebra is a finite dimensional clone algebra. \n\\end{proof}\n\n\n\\section{The operators of an algebraic type as nullary operators}\\label{sec:nullary}\nEach $n$-ary basic operation $\\sigma$ of a clone algebra is represented by the element $\\sigma(e_1,\\ldots,e_n)$.\nTacking these elements as nullary operators and discharging the $\\sigma$'s, we get \\emph{pure clone algebras with constants}. In this section \nwe show that the variety of clone algebras of type $\\tau$ is equivalent to the variety of pure clone algebras with\n$\\tau$-constants.\n\n\\begin{definition}\n A \\emph{pure clone algebra with $\\tau$-constants}   is a pure clone algebra\n $\\mathbf A = (A, q^\\mathbf A_n,\\e^\\mathbf A_i, c^\\mathbf A_\\sigma)$ enriched with a nullary operator  $c^\\mathbf A_\\sigma$ of dimension $\\leq k$ for every $\\sigma\\in\\tau$ of arity $k$.\n\\end{definition}\n\nThe variety of clone $\\tau$-algebras  and the variety of pure clone algebra with $\\tau$-constants are term equivalent.\nConsider the following correspondence.\n\\begin{itemize}\n\\item Beginning on the clone algebra side,  if $\\mathbf C=(\\mathbf C_\\tau, q^\\mathbf C, \\e_i^\\mathbf C)$ is a clone $\\tau$-algebra, then $\\mathbf C^\\bullet = (C; q^\\mathbf C, \\e_i^\\mathbf C,c^\\bullet_\\sigma)$, where $c^\\bullet_\\sigma = \\sigma^\\mathbf C(\\e_1^\\mathbf C,\\dots,\\e_k^\\mathbf C)$ for every $\\sigma\\in\\tau$ of arity $k$, denotes the corresponding algebra in the similarity type of pure clone algebras with $\\tau$-constants.\n\\item Beginning on the other  side, if $\\mathbf A= (A, q^\\mathbf A_n,\\e^\\mathbf A_i, c^\\mathbf A_\\sigma)$ is a pure clone algebra with $\\tau$-constants, then \n$\\mathbf A^* = (\\mathbf A_\\tau, q_n^\\mathbf A,\\e_i^\\mathbf A)$, where $\\mathbf A_\\tau= (A,\\sigma^*)_{\\sigma\\in\\tau}$ and $\\sigma^*(a_1,\\dots,a_k)= q_k^\\mathbf A(c^\\mathbf A_\\sigma,a_1,\\dots,a_k)$ for all $a_i\\in A$ and every $\\sigma\\in\\tau$ of arity $k$, denotes the corresponding algebra in the similarity type of clone $\\tau$-algebras.\n\\end{itemize}\n\nIt is not difficult to prove the following proposition.\n\n\\begin{proposition}\\label{prop:equiv}\n  The above correspondences define a term equivalence between the varieties of clone $\\tau$-algebras  and the variety of pure clone algebras with $\\tau$-constants. More precisely,\n  \\begin{itemize}\n\\item[(i)] If $\\mathbf A$ is a pure clone algebra with $\\tau$-constants, then $\\mathbf A^*$ is a clone $\\tau$-algebra;\n\\item[(ii)] If $\\mathbf C$ is a clone $\\tau$-algebra, then $\\mathbf C^\\bullet$ is a pure clone algebra with $\\tau$-constants;\n\\item[(iii)] $(\\mathbf A^*)^\\bullet = \\mathbf A$;\n\\item[(iv)] $(\\mathbf C^\\bullet)^* = \\mathbf C$.\n\\end{itemize}\n\\end{proposition}\n\n\\begin{proof} (i) By Lemma \\ref{12} applied to $\\sigma^*$ we get (C6).\n\n(ii) By Lemma \\ref{cor:sigma} and Definition \\ref{def:representable}.\n\n(iii) $\\sigma^*(\\e_1,\\dots,\\e_k)= q_k^\\mathbf A(c^\\mathbf A_\\sigma,\\e_1,\\dots,\\e_k)=c^\\mathbf A_\\sigma$.\n\n(iv) Since $c^\\bullet_\\sigma = \\sigma^\\mathbf C(\\e_1^\\mathbf C,\\dots,\\e_k^\\mathbf C)$, then we have:\n $\\sigma^*(a_1,\\dots,a_k)= q_k^\\mathbf C(c^\\bullet_\\sigma,a_1,\\dots,a_k)=$\\\\\n $q_k^\\mathbf C(\\sigma^\\mathbf C(\\e_1^\\mathbf C,\\dots,\\e_k^\\mathbf C),a_1,\\dots,a_k)=\\sigma^\\mathbf C(a_1,\\dots,a_k)$.\n\\end{proof}\n\nIn view of this proposition, we will denote a clone $\\tau$-algebra  either as $\\mathbf C = (\\mathbf C_\\tau, q^\\mathbf C_n,\\e^\\mathbf C_i)$ or as $\\mathbf C = (C, q^\\mathbf C_n,\\e^\\mathbf C_i, c^\\mathbf C_\\sigma)_{\\sigma\\in\\tau}$, whichever seems more convenient.\n\n\\bigskip\n\nProposition \\ref{prop:equiv} has two important consequences.\n\n\\begin{corollary}\n Let $\\mathbf C$ be a clone $\\tau$-algebra, $\\mathbf C_0$ be the pure reduct of $\\mathbf C$ and $\\theta$ be an equivalence relation on $C$. Then,\n $\\theta$ is a congruence on $\\mathbf C$ if and only if $\\theta$ is a congruence on $\\mathbf C_0$; hence, \n $$\\mathrm{Con}\\, \\mathbf C=\\mathrm{Con}\\, \\mathbf C_0.$$\n\\end{corollary}\n\n\\begin{proof}\n If $\\mathbf a\\theta \\mathbf b$ and $\\theta$ preserves the operators $q_n$, then\n$\\sigma^\\mathbf C(\\mathbf a)=_{(C6),(C1)}q_k^\\mathbf C(\\sigma^\\mathbf C(\\mathbf e),\\mathbf a)\\ \\theta\\ q_k^\\mathbf C(\\sigma^\\mathbf C(\\mathbf e),\\mathbf b)=\\sigma^\\mathbf C(\\mathbf b).$\n\\end{proof}\n\n\\begin{corollary}\\label{cor:taunu} Let $\\mathbf C$ and $\\mathbf D$ be clone algebras of type $\\tau$ and $\\nu$, respectively.   If $\\mathbf C$ and $\\mathbf D$ have the same pure reduct, then  $\\mathrm{Con}\\, \\mathbf C=\\mathrm{Con}\\, \\mathbf D$.\n\\end{corollary}\n\n\\section{The General Representation Theorem}\\label{sec:GRT}\n\nThis section is devoted to the proof of the main representation theorem.\nFirstly we introduce the class $\\mathsf{RCA}$ of \\emph{point-relativized functional clone algebras}, which is instrumental in the proof of  the representation theorem.\nThe following diagram provides the outline of the proof that $\\mathsf{CA}=\\mathbb I\\,\\mathsf{FCA}$:\n\\[\n\\begin{array}{llll}\n\\mathsf{CA}  & =  & \\mathbb I\\,\\mathsf{RCA}  &\\text{Lemma \\ref{lem:ca=rca}}\\\\\n  & \\subseteq  &\\mathbb I\\,\\mathbb S\\,\\mathbb U_p\\,  \\mathsf{FCA} &\\text{Lemma \\ref{lem:ultrapower}, Lemma \\ref{lem:red}} \\\\\n  & \\subseteq  &   \\mathbb I\\,\\mathbb S\\,\\mathbb P\\,  \\mathsf{FCA} &\\text{Lemma \\ref{lem:ultrafca}} \\\\\n  & \\subseteq  &\\mathbb I\\, \\mathsf{FCA}&\\text{Lemma \\ref{lem:subprod}}\\\\\n  & \\subseteq  & \\mathsf{CA}&\\text{Lemma \\ref{lem:fun}}\\\\\n\\end{array}\n\\]\nIn other words, the proof is structured as follows:\n\\begin{itemize}\n\\item Each clone algebra is isomorphic to a point relativized clone algebra.\n\\item Each point relativized clone algebra embeds into an ultrapower of a functional clone algebra.\n\\item Each ultrapower of a functional clone algebra is isomorphic to a subdirect product of a family of functional clone algebras.\n\\item Functional clone algebras are closed under subalgebras and direct products.\n\\end{itemize}\nMoreover, we prove that the variety of  clone algebras is generated by its \nfinite dimensional members (or by the class of block algebras):\n$$\\mathsf{CA} = \\mathbb H\\,\\mathbb S\\,\\mathbb P (\\mathsf{FiCA})=  \\mathbb H\\,\\mathbb S\\,\\mathbb P (\\mathsf{BLK}).$$\nThen, the variety of clone algebras is the algebraic counterpart of $\\omega$-clones, \nthe class of block algebras is the algebraic counterpart of clones, and the $\\omega$-clones\nare algebraically generated by clones through direct products, subalgebras and \nhomomorphic images.\n\n\n\n\\subsection{Point-relativized functional clone algebras}\n\n\nLet $A$ be a set.  \nWe define an equivalence relation on $A^\\omega$ as follows \n$$r\\equiv s\\ \\text{iff}\\ |\\{i: r_i\\neq s_i\\}|<\\omega.$$\nLet $A^\\omega_r=\\{s\\in A^\\omega : s\\equiv r\\}$ be the equivalence class of $r$ and $\\mathcal O_{A,r}^{(\\omega)}$ be the set of all functions from $A^\\omega_r$ to $A$. \n\n%For every $f\\in \\mathcal O_{A}^{(\\omega)}$, we denote by $f_r\\in \\mathcal O_{A,r}^{(\\omega)}$ the restriction of $f$ to $A^\\omega_r$:  $f_r(s)=f(s)$ for every $s\\in A^\\omega_r$.\n\n\\begin{lemma}\\label{lem:fun2} Let $\\mathbf A$ be a $\\tau$-algebra and $r\\in A^\\omega$.\nThe algebra  $\\mathbf O_{\\mathbf A,r}^{(\\omega)}=(\\mathcal O_{A,r}^{(\\omega)},\\sigma^r, q^r_{n},\\e_{i}^r)$, where, for every $s\\in A^\\omega_r$ and $\\varphi,\\psi_1,\\dots,\\psi_n\\in \\mathcal O_{A,r}^{(\\omega)}$, \n\\begin{itemize}\n\\item $\\e_i^r(s)=s_i$;\n\\item $q^r_n(\\varphi,\\psi_1,\\dots,\\psi_n)(s)=\\varphi(s[\\psi_1(s),\\dots, \\psi_n(s)])$;\n\\item $\\sigma^r(\\psi_1,\\dots,\\psi_n)(s)=\\sigma^\\mathbf A(\\psi_1(s),\\dots, \\psi_n(s))$ for every $\\sigma\\in\\tau$ of arity $n$,\n\\end{itemize}\n is a clone algebra of type $\\tau$, called the \\emph{full point-relativized functional clone algebra with value domain} $\\mathbf A$ \\emph{and thread} $r$.\n\\end{lemma}\n\n\n\\begin{definition} \n A subalgebra of  $\\mathbf O_{\\mathbf A,r}^{(\\omega)}$ is called a   \\emph{point-relativized functional clone algebra} with value domain $\\mathbf A$ and thread $r$.\n\\end{definition}\n \n The class of point-relativized functional clone algebras is denoted by $\\mathsf{RCA}$.  $\\mathsf{RCA}_\\tau$ is the class of $\\mathsf{RCA}$s  whose value domain is a $\\tau$-algebra.\n \n\n\nWe introduce the following maps.\n \\begin{itemize}\n\\item If $B\\in \\mathcal B_A$ is a block, then \\emph{the $r$-relativized top extension $B^\\top_r:A^\\omega_r \\to A$ of $B$} is defined by $B^\\top_r(s)=B^{(n)}(s_1,\\dots,s_n)$, for every $s\\in A^\\omega_r$ and $n$ greater than the arity of $B$.\n\\item \\emph{The $r$-relativized $n$-ary restriction $\\psi_{n,r}:A^n\\to A$ of $\\psi\\in \\mathcal O_{ A,r}^{(\\omega)}$} is defined as follows: \n$$\\psi_{n,r}(a_1,\\dots,a_n)= \\psi(r[a_1,\\dots,a_n])\\ \\text{for all $a_1,\\dots,a_n\\in A$}.$$\n\\end{itemize}\n\nAn analogous of Lemma \\ref{lem:independent}, relating the algebraic and functional notions of independence, holds for $\\mathsf{RCA}$s. %We will refer to Lemma \\ref{lem:independent} when we will apply the notion of functional independence to elements of $\\mathsf{RCA}$s.\n\nThe following lemma, which is true in $\\mathcal O_{ A,r}^{(\\omega)}$ and false in $\\mathcal O_{ A}^{(\\omega)}$, explains well the difference between $\\mathsf{RCA}$s and $\\mathsf{FCA}$s.\n\n\\begin{lemma} \\label{lem:toptop}\nLet $\\varphi\\in \\mathcal O_{ A,r}^{(\\omega)}$. Then the following conditions are equivalent:\n\\begin{itemize}\n\\item[(i)] $\\varphi=B^\\top_r$ for some block $B$;\n%\\item[(ii)] There exists $k$ such that $f(s)=f(r[s_1,\\dots,s_n])$ for every $s\\in A^\\omega_r$ and $n\\geq k$;\n\\item[(ii)] $\\varphi$ is finite dimensional in the clone algebra $\\mathbf O_{ A,r}^{(\\omega)}$.\n\\end{itemize} \n\\end{lemma}\n\n\\begin{proof} (i) $\\Rightarrow$ (ii) If $B$ has arity $k$ then, for every $s\\in A^\\omega_r$ and $n\\geq k$, we have\n$$\\varphi(s)= B^\\top_r(s)=B^{(n)}(s_1,\\dots,s_n)=B^\\top_r(r[s_1,\\dots,s_n]) =\\varphi(r[s_1,\\dots,s_n]).$$ \nWe now prove that \n$\\varphi$ is independent of $\\e_n$ for every $n> k$. Let\n$s,u\\in A^\\omega_r$ such that $s_i=u_i$ for every $i\\neq n$.\nThen  $\\varphi(s)=\\varphi(r[s_1,\\dots,s_k]) = \\varphi(r[u_1,\\dots,u_k]) = \\varphi(u)$. Then by Lemma \\ref{lem:independent} $\\varphi$ is independent of $\\e_n$ for every $n>k$. In other words, $\\varphi$ is finite dimensional.\n \n (ii) $\\Rightarrow$ (i) Let $n$ be the dimension of $\\varphi$ and $s\\in A^\\omega_r$. We have to show that  $\\varphi(s)=(\\varphi_{n,r})^\\top_r(s)$. \n Let $k$ be  minimal such that $s=r[s_1,\\dots,s_k]$. If $k \\leq n$ then $s_i=r_i$ for all $k+1\\leq i\\leq n$ and $s=r[s_1,\\dots,s_k]= r[s_1,\\dots,s_n]$. Hence, \n $(\\varphi_{n,r})^\\top_r(s)= \\varphi_{n,r}(s_1,\\dots,s_n) = \\varphi(r[s_1,\\dots,s_n]) =\\varphi(s)$.\n If $k> n$, then $(\\varphi_{n,r})^\\top_r(s)= \\varphi_{n,r}(s_1,\\dots,s_n) = \\varphi(r[s_1,\\dots,s_n]) =\\varphi(r[s_1,\\dots,s_n,s_{n+1}])=\\dots=\\varphi(r[s_1,\\dots,s_n,s_{n+1},\\dots,s_k])= \\varphi(s)$, because $\\varphi$ is independent of $\\e_{n+1},\\dots,\\e_k$.\n\\end{proof}\n\n%\\begin{example} %In this example we show that there are \n%Let $2=\\{0,1\\}$ and $r\\in 2^\\omega$ such that $r_i=1$ for all $i$. We denote by $0^\\top_r:2^\\omega_r\\to 2$ the constant function of value $0$, and by $1^\\top_r:2^\\omega_r\\to 2$ the constant function of value $1$. The set $\\{0^\\top_r,1^\\top_r,\\e_1^r,\\dots,\\e_n^r,\\dots\\}$ is a subalgebra of the full $\\mathsf{RCA}$ $\\mathbf O^{(\\omega)}_{2,r}$. Both algebras have the same set $\\{0^\\top_r,1^\\top_r\\}$ of zero-dimensional elements. \n%\\end{example}\n\n\\subsection{The main theorem}\nWe recall that  $\\mathsf{CA}$ is the class of all clone algebras, $\\mathsf{RCA}$ is the class of all point-relativized functional clone algebras, $ \\mathsf{FCA}$ is the class of all functional clone algebras,  $\\mathsf{FiCA}$ is the class of all finite dimensional clone algebras, and $\\mathsf{BLK}$ is the class of all block algebras.\n\n\\begin{theorem}\\label{thm:main}\n $\\mathsf{CA} = \\mathbb I\\, \\mathsf{RCA}=\\mathbb I\\, \\mathsf{FCA}=\\mathbb{HSP}(\\mathsf{FiCA})=\\mathbb{HSP}(\\mathsf{BLK})$.\n\\end{theorem}\n\n\\begin{remark} \n As a consequence of the proof of main theorem, every clone $\\tau$-algebra $\\mathbf C=(\\mathbf C_\\tau,q^\\mathbf C_n,\\e^\\mathbf C_i)$ can be embedded into the full $\\mathsf{FCA}$ with value domain $((\\mathbf C_\\tau)^\\omega/U)^J$, where $U$ is a nonprincipal ultrafilter on $\\omega$ and $J$ is a suitable set having the same cardinality as $C$. Since the $\\tau$-algebra $((\\mathbf C_\\tau)^\\omega/U)^J$ is a power of an ultraproduct, then it belongs to the quasivariety generated by  $\\mathbf C_\\tau$.\n\\end{remark}\n \n The proof of the main theorem is divided into lemmas.\n \n \\begin{lemma}\\label{lem:ca=rca}\n $\\mathsf{CA}_\\tau = \\mathbb I\\, \\mathsf{RCA}_\\tau$.\n\\end{lemma}\n\n\\begin{proof} Let $\\mathbf C=(\\mathbf C_\\tau,q^\\mathbf C_n,\\e^\\mathbf C_i)$ \nbe a clone $\\tau$-algebra.\n%To simplify notations we put $\\mathbf B=\\mathbf C_\\tau$ in this proof.  \nLet $\\mathbf O_{ \\mathbf C_\\tau,\\epsilon}^{(\\omega)}$    be the full $\\mathsf{RCA}$ with value domain $\\mathbf C_\\tau$ and thread $\\epsilon$, where  $\\epsilon_i=\\e^\\mathbf C_i$ for every $i$. We define a map $F:C\\to  \\mathcal O_{C,\\epsilon}^{(\\omega)}$ as follows for every $s\\in C^\\omega_\\epsilon$   such that $s= \\epsilon[s_1,\\dots,s_k]$ and $s_k\\neq \\e_k^\\mathbf C$:\n$$F(c)(s)=q_k^\\mathbf C(c, s_1,\\dots,s_k).$$\nNotice that by Lemma \\ref{lem:exc4} $F(c)(s)=q_n^\\mathbf C(c, s_1,\\dots,s_k,\\e_{k+1}^\\mathbf C,\\dots,\\e_n^\\mathbf C)$ for every $n\\geq k$.\n$F$ is injective because $F(c)(\\epsilon)=q_0^\\mathbf C(c)=c$. \nWe prove that $F$ embeds $\\mathbf C$ into $\\mathbf O_{\\mathbf C_\\tau,\\epsilon}^{(\\omega)}$.  Let $\\mathbf a=s_1,\\dots,s_k$. \n%in the remaining part of this proof.\n\n($n\\geq k$):\n$\\qquad\\qquad\n\\begin{array}{rlll}\n &   & F(q^\\mathbf C_n(b,\\mathbf c))(s) &\\\\\n & =  &  q_k^\\mathbf C(q^\\mathbf C_n(b,\\mathbf c), \\mathbf a) &\\text{Def. $F$}\\\\\n  & =  & q_n^\\mathbf C(b,q_k^\\mathbf C(c_1,\\mathbf a),\\dots,q_k^\\mathbf C(c_n,\\mathbf a))&\\text{(C5)} \\\\\n&=& q_n^\\mathbf C(b,F(c_1)(s),\\dots,F(c_n)(s))&\\text{Def. $F$}\\\\\n  &  = & F(b)(\\epsilon[F(c_1)(s),\\dots,F(c_n)(s)])  &\\text{Def. $F$}\\\\\n    &  = & F(b)(s[F(c_1)(s),\\dots,F(c_n)(s)])  &\\text{by $n\\geq k$}\\\\\n  &  = & q^\\epsilon_n(F(b),F(c_1),\\dots,F(c_n))(s).&\n \\end{array}\n$\n\n\\bigskip\n\n($n< k$):\n$\\qquad\\qquad\n\\begin{array}{rlll}\n&  & F(q^\\mathbf C_n(b,\\mathbf c))(s)   &\\\\\n & =  &  q_k^\\mathbf C(q^\\mathbf C_n(b,\\mathbf c), \\mathbf a) &\\\\\n& =  & q_k^\\mathbf C(b,q_k^\\mathbf C(c_1,\\mathbf a),\\dots,q_k^\\mathbf C(c_n,\\mathbf a),s_{n+1},\\dots,s_k)&\\text{(C4)} \\\\\n   &  = & F(b)(\\epsilon[F(c_1)(s),\\dots,F(c_n)(s),s_{n+1},\\dots,s_k])  &\\\\\n   &  = & F(b)(s[F(c_1)(s),\\dots,F(c_n)(s),s_{n+1},\\dots,s_k])  &\\\\\n  &  = & q^\\epsilon_k(F(b),F(c_1),\\dots,F(c_n),\\e^\\epsilon_{n+1},\\dots,\\e^\\epsilon_n)(s)&\\\\\n    &  = & q^\\epsilon_n(F(b),F(c_1),\\dots,F(c_n))(s).&\\\\\n  \\end{array}\n$\n\n\\bigskip\n\n$\\qquad\\qquad\n\\begin{array}{rlll}\nF(\\sigma^\\mathbf C(\\mathbf b))(s) \n& =&   q^\\mathbf C_k(\\sigma^\\mathbf C(\\mathbf b),\\mathbf a)\\\\\n  & =&  \\sigma^\\mathbf C(q^\\mathbf C_k(b_1,\\mathbf a),\\dots,q^\\mathbf C_k(b_n,\\mathbf a))  \\\\\n& =&  \\sigma^\\mathbf C(F(b_1)(s),\\dots,F(b_n)(s))  \\\\\n & =&   \\sigma^\\epsilon(F(b_1),\\dots,F(b_n))(s). \n  \\end{array}\n$\n\n\\end{proof}\n\nBy the $n$-reduct of a clone $\\tau$-algebra $\\mathbf C=(\\mathbf C_\\tau,q^\\mathbf C_n,\\e^\\mathbf C_i)_{n\\geq 0,i\\geq 1}$ we mean the algebra \n$$\\mathrm{Rd}_n \\mathbf C:=(\\mathbf C_\\tau,q^\\mathbf C_0,\\dots,q^\\mathbf C_n,\\e^\\mathbf C_1,\\dots,\\e^\\mathbf C_n).$$\n\n\\begin{lemma}\\label{lem:red} Let $\\mathbf A$ be a $\\tau$-algebra and\n $\\mathbf D$ be a $\\mathsf{RCA}$ with value domain $\\mathbf A$ and thread $r$. For every $n> 0$ \n the map $F_{r,n}: D \\to \\mathcal B_{A}^\\top$, defined by\n $$F_{r,n}(\\varphi)(s)=\\varphi(r[s_1,\\dots,s_n])\\qquad\\text{for every $\\varphi\\in D$ and $s\\in A^\\omega$},$$\n is a homomorphism of $\\mathrm{Rd}_n(\\mathbf D)$ into the $n$-reduct of the full block algebra\n $\\mathbf B_{\\mathbf A}^\\top$.\n\\end{lemma}\n\n\\begin{proof}\n Let $k\\leq n$,  $s\\in A^\\omega$ and $u=r[s_1,\\dots,s_n]$. Let $F= F_{r,n}$ in this proof. \n \\[\n\\begin{array}{rll}\nF(q^r_k(\\varphi,\\psi_1,\\dots,\\psi_k))(s)   & =  & q^r_k(\\varphi,\\psi_1,\\dots,\\psi_k)(u)\\\\\n  &= & \\varphi(u[\\psi_1(u),\\dots,\\psi_k(u)])  \\\\\n  &  = &   \\varphi(r[\\psi_1(u),\\dots,\\psi_k(u),s_{k+1},\\dots,s_n])\\\\\n % &=& q_k^\\omega (a,b_1,\\dots,b_k)(\\mu)\\\\\n  &&\\\\\n q_k^\\omega (F(\\varphi),F(\\psi_1),\\dots,F(\\psi_k))(s)\n   &=&F(\\varphi)(s[F(\\psi_1)(s),\\dots,F(\\psi_k)(s)]) \\\\\n   &=&F(\\varphi)(s[F(\\psi_1)(s),\\dots,F(\\psi_k)(s),s_{k+1},\\dots,s_n]) \\\\\n   &=&F(\\varphi)(s[\\psi_1(u),\\dots,\\psi_k(u),s_{k+1},\\dots,s_n])\\\\\n   &=&\\varphi(r[\\psi_1(u),\\dots,\\psi_k(u),s_{k+1},\\dots,s_n])\\\\\n &&\\\\\nF(\\sigma^r(\\psi_1,\\dots,\\psi_k))(s)   & =  & \\sigma^r(\\psi_1,\\dots,\\psi_k)(u)\\\\\n  &= & \\sigma^\\mathbf A(\\psi_1(u),\\dots,\\psi_k(u))  \\\\\n  &= & \\sigma^\\mathbf A(F(\\psi_1)(s),\\dots,F(\\psi_k)(s))  \\\\  \n  &  = &  \\sigma^\\omega(F(\\psi_1),\\dots,F(\\psi_k))(s). \\\\\n  \\end{array}\n\\]\n\\end{proof}\n\n\\begin{lemma}\\label{lem:cafica} $\\mathsf{CA}_\\tau =\\mathbb{HSP}(\\mathsf{FiCA}_\\tau)$.\n% The variety of clone algebras is generated by its locally finite members.\n\\end{lemma}\n\n\\begin{proof}\n Let $t(v_1,\\dots,v_k)=u(v_1,\\dots,v_k)$ be an identity (in the language of clone $\\tau$-algebras) satisfied by every finite dimensional clone $\\tau$-algebra.\n We now show that the identity $t=u$ holds in every clone $\\tau$-algebra. Since $\\mathsf{CA}_\\tau =\\mathbb I\\,\\mathsf{RCA}_\\tau$\n it is sufficient to prove that the identity $t=u$ holds in every full $\\mathsf{RCA}_\\tau$ $\\mathbf O_{ \\mathbf A,r}^{(\\omega)}$ with value domain  $\\mathbf A$ and thread $r$. If $t^r$ and $u^r$ are the interpretation of $t$ and $u$ in $\\mathbf O_{ \\mathbf A,r}^{(\\omega)}$, we have to show that\n  $$t^r(\\varphi_1,\\dots, \\varphi_k)(s)=u^r(\\varphi_1,\\dots, \\varphi_k)(s)$$\nfor all $\\varphi_1,\\dots,\\varphi_k\\in \\mathcal O_{ A,r}^{(\\omega)}$ and all $s \\in A^\\omega_r$.\nLet $n>k$ such that $q_m$ and $\\e_m$ do not occur in $t,u$ for every $m> n$. Since $\\mathbf O_{ \\mathbf A,r}^{(\\omega)}$ satisfies the equation $t=u$ iff the $n$-reduct $\\mathrm{Rd}_n\\, \\mathbf O_{ \\mathbf A,r}^{(\\omega)}$ satisfies it, then\nwe can use the function $F_{s,n}$  defined in Lemma \\ref{lem:red}. Let $t^\\omega$ and $u^\\omega$ be the interpretation of $t$ and $u$ in the full $\\mathsf{FCA}$  $\\mathbf O_{ \\mathbf A}^{(\\omega)}$.\n\\[\n\\begin{array}{lll}\nt^r(\\varphi_1,\\dots, \\varphi_k)(s)  & =  & t^r(\\varphi_1,\\dots, \\varphi_k)(s[s_1,\\dots,s_n])  \\\\\n  & =  &F_{s,n}(t^r(\\varphi_1,\\dots, \\varphi_k))(s)   \\\\\n  &  = &  t^\\omega(F_{s,n}(\\varphi_1),\\dots, F_{s,n}(\\varphi_k))(s) \\\\ \n  &  = &  u^\\omega(F_{s,n}(\\varphi_1),\\dots, F_{s,n}(\\varphi_k))(s) \\\\ \n    & =  &F_{s,n}(u^r(\\varphi_1,\\dots, \\varphi_k))(s)   \\\\\n & =  & u^r(\\varphi_1,\\dots, \\varphi_k)(s)\n\\end{array}\n\\]\nbecause the image of $F_{s,n}$ is a finite dimensional $\\mathsf{FCA}$.\n\\end{proof}\n\nThen, the following corollary is a consequence of  Theorem \\ref{thm:fica}.\n\n\\begin{corollary}\\label{cor:cablk}\n $\\mathsf{CA}_\\tau =\\mathbb{HSP}(\\mathsf{BLK}_\\tau)$.\n\\end{corollary}\n\nThe remaining part of the proof of Theorem \\ref{thm:main} is technical and it is postponed in Appendix.\n\n\n\\section{A characterisation of the lattices of equational theories}\\label{sec:eqth}\nIn this section we propose a possible answer to the lattice of equational theories problem described in Section \\ref{sec:pre:leq}. We prove that a lattice is isomorphic to a lattice of equational theories if and only if it is isomorphic to the lattice of all congruences of a finite dimensional clone algebra. Unlike Newrly's and Nurakunov's approaches \\cite{newrly,nur}, we have an equational axiomatisation of the variety generated by  the class of finite dimensional clone algebras (see Theorem \\ref{thm:main} and  Section \\ref{sec:pre:leq}). The main steps of the proof are the following:\n\\begin{itemize}\n\\item Given a variety of algebras axiomatised by an equational theory $T$, we turn its free algebra into a finite dimensional clone algebra, whose lattice of congruences is the lattice of equational theories extending $T$.\n\\item Given a finite dimensional clone algebra $\\mathbf C$, we build a variety such that the congruence lattice of $\\mathbf C$ is isomorphic to the lattice of equational theories extending the theory of that variety.\n\\end{itemize}\nWe conclude the section by showing that a lattice is isomorphic to a lattice of subclones if and only if it is isomorphic to the lattice of all subalgebras of a finite dimensional clone algebra.\n\n\\bigskip\n\nIt is well known that any lattice of equational theories is isomorphic to a congruence lattice. \nLet $T$ be an equational theory and $\\mathcal V$ be the variety axiomatised by $T$. The lattice $L(T)$ of all equational theories extending $T$ is isomorphic \nto the lattice of all fully invariant congruences of the free algebra $\\mathbf{F}_\\mathcal{V}$ over a countable set $I=\\{v_1,v_2,\\ldots,v_n,\\ldots\\}$ of generators.\n\nWe say that an endomorphism $f$ of the free algebra $\\mathbf{F}_\\mathcal{V}$ is \\emph{$n$-finite} if $f(v_i)=v_i$ for every $i>n$. An endomorphism is finite if it is $n$-finite for some $n$. \n\n\\begin{lemma}\\label{lem:end} \\cite{BS,mac} \n  The lattice of fully invariant congruences is isomorphic to\nthe congruence lattice of the algebra $(\\mathbf{F}_\\mathcal{V},f)_{f\\in \\mathrm{End}}$, which is an expansion of  $\\mathbf{F}_\\mathcal{V}$ by the set End of all its finite endomorphisms.\n\\end{lemma}\n\nThe set of all $n$-finite endomorphisms can be collectively expressed by an $(n+1)$-ary operation $q_n^\\mathbf F$ on $\\mathbf{F}_\\mathcal{V}$ (see Example \\ref{exa:free}):\n \\begin{equation}\\label{eq:qqq} q_n^\\mathbf F(a,b_1,\\dots,b_n)=s(a),\\quad\\text{for every\n$a,b_1,\\dots,b_n\\in F_\\mathcal{V}$,}\\end{equation}\nwhere $s$ is the unique $n$-finite endomorphism\nof $\\mathbf{F}_\\mathcal{V}$ which sends the generator $ v_i$ to $b_i$ ($1\\leq i\\leq n$). \n%More suggestively: $q_n^\\mathbf F(a,b_1,\\dots,b_n)$ is the equivalence class of the term $t[w_1/v_1,\\dots,w_n/v_n]$, where $t\\in a$ and $w_i\\in b_i$. \n\n%We remark that Lampe's proof of the Zipper condition (defined in Section \\ref{sec:pre:leq}) uses the operator $q_2^\\mathbf F$  in (\\ref{eq:qqq}) (see the proof of McKenzie Lemma in \\cite{lampe}).\n%If $T$ is any equational theory, then $L(T)$ is isomorphic to $\\mathrm{Con} \\mathbf A$ for some algebra $\\mathbf A$ having a binary term function which has a left zero and a left one. \n% [commento: dire che Lampe prova la Zipper con $q_1$]\n\n\\begin{definition}\\label{def:cva}\n Let $\\mathcal V$ be a variety and $\\mathbf{F}_\\mathcal{V}$ be the free $\\mathcal V$-algebra over a countable set $I$ of generators.\n Then the algebra  $\\mathbf{Cl}(\\mathcal{V})=(\\mathbf{F}_\\mathcal{V}, q_n^\\mathbf{F}, \\e_i^\\mathbf{F})$,\nwhere $\\e_i^\\mathbf{F}= v_i\\in I$ and $q_n^\\mathbf{F}$ is defined in (\\ref{eq:qqq}),\nis  called \\emph{the clone  $\\mathcal V$-algebra}.\n\\end{definition}\n \n\\begin{proposition}\\label{prop:free} Let $\\mathcal V$ be a variety of $\\tau$-algebras axiomatised by the equational theory $T$. Then we have:\n\\begin{enumerate}\n\\item   The clone  $\\mathcal V$-algebra  $\\mathbf{Cl}(\\mathcal{V})$\nis a finite dimensional clone $\\tau$-algebra.\n\\item  The congruences lattice $\\mathrm{Con}\\,\\mathbf{Cl}(\\mathcal{V})$   is isomorphic to the lattice of equational theories $L(T)$.\n\\item If $w\\in F_\\mathcal{V}$ has dimension $n>0$ in $\\mathbf{Cl}(\\mathcal{V})$, then there exists a $\\tau$-term $t(v_1,\\dots,v_n)$ belonging to $w$. \n\\item If $w\\in F_\\mathcal{V}$ has dimension $0$ in $\\mathbf{Cl}(\\mathcal{V})$, then there exists a $\\tau$-term $t(v_1)\\in w$ such that $\\mathcal V]\\models t(v_1)=t(v_2)$.\n\\item If $\\mathrm{Clo}\\,\\mathbf{F}_\\mathcal{V}$ is the clone of term operations of $\\mathbf{F}_\\mathcal{V}$, then the clone  $\\mathcal V$-algebra  $\\mathbf{Cl}(\\mathcal{V})$ is isomorphic to the block algebra $(\\mathrm{Clo}\\,\\mathbf{F}_\\mathcal{V})^\\top$ (see Section \\ref{sec:to} and Lemma \\ref{prop:cloneblock}). \n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof} (1) is straightforward.\n\n(2) By Lemma \\ref{lem:end} and the definition of $q_n^\\mathbf{F}$.\n\n (3) Let $u\\in w$ be an arbitrary term. Let $v_k$ be the last variable occurring in $u$ (i.e., $v_i$ does not occur in $u$ for every $i>k$). The term $q_k(u,v_1,\\dots,v_n,v_{1},\\dots, v_1)= u[v_1/v_{n+1},v_1/v_{n+2}\\dots,v_1/v_k ]$ belongs to $w$ and satisfies the required properties.\n \n (4) Let $u\\in w$ be an arbitrary term. If $u$ is ground, then $u=u(v_1)$ and we are done. Otherwise, we follow the reasoning in item (3).\n \n(5) If $t(v_1,\\dots,v_n)$ is a $\\tau$-term and $\\mathbf A\\in\\mathcal V$ is a $\\tau$-algebra, then the set $T_t^\\mathbf A$ (defined in Section \\ref{sec:to}) of the term operations determined by $t$ is a block.\nNotice that the arity of the block $T_t^\\mathbf A$ may be less than $n$.  If $\\mathcal V\\models t_1=t_2$, then $T_{t_1}^\\mathbf A = T_{t_2}^\\mathbf A$ for every $\\mathbf A\\in\\mathcal V$.\nFor the free algebra $\\mathbf{F}_\\mathcal{V}$, we have that $\\mathcal V\\models t_1=t_2$ iff $T_{t_1}^\\mathbf A = T_{t_2}^\\mathbf A$ iff $(T_{t_1}^\\mathbf A)^\\top = (T_{t_2}^\\mathbf A)^\\top$. It easily follows that $\\mathbf{Cl}(\\mathcal{V})$ is isomorphic to the block algebra $(\\mathrm{Clo}\\,\\mathbf{F}_\\mathcal{V})^\\top$.\n\\end{proof}\n\n\\begin{definition}\\label{def:ctype}\n Let $\\mathbf C$ be a pure clone algebra and  $R_\\mathbf C$ be the clone of all $\\mathbf C$-representable functions described in Definition \\ref{def:representable}. \n\\begin{enumerate}\n\\item The \\emph{$\\mathbf C$-type} is the algebraic type\n$\\rho_\\mathbf C =  \\{\\overline f: f \\in R_\\mathbf C\\}$, \nwhere  the operation symbol $\\overline f$ has  arity $k$ if  $f$ is a $k$-ary representable function. \n\\item The $\\rho_\\mathbf C$-algebra $\\mathbf R_\\mathbf C=(C,  f)_{f\\in R_\\mathbf C}$ is called  the \\emph{algebra of $\\mathbf C$-representable functions};\n\\item The algebra $\\overline{\\mathbf R}_\\mathbf C=(\\mathbf R_\\mathbf C,q_n^\\mathbf C,\\e_i^\\mathbf C)$ is called the \\emph{clone $\\rho_\\mathbf C$-algebra of $\\mathbf C$-representable functions}.\n\\end{enumerate}\n\n\\end{definition}\n\n\n\n%The type $\\rho_\\mathbf C$ is an expansion of $\\tau$ because\n%by Corollary \\ref{cor:sigma} every basic operation $\\sigma^\\mathbf C$ of  type $\\tau$ is $\\mathbf C$-representable. \n%\n%We define $\\mathbf C_{\\overline{\\tau}}$  to be the $\\overline{\\tau}$-algebra $(C,  h)_{h\\in R_\\mathbf C}$.\n%\n%Let $\\mathbf C=(\\mathbf C_\\tau,q_n^\\mathbf C,\\e_i^\\mathbf C)$ be a finite dimensional clone $\\tau$-algebra and  $R_\\mathbf C$ be the clone of all $\\mathbf C$-representable functions described in Definition \\ref{def:representable}. \n%We consider a new algebraic type $\\overline\\tau =  \\{\\overline h: h \\in R_\\mathbf C\\}$, where  the operation symbol $\\overline h$ has  arity $k$ if $h$ is a function from $C^k$ to $C$. The type $\\overline\\tau$ is an expansion of $\\tau$ because\n%by Corollary \\ref{cor:sigma} every basic operation $\\sigma^\\mathbf C$ of  type $\\tau$ is $\\mathbf C$-representable. \n%\n%We define $\\mathbf C_{\\overline{\\tau}}$  to be the $\\overline{\\tau}$-algebra $(C,  h)_{h\\in R_\\mathbf C}$.\n%We denote by $\\mathrm{Var}(\\mathbf C)$ $\\mathcal C$ the variety generated by the $\\tau_\\mathbf C$-algebra $\\mathbf C_{\\tau_\\mathbf C}=(C,  h)_{h\\in R_\\mathbf C}$.\n\n\n\\begin{theorem}\\label{thm:ch} Let $\\mathbf C$ be a finite dimensional clone algebra.\n% $\\overline{\\mathbf C}=(\\mathbf C_{\\rho},q_n^\\mathbf C,\\e_i^\\mathbf C)$ be the clone $\\rho_\\mathbf C$-algebra of $\\mathbf C$-representable functions and $\\mathcal V=\\mathrm{Var}(\\mathbf C_\\rho)$ be the variety of $\\rho_\\mathbf C$-algebras generated by $\\mathbf C_\\rho$. \nThen we have:\n\\begin{itemize}\n\\item[(i)]  $\\mathbf R_\\mathbf C$ is isomorphic to the free algebra over a countable set of generators in the variety $\\mathrm{Var}(\\mathbf R_\\mathbf C)$;\n\\item[(ii)] $\\overline{\\mathbf R}_\\mathbf C$ is isomorphic to the clone $\\mathrm{Var}(\\mathbf R_\\mathbf C)$-algebra.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof}  \nWe show that $\\mathbf R_\\mathbf C$ is the free algebra  over a countable set $\\{\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C,\\dots\\}$ of generators in the variety $\\mathrm{Var}(\\mathbf R_\\mathbf C)$. \n Let $\\mathbf A\\in  \\mathrm{Var}(\\mathbf R_\\mathbf C)$, $g: \\{\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C,\\dots\\}\\to A$ be an arbitrary map, and $d_i=g(\\e_i^\\mathbf C)$.\n We extend $g$ to a map $g^*: C\\to A$ as follows. Let $b\\in C$ of dimension $k$ and, for every $m\\geq k$, let $f^{m}_b:C^m\\to C$ be the function defined by $f^{m}_b(c_1,\\dots,c_m)=q_m^\\mathbf C(b,c_1,\\dots,c_m)$ for every $c_i\\in C$. Since $f^{m}_b$ is $\\mathbf C$-representable (see Definition \\ref{def:representable} and Lemma \\ref{12}), then $\\overline{f^{m}_b}\\in \\rho_\\mathbf C$ for every $m\\geq k$ and we define \n $$g^*(b)=\\overline{f^{k}_b}^\\mathbf A(d_1,\\dots,d_{k}).$$\nSince $\\mathbf C\\models f^m_b(x_1,\\dots,x_k,x_{k+1},\\dots, x_m)= f^k_b(x_1,\\dots,x_k)$ for every $m\\geq k$ and $\\mathbf A\\in \\mathrm{Var}(\\mathbf R_\\mathbf C)$, then we have   \n$$g^*(b) =\\overline{f^m_b}^\\mathbf A (d_1,\\dots,d_m)\\quad \\text{for every $m\\geq k$}.$$ \nWe now show that $g^*$ is a homomorphism of $\\rho_\\mathbf C$-algebras. \nLet $\\overline h\\in \\rho_\\mathbf C$ of arity $n$, $\\mathbf b=b_1,\\dots,b_n\\in C$ and $\\mathbf e=\\e_1,\\dots,\\e_n$. \nLet $m\\geq n$ be a natural number greater than the maximal among the dimensions of the elements $b_1,\\dots,b_n,q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$.\nLet $\\mathbf d=d_1,\\dots,d_m$ and $\\mathbf o=\\e_1,\\dots,\\e_m$. \nWe now show that \n$$g^*( h(\\mathbf b))=\\overline h^\\mathbf A(g^*(b_1),\\dots,g^*(b_n)).$$\nRecalling that $h(\\mathbf b)=q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$ (see Definition \\ref{def:representable}), then we have:\n\\begin{itemize}\n\\item $\\overline h^\\mathbf A(g^*(b_1),\\dots,g^*(b_n))=\n\\overline h^\\mathbf A(\\overline{f^m_{b_1}}^\\mathbf A(\\mathbf d),\\dots,\\overline{f^m_{b_n}}^\\mathbf A(\\mathbf d))$;\n\\item $ g^*(h(\\mathbf b))\n=g^*(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b))= \\overline{f^m_r}^\\mathbf A(\\mathbf d)$, where $r= q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$.\n\n\\end{itemize}\n\nWe get that $g^*$ is a homomorphism if  the algebra $\\mathbf A$ satisfies the identity \n$$\\overline h(\\overline{f^m_{b_1}} (x_1,\\dots,x_m),\\dots,\\overline{f^m_{b_n}} (x_1,\\dots,x_m))=\n\\overline{f^m_r}(x_1,\\dots,x_m),\\quad\n\\text{where $r= q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$}.$$\nSince $\\mathbf A\\in\\mathrm{Var}(\\mathbf R_\\mathbf C)$, then it is sufficient to prove that $\\mathbf R_\\mathbf C$ satisfies the above identity. By putting $\\mathbf x= x_1,\\dots,x_m$ the conclusion follows from Lemma \\ref{12}(ii):\n$$f^m_r(\\mathbf x)=q_m^\\mathbf C(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b),\\mathbf x)= q_m^\\mathbf C(h(\\mathbf b),\\mathbf x)=_{Lem. \\ref{12}}\n h(q_m^\\mathbf C(b_1,\\mathbf x),\\dots,q_m^\\mathbf C(b_n,\\mathbf x))=h(f^m_{b_1}(\\mathbf x),\\dots,f^m_{b_n} (\\mathbf x)).$$ \nIt remains to show that the operation $p(x)=q_n^\\mathbf C(x,\\mathbf b)$ is the unique $n$-finite endomorphism\nof the free algebra $\\mathbf R_\\mathbf C$ which sends $\\e_i$ to $b_i$ ($1\\leq i\\leq n$). This again follows from Lemma \\ref{12}(ii) because\n$p(h(\\mathbf a))=q_n^\\mathbf C(h(\\mathbf a),\\mathbf b) = h(q_n^\\mathbf C(a_1,\\mathbf b),\\dots,q_n^\\mathbf C(a_k,\\mathbf b))=h(p(a_1),\\dots,p(a_k))$ for every $\\overline h\\in\\rho_\\mathbf C$ of arity $k$.\n\\end{proof}\n\n%For every finite dimensional clone algebra $\\mathbf C$, the variety $\\mathcal V(\\mathbf C)$ of $\\tau_\\mathbf C$-algebras generated by $(C,h)_{h\\in R(\\mathbf C)}$ is called \\emph{the $\\mathbf C$-variety}.\n\nLet $\\tau$ be a type and $\\mathsf{CA}_\\tau$ be the variety of clone $\\tau$-algebras. We define $\\mathrm{Con}\\,\\mathsf{CA}_\\tau$ as the class of the isomorphic copies of all congruence lattices of algebras in $\\mathsf{CA}_\\tau$:\n$$\\mathrm{Con}\\,\\mathsf{CA}_\\tau = \\mathbb I \\{\\mathrm{Con}\\, \\mathbf C: \\mathbf C \\in \\mathsf{CA}_\\tau \\}.$$\nNotice that by Corollary \\ref{cor:taunu}  $\\mathrm{Con}\\,\\mathsf{CA}_\\tau =\\mathrm{Con}\\,\\mathsf{CA}_\\nu$ for all types $\\tau$ and $\\nu$.\n\n\\begin{theorem}\\label{thm:BM} A lattice $L$ is isomorphic to a lattice of equational theories if and only if $L\\in \\mathrm{Con}\\,\\mathsf{CA}_\\tau$. \n  \\end{theorem}\n\n\\begin{proof} ($\\Rightarrow$) It follows from Proposition \\ref{prop:free}. \n\n($\\Leftarrow$) Let $\\mathbf C$  be a finite dimensional clone algebra and $\\overline{\\mathbf R}_\\mathbf C=(\\mathbf C_\\rho,q_n^\\mathbf C,\\e_i^\\mathbf C)$ be the clone $\\rho_\\mathbf C$-algebra of representable functions. Since $\\mathbf C$ and $\\overline{\\mathbf R}_\\mathbf C$ have the same pure reduct, then by Corollary \\ref{cor:taunu} we have $\\mathrm{Con}\\,\\mathbf C=\\mathrm{Con}\\,\\overline{\\mathbf R}_\\mathbf C$. The conclusion of the theorem follows from Theorem \\ref{thm:ch}(ii) and Proposition \\ref{prop:free}(2), because $\\overline{\\mathbf R}_\\mathbf C$ is isomorphic to the clone $\\mathrm{Var}(\\mathbf R_\\mathbf C)$-algebra. \n%\n%By Theorem \\ref{thm:ch} $\\overline{\\mathbf C}=(\\mathbf C_{\\overline{\\tau}},q_n^\\mathbf C,\\e_i^\\mathbf C)$\n%is isomorphic to the clone $\\mathrm{Var}(\\mathbf C_{\\overline{\\tau}})$-algebra. \n%We conclude the proof by showing that $\\mathrm{Con}(\\mathbf C)=\\mathrm{Con}(\\overline{\\mathbf C})$.\n% We have that $\\mathrm{Con}(\\overline{\\mathbf C})\\subseteq \\mathrm{Con}(\\mathbf C)$ because every basic operation $\\sigma^\\mathbf C$ of $\\mathbf C_\\tau$ is $\\mathbf C$-representable and \n%$(\\overline{\\sigma^\\mathbf C})^{\\mathbf C_{\\overline{\\tau}}}=\\sigma^\\mathbf C$. For the opposite direction,\n%let $\\phi\\in  \\mathrm{Con}(\\mathbf C)$. We have to show that $\\phi$ is compatible w.r.t. every $\\mathbf C$-representable function $h: C^k\\to C$. Let $\\mathbf a\\phi \\mathbf b$. Then\n%$h(\\mathbf a)=q_k^\\mathbf C(h(\\mathbf e),\\mathbf a)\\ \\phi\\ q_k^\\mathbf C(h(\\mathbf e),\\mathbf b)=h(\\mathbf b)$.\n%By Proposition \\ref{prop:free}(2) we get that $\\mathrm{Con}(\\mathbf C)$ is isomorphic to a lattice of equational theories.\n\\end{proof}\n\n%By Theorem \\ref{thm:representation} $\\mathbf C$ is isomorphic to a functional $\\mathcal G$-clone algebra $\\mathbf F=(F,q_n^\\mathcal G,p_i)$. Let $F$ be the $\\mathcal G$-clone associated with this isomorphism.\n%We consider a type $\\tau$ of algebras defined as follows. For every generator $f\\in F$ of arity $n$, which is not a projection, we consider a symbol $\\sigma_f\\in\\tau$ of arity $n$.\n%$F$ becomes a $\\tau$-algebra $\\hat{\\mathbf F}=(F,q_n^\\mathcal G,f^\\mathcal G)$. \n%\\begin{claim}\n%$\\mathbf C_\\tau$ is isomorphic to the free algebra over a countable set $\\e_1,\\dots,\\e_n,\\dots$ of generators in the variety $\\mathcal V(\\mathbf C_\\tau)$ generated by $\\mathbf C_\\tau$. \n%\\end{claim}\n%\n%\\begin{proof}\n% Let $\\mathbf A\\in \\mathcal V(\\mathbf C_\\tau)$ and let $\\phi: X\\to A$ be an arbitrary map. Let $\\phi(\\e_i)=d_i\\in A$.\n% We extend $\\phi$ to a map $\\phi^*: C\\to A$ as follows. Let $b\\in C$, $k=\\gamma(b)$ and $f^{m}_b=q_m^\\mathbf C(b,-)$ for every $m\\geq k$. Since $f^{m}_b$ belongs to the set $R(b)$ of $\\mathbf C$-representable operations determined by $b$, then $\\overline{f^{m}_b}\\in \\tau$ and we define \n% $$\\phi^*(b)=\\overline{f^{k}_b}^\\mathbf A(d_1,\\dots,d_{k}).$$\n%By definition of $f^m_b$ and by $\\mathbf C_\\tau\\models f^m_b(x_1,\\dots,x_k,x_{k+1},\\dots, x_m)= f^m_b(x_1,\\dots,x_k)$ we also have that  \n%$$\\phi^*(b) =\\overline{f^m_b}^\\mathbf A (d_1,\\dots,d_m)\\quad \\text{for every $m\\geq k$}.$$ \n%\n%Let $\\overline h\\in\\tau$ of arity $n$, $\\mathbf b=b_1,\\dots,b_n\\in C$ and $\\mathbf e=\\e_1,\\dots,\\e_n$. \n%Let $m$ be a natural number greater than $n,\\gamma(b_1),\\dots,\\gamma(b_n)$ and $\\gamma(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b))$.\n%Let $\\mathbf d=d_1,\\dots,d_m$ and $\\mathbf o=\\e_1,\\dots,\\e_m$. \n%We now show that $\\phi^*$ is a homomorphism, i.e,\n%$$\\phi^*(\\overline h^{\\mathbf C_\\tau}(\\mathbf b))=\\overline h^\\mathbf A(\\phi^*(b_1),\\dots,\\phi^*(b_n)).$$\n%\n%\\begin{itemize}\n%\\item $\\overline h^\\mathbf A(\\phi^*(b_1),\\dots,\\phi^*(b_n))=\n%\\overline h^\\mathbf A(\\overline{f^m_{b_1}}^\\mathbf A(\\mathbf d),\\dots,\\overline{f^m_{b_n}}^\\mathbf A(\\mathbf d))$;\n%\\item $\\phi^*(\\overline h^{\\mathbf C_\\tau}(\\mathbf b))= \\phi^*(h(\\mathbf b))\n%=\\phi^*(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b))= \\overline{f^m_r}^\\mathbf A(\\mathbf d)$, where $r= q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$.\n%\n%\\end{itemize}\n%\n%We get that $\\phi^*$ is a homomorphism if  the algebra $\\mathbf A$ satisfies the identity \n%$$\\overline h(\\overline{f^m_{b_1}} (x_1,\\dots,x_m),\\dots,\\overline{f^m_{b_n}} (x_1,\\dots,x_m))=\n%\\overline{f^m_r}(x_1,\\dots,x_m),$$\n%where $r= q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$.\n%Since $\\mathbf A\\in \\mathcal V(\\mathbf C_\\tau)$, then it is sufficient to prove that $\\mathbf C_\\tau$ satisfies the above identity.  This follows from Lemma \\ref{12}(ii), because\n%$$\\overline{f^m_r}^{\\mathbf{C}_\\tau}(x_1,\\dots,x_m)=q_m^\\mathbf C(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b),x_1,\\dots,x_m)= q_m^\\mathbf C(h(\\mathbf b),x_1,\\dots,x_m)$$ and\n%$$\\overline h^{\\mathbf C_\\tau}(\\overline{f^m_{b_1}}^{\\mathbf C_\\tau} (x_1,\\dots,x_m),\\dots,\\overline{f^m_{b_n}}^{\\mathbf C_\\tau} (x_1,\\dots,x_m))=$$\n%$$\\qquad\\qquad\\qquad h(q_m^\\mathbf C(b_1,x_1,\\dots,x_m),\\dots,q_m^\\mathbf C(b_n,x_1,\\dots,x_m)).$$\n%%We now show that $\\bar h^\\mathbf C(\\overline{f^m_{b_1}}^\\mathbf C\n%%(\\bar o),\\dots,\\overline{f^m_{b_n}}^\\mathbf C(\\bar o))=\\overline{f^m_d}^\\mathbf C(\\bar o)$ for almost all $m$.\n%%\n%%$h(f^m_{b_1}(\\bar o),\\dots,f^m_{b_n}(\\bar o))=h(q_m(b_1,\\bar o),\\dots, q_m(b_n,\\bar o))\n%%=q_m(q_n(h(\\bar\\e),\\bar b),\\bar o)$. By .\n%\\end{proof}\n\nRecalling  that every finite dimensional $\\mathsf{CA}$ is isomorphic to a block algebra (see Theorem \\ref{thm:fica}), in this corollary we relate lattices of equational theories and clones. \n\n\\begin{corollary}\n  A lattice $L$ is isomorphic to a lattice of equational theories if and only if $L$ is isomorphic to the lattice of all congruences of a block algebra. \n\\end{corollary}\n\nWe conclude this section by characterising the lattices of subclones.\n\nLet $A$ be a set and $F$ be a clone on $A$. A subset $G\\subseteq F$ is called a \\emph{subclone} of $F$ if $G$ is a clone on $A$. For example, every clone on $A$ is a subclone of $\\mathcal O_A$.\n\nWe denote by $\\mathrm{Sb}(F)$ the lattice of all subclones of a clone $F$. We say that a lattice $L$ is  isomorphic to a lattice of subclones if there exists a set $A$ and a clone $F$ on $A$ such that $L$ is isomorphic to the lattice $\\mathrm{Sb}(F)$.\n\n\\begin{proposition}\n   A lattice $L$ is isomorphic to a lattice of subclones if and only if $L$ is isomorphic to the lattice of subalgebras of a block algebra. \n\\end{proposition}\n\n\\begin{proof}\n By Proposition \\ref{prop:cloneblock} and Corollary \\ref{cor:cloneblock}.\n\\end{proof}\n\n\n\n\n\n%\\subsection{Centralisers in clone algebras}\n%\n%If $m=(m_{ij})\\in A^{\\omega\\times\\omega}$ then we denote by \n%$m_i\\in A^\\omega$ the sequence defined by $m_i(k)=m_{ik}$\n%and by  $m^j\\in A^\\omega$ the sequence defined by $m^j(k)=m_{kj}$.\n%\n%\\begin{definition}\\label{def:com} Let $f,g:A^\\omega \\to A$ be infinitary maps. We define the \\emph{commutator} $[f,g]:A^{\\omega\\times\\omega}\\to A$ of $f$ and $g$ as follows, for all $m=(m_{ij})\\in A^{\\omega\\times\\omega}$:\n% $$[f,g](m)= f\\langle g(m_i) : i\\in \\omega\\rangle.$$\n% We say that $f$ and $g$ \\emph{commute}, and we write $f\\bot g$, if  \n% $$[f,g]=[g,f].$$\n%\\end{definition}\n%\n%%\\begin{definition}\\label{def:com}\n%%Let $\\mathbf F$ be a $\\mathsf{FCA}$ with value domain $A$.\n%%We say that $f,g\\in F$ \\emph{commute}, and we write $f\\bot g$, if, for every $m\\in A^{\\omega\\times\\omega}$, \n%%$$f\\langle g(m_i) : i\\in \\omega\\rangle =g\\langle f(m^i): i\\in \\omega\\rangle.$$\n%%\\end{definition}\n%\n%\\begin{lemma} Let $\\mathbf F$ be a $\\mathsf{FCA}$ with value domain $A$ and let $f\\in F$.\n%The set $f^*=\\{ g\\in F: f\\bot g\\}$ is a subalgebra of the pure reduct of $\\mathbf F$.\n%\\end{lemma}\n%\n%\\begin{proof} Let $g,h_1,\\dots,h_k\\in f^*$, $t=q_k^\\mathbf F(g,h_1,\\dots,h_k)$ and $m\\in A^{\\omega\\times\\omega}$.\n%Then by definition of $q_k^\\mathbf F$ we derive:\n% $$t(m_i)=  g(m_i[h_1(m_i),\\dots,h_k(m_i)]).$$\n%%Let $\\mu_n=m_n[h_1(m_n),\\dots,h_k(m_n)]$. \n%We now prove that $t\\in f^*$:\n%\\[\n%\\begin{array}{lll}\n%  &   & f\\langle t(m_i) : i\\in \\omega\\rangle  \\\\\n%  &   & f\\langle g(m_i[h_1(m_i),\\dots,h_k(m_i)]) : i\\in \\omega\\rangle  \\\\  \n%  &  = & f(g(m_1[h_1(m_1),\\dots,h_k(m_1)]),\\dots,g(m_n[h_1(m_n),\\dots,h_k(m_n)]),\\dots)  \\\\\n%  & =  &   g(f\\langle h_1(m_i): i\\in \\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in \\omega\\rangle,f(m^{k+1}),\\dots,f(m^{n}),\\dots)\n%\\end{array}\n%\\]\n%\n%\n% Let $s=\\langle f(m^i): i\\in\\omega\\rangle\\in A^\\omega$. Then by hypothesis and Definition \\ref{def:com} we have:\n% $$h_j(s)= h_j\\langle f(m^i): i\\in\\omega\\rangle= f\\langle h_j(m_i): i\\in\\omega\\rangle$$\n% We conclude as follows:\n%\\[\n%\\begin{array}{lll}\n%  &   &t\\langle f(m^i): i\\in \\omega\\rangle\\\\\n%  &=&g(\\langle  f(m^i): i\\in \\omega\\rangle[h_1(s),\\dots,h_k(s)])\\\\\n%  &=& g(\\langle  f(m^i): i\\in \\omega\\rangle[f\\langle h_1(m_i): i\\in\\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in\\omega\\rangle])\\\\\n%  &=& g(f\\langle h_1(m_i): i\\in \\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in \\omega\\rangle,f(m^{k+1}),\\dots,f(m^{n}),\\dots)\n%\\end{array}\n%\\]\n%\\end{proof}\n%\n%For any $X\\subseteq F$, we write $X^*$ for $\\bigcap_{f\\in X} f^*$.   The set $X^*$ is called the \\emph{centraliser} of $X$ and it is a subalgebra of $\\mathbf F$.\n%\n%\n%\\begin{definition}\n%  Two elements $a,b$ of a clone algebra $\\mathbf C$ \\emph{commute} if, for every $n\\geq \\gamma(a)$ and $k\\geq \\gamma(b)$, we have\n%$$q_n(a,q_k(b,x_{11},\\dots,x_{1k}),\\dots,q_k(b,x_{n1},\\dots,x_{nk}))=\n%q_k(b,q_n(a,x_{11},\\dots,x_{n1}),\\dots,q_n(a,x_{1k},\\dots,x_{nk})).$$\n%\\end{definition}\n%\n%%$f(s[g(s[a_{11},\\dots,a_{1k}]),\\dots,g(s[a_{n1},\\dots,a_{nk}])]=g()$\n%\n%We write  $a\\bot b$ for $a$ and $b$ commute.\n%\n%\\begin{lemma}\n%  For any $F\\subseteq \\mathcal{O}_A$ , the centralizer $F^{*}$ of $F$ is a clone.\n%\\end{lemma}\n%\n%\\begin{proof}\n% $F^*$ is the clone of all homomorphisms from the algebra $(A,F)^n$ into $(A,F)$ ($n\\geq 0$).\n%\\end{proof}\n%\n%%$F^*$ is the clone of all homomorphisms of the algebra $(A,F)$.\n%\n%The following properties of centralizers are easy but important. \n%\n%\\begin{lemma}\n%  For any $F,G\\subseteq \\mathcal O_A$ we have:\n%\\begin{enumerate}\n%\\item[(i)] $F\\subseteq F^{**}$;\n%\\item[(ii)] $F\\subseteq G\\Longrightarrow F^*\\supseteq G^*$;\n%\\item[(iii)]  $F^*=F^{***}$.\n%\\end{enumerate}\n%\\end{lemma} \n%\n\n%\\subsection{Central elements in block algebras and decomposition operators}\n%\n%\\begin{lemma}\n%Let $\\mathbf A$ be an algebra  and $f$ be  a  decomposition operator on \n%$\\mathbf  A$. Then\n%$\\langle f\\rangle$ contains only decomposition operators.\n%\\end{lemma}\n%\n%[the proof of this lemma can be deleted] \n%%\\begin{proof}\n%%Let  $g\\in\\langle f\\rangle$, $n$ and $k$ being the arities of $g$ and $f$,\n%%respectively.\n%%\n%%It is clear that $g(\\underbrace{x,\\ldots,x}_{n})=f(\\underbrace{x,\\ldots, x}_{k})=x$.\n%%For the two remaining axioms of decomposition operators, we reason by cases analysis.\n%%Let $\\sigma$ be a basic operation of arity $l$ in the type of $\\mathbf A$, and\n%%let us suppose first that  $f\\preceq g$ (i.e. that $k\\leq n$).\n%%\\begin{itemize}\n%%\\item \n%%\\begin{tabular}{l}\n%%$g(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_n^1,\\ldots,x_n^n))=f(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_k^1,\\ldots,x_k^n))=$\\\\\n%%$f(f(x_1^1,\\ldots,x_1^k),\\ldots,f(x_k^1,\\ldots,x_k^k))=f(x_1^1,\\ldots,x_k^k)=g(x_1^1,\\ldots,x_n^n)$\n%%\\end{tabular}\n%%\\item \n%%\\begin{tabular}{l}\n%%$g(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l))=f(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_k^1,\\ldots,x_k^l))=$\\\\\n%%$\\sigma(f(x_1^1,\\ldots,x_k^1),\\ldots,f(x_l^1,\\ldots,x_l^k))=\\sigma(g(x_1^1,\\ldots,x_n^1),\\ldots,g(x_1^l,\\ldots,x_n^l))$\n%%\\end{tabular}\n%%\n%%If  $g\\preceq f$ (i.e. $k\\geq n$) we get similarly:\n%%\n%%\\item \n%%\\begin{tabular}{l}\n%%$g(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_n^1,\\ldots,x_n^n))=f(f(x_1^1,\\ldots,x_1^n, \\ldots),\\ldots,f(x_n^1,\\ldots,x_n^n,\\ldots),\\ldots)=$\\\\\n%%$f(x_1^1,\\ldots,x_n^n,\\ldots)=g(x_1^1,\\ldots,x_n^n)$\n%%\\end{tabular}\n%%\\item \n%%\\begin{tabular}{l}\n%%$g(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l))=f(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l),\\ldots)=$\\\\\n%%$\\sigma(f(x_1^1,\\ldots,x_n^1,\\ldots),\\ldots,f(x_l^1,\\ldots,x_l^n,\\ldots))=\\sigma(g(x_1^1,\\ldots,x_n^1),\\ldots,g(x_1^l,\\ldots,x_n^l))$\n%%\\end{tabular}\n%%\\end{itemize}\n%%\\end{proof}\n%\n%\\begin{definition}\n% A decomposition operator $f$ is {\\em proper} if it is the generator\n%of $\\langle f\\rangle$.\n%\\end{definition}\n%\n%\n%\n%\n%\n%\n%Let $\\mathbf A$ be a $\\tau$-algebra and $\\mathcal B_\\mathbf A^\\top$ be the full block algebra on $\\mathbf A$. \n%\n%\n%%We know by Lemma \\ref{} that the set of the strongly finite elements of \n%%$A^\\top$ is a subalgebra of ${\\mathbf A}^\\top$.\n%%As a matter of terminology, let us call {\\em full and finite functional clone algebra  with value domain $\\mathbf A$}, written\n%%FFCA$\\mathbf A$, the algebra $(\\mathrm{Sf} A^\\top,\\sigma^\\top, q_n^\\top,e_i^\\top)_{n\\geq 0,i\\geq 1}$, and  {\\em finite functional clone algebra  with value domain $\\mathbf A$}, written\n%%FCA$\\mathbf A$ any subalgebra of FFCA$\\mathbf A$.\n%%Given $f \\in\\mathrm{Sf} A^\\top$, its {\\em arity} $ar(f)$ is the smallest \n%%$n\\in\\mathrm N$ such that there exists $g\\in \\mathcal O^{(n)}$ \n%%with $g^\\top=f$. The {\\em seed} of $f$, noted $f_\\bot$,  is the function $g\\in\\mathcal O^{ar(f)}$\n%%such that $g^\\top=f$. It is easy to see that $f_\\bot$ is a generator, \n%%for all $f$ in $\\mathrm{Sf} A^\\top$.\n%\n%%\\begin{fact}\n%%Let $\\mathbf F$ be a $\\mathsf{FCA}$ with value domain $\\mathbf A$.\n%%For all $n\\geq 2$, $\\mathbf{F}$ is a $n$-Church algebra\n%%by posing $q= q_n^\\omega$ and $\\e_i=e_i^\\omega$, for $1\\leq i\\leq n$.\n%%\\end{fact}\n%\n%%Indeed, for all $g_1,\\ldots,g_n\\in F$, $1\\leq i \\leq n$ and $\\rho\\in A^\\omega$:\n%% \n%%$$(q_n^\\top(e_i^\\top,g_1,\\ldots,g_n))(\\rho)=e_i^\\top(\\rho[g_1(\\rho),\\ldots,g_n(\\rho)]=g_i(\\rho)$$\n%\n%\n%%An element of  a  polynomial   $\\mathcal{G}$-clone on $\\mathbf A$ %of a Church algebra of dimension $\\omega$ $\\mathbf A$ \n%%is $n$-central if it is central for $q_n^{\\mathcal{G}}$, $p_1,\\ldots,p_n$;\n%%it is {\\em central} if it is $n$-central \n%%in $(A,q_n,e_1,\\ldots,e_n)$ \n%%for some $n$.\n%\n%The rest of this section is devoted to prove that the central elements of an\n%$\\mathsf{FCA}$ $\\mathbf F$ with value domain $\\mathbf A$  correspond to suitable decomposition operators on $\\mathbf A$.\n%%The first observation is that if $f\\in F$ is $k$-central, than $k\\geq ar(f)$.\n%\n%\n%%\\begin{proposition}\n%%Let $\\mathbf F$ be a FCA$\\mathbf A$, \n%%$f\\in\\mathbf F$ be such that \n%%$f_\\bot$ has arity $n$, and $k<n$. Then $f$ is not $k$-central.\n%%\\end{proposition}\n%%\\begin{proof}\n%%Let $a_{1}, \\ldots, a_{n-1},b,c\\in A$ be such that \n%%$f_\\bot(a_1,\\ldots, a_{n-1},b)\\neq f_\\bot(a_1,\\ldots, a_{n-1},c)$.\n%%If $f$ is $k$-central, then the equation\n%%\\[\\begin{array}{lllr}\n%%&& q^\\top_k(f,q^\\top_n(g_1,h_1^1,\\ldots,h_n^1),\\ldots, q^\\top_n(g_k,h_1^k,\\ldots,h_n^k)) &\\\\\n%%&=& q^\\top_n(q^\\top_k(f,g_1,\\ldots,g_k),q^\\top_k(f,h_1^1,\\ldots,h_1^k),\\ldots,q^\\top_k(f,h_n^1,\\ldots,h_n^k))&\\\\\n%%\\end{array}\n%%\\]\n%%%$$q^\\top_k(f,q^\\top_n(g_1,h_1^1,\\ldots,h_n^1),\\ldots, q^\\top_n(g_k,h_1^k,\\ldots,h_n^k)=q^\\top_n(q^\\top_k(f,g_1,\\ldots,g_k),q^\\top_k(f,h_1^1,\\ldots,h_1^k),\\ldots,q^\\top_k(f,h_n^1,\\ldots,h_n^k))$$\n%%holds for all $g_1,\\ldots,g_k,h_1^1,\\ldots h_n^k$ in $F$.\n%%By letting $g_i=e_i^\\top$ for $1\\leq i\\leq k$ , $h_i^j=a_i^\\top$ for $1\\leq i\\leq n-1$ and $1\\leq j\\leq k$, \n%%and $h_n^j=b^\\top$ for $1\\leq j\\leq k$ in the equation above, and by exploiting again the fact that $f$ is $k$-central, we get:\n%%$$q^\\top_k(f,a_1^\\top,\\ldots,a_k^\\top)=\n%%%q^\\top_n(f,q^\\top_k(f,a_1^\\top,\\ldots,a_1^\\top),\\ldots,q^\\top_k(f,a_{n-1}^\\top,\\ldots,a_{n-1}^\\top), , q^\\top_k(f,b^\\top,\\ldots,b^\\top))\n%%q^\\top_n(f,a_1^\\top,\\ldots,a_{n-1}^\\top,b^\\top)$$\n%%\n%%Now, let $\\rho\\in A^\\omega$ be such that $\\rho_{k+1}=a_{k+1},\\ldots,\\rho_{n-1}=a_{n-1},\\rho_n=c$. \n%%We get\n%%\n%%$$f_\\bot(a_1,\\ldots, a_{n-1},c)=q^\\top_k(f,a_1^\\top,\\ldots,a_k^\\top)(\\rho)=q^\\top_n(f,a_1^\\top,\\ldots,a_{n-1}^\\top,b^\\top)(\\rho)=\n%%f_\\bot(a_1,\\ldots, a_{n-1},b)$$\n%%\n%%a contradiction.\n%%\\end{proof}\n%%\n%\n%\n%\\begin{theorem}\n% Let $\\mathbf F$ be a FCA$\\mathbf A$, and let \n%$f\\in F$ be of finite dimension $n$. Then $f$ is $n$-central in $\\mathbf F$ iff $f_\\bot$ is an\n%$n$-ary decomposition operator on $\\mathbf A$, commuting with $g_\\bot$,\n%for all $g\\in F$.\n%\\end{theorem}\n%\\begin{proof}\n%($\\Rightarrow$) \n%We suppose that $f$ is $n$-central in $\\mathbf F$, and prove that $f_\\bot$ is a \n%decompostion operator on $\\mathbf A$, commuting with $g_\\bot$ for all $g\\in F$.\n%\n%Given $a\\in A$, let $\\rho\\in A^\\omega$ be such that $\\rho_1=a$:\n%$$f_\\bot(a,\\ldots,a)=f(\\rho[e_1^\\top(\\rho),\\ldots,e_1^\\top(\\rho)])=q^\\top_n(f,e_1^\\top,\\ldots,\n%e_1^\\top)(\\rho)=e_1^\\top(\\rho)=\\rho_1=a $$\n%\n%Given $a_{i,j}\\in A$ for  $1\\leq i,j\\leq n$, let  $\\rho\\in A^\\omega$ be such that\n%$\\rho_{\\langle i,j\\rangle}=a_{i,j}$, for  $1\\leq i,j\\leq n$, where $\\langle i,j\\rangle=\n%(i-1)\\times n+j$:\n%\n%%$$f_\\bot(f_\\bot(a^1_1,\\ldots,a^1_n),\\ldots,f_\\bot(a^n_1,\\ldots,a^n_n))=f(\\rho[f_\\bot(a^1_1,\\ldots,a^1_n),\\ldots,f_\\bot(a^n_1,\\ldots,a^n_n)])=$$\n%%$$f(\\rho [f(\\rho[a^1_1     ]) $$\n%\n%\\[\\begin{array}{lllr}\n%&& f_\\bot(f_\\bot(a_{1,1},\\ldots,a_{1,n}),\\ldots,f_\\bot(a_{n,1},\\ldots,a_{n,n}))&\\\\\n%&=& f(\\rho[f_\\bot(a_{1,1},\\ldots,a_{1,n}),\\ldots,f_\\bot(a_{n,1},\\ldots,a_{n,n})]) &\\\\\n%&=& f(\\rho[f(\\rho[a_{1,1},\\ldots,a_{1,n}]),\\ldots,f(\\rho[a_{n,1},\\ldots,a_{n,n}])]) &\\\\\n%&=&q^\\top_n(f,q^\\top_n(f,e^\\top_{\\langle 1,1\\rangle },\\ldots,e^\\top_{\\langle 1,n\\rangle}),\\ldots,q^\\top_n(f,e^\\top_{\\langle n,1\\rangle},\\ldots,e^\\top_{\\langle n,n\\rangle }))(\\rho)&\\\\\n%&=& q^\\top_n(f,e^\\top_{\\langle 1,1\\rangle},\\ldots,e^\\top_{\\langle n,n\\rangle })(\\rho)&\\\\\n%&=& f(\\rho[a_{1,1},\\ldots,a_{n,n}])  &\\\\\n%&=& f_\\bot(a_{1,1},\\ldots,a_{n,n})&\\\\\n%\\end{array}\n%\\]\n%\n%\n%Given $\\sigma$ in the signature of $\\mathbf A$ of arity $k$ and \n%$a_{i,j}\\in A$ for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, \n% let  $\\rho\\in A^\\omega$  be such that\n%$\\rho_{\\langle i,j\\rangle}=a_{i,j}$,  for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, where $\\langle i,j\\rangle=\n%(i-1)\\times k+j$:\n%\n%\n%\\[\\begin{array}{lllr}\n%&& f_\\bot(\\sigma(a_{1,1},\\ldots,a_{1,k}),\\ldots,\\sigma(a_{n,1},\\ldots,a_{n,k})) &\\\\\n%&=& f(\\rho[\\sigma(a_{1,1},\\ldots,a_{1,k}),\\ldots,\\sigma(a_{n,1},\\ldots,a_{n,k})]) &\\\\\n%&=& q^\\top_n(f,\\sigma^\\top(e^\\top_{\\langle 1,1\\rangle},\\ldots,a^\\top_{\\langle 1,k\\rangle}),\\ldots,\n%\\sigma^\\top(e^\\top_{\\langle n,1\\rangle},\\ldots,e^\\top_{\\langle n,k\\rangle}))(\\rho)\\\\\n%&= & \\sigma^\\top(q^\\top_n(f,e_{\\langle 1,1\\rangle}^\\top,\\ldots,e_{\\langle n,1\\rangle}^\\top),\\ldots\n%q^\\top_n(f,e_{\\langle 1,k\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle }^\\top))(\\rho)\\\\\n%&=& \\sigma(f_\\bot(a_{1,1},\\ldots,a_{n,1}),\\ldots,\n%f_\\bot(a_{1,k},\\ldots,a_{n,k}))&\\\\\n%\\end{array}\n%\\]\n%\n%\n%Given $g\\in F$ be such that $g_\\bot$ is $k$-ary, $a_{i,j}\\in A$ for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, let  $\\rho\\in A^\\omega$  be such that\n%$\\rho_{\\langle i,j\\rangle}=a_{i,j}$,  for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, where $\\langle i,j\\rangle=\n%(i-1)\\times k +j$:\n% \n%\n%\\[\\begin{array}{lllr}\n%&& f_\\bot(g_\\bot(a_{1,1},\\ldots,a_{1,k}),\\ldots,\n%(g_\\bot(a_{n,1},\\ldots,a_{n,k})) &\\\\\n%&=& q^\\top_n(f, q^\\top_k(g,e_{\\langle 1,1\\rangle}^\\top,\\ldots,e_{\\langle 1,k\\rangle}^\\top),\\ldots,\n% q^\\top_k(g,e_{\\langle n,1\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle}^\\top))(\\rho) &\\\\\n%&=&q^\\top_k(g, q^\\top_n(f,e_{\\langle 1,1\\rangle }^\\top,\\ldots,e_{\\langle n,1\\rangle}^\\top),\\ldots,\n% q^\\top_n(f,e_{\\langle 1,k\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle}^\\top))(\\rho)  &\\\\\n%&=&  g_\\bot(f_\\bot(a_{1,1},\\ldots,a_{n,1}),\\ldots,\n%(f_\\bot(a_{1,k},\\ldots,a_{n,k})) &\\\\\n%\\end{array}\n%\\]\n%\n%\n%($\\Leftarrow$) We suppose that $f_\\bot$ is a decomposition operator on $\\mathbf A$\n%commuting with $g_\\bot$ for all $g\\in F$. and prove that $f$ is\n% $n$-central in $\\mathbf F$. The first axiom of centrality, namely\n%$q_n^\\top(f,e^\\top_1,\\ldots,e^\\top_n)=f$, holds a priori.\n%\n%Given $g\\in F$ and $\\rho\\in A^\\omega$:\n%\n%\\[\\begin{array}{lllr}\n%&&q^\\top_n(f,g,\\ldots,g)(\\rho)  &\\\\\n%&=&f(\\rho[g(\\rho),\\ldots,g(\\rho)]) &\\\\\n%&=& f_\\bot(g(\\rho),\\ldots,g(\\rho)) &\\\\\n%&=& g(\\rho) &\\\\\n%\\end{array}\n%\\]\n%\n%It remains to prove that, for all $k$-ary\n%operation $\\delta$ in the type of $\\mathbf F$ and for all\n%elements  $g^{i,j}\\in F$ for $1\\leq i\\leq n$, $1\\leq j\\leq k$,  \n% $f$ satisfies the equation \n%$$q^\\top_n(f,\\delta(g^{1,1},\\ldots,g^{1,k}),\\ldots,\\delta(g^{n,1},\n%\\ldots,g^{n,k})=\\delta(q^\\top_n(f,g^{1,1},\\ldots,g^{n,1}),\\ldots,\n%q^\\top_n(f,g^{1,k},\\ldots,g^{n,k}))$$\n%\n%Let $\\rho\\in A^\\omega$, and let us distinguish the case $\\delta=\\sigma^\\top$,\n%for some $\\sigma$ in the type of $\\mathbf A$, and $\\delta=q^\\top_{k-1}$.\n%\n%\n%\\[\\begin{array}{lllr}\n%&&q^\\top_n(f,\\sigma^\\top(g^{1,1},\\ldots,g^{1,k}),\\ldots,\\sigma^\\top(g^{n,1},\n%\\ldots,g^{n,k}))(\\rho)\\\\\n%&=& f_\\bot(\\sigma^\\top(g^{1,1},\\ldots,g^{1,k})(\\rho),\\ldots, \\sigma^\\top(g^{n,1},\\ldots,g^{n,k})(\\rho)) &\\\\\n%&=& f_\\bot(\\sigma^\\mathbf A(g^{1,1}(\\rho),\\ldots,g^{1,k}(\\rho)),\\ldots\n%\\sigma^\\mathbf A(g^{n,1}(\\rho),\\ldots,g^{n,k}(\\rho))) &  \\\\\n%&=& \\sigma^\\mathbf A(f_\\bot(g^{1,1}(\\rho),\\ldots,g^{n,1}(\\rho)),\\ldots\n%f_\\bot(g^{1,k}(\\rho),\\ldots,g^{n,k}(\\rho))) &\\\\\n%&=&  \\sigma^\\top(f(g^{1,1},\\ldots,g^{n,1}),\\ldots\n%f(g^{1,k},\\ldots,g^{n,k}))(\\rho)&\\\\\n%\\end{array}\n%\\]\n%\n%\n%The case  $\\delta=q^\\top_{k-1}$ is the most involved one.\n%Let $l$ be the maximum of the arities of $g^{1,1}_\\bot,\\ldots,g^{n,1}_\\bot$ and\n%let $\\hat g ^{i,1}_\\bot$ be the $l$-ary function in the block of \n%$ g ^{i,1}_\\bot$ for $1\\leq i\\leq n$. Remark that $(\\hat g^{i,1}_\\bot)^\\top=g^{i,1}$, \n%for $1\\leq i\\leq n$.\n%It is easy to see that if $f_\\bot$ commutes with  $g_\\bot$, then it also commutes\n%with any other element in the block of  $g_\\bot$.\n%%The equations below derive mostly  the  definition of $q_n^\\top$,\n%%$q_k^\\top$ and by the definition of seed  of a strongly finite function. \n%The fourth equation derives from  the second item of the definition of \n%decomposition operator and the fifth one from the fact that $f_\\bot$ commutes \n%with $g_\\bot$ for all $g\\in \\mathbf F$. \n%\n%The others simply use the definition of \n%$q_n^\\top$, $q_{k-1}^\\top$ and of seed  of a strongly finite function. \n%\n%\n%\n%\n%\\[\\begin{array}{lllr}\n%&&q^\\top_n(f,q^\\top_{k-1}(g^{1,1},\\ldots,g^{1,k}),\\ldots,q^\\top_{k-1}(g^{n,1},\n%\\ldots,g^{n,k}))(\\rho)\\\\\n%\n%&=&f(\\rho[g^{1,1}(\\rho[g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho)]),\\dots,g^{n,1}(\\rho[g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho)])])&\\\\\n%\n%&=&f_\\bot(g^{1,1}(\\rho[g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho)]),\\dots,g^{n,1}(\\rho[g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho)])&\\\\\n%\n%&=&f_\\bot(\\hat g_\\bot^{1,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{n,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l ))&\\\\\n%\n%&=&f_\\bot( f_\\bot(\\hat g_\\bot^{1,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{1,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho), \\rho_{k+1},\\ldots,\\rho_l)),\\dots\\\\\n%&& \\ \\ \\ \\ \\ f_\\bot(\\hat g_\\bot^{n,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{n,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l))) &\\\\\n%\n%&=&f_\\bot(\\hat g_\\bot^{1,1}(f_\\bot(g^{1,2}(\\rho),\\dots,g^{n,2}(\\rho)),\\dots,f_\\bot(g^{1,k}(\\rho),\\dots,g^{n,k}(\\rho)),\\rho_{k+1},\\ldots,\\rho_l)\\dots,\\\\\n%&&  \\ \\ \\ \\ \\ \\hat g_\\bot^{n,1}(f_\\bot(g^{1,2}(\\rho),\\dots,g^{n,2}(\\rho)),\\dots,f_\\bot(g^{1,k}(\\rho),\\dots,g^{n,k}(\\rho)),\\rho_{k+1},\\ldots,\\rho_l))\\\\\n%\n%&=& f_\\bot(g^{1,1}(\\rho'),\\ldots,g^{n,1}(\\rho'))\\mbox{ where }  \n%\\rho'=\\rho[f_\\bot(g^{1,2}(\\rho),\\ldots,g^{n,2}(\\rho)),\\ldots,  \n%f_\\bot(g^{1,k}(\\rho),\\ldots,g^{n,k}(\\rho))]                                       &\\\\\n%\n%\n%&=& f(\\rho'[g^{1,1}(\\rho'),\\ldots,g^{n,1}(\\rho')])&\\\\\n%\n%\n%&=& q_n^\\top(f,g^{1,1},\\ldots,g^{n,1})(\\rho')&\\\\\n%\n%\n%&=& q_n^\\top(f,g^{1,1},\\ldots,g^{n,1})(\\rho[q_n^\\top(f,g^{1,2},\\ldots,g^{n,2})(\\rho),\n%\\ldots,q_n^\\top(f,g^{1,k},\\ldots,g^{n,k})(\\rho)])&\\\\\n%\n%\n%&=& q_{k-1}^\\top(q_n^\\top(f,g^{1,1},\\ldots,g^{n,1}),q_n^\\top(f,g^{1,2},\\ldots,g^{n,2}),\\ldots,q_n^\\top(f,g^{1,k},\\ldots,g^{n,k})) (\\rho)&\\\\\n%\n%\\end{array}\n%\\]\n%\n%\n%\n%\n%\\end{proof}\n%\n%The decomposition operator $f_\\bot$ of the Theorem above is \n%proper, since  $f_\\bot$ is a generator. \n%\n%\n%\n%%Let $\\mathrm{V}=\\{x_1,x_2,\\dots\\}$ be a countable infinite set of variables disjoint from the set $I=\\{v_1,\\dots,v_n,\\dots\\}$.\n%%A \\emph{clone $\\tau$-term} is a term in the similarity type of clone $\\tau$-algebras with variables in $\\mathrm{V}$. \n%%A clone  $\\tau$-term is \\emph{ground} if has no occurrences of variables in $\\mathrm{V}$. \n%%\n%%\n%%\\subsection{The  head normal form of a term}\n%%\\label{sec:rewriting1}\n%%In this section we show how  to turn the equations axiomatising $\\mathsf{CA}$ into rewriting rules. \n%%\n%%\\begin{definition} A clone $\\tau$-term\n%% is called a \\emph{head normal form} (hnf, for short) if it is defined by induction as follows:\n%% \\begin{itemize}\n%%\\item $\\e_i$ is a hnf for every $i$;\n%%\\item $x$ is a hnf for every $x\\in \\mathrm{V}$;\n%%\\item If $t_1,\\dots, t_k$ are hnfs, then $\\sigma(t_1,\\dots, t_k)$ is a hnf for every $\\sigma\\in\\tau$ of arity $k$;\n%%\\item  If $x\\in \\mathrm{V}$, $t_1,\\dots, t_n$ are hnfs and there is an $i$ such that $t_i\\neq \\e_i$, then $q_n(x,t_1,\\dots, t_n)$ is a hnf.\n%%\\end{itemize}\n%% The occurrence of the variable $x$ in the hnf $t::= q(x, t_1,\\dots, t_n)$ is called \\emph{head occurrence of $x$ into $t$}.\n%%\\end{definition}\n%%\n%%\\begin{lemma}\\label{lem:hnf} The following conditions are equivalent for a clone term $t$:\n%%\\begin{enumerate}\n%%\\item $t$ is a ground hnf;\n%%\\item $t$ is defined according to the following grammar: \n%%$$t, t_i ::= \\e_i\\ |\\  \\sigma(t_1,\\dots, t_k).$$ \n%%\\end{enumerate}\n%%\\end{lemma}\n%%\n%%We define an algebra $\\mathbf{H}$, having the set of hnfs as universe. The operations $q_n^\\mathbf H$ and $\\sigma^\\mathbf H$ are defined by induction over the complexity of its first hnf argument. \n%%\n%%For all hnfs $\\bar \\psi=\\psi_1,\\dots,\\psi_n$ and $x\\in \\mathrm{V}$:\n%%\\[\n%%\\begin{array}{rl}\n%%&  q_n^{\\mathbf H}(\\e_i,\\bar\\psi)=\\psi_i\\quad (i\\leq n) \\\\\n%%&  q_n^{\\mathbf H}(\\e_j,\\bar\\psi)=\\e_j\\quad (j> n) \\\\\n%%&   q_n^{\\mathbf H}(x,\\bar\\psi)=\\begin{cases}x&\\text{if $\\psi_i=\\e_i$ for every $i=1,\\dots,n$}\\\\ \n%%q_n(x,\\bar\\psi)&\\text{otherwise}\\end{cases}\\\\\n%%&   q_n^{\\mathbf  H}(q_k(x,u_1,\\dots,u_k),\\bar\\psi )=q_k(x,q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi))\\quad (k\\geq n)\\\\\n%%&   q_n^{\\mathbf  H}(q_k(x,u_1,\\dots,u_k),\\bar\\psi )=q_n(x,q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi),\\psi_{k+1},\\dots,\\psi_n)\\quad (k < n)\\\\\n%%& q_n^{\\mathbf  H}(\\sigma(u_1,\\dots,u_k),\\bar\\psi )=\\sigma(q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi))\\\\\n%%&   \\sigma^{\\mathbf H}(\\bar\\psi)=\\sigma(\\bar\\psi) \\\\\n%%\\end{array}\n%%\\]\n%%A routine calculation shows the following result.\n%%\n%%\\begin{proposition}\n%% $\\mathbf{H}$ is the free clone $\\tau$-algebra over a countable set $\\mathrm{V}$ of generators. \n%%\\end{proposition}\n%%\n%%\\begin{proof}\n%% Let $\\mathbf C$ be a clone $\\tau$-algebra and $f: \\mathrm{V}\\to C$ be a map. We extend $f$ to $f^*: H\\to C$ by induction as follows: $f^*(\\e_i)=\\e_i^\\mathbf C$; $f^*(\\sigma(\\bar\\psi))= \\sigma^\\mathbf C(f^*(\\psi_1),\\dots,f^*(\\psi_n))$;\n%% $f^*(q_k(x,u_1,\\dots,u_k))= q_k^\\mathbf C(f(x),f^*(u_1),\\dots,f^*(u_k))$.\n%%\\end{proof}\n%%\n%%\n%%\n%%\n%%We denote by $\\mathrm{hnf}(t)$ the head normal form of a clone term $t$.\n%%\n%%\\begin{proposition}\\label{prop:hnf} Let $\\mathbf C$ be a clone $\\tau$-algebra. Then the following conditions hold:\n%%\\begin{itemize}\n%%\\item[(i)] $\\mathbf C\\models t=\\mathrm{hnf}(t)$;\n%%\\item[(ii)] If  $\\mathrm{hnf}(t)=\\mathrm{hnf}(u)$ (syntactically), then $\\mathbf C\\models t=u$;\n%%\\item[(iii)] $\\mathbf C\\models t=u\\ \\text{iff}\\ \\mathbf C\\models \\mathrm{hnf}(t)=\\mathrm{hnf}(u)$.\n%%\\end{itemize}\n%%\\end{proposition}\n%%\n%%\n%%The interpretation $t^\\mathbf C\\in C$ of a ground clone term $t$ in a clone algebra $\\mathbf C$ is trivially defined.\n%%\n\n\\section{The category of  varieties}\\label{sec:allvar}\nImportant properties of a variety $\\mathcal V$ depend on the pure reduct of the clone $\\mathcal V$-algebra $\\mathbf{Cl}(\\mathcal V)$ associated to its free algebra. In this section,\nafter characterising central elements in clone algebras, we introduce the concept of a minimal clone algebra.  We show that a clone  $\\tau$-algebra $\\mathbf C$ is minimal if and only if the $\\tau$-reduct $\\mathbf C_\\tau$ of $\\mathbf C$  is the free algebra over a countable set of generators in the variety generated by $\\mathbf C_\\tau$. We introduce the category $\\mathcal{CA}$ of all clone algebras (of arbitrary similarity types) with pure homomorphisms (i.e., preserving only the nullary operators $\\e_i$ and the operators $q_n$) as arrows and we show that $\\mathcal{CA}$ is equivalent both to the full subcategory $\\mathcal{MCA}$ of minimal clone algebras and, more to the point, to the full subcategory $\\mathcal{CA}_0$ of pure clone algebras.\nMoreover, we show that $\\mathcal{MCA}$ is isomorphic (as a category) to the category $\\mathcal{VAR}$ of all varieties. This result allows us to directly use $\\mathcal{MCA}$ to study $\\mathcal{VAR}$. \n%that the category $\\mathcal{MCA}$ is closed under categorical products and we use this result and central elements to provide \nA generalisation of the theorem on independent varieties presented by Gr\\\"atzer et al. in \\cite{GLP} concludes this work.\n\n\n\\subsection{Central elements in clone algebras}\\label{sec:central}\nA clone algebra $\\mathbf C$ is an $n$CH, for every $n$. Therefore, there exists a bijection between the set of $n$-central elements of ${\\bf C}$ and the set of $n$-tuples of complementary factor congruences on ${\\bf C}$.\nIn this section we show the following results:\n\\begin{itemize}\n\\item  Every $n$-central element is finite dimensional;\n\\item An element $c$ is $n$-central if and only if $n\\geq \\gamma(c)$ and $c$ is $m$-central for every $m\\geq \\gamma(c)$;\n\\item The set $\\{c: \\text{$c$ is $n$-central for some $n$}\\}$ of all central elements of ${\\bf C}$ is a pure clone subalgebra of the pure reduct of $\\mathbf C$.\n\\end{itemize}\n\n\n\\begin{lemma}\\label{central1}\nLet ${\\bf C}$ be a clone algebra and $c\\in C$ be  $n$-central, for some $n$. \nThen $c$ is finite dimensional and $\\gamma(c)\\leq n$.\n\\end{lemma}\n\\begin{proof}\nBy the way of contradiction, let us suppose that either $c$ is finite dimensional and $\\gamma(c)>n$  or $\\gamma(c)=\\omega$. \nIn both cases there exists $m>n$ such that $c$ is dependent on $\\e_m$, meaning that $c\\neq q_m(c,\\e_1,\\ldots,\\e_{m-1},\\e_{m+1})$.\n\nSince $c$ is  $n$-central, the equation\n\\[\\begin{array}{lllr}\n&&q_n(c,q_m(g_1,h_1^1,\\ldots,h_m^1),\\ldots, q_m(g_n,h_1^n,\\ldots,h_m^n)) &\\\\\n&=& q_m(q_n(c,g_1,\\ldots,g_n),q_n(c,h_1^1,\\ldots,h_1^n),\\ldots,q_n(c,h_m^1,\\ldots,h_m^n))&\\\\\n\\end{array}\n\\]\nholds for all $g_1,\\ldots,g_n,h_1^1,\\ldots h^1_m,\\ldots, h^n_1,\\ldots,  h_m^n$ in $C$.\nBy letting $g_i=\\e_i$ for $1\\leq i\\leq n$ , $h_i^j=\\e_i$ for $1\\leq i\\leq m-1$ and $1\\leq j\\leq n$, \nand $h_m^j=\\e_{m+1}$ for $1\\leq j\\leq n$ in the equation above, and by exploiting again the fact that $c$ is $n$-central, we get:\n$$q_n(c,\\e_1,\\ldots,\\e_n)=\n%q^\\top_n(f,q^\\top_k(f,a_1^\\top,\\ldots,a_1^\\top),\\ldots,q^\\top_k(f,a_{n-1}^\\top,\\ldots,a_{n-1}^\\top), , q^\\top_k(f,b^\\top,\\ldots,b^\\top))\nq_m(c,\\e_1,\\dots,\\e_{m-1},\\e_{m+1})$$\n\nThe left-hand side of the equation above being equal to $c$, we get a contradiction using our initial assumption that $c\\neq q_m(c,\\e_1,\\ldots,\\e_{m-1},\\e_{m+1})$.\n\\end{proof}\n\n\n\n\n\\begin{lemma}\\label{central2}\nLet ${\\bf C}$ be a clone $\\tau$-algebra, $c\\in C$ be  $n$-central  for some $n$,\nand let $m\\geq n$. Then $c$ is $m$-central.\n\\end{lemma}\n\\begin{proof}\nBy Lemma \\ref{central1}, $\\gamma(c)\\leq n$ so that $c$ is independent of $\\e_n$, $\\e_{n+1},\\ldots,\\e_m$. The first equation characterising $m$-centrality, namely $q_m(c,\\e_1,\\ldots,\\e_m)=c$ is\nverified {\\em a priori}. As for the second one: given $x\\in C$, we have \n$x=q_n(c,x,\\ldots,x)=q_m(c,x,\\ldots,x)$, the second equality following from Lemma \\ref{lem:ind1}, \nIt remains to verify the third equation of $m$-centrality. We have:\n\n\\[\\begin{array}{lllr}\n q_m(c,\\sigma(x^1_1,\\ldots,x^1_k),\\ldots,\\sigma(x^m_1,\\ldots,x^m_k))\n&=& q_n(c,\\sigma(x^1_1,\\ldots,x^1_k),\\ldots,\\sigma(x^n_1,\\ldots,x^n_k))&\\\\ \n&=& \\sigma(q_n(c,x^1_1,\\ldots,x^n_1),\\ldots,q_n(c,x^1_k,\\ldots,x^n_k)) &\\\\ \n&=& \\sigma(q_m(c,x^1_1,\\ldots,x^m_1),\\ldots,q_m(c,x^1_k,\\ldots,x^m_k)) &\\\\ \n\\end{array}\n\\]\nand we are done.\n\\end{proof}\n\n\n\\begin{proposition}\\label{prop:central}\nLet ${\\bf C}$ be a clone $\\tau$-algebra and $c\\in C$. If there exists $n$ such that $c$ is   $n$-central,\nthen, for all $m$,  $c$ is $m$-central if and only if $m\\geq \\gamma(c)$.\n\\end{proposition}\n\\begin{proof}\nBy Lemma \\ref{central1} and Lemma \\ref{central2}, it is enough to show that\n$c$ is $\\gamma(c)$-central. For the sake of readability, let $\\gamma(c)=l$. \nFor all $x,x^1_1,\\ldots,x^1_k,\\ldots,x^l_1,\\ldots, x^l_k\\in C$, and for all $k$-ary $\\sigma$,\nusing repeatedly Lemma \\ref{lem:ind1}, \nwe have $q_l(c,x,\\ldots,x)=q_n(c,x,\\ldots,x)=x$, and \n\n\\[\\begin{array}{lllr}\n  q_l(c,\\sigma(x^1_1,\\ldots,x^1_k),\\ldots,\\sigma(x^l_1,\\ldots,x^l_k))\n&=& q_n(c,\\sigma(x^1_1,\\ldots,x^1_k),\\ldots,\\sigma(x^n_1,\\ldots,x^n_k))&\\\\ \n&=& \\sigma(q_n(c,x^1_1,\\ldots,x^n_1),\\ldots,q_n(c,x^1_k,\\ldots,x^n_k)) &\\\\ \n&=& \\sigma(q_l(c,x^1_1,\\ldots,x^l_1),\\ldots,q_l(c,x^1_k,\\ldots,x^l_k)) &\\\\ \n\\end{array}\n\\]\n\\end{proof}\n\nWe denote by $\\mathrm{Ce}_n(\\mathbf C)$ the set of all $n$-central elements of $\\mathbf C$, and by\n$\\mathrm{Ce}(\\mathbf C)$ the set $\\bigcup_{n\\geq 1} \\mathrm{Ce}_n(\\mathbf C)$.\nThe algebra $(\\mathrm{Ce}_n(\\mathbf C),q_n^\\mathbf C,\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C)$ is an $n\\mathrm{BA}$ (see Section \\ref{sec:nba}).\n\n\\begin{proposition} Let $\\mathbf C$ be a clone $\\tau$-algebra. Then $\\mathrm{Ce}(\\mathbf C)$ is a finite dimensional subalgebra of the pure reduct of $\\mathbf C$.\n\\end{proposition}\n\n\\begin{proof} Let $a$ and $\\mathbf b=b_1,\\dots,b_n$ be elements of  $\\mathrm{Ce}(\\mathbf C)$. We show that $q_n(a,\\mathbf b)$ is also central. By Lemma \\ref{central1} $a,b_1,\\dots,b_n$ are finite dimensional. Let $m\\geq n$ be greater than the dimensions of $a,b_1,\\dots,b_n$. Since by Lemma \\ref{lem:exc4} $q_n(a,\\mathbf b)= q_m(a,\\mathbf b,\\e_{n+1},\\dots,\\e_m)$ and by Lemma \\ref{central2} the elements $a,b_1,\\dots,b_n, \\e_{n+1},\\dots,\\e_m$ are $m$-central, \nthen we claim that $q_m(a,\\mathbf b,\\e_{n+1},\\dots,\\e_m)$ is also $m$-central.\n This follows from Example \n \\ref{exa:canonical}, because $\\mathbf C$ is an $m\\mathrm{CH}$ (see Section \\ref{dobbiaco}).\n\\end{proof}\n\nThe variety generated by the class $\\{ \\mathrm{Ce}(\\mathbf C) : \\mathbf C\\in\\mathsf{CA}\\}$ will be called the variety of pure $\\omega$-Boolean-like algebras ($\\omega\\mathrm{BA}$, for short). We propose the problem of finding an equational axiomatisation for the variety of $\\omega\\mathrm{BA}$s.  \n\n\\bigskip\n\nWe conclude the section with the following useful result. \n\n\\begin{proposition}\\label{prop:de} Let $\\mathbf C$ be a clone $\\tau$-algebra and $c\\in C$ of dimension $n$. Then  $c$ is $n$-central in $\\mathbf C$ iff it is $n$-central in the pure reduct of $\\mathbf C$.\n\\end{proposition}\n\n\\begin{proof}\n The conclusion follows because, for every $\\sigma\\in\\tau$ of arity $k$, $\\sigma^\\mathbf C$ is defined in terms of $q_k^\\mathbf C$ and the element $\\sigma^\\mathbf C(\\e_1,\\dots,\\e_k)$:\n $\\sigma^\\mathbf C(a_1,\\dots,a_k)=q_k^\\mathbf C(\\sigma^\\mathbf C(\\e_1,\\dots,\\e_k),a_1,\\dots,a_k)$.\n\\end{proof}\n\n The meaning of the above proposition is that the decomposability of a variety as product of other varieties only depends on the pure clone algebraic structure of its free algebra.\n\n\n\\subsection{Minimal clone algebras}\\label{sec:mca}\n\nLet $\\mathbf C=(\\mathbf C_\\tau,q_n^\\mathbf C,\\e_i^\\mathbf C)$ be a clone $\\tau$-algebra. We denote by $M(\\mathbf C)$ the minimal subalgebra of the algebra $(\\mathbf C_\\tau,\\e_i^\\mathbf C)$. \n%generated by the subset $\\{\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C,\\dots\\}$. \nThe algebra $M(\\mathbf C)$ is an algebra in the type $\\tau(\\e)=\\tau\\cup\\{\\e_1,\\dots,\\e_n,\\dots\\}$. \nIn Lemma \\ref{lem:min} we show  that $M(\\mathbf C)$ is also closed under the operators $q_n^\\mathbf C$ and, as algebra in the type of clone $\\tau$-algebras, it is the minimal subalgebra of $\\mathbf C$.\n\nA ground $\\tau(\\e)$-term is a term defined by the following grammar: $t,t_i::= \\e_i\\ |\\ \\sigma(t_1,\\dots,t_k)$, where  \n$\\sigma\\in \\tau$. \n\n\\begin{lemma}\\label{lem:ground}\n  If $b\\in M(\\mathbf C)$, then there exists a ground $\\tau(\\e)$-term $t$ such that $b=t^\\mathbf C$.\n\\end{lemma}\n\n\\begin{lemma}\\label{lem:min}\n Let $\\mathbf C$ be a clone $\\tau$-algebra. Then the following conditions hold: \n \\begin{itemize}\n\\item[(i)]  $M(\\mathbf C)$ is closed under the operators $q_n^\\mathbf C$. \n\\item[(ii)] The clone $\\tau$-algebra $M(\\mathbf C)$ is finite dimensional and it is the minimal subalgebra of $\\mathbf C$.\n\\end{itemize}\n\\end{lemma}\n\n\\begin{proof} (i) The proof is by induction over the complexity of the ground $\\tau(\\e)$-terms in the first argument of $q_n$.\n \n(ii) By induction on the complexity of a ground $\\tau(\\e)$-term $t$, if $\\e_k$ does not occur in $t$, then $t^\\mathbf C$ is independent of $\\e_k$. Then, if $t=t(\\e_1,\\dots,\\e_n)$, then $t^\\mathbf C$ has dimension $\\leq n$.\n\\end{proof}\n\n\n\n\\begin{definition}\n  We say that a clone $\\tau$-algebra $\\mathbf C$ is \\emph{minimal} if $\\mathbf C= M(\\mathbf C)$.\n\\end{definition}\n\nWe remark that,  if $h:\\mathbf C\\to\\mathbf D$ is an onto homomorphism of clone $\\tau$-algebras and $\\mathbf C$ is minimal, then $\\mathbf D$ is minimal.\n\n%sbagliato \\begin{proposition}\\label{prop:mincen}\n% Let $\\mathbf C$ be a clone $\\tau$-algebra and $c\\in C$ be $n$-central.\n% \\begin{itemize}\n%\\item[(i)]  $c\\in M(\\mathbf C)$ iff $\\mathbf C=M(\\mathbf C)$.\n%\\item[(ii)]   Let $\\tau_c=\\tau \\cup\\{f_c\\}$ be an extension of type $\\tau$ with an operator symbol $f_c$ of arity $n$. If we interpret $f_c$ as \n%$$f_c^\\mathbf C(a_1,\\dots,a_n)=q_n^\\mathbf C(c,a_1,\\dots,a_n)\\quad\\text{for all $a_1,\\dots,a_n\\in C$}$$\n%and define $\\mathbf C_{\\tau_c} = \\langle\\mathbf C_\\tau, f_c^\\mathbf C\\rangle$,\n%then the algebra $\\mathbf C_c=(\\mathbf C_{\\tau_c}, q_n^\\mathbf C,\\e_i^\\mathbf C)$ is a minimal clone $\\tau_c$-algebra.\n%\\end{itemize}\n%\\end{proposition}\n%\n%\\begin{proof}  By Proposition  \\ref{prop:central}  $c$ has dimension $\\gamma(c)\\leq n$.\n%\n%(i) Let $c\\in M(\\mathbf C)$.\n%\n%(ii) By Theorem \\ref{thm:centrale}(2) and by the hypothesis that $c$ is $n$-central, for every $b_1,\\dots,b_n\\in C$, $q_n^\\mathbf C(c,b_1,\\dots,b_n)$ is the unique element such that $b_i\\ \\theta(c,\\e_i^\\mathbf C)\\ q_n^\\mathbf C(c,b_1,\\dots,b_n)$ for every $i=1,\\dots,n$.\n%Since $q_n^\\mathbf C(c,b_1,\\dots,b_n)= f_c^\\mathbf C(b_1,\\dots,b_n)$, then $\\mathbf C_{\\tau_c}$ is $\\tau(\\e)$-minimal and\n%$\\mathbf C_c=M(\\mathbf C_c)$.\n%\\end{proof}\n\n\n The translation of the ground $\\tau(\\e)$-terms into $\\tau$-terms in the variables $v_1,v_2,\\dots,v_n,\\dots$ is defined by\n$$\\e_i^*=v_i;\\quad  \\sigma(t_1,\\dots,t_n)^*=\\sigma(t_1^*,\\dots,t_n^*).$$ \n\n\n\n\\begin{theorem}\\label{thm:ch2} Let $\\mathbf C=(\\mathbf C_\\tau,q_n^\\mathbf C,\\e_i^\\mathbf C)$ be a minimal  clone $\\tau$-algebra and $\\mathrm{Var}(\\mathbf C_\\tau)$ be the variety of $\\tau$-algebras generated by $\\mathbf C_\\tau$. Then  \\begin{itemize}\n\\item[(i)] $\\mathbf C_\\tau$ is  the free algebra over a countable set of generators in the variety $ \\mathrm{Var}(\\mathbf C_\\tau)$ of $\\tau$-algebras;\n\\item[(ii)] $\\mathbf C$ is  the free algebra over an empty set of generators in the variety $ \\mathrm{Var}(\\mathbf C)$ of clone $\\tau$-algebras.\n\\end{itemize} \n\\end{theorem}\n\n\n\n\\begin{proof} (i) We show that $\\mathbf C_\\tau$ is isomorphic to the free algebra  over a countable set $\\{\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C,\\dots\\}$ of generators in the variety $\\mathrm{Var}(\\mathbf C_\\tau)$. \n Let $\\mathbf A\\in  \\mathrm{Var}(\\mathbf C_\\tau)$, $g: \\{\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C,\\dots\\}\\to A$ be an arbitrary map, and $d_i=g(\\e_i^\\mathbf C)$.\n We extend $g$ to a map $g^*: C\\to A$ as follows. Let $b\\in C$ of dimension $k$ and let $m\\geq k$.\n Since $\\mathbf C$ is minimal, there exists a ground $\\tau(\\e)$-term $t$ such that $t^\\mathbf C=b$.\n We define \n $$g^*(b)=(t^*)^{\\mathbf A,m}(d_1,\\dots,d_m),$$\n where  $(t^*)^{\\mathbf A,m}$ is the term operation defined in Section \\ref{sec:to}. \n The definition of $g^*(b)$ is independent of $m\\geq k$.\n%Since $\\mathbf C\\models f^m_b(x_1,\\dots,x_k,x_{k+1},\\dots, x_m)= f^k_b(x_1,\\dots,x_k)$ for every $m\\geq k$ and $\\mathbf A\\in\\mathcal V(\\mathbf C)$, then we have   \n%$$g^*(b) =\\overline{f^m_b}^\\mathbf A (d_1,\\dots,d_m)\\quad \\text{for every $m\\geq k$}.$$ \nWe now show that $g^*$ is a homomorphism of $\\tau$-algebras. \nLet $\\sigma\\in\\tau$ of arity $n$, $\\mathbf b=b_1,\\dots,b_n\\in C$ and $\\mathbf e=\\e_1,\\dots,\\e_n$. \nLet $m\\geq n$ be a natural number greater than the maximal among the dimensions of the elements $b_1,\\dots,b_n,\\sigma^\\mathbf C(\\mathbf b)$.\nLet $\\mathbf d=d_1,\\dots,d_m$. \nWe now show that \n$$g^*( \\sigma^\\mathbf C(\\mathbf b))=\\sigma^\\mathbf A(g^*(b_1),\\dots,g^*(b_n)).$$\nIf $b_i=t_i^{\\mathbf C}$ for some ground $\\tau(\\e)$-term $t_i$ ($i=1,\\dots,n$), then $\\sigma^\\mathbf C(\\mathbf b)=\\sigma(t_1,\\dots,t_n)^\\mathbf C$.\nRecalling that $\\sigma^\\mathbf C(\\mathbf b)=q^\\mathbf C_n(\\sigma^\\mathbf C(\\mathbf e),\\mathbf b)$ (see Definition \\ref{def:representable}), then we have:\n$$\\sigma^\\mathbf A(g^*(b_1),\\dots,g^*(b_n))=\n\\sigma^\\mathbf A((t_1^*)^{\\mathbf A,m}(\\mathbf d),\\dots,(t_n^*)^{\\mathbf A,m}(\\mathbf d))=\n(\\sigma(t_1,\\dots,t_n)^*)^{\\mathbf A,m}(\\mathbf d)=g^*(\\sigma^\\mathbf C(\\mathbf b)).$$\n\n%We get that $\\phi^*$ is a homomorphism if  the algebra $\\mathbf A$ satisfies the identity \n%$$\\overline h(\\overline{f^m_{b_1}} (x_1,\\dots,x_m),\\dots,\\overline{f^m_{b_n}} (x_1,\\dots,x_m))=\n%\\overline{f^m_r}(x_1,\\dots,x_m),$$\n%where $r= q^\\mathbf C_n(h(\\mathbf e),\\mathbf b)$.\n%Since $\\mathbf A$ belongs to the variety $ V(\\mathbf C)$ generated by $\\mathbf C_{\\overline{\\tau}}$, then it is sufficient to prove that $\\mathbf C_{\\overline{\\tau}}$ satisfies the above identity. By putting $\\mathbf x= x_1,\\dots,x_m$ the conclusion follows from Lemma \\ref{12}(ii):\n%$$f^m_r(\\mathbf x)=q_m^\\mathbf C(q^\\mathbf C_n(h(\\mathbf e),\\mathbf b),\\mathbf x)= q_m^\\mathbf C(h(\\mathbf b),\\mathbf x)=_{Lem. \\ref{12}(ii)}$$\n%$$\\qquad\\qquad\\qquad\\qquad h(q_m^\\mathbf C(b_1,\\mathbf x),\\dots,q_m^\\mathbf C(b_n,\\mathbf x))=h(f^m_{b_1}(\\mathbf x),\\dots,f^m_{b_n} (\\mathbf x)).$$ \nBy Lemma \\ref{lem:24} the map $x \\mapsto q_n^\\mathbf C(x,\\mathbf b)$ is the unique endomorphism\nof the free algebra $\\mathbf C_\\tau$ which sends $\\e_i$ to $b_i$ ($1\\leq i\\leq n$). \n\n(ii) Let $\\mathbf A\\in  \\mathrm{Var}(\\mathbf C)$. Then $\\mathbf A_\\tau\\in  \\mathrm{Var}(\\mathbf C_\\tau)$. By (i) there exists a unique homomorphism $f$ from   $\\mathbf C_\\tau$ into $\\mathbf A_\\tau$ such that $f(\\e_i^\\mathbf C)= \\e_i^\\mathbf A$.\nSince $\\mathbf C$ is minimal, then $f$ is onto $M(\\mathbf A)$ and, for every ground $\\tau(\\e)$-term $t$, we have $f(t^\\mathbf C)=t^\\mathbf A$.\nThe proof that $f$ preserves $q_n$ is by induction over the complexity of the first argument of $q_n$.\n\\end{proof}\n\n\n\n\n\nLet  $\\mathcal V$ be a variety of $\\tau$-algebras axiomatised by the equational theory $T$ and\n $\\mathcal V^c$ be the variety of clone $\\tau$-algebras satisfying $T$. If $\\mathbf C=\\mathbf{Cl}(\\mathcal{V})$ is the clone $\\mathcal V$-algebra, then $\\mathrm{Var}(\\mathbf C)\\subseteq \\mathcal V$.\n\n\n\\begin{proposition} \n\\begin{itemize}\n\\item[(i)]  The clone $\\mathcal V$-algebra $\\mathbf{Cl}(\\mathcal{V})=(\\mathbf{F}_\\mathcal{V}, q_n^\\mathbf{F}, \\e_i^\\mathbf{F})$ (see Definition \\ref{def:cva}) is the free algebra over an empty set of generators in the variety $\\mathcal V^c$;\n\\item[(ii)] $\\mathcal V^c$ is not in general generated by $\\mathbf{Cl}(\\mathcal{V})$.\n\\end{itemize}\n\\end{proposition}\n\n\\begin{proof} (i) Let $\\mathbf A=(\\mathbf A_\\tau,q_n^\\mathbf A,\\e_i^\\mathbf A)\\in \\mathcal V^c$.\nSince $\\mathbf A_\\tau\\in \\mathcal V$, then there exists a unique homomorphism $f$ of $\\tau$-algebras from $\\mathbf{F}_\\mathcal{V}$ into $\\mathbf A_\\tau$ such that $f(\\e_i^\\mathbf F)=f(v_i)= \\e_i^\\mathbf A$. The proof that $f$ preserves the operators $q_n^\\mathbf F$ is similar to that of Theorem \\ref{thm:ch2}(ii). \n\n(ii) If $\\mathcal S$ is the class of all sets (i.e., the variety of all algebras in the empty type), then $\\mathcal S^c$ is the variety of all pure clone algebras. We show that $\\mathbf{Cl}(\\mathcal{S})$ does not genetate $\\mathcal S^c$.\n $\\mathbf{Cl}(\\mathcal{S})=(I,q_n^\\mathbf I,\\e_i^\\mathbf I)$ has the set  $I=\\{v_1,v_2,\\dots,v_n,\\dots\\}$ as universe and $\\e_i^\\mathbf I=v_i$. The algebra $\\mathbf I$ satisfies the identity\n\\begin{equation}\\label{eq:identity}\nq_n(y, q_n(y, x_{11},x_{12},\\dots,x_{1n}),\\dots,q_n(y,x_{n1},x_{n2},\\dots,x_{nn}))=q_n(y,x_{11},\\dots,x_{nn})\n\\end{equation}\n but $\\mathcal S^c$ does not satisfy it. Here is a counterexample.\n Let $2=\\{0,1\\}$ and $f:2^2\\to 2$ be a function such that $f(0,0)=0$ and $f(0,1)=f(1,0)=f(1,1)=1$.\n Then $1=f(f(0,1),f(1,0))\\neq f(0,0)$. Then the pure functional clone algebra of universe $\\mathcal O_2^{(\\omega)}$ does not satisfies identity (\\ref{eq:identity}): \n  $$q_2^\\omega(f^\\top,q_2^\\omega(f^\\top,\\e_1^\\omega,\\e_2^\\omega), q_2^\\omega(f,\\e_2^\\omega,\\e_1^\\omega))(r)\\neq q_2^\\omega(f^\\top,\\e_1^\\omega,\\e_1^\\omega).$$\nLet $r\\in 2^\\omega$ such that $r_1=0$ and $r_2=1$. Then,\n \\[\n\\begin{array}{lll}\n q_2^\\omega(f^\\top,q_2^\\omega(f^\\top,\\e_1^\\omega,\\e_2^\\omega), q_2^\\omega(f^\\top,\\e_2^\\omega,\\e_1^\\omega))(r)  \n  & =  & f^\\top(r[q_2^\\omega(f^\\top,\\e_1^\\omega,\\e_2^\\omega)(r),q_2^\\omega(f^\\top,\\e_2^\\omega,\\e_1^\\omega)(r)])  \\\\\n  &  = & f^\\top(r[f^\\top(r[\\e_1^\\omega(r),\\e_2^\\omega(r)]),f^\\top(r[\\e_2^\\omega(r),\\e_1^\\omega(r)])])  \\\\\n  &  = & f^\\top(r[f^\\top(r[0,1]),f^\\top(r[1,0])])  \\\\\n   &  = & f^\\top(r[f(0,1),f(1,0)])  \\\\ \n   &  = & f(f(0,1),f(1,0)) =1 \\\\ \n\\end{array}\n\\]\nwhile $q_2^\\omega(f^\\top,\\e_1^\\omega,\\e_1^\\omega)(r) = f(0,0)=0$.\n\\end{proof}\n\n\n%\\[\n%\\begin{array}{rcl}\n%\\text{Clone $\\tau$-algebra $\\mathbf C$}   &\\mapsto&   \\text{Variety $\\mathrm{Var}(\\mathbf C_{\\overline{\\tau}})$ of $\\overline{\\tau}$-algebras}\n%\\end{array}\n%\\]\n\n\\subsection{The category of clone algebras and pure homomorphisms}\nA map between clone algebras preserving the operators $q_n$ and the nullary operators $\\e_i$ will be called a \\emph{pure homomorphism}. Given a clone $\\tau$-algebra $\\mathbf C$ and a clone $\\nu$-algebra $\\mathbf D$, a map $f:C\\to D$ is a pure homomorphism from $\\mathbf C$ into $\\mathbf D$ if and only if $f$ is a  homomorphism between the pure reducts of $\\mathbf C$ and $\\mathbf D$.\n\nIn this section every variety $\\mathcal V$ of $\\tau$-algebras will be considered as a category whose objects are the algebras of $\\mathcal V$ and whose arrows are the homomorphisms of $\\tau$-algebras.\n\nLet Type be the class of all algebraic types. The category $\\mathcal{CA}$ has the class $\\bigcup_{\\tau\\in \\mathrm{Type}} \\mathsf{CA}_\\tau$ as class of objects and pure homomorphisms as arrows. We denote by $\\mathcal{MCA}$ the full subcategory of  $\\mathcal{CA}$ whose objects are the minimal clone algebras.  The variety $\\mathsf{CA}_0$ of pure clone algebras is a  full subcategory of  $\\mathcal{CA}$.\n\n\n\\begin{proposition}\\label{prop:equiva}\n The category $\\mathcal{CA}$ is equivalent to both $\\mathcal{MCA}$ and $\\mathsf{CA}_0$.\n\\end{proposition}\n\n\\begin{proof} Let $\\mathbf C$ be a  clone $\\tau$-algebra. Then $\\mathbf C$ is purely isomorphic to the pure reduct $\\mathbf C_0$ and to the minimal clone $\\rho_\\mathbf C$-algebra $\\mathbf R_\\mathbf C$ of $\\mathbf C$-representable functions (see Definition \\ref{def:ctype}).\n\\end{proof}\n \n\n\n%The  notion of \\emph{interpretation} of  into a variety $\\mathcal W$ of type $\\nu$ and that of \\emph{equivalence of varieties} can be found in . \n\nWe recall from \\cite[Page 245]{mac} that an \\emph{interpretation} of a variety $\\mathcal V$ of type $\\tau$ into a variety $\\mathcal W$ of type $\\nu$  is a mapping $f$ with domain $\\tau$ satisfying:\n\\begin{itemize}\n\\item If $\\sigma\\in\\tau$ has arity $n>0$, then $f(\\sigma)$ is an $n$-ary $\\nu$-term;\n\\item If $\\sigma\\in\\tau$ has arity $0$, then $f(\\sigma)=t$ is a unary $\\nu$-term such that the equation $t(v_1)=t(v_2)$ is valid in $\\mathcal W$;\n\\item For every algebra $\\mathbf A\\in \\mathcal W$, the algebra $\\mathbf A^f=(A,f(\\sigma)^{\\mathbf A,k})_{\\sigma\\in\\tau}$ belongs to $\\mathcal V$, where $f(\\sigma)^{\\mathbf A,k}$ ($\\sigma$ of arity $k$) is the $k$-ary term operation defined in Section \\ref{sec:to}.\n\\end{itemize}\nAn interpretation determines a functor from $\\mathcal W$ into $\\mathcal V$.\n\nWe denote by $\\mathcal{VAR}$  the category whose objects are varieties of algebras and whose arrows are interpretations of varieties.\n\n\n\n\\begin{lemma}\\label{lem:inter}  There is a bijection between interpretations of varieties and\n pure  homomorphisms of minimal clone algebras. \n \\end{lemma}\n\n\\begin{proof} Let $\\mathcal V$ be a variety of type $\\tau$,  $\\mathcal W$ be a variety of type $\\nu$, $\\mathbf C= \\mathbf{Cl}(\\mathcal V)$ and $\\mathbf D= \\mathbf{Cl}(\\mathcal W)$. We recall that $\\mathbf C_\\tau$ is the free algebra over a countable set of generators in variety $\\mathcal V$. Similarly for $\\mathbf D_\\nu$.\nAn interpretation $f$ of $\\mathcal V$ into  $\\mathcal W$ determines a pure homomorphism $F$ of $\\mathbf C$ into $\\mathbf D$.\nIf $t$ is a $\\tau$-term, then we denote by $t^\\mathbf C$ its equivalence class in the free algebra $\\mathbf C_\\tau$. Then we define:\n\\begin{itemize}\n\\item If $t=\\sigma(t_1,\\dots,t_n)$, then $F(\\sigma^\\mathbf C(t_1^\\mathbf C,\\dots,t_n^\\mathbf C)) =q_n^\\mathbf D(f(\\sigma)^\\mathbf D,F(t_1^\\mathbf C),\\dots,F(t_n^\\mathbf C))$ for every $c\\in \\tau$ of arity $n>0$.\n\\item $F(c^\\mathbf C)=f(c)^\\mathbf D$ for every $c\\in \\tau$ of arity $0$. Notice that $f(c)$ is a unary $\\nu$-term such that $f(c)^\\mathbf D$ is zero-dimensional in $\\mathbf D$.\n\\end{itemize}\n\nFor the converse, let $\\mathbf C$ be a minimal clone $\\tau$-algebra, $\\mathbf D$ be a minimal clone $\\nu$-algebra and $F$ be a pure homomorphism from $\\mathbf C$ into $\\mathbf D$. Then, for every $n$-ary operator $\\sigma\\in \\tau$ ($n > 0$), we define $f(\\sigma)$ to be any $\\nu$-term $t=t(v_1,\\dots,v_n)$ belonging to $\\sigma^\\mathbf D(\\e_1^\\mathbf D,\\dots,\\e_n^\\mathbf D)$ (see Proposition \\ref{prop:free}(3)). If $c\\in\\tau$ is a nullary operator, then we define $f(c)$ to be any $\\nu$-term $t=t(v_1)$ belonging to $c^\\mathbf D$ (see Proposition \\ref{prop:free}(4)).\n$f$ is an interpretation from $\\mathrm{Var}(\\mathbf C_\\tau)$ into $\\mathrm{Var}(\\mathbf D_\\nu)$.\n\\end{proof}\n\n\n\\begin{theorem}\\label{thm:iso} The categories $\\mathcal{VAR}$ and  $\\mathcal{MCA}$ are categorically isomorphic.\n There is a bijection between the class of all varieties of algebras and the class of all minimal clone algebras:\n \\[\n\\begin{array}{rcl}\n \\text{Variety $\\mathcal V$ of $\\tau$-algebras} & \\mapsto  & \\text{$\\mathcal V$-clone $\\tau$-algebra $\\mathbf{Cl}(\\mathcal V)$}  \\\\\n\\text{Minimal clone $\\tau$-algebra $\\mathbf C$}  & \\mapsto  & \\text{Variety $\\mathrm{Var}(\\mathbf C_\\tau)$ of $\\tau$-algebras}.  \\\\\n\\end{array}\n\\]\nWe have $$\\mathcal V= \\mathrm{Var}(\\mathbf{Cl}(\\mathcal V)_\\tau);\\qquad \\mathbf C \\cong \\mathbf{Cl}(\\mathrm{Var}(\\mathbf C_\\tau)).$$\nMoreover, there a bijective correspondence between the sets $\\mathrm{Hom}_{\\mathcal{VAR}}(\\mathcal V,\\mathcal W)$ of interpretations and the set $\\mathrm{Hom}_{\\mathcal{CA}}(\\mathbf{Cl}(\\mathcal V),\\mathbf{Cl}(\\mathcal W))$ of pure homomorphisms.\n\\end{theorem}\n\n%By Proposition \\ref{prop:equiva} and Theorem \\ref{thm:iso} the categories $\\mathcal{VAR}$ and  $\\mathcal{CA}$ are also equivalent.\n\n%We define two functors $F$ and $G$. For every variety $\\mathcal V$ and clone algebra $\\mathbf C$,  $$F(\\mathcal V)= \\mathbf{Cl}(\\mathcal V);\\quad G(\\mathbf C)=\\mathrm{Var}(\\mathbf R_\\mathbf C),$$  where $\\rho_\\mathbf C$ is the $\\mathbf C$-type and $\\mathbf R_\\mathbf C$ is the $\\rho_\\mathbf C$-algebra of $\\mathbf C$-representable functions. The varieties $\\mathcal V$ and $G(F(\\mathcal V))$ are equivalent, that is, isomorphic in the category $\\mathcal{VAR}$. The clone algebras $\\mathbf C$ and $F(G(\\mathbf C))$ have isomorphic pure reducts.\n\n%Two varieties $\\mathcal V$ and $\\mathcal W$ are \\emph{equivalent} if  there are an interpretation $f$ of $\\mathcal V$ into $\\mathcal W$ and an interpretation $g$ of $\\mathcal W$ into $\\mathcal V$ such that $\\mathbf A^{fg}=\\mathbf A$ ($\\mathbf A\\in \\mathcal W$) and $\\mathbf B^{gf}=\\mathbf B$ ($\\mathbf B\\in \\mathcal V$). Two varieties are equivalent iff they are  isomorphic in the category $\\mathcal{VAR}$. We write $\\mathcal V \\equiv_E \\mathcal W$ for expressing that the varieties $\\mathcal V$ and $\\mathcal W$ are equivalent.\n\nThe following proposition is an elegant reformulation of \\cite[Theorem 4.140]{mac}. \n\n\\begin{proposition} Two varieties $\\mathcal V$ and $\\mathcal W$ are isomorphic in the category $\\mathcal{VAR}$ (equivalent in the terminology of  \\cite[Theorem 4.140]{mac})  if and only if there is a pure isomorphism from $\\mathbf{Cl}(\\mathcal V)$ onto $\\mathbf{Cl}(\\mathcal W)$.\n\\end{proposition}\n\n\n\\begin{proposition}\\label{prop:catprod} \n\\begin{itemize}\n\\item[(i)] The categories $\\mathcal{MCA}$ and $\\mathcal{VAR}$ are closed under categorical product. \n\\item[(ii)] A categorical product of $\\mathbf C, \\mathbf D\\in \\mathcal{MCA}$, denoted by $\\mathbf C\\odot \\mathbf D$, is any minimal clone algebra, whose pure reduct is (purely isomorphic to) $\\mathbf C_0\\times\\mathbf D_0$.\n\\item[(iii)] A categorical product of  $\\mathcal V,\\mathcal W\\in \\mathcal{VAR}$, denoted by $\\mathcal V\\odot\\mathcal W$, is any variety $\\mathcal T$ such that $\\mathbf{Cl}(\\mathcal T)$ is purely isomorphic to  $\\mathbf{Cl}(\\mathcal V)_0\\times \\mathbf{Cl}(\\mathcal W)_0$.\n%If $\\mathbf C$ and $\\mathbf D$ are minimal clone algebras, then  every minimal clone algebra, whose pure reduct is $\\mathbf C_0\\times\\mathbf D_0$, is a categorical product of  $\\mathbf C$ and $\\mathbf D$.\n\\end{itemize}\n\\end{proposition}\n\n\\begin{proof} Both $\\mathcal{MCA}$ and $\\mathcal{VAR}$ are equivalent to the variety $\\mathsf{CA}_0$. $\\mathsf{CA}_0$ is a Cartesian category.\n%Let $\\mathbf C$ be a minimal clone $\\tau$-algebra and $\\mathbf D$ be a minimal clone $\\nu$-algebra. Then $\\mathbf E=\\mathbf C_0\\times\\mathbf D_0$ is a pure clone algebra. If  $\\rho_\\mathbf E$ is the $\\mathbf E$-type, then the minimal clone $\\rho_\\mathbf E$-algebra $\\overline{\\mathbf R}_\\mathbf E=(\\mathbf R_\\mathbf E,q_n^\\mathbf E,\\e_i^\\mathbf E)$ of $\\mathbf E$-representable functions (see Definition \\ref{def:ctype})  is the categorical product of $\\mathbf C$ and $\\mathbf D$.\n\\end{proof}\n\n\n\n\n\n\n%\\subsection{Some applications}\n\n%We recall that, if $f$ is an interpretation of $\\mathcal V$ into $\\mathcal W$, then every algebra $\\mathbf A\\in \\mathcal W$ admits a reduct belonging to $\\mathcal V$.\n\n\n\n\n\n%\\begin{corollary} Let $\\mathbb{VAR}$ be the class of all varieties and $\\mathsf{CA}_0$ be the class of all pure clone algebras. Then there is a bijection between the class $\\mathbb{VAR}/\\!\\equiv_E$ and the isomorphism class $\\mathsf{CA}_0/\\!\\cong$.\n% \\end{corollary}\n\n\n\n%\\begin{definition} Let $\\mathcal V$ be a variety  of $\\tau$-algebras and $\\mathcal W$ be a variety of $\\nu$-algebras.\n% \\begin{itemize}\n%\\item[(i)] A \\emph{pure interpretation} of $\\mathcal V$ into $\\mathcal W$ is a pure  homomorphism from $\\mathbf{Cl}(\\mathcal V)$ into $\\mathbf{Cl}(\\mathcal W)$;\n% \\item[(ii)] The varieties $\\mathcal V$ and $\\mathcal W$ are \\emph{purely equivalent} if there is a pure isomorphism from $\\mathbf{Cl}(\\mathcal V)$ onto  $\\mathbf{Cl}(\\mathcal W)$.\n% \\end{itemize}\n%\\end{definition}\n\n\n\n\n%\\begin{proof} \n% \n%\\end{proof}\n\n\n%\\begin{definition}\n%  Let $\\mathcal V$ be a variety  of $\\tau$-algebras, $\\mathbf A\\in\\mathcal V$ and $\\mathbf A[I]$ be the free extension of $\\mathbf A\\in\\mathcal V$ by $I$ in the variety $\\mathcal V$. \n%Then the algebra $\\mathbf C(\\mathcal V,\\mathbf A)= (\\mathbf A[I],q_n^{\\mathbf A},\\e_i^{\\mathbf A})$, where\n%$\\e_i^{\\mathbf A} = v_i$ and $q_n^{\\mathbf A}(a,\\mathbf b)=s(a)$ for   the unique endomorphism $s$ of $\\mathbf A[I]$ which sends $v_i$ to $b_i$ ($1\\leq i\\leq n$),\n% is called the \\emph{clone $(\\mathcal V,\\mathbf A)$-algebra}.\n%\\end{definition}\n%\n%\n%\\begin{proposition} Let $\\mathcal V$ be a variety  of $\\tau$-algebras. Then the following conditions are equivalent:\n%\\begin{enumerate}\n%\\item $\\mathcal V^c$ is the variety  of clone $\\tau$-algebras satisfying $Eq(\\mathcal V)$;\n%\\item $\\mathcal V^c$ is the variety generated by the class of all clone $(\\mathcal V,\\mathbf A)$-algebras ($\\mathbf A\\in\\mathcal V$).\n%\\end{enumerate}\n%\\end{proposition}\n%\n%\\begin{proof} We have $\\mathrm{Zd}(\\mathbf A[I],q_n,\\e_i)= A$.\n% \n%\\end{proof}\n%\n%\\begin{proposition} Let $\\mathcal W$ be a variety  of clone $\\tau$-algebras. Then the following conditions are equivalent:\n%\\begin{enumerate}\n%\\item $\\mathcal W^\\tau$ is the variety  of  $\\tau$-algebras axiomatised by $Eq(\\mathcal W)_\\tau$;\n%\\item $\\mathcal W^\\tau = \\{\\mathrm{Zd}\\mathbf C: \\mathbf C\\in\\mathcal W \\}$.\n%\\end{enumerate}\n%\\end{proposition}\n%\n%\\begin{proof} Let $\\mathbf A$ be a $\\tau$-algebra satisfying $Eq(\\mathcal W)_\\tau$. \n%Let $\\mathbf A\\in \\mathcal W^v$. Consider the block algebra $\\mathbf B$ determined by the polynomial clone $\\mathrm{Pol}\\mathbf A$ of $\\mathbf A$ (see Example \\ref{}). \n%\\end{proof}\n%\n%\\begin{proposition} Let $\\mathcal V$ be a variety  of $\\tau$-algebras and let $\\mathcal W$ be a variety  of clone $\\tau$-algebras.\n%We have $(\\mathcal V^{c})^\\tau= \\mathcal V$ and $(\\mathcal W^{\\tau})^c= \\mathcal W$.\n%\\end{proposition}\n \n \n%\\begin{proposition} Let $\\mathcal V$ be a variety of $\\tau$-algebras and $\\mathbf{F}_\\mathcal{V}(X)$ be  the free $\\mathcal V$-algebra over a countable infinite set $X=\\{v_1,\\dots, v_n,\\dots\\}$ of generators. Let $\\mathbf{F}_{\\mathcal V^c}=(\\mathbf{F}_\\mathcal{V}(X), q_n, \\e_i)$ be the algebra in the type of clone $\\tau$-algebras such that $q_n$ is the substitution operator defined by\n%$q_n(t,u_1,\\dots,u_n) =t\\left[ u_1/v_1,\\dots,u_n/v_n\\right]$ and $\\e_i= v_i$.\n%\\begin{enumerate}\n%\\item   $\\mathbf{F}_{\\mathcal V^c}$\n%is a locally finite clone algebra of type $\\tau$.\n%\\item $\\mathbf{F}_{\\mathcal V^c}$ is the free algebra over an empty set of generators in the variety $\\mathcal V^c$ of clone $\\tau$-algebras satisfying $Eq(\\mathcal V)$.\n%\\item $\\mathbf{F}_{\\mathcal V^c}$ generates the variety $\\mathcal V^c$.\n%\\end{enumerate}\n%\\end{proposition}\n%\n\n\nRecall from Section \\ref{sec:alg} the definition of product $\\mathcal V_1\\times\\dots\\times\\mathcal V_n$ of similar varieties. The equational theory generated by the union $\\bigcup_{i=1}^n Eq(\\mathcal V_i)$ axiomatises \n$\\mathcal V_1\\cap\\dots\\cap\\mathcal V_n$, while the join $\\mathcal V_1\\lor\\dots\\lor\\mathcal V_n$ is axiomatised by \n$\\bigcap_{i=1}^n Eq(\\mathcal V_i)$. The join $\\mathcal V_1\\lor\\dots\\lor\\mathcal V_n$ contains $\\mathcal V_1\\times\\dots\\times\\mathcal V_n$.\n\n%\\begin{definition} Let $\\mathcal V$ be a variety of type $\\tau$. The subvarieties  $\\mathcal V_1,\\dots,\\mathcal V_n$ of $\\mathcal V$ are  \\emph{$\\cap$-independent}, if there exists a term $t(v_1,\\dots,v_n)$ of type $\\tau$, containing at most the\n%indicated variables, such that $\\mathcal V_i\\models t(v_1,\\dots,v_n)=v_i$ ($i=1,\\dots,n$).\n%\\end{definition}\n\n\nThe following proposition and theorem provide necessary and sufficient conditions for the independence of varieties, improving a theorem on independent varieties by Gr\\\"atzer et al. \\cite{GLP} (see also \\cite{KP09,KPL13}).\n\n\\begin{proposition}\\label{prop:varind} Let $\\mathbf C$ and $\\mathbf D$ be minimal clone $\\tau$-algebras and let $\\mathbf E=\\mathbf C\\times\\mathbf D$. Then the following conditions are equivalent:\n\\begin{enumerate}\n\\item $\\mathbf E$ is minimal;\n\\item  $\\mathbf E =\\mathbf C\\odot\\mathbf D$;\n\\item $\\mathrm{Var}(\\mathbf C_\\tau)$ and $\\mathrm{Var}(\\mathbf D_\\tau)$ are independent.\n\\end{enumerate}\n If $\\mathbf E$ is minimal then  $\\mathrm{Var}(\\mathbf E_\\tau)=\\mathrm{Var}(\\mathbf C_\\tau)\\times \\mathrm{Var}(\\mathbf D_\\tau)$.\n\\end{proposition}\n\n\\begin{proof} (1 $\\Leftrightarrow$ 2) By Proposition \\ref{prop:catprod}.\n\n(1 $\\Rightarrow$ 3) By Proposition  \\ref{prop:central} there exists \n a $2$-central element $c=(\\e_1^{\\mathbf C},\\e_2^{\\mathbf D})\\in C$ of dimension $\\gamma(c)\\leq 2$ such that $\\mathbf C \\cong \\mathbf E/\\theta(c,\\e_1^\\mathbf E)$ and $\\mathbf D \\cong \\mathbf E/\\theta(c,\\e_2^\\mathbf E)$. \n By Lemma \\ref{lem:ground} and  the minimality of $\\mathbf E$ there exists a ground $\\tau(\\e)$-term $t=t(\\e_1,\\e_2)$ such that $c=t^\\mathbf C$. Let $t^*=t^*(v_1,v_2)$ be the $\\tau$-term corresponding to $t$ (see Section \\ref{sec:mca}). By $\\mathbf C \\cong \\mathbf E/\\theta(c,\\e_1^\\mathbf E)$ and $\\mathbf D \\cong \\mathbf E/\\theta(c,\\e_2^\\mathbf E)$ we get $\\mathrm{Var}(\\mathbf C_\\tau) \\models t^*(v_1,v_2)=v_1$ and $\\mathrm{Var}(\\mathbf D_\\tau) \\models t^*(v_1,v_2)=v_2$. Hence, the varieties $\\mathrm{Var}(\\mathbf C_\\tau)$ and $\\mathrm{Var}(\\mathbf D_\\tau)$ are independent.\n\n(3 $\\Rightarrow$ 1) Let $t(v_1,v_2)$ be a $\\tau$-term such that $\\mathrm{Var}(\\mathbf C_\\tau) \\models t(v_1,v_2)=v_1$ and $\\mathrm{Var}(\\mathbf D_\\tau) \\models t(v_1,v_2)=v_2$. Then $\\mathbf E$ is minimal, because every pair $(u,w)\\in E$ coincides with the interpretation of the $\\tau$-term $t(u,w)$. \n%Let $T,U$ be the equational theories respectively axiomatising $\\mathrm{Var}(\\mathbf C_\\tau)$ and $\\mathrm{Var}(\\mathbf D_\\tau)$. Then $T\\cap U$ axiomatises $\\mathrm{Var}(\\mathbf C_\\tau)\\lor \\mathrm{Var}(\\mathbf D_\\tau)$, $\\mathbf D$ is minimal and $t^\\mathbf D$ is $n$-central. It follows that $\\mathbf D\\cong \\mathbf C_1\\times\\dots\\times\\mathbf C_n=\\mathbf C$. Then we get (ii).By \\cite[Theorem 1]{KP09} $\\mathcal W=\\mathcal V_1\\times\\dots\\times\\mathcal V_n$. Since $\\mathbf D\\cong \\mathbf C_1\\times\\dots\\times\\mathbf C_n$ and $\\mathbf D$ is minimal, then \n\nWe conclude with the last implication. If $\\mathbf E$ is minimal, then  by Theorem \\ref{thm:ch2} $\\mathbf E_\\tau$ is the free algebra of the variety $\\mathrm{Var}(\\mathbf E_\\tau)$ and $\\mathbf E_\\tau = \\mathbf C_\\tau\\times \\mathbf D_\\tau$. Then $t^*(v_1,v_2)^{\\mathbf E_\\tau}$ is a decomposition operator on $\\mathbf E_\\tau$ giving the decomposition $\\mathrm{Var}(\\mathbf E_\\tau)=\\mathrm{Var}(\\mathbf C_\\tau)\\times \\mathrm{Var}(\\mathbf D_\\tau)$.\n\\end{proof}\n\n\\begin{theorem}\\label{thm:allvar}\n  Let $\\mathcal V,\\mathcal W$ be subvarieties of a variety $\\mathcal T$ of type $\\tau$, $\\mathbf C=\\mathbf{Cl}(\\mathcal V)$,  \n  $\\mathbf D=\\mathbf{Cl}(\\mathcal W)$ and $\\mathbf E= \\mathbf C\\times\\mathbf D$.\n  %$\\mathbf C=\\mathbf C_1\\times\\mathbf C_2$, $M(\\mathbf C)$ be the minimal clone $\\tau$-subalgebra of $\\mathbf C$ and $c=(\\e_1^{\\mathbf C_1},\\e_2^{\\mathbf C_n})\\in C$ be the $2$-central element making the above decomposition. \n Then the following conditions are equivalent:\n\\begin{itemize}\n\\item[(i)] The varieties $\\mathcal V$ and $\\mathcal W$ are independent.\n\\item[(ii)] $\\mathbf E=M(\\mathbf E)$.\n \\item[(iii)] $\\mathbf E=\\mathbf C\\odot\\mathbf D$.\n \\item[(iv)] $\\mathcal V\\lor\\mathcal W=\\mathcal V\\times\\mathcal W= \\mathcal V\\odot W$.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof} By Proposition \\ref{prop:varind}.\n\\end{proof}\n\nThe generalisation of Theorem \\ref{thm:allvar} to an arbitrary finite number of varieties is trivial.\n\n  Let $\\mathbf C$ be a clone $\\tau$-algebra, $\\mathbf D$ be a  clone $\\nu$-algebra and $f: \\mathbf C\\to \\mathbf D$ be a pure homomorphism. The \\emph{$f$-expansion} of $\\mathbf D$ is the clone $\\tau$-algebra $\\mathbf D^f=(\\mathbf D^f_\\tau, q_n^\\mathbf D, \\e_i^\\mathbf D)$, where $\\mathbf D^f_\\tau=(D,\\sigma^{\\mathbf D^f})_{\\sigma\\in\\tau}$ and  $\\sigma^{\\mathbf D^f}$ ($\\sigma\\in\\tau$ of arity $n$) is the $n$-ary operation such that\n$\\sigma^{\\mathbf D^f}(\\e_1^\\mathbf D,\\dots,\\e_n^\\mathbf D)= f(\\sigma^\\mathbf C(\\e_1^\\mathbf C,\\dots,\\e_n^\\mathbf C))$. \n\nIf $\\mathbf C$ is minimal and $f$ is onto, then $\\mathbf D^f$ is also minimal.\n\n\nThe following theorem is a generalisation of Theorem \\ref{thm:allvar} to  varieties of arbitrary type.\n\n\\begin{theorem}\\label{thm:gra} Let $\\mathcal V_1$ be a variety of type $\\tau_1$ and $\\mathcal V_2$ be a variety of type $\\tau_2$. Then there exists a type $\\nu$ and varieties $\\mathcal W_1,\\mathcal W_2$ of type $\\nu$ satisfying the following conditions:\n\\begin{enumerate}\n\\item $\\mathcal W_i$ is equivalent to $\\mathcal V_i$, for  $i=1,2$.\n\\item The varieties $\\mathcal W_1$ and $\\mathcal W_2$ are independent.\n\\item $\\mathcal V_1\\odot\\mathcal V_1=\\mathcal W_1\\vee\\mathcal W_2=\\mathcal W_1\\times\\mathcal W_2$.\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{proof} \nLet $\\mathbf C=\\mathbf{Cl}(\\mathcal V_1)$  and $\\mathbf D=\\mathbf{Cl}(\\mathcal V_2)$. If we put $\\nu=\\rho_{\\mathbf C\\odot\\mathbf D}$, then $\\mathbf C\\odot\\mathbf D$ is the minimal clone $\\nu$-algebra of the $\\mathbf C\\odot\\mathbf D$-representable functions.\nSince the projections \n $\\pi_1: \\mathbf C\\odot\\mathbf D\\to \\mathbf C$ and $\\pi_2: \\mathbf C\\odot\\mathbf D\\to \\mathbf D$ are onto pure homomorphisms, then $\\mathbf C^{\\pi_1}$ and $\\mathbf D^{\\pi_2}$ are minimal clone $\\nu$-algebras.\nWe define $\\mathcal W_1= \\mathrm{Var}((\\mathbf C^{\\pi_1})_\\nu)$ and $\\mathcal W_2= \\mathrm{Var}((\\mathbf D^{\\pi_2})_\\nu)$.\nSince $ \\mathbf C\\odot\\mathbf D= \\mathbf C^{\\pi_1}\\odot  \\mathbf D^{\\pi_2}$, by Theorem \\ref{thm:allvar} we get the conclusion.\n% \n%\n%\n%\n%\n%\n%If  $\\rho_\\mathbf E$ is the $\\mathbf E$-type introduced in Definition \\ref{def:ctype}, then \n%$\\overline{\\mathbf E}_\\rho=(\\mathbf E_{\\rho_\\mathbf E},q_n^\\mathbf E,\\e_i^\\mathbf E)$ is the minimal clone $\\rho_\\mathbf E$-algebra of $\\mathbf E$-representable functions (see Definition \\ref{def:ctype}). \n%Consider the following minimal clone $\\rho_\\mathbf C$-algebras:\n%the $\\pi_1$-expansion $\\mathbf C^{\\pi_1}$ of $\\mathbf C$ and the $\\pi_2$-expansion $\\mathbf D^{\\pi_2}$ of $\\mathbf D$ (see Definition \\ref{def:exp}).\n%\n%We have the following varieties of $\\rho_\\mathbf E$-algebras:\n%$\\mathrm{Var}(\\mathbf C^{\\pi_1}_{\\rho_\\mathbf E})$, $\\mathrm{Var}(\\mathbf D^{\\pi_2}_{\\rho_\\mathbf E})$ and\n%$\\mathrm{Var}(\\mathbf E_{\\rho_\\mathbf E})$\n\\end{proof}\n\n%We give an immediate application of the previous theorem providing a new proof of the Zipper condition based on commutator theory.\n%\n%Every clone algebra has a left zero and left one: \n%$$x*y := q_2(x,y,\\e_2);\\quad 0=\\e_2;\\quad 1=\\e_1;\\quad  q_2(\\e_1,x,\\e_2)=x;\\quad q_2(\\e_2,x,\\e_2)=\\e_2$$\n%The following lemma can be obtained by Definition 3.2 and the proof of Lemma 3.4 in \\cite{mac2}.\n%\n%\\begin{lemma}\n%  If $\\mathbf A$ is an algebra with a binary operation $*$ which has a left zero and left one, then $\\mathrm{Con}(\\mathbf A)$ satisfies the commutator equation $[1, x] = x$. \n%\\end{lemma}\n%\n%\\begin{proof}\n%Let $[1,x]=x$. We prove the Zipper condition. Assume $a+b=1$ and $ax=bx$.\n%Since $C(b,x;bx)$, then $C(b,x;ax)$ and\n%$C(a,x;ax)$. By \\cite[Proposition 1.2(4)]{lip} we obtain\n% $C(a+b,x;ax)$, that implies\n%$x=[1,x]=[a+b,x] \\leq ax\\leq a$.\n%\n%Let $w_n=(((a_0 x) + a_1)  x)+ \\dots )  x)+ a_n=w_{n-1}x+a_n$. \n%We have $w_n \\geq x(a_n+xw_n)$\n%\n%$w_n \\geq x(a_{n-1}+xw_n)=x(a_{n-1}+x(w_{n-1}x+a_n))$\n%\n%Anzi, direi che, per varieta', (*) e' equivalente ad [1,x]=x, ma questo\n%non dovrebbe essere utile.\n%\n%Se, oltre a soddisfare [1,x]=x, la varieta' e' anche modulare, allora\n%\n%(**) a+b=1 implica x=ax+bx, \n%\n%perche' x=[1,x]=[a+b,x]=[a,x]+[b,x] minore o uguale a ax+bx min o ug x .\n%\\end{proof}\n\n\\section*{Conclusions}\n\nAll the original results presented in this paper stem from the definition of clone algebra, that is, therefore, the main contribution of this work.  The results listed below give evidence of the relevance\nof the notion of clone algebra, that goes beyond providing a neat algebraic treatment of clones. Indeed, unexpected applications and promising further direction, as those we are going to describe, are often marks of the relevance and versatility of a new mathematical notion.\n\\begin{itemize}\n\\item Theorem \\ref{thm:main}, the representation theorem, \nensures that the variety of clone algebras provides \nan algebraic theory of clones.\n\\item In Theorem \\ref{thm:BM}, by endowing free algebras with the structure \nof clone algebras, and clone algebras with the structure of free algebras, we are able to characterise the lattices of \nequational theories, thus providing a possible answer to a classical \nopen question. \n\\item Theorem \\ref{thm:allvar}, and other results presented in Section \\ref{sec:allvar},\nshow that clone algebras may be used to study other classical topics in universal algebras, like the equivalence and the independence of varieties.\n\\end{itemize}\n\nThe focus of the present paper is on the representation theorems and their meaning for the theory of clones and $\\omega$-clones, \n and partly on the categorical aspects of clone algebras illustrated in the last section of the paper. A closer examination of potential implications  to universal algebra is deferred to future work that is currently in progress. \n We have here space to describe two possible directions of research.\n\nWe intend to analyse the relationship between a variety $\\mathcal V$ of pure clone algebras and the corresponding subcategory $\\mathbb{C}(\\mathcal V)$ of\n$\\mathcal{VAR}$, where a variety $\\mathcal W$ of $\\tau$-algebras belongs to  $\\mathbb{C}(\\mathcal V)$ if the pure reduct of the clone $\\mathcal W$-algebra $\\mathbf{Cl}(\\mathcal W)$ is an element of $\\mathcal V$. We explain with an example the kind of connection we are looking for. \nAssume that the class of indecomposable members of $\\mathcal V$ is a universal class.\n  Since $\\mathcal V$ is also a variety of $2\\mathrm{CH}$s, then by \\cite[Theorems 3.8,  3.9]{first} every member of $\\mathcal V$ is a weak Boolean product of a family of indecomposable members of $\\mathcal V$. We are interested in understanding how this weak Boolean representation influences the structure of the category $\\mathbb{C}(\\mathcal V)$.\n\nThere are some classical concepts of the theory of clones that have a more general and algebraic formulation within the theory of $\\omega$-clones. For example, if $F$ is an $\\omega$-clone and $f\\in F$, then the centralizer $f^*$ (of the infinitary operations commuting with $f$) is a subalgebra of the pure $\\mathsf{FCA}$ $\\mathbf F=(F,q_n^\\omega,\\e_i^\\omega)$. \nWe are interested in understanding whether the centralizer is invariant up to isomorphism of pure $\\mathsf{FCA}$s.\n\n\n\n%We abstract the centralizer to arbitrary pure clone algebras as follows.  Let $\\mathbf C$ be a pure clone algebra and $c\\in C$. By the functional representation theorem there exists a set $A$, a pure $\\mathsf{FCA}$ $\\mathbf B$ with value domain $A$ and an isomorphism $\\alpha: \\mathbf B\\to \\mathbf C$. \n%We define the centralizer of $c$ to be the set $\\{\\alpha(f) :  f$ commutes with  $\\alpha^{-1}(a)\\}$. Is this definition independent of the choice of the $\\mathsf{FCA}$ $\\mathbf B$ isomorphic to $\\mathbf C$?\n\n\n\n \n%\\begin{example} Let $\\mathbf A$ be any algebra ($n\\mathrm{CH}$) and $\\mathrm{Con}\\,\\mathbf A$ be its congruence lattice.\n%By Example \\ref{exa:elleomega} $(\\mathrm{Con}\\,\\mathbf A)^\\omega$ is a pure clone algebra. Let $\\mathbf B$ be the subalgebra of $(\\mathrm{Con}\\,\\mathbf A)^\\omega$ constituted by all the sequences for which there is an $n$ such that\n%$$(\\theta_1,\\dots,\\theta_n,\\nabla,\\dots,\\nabla,\\dots).$$\n% Then $(\\theta_1,\\dots,\\theta_n,\\nabla,\\dots,\\nabla,\\dots)$ is $n$-central in $(\\mathrm{Con}\\,\\mathbf A)^\\omega$ iff $(\\theta_1,\\dots,\\theta_n)$ is tuple of complementary factor congruences of $\\mathbf A$.\n%\\end{example}\n\n\n\n\n\\section*{Appendix}\nIn this Appendix we conclude the proof of Theorem \\ref{thm:main}.\n\nIn the following lemma we prove that  \na $\\mathsf{RCA}_\\tau$   $\\mathbf B$ with value domain $\\mathbf A$ can be embedded into the ultrapower $(\\mathbf O_{ \\mathbf A}^{(\\omega)})^\\omega/U$ of the full $\\mathsf{FCA}_\\tau$ $\\mathbf O_{ \\mathbf A}^{(\\omega)}$,\nfor every   nonprincipal ultrafilter $U$  on $\\omega$. \n\n\\begin{lemma}\\label{lem:ultrapower}\n Every $\\mathsf{RCA}_\\tau$ can be embedded  into an ultrapower of a $\\mathsf{FCA}_\\tau$. \n\\end{lemma}\n\n\\begin{proof}\n Let  $U$ be a nonprincipal ultrafilter on $\\omega$ that contains the set $\\{j: j\\geq i\\}$ for every $i\\in\\omega$. \n$U$ does not contain finite sets.\n%Hence $F$ contains $K_e=\\{j: e\\subseteq j\\}$ for each finite $e\\subseteq \\omega$.\nLet $\\mathbf O_{ \\mathbf A,r}^{(\\omega)}$ be the full $\\mathsf{RCA}$ with value domain $\\mathbf A$ and thread $r$. Let $F_{r, n}$ be the function defined in Lemma \\ref{lem:red}. We prove that the map\n$$h(\\varphi)=\\langle F_{r, n}(\\varphi): n\\in\\omega\\rangle /U,\\quad \\text{for all $\\varphi\\in \\mathcal O_{A,r}^{(\\omega)}$}$$\nis an embedding of the full $\\mathsf{RCA}$ $\\mathbf O_{ \\mathbf A,r}^{(\\omega)}$ into the  ultrapower $(\\mathbf O_{ \\mathbf A}^{(\\omega)})^\\omega/U$ of the full $\\mathsf{FCA}$ $\\mathbf O_{ \\mathbf A}^{(\\omega)}$ with value domain $\\mathbf A$.\n\nWe prove that $h$ is injective. If $h(\\varphi)=h(\\psi)$ then $\\{ n: F_{r, n}(\\varphi)=F_{r, n}(\\psi)\\}\\in U$. Then, for every $i\\in\\omega$, by the hypothesis on $U$ we have:\n$$\\{j: j\\geq i\\}\\cap \\{ n: F_{r, n}(\\varphi)=F_{r, n}(\\psi)\\}\\ \\text{is an infinite set}.$$\nThen there exists an increasing sequence $k_1 < k_2 <\\dots < k_i <\\dots$ of natural numbers such that \n$k_i\\in \\{j: j\\geq i\\}\\cap \\{ n: F_{r, n}(\\varphi)=F_{r, n}(\\psi)\\}$ and $k_i > k_{i-1}$.\nLet $s\\in A^\\omega_r$ such that $s=r[s_1,\\dots,s_m]$. \nLet $k_n>m$. Then $s=r[s_1,\\dots,s_m] = r[s_1,\\dots,s_m,r_{m+1},\\dots,r_{k_n}]$ and  we have:\n\\[\n\\begin{array}{llll}\n\\varphi(s)  &  = &  \\varphi(r[s_1,\\dots,s_m,r_{m+1},\\dots,r_{k_n}]) &\\\\\n  &  = & F_{r, k_n}(\\varphi)(s)  &\\text{by def. $F_{r, k_n}$} \\\\\n  &  = &    F_{r, k_n}(\\psi)(s)&\\text{by $k_n\\in \\{ n: F_{r, n}(\\varphi)=F_{r, n}(\\psi)\\}$}\\\\\n    &  = & \\psi(r[s_1,\\dots,s_m,r_{m+1},\\dots,r_{k_n}])&\\\\\n&  = & \\psi(s).&\n\\end{array}\n\\]\nBy the arbitrariness of $s$ it follows that $\\varphi=\\psi$.\nWe now prove that $h$ is a homomorphism. \n\\[\\begin{array}{llll}\n&   &h(q^r_k(\\varphi,\\psi_1,\\dots,\\psi_k))& \\\\\n & =  & \\langle F_{r, n}(q^r_k(\\varphi,\\psi_1,\\dots,\\psi_k)): n\\in\\omega\\rangle /U & \\\\\n  & =  & \\langle q^\\omega_k(F_{r, n}(\\varphi),F_{r, n}(\\psi_1),\\dots,F_{r, n}(\\psi_k)): n\\in\\omega\\rangle /U& \\\\\n\\end{array}\n\\]  \nbecause by Lemma \\ref{lem:red} $\\{n:F_{r, n}(q^r_k(\\varphi,\\psi_1,\\dots,\\psi_k))=q^\\omega_k(F_{r, n}(\\varphi),F_{r, n}(\\psi_1),\\dots,F_{r, n}(\\psi_k)) \\}\\supseteq \\{n: n\\geq k\\}\\in U$.\nLet $\\mathbf B=\\mathbf O_{ \\mathbf A}^{(\\omega)}$. By definition of $q^{\\mathbf B^\\omega/U}_k$, we obtain\n\\[\\begin{array}{llll}\n   &   & q^{\\mathbf B^\\omega/U}_k(h(\\varphi),h(\\psi_1),\\dots,h(\\psi_k))&\\\\\n  &  = &  q^{\\mathbf B^\\omega/U}_k (\\langle F_{r, n}(\\varphi): n\\in\\omega\\rangle /U, \\langle F_{r, n}(\\psi_1): n\\in\\omega\\rangle /U,\\dots, \\langle F_{r, n}(\\psi_k): n\\in\\omega\\rangle /U)&\\\\\n  & =  & \\langle q^\\omega_k(F_{r, n}(\\varphi),F_{r, n}(\\psi_1),\\dots,F_{r, n}(\\psi_k)): n\\in\\omega\\rangle /U.& \\\\  \n\\end{array}\n\\]\nMoreover, \n$h(\\e_i^r)=\\langle F_{r, n}(\\e_i^r): n\\in\\omega\\rangle /U = \\langle \\e_i^\\omega: n\\in\\omega\\rangle /U$\nbecause \n$\\{n:F_{r, n}(\\e_i^r)=\\e_i^\\omega \\}\\supseteq \\{n: n\\geq i\\}\\in U$.\nA similar computation works for $\\sigma\\in\\tau$.\n\\end{proof}\n\nThe product of a family of $\\mathsf{FCA}_\\tau$s can be embedded into a  $\\mathsf{FCA}$ whose value domain is the product of the value domains of the family.\n\n\\begin{lemma}\\label{lem:subprod}\nThe class $\\mathbb I\\,\\mathsf{FCA}_\\tau$ is  closed under subalgebras and direct products.\n\\end{lemma}\n\n\\begin{proof}\n  The class of $\\mathsf{FCA}_\\tau$'s is trivially closed under subalgebras. It is also closed under products,\nbecause $\\prod_{i\\in H} \\mathbf B_i$, where $\\mathbf B_i$ is a $\\mathsf{FCA}_\\tau$ with value domain $\\mathbf A_i$,\ncan be embedded into the full $\\mathsf{FCA}_\\tau$ with value domain $\\prod_{i\\in H}\\mathbf A_i$: the  sequence\n$\\langle \\varphi_i: A_i^\\omega \\to A_i\\in B_i\\ |\\ i\\in H\\rangle$ maps to $\\varphi : (\\prod_{i\\in H} A_i)^\\omega \\to \\prod_{i\\in H} A_i$ defined by $\\varphi(r)= \\langle \\varphi_i(\\langle r_j(i):j\\in\\omega\\rangle)\\ |\\ i\\in H\\rangle$.\n\\end{proof}\n\n%\\begin{corollary}\n% Let $\\mathbf B_i$ be a $\\mathsf{FCA}_\\tau$ with value domain $\\mathbf A_i$ ($i\\in H$). Then  the product $\\prod_{i\\in H} \\mathbf B_i$ can be embedded into the full $\\mathsf{FCA}_\\tau$ with value domain $\\prod_{i\\in H}\\mathbf A_i$.\n%\\end{corollary}\n\n\\begin{lemma}\\label{lem:ultrafca}\nUltrapowers of $\\mathsf{FCA}_\\tau$s are isomorphic to $\\mathsf{FCA}_\\tau$s.\n\\end{lemma}\n\n\\begin{proof} \n Let $\\mathbf B$ be a $\\mathsf{FCA}$ with value domain $\\mathbf A$,  $K$ be a set and $U$ be any ultrafilter on $K$.  By Lemma \\ref{lem:subprod} we get the conclusion if the ultrapower $\\mathbf B^K/U$ is isomorphic to a subdirect product of $\\mathsf{FCA}$s.\n\n A choice function is a function\n $ch: A^K/U\\to A^K$  such that $ch(w/U)\\in w/U$ for every $w\\in A^K$ (see \\cite[Section 6]{SG99}). \n Any choice function $ch$ induces a function $ch^+ : (A^K/U)^\\omega \\to (A^\\omega)^K$:\n $$ch^+(r)_k = \\langle ch(r_i)_k: i\\in \\omega \\rangle,\\qquad\\text{for every $r\\in (A^K/U)^\\omega$ and $k\\in K$.} $$\n We use the choice function $ch$ to define a function $h_{ch}: B^K/U\\to \\mathcal O_{A^K/U}^{(\\omega)}$ as follows:\n $$h_{ch}(u/U)(r)=\\langle u_k(ch^+(r)_k): k\\in K\\rangle/U,\\quad\\text{for every $u\\in B^K$ and $r\\in (A^K/U)^\\omega$}.$$\n The map $h_{ch}$ is a homomorphism from the ultrapower $\\mathbf B^K/U$ into the full $\\mathsf{FCA}$  $\\mathbf O_{\\mathbf A^K/U}^{(\\omega)}$ with value domain $\\mathbf A^K/U$. \n Let $\\mathbf C:= \\mathbf B^K/U$, $\\mathbf D:=\\mathbf O_{\\mathbf A^K/U}^{(\\omega)}$, $r\\in (A^K/U)^\\omega$ and $s_k:= ch^+(r)_k\\in A^\\omega$.\n  \\[\n\\begin{array}{llll}\nh_{ch}(\\e_i^\\mathbf C)(r)&=& h_{ch}(\\langle\\e_i^\\mathbf B:k\\in K\\rangle/U)(r)&\\\\\n&=&h_{ch}(\\langle\\e_i^\\omega:k\\in K\\rangle/U)(r)&\\text{by $\\mathbf B\\in \\mathsf{FCA}$ and Lemma \\ref{lem:fun}}\\\\\n&=&\\langle \\e_i^\\omega(ch^+(r)_k): k\\in K\\rangle/U&\\text{by def. $h_{ch}$}\\\\\n&=&\\langle ch(r_i)_k: k\\in K\\rangle/U &\\text{by def. $ch^+$ and $\\e_i^\\omega$}\\\\ \n&=& ch(r_i)/U&\\\\ \n&=& r_i&\\text{by $ch(r_i)\\in r_i$}\\\\ \n \\end{array}\n\\]\nWithout loss of generality, we prove that $h_{ch}$ preserves $q_2^\\mathbf C$.\n \\[\n\\begin{array}{llll}\n&&h_{ch}(q_2^\\mathbf C(u/U,w^1/U,w^2/U))(r)& \\\\\n &  = & h_{ch}( \\langle q_2^\\mathbf B(u_k,w^1_k,w^2_k): k\\in K\\rangle/U)(r) &\\text{by def. $q_2^\\mathbf C$}\\\\\n &  = &  \\langle q_2^\\mathbf B(u_k,w^1_k,w^2_k)(s_k): k\\in K\\rangle/U &\\text{by def. $h_{ch}$}\\\\\n  & =  & \\langle q_2^\\omega(u_k,w^1_k,w^2_k)(s_k): k\\in K\\rangle/U&\\text{by $\\mathbf B\\in \\mathsf{FCA}$ and Lemma \\ref{lem:fun}}  \\\\\n  & =  &    \\langle u_k(s_k[w^1_k(s_k),w^2_k(s_k)]): k\\in K\\rangle/U&\\text{by def.  $q_2^\\omega$}\\\\\n  & =  &    \\langle u_k(ch^+(r)_k[w^1_k(s_k),w^2_k(s_k)]): k\\in K\\rangle/U&\\text{by def.  $s_k$}\\\\\n  & =  &    \\langle u_k( \\langle ch(r_i)_k: i\\in \\omega \\rangle[w^1_k(s_k),w^2_k(s_k)]): k\\in K\\rangle/U&\\text{by def.  $ch^+$}\\\\\n    & =  &    \\langle u_k(w^1_k(s_k),w^2_k(s_k), ch(r_3)_k,ch(r_4)_k,\\dots): k\\in K\\rangle/U&\\\\\n\n\\end{array}\n\\]\n\nLet $t=r[\\langle w^1_j(s_j): j\\in K\\rangle/U, \\langle w^2_j(s_j): j\\in K\\rangle/U]$. \n \\[\n\\begin{array}{llll}\n&&q_2^\\omega(h_{ch}(u/U),h_{ch}(w^1/U),h_{ch}(w^2/U))(r)&\\\\\n&=& h_{ch}(u/U)(r[h_{ch}(w^1/U)(r),h_{ch}(w^2/U)(r)]) & \\text{by def.  $q_2^\\omega$}\\\\\n&=&h_{ch}(u/U)(r[\\langle w^1_j(s_j): j\\in K\\rangle/U, \\langle w^2_j(s_j): j\\in K\\rangle/U])&\\text{by def.  $h_{ch}$}\\\\\n&=& \\langle u_k(ch^+(t)_k): k\\in K\\rangle/U&  \\text{by def.  $h_{ch}$} \\\\\n&=& \\langle u_k(\\langle ch(t_i)_k : i\\in \\omega \\rangle): k\\in K\\rangle/U& \\text{by def.  $ch^+$}  \\\\\n&=& \\langle u_k( ch(t_1)_k, ch(t_2)_k, ch(t_3)_k,ch(t_4)_k,\\dots): k\\in K\\rangle/U&   \\\\\n&=& \\langle u_k( ch(t_1)_k, ch(t_2)_k, ch(r_3)_k,ch(r_4)_k,\\dots): k\\in K\\rangle/U& \\text{by def.  $t$}  \\\\\n&=& \\langle u_k( ch(\\langle w^1_j(s_j): j\\in K\\rangle/U)_k, ch(\\langle w^2_j(s_j): j\\in K\\rangle/U)_k, &\\\\\n&&\\qquad\\qquad\\qquad ch(r_3)_k,ch(r_4)_k,\\dots): k\\in K\\rangle/U& \\text{by def.  $t$}  \\\\\n    & =  &    \\langle u_k(w^1_k(s_k),w^2_k(s_k), ch(r_3)_k,ch(r_4)_k,\\dots): k\\in K\\rangle/U&\\\\\n\\end{array}\n\\]\nbecause $\\{k\\in K : ch(\\langle w^i_j(s_j): j\\in K\\rangle/U)_k =w^i_k(s_k) \\}\\in U$ ($i=1,2$). A similar proof works for $\\sigma\\in\\tau$.\n%We show that $s_k[w^1_k(s_k),\\dots,w^n_k(s_k)]= ch^+(t)_k$ as elements of $A^\\omega$.\n%We distinguish $i\\leq n$ and $i>n$.\n%\\begin{itemize}\n%\\item ($i>n$): $(s_k[w^1_k(s_k),\\dots,w^n_k(s_k)])(i)= (s_k)(i)=(ch^+(r)_k)(i)=ch(r_i)_k$;\n%\\item ($i>n$): $(ch^+(t)_k)(i)=ch(t_i)_k=ch(r_i)_k$;\n%\\item ($i\\leq n$): $(s_k[w^1_k(s_k),\\dots,w^n_k(s_k)])(i)=w^i_k(s_k)$;\n%\\item ($i\\leq n$): $(ch^+(t)_k)(i)=ch(t_i)_k= ch(\\langle w^i_j(s_j): j\\in K\\rangle/U)_k$\n%\\end{itemize}\nHence a homomorphic image of the ultrapower $\\mathbf B^K/U$ is isomorphic to a $\\mathsf{FCA}$.\n \n By \\cite[Lemma 8.2]{BS} we have that the ultrapower $\\mathbf B^K/U$ is isomorphic to a subdirect product of $\\mathsf{FCA}$s if the family of maps $h_{ch}$ (indexed by choice functions) satisfies the following property: for all distinct $w/U, u/U\\in B^K/U$ there exists a choice function $ch$ for which $h_{ch}(w/U)\\neq h_{ch}(u/U)$. We are going to prove this fact.\n \n Let $w = \\langle w_i:A^\\omega\\to A:i\\in K\\rangle$ and  $u = \\langle u_i:A^\\omega\\to A:i\\in K\\rangle$.\n For every $j\\in K$, let $\\rho_j\\in A^\\omega$ such that $w_j(\\rho_j)\\neq u_j(\\rho_j)$ whenever $w_j\\neq u_j$. For every $i\\in\\omega$, let $r_i\\in A^K$ such that $r_i(j)=\\rho_j(i)$ for all $j\\in K$. Define $s\\in (A^K/U)^\\omega$ as $s_i=r_i/U$ and consider any choice function $ch$ such that $ch(s_i)=r_i$. Then we have\n$h_{ch}(w/U)(s)=\\langle w_j(\\rho_j): j\\in K)\\rangle/U$ and $h_{ch}(u/U)(s)=\\langle u_j(\\rho_j): j\\in K)\\rangle/U$, but\n$\\{j: w_j(\\rho_j)=u_j (\\rho_j)\\}=\\{j: w_j= u_j\\} \\notin U$.\nsince $w/U\\neq u/U$. It follows that $h_{ch}(w/U)(s)\\neq h_{ch}(u/U)(s)$ and then $h_{ch}(w/U)\\neq h_{ch}(u/U)$.\n \\end{proof}\n \n \n\\begin{corollary} Let $\\mathbf B$ be a $\\mathsf{FCA}$ with value domain $\\mathbf A$ and $U$ be an ultrafilter on $\\omega$.\nThen there exists a set $J$ of the same cardinality as $B$ such that the ultrapower $\\mathbf B^\\omega/U$ is isomorphic to a $\\mathsf{FCA}$ with value domain\n$(\\mathbf A^\\omega/U)^J$.\n\\end{corollary}\n\n\n\\begin{thebibliography}{99}\n\n\\bibitem{B14} Behrisch, M., Clones with Nullary Operations. ENTCS vol. 303, 2014, pp. 3--35. doi:10.1016/j.entcs.2014.02.002\n\n\\bibitem{bir2} Birkhoff G.,  Universal algebra, Proceedings of the First Canadian Mathematical Conference,\nUniversity of Toronto Press, 1946, pp. 310--326.\n\n\\bibitem{bir} Birkhoff G., \\emph{Lattice Theory}, Third Edition, AMS Colloquium Publications 25, American Mathematical Society, Providence, RI, 1967.\n\n\\bibitem {BP} Blok W. J.  and Pigozzi D.,  On the structure of varieties with equationally definable principal congruences III, Algebra Universalis,  32, 1994, pp. 545--608.\n\n\\bibitem{BLPS18}  Bucciarelli A., Ledda A., Paoli F. and Salibra A., Boolean-like algebras of finite dimension, Preprint, 2018, arXiv:1806.06537 [cs.LO].\n\n\\bibitem{Bucciasali} Bucciarelli A. and Salibra A., On noncommutative generalisations of Boolean algebras. The Art of Discrete and Applied Mathematics, 2(2), 2019, \\#P2.07; https://doi.org/10.26493/2590-9770.1323.ceb \n\n\\bibitem{BS} Burris S. and Sankappanavar H. P., \\emph{A Course in Universal Algebra}, Graduate Texts in Mathematics, no. 78, Springer-Verlag, New York, 1981.\n\n\n%\\bibitem{CP} Clifford A., Preston G., \\emph{The algebraic theory of semigroup}s, Vol. 1, Mathematical surveys, No. 7, AMS Providence, 1964.\n\n\\bibitem{Co65} Cohn, P. M., \\emph{Universal algebra}, Harper \\& Row Publishers, New York, 1965.\n\n%\\bibitem{davey} Davey B.A.,  Knox B.J., From rectangular bands to k-primal algebras, Semigroup Forum, 2002.\n\n%\\bibitem{dicker} Dicker R. M., The substitutive law, Proc. London Math. Soc. 13, 1963, pp. 493--510.\n\n\\bibitem{D63} Dicker R.M., A set of independent axioms for Boolean algebra, Proc. London\nMath. Soc., 3,  1963, pp. 20--30.\n\n\\bibitem{evans} Evans T., Some remarks on the general theory of clones, Colloquia Mathematica Societatis \nJ\\'ainos Bolyai 28. Finite algebra and multiple-valued logic. Szeged (Hungary), 1979, pp. 203--244.\n\n%\\bibitem{FH} Fraser G. A.  and Horn A., Congruence relations in direct products. Proc. Amer. Math. Soc., 26, 1970, pp. 390--394.\n%\\bibitem{FM} Freese R., McKenzie, R. N., \\emph{Commutator Theory for Congruence Modular Varieties}, Cambridge University Press, 1987.\n\n\\bibitem{GLP} Gr\\\"atzer G., Lakser H. and P\\l onka J., Joins and direct products of equational classes, Canadian Mathematical Bulletin, 12, 1969, pp. 741--744.\n\n\\bibitem{HMT} Henkin, L., Monk, J. D., and Tarski, A., \\emph{Cylindric Algebras, Parts I and II}, (1971, 1985),\nNorth-Holland, Amsterdam.\n%\\bibitem{HM} Hirokawa N., Middeldorp A.,  ``Tyrolean termination tool: Techniques and features'', \\emph{Information and Computation}, 205, 2007, pp. 474--511.\n\n%\\bibitem{howie} Howie J. M., \\emph{Fundamentals of semigroup theory}, Oxford University Press, 1995.\n\n%\\bibitem{kle} Klein-Barmen F., \\\"{U}ber eine weitere Verallgerneinerung des Verbandsbegriffes, Math. Z. 46, 1940, pp. 477--480.\n\n%\\bibitem{ttt}  Korp M., Sternagel C.,  Zankl H.,  Middeldorp A., ``The Tyrolean Termination Tool 2'', \\textrm{http://cl-informatik.uibk.ac.at/software/ttt2/}.\n\n\\bibitem{KP09}  Kowalski T. and  Paoli P., Joins and subdirect products of varieties, Algebra Universalis, 65(4), 2009, pp. 371--391.\n\n\\bibitem{KPL13} Kowalski T.,  Paoli P., and  Ledda A., On independent varieties and some related notions, Algebra Universalis, 70, 2013, pp. 107--136.\n\n\\bibitem{lampe} Lampe W.A., A property of the lattice of equational theories, Algebra Universalis 23, 1986, pp. 61--69.\n\n\\bibitem{L06} Lau D., \\emph{Function Algebras on Finite Sets:\nA Basic Course on Many-Valued Logic and Clone Theory}, Springer-Verlag, 2006.\n\n\\bibitem{Law63} Lawvere, F.W., Functorial semantics of algebraic theories, Proc. Nat. Acad. Sci. (USA), 50, 1963, pp. 869--872.\n\n%\\bibitem {LPS13} Ledda A. , Paoli F.  and Salibra A.  , On Semi-Boolean-like algebras, Acta Univ. Palacki. Olomuc., Fac. rer. nat., Mathematica,  52(1), 2013, pp. 101--120.\n\n\n%\\bibitem{lip} Lipparini P., Commutator theory without join-distributivity, Transactions of the American Mathematical Society, 346(1), 1994, pp. 177-202. \n\n\\bibitem{MC} McCarthy J., A basis for a mathematical theory of computation, In: Braffort P., Hirschberg D. (eds.), \\emph{Computer Programming and Formal Systems}, North-Holland, Amsterdam, 1963, pp. 33--70.\n\n\\bibitem{mal} Maltsev A.I., Some borderline problems of algebra and logic, Proc. Internat. Congr. Math. (Moscow, 1966), Mir Publishers, Moscow, 1968, pp. 217--231. [English translation in A.I. Mal'cev, \\emph{The metamathematics of algebraic systems}. Collected papers: 1936-1967, North-Holland Pub. Co., Amsterdam 1971, pp. 460--473.]\n\n%\\bibitem{mal2} Maltsev, A.I., Iterative algebras and Post varieties, in Metamathematics of Algebraic Systems, North Holland, Amsterdam, 1971.\n\n\\bibitem{MS08} Manzonetto G.  and Salibra A., \nFrom lambda calculus to universal algebra and back. in: \\emph{33th Int. Symp. on Math. Found. of Computer Science}, LNCS 5162, (2008),  pp. 479--490.\n\n\n\\bibitem{mac2} McKenzie R. N., Finite forbidden lattices, Proc. Fourth Int. Conf. on Universal Alg. and Lattice Theory, Puebla, 1982, LNM 1004, 1983, Springer-Verlag, Berlin, pp. 176--205.\n\n\\bibitem{mac} McKenzie R. N., McNulty G. F.,  Taylor W. F., \\emph{Algebras, Lattices, Varieties, Volume I}, Wadsworth Brooks, Monterey, CA, 1987.\n\n\\bibitem{nulty} McNulty, G.F.,  A Field Guide to Equational Logic, Journal of Symbolic Computation, 14, 1992, pp. 371--397.\n\n%\\bibitem{menger1} Menger K., The algebra of functions: past, present, future, Rend. Math. 20, 1961, pp. 409--430.\n\n%\\bibitem{menger2} Menger K., Superassociative systems and logical functors, Math. Ann. 157, 1964, pp. 278--295.\n\n%\\bibitem{menger3} Menger K., Whitlock H., Two theorems on the generations of systems of functions, Fund. Math. 58, 1966, pp. 229--240.\n\n\\bibitem{neu70} Neumann W.D., Representing varieties of algebras by algebras, J. Austral. Math. Soc., 11, 1970, pp. 1--8.\n\n\\bibitem{newrly} Newrly N., Lattices of equational theories are congruence lattices of monoids with one additional unary operation, Algebra Universalis 30, 1993, pp. 217--220.\n\n\\bibitem{nur} Nurakunov A.M.,  Equational theories as congruences of enriched monoids,\nAlgebra Universalis 58, 2008, pp. 357--372\n\n%\\bibitem{plonka} P\\l onka J., Diagonal algebras, Fundamenta Mathematicae 58, 1966, pp. 309--322 DOI: 10.4064/fm-58-3-309-322\n\n%\\bibitem{plonka2} P\\l onka J., Remarks on diagonal and generalized diagonal algebras, Colloq. Math. 15, 1966, pp. 19--23.\n\n%\\bibitem{post1} Post E., Introduction to a general theory of elementary propositions, American Journal of Mathematics, 43, 1921, pp. 163--185.\n\n%\\bibitem{post2} Post E., \\emph{Two-Valued Iterative Systems of Mathematical Logic}, Princeton University Press, Princeton, 1941.\n\n\\bibitem{SG99} Salibra A., Goldblatt R., A finite equational axiomatization of the functional algebras for the lambda calculus, Information and Computation, 148, 1999, pp. 71--130.\n\n\\bibitem{first} Salibra A., Ledda A., Paoli F.  and Kowalski T., Boolean-like algebras, \\emph{Algebra Universalis},  69(2), 2013, pp. 113--138.\n\n\n%\\bibitem{SLP18} Salibra, A.,  Ledda A. and Paoli F., Boolean product representations of algebras via binary polynomials, In J. Czelakowski (Ed.), \\emph{Don Pigozzi on Abstract Algebraic Logic, Universal Algebra, and Computer Science}, Outstanding Contributions to Logic Vol. 16, Springer-Verlag, 2018, pp. 297--321. \n\n\\bibitem{SBLP20} Salibra, A., Bucciarelli A., Ledda A. and Paoli F., Classical logic with $n$ truth values as a symmetric many-valued logic. Foundations of Science, 2020, DOI: 10.1007/s10699-020-09697-7 \n\n\\bibitem{sangalli} Sangalli A., On the structure and representation of clones,  Algebra Universalis, 25, 1988, pp. 101--106.\n\n%\\bibitem{ssm} Swamy U.M., Suryanarayana Murti G., Boolean centre of a universal algebra, Algebra Universalis, 13, 1981, pp. 202--205.\n\n\\bibitem{SZ86} Szendrei A., \\emph{Clones in Universal Algebra}, Les Presses de l'Universit\\'e de Montr\\'eal, 1986.\n\n\\bibitem{T93} Taylor, W., Abstract clone theory, I. G. Rosenberg and G. Sabidussi (eds.), Algebras and Orders, Kuwer Academic Publisher, 1993, pp. 507--530.\n\n%\\bibitem{tro} Trokhimenko, V. S., On some Menger algebras of multiplace transformations of ordered sets,  Algebra Universalis, 33, 1995, pp. 375--386.\n\n\\bibitem{vaggione} Vaggione D., Varieties in which the Pierce stalks are directly indecomposable, \\emph{Journal of Algebra}, 184, 1996, pp. 424--434.\n\n%\\bibitem{whi} Whitlock H., A composition algebra for multiplace functions, Math. Ann. 157, 1964, pp. 167--178.\n\n\\end{thebibliography}\n\n\n\n\\end{document}\n\n\\section{Central elements and Decomposition Operators }\n\n\\begin{lemma}\nLet $\\mathbf A$ be an algebra  and $f$ be  a  decomposition operator on \n$\\mathbf  A$. Then\n$\\langle f\\rangle$ contains only decomposition operators.\n\\end{lemma}\n\\begin{proof}\nLet  $g\\in\\langle f\\rangle$, $n$ and $k$ being the arities of $g$ and $f$,\nrespectively.\n\nIt is clear that $g(\\underbrace{x,\\ldots,x}_{n})=f(\\underbrace{x,\\ldots, x}_{k})=x$.\nFor the two remaining axioms of decomposition operators, we reason by cases analysis.\nLet $\\sigma$ be a basic operation of arity $l$ in the type of $\\mathbf A$, and\nlet us suppose first that  $f\\preceq g$ (i.e. that $k\\leq n$).\n\\begin{itemize}\n\\item \n\\begin{tabular}{l}\n$g(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_n^1,\\ldots,x_n^n))=f(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_k^1,\\ldots,x_k^n))=$\\\\\n$f(f(x_1^1,\\ldots,x_1^k),\\ldots,f(x_k^1,\\ldots,x_k^k))=f(x_1^1,\\ldots,x_k^k)=g(x_1^1,\\ldots,x_n^n)$\n\\end{tabular}\n\\item \n\\begin{tabular}{l}\n$g(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l))=f(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_k^1,\\ldots,x_k^l))=$\\\\\n$\\sigma(f(x_1^1,\\ldots,x_k^1),\\ldots,f(x_l^1,\\ldots,x_l^k))=\\sigma(g(x_1^1,\\ldots,x_n^1),\\ldots,g(x_1^l,\\ldots,x_n^l))$\n\\end{tabular}\n\nIf  $g\\preceq f$ (i.e. $k\\geq n$) we get similarly:\n\n\\item \n\\begin{tabular}{l}\n$g(g(x_1^1,\\ldots,x_1^n),\\ldots,g(x_n^1,\\ldots,x_n^n))=f(f(x_1^1,\\ldots,x_1^n, \\ldots),\\ldots,f(x_n^1,\\ldots,x_n^n,\\ldots),\\ldots)=$\\\\\n$f(x_1^1,\\ldots,x_n^n,\\ldots)=g(x_1^1,\\ldots,x_n^n)$\n\\end{tabular}\n\\item \n\\begin{tabular}{l}\n$g(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l))=f(\\sigma(x_1^1,\\ldots,x_1^l),\\ldots,\\sigma(x_n^1,\\ldots,x_n^l),\\ldots)=$\\\\\n$\\sigma(f(x_1^1,\\ldots,x_n^1,\\ldots),\\ldots,f(x_l^1,\\ldots,x_l^n,\\ldots))=\\sigma(g(x_1^1,\\ldots,x_n^1),\\ldots,g(x_1^l,\\ldots,x_n^l))$\n\\end{tabular}\n\\end{itemize}\n\\end{proof}\n\n\\begin{definition}\nA decomposition operator $f$ is {\\em proper} if it is the generator\nof $\\langle f\\rangle$.\n\\end{definition}\n\n\n\n\n\n\nLet $\\mathbf A$ be a $\\tau$-algebra. \nWe know by Lemma \\ref{} that the set of the strongly finite elements of \n$A^\\top$ is a subalgebra of ${\\mathbf A}^\\top$.\nAs a matter of terminology, let us call {\\em full and finite functional clone algebra  with value domain $\\mathbf A$}, written\nFFCA$\\mathbf A$, the algebra $(\\mathrm{Sf} A^\\top,\\sigma^\\top, q_n^\\top,e_i^\\top)_{n\\geq 0,i\\geq 1}$, and  {\\em finite functional clone algebra  with value domain $\\mathbf A$}, written\nFCA$\\mathbf A$ any subalgebra of FFCA$\\mathbf A$.\nGiven $f \\in\\mathrm{Sf} A^\\top$, its {\\em arity} $ar(f)$ is the smallest \n$n\\in\\mathrm N$ such that there exists $g\\in \\mathcal O^{(n)}$ \nwith $g^\\top=f$. The {\\em seed} of $f$, noted $f_\\bot$,  is the function $g\\in\\mathcal O^{ar(f)}$\nsuch that $g^\\top=f$. It is easy to see that $f_\\bot$ is a generator, \nfor all $f$ in $\\mathrm{Sf} A^\\top$.\n\n\\begin{lemma}\nFor all $f\\in \\mathrm{Sf} A^\\top$, $ar(f)=\\gamma(f)$.\n\\end{lemma}\n\n\n\\begin{fact}\nLet $\\mathbf F$ be FCA$\\mathbf A$.\nFor all $n\\geq 2$, $\\mathbf{F}$ is a $n$-dimensional Church algebra\nby posing $q= q_n^\\top$ and $\\e_i=e_i^\\top$, for $1\\leq i\\leq n$.\n\\end{fact}\n\nIndeed, for all $g_1,\\ldots,g_n\\in F$, $1\\leq i \\leq n$ and $\\rho\\in A^\\omega$:\n \n$$(q_n^\\top(e_i^\\top,g_1,\\ldots,g_n))(\\rho)=e_i^\\top(\\rho[g_1(\\rho),\\ldots,g_n(\\rho)]=g_i(\\rho)$$\n\n\n%An element of  a  polynomial   $\\mathcal{G}$-clone on $\\mathbf A$ %of a Church algebra of dimension $\\omega$ $\\mathbf A$ \n%is $n$-central if it is central for $q_n^{\\mathcal{G}}$, $p_1,\\ldots,p_n$;\n%it is {\\em central} if it is $n$-central \n%in $(A,q_n,e_1,\\ldots,e_n)$ \n%for some $n$.\n\nThe rest of this section is devoted to prove that the central elements of an\nFCA$\\mathbf A$ $\\mathbf F$ correspond to decomposition operators on $\\mathbf A$.\nThe first observation is that if $f\\in F$ is $k$-central, than $k\\geq ar(f)$.\n\n\n\\begin{proposition}\nLet $\\mathbf F$ be a FCA$\\mathbf A$, \n$f\\in\\mathbf F$ be such that \n$f_\\bot$ has arity $n$, and $k<n$. Then $f$ is not $k$-central.\n\\end{proposition}\n\\begin{proof}\nLet $a_{1}, \\ldots, a_{n-1},b,c\\in A$ be such that \n$f_\\bot(a_1,\\ldots, a_{n-1},b)\\neq f_\\bot(a_1,\\ldots, a_{n-1},c)$.\nIf $f$ is $k$-central, then the equation\n\\[\\begin{array}{lllr}\n&& q^\\top_k(f,q^\\top_n(g_1,h_1^1,\\ldots,h_n^1),\\ldots, q^\\top_n(g_k,h_1^k,\\ldots,h_n^k)) &\\\\\n&=& q^\\top_n(q^\\top_k(f,g_1,\\ldots,g_k),q^\\top_k(f,h_1^1,\\ldots,h_1^k),\\ldots,q^\\top_k(f,h_n^1,\\ldots,h_n^k))&\\\\\n\\end{array}\n\\]\n%$$q^\\top_k(f,q^\\top_n(g_1,h_1^1,\\ldots,h_n^1),\\ldots, q^\\top_n(g_k,h_1^k,\\ldots,h_n^k)=q^\\top_n(q^\\top_k(f,g_1,\\ldots,g_k),q^\\top_k(f,h_1^1,\\ldots,h_1^k),\\ldots,q^\\top_k(f,h_n^1,\\ldots,h_n^k))$$\nholds for all $g_1,\\ldots,g_k,h_1^1,\\ldots h_n^k$ in $F$.\nBy letting $g_i=e_i^\\top$ for $1\\leq i\\leq k$ , $h_i^j=a_i^\\top$ for $1\\leq i\\leq n-1$ and $1\\leq j\\leq k$, \nand $h_n^j=b^\\top$ for $1\\leq j\\leq k$ in the equation above, and by exploiting again the fact that $f$ is $k$-central, we get:\n$$q^\\top_k(f,a_1^\\top,\\ldots,a_k^\\top)=\n%q^\\top_n(f,q^\\top_k(f,a_1^\\top,\\ldots,a_1^\\top),\\ldots,q^\\top_k(f,a_{n-1}^\\top,\\ldots,a_{n-1}^\\top), , q^\\top_k(f,b^\\top,\\ldots,b^\\top))\nq^\\top_n(f,a_1^\\top,\\ldots,a_{n-1}^\\top,b^\\top)$$\n\nNow, let $\\rho\\in A^\\omega$ be such that $\\rho_{k+1}=a_{k+1},\\ldots,\\rho_{n-1}=a_{n-1},\\rho_n=c$. \nWe get\n\n$$f_\\bot(a_1,\\ldots, a_{n-1},c)=q^\\top_k(f,a_1^\\top,\\ldots,a_k^\\top)(\\rho)=q^\\top_n(f,a_1^\\top,\\ldots,a_{n-1}^\\top,b^\\top)(\\rho)=\nf_\\bot(a_1,\\ldots, a_{n-1},b)$$\n\na contradiction.\n\\end{proof}\n\n\nThe main theorem of this section follows:\n\n\\begin{theorem}\n Let $\\mathbf F$ be a FCA$\\mathbf A$, and let \n$f\\in F$ be of arity $n$. Then $f$ is $n$-central in $\\mathbf F$ iff $f_\\bot$ is an\n$n$-ary decomposition operator on $\\mathbf A$, commuting with $g_\\bot$,\nfor all $g\\in F$.\n\\end{theorem}\n\\begin{proof}\n($\\Rightarrow$) \nWe suppose that $f$ is $n$-central in $\\mathbf F$, and prove that $f_\\bot$ is a \ndecompostion operator on $\\mathbf A$, commuting with $g_\\bot$ for all $g\\in F$.\n\nGiven $a\\in A$, let $\\rho\\in A^\\omega$ be such that $\\rho_1=a$:\n$$f_\\bot(a,\\ldots,a)=f(\\rho[e_1^\\top(\\rho),\\ldots,e_1^\\top(\\rho)])=q^\\top_n(f,e_1^\\top,\\ldots,\ne_1^\\top)(\\rho)=e_1^\\top(\\rho)=\\rho_1=a $$\n\nGiven $a_{i,j}\\in A$ for  $1\\leq i,j\\leq n$, let  $\\rho\\in A^\\omega$ be such that\n$\\rho_{\\langle i,j\\rangle}=a_{i,j}$, for  $1\\leq i,j\\leq n$, where $\\langle i,j\\rangle=\n(i-1)\\times n+j$:\n\n%$$f_\\bot(f_\\bot(a^1_1,\\ldots,a^1_n),\\ldots,f_\\bot(a^n_1,\\ldots,a^n_n))=f(\\rho[f_\\bot(a^1_1,\\ldots,a^1_n),\\ldots,f_\\bot(a^n_1,\\ldots,a^n_n)])=$$\n%$$f(\\rho [f(\\rho[a^1_1     ]) $$\n\n\\[\\begin{array}{lllr}\n&& f_\\bot(f_\\bot(a_{1,1},\\ldots,a_{1,n}),\\ldots,f_\\bot(a_{n,1},\\ldots,a_{n,n}))&\\\\\n&=& f(\\rho[f_\\bot(a_{1,1},\\ldots,a_{1,n}),\\ldots,f_\\bot(a_{n,1},\\ldots,a_{n,n})]) &\\\\\n&=& f(\\rho[f(\\rho[a_{1,1},\\ldots,a_{1,n}]),\\ldots,f(\\rho[a_{n,1},\\ldots,a_{n,n}])]) &\\\\\n&=&q^\\top_n(f,q^\\top_n(f,e^\\top_{\\langle 1,1\\rangle },\\ldots,e^\\top_{\\langle 1,n\\rangle}),\\ldots,q^\\top_n(f,e^\\top_{\\langle n,1\\rangle},\\ldots,e^\\top_{\\langle n,n\\rangle }))(\\rho)&\\\\\n&=& q^\\top_n(f,e^\\top_{\\langle 1,1\\rangle},\\ldots,e^\\top_{\\langle n,n\\rangle })(\\rho)&\\\\\n&=& f(\\rho[a_{1,1},\\ldots,a_{n,n}])  &\\\\\n&=& f_\\bot(a_{1,1},\\ldots,a_{n,n})&\\\\\n\\end{array}\n\\]\n\n\nGiven $\\sigma$ in the signature of $\\mathbf A$ of arity $k$ and \n$a_{i,j}\\in A$ for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, \n let  $\\rho\\in A^\\omega$  be such that\n$\\rho_{\\langle i,j\\rangle}=a_{i,j}$,  for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, where $\\langle i,j\\rangle=\n(i-1)\\times k+j$:\n\n\n\\[\\begin{array}{lllr}\n&& f_\\bot(\\sigma(a_{1,1},\\ldots,a_{1,k}),\\ldots,\\sigma(a_{n,1},\\ldots,a_{n,k})) &\\\\\n&=& f(\\rho[\\sigma(a_{1,1},\\ldots,a_{1,k}),\\ldots,\\sigma(a_{n,1},\\ldots,a_{n,k})]) &\\\\\n&=& q^\\top_n(f,\\sigma^\\top(e^\\top_{\\langle 1,1\\rangle},\\ldots,a^\\top_{\\langle 1,k\\rangle}),\\ldots,\n\\sigma^\\top(e^\\top_{\\langle n,1\\rangle},\\ldots,e^\\top_{\\langle n,k\\rangle}))(\\rho)\\\\\n&= & \\sigma^\\top(q^\\top_n(f,e_{\\langle 1,1\\rangle}^\\top,\\ldots,e_{\\langle n,1\\rangle}^\\top),\\ldots\nq^\\top_n(f,e_{\\langle 1,k\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle }^\\top))(\\rho)\\\\\n&=& \\sigma(f_\\bot(a_{1,1},\\ldots,a_{n,1}),\\ldots,\nf_\\bot(a_{1,k},\\ldots,a_{n,k}))&\\\\\n\\end{array}\n\\]\n\n\nGiven $g\\in F$ be such that $g_\\bot$ is $k$-ary, $a_{i,j}\\in A$ for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, let  $\\rho\\in A^\\omega$  be such that\n$\\rho_{\\langle i,j\\rangle}=a_{i,j}$,  for $1\\leq i\\leq n$ and $1\\leq j\\leq k$, where $\\langle i,j\\rangle=\n(i-1)\\times k +j$:\n \n\n\\[\\begin{array}{lllr}\n&& f_\\bot(g_\\bot(a_{1,1},\\ldots,a_{1,k}),\\ldots,\n(g_\\bot(a_{n,1},\\ldots,a_{n,k})) &\\\\\n&=& q^\\top_n(f, q^\\top_k(g,e_{\\langle 1,1\\rangle}^\\top,\\ldots,e_{\\langle 1,k\\rangle}^\\top),\\ldots,\n q^\\top_k(g,e_{\\langle n,1\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle}^\\top))(\\rho) &\\\\\n&=&q^\\top_k(g, q^\\top_n(f,e_{\\langle 1,1\\rangle }^\\top,\\ldots,e_{\\langle n,1\\rangle}^\\top),\\ldots,\n q^\\top_n(f,e_{\\langle 1,k\\rangle}^\\top,\\ldots,e_{\\langle n,k\\rangle}^\\top))(\\rho)  &\\\\\n&=&  g_\\bot(f_\\bot(a_{1,1},\\ldots,a_{n,1}),\\ldots,\n(f_\\bot(a_{1,k},\\ldots,a_{n,k})) &\\\\\n\\end{array}\n\\]\n\n\n($\\Leftarrow$) We suppose that $f_\\bot$ is a decomposition operator on $\\mathbf A$\ncommuting with $g_\\bot$ for all $g\\in F$. and prove that $f$ is\n $n$-central in $\\mathbf F$. The first axiom of centrality, namely\n$q_n^\\top(f,e^\\top_1,\\ldots,e^\\top_n)=f$, holds a priori.\n\nGiven $g\\in F$ and $\\rho\\in A^\\omega$:\n\n\\[\\begin{array}{lllr}\n&&q^\\top_n(f,g,\\ldots,g)(\\rho)  &\\\\\n&=&f(\\rho[g(\\rho),\\ldots,g(\\rho)]) &\\\\\n&=& f_\\bot(g(\\rho),\\ldots,g(\\rho)) &\\\\\n&=& g(\\rho) &\\\\\n\\end{array}\n\\]\n\nIt remains to prove that, for all $k$-ary\noperation $\\delta$ in the type of $\\mathbf F$ and for all\nelements  $g^{i,j}\\in F$ for $1\\leq i\\leq n$, $1\\leq j\\leq k$,  \n $f$ satisfies the equation \n$$q^\\top_n(f,\\delta(g^{1,1},\\ldots,g^{1,k}),\\ldots,\\delta(g^{n,1},\n\\ldots,g^{n,k})=\\delta(q^\\top_n(f,g^{1,1},\\ldots,g^{n,1}),\\ldots,\nq^\\top_n(f,g^{1,k},\\ldots,g^{n,k}))$$\n\nLet $\\rho\\in A^\\omega$, and let us distinguish the case $\\delta=\\sigma^\\top$,\nfor some $\\sigma$ in the type of $\\mathbf A$, and $\\delta=q^\\top_{k-1}$.\n\n\n\\[\\begin{array}{lllr}\n&&q^\\top_n(f,\\sigma^\\top(g^{1,1},\\ldots,g^{1,k}),\\ldots,\\sigma^\\top(g^{n,1},\n\\ldots,g^{n,k}))(\\rho)\\\\\n&=& f_\\bot(\\sigma^\\top(g^{1,1},\\ldots,g^{1,k})(\\rho),\\ldots, \\sigma^\\top(g^{n,1},\\ldots,g^{n,k})(\\rho)) &\\\\\n&=& f_\\bot(\\sigma^\\mathbf A(g^{1,1}(\\rho),\\ldots,g^{1,k}(\\rho)),\\ldots\n\\sigma^\\mathbf A(g^{n,1}(\\rho),\\ldots,g^{n,k}(\\rho))) &  \\\\\n&=& \\sigma^\\mathbf A(f_\\bot(g^{1,1}(\\rho),\\ldots,g^{n,1}(\\rho)),\\ldots\nf_\\bot(g^{1,k}(\\rho),\\ldots,g^{n,k}(\\rho))) &\\\\\n&=&  \\sigma^\\top(f(g^{1,1},\\ldots,g^{n,1}),\\ldots\nf(g^{1,k},\\ldots,g^{n,k}))(\\rho)&\\\\\n\\end{array}\n\\]\n\n\nThe case  $\\delta=q^\\top_{k-1}$ is the most involved one.\nLet $l$ be the maximum of the arities of $g^{1,1}_\\bot,\\ldots,g^{n,1}_\\bot$ and\nlet $\\hat g ^{i,1}_\\bot$ be the $l$-ary function in the block of \n$ g ^{i,1}_\\bot$ for $1\\leq i\\leq n$. Remark that $(\\hat g^{i,1}_\\bot)^\\top=g^{i,1}$, \nfor $1\\leq i\\leq n$.\nIt is easy to see that if $f_\\bot$ commutes with  $g_\\bot$, then it also commutes\nwith any other element in the block of  $g_\\bot$.\n%The equations below derive mostly  the  definition of $q_n^\\top$,\n%$q_k^\\top$ and by the definition of seed  of a strongly finite function. \nThe fourth equation derives from  the second item of the definition of \ndecomposition operator and the fifth one from the fact that $f_\\bot$ commutes \nwith $g_\\bot$ for all $g\\in \\mathbf F$. \n\nThe others simply use the definition of \n$q_n^\\top$, $q_{k-1}^\\top$ and of seed  of a strongly finite function. \n\n\n\n\n\\[\\begin{array}{lllr}\n&&q^\\top_n(f,q^\\top_{k-1}(g^{1,1},\\ldots,g^{1,k}),\\ldots,q^\\top_{k-1}(g^{n,1},\n\\ldots,g^{n,k}))(\\rho)\\\\\n\n&=&f(\\rho[g^{1,1}(\\rho[g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho)]),\\dots,g^{n,1}(\\rho[g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho)])])&\\\\\n\n&=&f_\\bot(g^{1,1}(\\rho[g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho)]),\\dots,g^{n,1}(\\rho[g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho)])&\\\\\n\n&=&f_\\bot(\\hat g_\\bot^{1,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{n,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l ))&\\\\\n\n&=&f_\\bot( f_\\bot(\\hat g_\\bot^{1,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{1,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho), \\rho_{k+1},\\ldots,\\rho_l)),\\dots\\\\\n&& \\ \\ \\ \\ \\ f_\\bot(\\hat g_\\bot^{n,1}(g^{1,2}(\\rho),\\dots,g^{1,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l),\\dots,\\hat g_\\bot^{n,1}(g^{n,2}(\\rho),\\dots,g^{n,k}(\\rho),\\rho_{k+1},\\ldots,\\rho_l))) &\\\\\n\n&=&f_\\bot(\\hat g_\\bot^{1,1}(f_\\bot(g^{1,2}(\\rho),\\dots,g^{n,2}(\\rho)),\\dots,f_\\bot(g^{1,k}(\\rho),\\dots,g^{n,k}(\\rho)),\\rho_{k+1},\\ldots,\\rho_l)\\dots,\\\\\n&&  \\ \\ \\ \\ \\ \\hat g_\\bot^{n,1}(f_\\bot(g^{1,2}(\\rho),\\dots,g^{n,2}(\\rho)),\\dots,f_\\bot(g^{1,k}(\\rho),\\dots,g^{n,k}(\\rho)),\\rho_{k+1},\\ldots,\\rho_l))\\\\\n\n&=& f_\\bot(g^{1,1}(\\rho'),\\ldots,g^{n,1}(\\rho'))\\mbox{ where }  \n\\rho'=\\rho[f_\\bot(g^{1,2}(\\rho),\\ldots,g^{n,2}(\\rho)),\\ldots,  \nf_\\bot(g^{1,k}(\\rho),\\ldots,g^{n,k}(\\rho))]                                       &\\\\\n\n\n&=& f(\\rho'[g^{1,1}(\\rho'),\\ldots,g^{n,1}(\\rho')])&\\\\\n\n\n&=& q_n^\\top(f,g^{1,1},\\ldots,g^{n,1})(\\rho')&\\\\\n\n\n&=& q_n^\\top(f,g^{1,1},\\ldots,g^{n,1})(\\rho[q_n^\\top(f,g^{1,2},\\ldots,g^{n,2})(\\rho),\n\\ldots,q_n^\\top(f,g^{1,k},\\ldots,g^{n,k})(\\rho)])&\\\\\n\n\n&=& q_{k-1}^\\top(q_n^\\top(f,g^{1,1},\\ldots,g^{n,1}),q_n^\\top(f,g^{1,2},\\ldots,g^{n,2}),\\ldots,q_n^\\top(f,g^{1,k},\\ldots,g^{n,k})) (\\rho)&\\\\\n\n\\end{array}\n\\]\n\n\n\n\n\\end{proof}\n\nThe decomposition operator $f_\\bot$ of the Theorem above is \nproper, since  $f_\\bot$ is a generator. \n\n\n\n\n\n\n\n\\section{Centralizers in clone algebras}\n\nIf $m=(m_{ij})\\in A^{\\omega\\times\\omega}$ then we denote by \n$m_i\\in A^\\omega$ the sequence defined by $m_i(k)=m_{ik}$\nand by  $m^j\\in A^\\omega$ the sequence defined by $m^j(k)=m_{kj}$.\n\n\\begin{definition}\\label{def:com}\nLet $\\mathbf F$ be a $\\mathsf{FCA}$ with value domain $A$.\nWe say that $f,g\\in F$ \\emph{commute}, and we write $f\\bot g$, if, for every $m\\in A^{\\omega\\times\\omega}$, \n$$f\\langle g(m_i) : i\\in \\omega\\rangle =g\\langle f(m^i): i\\in \\omega\\rangle.$$\n\\end{definition}\n\n\\begin{lemma} Let $\\mathbf F$ be a $\\mathsf{FCA}$ with value domain $A$ and let $f\\in F$.\nThe set $f^*=\\{ g\\in F: f\\bot g\\}$ is a subalgebra of $\\mathbf F$.\n\\end{lemma}\n\n\\begin{proof} Let $g,h_1,\\dots,h_k\\in f^*$, $t=q_k^\\mathbf F(g,h_1,\\dots,h_k)$ and $m\\in A^{\\omega\\times\\omega}$.\nThen by definition of $q_k^\\mathbf F$ we derive:\n $$t(m_i)=  g(m_i[h_1(m_i),\\dots,h_k(m_i)]).$$\n%Let $\\mu_n=m_n[h_1(m_n),\\dots,h_k(m_n)]$. \nWe now prove that $t\\in f^*$:\n\\[\n\\begin{array}{lll}\n  &   & f\\langle t(m_i) : i\\in \\omega\\rangle  \\\\\n  &   & f\\langle g(m_i[h_1(m_i),\\dots,h_k(m_i)]) : i\\in \\omega\\rangle  \\\\  \n  &  = & f(g(m_1[h_1(m_1),\\dots,h_k(m_1)]),\\dots,g(m_n[h_1(m_n),\\dots,h_k(m_n)]),\\dots)  \\\\\n  & =  &   g(f\\langle h_1(m_i): i\\in \\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in \\omega\\rangle,f(m^{k+1}),\\dots,f(m^{n}),\\dots)\n\\end{array}\n\\]\n\n\n Let $s=\\langle f(m^i): i\\in\\omega\\rangle\\in A^\\omega$. Then by hypothesis and Definition \\ref{def:com} we have:\n $$h_j(s)= h_j\\langle f(m^i): i\\in\\omega\\rangle= f\\langle h_j(m_i): i\\in\\omega\\rangle$$\n We conclude as follows:\n\\[\n\\begin{array}{lll}\n  &   &t\\langle f(m^i): i\\in \\omega\\rangle\\\\\n  &=&g(\\langle  f(m^i): i\\in \\omega\\rangle[h_1(s),\\dots,h_k(s)])\\\\\n  &=& g(\\langle  f(m^i): i\\in \\omega\\rangle[f\\langle h_1(m_i): i\\in\\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in\\omega\\rangle])\\\\\n  &=& g(f\\langle h_1(m_i): i\\in \\omega\\rangle,\\dots,f\\langle h_k(m_i): i\\in \\omega\\rangle,f(m^{k+1}),\\dots,f(m^{n}),\\dots)\n\\end{array}\n\\]\n\\end{proof}\n\nFor any $X\\subseteq F$, we write $X^*$ for $\\bigcap_{f\\in X} f^*$.   The set $X^*$ is called the \\emph{centralizer} of $X$.\n\n\n\\begin{definition}\n  Two elements $a,b$ of a clone algebra $\\mathbf C$ \\emph{commute} if, for every $n\\geq \\gamma(a)$ and $k\\geq \\gamma(b)$, we have\n$$q_n(a,q_k(b,x_{11},\\dots,x_{1k}),\\dots,q_k(b,x_{n1},\\dots,x_{nk}))=\nq_k(b,q_n(a,x_{11},\\dots,x_{n1}),\\dots,q_n(a,x_{1k},\\dots,x_{nk})).$$\n\\end{definition}\n\n%$f(s[g(s[a_{11},\\dots,a_{1k}]),\\dots,g(s[a_{n1},\\dots,a_{nk}])]=g()$\n\nWe write  $a\\bot b$ for $a$ and $b$ commute.\n\n\\begin{lemma}\n  For any $F\\subseteq \\mathcal{O}_A$ , the centralizer $F^{*}$ of $F$ is a clone.\n\\end{lemma}\n\n\\begin{proof}\n $F^*$ is the clone of all homomorphisms from the algebra $(A,F)^n$ into $(A,F)$ ($n\\geq 0$).\n\\end{proof}\n\n%$F^*$ is the clone of all homomorphisms of the algebra $(A,F)$.\n\nThe following properties of centralizers are easy but important. \n\n\\begin{lemma}\n  For any $F,G\\subseteq \\mathcal O_A$ we have:\n\\begin{enumerate}\n\\item[(i)] $F\\subseteq F^{**}$;\n\\item[(ii)] $F\\subseteq G\\Longrightarrow F^*\\supseteq G^*$;\n\\item[(iii)]  $F^*=F^{***}$.\n\\end{enumerate}\n\\end{lemma} \n\nKuznetsov Criterion was discovered by Kuznetsov in 1960's, and is an extremely useful tool (see \\cite{}).\n\nLet $f^{o}$ means the graph of $f$, i.e., $f^{o }=\\{(x_{1}, \\ldots, x_{n}, x_{n+1}) : f(x_{1}, \\ldots, x_{n})=x_{n+1}\\}$\n\n\\begin{definition} \n For $f\\in \\mathcal{O}_A^{(n)}$ and $\\Sigma\\subseteq \\mathcal O_A,$ $f$ is \\emph{parametrically expressible} (p-expressible) by $\\Sigma$ if there exist $m\\geq 1,$ $\\ell\\geq 0$ and $g_{i},$ $h_{i}\\in \\mathcal{O}_A^{(n+\\ell+1)}(i=1, \\ldots, m)$ such that $g_{i},$ $h_{i}\\in[\\Sigma]$ and \n \\[\n\\begin{array}{rcl}\n f(x_{1}, \\ldots, x_{n}) & =  & x_{n+1}  \\\\\n  &  \\text{iff} &\\\\\n \\exists a_{1},\\dots, a_{\\ell}\\in A\\ \n\\forall i\\ g_{i}(x_{1},\\dots, x_{n+1}, a_{1},\\dots, a_{\\ell}) &=&h_{i}(x_{1}, \\dots, x_{n+1}, a_{1},\\dots, a_{\\ell})\\\\\n  \\end{array}\n\\]\n\\end{definition}\n\n\\begin{theorem}\n  (Kuznetsov Criterion)\nFor $f\\in O_{k}$ and $\\Sigma\\subseteq \\mathcal{O}_{k}$, \n$f$ is p-expressible by $\\Sigma$ iff $\\Sigma^*\\subseteq f^*$.\n\\end{theorem}\n\nEquivalently, it can be expressed as:\n\n\\begin{corollary}\n For $f\\in O_{k}$ and $\\Sigma\\subseteq O_{k},$ $f$ is p-expressible by $\\Sigma$ iff $f\\in \\Sigma^{**}$.\n\\end{corollary}\n\n\n\n\n%$q_n(x,y_1,\\dots,y_n)=q_2(q_1(x,y_1),\\e_1,y_2)$\n\n%\n%\\section{Derivatives}\n%We denote by $A^\\top$  the set of  functions from $A^\\omega$ to $A$.\n%We define a structure of semimodule over the set $A^\\top$.\n%Let $A^{(0)}=A$ and $A^{(n+1)}=A\\to A^{(n)}$. \n%%Let $f,g^1,\\dots,g^n$ be functions. \n%%We define an $n$DA $$q_n(f,g^1,\\dots,g^n)(\\bar a) = f(g^1(\\bar a),\\dots,g^n(\\bar a));\\qquad \\e^i(\\bar a)=a_i.$$\n%\n%\\begin{definition} A scalar is a function $r:A^\\omega\\to A^{(n)}$  for some $n\\geq 1$. All the constant functions are identified and represent the scalar $0$.\n% A  \\emph{proper scalar} is a non-constant map $r:A^\\omega\\to A^{(n)}$.\n%\\end{definition}\n%\n%%$f_1: A\\to (A^{n-1}\\to A)$ defined by $f_1(a_1)(a_2,\\dots,a_n)=f(a_1,a_2,\\dots,a_n)$\n% If $r: A^\\omega\\to A^{(n)}$ and $s: A^\\omega\\to A^{(k)}$ are scalars, then we define the product $rs:A^\\omega\\to A^{(n+k-1)}$ as follows, for all $a\\in A$ and $\\rho\\in A^\\omega$: \n%$$(rs)\\rho a_1\\dots a_{n+k-1}=r\\rho(s\\rho a_1\\dots a_k)a_{k+1}\\dots a_{k+n-1}.$$\n%%We write $ra\\bar b$ for $r(a)(\\bar b)$.\n%It is a monoid with unit $1$, where $1\\rho a=a$:\n%$$[(rs)t]\\rho a = (rs)\\rho(t\\rho a) = r\\rho(s\\rho (t\\rho a))=r\\rho((st)\\rho a) = [r(st)]\\rho a$$\n%$$(r1)\\rho a=r\\rho (1\\rho a) = r\\rho a;\\qquad (1r)\\rho a=1\\rho(r\\rho a) = r\\rho a$$\n%$$(0r)\\rho a=0\\rho(r\\rho a) = 0\\rho a;\\qquad (r0)\\rho a=r\\rho(0\\rho a) =r\\rho(0\\rho b) = (r0)\\rho b.$$\n%Thus, $r0=0$ because $(r0)\\rho$ is a constant function for every $\\rho$.\n%\n%A scalar is idempotent if $rr = r$ (i.e., $r\\rho a=r\\rho(r\\rho a)$). %If $r,s$ are idempotents, then $rs$ is idempotent iff $srs=s$: $(rsrs)\\rho a= r\\rho(s\\rho[r\\rho(s\\rho a)])=r\\rho(s\\rho a)$.\n%\n%\\begin{definition}\n% The \\emph{derivative $\\frac{\\partial f}{\\partial x_i}$ along the coordinate $x_i$} of a map $f:A^\\omega\\to A$ is a scalar defined as follows:\n%$$\\frac{\\partial f}{\\partial x_i}\\rho a=f(\\rho[a/i]).$$\n%$$(\\frac{\\partial f}{\\partial x_i}+\\frac{\\partial f}{\\partial x_k})\\rho ab=\\frac{\\partial f}{\\partial x_k}\\rho[a/i]b=f(\\rho[a/i][b/k]) .$$\n%$$(\\frac{\\partial f}{\\partial x_i}\\cdot\\frac{\\partial f}{\\partial x_k})\\rho a=\\frac{\\partial f}{\\partial x_i}\\rho(f(\\rho[a/k])) =f(\\rho[f(\\rho[a/k])/i]) .$$\n%\n%%\\item[(ii)] If $r:A\\to \\mathcal O^{(n-1)}_A$ is a scalar, then the \\emph{integral of $r$ along the coordinate $x_i$} is a function\n%%$\\int_i r: A^{n}\\to A$ defined as follows:\n%%$$\\int_i r(a_1,\\dots,a_n)= r(a_i)(a_1,\\dots,a_{i-1},a_{i+1},\\dots,a_n).$$ \n%%\\end{enumerate}\n%\\end{definition}\n%\n%\\begin{definition}\n% We say that \\emph{$f$ is independent of $x_i$} if $\\frac{\\partial f}{\\partial x_i}= 0$.\n%\\end{definition}\n%\n%\n%\\begin{example} $\\e_i$ is independent of $x_j\\in\\omega\\setminus\\{i\\}$, because \n%$\\frac{\\partial \\e_i}{\\partial x_j}=\\delta^i_j$.\n%\\end{example}\n%\n%\n%\n%\\begin{lemma}\n% If $\\frac{\\partial f}{\\partial x_i}=\\frac{\\partial g}{\\partial x_i}$ for every $i\\in\\omega$, then $f=g$.\n%\\end{lemma}\n%\n%\\begin{proof}\n% \n%\\end{proof}\n%\n%\n%If $h= q_n(f,g^1,\\dots,g^n)$, then we have \n%$$\\frac{\\partial h}{\\partial x^i} =\\lambda a. \\lambda \\bar b. f(g^1(b_1,\\dots,b_{i-1},a,b_{i+1},\\dots,b_n),\\dots,g^n(b_1,\\dots,b_{i-1},a,b_{i+1},\\dots,b_n))$$\n%\n%$$\\frac{\\partial f}{\\partial x_k} \\frac{\\partial g^k}{\\partial x_i}a\\mathbf b=\\frac{\\partial f}{\\partial x_k}(\\frac{\\partial g^k}{\\partial x_i}a\\mathbf b)\\mathbf b=f(b_1,\\dots,b_{k-1},g^k(b_1,\\dots,b_{i-1},a,b_{i+1},\\dots,b_n),b_{k+1},\\dots, b_n)$$\n%\n%$$\\frac{\\partial h}{\\partial x^i}= \\sum_{k=1}^n \\frac{\\partial f}{\\partial x^k} \\frac{\\partial g^k}{\\partial x^i}$$\n%and\n%$$\\frac{\\partial f}{\\partial x^k} \\frac{\\partial g^k}{\\partial x^i}(a)=\n%\\lambda \\bar b. f(b_1,\\dots,b_{k-1},g^k(b_1,\\dots,b_{i-1},a,b_{i+1},\\dots,b_{n}),b_{k},\\dots,b_{n}) $$\n%\n%\n%\n%$$\\frac{\\partial h}{\\partial x^i}(a)= (\\sum_{k=1}^n \\frac{\\partial f}{\\partial x^k} \\frac{\\partial g^k}{\\partial x^i})(a)$$\n%In particular,\n%$$\\frac{\\partial q(f,\\e_1,\\dots,\\e_n)}{\\partial x_i}=\n%\\sum_{k=1}^n \\frac{\\partial f}{\\partial x_k} \\frac{\\partial \\e_k}{\\partial x_i}= \\sum_{k=1}^n \\frac{\\partial f}{\\partial x_k} \\delta^k_i= \\frac{\\partial f}{\\partial x_i},$$\n%so that $$q(f,\\e_1,\\dots,\\e_n)=f = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}\\e_i.$$\n%\n%$q(f,g^1,\\e^2) + q(f,\\e^2,g^2)= q(f,g^1,g^2)$\n%\n%\\begin{definition}\n% The \\emph{derivative} $\\frac{\\partial f}{\\partial g}: A\\to (A^{n-1}\\to A)$ ($i=1,\\dots,n$) of a map $f:A^n\\to A$ w.r.t. a map $g:A^n\\to A$ is defined as follows:\n%$$\\frac{\\partial f}{\\partial g}= \\sum_{i=1}^n \\frac{\\partial g}{\\partial x^i} \\frac{\\partial f}{\\partial x^i}.$$\n%\n%\\end{definition}\n%\n%\\begin{example}\n% $$q(f,g^1,\\dots,g^n)_1(a)=  f(g^1(a,-_2,\\dots,-_n),\\dots,g^k(a,-_2,\\dots,-_n))=(\\sum_{i=1}^n f_ig^i_1)(a),$$\n%where\n%$$(f_2g^2_1)(a)(\\bar b)= f_2(g^2_1a\\bar b)\\bar b=f_2(g^2(a,\\bar b))\\bar b= f(b_1,g^2(a,\\bar b),b_2,\\dots,b_{n-1})$$\n%and\n%$$(f_ng^n_1)(a)(\\bar b)= f_n(g^n_1a\\bar b)\\bar b=f_n(g^n(a,\\bar b))\\bar b= f(b_1,b_2,\\dots,b_{n-1},g^n(a,\\bar b)).$$\n%\\end{example}\n%\n%%(f_1g^1_1)(a)=f(g^1(a,-_2,\\dots,-_n),-_2\\dots,-_n)\n%We write $f=f_1\\e_1+\\dots+f_n\\e_n$, that means\n%$f=f_1\\circ\\e_1+\\dots+f_n\\circ\\e_n$. To compute, we have:\n%$$f(a_1,\\dots,a_n)=f_1\\e_1(a_1,\\dots,a_n)+\\dots+f_n\\e_n(a_1,\\dots,a_n) =f_1(a_1)+\\dots+f_n(a_n)= \n%f(a_1,)+\\dots+f_n(a_n$$\n%\n%$q(f,g^1,\\dots,g^n) = f_1g^1+\\dots+f_ng^n = (\\sum_{i=1}^n f_ig^i_1)\\e_1+\\dots+ (\\sum_{i=1}^n f_ig^i_n)\\e_n$\n%\n%$q(f,g^1,\\dots,g^n)_1(a_1)=  f(g^1(a_1,-_2,\\dots,-_n),\\dots,g^k(a_1,-_2,\\dots,-_n))=(\\sum_{i=1}^n f_ig^i_1)(a_1)+\\dots+(\\sum_{i=1}^n f_ig^i_n)(a_n)=\n%\\sum_{i=1}^n f_i(g^i_1(a_1))$\n%\n%$f(g_1,\\dots,g_k)(a_1,\\dots,a_n)= f(g_1(a_1,\\dots,a_n),\\dots,g_k(a_1,\\dots,a_n))=$\n%\n%$f(-,\\e_2,\\dots,\\e_n)g_1+\\dots+f(\\e_1,\\dots,\\e_{n-1},-)g_k$\n%\n\n\n\n\\section{Appendix 1}\nWe define the Green relation on $\\mathbf C$ as follows:\n$$a\\mathcal Db\\ \\text{iff}\\ q_n(a,\\mathbf c)=q_n(b,\\mathbf c),\\ \\text{for all $n$ and $\\mathbf c \\in (\\mathrm{Zd}\\mathbf C)^n$}.$$\n\n\\begin{lemma} The Green relation $\\mathcal D$ is a congruence on  $\\mathbf C$.\n\\end{lemma}\n\n\\begin{proof} $a\\mathcal Db$, $a_i\\mathcal Db_i$ and $\\mathbf c \\in (\\mathrm{Zd}\\mathbf C)^n$.\nThen $q_n(q_n(a,\\mathbf a),\\mathbf c)=q_n(a, q_n(a_1,\\mathbf c),\\dots,q_n(a_n,\\mathbf c)) =q_n(a, q_n(b_1,\\mathbf c),\\dots,q_n(b_n,\\mathbf c))=q_n(b, q_n(b_1,\\mathbf c),\\dots,q_n(b_n,\\mathbf c))$, because by Lemma \\ref{lem:zd}(2) $q_n(b_n,\\mathbf c)$ is zero-dimensional.\n\\end{proof}\n\n\\begin{definition}\n A clone algebra $\\mathbf C$ is \\emph{reduced} if $\\mathcal D=\\Delta_C$.\n\\end{definition}\n\nFor every permutation $\\sigma$ of the symmetric group $S_n$\nwe define\n$$a^\\sigma= q_n(a,\\e_{\\sigma 1},\\e_{\\sigma 2},\\dots,\\e_{\\sigma n}).$$\n\n%The transposition $(ij)$ exchanges $i$ and $j$: $(ij)(i)=j$ and $(ij)(j)=i$.\n\n\\begin{lemma}\\label{sigma} The following conditions hold in every clone algebra, for all permutations $\\sigma,\\tau$ of order $n$: \n\\begin{enumerate}\n%\\item $x^{\\sigma}= t_{\\tau 1}(x, t_{\\tau 2}(x, t_{\\tau 3}(x,\\dots t_{\\tau n}(x,\\e_{\\tau n},\\e_{\\sigma \\tau n})\\dots,\\e_{\\sigma \\tau 3})),\\e_{\\sigma \\tau 2}),\\e_{\\sigma \\tau 1})$;\n\\item $q_n(x^\\sigma, y_1,\\dots, y_n)=q_n(x, y_{\\sigma 1},\\dots, y_{\\sigma n})$;\n%\\item $x^{(ij)} =  t_{i}(x, t_{j}(x,x,\\e_i),\\e_j) =  t_{j}(x, t_{i}(x,x,\\e_j),\\e_i)$;\n\\item $q_n(x, y_1,\\dots, y_n)^\\sigma = q_n(x,(y_1)^{\\sigma},\\dots, (y_n)^{\\sigma})$;\n\\item $x^{\\tau\\circ\\sigma}=(x^{\\sigma})^{\\tau}$;\n\\item $\\e_i^\\sigma=\\e_{\\sigma i}$.\n\\end{enumerate}\n \n\\end{lemma}\n\n\\begin{proof} \n\n(1) $q_n(a^\\sigma, b_1,\\dots, b_n)=q_n(q_n(a,\\e_{\\sigma 1},\\dots,\\e_{\\sigma n}), b_1,\\dots, b_n)=_{(C5,C1)}q_n(a, b_{\\sigma 1},\\dots, b_{\\sigma n})$.\n\n(2) $$\\begin{array}{lll} \nq_n(a, b_1,\\dots, b_n)^\\sigma &=& q_n(q_n(a, b_1,\\dots, b_n),\\e_{\\sigma 1},\\e_{\\sigma 2},\\dots,\\e_{\\sigma n})\\\\\n&=_{(C5)}&\nq_n(a,q_n(b_1,\\e_{\\sigma 1},\\e_{\\sigma 2},\\dots,\\e_{\\sigma n}),\\dots,q_n(b_n,\\e_{\\sigma 1},\\e_{\\sigma 2},\\dots,\\e_{\\sigma n}))\\\\ \n&=& q_n(a,(b_1)^{\\sigma},\\dots, (b_n)^{\\sigma}). \n\\end{array}$$\n\n(3) \n$$\\begin{array}{lll} \n(a^{\\sigma})^{\\tau}\n&=&q_n(a,\\e_{\\sigma1},\\e_{\\sigma2},\\dots,\\e_{\\sigma n})^\\tau\\\\\n&=_{(2)}& q(a,(\\e_{\\sigma1})^{\\tau},\\dots, (\\e_{\\sigma n})^{\\tau})\\\\\n&=&q(a,\\e_{\\tau(\\sigma1)},\\dots, \\e_{\\tau(\\sigma n)})\\\\\n&=&a^{\\tau\\circ\\sigma}.\n\\end{array}$$\n\\end{proof}\n\n\\begin{definition} An element $a\\in \\mathrm{Fi}\\mathbf C$ is \\emph{essential} if $|\\Gamma(a)|=\\gamma(a)$.\n\\end{definition}\n\n\\begin{lemma} For every $a\\in \\mathrm{Fi}\\mathbf C$ there exists a permutation $\\sigma\\in S_{\\gamma(a)}$ such that $a^\\sigma$ is essential.\n\\end{lemma}\n\n\n\\section{Feldman's Substitution Algebras}\n\n\\begin{definition} An algebra $\\mathbf A = (A, p_i , \\e_i)_{i<\\omega}$ satisfying the following first order axiom schema is called a substitution algebra of dimension $\\omega$ ($\\mathrm{SA}\\omega$): \n\\begin{enumerate}\n\\item[(S1)] $p_i(\\e_i,x)=x$; \n\\item[(S2)] $p_i(\\e_j,x)=\\e_j$  $(j\\neq i)$;  \n\\item[(S3)] $p_i(x,\\e_i)=x$; \n\\item[(S4)] $p_i(p_i(z,y),x)= p_i(z,p_i(y,x))$; \n\\item[(S5)] If $p_i(x,w) = x$ for all $w$, then $p_i(p_j(z,\\e_i),x)= p_i(p_j(z,x),x)$;\n\\item[(S6)]\n If $p_i(x,w) = x$ for all $w$, then $p_j(p_i(z,y),x) =p_i(p_j(z,x),p_j(y,x))$ $(i\\neq j)$.\n\\end{enumerate}\n\\end{definition}\n\n\\begin{lemma}\n $\\forall w.p_i(x,w) = x$ iff $p_i(x,\\e_k)=x$ ($i\\neq k$).\n\\end{lemma}\n\n\\begin{proof}\n $p_i(x,w) =p_i(p_i(x,\\e_k),w)=p_i(x,p_i(\\e_k,w))=p_i(x,\\e_k)=x$.\n\\end{proof}\n\n\\begin{lemma} Assuming (S1)-(S4) we have the following equivalences:\n\\begin{itemize}\n\\item (S5) iff $p_i(p_j(z,\\e_i),p_i(x,\\e_k))= p_i(p_j(z,p_i(x,\\e_k)),p_i(x,\\e_k))$ ($k\\neq i,j$).\n\\item (S6) iff $p_j(p_i(z,y),p_i(x,\\e_k)) =p_i(p_j(z,p_i(x,\\e_k)),p_j(y,p_i(x,\\e_k)))$ ($i\\neq j$ and $k\\neq i,j$).\n\\end{itemize}\n\\end{lemma}\n\n\\begin{proof} We have $p_i(p_i(x,\\e_k),w) = p_i(x,p_i(\\e_k,w))=p_i(x,\\e_k)$.\n\\end{proof}\n\n\\begin{corollary}\n $\\mathrm{SA}\\omega$ is a variety of algebras.\n\\end{corollary}\n\n\\begin{theorem}\n $\\mathrm{SA}\\omega$ is generated by its locally finite members.\n\\end{theorem}\n\n\\begin{proof}\n \n\\end{proof}\n\nThe reduct $(S,q_n,\\e_i)$, where \n$q_n(x,y_1,\\dots,y_n)= $,\n is a $\\mathsf{CA}$.\n\n\\begin{lemma} Let $\\mathbf C$ be a pure clone algebra. The reduct $(C,p_i,\\e_i)_{i\\in\\omega}$,\nwhere $p_i(x,y)=q_i(x,\\e_1,\\dots,\\e_{i-1},y)$, is a $\\mathrm{SA}\\omega$.\n\\end{lemma}\n\n\\begin{proof}\n (S1) and (S3) respectively follow from (C1) and (C3). (S2) is a consequence of (C2) for $j>i$ and of (C1) for $j<i$.\nWe obtain (S4) by (C5). \n\n\n$q_i(x,\\e_1,\\dots,\\e_{i-1},\\e_{i+1})=x$ implies \n$$q_i(q_j(z,\\e_1,\\dots,\\e_{j-1},\\e_i),\\e_1,\\dots,\\e_{i-1}, x)=\nq_i(q_j(z,\\e_1,\\dots,\\e_{j-1},x),\\e_1,\\dots,\\e_{i-1}, x)$$\n\n$(i<j)$\n$q_i(q_j(z,\\e_1,\\dots,\\e_{j-1},\\e_i),\\e_1,\\dots,\\e_{i-1}, x)=$\\\\\n$q_j(z,q_i(\\e_1,\\e_1,\\dots,\\e_{i-1}, x),\\dots,q_i(\\e_{j-1},\\e_1,\\dots,\\e_{i-1}, x),q_i(\\e_i,\\e_1,\\dots,\\e_{i-1}, x))=$\\\\\n$q_j(z,\\e_1,\\e_1,\\dots,\\e_{i-1}, x,\\e_{i+1},\\dots,\\e_{j-1},x)$\n\n\n\\end{proof}\n\n\n\\section{Appendix: Rectangular Bands}\nThe notion of rectangular bands comes from geometry. On the direct product $X \\times Y$ of nonempty sets $X$ and $Y$ one can define a multiplication $(x_1,y_1)\\cdot(x_2,y_2):=(x_1,y_2)$. If $a_1=(x_1,y_1)$ and $a_2=(x_2,y_2)$ are the opposite corners of a rectangle in $X \\times Y$, then $a_1\\cdot a_2$ and $a_2\\cdot a_1$ are the other two corners of the rectangle (cf. e.g. \\cite{CP}, rectangular bands seem to be firstly considered in \\cite{kle}).\n\nThe multiplication is the direct product of the first and second binary projection on $X \\times Y$. This is satisfied for all rectangular bands: every rectangular band is isomorphic to a direct product of two projection algebras, i.e. algebras with projections as fundamental operations. Therefore the variety of all rectangular bands is generated by all algebras with one binary projection as multiplication.\n\n\nA semigroup is a \\emph{rectangular band} if it satisfies the identity $xyx=x$.\n\nA semigroup is \\emph{left zero} (resp. \\emph{right zero}) if it satisfies $xy=x$ (resp. $xy=y$).\n\n\\begin{theorem}\\label{thm1} \\cite[Theorem 1.1.3]{howie} The following conditions are equivalent for a semigroup $\\mathbf S$:\n\\begin{enumerate}\n\\item[(i)] $\\mathbf S$ is a rectangular band;\n\\item[(ii)] $\\mathbf S$ is idempotent and it satisfies the identity \n\\begin{equation}\\label{strange} xyz=xz;\\end{equation}\n\\item[(iii)] There exist a left zero semigroup $\\mathbf L$ and a right zero semigroup $\\mathbf R$ such that $\\mathbf S\\cong \\mathbf L\\times \\mathbf R$;\n\\item[(iv)] $\\mathbf S$ is isomorphic to a semigroup of the form $A\\times B$, where $A$ and $B$ are non-empty sets, and where multiplication is given by  $$(a_1,b_1)(a_2,b_2)= (a_1,b_2).$$\n\\item[(v)] For all $a,b\\in S$, \n$$ab=ba \\Rightarrow a=b.$$\n(Rectangular bands are the nowhere commutative semigroups).\n\\end{enumerate}\n\\end{theorem}\n\\begin{proof} (i) $\\Rightarrow$ (ii) By $x^3=x$ we derive $x^4=x^2$. Moreover, $x=x(x^2)x=x^4=x^2$.\nNow, \n$xz=xyxzyz=xy(xz)yz=xyz$, as required.\n \n (ii) $\\Rightarrow$ (iii) Let $c\\in S$. Then $L=Sc$ and $R=cS$, because $s_1cs_2c=s_1(cs_2c)=s_1c$ and similarly for $R$. The map $s\\mapsto (sc,cs)$ is an isomorphism. If $(sc,cs)= (uc,cu)$, then\n $s= sccs=uccu=u$. If $(sc,cu)\\in L\\times R$, then $suc=sc$ and $csu=cu$; hence the map is bijective.\n Moreover, $(suc,csu)=(sc,cu)=(sc,cs)(uc,cu)$.\n \n  (iii) $\\Rightarrow$ (iv) Put $A=L$ and $B=R$.\n  \n   (iv) $\\Rightarrow$ (i)  Trivial.\n   \n   (i) $\\Rightarrow$ (v) Let $ab=ba$. Then $a=aba=baa=ba=ab=abb=bab=b$.\n   \n   (v) $\\Rightarrow$ (i) Since $a(a^2)=(a^2)a$ then $a=a^2$. Since $S$ is a band,  then $a(aba)=(aba)a$. By hypothesis we conclude $a=aba$.\n \\end{proof}\n\n Let $\\mathbf S$ be a semigroup. \n The Green's equivalence relations on $S$ are defined as follows:\n$$a \\mathcal L b \\Leftrightarrow S^1a=S^1b;\\qquad a \\mathcal R b \\Leftrightarrow aS^1=bS^1;\n\\qquad a \\mathcal J b \\Leftrightarrow S^1aS^1=S^1bS^1;$$\n$$a \\mathcal H b \\Leftrightarrow a \\mathcal L b\\ \\text{and}\\ a \\mathcal R b;\\qquad \\mathcal D = \\mathcal L\\circ \\mathcal R=  \\mathcal R\\circ \\mathcal L$$\nwhere $S^1x=Sx\\cup \\{x\\}$ and $S^1xS^1=SxS \\cup Sx \\cup xS\\cup \\{x\\}$.\n\n \n We define two further binary relations on $S$:\n $$a\\theta_S b \\Leftrightarrow ab=a;\\qquad a\\bar\\theta_S b\\Leftrightarrow ab=b.$$\n\n\\begin{theorem}\\label{thm2}\n Let $\\mathbf S=(S,\\cdot)$ be a groupoid.  Then the following conditions are equivalent:\n \\begin{itemize}\n\\item[(i)]  $\\mathbf S$ is a rectangular band;\n\\item[(ii)] The operation $\\cdot$ is a binary decomposition operator on $\\mathbf S$, i.e., it satisfies the identities $xx=x$ and $(xy)(zu)=xu$;\n\\item[(iii)] $(\\theta_S,\\bar\\theta_S)$ is a pair of complementary factor congruences of $\\mathbf S$ such that\n$a\\theta_S(ba) \\bar \\theta_S b$;\n\\item[(iv)] $\\mathbf S$ is a semigroup and $\\theta_S=\\mathcal L$, $\\bar\\theta_S=\\mathcal R$.\n\\end{itemize}\n\\end{theorem}\n\n\n\\begin{proof} ($i\\Rightarrow ii$) By Theorem \\ref{thm1}(ii) $xx=x$ and  $(xy)(zu)=x(yz)u=xu$.\n\n($ii\\Rightarrow i$) $(xy)z= (xy)(zz)=xz$ and $x(yz)=(xx)(yz)=xz$.\n\n\n ($i\\Rightarrow iii$) By idempotence of $S$ the  relations $\\theta_S$ and $\\bar\\theta_S$ are reflexive. We prove the other properties for $\\theta_S$.\n\n(Symmetry): Let $ab=a$. Then $ba=bab=b$ and the conclusion is obtained. \n\n(Transitivity): Let $ab=a$ and $bc=b$. Then $ac=(ab)c=a(bc)=ab=a$ and the transitivity holds.\n\n(Compatibility): %Recall that the identity $xyz=xz$ holds in every rectangular band. \nIf $a\\theta_S b$ and $c\\theta_S d$, then by applying identity (1) in Theorem \\ref{thm1} we get $ac=(ab)(cd)=a(bc)d=ad$.\nMoreover, $(ac)(bd)=a(cb)d=ad=ac$. Then $ac\\theta_S bd$.\n\n($\\theta_S\\cap \\bar\\theta_S=\\Delta_S$): Trivial. \n\n($\\theta_S\\circ \\bar\\theta_S = \\nabla_S$): Let $a,b$ be arbitrary elements of $S$.\nSince $aba=a$ and $bab=b$, then $a\\theta_S\\ ba\\ \\bar \\theta_S b$.\n\n($iii\\Rightarrow i$) By reflexivity $aa=a$ for all $a\\in S$. \n\nBy $b\\theta_S(ab) \\bar \\theta_S a$ we get $bc\\theta_S(ab)c \\bar \\theta_S ac$\nBut $c\\theta_S(ac) \\bar \\theta_S a$. Then $bc\\theta_S(ab)c \\bar \\theta_S a$.\nMoreover, $bc\\theta_S a(bc) \\bar \\theta_S a$. Then $(ab)c=a(bc)$.\n\nMoreover, by $a\\theta_S(ba) \\bar \\theta_S b$ and the definition of $\\theta_S,\\bar\\theta_S$\nwe derive $a(ba)=a$ and $(ba)b=b$. By exchanging $a$ and $b$ we get $(ab)a=a$ and $b(ab)=b$.  \nIn conclusion, for all $a,b\\in S$, we have:\n$$a(ba)=a=(ab)a.$$\n%By $ab \\bar \\theta_S a$ and symmetry we derive $a \\bar \\theta_S ab$, so that $a(ab)=ab$. Similarly, we derive $(ba)a=ba$. \n\n\n% ($ii\\Rightarrow i$)  By the reflexivity of $\\theta_S$ the semigroup $S$ is a band. We now prove that $axa=a$ for all $x\\in S$. By symmetry of $\\theta_S$ we conclude:\n%$axa=a$ iff $a\\theta_S xa$ iff $xa\\theta_S a$ iff $(xa)a = x(aa)=xa$.\n\n($iii\\Rightarrow iv$) First we prove $\\theta_S\\subseteq \\mathcal L$. Let $a\\theta_S b$. Then $ab=a$ and, by symmetry of $\\theta_S$, $ba=b$.\nThen we have: $S^1a=Sa\\cup\\{a\\}= Sab\\cup\\{ab\\}=(Sa\\cup\\{a\\})b \\subseteq Sb$ and similarly $S^1b\\subseteq Sa$. Hence $S^1a=S^1b$ and $a\\mathcal L b$.\nFor the converse, if  $a\\mathcal L b$ then there exist $x,y$ such that $a=xb$ and $b=ya$.\nSince by reflexivity of $\\theta_S$ the operation is idempotent, then $ab=xbb=xb=a$ and $ba=yaa=ya=b$. \nHence, $\\mathcal L\\subseteq \\theta_S$.\n\n($iv\\Rightarrow i$) Since $\\mathcal L$ is an equivalence, then $\\theta_S$ is an equivalence.\nBy the reflexivity of $\\theta_S$ the semigroup $\\mathbf S$ is idempotent. We now prove that $axa=a$. By symmetry of $\\theta_S$ we conclude:\n$axa=a$ iff $a\\theta_S xa$ iff $xa\\theta_S a$ iff $xaa = xa$.\n\\end{proof}\n\n\\begin{lemma}\nLet $S$ be a rectangular band.\n\\begin{enumerate}\n\\item The equivalence class $a/\\mathcal L$ (resp. $a/\\mathcal  R$)  is the maximal left (right) zero subsemigroup of $S$ containing $a$. \n\\item The congruence $\\mathcal L$ (resp. $\\mathcal  R$) determines a partition of $S$ by the maximal left (right) zero semigroups of $S$.\n\\item $S\\cong S/\\mathcal L\\times S/ \\mathcal R$, where $S/\\mathcal L$ is a right zero semigroup and \n $S/\\mathcal R$ is a left zero semigroup. \n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}\n(3) If $x,y\\in S/\\mathcal L$ and $a\\in x$, $b\\in y$, then $(ab)b=ab$; hence, $ab \\mathcal L b$. In conclusion, $xy=y$.\n\\end{proof}\n\n\n \n%\\begin{definition}\n% Let $\\mathbf A$ be an algebra. A semigroup $S$ is called an $\\mathbf A$-semigroup if the following conditions hold:\n% \\begin{enumerate}\n%\\item $S$ is a rectangular band;\n%\\item $S$ and $\\mathbf A$ have the same universe;\n%\\item $\\sigma^\\mathbf A(a_1,\\dots,a_n)\\sigma^\\mathbf A(b_1,\\dots,b_n)= \\sigma^\\mathbf A(a_1b_1,\\dots,a_nb_n)$.\n%\\end{enumerate}\n%\\end{definition}\n \n \n \n\\section{Appendix: Diagonal Algebras and Rectangular  $n$-bands}\n%Recall that a function $f:S^n\\to S$ is said to be \\emph{associative} if it solves the following system of \n%$n - 1$ functional equations:\n%$$f(x_1,\\dots,x_{i-1},f(x_i,\\dots,x_{i+n-1}),x_{i+n},\\dots,x_{2n-1})$$\n%$$\\qquad = f (x_1,\\dots,x_{i-1},x_i, f(x_{i+1},\\dots,x_{i+n}),x_{n+i+1}, \\dots, x_{2n-1}),\\quad 1\\leq i \\leq n - 1.$$\n%In this case, the pair $(S,f)$ is called an \\emph{$n$-ary semigroup or $n$-semigroup}.\n%\n%An $n$-band is an $n$-semigroup satisfying $f(x,x,\\dots,x)=x$.\n\nP\\l onka's diagonal algebras \\cite{plonka,plonka2} are the natural generalisation of rectangular bands to dimension $n$.\n\n\\begin{definition}\\label{diag} A \\emph{diagonal algebra of dimension $n$} ($n\\mathrm{DA}$, for short) is an algebra $\\mathbf D=(D,d)$ of type $(n)$ satisfying the following identities:\n\\begin{itemize}\n\\item[(D1)] $d(x,x,\\dots,x)=x$; \n\\item[(D2)] $d(d(x_{11},\\dots,x_{1n}),\\dots,d(x_{n1},\\dots,x_{nn}))=d(x_{11},x_{22},\\dots,x_{nn})$.\n\\end{itemize}\n\\end{definition}\nDiagonal algebras of dimension $2$ are the rectangular bands.\n\nThe axioms of a diagonal algebra of dimension $n$ express that the function $d:D^n\\to D$ is a $n$-ary decomposition operator of the algebra $\\mathbf D$.\n\n\\bigskip\n\n%Notation: If $X$ is a $n\\times n$ matrix, then $X_i$ denotes the $i$-th row of $X$, and $X_i^j$ the cross of $i$-th row and $j$-th column. $X^T$ is the transpose of the matrix $X$.\n\n%\\bigskip\n%(D2) can be written as $d(d(X_1),\\dots,d(X_n))=d(X^1_1,\\dots,X^n_n)$.\n\n\\begin{lemma}\\label{lem:decd} Let $\\mathbf D=(D,d)$ be a $n\\mathrm{DA}$. Then the function $d:D^n\\to D$ is a $n$-ary decomposition operator of the algebra $\\mathbf D$.\n\\end{lemma}\n\n\\begin{proof} By axiom (D2) of Definition \\ref{diag} $d$ is self commuting:\n\\[\n\\begin{array}{lll}\nd(d(x_{11},\\dots,x_{1n}),\\dots,d(x_{n1},\\dots,x_{nn}))  & =_{(D2)}  &  d(x_{11},x_{22},\\dots,x_{nn}) \\\\\n  &  =_{(D2)} &  d(d(x_{11},\\dots,x_{n1}),\\dots,d(x_{1n},\\dots,x_{nn})).\\\\\n\\end{array}\n\\]\nThen it follows that $d$ satisfies condition (D3) of Definition \\ref{def:decomposition}.\n\\end{proof}\n\n\n\nFor every $1\\leq i\\leq n$, we define a groupoid $\\mathbf D_i=(D,d_i)$ as follows:\n$$d_i(x,y)=d(x/ i,y/\\bar i).$$\n\n\n\\begin{proposition}\\label{propstar} The following conditions hold:\n\\begin{enumerate}\n\\item  $\\mathbf D_i$ is a rectangular band, for every $1\\leq i\\leq n$;\n\\item $d_i$ and $d_k$ commute for all $i$ and $k$:\n$$d_i(d_k(x, y), d_k(z, u))= d_k(d_i(x, z), d_i(y, u))=\\begin{cases}d(y/i, z/k, u/\\overline{\\{i,k\\}})&\\text{if $i\\neq k$}\\\\\nd_i(x, u)&\\text{if $i=k$}\n\\end{cases}$$\n\\item For every $i\\neq k$, \n$$d_i(x, d_k(y, z))= d_k(y, d_i(x, z))=d(x/i, y/k, z/\\overline{\\{i,k\\}});$$\n%(y\\cdot_k z)\\cdot_i u= (y\\cdot_i u)\\cdot_k z$ ($i\\neq k$).\n\\item $d(x_1,\\dots,x_n)= d_1(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))$;\n\\item For all permutations $\\sigma$ and $\\tau$ of $1,\\dots,n$,\n$$d(x_{\\sigma 1},\\dots,x_{\\sigma n})= d_{\\tau 1}(x_{\\sigma\\tau 1},d_{\\tau 2}(x_{\\sigma\\tau 2},\\dots, d_{\\tau(n-1)}(x_{\\sigma\\tau(n-1)}, x_{\\sigma\\tau n})\\dots)).$$\n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof} (1) By (D1) $\\mathbf D_i$ is a band.\nThe other laws of rectangular bands are obtained as follows:\n $$d_i(d_i(x, y), z) =_{(D2)} d(x, z)=_{(D2)} d_i(x, d_i(y, z)).$$\n% = d(d(x/\\bar i,y/i)/\\bar i,z/i)\n%= d(x/\\bar i,d(y/\\bar i,z/i)/i)\n%We have $x\\cdot_i x=x$, $x\\cdot_i (y\\cdot_i z)= (x\\cdot_i y)\\cdot_i z$ and $x\\cdot_i y\\cdot_i x=x$.\n\n(2) If $i=k$ then we apply (1). Let now $i\\neq k$.\n$$\\begin{array}{lll} d_i(d_k(x, y), d_k(z, u)) &=& d(d_k(x, y)/i, d_k(z, u)/\\bar i) \\\\\n&=& d(d(x/k,y/\\bar k)/i, d(z/k,u/\\bar k)/\\bar i) \\\\\n&=_{(D2)}& d(y/i, z/k, u/\\overline{\\{i,k\\}}).\\\\\n&=& d_k(d_i(x, z), d_i(y, u))\n\\end{array}$$\n%By symmetry we also get $= d(y/i, z/k, u/\\overline{\\{i,k\\}})$.\n\n%$$\\begin{array}{lll} (x\\cdot_i y)\\cdot_i (z\\cdot_i u) &=& d((x\\cdot_i y)/i, (z\\cdot_i u)/\\bar i) \\\\\n%&=& d(d(x/i,y/\\bar i)/i, d(z/i,u/\\bar i)/\\bar i) \\\\\n%&=_{(D2)}& d(x/i, u/\\bar i)\\\\\n%&=&(x\\cdot_i z)\\cdot_i (y\\cdot_i u).\\\\\n%\\end{array}$$\n\n(3) It follows from (2) because $d_i(x, d_k(y, z))= d_i(d_k(x,x),d_k(y, z))=d(x/i, y/k, z/\\overline{\\{i,k\\}})$\nand similarly for the other term of the equality.\n%By (2) and (D1) we have \n%$$x\\cdot_i (y\\cdot_k z) = (x\\cdot_k x)\\cdot_i (y\\cdot_k z) = d(x/i, y/k, z/\\overline{\\{i,k\\}})$$ \n%and\n%$$y\\cdot_k (x\\cdot_i z) = (y\\cdot_i y)\\cdot_k (x\\cdot_i z) = d(x/i, y/k, z/\\overline{\\{i,k\\}}).$$\n\n(4) \n\\[\n\\begin{array}{lll}\n d_1(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))&  =_{(D2)} &  d(x_1, d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots)/ \\bar 1) \\\\\n  & =_{(D2)}  &d(x_1, x_2, d_3(x_3,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots)/\\overline{\\{1,2\\}})   \\\\\n  & =  &\\dots\\\\\n   & =_{(D2)}  &d(x_1,\\dots,x_n).\n\\end{array}\n\\]\n\\end{proof}\n\n\n%$d(d(x_1,y_2,\\dots,y_n), x_2,\\dots,x_n)=[x_1\\cdot_1(y_2\\cdot_2(\\dots (y_{n-1}\\cdot_{n-1} y_n)\\dots))] \\cdot_1(x_2\\cdot_2(\\dots (x_{n-1}\\cdot_{n-1} x_n)\\dots))$\n\n\n\n\n\n\\subsection{Appendix: Rectangular  $n$-bands}\\label{ssa}\nThe semigroup reducts of a $n$DA are so deeply related that they allow us to recover the full structure of the $n$DA.\nIt is worthwhile introducing a new variety of algebras, called {\\em rectangular bands of dimension $n$}, equationally axiomatising \n$n$   rectangular bands and their relationships. In the main result of this section we prove that the variety of \nrectangular bands of dimension $n$ is term equivalent to the variety of $n$DAs.\n\nBy Proposition \\ref{propstar} we have that the identity \n$$d(x_1,\\dots,x_n)= d_1(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))$$ holds in every $n\\mathrm{DA}$. It follows that \n$$d_n(y, z)=d_1(z,d_2(z,\\dots, d_{n-1}(z, y)\\dots)),$$\nso that $d_n$ is term definable by the remaining $d_i$ ($1\\leq i\\leq n-1$). This is one of the reasons for introducing $n-1$ (and not $n$) binary operators in the following definition.\nAnother reason is  technical simplification.\n\n\\begin{definition}\n An algebra $\\mathbf B= (B,d_1,\\dots,d_{n-1})$, where $d_i$ is binary for every $1\\leq i\\leq n$, is called\n a \\emph{rectangular band of dimension $n$}  if the following conditions hold, for every $1\\leq i,k\\leq n-1$:\n \\begin{itemize}\n\\item[(R1)] $\\mathbf B_i=(B,d_i)$ is a rectangular band.\n\\item[(R2)]  $d_i(d_k(x, y), d_k(z, u))= d_k(d_i(x, z), d_i(y, u))$.\n\\item[(R3)] $d_i(x, d_k(y, z))= d_k(y, d_i(x, z))$ ($i\\neq k$).\n\\end{itemize}\n%x+(y+z)=(x+y)+z.\n%x*(y*z)=(x*y)*z.\n%x+x=x.\n%x*x=x.\n%x+(y+z)=x+z.\n%x*(y*z)=x*z.\n%(x+y)*(z+u)= (x*z)+(y*u).\n%x+(y*z)=y*(x+z).\n%f(x,x,x)=x.\n%f(f(x,y,z),f(x1,y1,z1),f(x2,y2,z2))=f(x,y1,z2).\n%x+y=f(x,y,y).\n%x*y=f(y,x,y).\n%f(x,y,z)= x*(y+z).\n\\end{definition}\nIn the following we write rectangular $n$-band for rectangular band of dimension $n$.\n\n\nRectangular $2$-bands are the usual rectangular bands, because (R2) is trivially true in every rectangular band and (R3) is not applicable.\n\n\n\nWe now are going to prove that the variety of rectangular $n$-bands and of $n\\mathrm{DA}$s are term equivalent.\nConsider the following correspondence between the algebraic similarity types of $n$DAs and of  rectangular $n$-bands.\n\\begin{itemize}\n\\item Beginning on the $n$DA side: $d_i(x, y)=d(x/ i,y/\\bar i)$ ($1\\leq j\\leq n$).\\\\ \nIf $\\mathbf D=(D,d)$ is a $n$DA, then $\\mathbf  D^* = (D;d_1,\\dots,d_{n-1})$ denotes the corresponding algebra in the similarity type of rectangular $n$-bands.\n\n\\item Beginning on the  rectangular $n$-band side: \n$$d^\\bullet(x_1,\\dots,x_n)= d_1(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))$$\nIf $\\mathbf B=(B,d_1,\\dots,d_{n-1})$ is a  rectangular $n$-band, then $\\mathbf  B^\\bullet = (B; d^\\bullet)$ denotes the corresponding algebra in the similarity type of $n$DAs.\\\\ \n\\end{itemize}\n\nIt is not difficult to prove the following theorem.\n\n\\begin{theorem}\\label{thm:equivalence}\n  The above correspondences define a term equivalence between the varieties of $n\\mathrm{DA}$s and of  rectangular $n$-bands. More precisely,\n  \\begin{itemize}\n\\item[(i)] If $\\mathbf D=(D,d)$ is a $n\\mathrm{DA}$, then $\\mathbf  D^*$ is a  rectangular $n$-band;\n\\item[(ii)] If $\\mathbf B=(B,d_1,\\dots,d_{n-1})$ is a  rectangular $n$-band, then $\\mathbf  B^\\bullet$ is a $n\\mathrm{DA}$;\n\\item[(iii)] $(\\mathbf D^*)^\\bullet = \\mathbf D$;\n\\item[(iv)] $(\\mathbf  B^\\bullet)^* =  \\mathbf B$.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof} (i) follows from Proposition \\ref{propstar}.\n \n(ii) (D1) derives from (R1). \nBy (R1) and (R2), the binary operations $d_i$ ($1\\leq i\\leq n-1$) are commuting decomposition operators on $\\mathbf B$.\nThen $d^\\bullet$ is a $n$-ary decomposition operator on $B^\\bullet$ (i.e., (D1)-(D3) hold), because commuting decomposition operators are closed under composition (see \\cite{mac}, Proposition \\ref{commute} and Proposition \\ref{commute2}). \n\n(iii) Let $(D,d)$ be a $n$DA. Since $d_i(x, y)=d(x/i,y/\\bar i)$, then by (D2) we have: \n\\[\n\\begin{array}{lll}\nd^\\bullet(x_1,\\dots,x_n)  &  = & d_1(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))  \\\\\n  & =  &  d(x_1,d_2(x_2,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots)) \\\\\n  & =  &   d(x_1,x_2,d_3(x_3,\\dots, d_{n-1}(x_{n-1}, x_n)\\dots))\\\\\n  &\\dots&\\\\\n  &=& d(x_1,\\dots,x_n).\n\\end{array}\n\\]\n\n(iv) Let $(B,d_1,\\dots,d_{n-1})$ be a  rectangular $n$-band. The conclusion  follows because by (R3) \n$$d^\\bullet(x_1,\\dots,x_n)=d_i(x_i,d_1(x_1,\\dots, d_{i-1}(x_{i-1},d_{i+1}(x_{i+1},\\dots d_{n-1}(x_{n-1}, x_n)\\dots))\\dots))$$\nThen\n$$d^\\bullet(x/i, y/\\bar i)=d_i(x,d_1(y,\\dots, d_{i-1}(y,d_{i+1}(y,\\dots d_{n-1}(y, y)\\dots))\\dots)) =_{(R1)}\\dots=_{(R1)} d_i(x, y)$$\n\\end{proof}\n\n\n\\begin{definition}\n An algebra $\\mathbf D$ of type $(n)$ is $n$-associative if\n\\[\n\\begin{array}{lll}\nd(d(x_1,y_2,\\dots,y_n),x_2,\\dots,x_n)  &  = & d(x_1,d(y_2,x_2,y_3,\\dots,y_n),x_3,\\dots,x_n)  \\\\\n  & =  & \\dots  \\\\\n  &  = &  d(x_1,x_2,\\dots,x_{n-1},d(y_2,y_3,\\dots,y_n,x_n)).\n\\end{array}\n\\]\n\\end{definition}\n\nThe proof of the following theorem is similar to that of Theorem \\ref{thm1} and Theorem \\ref{thm2} and it is omitted (see \\cite{plonka,plonka2} and \\cite[Section 6]{davey}). \n\nLet $\\mathbf D=(D,d)$ be an algebra of type $(n)$ and $\\mathbf D_i=(D,d_i)$, where $d_i(x,y)=d(x/i,y/\\bar i)$. We define \n$$\\theta^D_i = \\{ (a,b): d_i(a,b)=a\\};\\qquad \\bar \\theta^D_i = \\{ (a,b): d_i(a,b)=b\\}.$$\n\n\\begin{theorem}\\label{thm3} The following conditions are equivalent for an algebra $\\mathbf D=(D,d)$ of type $(n)$:\n\\begin{enumerate}\n\\item[(i)] $\\mathbf D$ is a $n\\mathrm{DA}$;\n\\item[(ii)] $\\mathbf  D^*=(D,d_1,\\dots,d_n)$ is a rectangular $n$-band;\n\\item[(iii)] $(\\bar\\theta^D_1,\\dots,\\bar\\theta^D_n)$ is a tuple of complementary factor congruences of $\\mathbf D$ such that $a_i \\theta_i d(a_1,\\dots,a_n) $ for all $i=1,\\dots,n$ and all $a_1,\\dots,a_n\\in D$;\n\\item[(iv)] There exist projection algebras $\\mathbf L_1,\\dots,\\mathbf L_n$ such that $\\mathbf L_i$ projects into $i$-th coordinate and $\\mathbf D\\cong \\mathbf L_1\\times\\dots\\times\\mathbf  L_n$;\n\\item[(v)] $\\mathbf D$ is isomorphic to an algebra of the form $A_1\\times A_2\\times\\dots\\times A_n$, where $A_i$ is a non-empty set, and where the $n$-ary operation $d$ is given by  \n$$d(a_{11}\\dots a_{1n},a_{21}\\dots a_{2n},\\dots,a_{n1}\\dots a_{nn})= a_{11}\\dots a_{nn}.$$\n\\item[(iv)] $\\mathbf D$ is $n$-associative and,\nfor all $a,b\\in D$, \n$$d_1(a, b)=d_2(a, b)=\\dots=d_n(a, b) \\Rightarrow a=b.$$\n\\item[(vi)] $\\mathbf D$ is $n$-associative and $\\theta^D_i=\\mathcal L^D_i$ for every $i$.\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{proof} ($i\\Leftrightarrow ii$) By Theorem \\ref{thm:equivalence}. \n\n($i\\Rightarrow iii$) By Lemma \\ref{lem:decd}  $d$ is a $n$-ary decomposition operator on $\\mathbf D$. Then the conclusion follows from Theorem \\ref{prop:pairfactor}.\n\\end{proof}\n\n\n\n\n\n\\end{document}\n\n\n\n\n\\section{De Morgan bisemigroups}\n\nAn algebra $(D,\\land,\\lor)$ of type $(2,2)$ is called a \\emph{bisemigroup} if the binary operations $\\land$ and $\\lor$ are associative.\n\nAn algebra $(D,\\land,\\lor,',0,1)$ of type $(2,2,1,0,0)$ is called a \\emph{$01$-algebra} if it satisfies the identities\n\\begin{itemize}\n\\item[D0] $1\\land x = x;\\quad 0\\lor x = x;\\quad 0\\land x=0;\\quad 1\\lor x=1$.\n\\end{itemize}\n\n\n\n\\begin{definition} \\cite{}\n  A {\\em De Morgan bisemigroup} ($\\mathrm{DMB}$, for short) is a $01$-algebra $\\mathbf D = (D,\\land,\\lor,',0,1)$ satisfying the following conditions:\n\\begin{itemize}\n\\item[D1] $(D,\\land,\\lor)$ is a bisemigroup;\n\\item[D2] $(x')'=x\\land 1  = x\\lor 0$;\n\\item[D3] $(x\\wedge y)^{\\prime}=x^{\\prime}\\vee y^{\\prime}$ and $(x\\vee y)^{\\prime}=x^{\\prime}\\wedge y^{\\prime}$.\n\\item[D4] $(x')' = x$;\n\\item[D5] $x\\land 0=0$ and $x\\lor 1=1$.\n\\end{itemize}\n\\end{definition}\n\nIn this paper we define three weak versions of De Morgan bisemigroups.\n\n\\begin{definition} Let $\\mathbf D$ be a $01$-algebra. Then $\\mathbf D$ is called a \n\\begin{description}\n\\item[(i)] \\emph{ultraweak} $\\mathrm{DMB}$ ($\\mathrm{UDMB}$, for short) if it satisfies identities (D1), (D2) and (D3).\n \\item[(ii)]  \\emph{weak} $\\mathrm{DMB}$ ($\\mathrm{WDMB}$, for short) if it satisfies identities (D1), (D2), (D3) and (D4).\n \\item[(iii)] \\emph{semi} $\\mathrm{DMB}$ ($\\mathrm{SDMB}$, for short) if it satisfies identities (D1), (D2), (D3) and (D5).\n\\end{description}\n\\end{definition}\n\nA (U,W,S)-DMB $\\mathbf A$ is called a {\\em (U,W,S)-De Morgan  double band} if $(A,\\land,\\lor)$ is a  double band (i.e., an idempotent bisemigroup).\n\n\\begin{lemma} Let $\\mathbf D$ be a $\\mathrm{SDMB}$. Then $0'=1$ and $1'=0$.\n\\end{lemma}\n\n\\begin{proof} First we have: $(0')'=_{D2}0\\land 1=_{D0}0$ and $(1')'=_{D2} 1\\land 1=_{D0}1\\lor 0 =_{D0} 1$.\n Moreover,  $0=0\\land 1'= (0')'\\land 1' = (0'\\lor 1)'=_{D5} 1'$.\n\\end{proof}\n \n\\begin{definition} Let $\\mathbf D = (D,\\land,\\lor,',0,1)$ be a $01$-algebra and let $e\\in D$.\nWe say that $\\mathbf D$ is a $\\mathrm{DMB}(e)$ if it satisfies the following identities:\n\\begin{itemize}\n\\item[D1(e)]  $A_\\land(e)$ and $A_\\lor(e)$;\n\\item[D2(e)] $(e')'=e\\land 1= e\\lor 0$;\n\\item[D3(e)] $\\forall y.\\ (e\\wedge y)^{\\prime}=e^{\\prime}\\vee y^{\\prime}$ and $\\forall y.\\ (e\\vee y)^{\\prime}=e^{\\prime}\\wedge y^{\\prime}$.\n\\item[D4(e)] $(e')'=e$;\n\\item[D5(e)] $e\\land 0=0$ and $e\\lor 1=1$.\n\\end{itemize}\nSimilarly for the weak versions of $\\mathrm{DMB}$s.\n\\end{definition}\n \nLet $\\mathbf A$ be a CA. As usual, we define $x\\wedge y=q(x,y,0)$, $x\\vee y=q(x,1,y)$ and $x^{\\prime}=q(x,0,1)$.\n\nWhen there is no danger of confusion, we write ``A CA $\\mathbf A$ is a (U,W,S)DMB (resp., a $01$-algebra)'' for  ``the reduct $(A,\\land,\\lor,',0,1)$ of $\\mathbf A$ is a (U,W,S)DMB (resp., a $01$-algebra)''.\n\n\n\\begin{lemma}\n Any CA is a $01$-algebra.\n\\end{lemma}\n\n\n\n\n\\section{Substitutive Elements}\\label{sec:factor}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nLet $\\mathbf A$ be a CA, We consider the following properties of elements of $A$:\n\\begin{itemize}\n\\item $S(e)$ iff   $\\forall xyut.\\ q(q(e,x,y),u,t) = q(e, q(x,u,t), q(y,u,t))$.\n\\item $I(e)$ iff $e\\land e=e$ and $e\\lor e=e$.\n\\item $P(e)$ iff $\\forall xy.\\ q(e,q(e,x,y),y) =q(e,x,y)= q(e,x,q(e,x,y))$.\n\\item $D(e)$ iff $\\forall x.\\ q(e,x,x)=x$.\n\\item $U(e)$ iff $q(e,1,0)=e\\lor 0=e\\land 1=e$.\n\\item $A_\\land(e)$ iff $\\forall xy.\\ e\\land (x\\land y) = (e\\land x)\\land y$.\n\\item $A_\\lor(e)$ iff $\\forall xy.\\ e\\lor (x\\lor y) = (e\\lor x)\\lor y$.\n\\end{itemize}\n%We write $D(e)$ for $\\forall x.\\ D(e,x)$.\n\nThe constant $e=0,1$ satisfy all above properties.\n\nThe following  definition equationally characterises the elements of a CA.\n\n\\begin{definition}\\label{lem:factor} An element $e\\in A$ is called \n\\begin{itemize}\n\\item  \\emph{substitutive} if it satisfies the property $S$.\n\\item \\emph{idempotent} if it satisfies the property $I$.\n\\item \\emph{projective} if it satisfies the property $P$.\n\\item \\emph{diagonal} if it satisfies the property $D$.\n\\item \\emph{unital} if it satisfies the property $U$.\n\\end{itemize}\nA $\\mathrm{CA}$ is called substitutive if it satisfies $\\forall x.S(x)$. Similarly for the other properties.\n\\end{definition}\nWe denote by $\\mathrm{S}(\\mathbf{A})$ the set of substitutive elements of $\\mathbf{A}$.\n\nWe write $S(a,b,c)$ for $S(a)$ and $S(b)$ and $S(c)$. Similarly for the other properties.\n\n\n\\begin{lemma}\\label{sipd1} Let $\\mathbf{A}$ be a $\\mathrm{CA}$ and let $e\\in A$ such that $S(e)$. Then we have:\n \\begin{enumerate}\n\t\t\\item[(a)] $\\forall yz. q(e^{\\prime},y,z)=q(e,z,y)$.\n\t\t\\item[(b)] $\\forall yz. q(e,y,z)^{\\prime}=q(e,y',z')$.\n\t\t\\item[(c)] De Morgan Laws: $\\forall y. (e\\wedge y)^{\\prime}=e^{\\prime}\\vee y^{\\prime}$ and $\\forall y. (e\\vee y)^{\\prime}=e^{\\prime}\\wedge y^{\\prime}$.\n\t\t\\item[(d)] $(e')'=e\\land 1$.\n\t\t\\item[(e)] $A_\\land(e)$ and $A_\\lor(e)$.\n\t\t\\item[(f)] $a \\theta_e b \\Rightarrow \\forall xy.\\ q(a,x,y) \\theta_e q(b,x,y)$. Similarly for $\\bar\\theta_e$.\n\t\t\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}\n \\begin{itemize}\n\t\\item[(a)] $q(a',b,c)= q(q(a,0,1),b,c)=_{S(a)}q(a,c,b)$.\n\n\t\\item[(b)] $q(a,b,c)'= q(q(a,b,c),0,1)=_{S(a)}q(a,q(b,0,1),q(c,0,1))= q(a,b',c')$.\n\n\t\\item[(c)] $(a\\wedge b)^{\\prime} = q(q(a,b,0),0,1)=_{S(a)}q(a,b',1)=_{(8a)}q(a',1,b')$. Similarly, for the other identity.\n\n\t\\item[(d)] $q(q(e,0,1),0,1)=_{S(e)} q(e, 1,0)=e\\land 1$.\n\n\t\\item[(f)] If $a\\theta_e b$ then there is an element $y$ such that $q(e,y,a)=b$. Then from\n\t$q(b,c,d)=q(q(e,y,a),c,d) =_{S} q(e, q(y,c,d), q(a,c,d))$ and  it follows that $q(a,c,d) \\theta_e q(b,c,d).$\n\t\\end{itemize}\n\\end{proof}\n\n\\begin{lemma}\\label{sipd2} Let $\\mathbf{A}$ be a $\\mathrm{CA}$ and let $e,a,b,c\\in A$. Then we have:\n\\begin{enumerate}\n\\item $S(e) \\ \\text{and}\\ I(e)\\Rightarrow P(e)$.\n\\item $P(e)\\ \\text{and}\\ U(e)\\Rightarrow I(e)$. %Then $S(e)\\ \\text{and}\\ U(e)\\Rightarrow (I(e)$ iff $P(e))$.\n\\item $S(a,b,c)\\Rightarrow S(q(a,b,c))$.\n\\item $S(a) \\ \\text{and}\\ U(b,c)\\Rightarrow U(q(a,b,c))$.\n\\item $S(a,b,c) \\ \\text{and}\\ I(a,b,c)\\not\\Rightarrow I(q(a,b,c))$.\n%\\item $S(e) \\Rightarrow A_\\land(e)$ and $A_\\lor(e)$.\n\\item $S(e) \\ \\text{and}\\ P(e)\\Rightarrow I(e\\land e)\\ \\text{and}\\ S(e\\land e)$. The same for $\\lor$.\n\\item $S(e) \\ \\text{and}\\ U(e)\\Rightarrow U(e\\land e)$ and $U(e\\lor e)$ and $(e')'=e$. \n\\item If $S(e)$ and $U(e)$, then the following conditions are equivalent:\n\\begin{enumerate}\n\\item $I(e)$.\n\\item $P(e)$.\n\\item $\\forall ab(a \\theta_e b \\Leftrightarrow q(e,b,a)=b)$.\n\\item $\\forall ab(a \\bar\\theta_e b \\Leftrightarrow q(e,b,a)=a)$.\n%\\item $0 \\theta_e e$ and $e \\bar\\theta_e 1$.\n\\end{enumerate}\n\\item If $I(a)$ and $P(a)$, then $q(a,a,a)=a$.\n\\item  If $S(a)$ and $I(b)$, then $q(a,b,b)=(a\\land b)\\lor b=(a\\lor b)\\land b$.\n\\end{enumerate} \n\\end{lemma}\n\n\n\n\n\\begin{proof} (1) $q(e,q(e,x,y),y) =q(e,q(e,x,y),q(0,x,y))=_{S(e)}q(q(e,e,0),x,y)=_{I(e)} q(e,x,y)$. Similarly for the other equality.\n\n(2) $q(e,e,0)=_{U(e)}q(e,q(e,1,0),0) =_{P(e)} q(e,1,0)=_{U(e)}e$\nand similarly $q(e,1,e)=_{U(e)}q(e,1,q(e,1,0)) =_{P(e)} q(e,1,0)=_{U(e)}e$.\n\n(3)  Let $a,b,c$ be substitutive elements and let $d=q(a,b,c)$. We show that $d$ is also a substitutive element.\n\\[\n\\begin{array}{ccll}\nq(q(d,x,y),u,t) &  = & q(q(a, q(b, x,y), q(c, x,y)),u,t)&\\text{by S(a)}\\\\\n  &  = &q(a, q(q(b, x,y),u,t),q(q(c, x,y),u,t))) &\\text{by S(a)}\\\\\n  &  = &q(a, q(b,q(x,u,t), q(y,u,t)),q(c,q(x,u,t), q(y,u,t))) &\\text{by S(b,c)}\\\\\n  &  = &q(d, q(x,u,t), q(y,u,t))  &\\text{by S(a)}\n\\end{array}\n\\]\n\n(4) $q(q(a,b,c),1,0)=q(a, q(b, 1,0), q(c, 1,0))=q(a,b,c)$.\n\n(5) By Prover9 there is a counterexample of cardinality $4$.\n\n(6) By (5) $q(e,e,0)$ is substitutive.\nWe show that $q(e,e,0)$ is idempotent:\n\\[\n\\begin{array}{llll}\nq(q(e,e,0),q(e,e,0),0) &  = &  q(e,q(e,q(e,e,0), 0),0) &\\text{by $S(e)$}  \\\\\n\t\t&  = &  q(e,q(e,e, 0),0) &\\text{by $P(e)$}  \\\\\n  & =  &  q(e,e,0)&\\text{by $P(e)$}\\\\\n\\end{array}\n\\]\n\n(7) $q(q(e,e,0),1,0)=_{S(e)} q(e,q(e,1, 0),0)=_{U(e)}q(e,e,0)$.\n\n\n\n(8) The equivalence of (a) and (b) follows from (1)-(2).\n\n(b) $\\Rightarrow$ (c): If $a \\theta_e b$ then, by definition of $\\theta_e$, there exists $c$ such that $b= q(e,c,a)$. Then by (b) we have: $q(e,b,a)=q(e,q(e,c,a),a)=q(e,c,a)=b$. \n\n(b) $\\Rightarrow$ (d): If $a \\bar\\theta_e b$ then, by definition of $\\bar\\theta_e$, there exists $c$ such that $a= q(e,b,a)$. Then by (b) we have: $q(e,b,a)=q(e,b,q(e,b,c))=q(e,b,c)=a$. \n\n(c) $\\Rightarrow$ (b): By definition of $\\theta_e$ we have $b \\theta_e q(e,a,b)$. By hypothesis (c) this means that\n$q(e,q(e,a,b),b)= q(e,a,b)$. For the other identity, from $q(e,b,a) \\bar\\theta_e b$ and (c) we derive $q(e,b,q(e,b,a))= q(e,b,a)$.\n\n(9)  $q(a,a,a)= q(a,a,q(a,a,0))=_{P(a)}q(a,a,0)=_{I(a)} a$.\n\n(10) \n $(a\\land b)\\lor b=q(q(a,b,0),1,b)=_{S(a)} q(a,q(b,1,b),b)=_{I(b)}q(a,b,b)$ and\n $(a\\lor b)\\land b=q(q(a,1,b),b,0)=_{S(a)} q(a,b,q(b,b,0))=_{I(b)} q(a,b,b)$.\n%\n%(e) $\\Rightarrow$ (a): If $0\\theta_e e$ then there is $b$ such that $e=q(e,b,0)$. Then\n%$q(e,e,0)= q(q(e,b,0),e,0)=_{S(e)} q(e,q(b,e,0),0)=$. Similarly for the other.\n\\end{proof}\n\n\n\n\n%\\begin{proposition}\n%\\label{coseilcentro}If $\\mathbf{A}$ is an ICA and $e\\in A$, then\n% $e$ is a substitution element if, and only if,\n%the  relations\n%$$\\text{$\\theta_e= \\{ (x,y) : q(e,x,y) = x\\}$ and  $\\bar\\theta_e=\\{ (x,y) : q(e,x,y) = y\\}$}$$ \n%constitute a pair of complementary relations of $\\mathbf{A}$.\n%\\end{proposition}\n\n\n\n\n%\\begin{lemma} Let $\\mathbf{A}=(A, \\cdot_a, 0)_{a\\in A}$ be an algebra, where $0$ is a constant and each operation  $\\cdot_a$ is binary. \n%If there exists a subalgebra $B$ of $\\mathbf{A}$ satisfying the following conditions, for all $x,y,x',y'\\in A$ and $a,b,c\\in B$:\n%\\begin{enumerate}\n%\\item $x\\cdot_a x= x$;\n%\\item $x\\cdot_0 y=y$;\n%\\item $(x\\cdot_a y) \\cdot_{(b\\cdot_a c)} (x' \\cdot_a y') = (x\\cdot_b x') \\cdot_a (y\\cdot_c y')$;\n%\\item $a\\cdot_a 0=a$.\n%\\end{enumerate}\n%Then, for every $a\\in B$, the groupoid $(A,\\cdot_a)$ is a rectangular band.\n%\\end{lemma}\n%\n%\\begin{proof}\n% Associativity: \n% \\[\n%\\begin{array}{llll}\n% x \\cdot_a (y\\cdot_a z) &  = &   (x\\cdot_a x) \\cdot_a (y\\cdot_a z)&\\text{by (1)}\\\\\n%  & =  & (x\\cdot_a x) \\cdot_{(a\\cdot_a 0)} (y\\cdot_a z)&\\text{by (4)}  \\\\\n%  & =  &   (x\\cdot_a y) \\cdot_a (x\\cdot_0 z)&\\text{by (3)}\\\\\n%   & =  &  (x\\cdot_a y) \\cdot_a  z&\\text{by (2)}\n%\\end{array}\n%\\]\n%\n%  \n% Rectangularity: \n% \\[\n%\\begin{array}{ccll}\n% (y\\cdot_a z) \\cdot_a u&  = &  (y\\cdot_a z) \\cdot_a (u  \\cdot_a u) &\\text{by (1)}\\\\\n%  &  = & (y\\cdot_a z) \\cdot_{(a\\cdot_a 0)} (u  \\cdot_a u) &\\text{by (4)}\\\\\n%  &  = &  (y\\cdot_a u) \\cdot_a (z  \\cdot_0 u) &\\text{by (3)}\\\\\n%  &  = &  (y\\cdot_a u) \\cdot_a u &\\text{by (2)}\\\\\n%  &  = &   y\\cdot_a (u \\cdot_a u) &\\text{by associativity}\\\\\n%  &  = & y \\cdot_a  u  &\\text{by (1)}\\\\\n%  \n%\\end{array}\n%\\]\n%\\end{proof}\n\nWe denote by $\\mathrm{SU}(\\mathbf{A})$ the set of elements of $A$ that are simultaneously substitutive and unital.\n\n\\begin{corollary}\\label{prop-closure} Let $\\mathbf{A}$ be a  $\\mathrm{CA}$. Then $\\mathrm{S}(\\mathbf{A})$ and $\\mathrm{SU}(\\mathbf{A})$ are subalgebras of $\\mathbf{A}$.\n\\end{corollary}\n\n\\begin{proof} By Lemma \\ref{sipd2}(3)-(4).\n%\n%Let $a,b,c$ be substitution elements and let $d=q(a,b,c)$. We show that $d$ is also a substitution element.\n%We first prove that $q(d,q(d,x,y),y) = q(d,x,y)$,\n%by applying $d=_{\\mathrm{Idemp.}}q(d,d,0)=q(a,q(b,d,0),q(c,d,0))$: \n%\n%\\[\n%\\begin{array}{llll}\n%q(d,x,y)  & =  &  q(q(a,q(b,d,0),q(c,d,0)) ,x,y) &\\text{by $d=q(a,q(b,d,0),q(c,d,0))$}\\\\\n%  & =  &  q(a,q(q(b,d,0),x,y),q(q(c,d,0),x,y))&\\text{by S2} \\\\\n%  & =  &  q(a,q(b,q(d,x,y),y),q(c,q(d,x,y),y))&\\text{by S2} \\\\  \n%  & =  &   q(a,q(b,q(a,q(b,x,y),q(c,x,y)),y),q(c,q(a,q(b,x,y),q(c,x,y)),y))&\\text{by S2} \\\\\n%  & =  &  q(d,q(a,q(b,x,y),q(c,x,y)),y)&\\text{by S2} \\\\\n%   & =  &  q(d,q(d,x,y),y).\n%\\end{array}\n%\\]\n%Similarly, we prove $q(d,x,q(d,x,y)) = q(d,x,y)$,\n%by applying $d=_{\\mathrm{Idemp.}}q(d,1,d)=q(a,q(b,1,d),q(c,1,d))$: \n%\\[\n%\\begin{array}{llll}\n%q(d,x,y)  & =  &  q(q(a,q(b,1,d),q(c,1,d)) ,x,y) &\\text{by $d=q(a,q(b,1,d),q(c,1,d))$}\\\\\n%  & =  &  q(a,q(q(b,1,d),x,y),q(q(c,1,d),x,y))&\\text{by S2} \\\\\n%  & =  &  q(a,q(b,x,q(d,x,y)),q(c,x,q(d,x,y)))&\\text{by S2} \\\\  \n%  & =  &   q(a,q(b,x,q(a,q(b,x,y),q(c,x,y))),q(c,x,q(a,q(b,x,y),q(c,x,y))))&\\text{by S2} \\\\\n%  & =  &  q(d,x,q(a,q(b,x,y),q(c,x,y)))&\\text{by S2} \\\\\n%   & =  &  q(d,x,q(d,x,y)).\n%\\end{array}\n%\\]\n%\n\\end{proof}\n\n\\begin{definition}\n\\label{prop:church} A substitutive and unital $\\mathrm{CA}$ $\\mathbf{A}$ is called a \\emph{substitution Church algebra} ($\\mathrm{SCA}$, for short).\n\\end{definition}\n\n%As usual, define $x\\wedge y=q(x,y,0)$, $x\\vee y=q(x,1,y)$ and $x^{\\prime}=q(x,0,1)$.\n\n\n\n\\begin{corollary}\\label{morgan} Let $\\mathbf A$ be a $\\mathrm{CA}$ and let $e\\in A$. \n\\begin{enumerate}\n\\item If $S(e)$, then $(A,\\wedge,\\lor,',0,1)$ is a $\\mathrm{UDMB}(e)$.\n\\item If $S(e)$ and $U(e)$, then $(A,\\wedge,\\lor,',0,1)$ is a $\\mathrm{WDMB}(e)$.\n\\item If $\\mathbf A$ is a $\\mathrm{SCA}$, then $(A,\\wedge,\\lor,',0,1)$ is a $\\mathrm{WDMB}$.\n\\end{enumerate}\n\\end{corollary}\n\n\\begin{proof} (1) By Lemma \\ref{sipd1}(c,d,e).\n\n(2) By (1) and U(e), because $q(e,1,0)=e\\land 1=e$.\n\\end{proof}\n\n\\begin{lemma}\\label{idem} The following conditions are equivalent for a $\\mathrm{SCA}$ $\\mathbf A$:\n%q(a,q(x,1,x),x)=q(a,x,x)\n\\begin{itemize}\n\\item[(i)]  $\\mathbf A$ is idempotent.\n\\item[(ii)]  $\\mathbf A$ is projective.\n\\item[(iii)] $\\mathbf A\\models \\forall abx(a\\theta_x b \\Leftrightarrow q(x,b,a)=b)$.\n\\item[(iv)] $\\mathbf A\\models \\forall abx(a\\theta_x b \\Leftrightarrow q(x,b,a)=a)$.\n\\end{itemize}\n\\end{lemma}\n\n\n\\begin{proof} By Lemma \\ref{sipd2}(8).\n\\end{proof}\n\n\n\n%\\section{Substitution Church algebras} \n%%Let $\\nu$ be a type of algebra and let $\\nu^{\\prime}=\\nu\\cup\\{q,0,1\\}$ be the expansion of $\\nu$ by the ternary operation symbol $q$ and the constants $0,1$.\n%\n%\n%\n%%Any $\\mathrm{ SCA}$ satisfies\n%%\\begin{itemize}\n%%\\item $\\forall abc.\\ q(a^{\\prime},b,c)=q(a,c,b)$ and $\\forall abc.\\ q(a,b,c)^{\\prime}=q(a,b',c')$.\n%%\\end{itemize}\n%\n%\n%\n%\\begin{definition}\n% If $\\mathbf{A}$ is an arbitrary substitution Church algebra, then $b\\in A$ is\n%\\emph{zero-dimensional} if $q(b,x,y)=b$ for all $x,y\\in A$. \n%\\end{definition}\n%We denote by\n%$A_{0}$ the set of all zero-dimensional elements of $\\mathbf{A}$.\n%\n%\\begin{lemma}\n%\\label{zonzo}$A_{0}$ is a subuniverse of $\\mathbf{A}$\n%satisfying the following condition:\n%\\[\n%x\\in A\\ \\text{and}\\ y,z\\in A_{0}\\ \\Rightarrow\\ q(x,y,z)\\in A_{0}.\n%\\]\n%\n%\\end{lemma}\n%\n%\n%We denote by $\\mathbf{A}_{0}$ the algebra of universe $A_{0}$.\n%\n%\\begin{proposition}\n%\\label{prop:homo} Let $\\mathbf{A}$ be a substitution Church $\\nu$-algebra. The map\n%$$\n%x\\in A\\mapsto q^{\\mathbf{A}}(x,-,-):A_{0}\\times A_{0}\\rightarrow A_{0}$$\n%%where $$f_x(a,b)=q^{\\mathbf{S}}(x,a,b)\\ \\text{for every $a,b\\in S_0$,}$$\n%is a homomorphism from $\\mathbf{A}$ to the functional Church algebra\n%$F(\\mathbf{A}_{0})$, whose value domain is the algebra of all\n%zero-dimensional elements of $\\mathbf{A}$.\n%\\end{proposition}\n%\n\\subsection{Bounded involution biposets}\n\n\\begin{definition}\nA \\emph{bounded involution biposet} is a first-order structure\n\\[\n\\mathbf{B}=\\left(  B,\\leq_{1},\\leq_{2},^{\\prime},0,1\\right)\n\\]\nof type $\\left(  \\left(  2,2\\right)  ,\\left(  1,0,0\\right)  \\right)  $ such that:\n\n\\begin{enumerate}\n\\item $\\leq_{1}$ is a partial order with top element $1$ and $\\leq_{2}$ is a\npartial order with bottom element $0$;\n\n\\item for all $a\\in B$, $a^{\\prime\\prime}=a$;\n\n\\item for all $a,b\\in B$, $a\\leq_{1}b$ iff $b^{\\prime}\\leq_{2}a^{\\prime}$.\n\\end{enumerate}\n\\end{definition}\n\n\\begin{definition}\nA \\emph{bounded involution biqoset} is a first-order structure\n\\[\n\\mathbf{B}=\\left(  B,\\preceq^l_{0},\\preceq^r_{0},\\preceq^l_{1},\\preceq^r_{1},^{\\prime},0,1\\right)\n\\]\nof type $\\left(  \\left(  2,2,2,2\\right)  ,\\left(  1,0,0\\right)  \\right)  $ such that:\n\n\\begin{enumerate}\n\\item $\\preceq^l_{0}$ and $\\preceq^r_{0}$ are quasi-orders with top element $1$.\n\\item $\\preceq^l_{1}$ and $\\preceq^r_{1}$ are quasi-orders with bottom element $0$;\n\\item for all $a\\in B$, $a^{\\prime\\prime}=a$.\n\n\\item for all $a,b\\in B$ and $i=0,1$, $a\\preceq^l_{i}b$ iff $b^{\\prime}\\preceq^l_{1-i}a^{\\prime}$.\n\\item $\\preceq^l_{i} \\cap \\preceq^r_{i}$ ($i=0,1$) is a poset, denoted by $\\leq_i$.\n\n\\end{enumerate}\n\\end{definition}\n\n\\begin{proposition}\n If $\\mathbf{B}=(  B,\\preceq^l_{0},\\preceq^r_{0},\\preceq^l_{1},\\preceq^r_{1},^{\\prime},0,1)$ is a bounded involution biqoset, then $(B,\\leq_{0}, \\leq_{1},^{\\prime},0,1)$ is a bounded involution biposet.\n\\end{proposition}\n\nLet $\\mathbf S$ be a $\\mathrm{ SCA}$. We define six binary relations on $S$ as follows:\n \\begin{enumerate}\n\\item[(i)] $a\\leq^l_\\land b$ iff  $a=b$ or  $a\\land b=a$;\n\\item[(ii)] $a\\leq^r_\\land b$ iff  $a=b$ or  $b\\land a=a$;\n\\item[(iii)] $a\\leq_\\land b$ iff  $a=b$ or  $a\\land b=a=b\\land a$;\n%\\item[(iii)] $a\\leq b \\Leftrightarrow a\\leq_\\land b\\ \\text{and}\\ a\\leq_\\lor b$;\n\\item[(iv)] $a\\leq^l_\\lor b$ iff  $a=b$ or  $b\\lor a=b$;\n\\item[(v)] $a\\leq^r_\\lor b$ iff  $a=b$ or  $a\\lor b=b$;\n\\item[(vi)] $a\\leq_\\lor b$ iff  $a=b$ or  $a\\lor b=b=b\\lor a$.\n\\end{enumerate}\n\n\\begin{lemma} \n The relations $\\leq_\\land$ and $\\leq_\\lor$ are partial orderings.\n The relations $ \\leq^l_\\land$, $\\leq^r_\\land$, $ \\leq^r_\\lor $  and $ \\leq^l_\\lor $ are preorders.\n\\end{lemma}\n\n\\begin{proof} Transitivity is trivial: If $a\\land b=a=b\\land a$ and $b\\land c=b=c\\land b$\nthen $a = a\\land b = a\\land b\\land c=a\\land c$.\n\\end{proof}\n\n%\\begin{lemma} $a\\leq^l_\\land b$ iff  $a=b$ or  $a\\land b=a$ iff $a=b$ or  $a'\\lor b'=a'$ iff $b'\\leq^l_\\lor a'$.\\end{lemma}\n\n\\begin{example} Let $S=\\{0,1,2\\}$ with $q(2,x,y)=2$, for every $x,y\\in S$. Then $S$ is an idempotent $\\mathrm{ SCA}$\nwith two distinct partial orderings. For $\\leq_\\land$ we have: $0\\leq_\\land 1$, $2\\leq_\\land 1$ and $0,2$ \n$\\leq_\\land$-incomparable. For $\\leq_\\lor$ we have:  $0\\leq_\\lor 1$, $0\\leq_\\lor 2$ and $1,2$ $\\leq_\\lor$-incomparable.\n\\end{example}\n\n\\begin{proposition}\\label{cavolo} Let $\\mathbf S$ be a $\\mathrm{ SCA}$ and let $*\\in \\{\\land,\\lor\\}$. We have:\n\\begin{enumerate}\n\\item The structure $(S,\\leq^l_\\land,\\leq^r_\\land, \\leq^l_\\lor, \\leq^r_\\lor,',0,1)$ is a bounded involution biqoset.\n%\\item If $a,b\\in S_0$ then $a\\leq_* b$ iff $a=b$.\n%\\item If $a\\in S_0$ then $a$ is $\\leq_\\land$-minimal and $\\leq_\\lor$-maximal.\n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof} (1) Let $a\\neq b$. Then $a\\leq^l_\\land b$ iff $a\\land b= a$ iff (by De Morgan Laws of Proposition \\ref{morgan}) $a'=a'\\lor b'$ iff $b'\\leq^{l}_\\lor a'$.\n%\n%(2) By hypothesis $q(a,x,y)=a$ and $q(b,x,y)=b$, for all $x,y\\in S$. Then, for example, \n%$a\\leq_\\land b$ iff $a\\land b=b\\land a= a$ iff $a=q(a,b,0) =q(b,a,0)=b$. \n%\n%(3) Let $x\\neq a$ such that $x\\leq_\\land a$. Then $a\\land x = x\\land a = x$.\n%This contradicts the hypothesis $a\\in S_0$, that implies $q(a,x,0)=a$. \n%%By $q(a,x,0)=a$ and $q(a,1,x)=a$ for all $x$.\n\\end{proof}\n\n\\subsection{Idempotents}\n\nIf $x$ is idempotent, then $x'$ is also idempotent.\n\n%Notice that condition (ii) below has not the full power of the corresponding identity for $2$-central elements:$q(x,q(x,a,b),c)= q(x,a,c)= q(x,a,q(x,b,c))$.\n\n\n\n\n%\\begin{proposition}\n% Let $\\mathbf S$ be an idempotent $\\mathrm{ SCA}$. Then $L_{x\\lor y}\\subseteq \\theta_y; \\theta_x$, for every $x,y\\in S$.\n%\\end{proposition}\n%\n%\\begin{proof} \n%Let $a L_{x\\lor y} b$. Then $b=q(x\\lor y,b,a)=q(x,b,q(y,b,a))$. Then $q(y,b,a) \\theta_x b$.\n%It remains to prove that $a\\theta_y q(y,b,a)$. This follows because $q(y, q(y,b,a),a)=q(y,b,a)$. Then $a(\\theta_y; \\theta_x)b$.\n%\\end{proof}\n\n\n\\begin{lemma}\\label{lem:ide} Let $\\mathbf S$ be a $\\mathrm{ SCA}$ and let $x\\in S$ be idempotent. Then we have:\n \\begin{enumerate}\n%\\item $F_x$ is a transitive relation, for every $x$.\n\\item $\\theta_x\\cap \\bar\\theta_x\\subseteq\\Delta$.\n\\item $0 \\theta_x x$ and $x\\bar\\theta_x 1$, for every $x\\in S$. \n\\item $\\theta_x$ ($\\bar\\theta_x$) is $q$-generated by $0\\theta_x x$ ($x\\bar\\theta_x 1$).\n%\\item $\\theta_x\\cap (S_0\\times S_0)=\\{\\langle a,q(x,b,a)\\rangle: a,b\\in S_0\\}$. \n%\\item $\\theta_x$ ($\\bar\\theta_x$) is a transitive relation.\n%\\item $F$ is reflexive if $x\\in \\mathrm{Im}(f_x)$ ($f(a,a)=a$).\n%\\item $F$ is symmetric if $a\\in \\mathrm{Im}(f_{f_a(b)})$, for every $a,b$  ($f(x,f(y,x)) = x$).\n%\\item $F$ is transitive\n\\end{enumerate}\n\\end{lemma}\n\n\n\\begin{proof} %(1) Let $aF_xbF_xc$. By Lemma \\ref{idem}(iii) we have $q(x,b,a)=b$ and $q(x,c,b)=c$. Then $c= q(x,c,b)= q(x,c,q(x,b,a))= q(x,c,a)$.\n\n(1)  Let $a\\theta_x b$ and $a \\bar\\theta_x b$. By Lemma \\ref{idem}(iii)-(iv) we have $a=q(x,b,a)=b$.\n\n(2) Since $q(x,x,0)=x\\land x =x$, then $0 \\theta_x x$. Moreover, from $x=x\\lor x=q(x,1,x)$ it follows that $x\\bar\\theta_x 1$.\n\n(3) By $0\\theta_xx$ and by Lemma \\ref{boh}(4) we get $a=q(0,b,a)\\theta_xq(x,b,a)$.\n\n(4)  By Lemma 1 we have $\\langle a,q(x,b,a)\\rangle\\in S_0\\times S_0$ for every $a,b\\in S_0$. If $a\\in S_0$ and $q(x,b,a)\\in S_0$ but $b\\notin S_0$, then by idempotence and Lemma \\ref{idem}(ii) we have\n$q(x,b,a)= q(x,q(x,b,a),a)$.\nThen we conclude:\n$\\langle a,q(x,b,a)\\rangle = \\langle a,q(x,q(x,b,a),a)\\rangle$ with $a,q(x,b,a)\\in S_0$.\n\\end{proof}\n\n\n%$q(q(x,y,z), q(x,y,z),0)= q(x, q(y,q(x,y,z),0), q(z,q(x,y,z),0))= q(x,y,z)$\n\n\n\\begin{lemma}\\label{lem:effe}\n  Let $\\mathbf S$ be a $\\mathrm{ SCA}$ and $x,y\\in S$ be idempotent. The following conditions are equivalent:\n  \\begin{enumerate}\n\\item $\\theta_y\\subseteq \\theta_x$;\n\\item $x\\land y = y$;\n\\item $y\\leq^r_\\land x$.\n\\end{enumerate}\n%If $x\\neq y$, then $\\theta_y\\subsetneq \\theta_x$ (because $(0,x)\\notin \\theta_y$).\n\\end{lemma}\n\n\\begin{proof} (2) $\\Leftrightarrow$ (3) By definition of $\\leq^r_\\land$.\n\n(2) $\\Rightarrow$ (1) Let $a\\theta_y b$, that is $q(y,b,a)=b$. Then we have:\n$b=q(y,b,a)=q(x\\land y,b,a)=q(q(x,y,0),b,a)=_{S2}q(x,q(y,b,a),a)=q(x,b,a)$, so that \n $a\\theta_x b$.\n\n(1) $\\Rightarrow$ (2) By Lemma \\ref{lem:ide}(2) we have $0\\theta_y y$. Then by the hypothesis we get $0\\theta_x y$, that means $q(x,y,0)=x\\land y = y$.\n%By Lemma \\ref{lem:effe} $F_y\\subseteq F_x$ iff $x\\land y = y$. \n%By definition $y\\leq_\\land x \\Leftrightarrow  x\\land y=y=y\\land x$.\n%Let $q(y,b,a)=b$ and $y\\leq x$. Then $b=q(y,b,a)= q(x\\land y,b,a) = q(q(x,y,0),b,a)= q(x,q(y,b,a),q(0,b,a))= q(x,b,a)$.\n\\end{proof}\n\nLet $S$ be a $\\mathrm{ SCA}$. Define the relation $\\mathcal D^r_\\land$ on $S$ as follows: \n$$x\\mathcal D^r_\\land y\\ \\text{iff}\\ x\\leq^r_\\land y\\ \\text{and}\\ y\\leq^r_\\land x.$$\n\n\\begin{lemma} \nThe following conditions are equivalent, for all $x, y\\in S$:\n\\begin{enumerate}\n\\item $x\\mathcal D^r_\\land y$.\n\\item $F_x = F_y$.\n\\item $0F_x y$ and $0F_y x$.\n\\end{enumerate}\n\\end{lemma}\n\n\n\n\n\n\\section{The main theorem}\n\nLet $\\mathbf A$ be a $\\mathrm{CA}$. We define a binary relation $\\phi$ on $A$:\n\\[\n\\phi=\\{  (  a,b)  \\in A^{2}:q(b,a,a)  =a\\text{ and }q(a,b,b)  =b\\}.\n\\]\n%Recall that, if $\\mathbf A$ is idempotent, then $q(x,x,x)= q(x,x,q(x,x,0))=_{L.\\ref{idem}(ii)} x$, for all $x\\in A$.\n\n%\\begin{lemma}\\label{int} Let $\\mathbf A$ be $\\mathrm{CA}$. \n% If $S(a)$ and $I(b)$, then $(a\\land b)\\lor b=q(a,b,b)$ and $(a\\lor b)\\land b= q(a,b,b)$.\n%\\end{lemma}\n\nIn the following lemma we characterise $\\phi$-equivalent pairs of elements.\n\n\\begin{lemma}\\label{theta} Let $\\mathbf A$ be $\\mathrm{CA}$ satisfying $S(a,b)$ and $I(a,b)$. Then the following conditions are equivalent:\n\\begin{itemize}\n\\item[(i)] $a\\phi b$;\n\\item[(ii)] $a\\theta_ba$ and $b\\theta_ab$;\n\\item[(iii)] $a\\bar\\theta_ba$ and $b\\bar\\theta_ab$;\n\\item[(iv)] $(a\\land b)\\lor b= b$ and $(b\\land a)\\lor a= a$; \n\\item[(v)]  $(a\\lor b)\\land b= b$ and $(b\\lor a)\\land a= a$.\n%\\item[(vi)]  $a\\land b = a \\to a\\lor b=b$ and $b\\land a = b \\to b\\lor a=a$.\n\\item[(vi)] $a\\leq^l_\\land b \\to a \\leq^r_\\lor b$ and $b\\leq^l_\\land a \\to b \\leq^r_\\lor a$.   \n%\\item[(viii)] $a\\lor b = a\\to a\\land b=b$ and $b\\lor a = b\\to b\\land a=a$.\n\\item[(vii)] $a\\leq^l_\\lor b \\to a \\leq^r_\\land b$ and $b\\leq^l_\\lor a \\to b \\leq^r_\\land a$.\n\\end{itemize} \n\\end{lemma}\n\n\\begin{proof}\nThe equivalences (i) $\\Leftrightarrow$ (iv) and (i) $\\Leftrightarrow$ (v)  follow from Lemma \\ref{sipd2}(10). \n\\end{proof}\n\n\\begin{lemma}\\label{lem:2}\n  Let $\\mathbf A$ be an idempotent and substitutive $\\mathrm{CA}$. \nThen $\\phi$ is an involution-preserving\nequivalence relation on $A$.\n\\end{lemma}\n\n\\begin{proof}\n $\\phi$ is reflexive because by Lemma \\ref{sipd2}(9) $q(a,a,a)=a$.\n \n\n\n\\noindent $\\phi$ is transitive: let $q(b,a,a)  =a$, $q(a,b,b)  =b$, $q(b,c,c)=c$ and $q(c,b,b)=b$. Then\n$c= q(b,c,c)=q(q(a,b,b),c,c)=_{S(a)}q(a,q(b,c,c),q(b,c,c))=q(a,c,c)$ and \n$a=q(b,a,a)=q(q(c,b,b),a,a)=_{S(c)} q(c,q(b,a,a),q(b,a,a))= q(c,a,a).$\nThen $\\phi$ is an equivalence relation.\n\nWe now prove that $a\\phi a'$, for all $a$: $q(a,a',a')=_{\\text{Lem}\\ \\ref{sipd1}(b)}q(a,a,a)'=_{\\text{Lem}\\ \\ref{sipd2}(9)}a'$ and $q(a',a,a)=_{\\text{Lem}\\ \\ref{sipd1}(a)} = q(a,a,a)=_{\\text{Lem}\\ \\ref{sipd2}(9)}a$.\n\\end{proof}\n\nDefine $1_x=q(x,1,1)$ and $0_x=q(x,0,0)$. Then $1_1=1$ and $0_0=0$.\n\nNotice that $1_x=1$ iff $0_x=0$, because $q(x,1,1)=q(x,0',0')=q(x,0,0)'$. \n\n\n\\begin{lemma}\\label{11}\nLet $\\mathbf A$ be an idempotent $\\mathrm{ SCA}$. Then the following conditions are equivalent:\n\\begin{enumerate}\n\\item $\\phi = \\nabla$;\n\\item  $\\mathbf A$ is diagonal.\n\\item $\\forall x.\\ 1_x=1$.\n\\item $\\forall x.\\ 0_x=0$.  \n \\item $\\theta_x$ is reflexive, for all $x$.\n   \\item $\\forall x.\\ 0\\leq_\\land x$.\n  \\item $\\forall x.\\ x\\leq_\\lor 1$.\n\\item  $\\forall xy.\\ (y\\land x)\\lor x= x$. %(First right absorption law)\n\\item  $\\forall xy.\\ (y\\lor x)\\land x= x$. %(Second right absorption law) \n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}  The equivalence of (1) and (2) is by definition of $\\phi$.\nSince $\\forall x. 1_x=1$ iff $1/\\phi =A$, then (1) is equivalent to (3). Similarly, for $\\forall x. 0_x=0$. \nThe equivalence of (1) and (5) follows from Lemma \\ref{theta}.\nThe formula $\\forall x.\\ 0\\leq_\\land x$ means $x\\land 0=0=0\\land x$. Since $0_x=x\\land 0=0$, then again this means $0/\\phi =A$. Similarly, for $\\forall x.\\ x\\leq_\\lor 1$. The equivalence of (1) and (8) (resp. (9)) follows from Lemma \\ref{theta}.\n\\end{proof} \n\nLet $c: A\\to A$ defined by $c(a)=q(a,1,0)$.\n\n\\begin{lemma}\\label{closure}  Let $\\mathbf A$ be an idempotent $\\mathrm{ SCA}$ and let $x,y\\in A$.  Then we have:\n \\begin{enumerate}\n\\item[(i)] $1_x,0_x\\in x/\\phi$.\n\\item[(ii)] $x/\\phi$ is closed under the operators $q$, $\\land$, $\\lor$ and $c$.\n\\item[(iii)] If $y\\leq^r_\\land x$ and $x\\leq^r_\\land y$, then $x\\phi y$.\n\\item[(iv)] If $y\\leq^r_\\lor x$ and $x\\leq^r_\\lor y$, then $x\\phi y$.\n\\item[(v)] If $\\theta_x=\\theta_y$, then $x\\phi y$.\n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}\n (i) We show that $1_x, 0_x\\in x/\\phi$. Indeed,\n$q(x,q(x,1,1),q(x,1,1))=_{S(x)}q(q(x,x,x),1,1)=_{L.\\ref{sipd2}(9)}q(x,1,1)$\n and $q(q(x,1,1),x,x)=_{S(x)}q(x,x,x)=_{L.\\ref{sipd2}(9)}x$. A similar proof works for  $0_x$.\n \n(ii) Let $a,b,c\\in x/\\phi$. We show that $q(a,b,c) \\phi x$.\nIndeed, we have: $$q(q(a,b,c),x,x)=_{S(a)} q(a,q(b,x,x),q(c,x,x))=_{b\\phi x, c\\phi x} q(a,x,x)=_{a\\phi x} x$$ and\n$$q(x,q(a,b,c),q(a,b,c))=_{S(x)} q(q(x,a,a), b,c)=_{x\\phi a} q(a,b,c).$$\nLet $a,b\\in x/\\phi$. Then $q(a\\land b,x,x)=q(a,q(b,x,x),x)=q(a,x,x)=x$ and\n$q(x,a\\land b,a\\land b)=q(q(x,a,a),b,0)=q(a,b,0)=a\\land b$. Similarly for $a\\lor b$.\nMoreover, $q(c(a),x,x)= q(a,x,x)=x$ and $q(x,c(a),c(a))=q(q(x,a,a),1,0)=q(a,1,0)=c(a)$.\n\n(iii) $q(x,y,y)=q(x,y,q(x,y,0))=q(x,y,0)=y$ and $q(y,x,x)=q(y,x,q(y,x,0))=q(y,x,0)=x$.\n\n%q(x,y,0)=q(q(y,x,x),y,0)=q(y,q(x,y,0),q(x,y,0))\n\n(iv) $q(x,y,y)=q(x,q(x,1,y),y)=q(x,1,y)=y$ and $q(y,x,x)=q(y,q(y,1,x),x)=q(y,1,x)=x$.\n\n(v) follows from (iii) and Lemma \\ref{lem:effe}.\n\\end{proof}\n\n\\begin{proposition}  Let $\\mathbf A$ be an idempotent $\\mathrm{ SCA}$ and $x\\in A$.\nThen $(x/\\phi,\\land,\\lor,',0_x,1_x)$ is a $01$-algebra satisfying the identities\n(D1), (D3) and (D4).\n\\end{proposition}\n\n\\begin{proof} Let $a\\in x/\\phi$.\n $1_x\\land a=q(q(x,1,1),a,0)=q(x,a,a)=a$\n\n$0_x\\lor a=q(q(x,0,0),1,a)=q(x,a,a)=a$\n\n$0_x\\land a=q(q(x,0,0),a,0)=q(x,0,0)=0_x$\n\n$1_x\\lor a=q(q(x,1,1),1,a)=q(x,1,1)=1_x$\n\nto be finished.\n\\end{proof}\n\n\n\n\nWe define $a\\land_x b = q(a,b,0_x)$, $a\\lor_x b = q(a,1_x,b)$ and $\\neg_x(a)= q(a,0_x,1_x)$.\nMoreover, we denote by $c_x(a)$ the element $q(a,1_x,0_x)$.\n\n\n\\begin{theorem}\n Let $\\mathbf A$ be an idempotent $\\mathrm{ SCA}$ and let $x\\in A$. \n% satisfying the identities: \n% \\begin{itemize}\n%\\item[(i)] $x\\land (x\\lor y)= x=x\\lor (x\\land y)$.\n%\\item[(ii)] $q(x,1_y,1_y) = q(y,1_x,1_x)$ and $q(x,0_y,0_y) = q(y,0_x,0_x)$.\n%\\end{itemize}\nThen we have for  the equivalence class $x/\\phi$:\n\\begin{enumerate}\n\\item The algebra $\\mathbf{x_\\phi} = (x/\\phi,q,0_x,1_x)$ is a diagonal and substitutive CA satisfying\n$$\\forall a,b,c\\in x/\\phi.\\ q(\\neg_x(a),b,c)=q(a,c,b)\\ \\text{and}\\ \\neg_x q(a,b,c)=q(a,\\neg_x b,\\neg_x c).$$\n\\item The algebra $(x/\\phi,\\wedge_x,\\lor_x,\\neg_x,0_x,1_x)$ is a $\\mathrm{SDMB}$.\n\\item The map $c_x: x/\\phi\\to c_x[x/\\phi]$, defined by $c_x(a)= q(a,1_x,0_x)$, is an onto homomorphism such that $c_x\\circ c_x=c_x$. \n\\item The algebra $(c_x[x/\\phi],q,0_x,1_x)$ is a diagonal and idempotent $\\mathrm{SCA}$.\n\\item The algebra $(c_x[x/\\phi],\\wedge_x,\\lor_x,\\neg_x,0_x,1_x)$ is a De Morgan double band satisfying the identities $(y\\land_x z)\\lor_x z= z = (y\\lor_x z)\\land_x z$.\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{proof} \n(1) By Lemma \\ref{closure}(2) $x/\\phi$ is closed under $q$ and contains $0_x$ and $1_x$. Let now $a,b\\in x/\\phi$. Then $q(1_x,a,b)=q(q(x,1,1),a,b)=_{S(x)}q(x,a,a)=_{a\\phi x}a$ and $q(0_x,a,b)=q(q(x,0,0),a,b)=_{S(x)} q(x,b,b)=_{b\\phi x}b$. Then the algebra $\\mathbf{x_\\phi}$ is a Church algebra. It is substitutive because $\\mathbf A$ is substitutive, and it is diagonal because the carrier set of $\\mathbf{x_\\phi}$ is an equivalence class of $\\phi$.\n\n(2) \\begin{itemize}\n\\item[D1] follows from the hypothesis that $\\mathbf A$ is a SCA. \n\\item[D2] By (1) $q(\\neg_x(a), 0_x,1_x)=q(a,1_x,0_x)= a \\land_x 1_x$.\n\\item[D3] $\\neg_x(a\\land_x b)= q(q(a,b,0_x),0_x,1_x)=_{S} q(a, q(b,0_x,1_x), 1_x)= q(a, \\neg_x(b), 1_x) =_{(1)} $\\\\\n$q(\\neg_x(a), 1_x,\\neg_x(b)) =\\neg_x(a)\\lor_x \\neg_x(b)$.\n\\item[D5] $a\\land_x 0_x=q(a, 0_x, 0_x)= 0_x$ because $a\\phi 0_x$. Similarly for $x\\lor_x 1_x=1_x$.\n\\end{itemize}\n\n \n (3) First we notice that by Lemma  \\ref{closure}(2) $c_x(a)\\in x/\\phi$, because $a,1_x,0_x\\in x/\\phi$. Moreover, \n \\begin{itemize}\n\\item $c_x$ is a homomorphism: $c_x(q(a,b,d))=q(q(a,b,d),1_x,0_x)=_{S(a)}q(a,q(b,1_x,0_x), q(d,1_x,0_x))$\\\\\n$= q(a,c_x(b),c_x(d))=_{S(a)}q(c_x(a),c_x(b),c_x(d))$.\n\\item $c_x(c_x(a))=q(q(a,1_x,0_x),1_x,0_x)= q(a,1_x,0_x)=c_x(a)$.\n\\item $c_x(1_x)=1_x$ and $c_x(0_x)=0_x$.\n\\end{itemize}\n \n(4) $c_x[x/\\phi]$ is a homomorphic image of $x/\\phi$, so that it is a diagonal and substitutive CA.  For the idempotence we have: $c_x(a)\\land_x c_x(a)= q(a,q(a,1_x,0_x),0_x)=_{P(a)}q(a,1_x,0_x)=c_x(a)$.\n$P(a)$ holds by Lemma \\ref{idem} and by the hypothesis of idempotence of $\\mathbf A$.\n\nMoreover, the algebra is unital because $q(c_x(a), 1_x,0_x)= q(a,1_x,0_x)=c_x(a)$.\n% - $c_x(a)\\land_x (c_x(a)\\lor_x c_x(b)) = q(c_x(a), c_x(a)\\lor_x c_x(b),0_x)= q(a, a\\lor_x c_x(b),0_x) $\n\n(5) Since by (2) $(x/\\phi,\\wedge_x,\\lor_x,\\neg_x,0_x,1_x)$ is a $\\mathrm{SDMB}$, then the homomorphic image $c_x[x/\\phi]$ of $x/\\phi$ by $c_x$ is also a $\\mathrm{SDMB}$. By the proof of (4) we have that $c_x[x/\\phi]$ satisfies also (D4) and is idempotent, so that it is a De Morgan double band.    By (4) $c_x[x/\\phi]$ is diagonal, so that by Lemma \\ref{11} it satisfies $(y\\land_x z)\\lor_x z= z = (y\\lor_x z)\\land_x z$.\n \\end{proof}\n \n \nIt follows that if $\\mathbf A$ be a diagonal and idempotent $\\mathrm{ SCA}$, then\n$(A,\\land,\\lor,',0,1)$ is  a De Morgan double band satisfying the identities $(y\\land z)\\lor z= z = (y\\lor z)\\land z$.\n\n\\bigskip\n\nLet \n\\begin{itemize}\n\\item $\\mathrm{Ab}_\\land(a,b)$ iff $a\\land (a\\lor b)=a$ and $(b\\lor a)\\land a=a$.\n\\item $\\mathrm{Ab}_\\lor(b,a)$ iff $(a\\land b) \\lor b=b$ and $b\\lor (b\\land a)=b$.\n\\item $\\mathrm{Ab}(a,b)$ iff $\\mathrm{Ab}_\\land(a,b)$ and $\\mathrm{Ab}_\\lor(b,a)$.\n\\item $\\mathrm{AbL}(a,b)$ iff $a\\land (a\\lor b)=a$ and $b\\lor (b\\land a)=b$.\n\\item $\\mathrm{AbR}(a,b)$ iff $(b\\lor a)\\land a=a$ and $(a\\land b) \\lor b=b$.\n\\end{itemize}\n\nWe analyse the absorption law $\\mathrm{Ab}_\\land(a,b)$:\n\\begin{itemize}\n\\item  $a\\land (a\\lor b)=a \\Rightarrow (a\\lor b = b \\Rightarrow a\\land b = a)$, that is,\n $a\\land (a\\lor b)=a \\Rightarrow (a\\leq^r_\\lor b \\Rightarrow a\\leq^l_\\land b)$.\n\\item $(b\\lor a)\\land a=a \\Rightarrow (b\\lor a = b \\Rightarrow b\\land a = a)$, i.e., $(b\\lor a)\\land a=a \\Rightarrow (a\\leq^l_\\lor b \\Rightarrow a\\leq^r_\\land b)$.\n\\end{itemize}\nAssuming $\\mathrm{Ab}_\\land(a,b)$, $a\\leq_\\lor b$ implies $a\\leq_\\land b$.\n\nWe now analyse the absorption law $\\mathrm{Ab}_\\lor(b,a)$:\n\\begin{itemize}\n\\item  $(a\\land b) \\lor b=b \\Rightarrow (a\\land b = a \\Rightarrow a\\lor b = b)$, i.e., $(a\\land b) \\lor b=b \\Rightarrow (a\\leq^l_\\land b \\Rightarrow a\\leq^r_\\lor b)$.\n\n\\item $b\\lor (b\\land a)=b \\Rightarrow (b\\land a = a \\Rightarrow b\\lor a = b)$, i.e., $b\\lor (b\\land a)=b \\Rightarrow (a\\leq^r_\\land b \\Rightarrow a\\leq^l_\\lor b)$.\n\\end{itemize}\nAssuming $\\mathrm{Ab}_\\lor(b,a)$, $a\\leq_\\land b$ implies $a\\leq_\\lor b$.\n\n\nThe above analysis provides a proof of item (2) of the following lemma.\n\n\n\n\n\\begin{lemma}\\label{lem:3}\n Let $\\mathbf A$ be an idempotent and substitutive $\\mathrm{CA}$. Let $a,b\\in A$ such that  $\\mathrm{Abs}(a,b)$. Then we have:\n \\begin{enumerate}\n\\item $a\\phi b$;\n\\item $a\\leq_\\land b$ iff $a\\leq_\\lor b$.\n\\end{enumerate}  \n\\end{lemma}\n\n\\begin{proof} (1) By Lemma \\ref{theta} $a\\phi b$ is equivalent to $\\mathrm{AbR}(a,b)$. \n\\end{proof}\n\n%\\begin{proof} %If $a\\leq_\\land b$, then $a\\land b=a=b\\land a$. We derive \n%$a\\lor b=(a\\land b)\\lor b=q(q(a,b,0),1,b)=_{S(a)}q(a,b\\lor b,b)=_{I(b)}q(a,b,b)=_{a\\phi b}b$.\n%Moreover,\n%$b\\lor a=q(b,1,a)= q(b,1,q(b,a,0))=b\\lor (b\\land a)=_{\\mathrm{Hyp}}b$.\n%\n%\n%If $a\\leq_\\lor b$, then $a\\lor b=b=b\\lor a$. By Lemma \\ref{theta}(v) we have \n%$b\\land a= (b\\lor a)\\land a=$.\n%\n%Moreover, $a\\land b=q(a,b,0)=q(a, q(a,1,b),0)=a\\land (a\\lor b) =_{\\mathrm{Hyp.}}a$.\n%\\end{proof}\n\n%\\begin{lemma}\\label{lem:3}\n% Let $\\mathbf A$ be an idempotent and substitutive $\\mathrm{CA}$. Then the following conditions are equivalent:\n% \\begin{enumerate}\n%\\item $a=a\\land (a\\lor b)$ and   $b=b\\lor (b\\land a)$.\n%\\item $a\\leq_\\land b$ iff $a\\leq_\\lor b$.\n%\\end{enumerate}\n%\\end{lemma}\n\nQuestion: what is the relationship between $\\leq_\\land$ and $\\leq_{\\land_x}$ ?????\n\n\\begin{theorem} Let $\\mathbf A$ be an idempotent SCA and let $x\\in A$.  \nAssume $\\mathrm{AbL}(a,b)$, for all $a,b\\in x/\\phi$. Then we have:\n\n\\begin{enumerate}\n\\item If $1_a =1_x$ and $0_a=0_x$ for every $a\\in x/\\phi$, then  $x/\\phi$ is the universe of a bounded involution poset:\n \\[\n\\mathbf{x/\\phi}=(  x/\\phi,\\leq_{\\land},^{\\prime},0_x,1_x  )\n\\]\n\\item The structure $(A/\\phi, \\preceq, 0/\\phi)$ is a poset with bottom, where \n\\[\n\\begin{array}{lll}\na/\\phi \\preceq b/\\phi  &  \\text{iff} &  \\exists c\\in a/\\phi\\ \\exists d\\in b/\\phi:\\ q(c,d,d)=d  \\\\\n  &   \\text{iff} &  \\forall c\\in a/\\phi\\ \\forall d\\in b/\\phi:\\ q(c,d,d)=d.  \\\\\n\\end{array}\n\\] \n\\end{enumerate}\n\n\\end{theorem}\n\n\n\\begin{proof}\n \n%(1) \\[\n%\\begin{array}{llll}\n%q(a,1,1)  & =  & q(q(b,a,a),1,1) & \\text{by $a\\phi b$} \\\\\n%  &  = & q(b,q(a,1,1),q(a,1,1))&\\text{by S(b)}  \\\\\n%  & =  &   q(a,q(b,1,1),q(b,1,1))& \\text{by Hypothesis} \\\\\n%  & =  &   q(q(a,b,b),1,1)&\\text{by S(a)}  \\\\\n%  &=& q(b,1,1)& \\text{by $a\\phi b$} \\\\\n%\\end{array}\n%\\]\n%Similarly for $q(a,0,0)=q(b,0,0)$.\n\n\n\n(1) We already proved that each $x/\\phi$ is closed w.r.t. the involution (see Lemma \\ref{lem:2}),\nwhich is the restriction of $^{\\prime}$ to $x/\\phi$, and that\n$\\leq_{\\land}$ and $\\leq_{\\lor}$ coincide over $x/\\phi$ (see Lemma \\ref{lem:3}).\n\n%$q(a,q(x,1,1),q(x,0,0))=q(x,q(a,q(x,1,1),q(x,0,0)),q(a,q(x,1,1),q(x,0,0)))$\n\n \n To prove that $1_x$ is the top element,  let  $a\\in x/\\phi$, i.e., $q(x,a,a)=a$ and $q(a,x,x)=x$. \n Then $1_x\\land a = q(q(x,1,1),a,0)=_{S(x)} q(x,a,a)=a$ and \n $a\\land 1_x = q(a,q(x,1,1),0)=_{(1)}q(a,q(a,1,1),0)=a\\land (a\\lor 1)=_{\\mathrm{Hyp}}a$.\n Then it follows that $a\\leq_\\land 1_x$, for all $a\\in x/\\phi$. Similarly, we can prove that \n $0_x\\leq_\\land a$,  for all $a\\in x/\\phi$.\n \n (2) It is sufficient to prove that $a/\\phi\\preceq b/\\phi$ iff $\\forall c\\in a/\\phi$ and  $\\forall d\\in b/\\phi$,  $q(c,d,d)=d$. Let $q(c,d,d)=d$ for some $c\\in a/\\phi$ and $d\\in b/\\phi$. Let $e\\in a/\\phi$. Then\n $d=q(c,d,d)=q(q(e,c,c),d,d)=q(e,q(c,d,d),q(c,d,d))=q(e,d,d)$. Let $f\\in b/\\phi$.\n Then $q(c,f,f)=q(c,q(d,f,f),q(d,f,f))=q(q(c,d,d),f,f)=q(d,f,f)=f$.\n\\end{proof}\n\n\n\n\n%\\subsection{Orthomodular Posets}\n%Let $(S,\\leq)$ be a poset with a greatest element $1$.  An orthocomplementation of S is a bijection $': S\\to S$ such that the lub of $x$ and $x'$ exists for each $x\\in S$ and (i) $x''= x$, (ii) $x\\leq y$ implies $y'\\leq x'$ and (iii) $x\\lor x' = 1$. If a poset admits an orthocomplementation  we call the triple $(S, \\leq, ')$ an orthoposet.  The element $0=1'$ is the least element of $S$ and $x\\land x'= 0$ for each $x\\in S$. Elements $x$ and $y$ in an orthoposet are orthogonal when $x\\leq y'$. An orthoposet which is in fact a lattice\n%is called an ortholattice. An orthoposet is said to be an orthomodular poset when\n%\\begin{enumerate}\n%\\item $x\\leq y' \\Rightarrow$  $x\\lor y$ exists in $S$;\n%\\item $x\\geq y'$ and $x\\land y=0 \\Rightarrow x=y'$.\n%\\end{enumerate}\n%\n%In the definition of an orthomodular poset one may replace the implication (2) by any one of the three following implications which, in the presence of (1), are each equivalent to (2).\n%\\begin{enumerate}\n%\\item[(2a)] $x\\leq y'$ and $x\\lor y=1\\Rightarrow x=y'$. \n%\\item[(2b)] $x\\leq y' \\Rightarrow (x\\lor y)\\land y' = x$.\n%\\item[(2c)]  $x\\leq y \\Rightarrow x\\lor (y\\land x')=y$.\n%\\end{enumerate}\n%The asserted equivalence of these implications is contained essentially in \\cite{bir}.\n%\n\n\n%\\section{The family of relations $\\theta_x$ and $\\bar\\theta_x$}\n%We have $L_{x'}= \\{\\langle a,q(x,a,b)\\rangle: a,b\\in S\\}$. We denote by $\\breve R_{x}$ the converse of $R_{x}$.\n\n%Since $f_{x\\land y}(b,a)=f_x(f_y(b,a),a)$ and $f_{x\\lor y}(b,a)=f_x(b,f_y(b,a))$ then $F_{x\\land y}=\\{\\langle a,f_x(f_y(b,a),a)\\rangle: a,b\\in S\\}$ and $F_{x\\lor y}=\\{\\langle a,f_x(b,f_y(b,a))\\rangle: a,b\\in S\\}.$\n\n\n\n\n\n%If $q(x,b,a)=b$, then $aF_xb$.\n% \\{(b,a) : aF_{x'} b\\}=\\{(b,a) : \\exists c. b= q(x',c,a)=q(x,a,c)\\}$.\n\n\n%$q(x,q(x,b,a), b)= $\n\n\n\n%(3) We have: $a F_{x\\lor y} q(x\\lor y,b,a)=q(q(x,1,y),b,a)= q(x,b,q(y,b,a))$. Moreover, $a F_y q(y,b,a)$ and $q(y,b,a) F_x q(x,b,q(y,b,a))$.\n\n%(4) We have: $a F_{x\\land y} q(x\\land y,b,a)=q(x,q(y,b,a),a) = q(x',a,q(y,b,a))$. Moreover, $a F_y q(y,b,a)$, $q(y,b,a) F_{x'} q(x',a,q(y,b,a))$ and $aF_x q(x,q(y,b,a),a)$.\n\n \n\n%\\section{The reflexive and symmetric relations $F_x$}\n%\n%\\begin{lemma} \\label{lem:skew}\n%Let $\\mathbf S$ be a $\\mathrm{ SCA}$ and let $a\\in S$ be idempotent. Then the following conditions are equivalent:\n% \\begin{itemize}\n%\\item[(i)]  $\\forall x.\\ q(a,x,x)= x$.\n%\\item[(ii)] $a\\land 0= 0$.\n%\\item[(iii)] $a\\lor 1= 1$.  %q(x',1,x)=q(x,x,1)=q(x,1,1)=1$\n% \\item[(iv)] $F_a$ is reflexive.\n%   \\item[(v)] $0\\leq_\\land a$.\n%  \\item[(vi)] $a\\leq_\\lor 1$.\n% \\end{itemize}\n% $F_a$ is reflexive iff $F_{a'}$ is reflexive, because $a\\lor 1=a'\\lor 1$.\n% \n% If $\\mathbf S$ is idempotent, then the above equivalent conditions are also equivalent to:\n% \n%\\begin{itemize}\n%\\item[(vii)]  $\\forall x.\\ (a\\land x)\\lor x= x$. %(First right absorption law)\n%\\item[(viib)]  $\\forall x.\\ a\\land x = a \\to a\\lor x=x$.\n%\\item[(viic)] $\\forall x.\\ a\\leq^l_\\land x \\to a \\leq^r_\\lor x$.  %$a\\leq^l_\\land x$ iff $x'\\leq^l_\\lor a'$\n%\\item[(viii)]  $\\forall x.\\ (a\\lor x)\\land x= x$. %(Second right absorption law) \n%\\item[(viiib)] $\\forall x.\\ a\\lor x = a\\to a\\land x=x$.\n%\\item[(viiic)] $\\forall x.\\ a\\leq^l_\\lor x \\to a \\leq^r_\\land x$.\n%\\end{itemize}\n%\\end{lemma}\n%\n%%$xF_x 0$ implies  $q(x,a,b) F_x q(0,a,b)=b\n%\n%\\begin{proof} (i) $\\Leftarrow$ (ii,iii): By $z=q(0,y,z)=_{(ii)}q(q(a,0,0),y,z) = q(a,z,z)$ and by $y=q(1,y,z)=_{(ic)}q(q(a,1,1),y,z) = q(a,y,y)$.\n%\n%(i) $\\Rightarrow$ (ii,iii):  $a\\land 0=q(a,0,0)=_{(i)}0$ and $a\\lor 1=q(a,1,1)=_{(i)}1$.\n%\n% (i) $\\Leftrightarrow$ (iv): $xF_a x$ iff $q(a,x,x)=x$.\n%\n%Let $\\mathbf S$ be idempotent.\n%\n%(i) $\\Leftrightarrow$ (vii):  $(a\\land x)\\lor x = q(q(a,x,0),1,x)= q(a, q(x,1,x),x)=q(a,x,x)$ by idempotence of $x$. \n%\n%(i) $\\Leftrightarrow$ (viii): $(a\\lor x)\\land x = q(q(a,1,x),x,0)= q(a, x,q(x,x,0))=q(a,x,x)$ by idempotence of $x$.\n% \n% \n% (viiib) $\\Rightarrow$ (viii): By hypothesis $(a\\lor x)\\lor x = a\\lor x$ implies $(a\\lor x)\\land x=x$.\n% \n%  (viii) $\\Rightarrow$ (viiib): Trivial.\n%\\end{proof}\n%\n%\n%A bounded involution biposet $\\mathbf{B}=\\left(  B,\\leq_{1},\\leq_{2},^{\\prime},0,1\\right)$ is called a \n%\\emph{bi-bounded involution biposet} if $0$ is the bottom of $\\leq_1$ and $1$ is the top of $\\leq_2$.\n%\n%\\begin{corollary}\n% Let $\\mathbf S$ be an idempotent $\\mathrm{ SCA}$ satisfying the identity $q(x,y,y)\\approx y$. Then, \n% $\\left(  S,\\leq_{\\land},\\leq_{\\lor},^{\\prime},0,1\\right)$ is bi-bounded involution biposet.\n%\\end{corollary}\n%\n%\n%\\begin{lemma} \\label{lem:sym}\n%Let $\\mathbf S$ be a $\\mathrm{ SCA}$ and let $a\\in S$ be idempotent. Then the following conditions are equivalent:\n% \\begin{itemize}\n%\\item[(i)]  $a'\\land a=0$.\n% \\item[(ii)] $F_a$ is symmetric.\n%  \\item[(iii)] $a\\lor a'=1$. \n%\\end{itemize}\n%If $F_a$ is reflexive, then the above equivalent conditions imply that  the $\\leq_\\lor$-lub of $a$ and $a'$ exists and it is equal to $1$.\n%\\end{lemma}\n%\n%\\begin{proof} (ii) $\\Rightarrow$ (i): Since $0F_a a$ and $F_a$ is symmetric, then $aF_a0$ that is equivalent to $q(a,0,a)=0$. The conclusion follows because $0=q(a,0,a)=q(a',a,0)=a'\\land a$.\n%\n%(i) $\\Rightarrow$ (ii): Let $xF_ay$ (i.e., $q(a,y,x)=y$). By the hypothesis $a'\\land a=q(a,0,a)=0$ we get $aF_a0$. \n%By applying Lemma \\ref{boh}(4) we get $y=q(a,y,x)F_a q(0,y,x)=x$.\n%\n%(i) $\\Leftrightarrow$ (iii): By De Morgan laws of Proposition \\ref{morgan}.\n%\n%Let $F_a$ be reflexive. We now show that the lub of $a, a'$ exists and it is equal to $1$. Since\n%$a\\leq_\\lor a\\lor a'\\lor a= 1\\lor a=1$ and $a'\\leq_\\lor a'\\lor a\\lor a'=a'\\lor 1=q(a',1,1)=q(a,1,1)=a\\lor 1=1$ (by Lemma \\ref{lem:skew}(iii)), then $a\\lor a'\\lor a$ (= $a'\\lor a\\lor a'$) is an upper bound of $a$ and $a'$. Then by Lemma \\ref{upper}  $a\\lor a'\\lor a=1$ is the lub of $a,a'$.\n%\\end{proof}\n%\n%\n%\\begin{corollary}\n% Let $x\\in S$ be an idempotent element such that $F_x$ and $F_{x'}$ are both symmetric.  \n%  Then the $\\leq_\\lor$-lub of $x$ and $x'$ exists and it is equal to $1$.\n%\\end{corollary}\n%\n%\\begin{proof} By Lemma \\ref{lem:sym} and by hypothesis we have that $x\\lor x' = x'\\lor x=1$.\n%  To be finished.\n%\\end{proof}\n\n\n\n\n%\\subsection{The lub of two elements}\n%\n%We always have $x\\leq_\\lor x\\lor y\\lor x$. Then $x\\lor y\\lor x$ is an upper bound of $x$ and $y$ w.r.t. $\\leq_\\lor$ iff \n%$y\\lor x\\lor y\\lor x=x\\lor y\\lor x$ and $x\\lor y\\lor x\\lor y=x\\lor y\\lor x$ iff $x\\lor y\\lor x$ is the lub of $x$ and $y$ w.r.t. $\\leq_\\lor$. This last equivalence follows from the lemma below.\n%\n%\\begin{lemma}\\label{upper} Let $x,y$ be idempotents. If $z$ is an upper bound of $x$ and $y$ w.r.t. $\\leq_\\lor$, then $x\\lor y, y\\lor x, x\\lor y\\lor x$ and  $y\\lor x\\lor y$ are all  $\\leq_\\lor z$. \n%\\end{lemma}\n%\n%\\begin{proof} ($x= y$):  By idempotence $x\\lor y= y\\lor x= x\\lor y\\lor x=y\\lor x\\lor y=x=y$ and the result is trivial.\n%\n%($x\\neq y$ and $x\\leq_\\lor y$): Then $y=x\\lor y= y\\lor x= x\\lor y\\lor x=y\\lor x\\lor y$ and the result is trivial.\n%\n%($x\\neq y$ and neither $x\\leq_\\lor y$ nor $y\\leq_\\lor x$):\n% $(x\\lor y) \\lor z = x\\lor (y \\lor z)=x\\lor z=z$ and $z\\lor(x\\lor y)= (z\\lor x)\\lor y=z\\lor y =z$. Similarly for $y\\lor x$ and the others elements.\n%\\end{proof}\n%\n%\\begin{lemma}\\label{dieci} Let $x,y$ be elements of $S$.\n%The following conditions are equivalent:\n%\\begin{enumerate}\n% \\item[(a)] $y\\lor x$ is  idempotent and  $x\\lor y = y\\lor x\\lor y$;\n%\\item[(b)] $x\\lor y$ is  idempotent and $y\\lor x = x\\lor y\\lor x$.\n%\\end{enumerate}\n%\\end{lemma}\n%\n%\\begin{proof}\n% (b) $\\Rightarrow$ (a) $x\\lor y =_{idemp.} x\\lor y \\lor x \\lor y= (x\\lor y \\lor x) \\lor y =(y\\lor x) \\lor y = y\\lor x \\lor y$.\n% Moreover, $y\\lor x\\lor y \\lor x = (y\\lor x\\lor y) \\lor x = x\\lor y\\lor x = y\\lor x$.\n%\n%(a) $\\Rightarrow$ (b) By symmetry. \n%\\end{proof}\n%\n%\\begin{lemma}\\label{supp} Let $x,y$ be idempotents. Then the following conditions are equivalent:\n%\\begin{enumerate}\n%\\item[(i)] $x\\lor y\\lor x= y\\lor x\\lor y$ and both elements $x\\lor y,y\\lor x$ are idempotents;\n%\\item[(ii)] $x\\lor y = y\\lor x$;\n%%\\item[(iii)] $y\\lor x\\lor y=x\\lor y$ and $y\\lor x$ is idempotent;\n%\\item[(iii)] $y\\lor x$ is idempotent and the $\\leq_\\lor$-lub of $x$ and $y$ exists and it is equal to $x\\lor y$.\n%\\end{enumerate}\n%\\end{lemma}\n%\n%\\begin{proof} (ii) $\\Rightarrow$ (i) $x\\lor y\\lor x = x\\lor x\\lor y= x\\lor y = y\\lor x = y\\lor y\\lor x = y\\lor x\\lor y$. \n%Moreover, $y\\lor x \\lor y\\lor x=_{(ii)}y\\lor y \\lor x\\lor x = y\\lor x$ and \n%$x \\lor y\\lor x\\lor y=_{(ii)} x\\lor x \\lor y\\lor y = x\\lor y$.\n%\n%(i) $\\Rightarrow$ (ii) $x\\lor y = x\\lor y\\lor x \\lor y= y\\lor x\\lor y\\lor y= y\\lor x\\lor y$ and $y\\lor x = y\\lor x \\lor y\\lor x= x\\lor y\\lor x\\lor x = x\\lor y\\lor x$. Then $x\\lor y = y\\lor x$.\n%\n%(iii) $\\Rightarrow$ (i) By $x\\leq_\\lor x\\lor y$ we get $x\\lor y\\lor x=x\\lor y$.\n%By $y\\leq_\\lor x\\lor y$ we get $y\\lor x\\lor y=x\\lor y$. Then $x\\lor y\\lor x= y\\lor x\\lor y$.\n%Moreover, $x\\lor y\\lor x\\lor y= y\\lor x \\lor y\\lor y=y\\lor x \\lor y = x\\lor y$.\n%\n% (i) $\\Rightarrow$ (iii) By (i) $y\\lor x$ is idempotent. According to Lemma \\ref{upper} it remain to prove that \n% $x,y  \\leq_\\lor x\\lor y$.\n% Since $y\\leq_\\lor y\\lor x\\lor y$ and $x\\leq_\\lor x\\lor y\\lor x$ hold, then by the hypothesis\n% $y\\lor x\\lor y =x\\lor y\\lor x$, we have that $y\\lor x\\lor y$ is an upper bound of $x$ and $y$. By Lemma \\ref{upper}\n%we get that $y\\lor x\\lor y$ is the lub of $x$ and $y$. Since (ii) is equivant to (i), then $y\\lor x\\lor y = x\\lor y\\lor y=x\\lor y$.\n%\\end{proof}\n\n%\\begin{lemma}\n% Let $x,y\\in S$ be idempotent elements such that $x'\\leq^r_\\land y'$. Then \n%$y\\lor x\\lor y=x\\lor y$ and the element $x\\lor y$ is idempotent.\n%\\end{lemma}\n%\n%\\begin{proof}\n%From Lemma \\ref{lem:effe} and from the hypothesis $x'\\leq^r_\\land y'$ it follows that $F_{x'}\\subseteq F_{y'}$. \n%If $aF_{x'} b$ (i.e., $q(x',b,a)=b$), then $b= q(x',b,a)= q(y'\\land x',b,a)=q(q(y',x',0),b,a)=q(y',q(x',b,a), a)=\n%q(y',b,a)$.\n%\n%Since   $q(x,1,q(x,1,y)) = q(x,1,y)$ (i.e., $1F_{x'} q(x,1,y)$) then $q(x,1,y) = q(y,1,q(x,1,y))$ and\n%$$x\\lor y=q(x,1,y)=q(y,1,q(x,1,y))=y\\lor x\\lor y.$$\n%\\end{proof}\n\n\n%\\begin{lemma}\n% Let $x,y\\in S$ be idempotent elements satisfying the following conditions: \n% \\begin{itemize}\n%\\item[(i)] $x\\leq^r_\\land y'$;\n% \\item[(ii)] $q(y,y,q(x,1,y))=q(y,1,q(x,1,y))$.  %$q(y,y,z)= q(y,q(y,1,z),z)= q(q(y,y,0),1,z)=$\n%\\end{itemize}\n% Then the following properties hold:\n% \\begin{description}\n%\\item[(a)]  $y\\lor x\\lor y=x\\lor y$ (equivalent to $y\\leq_\\lor x\\lor y$);\n%\\item[(b)] $x\\lor y$ is idempotent;\n%\\item[(c)] $y\\lor x$ is idempotent iff $x\\lor y \\lor x = y\\lor x$;\n%\\item[(d)] $x\\lor y$ is the $\\leq_\\lor$-join of $x$ and $y$ iff $x\\leq_\\lor x\\lor y$ iff $x\\lor y\\lor x= x\\lor y$.\n%\\end{description}\n%\\end{lemma}\n\n\n%\\begin{proof}\n%(a) From Lemma \\ref{lem:effe} and from the hypothesis $x\\leq^r_\\land y'$ it follows that $F_{x}\\subseteq F_{y'}$. \n%If $aF_{x} b$ (i.e., $q(x,b,a)=b$), then $b= q(x,b,a)= q(y'\\land x,b,a)=q(q(y',x,0),b,a)=q(y',q(x,b,a), a)=\n%q(y',b,a)=q(y,a,b)$.\n%\n%Since   by Lemma \\ref{idem} we have that %$q(x,1,q(x,1,y)) = q(x,1,y)$ (i.e., $1F_{x'} q(x,1,y)$) then$q(x,1,y) = q(x,1,q(x,1,y)) = q(y'\\land x,1,q(x,1,y))= q(q(y',x,0),1,q(x,1,y)) = q(y', q(x,1,q(x,1,y)), q(x,1,y))= q(y', q(x,1,y), q(x,1,y))= q(y, q(x,1,y), q(x,1,y))$.\n%$q(x,q(x,1,y),y)=q(x,1,y)$ (i.e., $yF_xq(x,1,y)$), then $q(y,y,q(x,1,y))=q(x,1,y)$. Then we conclude as follows:\n%$$x\\lor y=q(x,1,y)=q(y,y,q(x,1,y))=_{(ii)} q(y,1,q(x,1,y))=y\\lor x\\lor y.$$\n%\n%If $x\\land y'=x$ and $q(y',b,a)=a$, then $q(x,b,a)= q(x\\land y',b,a)=q(q(x,y',0),b,a)=q(x,q(y',b,a), a)=\n%q(x,a,a)=?????a$. This means that $F_y\\subseteq F_{x'}$ (iff $y\\leq^r_\\land x'$ iff $x\\leq^l_\\land y'$).\n%\n%(b) By (a) $x\\lor y \\lor x\\lor y=x\\lor (y \\lor x\\lor y)=  x\\lor (x\\lor y) =  (x\\lor x)\\lor y = x\\lor y$. \n%\n%(c) By (a), (b) and Lemma \\ref{dieci}.\n%\n%(d) By Lemma \\ref{upper} the conclusion follows from (a).\n%\\end{proof}\n%\n%\\begin{corollary}\n% Let $x,y\\in S$ be idempotent elements satisfying the following conditions: \n% \\begin{itemize}\n%\\item[(i)] $x\\leq^r_\\land y'$ and $y\\leq^r_\\land x'$;\n% \\item[(ii)] $q(y,y,q(x,1,y))=q(y,1,q(x,1,y))$ and $q(x,x,q(y,1,x))=q(x,1,q(y,1,x))$.  %$q(y,y,z)= q(y,q(y,1,z),z)= q(q(y,y,0),1,z)=$\n%\\end{itemize}\n% Then $x\\lor y$ is the $\\leq_\\lor$-join of $x$ and $y$ iff $y\\lor x= x\\lor y$.\n%\\end{corollary}\n%\n%\\begin{corollary}\n% Let $x\\in S$ be an idempotent element satisfying  $q(x,x,1)=q(x,1,q(x,0,1)) =1$.  \n%  Then the $\\leq_\\lor$-join of $x$ and $x'$ exists and it is equal to $1$.\n%\\end{corollary}\n%\n%\\begin{proof} It is trivial to prove that $x\\lor x' =x'\\lor x$. By Lemma \\ref{supp} $1=x\\lor x'$ is the $\\leq_\\lor$-lub of $x$ and $x'$. \n%\\end{proof}\n%\n\n\n\\end{document}\n\n\n\\section{Substitution Church algebras of binary functions\\label{funny}}\n\nIn what follows, we dovetail the results of Subsections \\ref{sballo} and\n\\ref{guardaunpo}. The fact that central elements in a Church algebra form a\nBoolean algebra isomorphic to the Boolean algebra of its factor congruences\ninvites a conjecture to the effect that Theorem \\ref{thm:brumba} can be\nappropriately generalised. Mimicking the construction of guard algebras, in\nfact, we construct a substitution Church algebra $F(\\mathbf{A})$ out of the\nbinary functions on an arbitrary algebra $\\mathbf{A}$, which remains embedded\ntherein as its subreduct of zero-dimensional elements. We show that the\ncentral elements of any subalgebra $\\mathbf{B}$ of $F(\\mathbf{A})$ containing \n$F(\\mathbf{A})_{0}$ are decomposition operations on $\\mathbf{A}$ that commutes with every element of $B$. \nWe also prove that the factor congruences corresponding to decomposition\noperations on $\\mathbf{A}$ that commute with every other decomposition\noperation are bi-balanced and form a Boolean sublattice of the lattice of\ncongruences of $\\mathbf{A}$.\n\nLet $\\mathbf{A}$ be an algebra of type $\\nu$ and $F(A)$ be the set of all\nfunctions from $A\\times A$ into $A$. Consider the algebra of type $\\nu\n^{\\prime}$\n\\[\nF(\\mathbf{A})=(F(A),\\sigma^{F(\\mathbf{A})} ,q^{F(\\mathbf{A})},\\pi\n_{0}^{F(\\mathbf{A})},\\pi_{1}^{F(\\mathbf{A}) })_{\\sigma\\in\\nu},\n\\]\nwhose operations are defined as follows (for all $f,g,h,f_{1},\\dots,f_{k}\\in\nF(A)$ and all $a,b\\in A$):\n\n\\begin{enumerate}\n\\item $\\pi_{0}^{F(\\mathbf{A})}(a,b)=b$,\n\n\\item $\\pi_{1}^{F(\\mathbf{A})}(a,b)=a$,\n\n\\item $q^{F(\\mathbf{A})}(f,g,h)=f\\langle g,h\\rangle$,\n\n\\item $\\sigma^{F(\\mathbf{A})}(f_{1},\\dots,f_{k})= \\sigma^{\\mathbf{A}}\\langle\nf_{1},\\dots,f_{k}\\rangle$,\n\\end{enumerate}\nwhere the operation $-\\langle-,\\dots,-\\rangle$ is defined in Equation \\eqref{eq:comp} on page \\pageref{eq:comp}.\n\n\\begin{proposition}\n\\label{prop:churchs} (i) The algebra $F(\\mathbf{A})$ is a substitution Church algebra.\n\n(ii) The algebra $\\mathbf{A}$ is isomorphic to the $\\nu$-algebra\n$F(\\mathbf{A})_{0}$ of all zero-dimensional elements of $F(\\mathbf{A})$.\n\\end{proposition}\n\\begin{proof}\n(i) It is immediate to see that $F(\\mathbf{A})$ abides by the conditions of Definition \\ref{prop:church}. By way of example, we show Condition (S1); in fact, for $a,b\\in A$, $f\\langle \\pi_{1},\\pi_{0}\\rangle(a,b)=f( \\pi_{1}(a,b),\\pi_{0}(a,b))=f(a,b)$.\n(ii) The required map, for any $a\\in A$, is $a\\mapsto f_{a}$, where $f_{a}(x,y)=a$.\n\\end{proof}\n\n\nAny subalgebra $\\mathbf{B}$ of $F(\\mathbf{A})$ such that $F(\\mathbf{A})_{0}\\subseteq B$ is called a \\emph{functional Church algebra of value domain\n$\\mathbf{A}$}.\n\nIn the next proposition we give a representation theorem for substitution\nChurch algebras, in a similar vein to Theorem \\ref{thm:brumba}(2).\n\n\\begin{proposition}\n\\label{prop:homo} Let $\\mathbf{S}$ be a substitution Church algebra of type\n$\\nu^{\\prime}$. The map\n\\begin{equation}\na\\in S\\mapsto q^{\\mathbf{S}}(a,\\text{-},\\text{-}):S_{0}\\times S_{0}\\rightarrow S_{0}\n\\label{eq}\n\\end{equation}\nis a homomorphism from $\\mathbf{S}$ to the functional Church algebra\n$F(\\mathbf{S}_{0})$, whose value domain is the $\\nu$-algebra of all\nzero-dimensional elements of $\\mathbf{S}$.\n\\end{proposition}\n\n\\begin{proof}\nIf $a\\in S$, then $q^{\\mathbf{S}}(a,x,y)\\in S_{0}$ for all $x,y\\in S_{0}$, by\nLemma \\ref{zonzo}. It follows that the map defined in (\\ref{eq}) is\nwell-defined. We now prove that it is a homomorphism.\n\n\\noindent Let $x,y\\in S_{0}$.\n\\[%\n\\begin{array}\n[c]{llll}%\nq^{\\mathbf{S}}(\\sigma^{\\mathbf{S}}(\\bar{a}),x,y) & = & \\sigma^{\\mathbf{S}}(q(a_{1},x,y),\\dots,q(a_{k},x,y)) & \\text{by (S3)}\\\\\n& = & \\sigma^{\\mathbf{S}}\\langle q(a_{1},\\text{-},\\text{-}),\\dots,q(a_{k},\\text{-},\\text{-})\\rangle(x,y) &\n\\\\\n& = & \\sigma^{F(\\mathbf{S}_{0})}(q(a_{1},\\text{-},\\text{-}),\\dots,q(a_{k},\\text{-},\\text{-}))(x,y). &\n\\end{array}\n\\]%\n\\[%\n\\begin{array}\n[c]{llll}%\nq^{\\mathbf{S}}(q^{\\mathbf{S}}(\\bar a),x,y) & = & q^{\\mathbf{S}}(a_{1},q^{\\mathbf{S}}(a_{2},x,y),q^{\\mathbf{S}}(a_{3},x,y)) & \\text{by\n(S2)}\\\\\n& = & q^{{F(\\mathbf{S}_{0})}}(q^{\\mathbf{S}}(a_{1},\\text{-},\\text{-}),q^{\\mathbf{S}}(a_{2},\\text{-},\\text{-}),q^{\\mathbf{S}}(a_{3},\\text{-},\\text{-}))(x,y). &\n\\end{array}\n\\]\nMoreover, $q^{\\mathbf{S}}(0,\\text{-},\\text{-})=\\pi_{0}^{{F(\\mathbf{S}_{0})}}$ and $q^{\\mathbf{S}}(1,\\text{-},\\text{-})=\\pi_{1}^{{F(\\mathbf{S}_{0})}}$. This concludes the proof that $a\\mapsto q(a,\\text{-},\\text{-})$ is a homomorphism.\n\\end{proof}\n\n\n\\section{Factor Congruences}\nLet $\\mathbf A$ be any algebra.\n\\begin{itemize}\n\\item We denote by $Fac(\\mathbf A)$ the set of factor congruences of $\\mathbf A$. \n\\item We denote by $Dec(\\mathbf A)$ the set of decomposition operators of $\\mathbf A$.\n\\item For every $\\phi\\in Fac(\\mathbf A)$, $D(\\phi)$ is the set of decomposition operators $f\\in Dec(\\mathbf A)$ such that $\\theta_f=\\phi$.\n\\item We write \n$\\theta\\mathcal F \\theta^*$ for $(\\theta, \\theta^*)$ is a pair of complementary factor congruences of $\\mathbf A$.\n\\item If $\\theta\\mathcal F \\theta^*$ then we denote by $f_{\\theta,\\theta^*}$ the unique decomposition operator associated to the pair $(\\theta,\\theta^*)$. Recall that, in general, a factor congruence $\\theta$ may have more than one complement $\\theta^*$.\n\\end{itemize}\nLet $f:A^2\\to A$ be a function. We define two binary relations $F,\\hat{F}\\subseteq A^2$ as follows, for every $a,b\\in A$: \n$$a\\ F\\ f(b,a)\\ \\hat F\\ b.$$\nWe define $f_a: A\\to A$ and $f^a : A\\to A$ as follows: $f_a(x)= f(x,a)$ and $f^a(x)= f(a,x)$.\nWe have $f_a(b)=f^b(a)$, for every $a,b$. Moreover, $a\\ F\\ f_a(b)$ and $f^b(a)\\ \\hat F\\ b$.\n\n\n We define $f\\leq g$ if $F\\subseteq G$, $\\hat G\\subseteq \\hat F$ and $F\\circ \\hat G= \\hat G\\circ F$.\n\\begin{itemize}\n\\item[(i)] $f(b,a)=b =g(c,b) \\Rightarrow \\exists u. g(a,u)=u=f(u,b)$.\n\\end{itemize}\n\n$F\\circ \\hat G= \\hat G\\circ F$ and $G\\circ \\hat H= \\hat H\\circ G$ imply $F\\circ \\hat H= \\hat H\\circ F$.\n\n\n\\begin{lemma}\n Let $\\phi,\\theta,\\theta^*\\in Fac(\\mathbf A)$ such that $\\theta\\mathcal F\\theta^*$.\n Then the following conditions are equivalent:\n \\begin{enumerate}\n\\item   $\\phi=(\\phi\\lor\\theta)\\cap(\\phi\\lor\\theta^*)$;\n\\item $\\phi\\circ\\theta=\\theta\\circ\\phi$ and $(\\phi\\lor\\theta)\\cap \\theta^*\\subseteq \\phi$;\n\\item $g \\ \\mathrm{Cm}\\ f_{\\theta,\\theta^*}$, for every $g\\in D(\\phi)$.\n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}\n By \\cite[Theorem 1]{ssm} we have the equivalence of (1) and (2).\n \n Let $f=f_{\\theta,\\theta^*}$ in this proof. $f(g(a,b),g(c,d)) = g(f(a,c),f(b,d))$.\n \n $f(g(a,b),c) = g(f(a,c),f(b,d))$.\n \n$a\\phi g(a,b)\\phi^* b$, %$c\\phi g(c,d)\\phi^* d$, \n\n$a\\theta f(a,c)\\theta^* c$, $b\\theta f(b,d)\\theta^* d$, \n\n \n\\end{proof}\n\n\n\\begin{lemma}\n $g\\ \\mathrm{Cm}\\ h$, for all $g,h\\in D(\\phi)$.\n\\end{lemma}\n\n\\begin{proof}\n$\\theta_g =(\\theta_g\\lor \\theta_{h'})\\cap(\\theta_g\\lor\\theta_{h})$ for every $x,y\\in\\{g,h,g',h'\\}$\n\n\\end{proof}\n\n\n\\section{due}\n\\begin{proposition}\n Let $\\mathbf A$ be an algebra and $\\theta, \\theta^*$ be congruences such that $\\theta\\mathcal F\\theta^*$. If  $\\phi\\in \\mathrm{Con}(\\mathbf A)$ then\n $\\theta \\subseteq \\phi$ and $\\theta^*\\cap \\phi=\\Delta$ imply $\\theta=\\phi$.\n\\end{proposition}\n\n\\begin{proof} Let $a\\phi b$. Then there exists $c$ such that $a\\theta c\\theta^* b$. By hypothesis we derive $a\\phi c$, that implies $b\\phi c$. This last condition and $b\\theta^* c$ imply $b=c$, i.e., $a\\theta b$. In conclusion, $\\theta=\\phi$.\n\\end{proof}\n\n\n\\begin{corollary}\n Let $\\mathbf A$ be an algebra such that $Fac(\\mathbf A)$ is a sublattice of $\\mathrm{Con}\\mathbf A$. \n If the map $$\\theta\\in Fac(\\mathbf A) \\mapsto \\theta^*$$\n is antitone and involutive, then $Fac(\\mathbf A)$ is an orthomodular lattice.\n\\end{corollary}\n\n\\begin{proof} Every ortholattice satisfying the condition of Proposition 1 is an orthomodular lattice.\n\\end{proof}\n\n\n\\section{Birkhoff and Malcev}\n\nOpen Problem by Birkhoff and Malcev: Characterise the lattices of equational theories among all lattices.\n\n\nSome known facts:\n\\begin{itemize}\n\\item A lattice of equational theories is an algebraic lattice with compact unit.\n\\item (Lampe 1986) Any equational theories lattice satisfies the Zipper Condition: If $\\bigvee \\{a_i : i \\in I\\} = 1$ and $a_i \\land c = a_j\\land c$ for all $i$ and $j$, then $c\\leq a_i$.\n\\end{itemize}\n\n\nLet $\\mathbf{F}_\\mathcal{V}$ be  the free algebra $\\mathbf{F}_\\mathcal{V}$ with countable generators $x_0,\\dots, x_n,\\dots$  in a variety $\\mathcal{V}$.\n The algebra  $$(\\mathbf{F}_\\mathcal{V}, q_n, \\e_n)_{n\\geq 1}$$ is\nan algebra of dimension $\\omega$, where $q_n$ is the substitution operator\n$$q_n(t,u_{0},\\dots,u_{n-1}) =t\\left[ u_{0}/x_{0},\\dots,u_{n-1}/x_{n-1}\\right];\\qquad \\e_i = x_i.$$\n\n\\begin{lemma}\n The lattice $\\mathrm{Con}(\\mathbf{F}_\\mathcal{V}, q_n, \\e_n)_{n\\geq 1}$  of congruences is isomorphic to the lattice of equational theories extending $\\mathrm{Eq}(\\mathcal V)$.\n\\end{lemma}\n\n\n\n\\begin{theorem}\n If a term $t(x_0,\\dots,x_{n-1})$ is $n$-central in the algebra $(\\mathbf{F}_\\mathcal{V}, q_n, \\e_n)_{n\\geq 1}$, then there exist subvarieties $\\mathcal V_0,\\dots, \\mathcal V_{n-1}$ of $\\mathcal V$ s. t.\n\\begin{itemize}\n\\item $\\mathcal V_i$ is axiomatised over $\\mathcal V$ by the identity $t(x_0,\\dots,x_{n-1})=x_i$;\n\\item $\\mathrm{Eq}(\\mathcal V) = \\mathrm{Eq}(\\mathcal V_1)\\cap \\dots\\cap \\mathrm{Eq}(\\mathcal V_n)$.\n\\item $\\mathcal V= \\mathcal V_0\\times\\dots\\times \\mathcal V_{n-1}$\n\\end{itemize}\n\\end{theorem}\n\n\n\\begin{definition} Let $\\tau$ be an algebraic similarity type.\n  A substitution $\\omega$DA is an algebra $$\\mathbf S = (S, \\sigma, q_n, \\e_i)_{\\sigma\\in\\tau, n\\geq 1, i\\geq 0}$$ satisfying the following identities:\n  \\begin{enumerate}\n\\item $q_n(\\e_i,y_0,\\dots,y_{n-1})=y_i$ ($i=0,\\dots,n-1$);\n\\item $q_n(x,\\e_0,\\dots,\\e_{n-1}) = x$;\n\\item $q_k(x,\\bar y) = q_n(x,\\bar y,\\e_{k+1},\\dots,\\e_{n-1})$ ($n\\geq k$);\n\\item If $n\\geq k$ then $q_k(q_n(x,y_0,\\dots,y_{n-1}),\\bar z)=q_n(x,q_k(y_0,\\bar z),\\dots,q_k(y_{n-1},\\bar z))$;\n\\item If $n< k$ then $q_k(q_n(x,y_0,\\dots,y_{n-1}),\\bar z)=q_k(x,q_k(y_0,\\bar z),\\dots,q_k(y_{n-1},\\bar z), z_n,\\dots,z_{k-1}))$;\n\\item $q_n(\\sigma(\\bar x),y_0,\\dots,y_{n-1}) = \\sigma(q_n(x_1,y_0,\\dots,y_{n-1}),\\dots,q_n(x_k,y_0,\\dots,y_{n-1}))$ for  $\\sigma\\in\\tau$.\n\\end{enumerate}\n\\end{definition}\n\n\n\nAn element $s$ of the algebra \\emph{does not depend on} $\\e_{n}$ if \n$q_{n+1}(s,\\e_0,\\dots,\\e_{n-1},\\e_{n+1})=s$.\n\nA substitution $\\omega$DA $\\mathbf S$ is \\emph{locally finite} if, for every $s\\in S$, the following set is finite:\n$$D(s)=\\{\\e_n: q_{n+1}(s,\\e_0,\\dots,\\e_{n-1},\\e_{n+1})\\neq s\\}.$$ \n\\begin{theorem} A lattice $L$ is isomorphic to a lattice of equational theories \nif and only if $L \\cong \\mathrm{Con}(\\mathbf S)$, for a suitable locally finite\n  substitution $\\omega$DA $\\mathbf S$. \n  \\end{theorem}\n  \n  \n\\section{The Zipper condition}\nThe following results are based on a paper by V. Diercks, M. Erne', J. Reinhold\nComplements in lattices of varieties and equational theories.\nAlgebra Universalis 1994 vol. 31 pp. 506-515.\n\nThe lattice of lambda theories, and, more generally, every lattice of equational theories, satisfies the Zipper condition,\nthat can be expressed as follows:\n$$\\forall a\\forall c(\\bigvee\\{ b: a \\wedge b = c\\} = 1 \\to a = c).$$\n\nHereafter, let $L$ be a complete lattice.\n\n\\begin{definition} $U_a = \\{ b \\in L- \\{ 1\\} : a \\vee b = 1\\}$ and \n$L_a = \\{ b \\in L- \\{ 0\\} : a \\wedge b = 0\\}$.\n\\end{definition}\n\n\nWe define some properties:\n\n\\begin{itemize}\n\\item [(LS)] L is said to be {\\em lower semicomplemented} if $L_a$ is nonempty for all $a \\neq 1$.\n\\item [(US)] L is said to be {\\em upper semicomplemented} if $U_a$ is nonempty for all $a \\neq 0$.\n\\item [(MC)] The least element of $L$ is a meet of coatoms.\n\\end{itemize}\n\n\\begin{proposition}\\label{label1} If $L$ is coatomic, then (MC) iff (US).\n\\end{proposition}\n\n\\begin{proof} (US) $\\Rightarrow$ (MC)  If the element $a$ \nis a lower bound of the coatoms then $U_a$ is empty.\n\n(MC) $\\Rightarrow$ (US) If $U_a$ is empty then $a \\vee b = b$ for every coatom $b$.\n\\end{proof}\n\n\nDefine \n$$\\mbox{$a^- = \\vee L_a$.}$$\nWe note that $a^- = 0$ if, and only if, $a$ has no lower semicomplements.\n\n\\begin{lemma}\\label{f} Let L be a coatomic complete lattice.\n Then the function $^-$ satisfies the following conditions:\n\\begin{enumerate}\n\\item $^-$ is an antitone map, i.e., $a\\leq b$ implies $b^- \\leq a^-$. In particular, \nthe set of elements with (without) a lower complement is a lower (upper) set.\n\\item $a^-\\leq a$ iff $a^- =0$. \n\\item $(a \\vee a^-)^- = 0$.\n\\item $((a\\wedge a^-)^-)^- = 0$.\n\\item If $L$ satisfies the Zipper condition, then $a^- \\neq 1$ for all $a \\neq 0$.\n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof} (1) If  $a\\leq b$ then $L_b \\subseteq L_a$.\n\n\n(2) If $a^-\\leq a$ then $b \\leq a$ for all $b$ such that $b\\wedge a = 0$. This is possible only if $L_a = \\emptyset$,\nthat is, $a^- = 0$.\n\n(3) From $a \\leq a \\vee a^-$ and from (1) it follows that  $(a \\vee a^-)^- \\leq a^- \\leq a \\vee a^-$,\n and this is possible only if $(a \\vee a^-)^- = 0$ by (2).\n\n(4) From (3) applied to $a \\wedge a^-$ it follows that $((a \\wedge a^-) \\vee (a \\wedge a^-)^-)^- = 0$.\nSince $a \\wedge a^- \\leq a^- \\leq (a \\wedge a^-)^-$ by (1) applied to\n$a \\wedge a^- \\leq a$, then we get $((a \\wedge a^-)^-)^- = 0$, i.e., $(a\\wedge a^-)^-$ has no lower semicomplements.\n\n(5) If $1 = a^- = \\vee \\{ b \\in L-\\{ 0\\} : b\\wedge a = 0\\}$ then $a = 0$ from the Zipper condition.\n\\end{proof}\n\nWe say that $b$ is a {\\em weak complement} of $a$ if $(a \\vee b)^- = 0$ and $((a\\wedge b)^-)^- = 0$.\nThe element $a^-$ is the greatest weak complement of $a$ (to prove).\n\nWe say that a lattice $\\mathbf L = (L,\\wedge, \\vee, 0,1)$ is a {\\em Zipper lattice} if it satisfies the following axioms:\n\\begin{itemize}\n\\item [($\\pi_1$)] $a\\leq b\\ \\Rightarrow\\ b^- \\leq a^-$. \n\\item [($\\pi_2$)] $a^-\\leq a\\ \\Rightarrow\\ a^- =0$. \n\\item [($\\pi_3$)] $(a \\vee a^-)^- = 0$.\n\\item [($\\pi_4$)] $((a\\wedge a^-)^-)^- = 0$.\n\\item [($\\pi_5$)] $a^- = 1\\ \\Leftrightarrow\\ a = 0$.\n\\item [($\\pi_6$)] $b\\wedge a = 0\\ \\Rightarrow\\ b \\leq a^-$.\n\\end{itemize}\n\n\\begin{proposition}\\label{label2} Let $L$ be a Zipper lattice.\nThen the following conditions are equivalent:\n\\begin{enumerate}\n\\item $L$ is complemented;\n\\item $L$ is (LS);\n\\item $a^-$ is a complement of $a$ for all $a\\in L$.\n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof} The implications (3 $\\Rightarrow$ 1) and (1 $\\Rightarrow$ 2) are obvious. We now prove that \n(2 $\\Rightarrow$ 3). By hypothesis and by definition of $a^-$ we have that\n$a^- = 0$ iff $a = 1$. Then from $(a \\vee a^-)^- = 0$ and $((a\\wedge a^-)^-)^- = 0$\nwe get $a \\vee a^- = 1$ and $(a\\wedge a^-)^- = 1$, from which by Lemma~\\ref{f}(1) $a\\wedge a^- = 0$.\n\\end{proof}\n\n\\begin{lemma} Let $L$ be a Zipper lattice.\nThen $a^- \\vee b \\neq 1$ for all $a,b \\neq 0,1$.\n\\end{lemma}\n\n\\begin{proof}\nWe have: $a^-\\wedge b^- \\wedge a = c'\\wedge d' \\wedge d = 0$ and $c\\vee d = 1$ together with the Zipper condition\nimply $c' \\wedge d' = 0$. From this last equality and $d\\wedge d' = 0$ and the Zipper condition it follows that\n$c' \\vee d \\neq 1$.\n\\end{proof}\n\nIf L is a coatomic lattice, then we denote by $\\mathcal C_{ls}$ the set of coatoms with a lower semicomplement.\n\n\\begin{lemma} Let L be a coatomic complete lattice satisfying the Zipper condition\nand let $\\pi = \\wedge \\mathcal C_{ls}$. Then, we have:\n\\begin{enumerate}\n\\item  $\\pi \\neq \\wedge (\\mathcal C_{ls}-\\{c\\})$, for every $c\\in \\mathcal C_{ls}$.\n\\item An element $a$ has a complement iff $a\\leq c$ for a coatom $c\\in \\mathcal C_{ls}$.\n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof} \n(1) If $c$ and $d$ are distinct coatoms with lower semicomplements $c'$ and $d'$, respectively,\nthen $c'\\wedge d' \\wedge c = c'\\wedge d' \\wedge d = 0$ and $c\\vee d = 1$ together with the Zipper condition\nimply $c' \\wedge d' = 0$. From this last equality and $d\\wedge d' = 0$ and the Zipper condition it follows that\n$c' \\vee d \\neq 1$. Since $d$ is a coatom, then it must be $c' \\leq d$. By the arbitrariness of $d\\in SC$\nwe obtain $c' \\leq \\wedge (SC - \\{ c\\})\\not\\leq c$.\n\n(2) ($\\Rightarrow$) Let $a \\wedge a' = 0$ and $a\\vee a' = 1$. Let $a \\leq c$ for a coatom $c$\nAssume, by contraposition that $a\\not\\leq c$\nfor all $c\\in SC$.\n\\end{proof}\n\n\\begin{proposition} Let L be a coatomic complete lattice satisfying the Zipper condition\nand such that the top element is compact. Then the following conditions are equivalent:\n\\begin{enumerate}\n\\item L is complemented (= lower semicomplemented, by Prop.~\\ref{label2});\n\\item L is upper semicomplemented, and coatoms have lower semicomplements;\n\\item The coatoms form an irredundant decomposition of the least element;\n\\item The coatoms form a finite decomposition of the least element.\n\\end{enumerate}\n\\end{proposition}\n\n\\begin{proof} Let $C$ be the set of coatoms.\n\n($1 \\Rightarrow 2$): Trivial.\n\n($2 \\Rightarrow 3$): By Prop.~\\ref{label1} the coatoms form a decomposition of the least element.\n If $c$ and $d$ are distinct coatoms with lower semicomplements $c'$ and $d'$, respectively,\nthen $c'\\wedge d' \\wedge c = c'\\wedge d' \\wedge d = 0$ and $c\\vee d = 1$ together with the Zipper condition\nimply $c' \\wedge d' = 0$. From this last equality and $d\\wedge d' = 0$ and the Zipper condition it follows that\n$c' \\vee d \\neq 1$. Since $d$ is a coatom, then it must be $c' \\leq d$. By the arbitrariness of $d$\nwe obtain $c' \\leq \\wedge (C - \\{ c\\})\\not\\leq c$.\n\n($3 \\Rightarrow 4$): Let $L_a = \\{ b \\in L- \\{ 0\\} : a \\wedge b = 0\\}$.\nConsider the set $A = \\{ b\\in C: a \\not\\leq b\\}$. It is obvious that $\\emptyset \\neq A \\neq C$. \nThen we have $(\\wedge A)\\wedge a \\leq (\\wedge A) \\wedge (\\wedge C-A) = 0$. Since by hypothesis\n$\\wedge A \\neq 0$, we have the conclusion.\n\n($4 \\Leftrightarrow 1$): By Prop.~\\ref{label2}.\n\n($1-4 \\Rightarrow 5$): First we  show that\n$1$ is the join of all elements of the form $\\wedge (C - \\{ c\\})$ with $c\\in C$.\nLet $a\\neq 1$ be an upper bound of all these elements and let $c$ be a coatom such that $a \\leq c$.\nIf $c'$ is the complement of $c$, then we have (by the Zipper condition) $c' \\leq \\wedge (C - \\{ c\\}) \\leq a\\leq c$.\nThis is a contradiction.\nThen $1$ is the join of the elements $\\wedge (C - \\{ c\\})$ with $c\\in C$. Since $1$ is compact, then\nthere is a finite number of coatoms $c_1,\\dots, c_n$ such that the join of $\\wedge (C - \\{ c_i\\})$ with \n$i = 1,\\dots,n$ is equal to $1$. \nIf there exists a coatom $d$ such that $d \\neq c_i$ for all $i$, then $d\\in C - \\{ c_i\\}$\nfor all $i$, so that $\\wedge (C - \\{ c_i\\}) \\leq d$ for all \n$i = 1,\\dots,n$. Contradiction.\n\n\n($5 \\Rightarrow 1-4$): \nLet $c_1\\wedge\\dots\\wedge c_n = 0$, where  $c_1,\\dots, c_n$ are all coatoms.\nThen, for example, $c_2\\wedge\\dots\\wedge c_n$ is a complement of $c_1$.\n\n\\end{proof}\n\n\n\\subsection{Rewriting and the  head normal form of a term}\n\\label{sec:rewriting1}\nIn this section we show how  to turn the equations axiomatising $\\mathsf{CA}$ into rewriting rules. \n\n\\begin{definition} A clone $\\tau$-term\n is called a \\emph{head normal form} (hnf, for short) if it is defined according to the following grammar: \n$$t, t_i ::= \\e_i\\ |\\ x\\ |\\ q_n(x, t_1,\\dots, t_n)\\ |\\ \\sigma(t_1,\\dots, t_k),$$ where $x\\in\\mathrm{V}$ is an arbitrary variable and $\\sigma\\in \\tau$. The occurrence of the variable $x$ in the hnf $t::= q(x, t_1,\\dots, t_n)$ is called \\emph{head occurrence of $x$ into $t$}.\n\n\nA hnf is called a \\emph{strong hnf} (shnf, for short) if it does admit no subterm of the form $q_n(x,\\e_1,\\dots,\\e_n)$.\n\\end{definition}\n\n\\begin{lemma}\\label{lem:hnf} The following conditions are equivalent for a clone term $t$:\n\\begin{enumerate}\n\\item $t$ is a ground hnf;\n\\item $t$ is a ground shnf;\n\\item $t$ is defined according to the following grammar: \n$$t, t_i ::= \\e_i\\ |\\  \\sigma(t_1,\\dots, t_k).$$ \n\\end{enumerate}\n\\end{lemma}\n\nWe define a confluent and terminating rewriting system to get the canonical hnf of a  term.\n\nWe consider the variety $\\mathcal{H}$ of algebras in the type of clone $\\tau$-algebras axiomatised by \n identities (C1), (C2), (C4),(C5) and (C6) of Definition \\ref{def:clonealg}.\n%the following identities:\n%\\begin{enumerate}\n%\\item[(C1)] $q_n(\\e_i,x_1,\\dots,x_n)=x_i$ $(1\\leq i\\leq n)$;\n%\\item[(C2)] $q_n(\\e_j,x_1,\\dots,x_n)=\\e_j$ $(j>n)$;\n%%\\item[(C3)] $q_n(x,\\e_1,\\dots,\\e_n)=x$;\n%%\\item[(C4)] $q_k(x,\\bar y)= q_n(x,\\bar y,\\e_{k+1},\\dots,\\e_n)$ ($n> k$);\n%\\item[(C4)] If $n< k$, then\n%$$q_k(q_n(x,\\mathbf y),\\mathbf z) = q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z),z_{n+1},\\dots,z_k)).$$\n%\\item[(C5)] If $n\\geq k$,  then\n%$$q_k(q_n(x,\\mathbf y),\\mathbf z) = q_n(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z)).$$\n%\\item[(C6)]  $q_n(\\sigma(x_1,\\dots,x_k),y_1,\\dots,y_n) = \\sigma(q_n(x_1,y_1,\\dots,y_n),\\dots,q_n(x_k,y_1,\\dots,y_n))$ for every $\\sigma\\in\\tau$ of arity $k$.\n%\n%\\end{enumerate}\n\nWe define an algebra $\\mathbf{H}$, having the set of hnfs as universe. The operations $q_n^\\mathbf H$ and $\\sigma^\\mathbf H$ are defined by induction over the complexity of its first hnf argument. \n\nFor every hnfs $\\bar \\psi=\\psi_1,\\dots,\\psi_n$ and $x\\in \\mathrm{V}$:\n\\[\n\\begin{array}{rl}\n&  q_n^{\\mathbf H}(\\e_i,\\bar\\psi)=\\psi_i\\quad (i\\leq n) \\\\\n&  q_n^{\\mathbf H}(\\e_j,\\bar\\psi)=\\e_j\\quad (j> n) \\\\\n&   q_n^{\\mathbf H}(x,\\bar\\psi)=q_n(x,\\bar\\psi)\\\\\n&   q_n^{\\mathbf  H}(q_k(x,u_1,\\dots,u_k),\\bar\\psi )=q_k(x,q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi))\\quad (k\\geq n)\\\\\n&   q_n^{\\mathbf  H}(q_k(x,u_1,\\dots,u_k),\\bar\\psi )=q_n(x,q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi),\\psi_{k+1},\\dots,\\psi_n)\\quad (k < n)\\\\\n& q_n^{\\mathbf  H}(\\sigma(u_1,\\dots,u_k),\\bar\\psi )=\\sigma(q_n^{\\mathbf  H}(u_1,\\bar\\psi),\\dots, q_n^{\\mathbf H}(u_k,\\bar\\psi))\\\\\n&   \\sigma^{\\mathbf H}(\\bar\\psi)=\\sigma(\\bar\\psi) \\\\\n\\end{array}\n\\]\nA routine calculation shows that $\\mathbf{H}$ is isomorphic to the free $\\mathcal H$-algebra $\\mathbf F_\\mathcal H$ over a countable set V of generators. \n\nWe turn the identities axiomatising $\\mathcal H$ into rewriting rules.\n\n\\begin{definition}\nThe rewriting rules $\\rightarrowtail_\\mathrm{hnf}$ are:\n\\begin{description}\n\\item[($h_1$)] $q_n(\\e_i,x_1,\\dots,x_n) \\rightarrowtail_\\mathrm{hnf} x_i$ ($1\\leq i\\leq n$)\n\\item[($h_2$)] $q_n(\\e_j,x_1,\\dots,x_n) \\rightarrowtail_\\mathrm{hnf} \\e_j$ ($j > n$)\n%\\item[($h_2$)] $q_n(x, \\e_1,\\dots,\\e_n) \\rightarrowtail_\\mathrm{hnf} x$ \n\\item[($h_3$)] $(n\\geq k)$\n$$q_k(q_n(x,y_1\\dots,y_n),z_1,\\dots,z_k)  \\rightarrowtail_\\mathrm{hnf} q_n(x,q_k(y_1,z_1,\\dots,z_k),\\dots, q_k(y_n,z_1,\\dots,z_k))$$\n\\item[($h_4$)] $(n< k)$\n$$q_k(q_n(x,\\mathbf y),\\mathbf z) \\rightarrowtail_\\mathrm{hnf} q_k(x,q_k(y_1,\\mathbf z),\\dots,q_k(y_n,\\mathbf z),z_{n+1},\\dots,z_k))$$\n\\item[($h_5$)] $q_n(\\sigma(x_1,\\dots,x_k),y_1,\\dots,y_n) \\rightarrowtail_\\mathrm{hnf} \\sigma(q_n(x_1,y_1,\\dots,y_n),\\dots,q_n(x_k,y_1,\\dots,y_n))$.\n\\end{description}\n\\end{definition}\n\n\\begin{theorem}\\label{thm:trs1} The rewriting system $\\rightarrowtail_\\mathrm{hnf}$ is terminating and confluent.\n\\end{theorem}\n\n\\begin{proof} The left linear system  $\\rightarrowtail_\\mathrm{hnf}$ is confluent because all critical pairs are converging. Termination  is  obtained by applying the subterm criterion to the dependency pairs of  $\\rightarrowtail_\\mathrm{hnf}$ (see  \\cite[Section 2]{HM}). We have the following dependency pairs of rule $(h_1)$ $l \\rightarrowtail_\\mathrm{hnf} r$:\n $q^\\#(q(x,\\mathbf y),\\mathbf z) \\rightarrowtail q^\\#(y_i,\\mathbf z)$, since $q(y_i,\\mathbf z)$ is not a subterm of $l$, and \n$q^\\#(q(x,\\mathbf y),\\mathbf z)  \\rightarrowtail q(x,q(y_1,\\mathbf z),\\dots, q(y_n,\\mathbf z))$, since $r$ is not a subterm of $l$. For the subterm criterion, we  apply the simple projection in the first argument. This proof of termination of the TRS $\\rightarrowtail_\\mathrm{hnf}$ is automatised by the tool \\TTTT\\ (see \\cite{ttt}).\n\\end{proof}\n\n\n\nThe normal forms of $\\rightarrowtail_\\mathrm{hnf}$ are the hnfs;  we denote by $\\mathrm{hnf}(t)$ the head normal form of $t$.\n\nEvery hnf can be rewritten into a shnf by applying the rewriting rule\n\\begin{description}\n\\item[($h_6$)] $q_n(x, \\e_1,\\dots,\\e_n) \\rightarrowtail_\\mathrm{shnf} x$.\n\\end{description}\nWe denote by $\\mathrm{shnf}(t)$ the strong head normal form of $t$.\n\n\\begin{proposition}\\label{prop:hnf} Let $\\mathbf C$ be a clone $\\tau$-algebra. Then the following conditions hold:\n\\begin{itemize}\n\\item[(i)] $\\mathbf C\\models t=\\mathrm{hnf}(t)=\\mathrm{shnf}(t)$;\n\\item[(ii)] If  $\\mathrm{shnf}(t)=\\mathrm{shnf}(u)$ (syntactically), then $\\mathbf C\\models t=u$;\n\\item[(iii)] $\\mathbf C\\models t=u\\ \\text{iff}\\ \\mathbf C\\models \\mathrm{shnf}(t)=\\mathrm{shnf}(u)$.\n\\end{itemize}\n\\end{proposition}\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:15", "yymm": "2010", "arxiv_id": "2010.14461", "url": "https://arxiv.org/abs/2010.14461", "source": "arxiv"}}
{"text": "\\documentclass{amsart}\n\\usepackage{tikz}\n\\usepackage{thmtools,thm-restate}\n\\usepackage{ifthen}\n\\usepackage{scalefnt}\n\\usepackage[latin1]{inputenc}\n\\usepackage[T1]{fontenc}\n\\usepackage{amsmath,amssymb,amsthm,bm}\n\\usepackage{graphicx}\n\\usepackage{hyperref}\n\\usepackage{upgreek}\n\\usepackage{cleveref}\n\n\\usepackage[marginpar]{todo}\n\n\\usepackage{booktabs,siunitx}\n\\sisetup{table-format=2.1}\n\n\\usepackage{scalerel}\n\n\\DeclareMathOperator*{\\bigcdot}{\\scalerel*{\\cdot}{\\bigodot}}\n\\DeclareMathOperator{\\snap}{snap}\n\\declaretheorem[numberwithin=section]{theorem}\n\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\abs}[1]{\\left\\lvert #1 \\right\\rvert}\n\\newcommand{\\co}{\\colon\\thinspace}\n\\DeclareMathOperator{\\Conf}{Conf}\n\\DeclareMathOperator{\\Grid}{Grid}\n\\DeclareMathOperator{\\Cplx}{Cplx}\n\\DeclareMathOperator{\\bary}{bary}\n\\DeclareMathOperator{\\sgn}{sgn}\n\n\n\\newcommand{\\config}[3]{C(#1;#2,#3)}\n\\newcommand{\\cell}[3]{X(#1;#2,#3)}\n\\newcommand{\\ambient}[3]{G(#1;#2,#3)}\n\n\n\n%\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{conjecture}[theorem]{Conjecture}\n\\newtheorem{question}[theorem]{Question}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\theoremstyle{definition}\n\\newtheorem{definition}[theorem]{Definition}\n\\newtheorem{example}[theorem]{Example}\n\\newtheorem{claim}[theorem]{Claim}\n\n%\\newcommand{\\config}{\\mathcal{C}}\n\\newcommand{\\cconfig}{\\bar{\\mathrm{config}}} % closed configuration space\n%\\newcommand{\\cell}{\\mathrm{cell}}\n\\newcommand{\\poset}{\\mathrm{poset}}\n\\newcommand{\\symbols}{\\mathcal{A}}\n\n\n\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\Q}{\\mathbb{Q}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\newcommand{\\hequiv}{\\simeq}\n\n\n%\\renewcommand{\\baselinestretch}{1.25}\n\n%\\usepackage[square,authoryear,sort&compress]{natbib}\n%\\usepackage[total={8.5in,11in},text={6.5in,9in},centering]{geometry}\n\n\\begin{document}\n\\author[H. Alpert]{Hannah Alpert}\n\\author[U. Bauer]{Ulrich Bauer}\n\\author[M. Kahle]{Matthew Kahle}\n\\author[R. MacPherson]{Robert MacPherson}\n\\author[K. Spendlove]{Kelly Spendlove}\n\\title{Configuration spaces of hard squares in a rectangle}\n\\maketitle\n\n\\begin{abstract}\n\nWe study the configuration spaces $\\config{n}{p}{q}$ of $n$ labeled hard squares in a $p \\times q$ rectangle, a generalization of the well-known ``15 Puzzle''. Our main interest is in the topology of these spaces. Our first result is to describe a cubical cell complex and prove that is homotopy equivalent to the configuration space. We then focus on determining for which $n$, $j$, $p$, and $q$ the homology group $H_j [ \\config{n}{p}{q} ]$ is nontrivial. We prove three homology-vanishing theorems, based on discrete Morse theory on the cell complex. Then we describe several explicit families of nontrivial cycles, and a method for interpolating between parameters to fill in most of the picture for ``large-scale'' nontrivial homology. \n\n\n% One summary of results is via the `large-scale' picture where $x = n / pq$ and $y = j / pq$. We give necessary conditions and sufficient conditions for a point in the $xy$-plane to be a realizable by a nontrivial cycle, and the conditions nearly match.\n\\end{abstract}\n\n\n\n\\section{Introduction}\n\n% Configuration spaces of points on manifolds are well studied. For example, Arnold computed the homology of the configuration space of points in the plane \\cite{Arnold14}. \n\nWe study the configuration space of $n$ labeled hard squares in a $p \\times q$ rectangle, which we denote by $\\config{n}{p}{q}$.\nThe case $n=15$ and $p=q=4$ corresponds to the famous ``15 Puzzle''. This puzzle was apparently invented by Noyes Palmer Chapman, a postmaster in Canastota, New York, in 1874 \\cite{15puzzle}. Already by 1879, the puzzle had been analyzed mathematically by Johnson and Story \\cite{JS1879}. They showed that it is not possible, for example, for any sequence of moves to transpose the pieces labelled $14$ and $15$. Their observation is really a topological one, namely that the configuration space has two connected components.\n\nA natural discrete model for the 15 Puzzle is the graph $G_{15}$, which we describe as follows. The vertices are the aligned positions of the puzzle, corresponding to the $16!$ permutations of the 15 pieces and the one hole, and we have an edge between every pair of positions that differ by sliding a piece into the hole. \n\nIf we allow arbitrary positions for non-overlapping squares, as long as they do not overlap, then the configuration space for the 15 Puzzle is more than $1$-dimensional, though; for instance, there is a three-parameter family of ways to slide horizontally the three pieces in the bottom row. Nevertheless, as a special case of our results here, the configuration space of the 15 Puzzle deformation retracts to a one-dimensional subspace homeomorphic to $G_{15}$.\n\nHaving a cell complex structure allows for computing many topological invariants directly. For example, the Betti number $\\beta_1$ can be computed by counting the number of $0$--cells $f_0=16!$ and $1$--cells $f_1=24 \\times 15!$ of $G_{15}$, using the fact that $\\beta_0 = 2$, and applying the $1$-dimensional Euler formula $f_0 - f_1 = \\beta_0 - \\beta_1$. \n\nIn the more general setting, we describe a cubical complex $\\cell{n}{p}{q}$ and show it is always a deformation retract of the configuration space $\\config{n}{p}{q}$. Applying discrete Morse theory on this complex allows us to establish some necessary conditions on where nontrivial homology can appear.\n\n% The rest of this paper is organized as follows. In Section \\ref{sec:defs}, we describe the cubical cell complex $\\cell{n}{p}{q}$, and in Section \\ref{sec:homotopy} we prove the homotopy equivalence $\\config{n}{p}{q} \\sim \\cell{n}{p}{q}$. (This needs to be filled in.)\n\nIn the following, we always assume that $p,q \\ge 1$, $0 \\le n \\le pq$, and $j \\ge 0$. We also sometimes use a different parametrization, which can be thought of as a ``large-scale'' parametrization, by defining $x=n/pq$ and $y=j/pq$.\nThe quantity $x$ has an easy interpretation as a ``density'', describing the area ratio in the rectangular that is occupied by squares.\n\n\\begin{restatable}[Homology vanishing theorem]{theorem}{vanishinghomology} \\label{thm:homologyvanishing}\nWe have the following. \n\\begin{enumerate}\n    \\item If $j > pq-n$, then $H_j[\\config{n}{p}{q}] =0$.\n    \\item If $j > n$, then  $H_j[\\config{n}{p}{q}] =0$.\n    \\item If $j > pq / 3$, then $H_j[\\config{n}{p}{q}] =0$. \n\\end{enumerate}\nEquivalently, on the large scale we have that if $H_j [ \\config{n}{p}{q} ] \\neq 0$, then\n $y \\le \\min \\{ 1-x, \\; x, \\; 1/ 3 \\}.$ \\\\\n\\end{restatable}\n\nThe cubical cell complex model allows us to do exact computations for small examples. We include a table of Betti numbers in Section~\\ref{sec:computation}. Based in part on our computations, we conjecture the following.\n% In Theorem \\ref{thm:homologyvanishing}, (1) comes immediately once we have the cell complex, simply by dimension of the complex. Then for (2) and (3), we describe a discrete Morse function on $\\cell{n}{p}{q}$ to reduce its dimension further.\n\n\n\\begin{conjecture} \\label{conj:main}\nIf $H_j [ \\config{n}{p}{q} ] \\neq 0$, then\n\\[j \\le \\min \\{ pq-n, \\; n-\\frac{8n^2}{9pq}, \\; pq/ 4 \\}.\\]\nEquivalently, we conjecture that if\n $H_j [ \\config{n}{p}{q} ] \\neq 0$, then\n \\[y \\le \\min \\{ 1-x, \\; x-(8/9)x^2, \\; 1/ 4 \\}.\\]\n\\end{conjecture}\n\n\nIn Section \\ref{sec:nontrivial}, we describe several families of explicit nontrivial cycles, and a method for interpolating between parameters. We \\emph{almost} show that whenever  $y \\le \\min \\{ 1-x, \\; x-(8/9)x^2, \\; 1/ 4 \\}$, there exist $n,j,p,q$ such that $H_j [ \\config{n}{p}{q}] \\neq 0$.\nInstead we prove an analogous statement with a piecewise linear approximation of the parabola $y = x -(8/9)x^2$. Let $S$ be the set of points on the parabola defined by\n\\[ S = \\left\\{ \\left( x,x-(8/9)x^2 \\right) \\bigm\\vert x=  \\frac{3}{4k},k \\ge 1 \\right\\}. \\]\nNote that $(3/4,1/4) \\in S$ and $(3/8,1/4) \\in S$.\nLet $I$ be the closed interval $$ I = \\{ (x,y) \\mid 0 \\le x \\le 1 \\mathrm{\\ and\\ } y = 0 \\}.$$\n\n\\begin{restatable}[Large-scale homology non-vanishing theorem]{theorem}{nonvanish} \\label{thm:allnonvanish}\nLet $(x,y)$ be any rational point in the convex hull of $S \\cup I$. Then there exist $n,p,q,j$ such that $x=n/pq$, $y=j/pq$, and $H_j[ \\config{n}{p}{q} ] \\neq 0$.\n\\end{restatable}\n\nIt may actually be that Theorem \\ref{thm:allnonvanish} suggests the right necessary conditions for nontrivial homology, rather than Conjecture \\ref{conj:main}. We do not currently know of any instance of $n,j,p,q$ where $H_j [\\config{n}{p}{q}] \\neq 0$ and $(x,y)$ lies outside of the convex hull of $S \\cup I$.\n\nA summary of our main results is illustrated in Figure \\ref{fig:main}. Although we have made some headway, completely answering the following question is left as an open problem. \n\n\\begin{question} \\label{quest:liq-sol} What are necessary and sufficient conditions on $(n; j ; p,q)$ for\n\\[ H_j [ \\config{n}{p}{q}]  \\neq 0? \\]\n\\end{question}\n\n\\begin{figure}\n\\begin{tikzpicture}[scale = 12]\n\\fill [opacity = 0.1] (0,0)--(1/3,1/3)--(2/3,1/3)--(1,0)--cycle;\n\\draw [blue, line width = 0.3mm](0,0)--(1,0)--(3/4,1/4)--( 3/8 , 1/4 )--( 1/4 , 7/36 )--( 3/16 , 5/32 )--( 3/20 , 13/100 )--( 1/8 , 1/9 )--( 3/28 , 19/196 )--( 3/32 , 11/128 )--( 1/12 , 25/324 )--( 3/40 , 7/100 )--( 3/44 , 31/484 )--\n( 1/16 , 17/288 )--( 3/52 , 37/676 )--( 3/56 , 5/98 )--( 1/20 , 43/900 )--cycle;\n\\draw[densely dashed] plot[domain=0:9/8] (\\x, {\\x-(8/9)*(\\x)^2});\n\\draw [densely dashed] (0,1/4)--(1,1/4);\n\\draw (0,0)--(0.7,0.7);\n\\node at (0.75,0.75) {$y=x$};\n\\draw (1,0)--(0.3,0.7);\n\\node at (0.25,0.75) {$y=1-x$};\n\\draw (0,1/3)--(1,1/3);\n\\node at (1.1,1/3) {$y=1/3$};\n\\node at (1.1,1/4) {$y=1/4$};\n\\node at (1.1,1/7) {$y=x-(8/9)x^2$};\n\\draw [line width =0.5mm,->] (0,0)--(1.25,0);\n\\draw [line width =0.5mm,->] (0,0)--(0,0.75);\n%\\node at (1.2,0) {$x=n/pq$};\n%\\node at (0,0.65) {$y=j/pq$};\n\\fill [blue] ( 0 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/8 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/10 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/18 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/24 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/25 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/36 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/9 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/9 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/8 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/8 , 1/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/25 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/25 , 1/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/18 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/18 , 1/36 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/4 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/4 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 2/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/16 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/16 , 1/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/16 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/25 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/25 , 1/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/25 , 2/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/12 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/12 , 1/36 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/12 , 1/18 ) circle[radius=0.2pt];\n\\fill [blue] ( 1 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/3 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/9 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/9 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/9 , 2/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 1/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 3/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/25 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/25 , 1/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/25 , 2/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 4/25 , 3/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/9 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/9 , 1/36 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/9 , 1/18 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/9 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/6 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/6 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/8 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/8 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/8 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/10 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/5 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/9 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/9 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/9 , 2/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/12 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/12 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/12 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 2/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/5 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/16 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/16 , 1/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/16 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 5/16 , 3/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 1/20 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 1/10 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/4 , 3/20 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 1/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 2/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 3/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 4/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/4 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/4 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/4 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/5 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/5 , 1/10 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/5 , 1/5 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/3 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/3 , 2/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/2 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/5 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/5 , 1/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/5 , 2/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 2/5 , 1/5 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/18 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 1/6 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/3 , 2/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/8 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/8 , 1/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/8 , 1/8 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/8 , 3/16 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/8 , 1/4 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/10 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/10 , 1/20 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/10 , 1/10 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/10 , 3/20 ) circle[radius=0.2pt];\n\\fill [blue] ( 3/10 , 1/5 ) circle[radius=0.2pt];\n\\fill [blue] ( 6/25 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 6/25 , 1/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 6/25 , 2/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 6/25 , 3/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 6/25 , 4/25 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 1/30 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 1/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 1/10 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/5 , 2/15 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 0 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 1/36 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 1/18 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 1/12 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 1/9 ) circle[radius=0.2pt];\n\\fill [blue] ( 1/6 , 5/36 ) circle[radius=0.2pt];\n\n\\fill [blue,opacity = 0.2,line width=0.1mm](0,0)--(1,0)--(3/4,1/4)--( 3/8 , 1/4 )--( 1/4 , 7/36 )--( 3/16 , 5/32 )--( 3/20 , 13/100 )--( 1/8 , 1/9 )--( 3/28 , 19/196 )--( 3/32 , 11/128 )--( 1/12 , 25/324 )--( 3/40 , 7/100 )--( 3/44 , 31/484 )--\n( 1/16 , 17/288 )--( 3/52 , 37/676 )--( 3/56 , 5/98 )--( 1/20 , 43/900 )--cycle;\n\\draw [blue,line width=0.5mm](0,0)--(1,0)--(3/4,1/4)--( 3/8 , 1/4 )--( 1/4 , 7/36 )--( 3/16 , 5/32 )--( 3/20 , 13/100 )--( 1/8 , 1/9 )--( 3/28 , 19/196 )--( 3/32 , 11/128 )--( 1/12 , 25/324 )--( 3/40 , 7/100 )--( 3/44 , 31/484 )--\n( 1/16 , 17/288 )--( 3/52 , 37/676 )--( 3/56 , 5/98 )--( 1/20 , 43/900 )--cycle;\n\n\\end{tikzpicture}\n\\label{fig:summary}\n\n\\caption{A summary of our main results. The axes are $x=n/pq$ and $y=j/pq$. We show that if $(x,y)$ is outside  the shaded region bounded by $y = 1-x$, $y = x$, and $y = 1/3$, then $H_j [ \\config{n}{p}{q} ] = 0$. We show conversely that for every rational point $(x,y)$ in the blue part of the shaded region, there exist $n,j,p,$ and $q$ such that $x=n / pq$, $y = j / pq$, and $H_j [ \\config{n}{p}{q} ] \\neq 0 $. Each of the blue dots represents a point $(x,y)$ where we computed that $H_j [ \\config{n}{p}{q} ] \\neq 0$, with $n \\le 6$.}\n\\label{fig:main}\n\\end{figure}\n \nIn recent years, there has been increased interest in similar kinds of configuration spaces; see \\cite{Alpert17, BBK14, CGKM12} for some earlier work on configuration spaces of disks.\nThe most closely related earlier work to what we study here is the recent preprint \\cite{AKM19} on configuration spaces of hard disks in an infinite strip. Let $\\mathrm{config}(n,w)$ denote the configuration space of $n$ disks of unit diameter in an infinite strip of width $w$. While we do not prove it here, it is not hard to check that $\\config{n}{p}{q}$ is homotopy equivalent to $\\mathrm{config}(n,w)$ if $q \\ge n$ and $p=w$. So the configuration spaces of hard squares in a rectangle we study here are a generalization of the configuration spaces of hard disks in an infinite strip.\n\nMotivated by the notion of phase transitions for hard-spheres systems, definitions are suggested in \\cite{AKM19} for homological solid, liquid, and gas regimes. The definitions apply here as well.\n\nLet $\\mathrm{Conf}(n;\\R^2)$ denote the (ordered) configuration space of points in the plane. We say that $(n; j; p,q)$ is\n\\begin{itemize}\n    \\item in the \\emph{homological solid regime} if\n    \\[H_j [ \\config{n}{p}{q} ]= 0,\\]\n    \n    \\item in the \\emph{homological gas regime} if the inclusion map $i: \\config{n}{p}{q} \\to \\mathrm{Conf}(n; \\R^2)$\n    induces an isomorphism on homology\n    $$i_* : H_j [ \\config{n}{p}{q}] \\to H_j [ \\mathrm{Conf}(n ; \\R^2)], \\mbox{ and }$$\n    \n    \\item in the \\emph{homological liquid regime} otherwise.\n\\end{itemize}\n\nIn the present paper, we are mainly concerned with the boundary between trivial and nontrivial homology, i.e., separating the solid regime from liquid and gas. It will also be interesting to better understand the boundary between the homological liquid and gas regimes, as summarized in the following question.\n\n\\begin{question} \\label{quest:liq-sol} What are necessary and sufficient conditions on $(n; j ; p,q)$ for the inclusion map $i: \\config{n}{p}{q} \\to \\mathrm{Conf}(n; \\R^2)$ to induce an isomorphism on homology\n    \\[i_* : H_j [ \\config{n}{p}{q}] \\to H_j [ \\mathrm{Conf}(n ; \\R^2)] ?\\]\n\\end{question}\n\n\n\\section{Definitions and notation} \\label{sec:defs}\n\nThe configuration space $\\config{n}{p}{q}$ of $n$ unit squares in a $p$ by $q$ rectangle can be written as a subspace of $\\mathbb{R}^{2n}$ by keeping track of the coordinates of the centers of the squares.  We select our $p$ by $q$ rectangle to be the set $\\left[\\frac{1}{2}, p + \\frac{1}{2}\\right] \\times \\left[\\frac{1}{2}, q+\\frac{1}{2}\\right]$ in $\\mathbb{R}^2$.  Accordingly, we define $\\config{n}{p}{q}$ to be the set of all points $(x_1, y_1, \\ldots, x_n, y_n) \\in \\mathbb{R}^{2n}$ such that\n\\begin{itemize}\n\\item $1 \\leq x_k \\leq p$ and $1 \\leq y_k \\leq q$ for all $1 \\leq k \\leq n$, and\n\\item $\\abs{x_k - x_\\ell} \\geq 1$ or $\\abs{y_k - y_\\ell} \\geq 1$ for all $1 \\leq k < \\ell \\leq n$.\n\\end{itemize}\nNote that the boundaries of the unit squares can intersect each other or the edges of the rectangle. \n\nWe will be working with two ways to draw a grid on the rectangle; these two grids can be thought of as dual to each other, or as offset by $\\left(\\frac{1}{2}, \\frac{1}{2}\\right)$.  One grid is the integer coordinate grid.  The set of possible positions of the center of one square is $[1, p] \\times [1, q]$, which we can think of as having vertices at the points where both coordinates are integers, edges between vertices at distance $1$, and $(p-1)(q-1)$ square $2$-cells.  We refer to these integer points as \\emph{\\textbf{coordinate grid vertices}}, to the edges as \\emph{\\textbf{coordinate grid edges}}, and to the squares as \\emph{\\textbf{coordinate grid squares}}.  Together we refer to the coordinate grid vertices, edges, and squares as \\emph{\\textbf{coordinate grid cells}}.\n\nThe other grid is the $p$ by $q$ grid on the rectangle itself.  Thinking of the rectangle as a $p$ by $q$ chessboard, we refer to the unit square centered at each coordinate grid vertex as a \\emph{\\textbf{board square}}.  For each coordinate grid cell, there is a corresponding rectangle of board squares given by taking the union of all unit squares for which the center lies on that coordinate grid cell, as shown in Figure~\\ref{fig-grid-edge}.  The rectangle corresponding to a coordinate grid vertex is a single board square; the rectangle corresponding to a coordinate grid edge is a pair of adjacent board squares; and the rectangle corresponding to a coordinate grid square is a $2$ by $2$ rectangle of board squares.\n\n\\begin{figure}\n\\begin{center}\n\\begin{tikzpicture}[vert/.style={circle, draw=black, fill=black, inner sep = 0pt, minimum size = 1mm}]\n\\draw[draw=gray!40, fill=gray!40] (1.5, 1.5)--(2.5, 1.5)--(2.5, 3.5)--(1.5, 3.5)--(1.5, 1.5);\n\\draw (.5, .5)--(4.5, .5) (.5, 1.5)--(4.5, 1.5) (.5, 2.5)--(4.5, 2.5) (.5, 3.5)--(4.5, 3.5) (.5, .5)--(.5, 3.5) (1.5, .5)--(1.5, 3.5) (2.5, .5)--(2.5, 3.5) (3.5, .5)--(3.5, 3.5) (4.5, .5)--(4.5, 3.5);\n\\draw[dotted] (.5, 1)--(4.5, 1) (.5, 2)--(4.5, 2) (.5, 3)--(4.5, 3) (1, .5)--(1, 3.5) (2, .5)--(2, 3.5) (3, .5)--(3, 3.5) (4, .5)--(4, 3.5);\n\\draw (.5, .5)--(4.5, .5)--(4.5, 3.5)--(.5, 3.5)--(.5, .5);\n\\draw[very thick] (2, 2)--(2, 3);\n\\end{tikzpicture}\n\\end{center}\n\\caption{The coordinate grid vertices, at points with integer coordinates, are the centers of the board squares.  Here a coordinate grid edge is shown with its corresponding rectangular piece.}\\label{fig-grid-edge}\n\\end{figure}\n\nLet $\\ambient{n}{p}{q}$ be the space $([1, p] \\times [1, q])^n$ with its standard cubical complex structure.  Here the letter $G$ stands for \\emph{grid}.  We can think of this space as the set of configurations of labeled squares in the rectangle where the squares are allowed to overlap.  As a cubical complex, each cell of $\\ambient{n}{p}{q}$ corresponds to an $n$-tuple in which each entry is a coordinate grid cell.  We can draw the cell of $\\ambient{n}{p}{q}$ by drawing the $n$ corresponding rectangles of board squares.  We refer to such a picture as a \\emph{\\textbf{rectangle arrangement}}, and we refer to the $n$ rectangles as \\emph{\\textbf{pieces}} in the arrangement.  Any list of $n$ rectangles of board squares of sizes $1$ by $1$, $1$ by $2$, $2$ by $1$, and $2$ by $2$ is the rectangle arrangement of some cell of $\\ambient{n}{p}{q}$.\n\n\\begin{figure}\n\n\\begin{tikzpicture}[scale=0.35]\n\\draw[fill=gray] (0,8)--(5,5)--(8,0)--(3,3)--cycle;\n\\draw[fill=gray] (8,0)--(5,-5)--(0,-8)--(3,-3)--cycle;\n\\draw[fill=gray] (0,-8)--(-5,-5)--(-8,0)--(-3,-3)--cycle;\n\\draw[fill=gray] (-8,0)--(-5,5)--(0,8)--(-3,3)--cycle;\n\n\\draw (-0.5,8)--(-0.5,9)--(0.5,9)--(0.5,8)--cycle;\n\\draw (8,-0.5)--(9,-0.5)--(9,0.5)--(8,0.5)--cycle;\n\\draw (-0.5,-8)--(-0.5,-9)--(0.5,-9)--(0.5,-8)--cycle;\n\\draw (-8,-0.5)--(-9,-0.5)--(-9,0.5)--(-8,0.5)--cycle;\n\\draw (5,5)--(6,5)--(6,6)--(5,6)--cycle;\n\\draw (2,2)--(3,2)--(3,3)--(2,3)--cycle;\n\\draw (5,-5)--(6,-5)--(6,-6)--(5,-6)--cycle;\n\\draw (2,-2)--(3,-2)--(3,-3)--(2,-3)--cycle;\n\\draw (-5,-5)--(-6,-5)--(-6,-6)--(-5,-6)--cycle;\n\\draw (-2,-2)--(-3,-2)--(-3,-3)--(-2,-3)--cycle;\n\\draw (-5,5)--(-6,5)--(-6,6)--(-5,6)--cycle;\n\\draw (-2,2)--(-3,2)--(-3,3)--(-2,3)--cycle;\n\n\\draw[fill=darkgray](-0.5,8.5)--(-0.5,9)--(0,9)--(0,8.5)--cycle;\n\\draw[fill=lightgray] (0,8)--(0,8.5)--(0.5,8.5)--(0.5,8)--cycle;\n\\draw[fill=darkgray](8.5,0)--(9,0)--(9,0.5)--(8.5,0.5)--cycle;\n\\draw[fill=lightgray](8,-0.5)--(8.5,-0.5)--(8.5,0)--(8,0)--cycle;\n\\draw[fill=darkgray] (0,-8.5)--(0,-9)--(0.5,-9)--(0.5,-8.5)--cycle;\n\\draw[fill=lightgray] (-0.5,-8)--(-0.5,-8.5)--(0,-8.5)--(0,-8)--cycle;\n\\draw[fill=darkgray]  (-8.5,-0.5)--(-9,-0.5)--(-9,0)--(-8.5,0)--cycle;\n\\draw[fill=lightgray]  (-8,0)--(-8.5,0)--(-8.5,0.5)--(-8,0.5)--cycle;\n\\draw[fill=darkgray] (5,5.5)--(5.5,5.5)--(5.5,6)--(5,6)--cycle;\n\\draw[fill=lightgray] (5,5)--(5.5,5)--(5.5,5.5)--(5,5.5)--cycle;\n\\draw[fill=darkgray] (2.5,2.5)--(3,2.5)--(3,3)--(2.5,3)--cycle;\n\\draw[fill=lightgray] (2.5,2)--(3,2)--(3,2.5)--(2.5,2.5)--cycle;\n\\draw[fill=darkgray] (5.5,-5)--(6,-5)--(6,-5.5)--(5.5,-5.5)--cycle;\n\\draw[fill=lightgray] (5,-5)--(5.5,-5)--(5.5,-5.5)--(5,-5.5)--cycle;\n\\draw[fill=darkgray] (2.5,-2.5)--(3,-2.5)--(3,-3)--(2.5,-3)--cycle;\n\\draw[fill=lightgray] (2,-2.5)--(2.5,-2.5)--(2.5,-3)--(2,-3)--cycle;\n\\draw[fill=darkgray] (-5,-5.5)--(-5.5,-5.5)--(-5.5,-6)--(-5,-6)--cycle;\n\\draw[fill=lightgray] (-5,-5)--(-5.5,-5)--(-5.5,-5.5)--(-5,-5.5)--cycle;\n\\draw[fill=darkgray] (-2.5,-2.5)--(-3,-2.5)--(-3,-3)--(-2.5,-3)--cycle;\n\\draw [fill=lightgray] (-2.5,-2)--(-3,-2)--(-3,-2.5)--(-2.5,-2.5)--cycle;\n\\draw[fill=darkgray] (-5.5,5)--(-6,5)--(-6,5.5)--(-5.5,5.5)--cycle;\n\\draw [fill=lightgray] (-5,5)--(-5.5,5)--(-5.5,5.5)--(-5,5.5)--cycle;\n\\draw[fill=darkgray] (-2.5,2.5)--(-3,2.5)--(-3,3)--(-2.5,3)--cycle;\n\\draw [fill=lightgray] (-2,2.5)--(-2.5,2.5)--(-2.5,3)--(-2,3)--cycle;\n\n\\end{tikzpicture}\n\\caption{An illustration of the cell complex $\\cell{2}{2}{2}$. The vertices of the complex are labeled by their corresponding configurations with integer coordinates. Note that in this simple case, the cell complex $\\cell{2}{2}{2}$ equals the configuration space $\\config{2}{2}{2}$, while in general the cell complex $\\cell{n}{p}{q}$ is only a subspace of the configuration space $\\config{n}{p}{q}$.}\n\\end{figure}\n \nWe define $\\cell{n}{p}{q}$ to be the subcomplex of $\\ambient{n}{p}{q}$ consisting of all cells of $\\ambient{n}{p}{q}$ that are fully contained in $\\config{n}{p}{q}$.  Here the letter $X$ stands for \\emph{complex}, because $\\cell{n}{p}{q}$ is the main cell complex that we work with throughout the paper.  It is quick to check that $\\cell{n}{p}{q}$ is equal to the set of cells in which the corresponding rectangle arrangement has none of its pieces overlapping.  Given a configuration in $\\config{n}{p}{q}$, we can check whether it is in $\\cell{n}{p}{q}$ by looking at each unit square in the configuration and drawing the rectangle of board squares that it intersects, as shown in Figure~\\ref{fig-rectangles}.  If these rectangles are disjoint, then the configuration is in $\\cell{n}{p}{q}$, and it is in the cell corresponding to the rectangular arrangement that we have just drawn.\n\n\\begin{figure}\n\\begin{center}\n\\begin{tikzpicture}\n\\draw (.5, .5)--(4.5, .5) (.5, 1.5)--(4.5, 1.5) (.5, 2.5)--(4.5, 2.5) (.5, 3.5)--(4.5, 3.5) (.5, .5)--(.5, 3.5) (1.5, .5)--(1.5, 3.5) (2.5, .5)--(2.5, 3.5) (3.5, .5)--(3.5, 3.5) (4.5, .5)--(4.5, 3.5);\n\\draw[thick, fill=gray!40] (1.5, 1.7)--(2.5, 1.7)--(2.5, 2.7)--(1.5, 2.7)--cycle (3.1, 1.2)--(4.1, 1.2)--(4.1, 2.2)--(3.1, 2.2)--cycle;\n\\end{tikzpicture}\n\\begin{tikzpicture}\n\\draw (.5, .5)--(4.5, .5) (.5, 1.5)--(4.5, 1.5) (.5, 2.5)--(4.5, 2.5) (.5, 3.5)--(4.5, 3.5) (.5, .5)--(.5, 3.5) (1.5, .5)--(1.5, 3.5) (2.5, .5)--(2.5, 3.5) (3.5, .5)--(3.5, 3.5) (4.5, .5)--(4.5, 3.5);\n\\draw[draw=gray!40, fill=gray!40] (1.6, 1.6)--(2.4, 1.6)--(2.4, 3.4)--(1.6, 3.4)--cycle (2.6, .6)--(4.4, .6)--(4.4, 2.4)--(2.6, 2.4)--cycle;\n\\end{tikzpicture}\n\\end{center}\n\\caption{Any configuration where no two squares touch the same board square is in the cell of $\\cell{n}{p}{q}$ corresponding to the rectangle arrangement that shows which board squares each square touches.}\\label{fig-rectangles}\n\\end{figure}\n\n\\section{Homotopy equivalence of the configuration space and complex} \\label{sec:homotopy}\nThe ambient cubical complex $\\ambient{n}{p}{q}$ has three kinds of cells: some cells are fully contained in $\\config{n}{p}{q}$, and together form $\\cell{n}{p}{q}$; some cells are partially in $\\config{n}{p}{q}$; and some cells are disjoint from $\\config{n}{p}{q}$.  We will define a deformation retraction from $\\config{n}{p}{q}$ to $\\cell{n}{p}{q}$ by considering the cells of $\\ambient{n}{p}{q}$ that are partially in $\\config{n}{p}{q}$ one at a time.  To do this, we define local coordinates on each of these cells and give a criterion in those local coordinates for which points are in $\\config{n}{p}{q}$ and which points are not.\n\nWe define a function $\\snap \\co \\mathbb{R} \\rightarrow \\mathbb{R}$ by $\\snap(x) = \\frac{1}{2}(\\lfloor x \\rfloor + \\lceil x \\rceil)$.  In other words, we have $\\snap(k) = k$ for all $k \\in \\mathbb{Z}$, and if $x \\in (k, k+1)$, then $\\snap(x) = k + \\frac{1}{2}$.  We can also define $\\snap \\co \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ for any dimension $d$, by applying snap to each coordinate separately.\n\nIf $z = (x_1, y_1, \\ldots, x_n, y_n) \\in \\mathbb{R}^{2n}$ is a point in the complex $\\ambient{n}{p}{q}$, then $\\snap(z)$ is the barycenter of the unique cubical cell of $\\ambient{n}{p}{q}$ whose interior contains $z$.  Geometrically, if $(x_i, y_i)$ is the center of a unit square, then $\\snap(x_i, y_i)$ is the center of the corresponding rectangle of the board squares that it touches.\nNote that $\\snap$ is idempotent, $\\snap(\\snap(z)) = \\snap(z)$, and $z$ is a barycenter of some grid cell in $\\ambient{n}{p}{q}$ if and only if $z = \\snap(z)$.\n\n\n\\subsection{Containment of cells in the configuration space}\n\nWe can check whether a given cell of $\\ambient{n}{p}{q}$ has empty intersection with $\\config{n}{p}{q}$ by looking at pairs of pieces, case by case, in its corresponding rectangle arrangement.  Figure~\\ref{fig-noconfigs} shows which pairs of pieces prevent a cell from having any configurations in $\\config{n}{p}{q}$; in each case, the barycenter of the corresponding cell is not a configuration in $\\config{n}{p}{q}$.  For each pair of pieces, there is no way to fit a unit square in the interior of each piece, while keeping the two unit squares disjoint.  (Two unit squares can fit if they touch the boundaries of the rectangles, but the resulting configuration is in the boundary of the specified open cell, not inside it.)  \n\nFigure~\\ref{fig-allowed-overlap} shows the four remaining ways for two pieces in a rectangle arrangement to overlap; for these, the corresponding cell is partially in in $\\config{n}{p}{q}$, and \nthe barycenter is a configuration in $\\config{n}{p}{q}$.  \n%We say that $\\sigma$ is \\emph{\\textbf{partially in $\\config{n}{p}{q}$}} if $\\sigma$ has a nonempty intersection but is not fully contained in $\\config{n}{p}{q}$.\nThe following lemma summarizes how to check whether a given cell of $\\ambient{n}{p}{q}$ is partially in $\\config{n}{p}{q}$.\n\n\n\n\n\n\\begin{figure}\n\\begin{center}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(2.5, 0) (-.5, 1)--(2.5, 1) (0, -.5)--(0, 1.5) (1, -.5)--(1, 1.5) (2, -.5)--(2, 1.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, .9)--(.1, .9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (.1, .1)--(.9, .1)--(.9, .9)--(.1, .9)--cycle;\n\\draw[fill=black] \n(.5, .5) circle (.03)\n(1, .5) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(2.5, 0) (-.5, 1)--(2.5, 1) (-.5, 2)--(2.5, 2) (0, -.5)--(0, 2.5) (1, -.5)--(1, 2.5) (2, -.5)--(2, 2.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, 1.9)--(.1, 1.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (.1, .1)--(.9, .1)--(.9, .9)--(.1, .9)--cycle;\n\\draw[fill=black] \n(.5, .5) circle (.03)\n(1, 1) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(2.5, 0) (-.5, 1)--(2.5, 1) (-.5, 2)--(2.5, 2) (0, -.5)--(0, 2.5) (1, -.5)--(1, 2.5) (2, -.5)--(2, 2.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, 1.9)--(.1, 1.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (.1, .1)--(1.9, .1)--(1.9, .9)--(.1, .9)--cycle;\n\\draw[fill=black]\n(1, .5) circle (.03)\n(1, 1) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(2.5, 0) (-.5, 1)--(2.5, 1) (-.5, 2)--(2.5, 2) (0, -.5)--(0, 2.5) (1, -.5)--(1, 2.5) (2, -.5)--(2, 2.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(.1, 1.9)--cycle (1.1, .1)--(1.9, .1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[fill=black]\n(1.5, 1) circle (.03)\n(1, 1.5) circle (.03);\n\\end{tikzpicture}\n\\end{center}\n\\caption{If the unit squares at the centers of the rectangular pieces overlap, then the corresponding cell in $\\ambient{n}{p}{q}$ does not contain any configurations in $\\config{n}{p}{q}$.  The darker gray indicates where the two pieces overlap, and the black dots give the centers of the pieces.}\\label{fig-noconfigs}\n\\end{figure}\n\n\n\n\\begin{figure}\n\\begin{center}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(3.5, 0) (-.5, 1)--(3.5, 1) (0, -.5)--(0, 1.5) (1, -.5)--(1, 1.5) (2, -.5)--(2, 1.5) (3, -.5)--(3, 1.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, .9)--(.1, .9)--cycle (1.1, .1)--(2.9, .1)--(2.9, .9)--(1.1, .9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (1.1, .1)--(1.9, .1)--(1.9, .9)--(1.1, .9)--cycle;\n\\draw[fill=black]\n(1, .5) circle (.03)\n(2, .5) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(3.5, 0) (-.5, 1)--(3.5, 1) (-.5, 2)--(3.5, 2) (0, -.5)--(0, 2.5) (1, -.5)--(1, 2.5) (2, -.5)--(2, 2.5) (3, -.5)--(3, 2.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, .9)--(.1, .9)--cycle (1.1, .1)--(2.9, .1)--(2.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (1.1, .1)--(1.9, .1)--(1.9, .9)--(1.1, .9)--cycle;\n\\draw[fill=black]\n(1, .5) circle (.03)\n(2, 1) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(3.5, 0) (-.5, 1)--(3.5, 1) (-.5, 2)--(3.5, 2) (0, -.5)--(0, 2.5) (1, -.5)--(1, 2.5) (2, -.5)--(2, 2.5) (3, -.5)--(3, 2.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, 1.9)--(.1, 1.9)--cycle (1.1, .1)--(2.9, .1)--(2.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (1.1, .1)--(1.9, .1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[fill=black]\n(1, 1) circle (.03)\n(2, 1) circle (.03);\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (-.5, 0)--(3.5, 0) (-.5, 1)--(3.5, 1) (-.5, 2)--(3.5, 2) (-.5, 3)--(3.5, 3) (0, -.5)--(0, 3.5) (1, -.5)--(1, 3.5) (2, -.5)--(2, 3.5) (3, -.5)--(3, 3.5);\n\\draw[draw=gray!40,fill=gray!40] (.1, .1)--(1.9, .1)--(1.9, 1.9)--(.1, 1.9)--cycle (1.1, 1.1)--(2.9, 1.1)--(2.9, 2.9)--(1.1, 2.9)--cycle;\n\\draw[draw=gray!80,fill=gray!80] (1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[fill=black]\n(1, 1) circle (.03)\n(2, 2) circle (.03);\n\\end{tikzpicture}\n\\end{center}\n\\caption{If a given cell of $\\ambient{n}{p}{q}$ is partially contained in $\\config{n}{p}{q}$, then some pair of overlapping pieces in the rectangle arrangement must overlap in one of the four ways shown.  The darker gray indicates where the two pieces overlap, and the black dots give the centers of the pieces.}\\label{fig-allowed-overlap}\n\\end{figure}\n\n\\begin{lemma}\\label{lem-partial-cell}\nLet $z = \\snap(z) = (x_1, y_1, \\ldots, x_n, y_n) \\in \\ambient{n}{p}{q}$ be the barycenter of an open cell $\\sigma$ of $\\ambient{n}{p}{q}$.  Then\n\\begin{enumerate}\n\\item $\\sigma$ has a nonempty intersection with $\\config{n}{p}{q}$\nif and only if its barycenter~$z$ lies in the configuration space $\\config{n}{p}{q}$, or equivalently, the $\\ell^\\infty$ distance between $(x_\\ell,y_\\ell)$ and $(x_k,y_k)$ is at least $1$ for all $1 \\leq k < \\ell \\leq n$:\n\\[\\max(\\abs{x_\\ell - x_k}, \\abs{y_\\ell - y_k}) \\geq 1.\\]\n%\\item $\\sigma$ is partially contained in $\\config{n}{p}{q}$ if and only if the condition above holds and, in addition, there is some pair $k, \\ell$ for which the corresponding rectangles overlap: \n%\\[\\lfloor \\max(x_k, x_\\ell) \\rfloor \\leq \\lceil \\min(x_k, x_\\ell) \\rceil \\quad \\text{and} \\quad \\lfloor \\max(y_k, y_\\ell) \\rfloor \\leq \\lceil \\min(y_k, y_\\ell) \\rceil.\\]\n\\item $\\sigma$ is fully contained in $\\config{n}{p}{q}$, and hence a cell of $\\cell{n}{p}{q}$, if and only if for all $1 \\leq k < \\ell \\leq n$,\nthe corresponding pieces do not overlap, or equivalently,\n\\[\\lfloor \\max(x_k, x_\\ell) \\rfloor > \\lceil \\min(x_k, x_\\ell) \\rceil \n\\quad\n\\text{or}\n\\quad\n\\lfloor \\max(y_k, y_\\ell) \\rfloor > \\lceil \\min(y_k, y_\\ell) \\rceil.\\]\n \n\\end{enumerate}\n\\end{lemma}\n\n\\begin{proof}\n%\n%\n%It turns out that a given cell of $\\ambient{n}{p}{q}$ intersects $\\config{n}{p}{q}$ if and only if its barycenter is in $\\config{n}{p}{q}$.  \n%\nTo check the first claim, we observe that if any point $z \\in \\sigma$ is in $\\config{n}{p}{q}$, then $\\snap(z) \\in \\config{n}{p}{q}$ as well.  This is because for any $x_1, x_2 \\in \\mathbb{R}$, if $x_2 - x_1 \\geq 1$, then $\\snap(x_2) - \\snap(x_1) \\geq 1$ as well.  \n\nFor the second statement, note that piece $k$ covers the board squares with centers in $[\\lfloor x_k \\rfloor, \\lceil x_k \\rceil] \\times [\\lfloor y_k \\rfloor, \\lceil y_k \\rceil]$, and piece $\\ell$ covers the board squares with centers in $[\\lfloor x_\\ell \\rfloor, \\lceil x_\\ell \\rceil] \\times [\\lfloor y_\\ell \\rfloor, \\lceil y_\\ell \\rceil]$.  The two pieces overlap if and only if the intervals $[\\lfloor x_k \\rfloor, \\lceil x_k \\rceil]$ and $[\\lfloor x_\\ell \\rfloor, \\lceil x_\\ell \\rceil]$ overlap and the intervals $[\\lfloor y_k \\rfloor, \\lceil y_k \\rceil]$ and $[\\lfloor y_\\ell \\rfloor, \\lceil y_\\ell \\rceil]$ also overlap.\n\\end{proof}\n\nWe say that a subcomplex of a regular CW complex is a \\emph{full subcomplex} if it is maximal with respect to its vertex set.\n\n\\begin{corollary}\\label{cor-full-subcomplex}\n$\\cell{n}{p}{q}$ is a full subcomplex of the ambient cubical complex $\\ambient{n}{p}{q}$.\n\\end{corollary}\n%\n% [Uli] The following corollary is not used in the sequel, and hence just left as a comment here. If included, it should probably come with a short proof.\n%\\begin{corollary}\\label{cor-bary-subcomplex}\n%$\\config{n}{p}{q}$ is the underlying space of a simplicial subcomplex of the barycentric subdivision of the ambient cubical complex $\\ambient{n}{p}{q}$.\n%\\end{corollary}\n%\nAn equivalent description for when an open cell $\\sigma$ is partially in $\\config{n}{p}{q}$ can be obtained from examining the cases in Figure~\\ref{fig-allowed-overlap}:\nLet $b = (i_1, j_1, \\ldots, i_n, j_n) \\in \\ambient{n}{p}{q}$ be the barycenter of $\\sigma$; note that the coordinates $i_k, j_k$ are half-integers.\nThen $\\sigma$ is partially in $\\config{n}{p}{q}$ if and only if\n\\begin{enumerate}\n\\item for all $k$ and $\\ell$, we have\n$\\max(\\abs{i_\\ell - i_k}, \\abs{j_\\ell- j_k}) \\geq 1,$ and\n\\item \nthere is a pair $k, \\ell$ such that either \n\\begin{enumerate}\n\\item\n$\\abs{i_\\ell - i_k} = 1$ and $\\abs{j_\\ell - j_k} < 1$ and $i_k, i_\\ell$ are not integers, or \n\\item \n$\\abs{j_\\ell - j_k} = 1$ and $\\abs{i_\\ell - i_k} < 1$ and $j_k, j_\\ell$ are not integers, or \n\\item\n$\\abs{i_\\ell - i_k} = \\abs{j_\\ell - j_k} = 1$ and none of $i_k, i_\\ell, j_k, j_\\ell$ are integers.\n\\end{enumerate}\n\\end{enumerate}\n\n\\subsection{Membership in the configuration space using local coordinates}\n\nThe next lemma specifies how to use local coordinates to check, for an open cell partially in $\\config{n}{p}{q}$, whether a given point in the cell is in $\\config{n}{p}{q}$.  Given an open cell $\\sigma$ of $\\ambient{n}{p}{q}$, we can specify the points $z \\in \\sigma$ in terms of the local coordinates $z - \\snap(z) \\in (-\\frac{1}{2}, \\frac{1}{2} )^{2n}$.  Not every point in $(-\\frac{1}{2}, \\frac{1}{2})^{2n}$ corresponds to a point in the cell, because for each coordinate of the barycenter $\\snap(z)$ that is an integer, the corresponding coordinate in $z - \\snap(z)$ is zero.\n\nLet $b$ be the barycenter of cell $\\sigma$, and let $I(\\sigma)$ be the set of indices of non-integer coordinates of $b$.  The number of elements of $I(\\sigma)$ is the dimension of $\\sigma$.  Let $(-\\frac{1}{2}, \\frac{1}{2})^{I(\\sigma)}$ denote the coordinate subspace of $(-\\frac{1}{2}, \\frac{1}{2})^{2n}$ given by letting the $I(\\sigma)$ coordinates vary and requiring the remaining coordinates (corresponding to the integer coordinates in $b$) to be zero.  We have $z \\in \\sigma$ if and only if $z-b \\in (-\\frac{1}{2}, \\frac{1}{2})^{I(\\sigma)}$, in which case $b = \\snap(z)$.  \n\nA point of $\\ambient{n}{p}{q}$ is in $\\config{n}{p}{q}$ if and only if no two of the $n$ specified squares intersect.  Thus, we check the local coordinates for two of the $n$ squares at a time to see whether those two squares overlap.\n\n\\begin{lemma}\\label{lem-partial-point}\nLet $\\sigma$ be an open cell of $\\ambient{2}{p}{q}$ that is partially in $\\config{2}{p}{q}$, and let $z = (x_1, y_1, x_2, y_2)$ be a point in the interior of $\\sigma$. \n% (The barycenter of $\\sigma$ is $\\snap(z)$.)\nThen $(x_1, y_1, x_2, y_2) \\in \\config{2}{p}{q}$ if and only if one of the following conditions holds: \n\\begin{itemize}\n\\item $\\abs{\\snap(x_2) - \\snap(x_1)} = 1$ and\n$(x_2 - \\snap(x_2)) - (x_1 - \\snap(x_1))$ is zero or\nhas the same sign as $\\snap(x_2) - \\snap(x_1)$, or\n\\item $\\abs{\\snap(y_2) - \\snap(y_1)} = 1$ and\n$(y_2 - \\snap(y_2)) - (y_1 - \\snap(y_1))$ is zero or\nhas the same sign as $\\snap(y_2) - \\snap(y_1)$.\n\\end{itemize}\n\\end{lemma}\n\nIn the fourth case in Figure~\\ref{fig-allowed-overlap}, where the two pieces are $2$ by $2$ rectangles intersecting at one board square, either condition in the lemma may hold, so the intersection of $\\config{n}{p}{q}$ with the cell of $\\ambient{2}{p}{q}$ is the union of solutions to two linear inequalities.  In the other three cases, the centers of the two pieces have only one coordinate that differs by $1$, so the intersection of $\\config{n}{p}{q}$ with the cell is the set of solutions to one linear inequality.\n\n\\begin{proof}\nA point $(x_1, y_1, x_2, y_2)$ is in $\\config{2}{p}{q}$ if and only if either $\\abs{x_2 - x_1} \\geq 1$ or $\\abs{y_2 - y_1} \\geq 1$.\nNote that the function $\\snap$ is weakly order-preserving, meaning that \n%$x_1 \\leq x_2$ implies $\\snap(x_1) \\leq \\snap(x_2)$, or equivalently, \n$x_2 - x_1 \\geq 0$ implies $\\snap(x_2) - \\snap(x_1) \\geq 0$. \nThus, by symmetry of $x_1$ and $x_2$ as well as $(x_1,x_2)$ and $(y_1,y_2)$, it suffices to show that $x_2 - x_1 \\geq 1$ if and only if both $\\snap(x_2) - \\snap(x_1) = 1$ and $(x_2 - \\snap(x_2)) - (x_1 - \\snap(x_1)) \\geq 0$.\nThe latter condition straightforwardly implies the former.\n\nConversely, assume  $x_2 - x_1 \\geq 1$.\nThen clearly $\\snap(x_2) - \\snap(x_1) \\geq 1$.\nMoreover, the assumption that $\\sigma$ is only partially in $\\config{2}{p}{q}$ rules out the case $\\snap(x_2) - \\snap(x_1) > 1$,\nas in this case we would necessarily have $\\lfloor \\snap(x_2) \\rfloor > \\lceil \\snap(x_1) \\rceil$, and \\Cref{lem-partial-cell} would imply that $\\sigma$ is fully contained in $\\config{2}{p}{q}$. \nThus we get $\\snap(x_2) - \\snap(x_1) = 1$ and $(x_2 - \\snap(x_2)) - (x_1 - \\snap(x_1)) \\geq 0$ as desired.\n\\end{proof}\n\n\n\\subsection{Construction of the deformation retraction}\n\n\nThe next lemma gives the main step in constructing the deformation retraction from $\\config{n}{p}{q}$ to $\\cell{n}{p}{q}$.\n\n\\begin{lemma}\n\\label{lem:defRetractCell}\nLet $\\sigma$ be an open cell of $\\ambient{n}{p}{q}$ that is partially in $\\config{n}{p}{q}$.  Then we have that~$\\del\\sigma \\cap \\config{n}{p}{q}$ is a deformation retract of~$\\overline{\\sigma} \\cap \\config{n}{p}{q}$.\n\\end{lemma}\n\n\n\n\\begin{proof}\nLet $z = (x_1, y_1, \\ldots, x_n, y_n)$ be a point in the open cell $\\sigma$.\nIf we want to check whether $z$ is in $\\config{n}{p}{q}$, then Lemma~\\ref{lem-partial-point} gives a set of inequalities on the local coordinates $z - \\snap(z) = (u_1, v_1, \\ldots, u_n, v_n)$ within the open cell $\\sigma$ that we can evaluate.  For each pair of pieces $k, \\ell$ in the rectangle arrangement for $\\sigma$, the lemma specifies zero, one, or two inequalities of the following form:\n\\begin{itemize}\n\\item $u_k \\geq u_\\ell$ or $u_k \\leq u_\\ell$;\n\\item $v_k \\geq v_\\ell$ or $v_k \\leq v_\\ell$.\n\\end{itemize}\nThe case of zero inequalities comes from the case where the two rectangular pieces do not intersect.  The case of one inequality comes from the case where they intersect in one of the first three ways shown in Figure~\\ref{fig-allowed-overlap}.  And, the case of two inequalities comes from the fourth case in Figure~\\ref{fig-allowed-overlap}, where the pieces are both $2$ by $2$ squares and they have one board square in common; in this case, the local coordinate $z - \\snap(z)$ needs to satisfy either or both of the two inequalities.  Together, we refer to the inequalities from the lemma as the inequalities associated to $\\sigma$.\nNote that the above inequalities are stated for local coordinates, but at the same time,\nthe coordinates of the barycenter\n\\[\nb=(i_1,j_1,\\dots,i_n,j_n)\n\\]\nsatisfy the same set of inequalities, even strictly.\nThis property will be crucial for our argument.\n\nWe define the deformation retraction  \nas follows.\nLet $\\lambda$ be large enough that $\\frac{1}{\\lambda} b$ is in $\\left(-\\frac12,\\frac12\\right)^{2n}$; we can take $\\lambda = 2(p+q)$.  Let $m$ be the coordinate projection of $\\frac{1}{\\lambda}b$ onto $\\left(-\\frac{1}{2}, \\frac{1}{2}\\right)^{I(\\sigma)}$; that is, for each integer coordinate of $b$, we set the corresponding coordinate of $m$ to be zero.  \nSince $m$ is a positively scaled version of $b$, it inherits the magical quality of satisfying all of the inequalities associated to $\\sigma$, and since $b$ satisfies all those inequalities strictly, $-m$ has the magical quality of violating all of the inequalities associated to $\\sigma$.  (Note that every coordinate appearing in the inequalities associated to $\\sigma$ is in $I(\\sigma)$.)  Thus the point $b+m$ in $\\sigma$ is in the configuration space $\\config{n}{p}{q}$, while the point $b-m$ is not.\n\nThe deformation retraction now pushes every point $z \\in \\sigma$ outward along a ray from $b-m$ until it hits $\\del \\sigma$.  In other words, the vector from $b-m$ to $z$ is given by $z - b + m$, so as time~$t$ increases from~$0$, we set\n\\[z_t = z + t(z-b+m),\\]\nuntil we reach the maximum~$t$ for which~$z + t(z-b+m)$ is in~$\\overline{\\sigma}$, and then the point no longer moves.  Formally, we can define $T_z$ to be the positive value such that $z + T_z(z-b+m) \\in \\del\\sigma$.  (Because $\\sigma$ is a cube and hence star-shaped around any interior point, for any point in $\\sigma$ and any nonzero vector within $\\sigma$ starting at that point,  there is a unique non-negative multiple of that vector that reaches $\\del\\sigma$.)  If $d$ is the distance within $\\sigma$ from $b-m$ to $\\config{n}{p}{q}$, then the vector $z-b+m$ from $b-m$ to $z$ has length at least $d$, and any vector from $z$ to $\\del \\sigma$ has length at most $\\mathrm{diam}(\\sigma)$, so $T_z \\leq \\frac{1}{d} \\mathrm{diam}(\\sigma) \\leq \\frac{2n}{d}$.\n\nUsing this notation, the deformation retraction is defined as\n\\begin{align*}\nF \\co \\overline{\\sigma} \\cap \\config{n}{p}{q} \\times \\left[0,\\frac{2n}{d}\\right] &\\to \\overline{\\sigma} \\cap \\config{n}{p}{q}, \\\\ \n(z,t) &\\mapsto z + \\min(t,T_z)(z-b+m).\n\\end{align*}\n\nWe still need to check that if $z \\in \\config{n}{p}{q}$, then $z_t \\in \\config{n}{p}{q}$ for all $t$, in order to ensure that the homotopy remains in $\\overline{\\sigma} \\cap \\config{n}{p}{q}$.  This is equivalent to checking that $z_t - b = t(z-b+m)$ satisfies a sufficient collection of the inequalities associated to $\\sigma$.  We claim that $z_t - b$ satisfies every one of the inequalities that $z-b$ satisfies; since this collection of inequalities is sufficient for $z$ to be in $\\config{n}{p}{q}$, it is also sufficient for $z_t$ to be in $\\config{n}{p}{q}$.  Indeed, the inequalities are linear with no constant term, so given two points satisfying the inequalities, any linear combination of them with positive coefficients also satisfies the inequalities.  Because $z-b$ satisfies a sufficient set of inequalities and $m$ satisfies all of the inequalities associated to $\\sigma$, this implies that $t(z-b) + tm$ also satisfies the same set of inequalities as $z-b$.  Thus, $z_t$ is in $\\config{n}{p}{q}$ for every $t \\leq T_z$, and the map $F$ that we have defined is indeed a deformation retraction from~$\\overline{\\sigma} \\cap \\config{n}{p}{q}$ to~$\\del\\sigma \\cap \\config{n}{p}{q}$.\n\\end{proof}\n\nPutting all the cells together, we obtain a deformation retraction from $\\config{n}{p}{q}$ to $\\cell{n}{p}{q}$.\n\n\\begin{theorem}\n\\label{thm:defRetract}\nThe subcomplex~$\\cell{n}{p}{q}$ is a deformation retract of the configuration space~$\\config{n}{p}{q}$.\n\\end{theorem}\n\n\\begin{proof}\nOrder the cells~$\\sigma$ of~$\\ambient{n}{p}{q}$ that are partially in $\\config{n}{p}{q}$, such that their dimensions are nonincreasing.  Then, cell by cell in order, we use \\Cref{lem:defRetractCell} to obtain a deformation retraction from~$\\overline{\\sigma} \\cap \\config{n}{p}{q}$ to~$\\del\\sigma \\cap \\config{n}{p}{q}$.  Concatenating these deformation retractions gives a deformation retraction from~$\\config{n}{p}{q}$ to the set~$\\cell{n}{p}{q}$ of cells completely contained in $\\config{n}{p}{q}$.\n\\end{proof}\n\n\n\\section{Discrete Morse theory} \\label{sec:dMt}\n\nIn this section, we describe a discrete gradient vector field on $\\cell{n}{p}{q}$, in the sense of Forman's discrete Morse theory \\cite{Forman1998Morse}, and characterize its critical cells.  The analysis of which cells are critical is based on what we call the \\textbf{\\textit{apex}} of a cell.  The apex of a cell, as shown in Figure~\\ref{apexfig}, is the $0$-dimensional face that is obtained by replacing each piece by its upper-right corner square -- in particular, the apex of any $0$--dimensional cell is that $0$-cell itself.  We use discrete Morse theory to collapse our cell complex so that among the cells remaining, at most one cell has any given apex.\n\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[scale=.7]\n\\draw (0, 0)--(5, 0) (0, 1)--(5, 1) (0, 2)--(5, 2) (0, 3)--(5, 3) (0, 4)--(5, 4) (0, 5)--(5, 5) (0, 0)--(0, 5) (1, 0)--(1, 5) (2, 0)--(2, 5) (3, 0)--(3, 5) (4, 0)--(4, 5) (5, 0)--(5, 5);\n\\draw[draw=gray!40,fill=gray!40] \n(.1, .1)--(.9, .1)--(.9, 1.9)--(.1, 1.9)--cycle\n(1.1, .1)--(1.9, .1)--(1.9, 1.9)--(1.1, 1.9)--cycle\n(3.1, .1)--(4.9, .1)--(4.9, .9)--(3.1, .9)--cycle\n(2.1, 1.1)--(3.9, 1.1)--(3.9, 1.9)--(2.1, 1.9)--cycle\n(2.1, 2.1)--(2.9, 2.1)--(2.9, 2.9)--(2.1, 2.9)--cycle\n(2.1, 3.1)--(3.9, 3.1)--(3.9, 4.9)--(2.1, 4.9)--cycle;\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw[->] (2, 2.5)--(3, 2.5);\n\\node at (1.5, 0) {};\n\\node at (3.5, 0) {};\n\\end{tikzpicture}\n\\begin{tikzpicture}[scale=.7]\n\\draw (0, 0)--(5, 0) (0, 1)--(5, 1) (0, 2)--(5, 2) (0, 3)--(5, 3) (0, 4)--(5, 4) (0, 5)--(5, 5) (0, 0)--(0, 5) (1, 0)--(1, 5) (2, 0)--(2, 5) (3, 0)--(3, 5) (4, 0)--(4, 5) (5, 0)--(5, 5);\n\\draw[draw=gray!40,fill=gray!40] \n(.1, 1.1)--(.9, 1.1)--(.9, 1.9)--(.1, 1.9)--cycle\n(1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle\n(4.1, .1)--(4.9, .1)--(4.9, .9)--(4.1, .9)--cycle\n(3.1, 1.1)--(3.9, 1.1)--(3.9, 1.9)--(3.1, 1.9)--cycle\n(2.1, 2.1)--(2.9, 2.1)--(2.9, 2.9)--(2.1, 2.9)--cycle\n(3.1, 4.1)--(3.9, 4.1)--(3.9, 4.9)--(3.1, 4.9)--cycle;\n\\end{tikzpicture}\n\\end{center}\n\\caption{The apex of a rectangle arrangement replaces each piece by its upper-right corner.  The correspondence does not depend on the labels of the pieces, so the labels are not shown.}\\label{apexfig}\n\\end{figure}\n\n\n\\begin{theorem}\\label{mainthm}\nThere is a discrete gradient vector field on the cubical complex $\\cell{n}{p}{q}$ with the following properties.\n\\begin{enumerate}\n\\item Every matched pair consists of two cells with the same apex.\\label{apexprop}\n\\item Among the cells with a given apex, at most one cell is critical (unmatched).\\label{oneprop}\n\\item The matching is $S_n$--equivariant: if cells $e_1$ and $e_2$ are a matched pair, and we apply the same permutation to the labels in the rectangle arrangements of $e_1$ and $e_2$, then the two resulting cells are also a matched pair. \\label{snprop}\n\\end{enumerate}\n\\end{theorem}\n\nThe proof relies on constructing what we call the apex graph, which facilitates the enumeration of all the cells with a given apex.  In Lemmas~\\ref{pathslemma} and~\\ref{bijlemma} we prove the basic properties of the apex graph, and in Lemma~\\ref{matchlemma} we define the matching for Theorem~\\ref{mainthm} in the language of the apex graph.  After that, it is straightforward to finish the proof of Theorem~\\ref{mainthm}.\n\nGiven any rectangle arrangement, we describe the locations of the pieces according to the coordinates of their upper-right corner squares, so that we say that a piece is at $(i, j)$ if its upper-right corner is in column $i$ (from left to right) and row $j$ (from bottom to top) of our $p$ by $q$ rectangle.  (Alternatively, the center of the upper-right board square has coordinates $(i, j)$ in the plane.)  Giving the coordinates of each piece is the same as specifying the apex of our cell.  To distinguish cells with the same apex, we need to specify, for each piece, whether it has height $1$ or $2$ and whether it has width $1$ or $2$.  Not all these possibilities give rise to valid rectangle arrangements, because some pieces may overlap or hang off the board.  For each possible apex, we construct the \\textbf{\\textit{apex graph}} to record these possible conflicts, as shown in Figure~\\ref{apexgraphfig}.\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[scale=.7]\n\\draw (0, 0)--(5, 0) (0, 1)--(5, 1) (0, 2)--(5, 2) (0, 3)--(5, 3) (0, 4)--(5, 4) (0, 5)--(5, 5) (0, 0)--(0, 5) (1, 0)--(1, 5) (2, 0)--(2, 5) (3, 0)--(3, 5) (4, 0)--(4, 5) (5, 0)--(5, 5);\n\\draw[draw=gray!40,fill=gray!40] \n(.1, 1.1)--(.9, 1.1)--(.9, 1.9)--(.1, 1.9)--cycle\n(1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle\n(4.1, .1)--(4.9, .1)--(4.9, .9)--(4.1, .9)--cycle\n(3.1, 1.1)--(3.9, 1.1)--(3.9, 1.9)--(3.1, 1.9)--cycle\n(2.1, 2.1)--(2.9, 2.1)--(2.9, 2.9)--(2.1, 2.9)--cycle\n(3.1, 4.1)--(3.9, 4.1)--(3.9, 4.9)--(3.1, 4.9)--cycle;\n\n\\draw (2, 2.5)--(3, 1.5) (3.5, 1)--(4, .5);\n\\draw[fill=white] \n(.5, 1) circle (.07) \n(1.5, 1) circle (.07)\n(2, 2.5) circle (.07)\n(2.5, 2) circle (.07)\n(3, 1.5 ) circle (.07)\n(3.5, 1) circle (.07)\n(4, .5) circle (.07)\n(3, 4.5) circle (.07)\n(3.5, 4) circle (.07);\n\\end{tikzpicture}\n\\end{center}\n\\caption{To find the apex graph, we place one vertex for each direction that a piece in the apex can extend, and draw edges between directions where the pieces cannot extend simultaneously.}\\label{apexgraphfig}\n\\end{figure}\n\nThe apex graph has at most two vertices per piece.  If our apex has a piece at $(i, j)$, then we let $(i-\\frac{1}{2}, j)$ -- the center of the left edge of the $(i, j)$ board square -- be a vertex of the apex graph if and only if the piece at $(i, j)$ can have width $2$ in some cell with that apex -- that is, if $i>1$ and there is no piece at $(i-1, j)$.  Similarly, we let $(i, j-\\frac{1}{2})$ -- the center of the lower edge of the $(i, j)$ board square -- be a vertex if and only if there is a piece at $(i, j)$, we have $j>1$, and there is no piece at $(i, j-1)$.\n\nThe edges of the apex graph record which of the width $2$ or height $2$ options would conflict with each other.  A piece at $(i, j)$ can have width $2$ or height $2$ but not both when there are no pieces at $(i-1, j)$ and $(i, j-1)$, but there is a piece at $(i-1, j-1)$.  In this case we draw an edge between the vertices $(i-\\frac{1}{2}, j)$ and $(i, j-\\frac{1}{2})$.  The other possible conflict is between pieces at $(i, j)$ and $(i-1, j+1)$.  If there is no piece at $(i-1, j)$, then the $(i, j)$ piece may have width $2$, and the $(i-1, j+1)$ piece may have height $2$, but not both simultaneously.  In this case we draw an edge between $(i-\\frac{1}{2}, j)$ and $(i-1, j+\\frac{1}{2})$.  These two types of edges give all the edges in the apex graph.\n\n\\begin{lemma}\\label{pathslemma}\nEach apex graph is a disjoint union of path graphs.\n\\end{lemma}\n\n\\begin{proof}\nThe two types of edges have the same slope and length when drawn on the coordinate lattice.  Any graph that can be drawn in this way is a disjoint union of paths.  Note that some of the paths may be single vertices.\n\\end{proof}\n\n\\begin{lemma}\\label{bijlemma}\nThe set of cells with a given apex is in bijection with the set of independent sets in its apex graph.\nOne cell is a face of another if and only if the independent set corresponding to the first cell under this bijection is a subset of the independent set corresponding to the second cell.\n\\end{lemma}\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[scale=.7]\n\\draw (0, 0)--(5, 0) (0, 1)--(5, 1) (0, 2)--(5, 2) (0, 3)--(5, 3) (0, 4)--(5, 4) (0, 5)--(5, 5) (0, 0)--(0, 5) (1, 0)--(1, 5) (2, 0)--(2, 5) (3, 0)--(3, 5) (4, 0)--(4, 5) (5, 0)--(5, 5);\n\\draw[draw=gray!40,fill=gray!40] \n(.1, .1)--(.9, .1)--(.9, 1.9)--(.1, 1.9)--cycle\n(1.1, .1)--(1.9, .1)--(1.9, 1.9)--(1.1, 1.9)--cycle\n(3.1, .1)--(4.9, .1)--(4.9, .9)--(3.1, .9)--cycle\n(2.1, 1.1)--(3.9, 1.1)--(3.9, 1.9)--(2.1, 1.9)--cycle\n(2.1, 2.1)--(2.9, 2.1)--(2.9, 2.9)--(2.1, 2.9)--cycle\n(2.1, 3.1)--(3.9, 3.1)--(3.9, 4.9)--(2.1, 4.9)--cycle;\n\n\\draw (2, 2.5)--(3, 1.5) (3.5, 1)--(4, .5);\n\\draw[fill=black] \n(.5, 1) circle (.07) \n(1.5, 1) circle (.07)\n(3, 1.5 ) circle (.07)\n(4, .5) circle (.07)\n(3, 4.5) circle (.07)\n(3.5, 4) circle (.07);\n\n\\draw[fill=white] \n(2, 2.5) circle (.07)\n(2.5, 2) circle (.07)\n(3.5, 1) circle (.07);\n\\end{tikzpicture}\n\\end{center}\n\\caption{Cells with a given apex correspond to independent sets in the apex graph: we select the vertices corresponding to the directions where the apex pieces extend.  Here, the vertices in the independent set are drawn filled, and the other vertices are drawn empty.}\\label{independentfig}\n\\end{figure}\n\n\\begin{proof}\nGiven a cell with a given apex, we find the corresponding subset of vertices in the apex graph by considering each piece in the associated rectangle arrangement, say at $(i, j)$, selecting vertex $(i-\\frac{1}{2}, j)$ if the piece has width $2$, and selecting vertex $(i, j-\\frac{1}{2})$ if it has height $2$, as in Figure~\\ref{independentfig}.  The construction guarantees that these are in fact vertices of the apex graph and that no two of them share an edge.\n\nFor the converse, suppose that we have an independent set in the apex graph.  We select our pieces to have width $2$ and/or height $2$ according to which vertices are in the independent set, and we want to check whether the pieces overlap or hang off the board.  Consider the $(i, j)$ piece.  It cannot hang off the board or overlap with a piece at $(i-1, j)$ or $(i, j-1)$, because the vertices corresponding to those possibilities are not in the apex graph.  It cannot overlap with a piece at $(i-1, j-1)$ because that would mean choosing both vertices $(i-\\frac{1}{2}, j)$ and $(i, j-\\frac{1}{2})$ which would be adjacent.  And, it cannot overlap with a piece at $(i-1, j+1)$, because that would mean choosing both vertex $(i-\\frac{1}{2}, j)$ and $(i-1, j+\\frac{1}{2})$ which would be adjacent.  Symmetrically, by swapping the roles of the two pieces, we see that the piece at $(i, j)$ also cannot overlap with the pieces at $(i+1, j)$, $(i, j+1)$, $(i+1, j+1)$, or $(i+1, j-1)$.  This exhausts all the possibilities for how two pieces of width and height at most $2$ might overlap, and shows that we have a bijection.\n\nFor the second property, suppose that cells $e$ and $f$ have the same apex.  Then $f$ is a face of $e$ if and only if every piece of width $2$ in $f$ also has width $2$ in $e$, and every piece of height $2$ in $f$ also has height $2$ in $e$.  This is equivalent to the condition that the independent set corresponding to $f$ is a subset of the independent set corresponding to $e$.\n\\end{proof}\n\nThinking of the cells as independent sets in the apex graph suggests how to think about pairing them up.  The dimension of a cell is equal to the number of vertices in the independent set corresponding to that cell.  So, if cells $e$ and $f$ have the same apex, then $f$ is a face of $e$ with $\\dim f = \\dim e - 1$ if and only if the independent set of $f$ is a subset of the independent set of $e$ and the two sets differ by one vertex.  When two independent sets differ by one vertex, we say that they are \\textit{\\textbf{adjacent}}.\n\n\\begin{lemma}\\label{matchlemma}\nGiven a disjoint union of paths, there is a matching on the set of independent sets such that every matched pair of independent sets are adjacent and at most one independent set is unmatched.\n\\end{lemma}\n\n\\begin{proof}\nWe start by proving the statement for one connected path of $k$ vertices.  We express the independent sets as binary strings of length $k$ with no consecutive $1$'s, so that $0$ indicates that the vertex in that position is not part of the independent set, and $1$ indicates that the vertex is part of the independent set.  The matching is defined recursively.  For $k=1$ the strings are $0$ and $1$, which we match as a pair.  For $k=2$ the strings are $00$, $01$, and $10$; we match $00$ with $10$ and leave $01$ unmatched.  For $k>2$, each string begins with $00$, $10$, or $010$.  We match the strings beginning with $00$ to the strings beginning with $10$ such that each matched pair differs only in the first bit.  Then, for the strings beginning with $010$ we ignore the first three bits and use the matching for the $k-3$ case.  \n\nThe result is that for $k\\equiv 1\\mod 3$, all strings are matched; for $k \\equiv 0 \\mod 3$, the only unmatched string consists of repeating copies of $010$; and for $k \\equiv 2 \\mod 3$ the only unmatched string consists of repeating copies of $010$ followed by $01$ at the end.  This proves the lemma for the case of one path.\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}\n\\draw (0, 0)--(3, 0) (0, 1)--(2, 1);\n\\draw[fill=black] (.5, 0) circle (.07)\n(.5, 1) circle (.07)\n(2.5, 0) circle (.07)\n(2, 1) circle (.07);\n\\draw[fill=white] (0, 0) circle (.07)\n(0, 1) circle (.07)\n(1, 0) circle (.07)\n(1, 1) circle (.07)\n(1.5, 0) circle (.07)\n(1.5, 1) circle (.07)\n(2, 0) circle (.07)\n(3, 0) circle (.07);\n\n\\node at (0, 0) [label=below:{$0$}] {};\n\\node at (.5, 0) [label=below:{$1$}] {};\n\\node at (1, 0) [label=below:{$0$}] {};\n\\node at (1.5, 0) [label=below:{$0$}] {};\n\\node at (2, 0) [label=below:{$0$}] {};\n\\node at (2.5, 0) [label=below:{$1$}] {};\n\\node at (3, 0) [label=below:{$0$}] {};\n\n\\node at (0, 1) [label=below:{$0$}] {};\n\\node at (.5, 1) [label=below:{$1$}] {};\n\\node at (1, 1) [label=below:{$0$}] {};\n\\node at (1.5, 1) [label=below:{$0$}] {};\n\\node at (2, 1) [label=below:{$1$}] {};\n\\end{tikzpicture}\n\\begin{tikzpicture}\n\\draw[<->] (-.5, .5)--(.5, .5);\n\\node at (-1, -.5) {};\n\\node at (1.5, -.5) {};\n\\end{tikzpicture}\n\\begin{tikzpicture}\n\\draw (0, 0)--(3, 0) (0, 1)--(2, 1);\n\\draw[fill=black] (.5, 0) circle (.07)\n(.5, 1) circle (.07)\n(1.5, 0) circle (.07)\n(2.5, 0) circle (.07)\n(2, 1) circle (.07);\n\\draw[fill=white] (0, 0) circle (.07)\n(0, 1) circle (.07)\n(1, 0) circle (.07)\n(1, 1) circle (.07)\n(1.5, 1) circle (.07)\n(2, 0) circle (.07)\n(3, 0) circle (.07);\n\n\\node at (0, 0) [label=below:{$0$}] {};\n\\node at (.5, 0) [label=below:{$1$}] {};\n\\node at (1, 0) [label=below:{$0$}] {};\n\\node at (1.5, 0) [label=below:{$1$}] {};\n\\node at (2, 0) [label=below:{$0$}] {};\n\\node at (2.5, 0) [label=below:{$1$}] {};\n\\node at (3, 0) [label=below:{$0$}] {};\n\n\\node at (0, 1) [label=below:{$0$}] {};\n\\node at (.5, 1) [label=below:{$1$}] {};\n\\node at (1, 1) [label=below:{$0$}] {};\n\\node at (1.5, 1) [label=below:{$0$}] {};\n\\node at (2, 1) [label=below:{$1$}] {};\n\\end{tikzpicture}\n\\end{center}\n\\caption{Given an independent set on a disjoint union of paths, to find its match we select the first component that is not critical, ignore any $010$ prefixes, and flip the first bit of the remainder.}\\label{matchingfig}\n\\end{figure}\n\nFor several disjoint paths, we select some ordering on them.  Given an independent set, if its restriction to each path agrees with the unmatched independent set from the one-path case, we leave it unmatched.  Otherwise, we find the first path $P$ where this is not true.  To find the matching independent set, we keep all the other paths as they are and alter the set on $P$ to be the matching set from the one-path case, as in Figure~\\ref{matchingfig}.  There is an unmatched independent set if and only if none of the paths has $1 \\mod 3$ vertices, and in this case the unmatched set corresponds to repeating $010$ on each path.\n\\end{proof}\n\nTo finish the proof of Theorem~\\ref{mainthm}, we need to check that the matching we have just defined determines a discrete gradient vector field with the properties we are looking for.\n\n\\begin{proof}[Proof of Theorem~\\ref{mainthm}]\nThe discrete vector field is defined as follows.  Given a cell, we find its apex and the apex graph.  Encoding the original rectangle arrangement as an independent set in the apex graph (Lemma~\\ref{bijlemma}), we find the matching independent set (Lemma~\\ref{matchlemma}) if there is one, and decode to get another cell with the same apex.  Properties~(\\ref{apexprop}) and~(\\ref{snprop}) are automatic from the construction, and Property~(\\ref{oneprop}) is a consequence of Lemma~\\ref{matchlemma}.\n\nWe still need to check that the discrete vector field is gradient.  We want to show that there does not exist a cycle of cells $e_1, f_1, e_2, f_2, \\ldots, e_r, f_r, e_{r+1}=e_1$ such that every $e_i$ and $f_i$ are a matched pair and every $f_i$ is a face of $e_{i+1}$ with $\\dim f_i = \\dim e_{i+1} - 1$.  We observe that because $f_i$ is a face of $e_{i+1}$, if the apex of $e_{i+1}$ is not equal to the apex of $f_i$, then it differs by moving some piece one square left or down.  Every pair $e_i$ and $f_i$ have the same apex, so as the sequence continues, the apex keeps moving leftward and downward, making it impossible to have a cycle unless all cells in it have the same apex.\n\nThus we may assume that the cells $e_1, f_1, \\ldots, e_r, f_r$ all have the same apex.  We can encode these cells as independent sets in the apex graph.  To go from $e_1$ to $f_1$, we delete one vertex $v$ from the independent set of $e_1$, and to go from $f_1$ to $e_2$, we add one vertex $w$ to the independent set of $f_1$.  Remembering the ordering of the paths and vertices in the apex graph, we observe that up until $v$, the independent set for $f_1$ agrees with the unmatched independent set, so any added vertices there would destroy the property of being an independent set.  Thus $w$ cannot be at or before $v$.  If the vertex immediately after $v$ is on the same path, then $w$ can be that vertex.  But $w$ cannot be anywhere else after $v$, because if so, then the matching independent set to $e_2$, which we have supposed is $f_2$, would have $v$ added rather than a vertex subtracted -- it would have the wrong dimension -- giving a contradiction unless $w$ is immediately after $v$.\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}\n\\draw (0, 0)--(2, 0) (0, 1.5)--(2, 1.5) (0, 3)--(2, 3);\n\\draw[fill=white] (0, 0) circle (.07)\n(1, 0) circle (.07)\n(1.5, 0) circle (.07)\n(0, 1.5) circle (.07)\n(1, 1.5) circle (.07)\n(1.5, 1.5) circle (.07)\n(2, 1.5) circle (.07)\n(0, 3) circle (.07)\n(1, 3) circle (.07)\n(2, 3) circle (.07);\n\\draw[fill=black] (.5, 0) circle (.07)\n(2, 0) circle (.07)\n(.5, 1.5) circle (.07)\n(.5, 3) circle (.07)\n(1.5, 3) circle (.07);\n%\\node at (0, 0) [label=below:{$0$}] {};\n%\\node at (.5, 0) [label=below:{$1$}] {};\n%\\node at (1, 0) [label=below:{$0$}] {};\n%\\node at (1.5, 0) [label=below:{$0$}] {};\n%\\node at (2, 0) [label=below:{$1$}] {};\n\\node at (2, 0) [label=above:{$w$}] {};\n%\\node at (0, 1.5) [label=below:{$0$}] {};\n%\\node at (.5, 1.5) [label=below:{$1$}] {};\n%\\node at (1, 1.5) [label=below:{$0$}] {};\n%\\node at (1.5, 1.5) [label=below:{$0$}] {};\n%\\node at (2, 1.5) [label=below:{$0$}] {};\n\\node at (1.5, 1.5) [label=above:{$v$}] {};\n\\node at (2, 1.5) [label=above:{$w$}] {};\n\\node at (1.5, 3) [label=above:{$v$}] {};\n\\draw[->] (1, 1)--(1, .5);\n\\draw[->] (1, 2.5)--(1, 2);\n\\node at (0, 0) [label=left:{\\ldots}] {};\n\\node at (0, 1.5) [label=left:{\\ldots}] {};\n\\node at (0, 3) [label=left:{\\ldots}] {};\n\\node at (2, 0) [label=right:{\\ldots}] {};\n\\node at (2, 1.5) [label=right:{\\ldots}] {};\n\\node at (2, 3) [label=right:{\\ldots}] {};\n\\node at (-1.5, 0) {$e_2$};\n\\node at (-1.5, 1.5) {$f_1$};\n\\node at (-1.5, 3) {$e_1$};\n\\end{tikzpicture}\n\\end{center}\n\\caption{In a sequence of cells with the same apex, alternating between two consecutive dimensions, with consecutive pairs alternating between matched and incident, the corresponding independent sets look more and more like the unmatched set, and thus cannot cycle.}\\label{sequencefig}\n\\end{figure}\n\nThus we cannot have a cycle $e_1, f_1, \\ldots, e_r, f_r, e_{r+1}=e_1$, because each successive item agrees more and more with the unmatched set, as in Figure~\\ref{sequencefig}: the independent set of $e_1$ agrees before $v$, the independent set of $f_1$ agrees through $v$, the independent set of $e_2$ agrees through $w$, and so on.  So, our discrete vector field is gradient and has all three desired properties from the theorem statement.\n\\end{proof}\n\nWe prove one last theorem in this section, which helps with assessing the dimension of critical cells in the following section. For the following, we divide each unit square in  the $p$ by $q$ grid into two \\emph{half-squares} by drawing a diagonal line from the upper-right to the lower-left corner.\n\n\\begin{theorem} \\label{thm-halfsquares}\nThere is a function $r$ that assigns a set of half-squares to each vertex of the apex graph, with the following properties:\n\\begin{enumerate}\n\\item For any vertex $v$, the set $r(v)$ has four half-squares if $v$ is the only vertex of a path, three half-squares if $v$ is the first or last vertex of a path, and two half-squares otherwise.\n\\item The sets $r(v)$ are disjoint for all $v$.\n\\end{enumerate}\n\\end{theorem}\n\n%%%%%\n%%%%% This proof has been copied and pasted to the next section. It is now listed as Theorem \\ref{thm:pq3}.\n%%%%%%\n% \\begin{corollary}\n% There are no critical cells of dimension greater than $pq/3$.\n% \\end{corollary}\n\n% \\begin{proof}\n% A critical cell corresponds to an independent set that on each path looks like $010\\ldots010$ or $010\\ldots01$ depending on whether the number of vertices in the path is $0$ or $2$ mod $3$.  The dimension of the critical cell is the number of vertices in the independent set.  If the path has $k$ vertices, then the independent set has $k/3$ vertices in the first case, and has $(k+1)/3$ vertices in the second case.\n\n% For a path of $k$ vertices, the theorem allocates half-squares with a total area of $k+1$ to the vertices of the path.  The independent set for that path contributes at most $(k+1)/3$ to the dimension of the critical cell.  Thus, in total, the dimension of the critical cell is at most one third of the total area allocated to all the paths in the apex graph, and thus is at most $pq/3$.\n% \\end{proof}\n\n\\begin{proof}[Proof of Theorem~\\ref{thm-halfsquares}]\nRecalling that we can draw each vertex of the apex graph as the midpoint of an edge between a square occupied by an apex piece and an unoccupied square, we set $r(v)$ to contain both of the half-squares that $v$ touches, as in Figure~\\ref{fig-rule0}.  \n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[>=stealth]\n\\draw (0, 0)--(2, 0) (0, 1)--(2, 1) (0, 0)--(0, 1) (1, 0)--(1, 1) (2, 0)--(2, 1);\n\\draw[draw=gray!40,fill=gray!40] (1.1, .1)--(1.9, .1)--(1.9, .9)--(1.1, .9)--cycle;\n\\draw[<->] (.75, .75)--(1.25, .25);\n\\draw[fill=white] (1, .5) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(1, 0)--(2, 1)--(1, 1)--cycle;\n\\end{tikzpicture}\\hspace{10pt}\n\\begin{tikzpicture}[>=stealth]\n\\draw (0, 0)--(0, 2) (1, 0)--(1, 2) (0, 0)--(1, 0) (0, 1)--(1, 1) (0, 2)--(1, 2);\n\\draw[draw=gray!40,fill=gray!40] (.1, 1.1)--(.1, 1.9)--(.9, 1.9)--(.9, 1.1)--cycle;\n\\draw[<->] (.25, 1.25)--(.75, .75);\n\\draw[fill=white] (.5, 1) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(1, 1)--(1, 2)--(0, 1)--cycle;\n\\end{tikzpicture}\n\\end{center}\n\\caption{Each vertex is assigned the two half-squares it touches.  If vertex $v$ has neighbors in both directions, then $r(v)$ contains only these two half-squares.}\\label{fig-rule0}\n\\end{figure}\n\nWe think of the vertices as ordered first by the sum of coordinates and then by the column coordinate, so that the ordering starts in the lower-left corner and goes right and down along diagonals.  If $v$ is the first or last vertex of a path, we need to find another half-square to add to $r(v)$.  There are several cases, shown in Figure~\\ref{fig-rule135}:\n\\begin{enumerate}\n\\item If $v$ is the first vertex of a path and is on a vertical edge:  Add in the remainder of the square to the left of $v$.\n\\item If $v$ is the last vertex of a path and is on a horizontal edge: Add in the remainder of the square below $v$.\n\\item If $v$ is the first vertex of a path and is on a horizontal edge, and there is no vertex on the preceding (above-left) edge:  Add in the remainder of the square above $v$.\n\\item If $v$ is the last vertex of a path and is on a vertical edge, and there is no vertex on the following (below-right) edge: Add in the remainder of the square to the right of $v$.\n\\item If $v$ is the first vertex of a path and is on a horizontal edge, and there is a (non-adjacent) vertex on the preceding edge: Add the half-square to the left of the square below $v$.\n\\item If $v$ is the last vertex of a path and is on a vertical edge, and there is a (non-adjacent) vertex on the following edge: Add the half-square below the square to the left of $v$.\n\\end{enumerate}\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[>=stealth]\n\\draw (0, 0)--(2, 0) (0, 1)--(2, 1) (0, 0)--(0, 1) (1, 0)--(1, 1) (2, 0)--(2, 1);\n\\draw[draw=gray!40,fill=gray!40] (1.1, .1)--(1.9, .1)--(1.9, .9)--(1.1, .9)--cycle;\n\\draw[->] (1, .5)--(1.25, .25);\n\\draw[fill=white] (1, .5) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(1, 0)--(2, 1)--(0, 1)--cycle;\n\\draw (.4, .9)--(.6, 1.1) (.4, 1.1)--(.6, .9);\n\\end{tikzpicture}\\hspace{10pt}\n\\begin{tikzpicture}[>=stealth]\n\\draw (0, 0)--(0, 2) (1, 0)--(1, 2) (0, 0)--(1, 0) (0, 1)--(1, 1) (0, 2)--(1, 2);\n\\draw[draw=gray!40,fill=gray!40] (.1, 1.1)--(.1, 1.9)--(.9, 1.9)--(.9, 1.1)--cycle;\n\\draw[->] (.5, 1)--(.75, .75);\n\\draw[fill=white] (.5, 1) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(1, 1)--(1, 2)--(0, 2)--cycle;\n\\draw (-.1, 1.4)--(.1, 1.6) (.1, 1.4)--(-.1, 1.6);\n\\end{tikzpicture}\\hspace{10pt}\n\\begin{tikzpicture}[>=stealth]\n\\draw (0, 0)--(2, 0) (0, 1)--(2, 1) (0, 2)--(2, 2) (0, 0)--(0, 2) (1, 0)--(1, 2) (2, 0)--(2, 2);\n\\draw[draw=gray!40,fill=gray!40] (1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[<-] (.75, 1.75)--(1, 1.5);\n\\draw[->] (1.5, 1)--(1.75, .75);\n\\draw[fill=white] (1, 1.5) circle (.07) (1.5, 1) circle (.07);\n\\draw[line width=.5mm] (1, 0)--(2, 1)--(2, 2)--(0, 0)--cycle (0, 1)--(0, 0)--(2, 2)--(1, 2)--cycle;\n\\end{tikzpicture}\n\\end{center}\n\\caption{For the first vertex of a path, rules (1), (3), and (5) specify how to add a third half-square; the $\\times$ symbol indicates an absence of vertex.  The third picture also shows an instance of rule (6).  For the last vertex of a path, rules (2), (4), and (6) are analogous.}\\label{fig-rule135}\n\\end{figure}\n\n\n\\begin{figure}[h!]\n\\begin{center}\n\\begin{tikzpicture}[>=stealth]\n\\node at (-.1, -.1) {};\n\\draw (0, 0)--(2, 0) (0, 1)--(2, 1) (0, 0)--(0, 1) (1, 0)--(1, 1) (2, 0)--(2, 1);\n\\draw[draw=gray!40,fill=gray!40] (1.1, .1)--(1.9, .1)--(1.9, .9)--(1.1, .9)--cycle;\n\\draw[fill=white] (1, .5) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(2, 0)--(2, 1)--(0, 1)--cycle;\n\\draw (.4, .9)--(.6, 1.1) (.4, 1.1)--(.6, .9);\n\\draw (1.4, -.1)--(1.6, .1) (1.4, .1)--(1.6, -.1);\n\\end{tikzpicture}\\hspace{10pt}\n\\begin{tikzpicture}[>=stealth]\n\\node at (-.1, -.1) {};\n\\draw (0, 0)--(2, 0) (0, 1)--(2, 1) (0, 2)--(2, 2) (0, 0)--(0, 2) (1, 0)--(1, 2) (2, 0)--(2, 2);\n\\draw[draw=gray!40,fill=gray!40] (1.1, 1.1)--(1.9, 1.1)--(1.9, 1.9)--(1.1, 1.9)--cycle;\n\\draw[->] (1.5, 1)--(1.75, .75);\n\\draw[fill=white] (1, 1.5) circle (.07) (1.5, 1) circle (.07);\n\\draw[line width=.5mm] (0, 0)--(2, 2)--(0, 2)--cycle;\n\\draw (.4, 1.9)--(.6, 2.1) (.4, 2.1)--(.6, 1.9);\n\\end{tikzpicture}\n\\end{center}\n\\caption{If the only vertex of a path is on a vertical edge, rules (1) and (4) or rules (1) and (6) assign four half-squares to that vertex.  If the vertex is on a horizontal edge, rules (2) and (3) or rules (2) and (5) are analogous.}\\label{fig-rule146}\n\\end{figure}\n\nIn the case where $v$ is the only vertex of the path, if $v$ is on a vertical edge, then either rules (1) and (4) or rules (1) and (6) apply, as shown in Figure~\\ref{fig-rule146}, and if $v$ is on a horizontal edge, then either rules (2) and (3) or rules (2) and (5) apply, so that $r(v)$ has four half-squares in total.  This completes the definition of $r(v)$.\n\n\nWe need to check that no half-square has been assigned twice.  To do this, we consider the assignment from the point of view of each square.  Consider a square that is occupied by a piece in the apex arrangement.  It may have vertices on its left or lower edges.  If it has both vertices, then half of the square is assigned to each vertex.  If it has one vertex, then all of the square is assigned to that vertex, by rule (3) or rule (4).  If it has no vertex, then none of the rules assign that square to any vertex.\n\nSimilarly, consider a square that is unoccupied in the apex arrangement.  It may have vertices on its right or upper edges.  If it has both vertices, then half of the square is assigned to each vertex.  If it has one vertex, then all of the square is assigned to that vertex, by rule (1) or rule (2).  (Note that rule (1) and rule (2) cannot apply to an unoccupied square with both vertices, because in this case the two vertices would be adjacent.)  If our unoccupied square has no vertices, then we divide the square in half.  The lower-right half gets assigned by rule (5) to the same vertex (if any) as the half-square to its right, and the upper-left half gets assigned by rule (6) to the same vertex (if any) as the half-square above it.\n\nIn each case, only one rule can apply to each half-square, so each half-square can be assigned to only one vertex.\n\\end{proof}\n\n% \\begin{enumerate}\n% \\item If $p$ and $q$ are both even, then $M(p,q)=pq/4$.\n% \\item If $p$ is even and $q$ is odd:\n% \\begin{enumerate}\n% \\item If  $p \\equiv  0 \\pmod 3$, then  $M(p,q)=p(q-3)/4 + 2p/3$.\n% \\item If $p \\equiv 1 \\pmod 3$, then $M(p,q)=p(q-3)/4 + 2(p-1)/3$.\n% \\item If $p \\equiv 2 \\pmod 3$, then  $M(p,q)=p(q-3)/4 + 2(p-2)/3 + 1$.\n% \\end{enumerate}\n% \\item If $p$ and $q$ are both odd:\n% \\begin{enumerate}\n% \\item If $p, q \\equiv 0 \\pmod 3$, then $M(p,q)= (p-3)(q-3)/4 + 2((p-3)/3 + (q-3)/3 + 1)$.\n% \\item If $p \\equiv 0 \\pmod 3$ and $q \\equiv 1 \\pmod 3$, then $M(p,q)= (p-3)(q-3)/4 + 2((p-3)/3 + (q-4)/3 + 1)$.\n% \\item If $p \\equiv 0 \\pmod 3$ and $q \\equiv 2 \\pmod 3$, then $M(p,q)=(p-3)(q-3)/4 + 2((p-3)/3 + (q-5)/3 + 1) + 1$.\n% \\item If $p \\equiv 1 \\pmod 3$ and $q \\equiv 1 \\pmod 3$, then $M(p,q)= (p-3)(q-3)/4 + 2((p-4)/3 + (q-4)/3) + 3$.\n% \\item If $p \\equiv 1 \\pmod 3$ and $q \\equiv 2 \\pmod 3$, then $M(p,q) = (p-3)(q-3)/4 + 2((p-4)/3 + (q-5)/3 + 1) + 2$.\n% \\item If $p \\equiv 2 \\pmod 3$ and $q \\equiv 2 \\pmod 3$, then $M(p,q)= (p-3)(q-3)/4 + 2((p-5)/3 + (q-5)/3 + 1) + 2$.\n% \\end{enumerate}\n% \\end{enumerate}\n% \\end{conjecture}\n\n% We know that $M(p,q)$ must be at least as large as in this conjecture, as we describe in the following section.\n\n\\section{Homology-vanishing theorems}\n\nThe existence of the cell complex $\\cell{n}{p}{q}$ and the discrete gradient on it allow us to establish a number of homology-vanishing results.\n\n\\begin{theorem} \\label{thm:hv:pq-n}\nIf $j > pq - n$, then $H_j [ \\config{n}{p}{q} ] = 0$.\n\\end{theorem}\n\n\\begin{proof}[Proof of Theorem \\ref{thm:hv:pq-n}] This is almost immediate from the homotopy equivalence $\\config{n}{p}{q} \\sim \\cell{n}{p}{q}$.  Consider the dimensions of the cells in $\\cell{n}{p}{q}$. A cell is indexed by a collection of $n$ non-overlapping rectangular pieces in a $p \\times q$ grid. A $1 \\times 1$ piece contributes $0$ to the dimension of the cell, a $1 \\times 2$ or $2 \\times 1$ piece contributes $1$, and a $2 \\times 2$ piece contributes $2$. The total area of the pieces is at most $pq$. So the largest dimension of a cell is at most $pq-n$. By the definition of cellular homology, there is no homology above the dimension of the cell complex itself, so $H_j [ \\config{n}{p}{q} ] = 0$ for $j > pq - n$.\n\\end{proof}\n\n\\begin{theorem} \\label{thm:hv:n}\nIf $j > n$, then $H_j [ \\config{n}{p}{q} ] = 0$.\n\\end{theorem}\n\n\\begin{proof}[Proof of Theorem \\ref{thm:hv:n}]\nThis follows from the properties of the discrete gradient described in Section \\ref{sec:dMt}. Every cell is indexed by a collection of non-overlapping rectangular pieces, each piece either $1 \\times 1$, $1 \\times 2$, $2 \\times 1$, or $2 \\times 2$. The analysis of the gradient shows that there are no critical cells indexed by a collection of pieces including a $2 \\times 2$ piece. (When such a cell is encoded as an independent set in the apex graph as in Lemma~\\ref{bijlemma}, the $2 \\times 2$ piece corresponds to two vertices of the independent set that are consecutive but not adjacent.  However, the proof of Lemma~\\ref{matchlemma} implies that in a critical cell, the first vertex of each path is never part of the corresponding independent set.) Hence the dimension of a critical cell is at most $n$.\n\\end{proof}\n\n\n\\begin{theorem} \\label{thm:pq3}\nIf $j > pq / 3$, then $H_j [ \\config{n}{p}{q} ] = 0$.\n\\end{theorem}\n\n\\begin{proof}[Proof of Theorem \\ref{thm:pq3}]\nThis follows from Theorem \\ref{thm-halfsquares}. A critical cell corresponds to an independent set that on each path looks like $010\\ldots010$ or $010\\ldots01$ depending on whether the number of vertices in the path is $0$ or $2$ mod $3$.  The dimension of the critical cell is the number of vertices in the independent set.  If the path has $k$ vertices, then the independent set has $k/3$ vertices in the first case, and has $(k+1)/3$ vertices in the second case.\n\nFor a path of $k$ vertices, the theorem allocates half-squares with a total area of $k+1$ to the vertices of the path.  The independent set for that path contributes at most $(k+1)/3$ to the dimension of the critical cell.  Thus, in total, the dimension of the critical cell is at most one third of the total area allocated to all the paths in the apex graph, and thus is at most $pq/3$.\n\\end{proof}\n\nPutting together Theorems \\ref{thm:hv:pq-n}, \\ref{thm:hv:n}, and \\ref{thm:pq3}, we have proved Theorem \\ref{thm:homologyvanishing}.\n\n\\vanishinghomology*\n\n\\section{Nontrivial homology} \\label{sec:nontrivial}\n\nIn this section, our main aim is to prove Theorem \\ref{thm:allnonvanish}. We give several explicit constructions of nontrivial cycles, and then a method for interpolating between parameters.\n\n\\begin{lemma}  \\label{lem:14attainable}\nThe points $(1/2,1/4)$ and $(3/4,1/4)$ are attainable.\n\\end{lemma}\n\n\\begin{proof}\nFigure \\ref{fig:222} shows a cycle in $H_1[\\config{2}{2}{2}]$. More precisely, the figure illustrates a piecewise-linear map $i: S^1 \\to \\config{2}{2}{2}$, where we linearly interpolate at constant speed between the positions shown. Then if $[\\sigma]$ is a generator of $H_1(S^1)$, the cycle we are describing is the image $i_*([\\sigma])$. \n\nTo show that this cycle is nontrivial, consider the map $f: \\config{2}{2}{2} \\to S^1$, where one takes the angle the line from the center of square 1 to the center of square 2 makes with the $x$-axis. In other words, define\n$$f(x_1, y_1, x_2, y_2) = \\frac{1}{\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}}(x_2-x_1,y_2-y_1).$$\nThe composition $f \\circ i$ is a degree-one map $S^1 \\to S^1$, and in particular the induced map $(f \\circ i)_*$ is an isomorphism on $H_1$. So then $i$ must be injective on $H_1$.\n\nSimilarly, Figure \\ref{fig:322} shows a cycle in $H_1[\\config{3}{2}{2}]$. The figure illustrates a piecewise-linear map $i: S^1 \\to \\config{3}{2}{2}$, and the cycle we are interested in is the image. This also represents a nontrivial cycle in $H_1[\\config{3}{2}{2}]$. Indeed, we have a natural projection map to $\\config{2}{2}{2}$ where one forgets the coordinates of the third square, and then the argument above shows that the image of the cycle is still nontrivial in this projection.\n\\begin{figure}\n\\begin{tikzpicture}[scale=2]\n\\draw[line width=0.25mm] (0,0) circle (1.25);\n\\foreach \\a in {0, ..., 7}\n{\n%\\draw (0,0)--(\\a*30:1);\n\\draw[line width=0.25mm,fill=white](\\a*45:1.25)++(-0.2,0.2)--++(0.4,0)--++(0,-0.4)--++(-0.4,0)--cycle;\n}\n\\draw[line width=0.25mm,fill=lightgray] (-45:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-45:1.25)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (0:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (0:1.25)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (45:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (45:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (90:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (90:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (135:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (135:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (180:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (180:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (225:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (225:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (270:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (270:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\end{tikzpicture}\n\\caption{A nontrivial cycle in $H_1[ \\config{2}{2}{2} ]$. This realizes the point $(x,y)=(1/2, 1/4)$.}\n\\label{fig:222}\n\\end{figure} \\begin{figure}\n\n\\begin{tikzpicture}[scale=2]\n\\draw[line width=0.25mm] (0,0) circle (1.25);\n\\foreach \\a in {0, ..., 11}\n{\n%\\draw (0,0)--(\\a*30:1);\n\\draw[line width=0.25mm,fill=white](\\a*30:1.25)++(-0.2,0.2)--++(0.4,0)--++(0,-0.4)--++(-0.4,0)--cycle;\n}\n\\draw[line width=0.25mm,fill=gray] (0:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (0:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (0:1.25)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (-30:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (-30:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-30:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (-60:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (-60:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-60:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (-90:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (-90:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-90:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (-120:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (-120:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-120:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (-150:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (-150:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (-150:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (180:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (180:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (180:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (150:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (150:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (150:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (120:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (120:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (120:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (90:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (90:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (90:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (60:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (60:1.25)++(-0.2,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (60:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=gray] (30:1.25)++(-0.2,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=lightgray] (30:1.25)++(0,0.2)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[line width=0.25mm,fill=darkgray] (30:1.25)++(0,0)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\end{tikzpicture}\n\\caption{A nontrivial cycle in $H_1[\\config{3}{2}{2}]$. This realizes the point $(x,y)=(3/4, 1/4)$.}\n\\label{fig:322}\n\\end{figure} \\end{proof}\n\n%\\todo{The following lemma ends up being superseded by a stronger version; maybe this should be mentioned here already. On the other hand, the embedding of the torus appearing in the proof is actually used later. Maybe describe the embedding outside of a proof environment? \n%Matt says: I added a sentence that a stronger statement is coming. If someone wants to move something about embedding the torus outside of a proof environment, that's fine with me, but I left it where it is for now.}\n\nThe following lemma will be superseded later in this section by a stronger result, but we present the lemma and proof as a warmup, and we will also reuse the main construction in its proof later.\n\n\\begin{lemma} \\label{lem:diag}\nThe point\n$$(x,y) = \\left( \\frac{k}{k^2},\\frac{k-1}{k^2} \\right)= \\left( \\frac{1}{k}, \\frac{1}{k} - \\frac{1}{k^2} \\right)$$\nis attainable, for every $k \\ge 1$.\n\\end{lemma}\n\n\\begin{figure}\n\n\\begin{tikzpicture}[scale=2]\n\\draw[line width=0.25mm] (0,0) circle (1.25);\n\\foreach \\a in {0, ..., 7}\n{\n%\\draw (0,0)--(\\a*30:1);\n\\draw[blue,line width=0.25mm,fill=white](\\a*45:1.25)++(-0.3,0.3)--++(0.6,0)--++(0,-0.6)--++(-0.6,0)--cycle;\n}\n\\draw[blue,line width=0.25mm,fill=white] (-45:1.25)++(0.1,-0.1)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (-45:1.25)++(0.1,-0.1)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (0:1.25)++(0.1,-0.3)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (0:1.25)++(0.1,-0.1)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (45:1.25)++(0.1,-0.3)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (45:1.25)++(0.1,0.3)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (90:1.25)++(0.3,-0.3)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (90:1.25)++(0.1,0.3)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (135:1.25)++(0.3,-0.3)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (135:1.25)++(-0.3,0.3)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (180:1.25)++(0.3,-0.1)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (180:1.25)++(-0.3,0.3)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (225:1.25)++(0.3,-0.1)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (225:1.25)++(-0.3,-0.1)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\\draw[blue,line width=0.25mm,fill=white] (270:1.25)++(0.1,-0.1)--++(-0.4,0)--++(0,0.4)--++(0.4,0)--cycle;\n\\draw[line width=0.25mm,fill=black] (270:1.25)++(-0.3,-0.1)--++(0.2,0)--++(0,-0.2)--++(-0.2,0)--cycle;\n\n\\end{tikzpicture}\n\\caption{A $2 \\times 2$ square and $1 \\times 1$ orbiting each other in a $3 \\times 3$ grid.}\n\\label{fig:2and1}\n\\end{figure}\n \n\\begin{proof}\nConsider first Figure \\ref{fig:2and1}. We illustrate a $2 \\times 2$ square and $1 \\times 1$ square orbiting each other in a $3 \\times 3$ grid, as in Figure \\ref{fig:222}. We can then put two $1 \\times 1$ squares inside the $2 \\times 2$ square, and these can orbit each other independently. So, together these motions describe a map $i: T^2 \\to \\config{3}{3}{3}$. This map is illustrated in Figure  \\ref{fig:2333} and \\ref{fig:2torus}. By induction, we can embed an $(k-1)$-dimensional torus realizing a nontrivial cycle in $\\config{k}{k}{k}$, for every $k \\ge 2$.\n\\begin{figure}\n\\centering\n\\begin{tikzpicture}[line width=0.25mm,scale=1]\n\\draw (0,0)--(3,0)--(3,3)--(0,3)--cycle;\n\\draw[fill=lightgray] (0,3)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=gray] (1,2)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=black] (2,1)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw (1,2) circle (0.71);\n\\draw (1.75,1.25) circle (1.07);\n\\draw [blue,line width=0.5mm] (0,3)--++(2,0)--++(0,-2)--++(-2,0)--cycle;\n\\end{tikzpicture}\n\\caption{A map $T^2 \\to \\config{3}{3}{3}$. The light gray and dark gray squares orbit each other inside the blue $2 \\times 2$ square as in Figure \\ref{fig:222}, while the black and blue square orbit each other independently as in Figure \\ref{fig:2and1}.}\n\\label{fig:2333}\n\\end{figure}\n\n\\begin{figure}\n\\centering\n\n\\begin{tikzpicture}[line width=0.25mm,scale=0.30]\n\n\\foreach \\a in {0, ..., 7}\n{\n\\draw (-1,\\a*4+1.5)--(32,\\a*4+1.5);\n\\draw (\\a*4+1.5,-1)--(\\a*4+1.5,32);\n}\n\n\\foreach \\a in {0, ..., 7}\n{\n\\foreach \\b in {0, ..., 7}\n{\n\\draw[fill=white] (\\a*4,\\b*4)--++(3,0)--++(0,3)--++(-3,0)--cycle;\n}\n}\n\n\\foreach \\a in {0, ..., 7}\n{\n\\draw[fill=black] (2,\\a*4)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (6,\\a*4+2)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (10,\\a*4+2)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (12,\\a*4+2)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (16,\\a*4+2)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (20,\\a*4)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (24,\\a*4)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=black] (30,\\a*4)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\ifthenelse{\\a=2 \\OR \\a=3 \\OR \\a=4 \\OR \\a=5}{\\def\\x{1}}{\\def\\x{0}}\n\\ifthenelse{\\a=6 \\OR \\a=7 \\OR \\a=4 \\OR \\a=5}{\\def\\y{1}}{\\def\\y{0}}\n\\draw[fill=lightgray] (\\a*4+\\x,\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x+1,\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x,4+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x+1,5+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x+1,8+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x+1,9+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x+1,12+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x,13+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x+1,17+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x,17+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x+1,21+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x,20+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x,25+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x,24+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (\\a*4+\\x,29+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n\\draw[fill=gray] (\\a*4+\\x+1,28+\\y)--++(1,0)--++(0,1)--++(-1,0)--cycle;\n}\n\n\n\\end{tikzpicture}\n\\caption{Another view of the map $i: T^2 \\to \\config{3}{3}{3}$ visualized in Figure \\ref{fig:2333}. The image of the fundamental class of the torus is a nontrivial cycle in $H_2[ \\config{3}{3}{3}]$.}\n\\label{fig:2torus}\n\\end{figure}\n\n  %% comment the line out for faster compiling of the LaTeX\n\nThe same argument as before gives that this represents a nontrivial class in $H_2[ \\config{3}{3}{3}]$. Indeed, compose with a map $f: \\config{3}{3}{3} \\to T^2 = S^1 \\times S^1$ which assigns to the first coordinate the angle between the line segment from the center of square $1$ to the center of square $2$ and the $x$-axis. Similarly, the map assigns to the second coordinate the angle between the line segment from the center of square $1$ to the center of square $3$ and the $x$-axis. This is a degree one map $T^2 \\to T^2$. The induced map $(f \\circ i)_*$ is an isomorphism on homology, and so $i_*$ is injective.\n\\end{proof}\n\n\\begin{figure}\n\\centering\n\n\\begin{tikzpicture}[line width=0.25mm,scale=1]\n\\draw (0,0)--(4,0)--(4,4)--(0,4)--cycle;\n\\draw[fill=lightgray] (0,4)--(1,4)--(1,3)--(0,3)--cycle;\n\\draw[fill=gray] (1,3)--(2,3)--(2,2)--(1,2)--cycle;\n\\draw[fill=lightgray] (2,4)--(3,4)--(3,3)--(2,3)--cycle;\n\\draw[fill=gray] (3,3)--(4,3)--(4,2)--(3,2)--cycle;\n\\draw[fill=lightgray] (0,2)--(1,2)--(1,1)--(0,1)--cycle;\n\\draw[fill=gray] (1,1)--(2,1)--(2,0)--(1,0)--cycle;\n\\draw (1,3) circle (0.71);\n\\draw (3,3) circle (0.71);\n\\draw (1,1) circle (0.71);\n\\draw (2,2) circle (1.414);\n\n\\end{tikzpicture}\n\\caption{A map $T^4 \\to \\config{6}{4}{4}$. The three pairs of squares orbit each other in the blue $2 \\times 2$ squares, and these three blue $2 \\times 2$ squares orbit each other in the $4 \\times 4$ square, as in Figure \\ref{fig:322}. The image of this map gives a nontrivial cycle in $H_4 [ \\config{6}{4}{4}]$, realizing the point $(x,y) = (3/8, 1/4)$.}\n\\label{fig:4644}\n\\end{figure}\n\nLemma \\ref{lem:diag} shows that there are infinitely many points realized on the parabola $y = x - x^2$. The following lemma improves on that result, showing that there are infinitely many points realized on the parabola $y = x - (8/9) x^2$.\n\n\\begin{lemma}\nThe point \n$$(x,y) = \\left( \\frac{3}{4k},\\frac{3}{4k}- \\frac{1}{2k^2} \\right)$$\nis attainable for every $k \\ge 1$.\n\\end{lemma}\n\n\\begin{proof}\nThe case $k = 1$ is already covered by \\Cref{lem:14attainable}.\nFor any $k \\ge 2$, we can embed a $(k-1)$-dimensional torus in a $\\config{k}{k}{k}$. Now consider the configuration space $\\config{3k}{2k}{2k}$. We can divide the $2k \\times 2k$ grid into four $k \\times k$ grids. Inside each, we use $k$ squares to embed an $(k-1)$ torus as in the proof of \\Cref{lem:diag}. This describes a $(3k-3)$-torus, and the three $k \\times k$ squares can orbit each other in the $2k \\times 2k$ grid, giving one more dimension. So putting it all together, we have a $(3k-2)$-torus. This realizes the point\n\\[\n(x,y) = \\left( \\frac{3k}{4k^2}, \\frac{3k-2}{4k^2} \\right)=\n\\left( \\frac{3}{4k},\\frac{3}{4k}- \\frac{1}{2k^2} \\right).\n\\]\nThe case $k=2$ is illustrated in Figure~\\ref{fig:4644}, and the case $k=3$ in Figure~\\ref{fig:7966}.\n\\end{proof}\n\n\\begin{lemma}\nThe point $( x,0)$\nis attainable for every rational $x$ with $0 \\le x \\le 1$.\n\\end{lemma}\n\n\\begin{proof}\nIndeed, suppose $x$ is a rational point in $[0,1]$, and write $x = a/b$, where $a$ is a non-negative integer, $b$ is a positive integer, and $a \\le b$. Set $n = ab$ and $p = q= b$. By assumption, we have $a \\le b$, so $n \\le pq $ and the configuration space $\\config{n}{p}{q}$ is nonempty, so $H_0[ \\config{n}{p}{q} ] \\neq 0$.\n\\end{proof}\n\n\\begin{figure}\n\\centering\n\n\\begin{tikzpicture}[line width=0.25mm,scale=2/3]\n\\draw (0,0)--(6,0)--(6,6)--(0,6)--cycle;\n\\draw[fill=lightgray] (0,6)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=gray] (1,5)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=black] (2,4)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (3,6)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=gray] (4,5)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=black] (5,4)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=lightgray] (0,3)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=gray] (1,2)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw[fill=black] (2,1)--++(1,0)--++(0,-1)--++(-1,0)--cycle;\n\\draw (1,5) circle (0.71);\n\\draw (4,5) circle (0.71);\n\\draw (1,2) circle (0.71);\n\\draw (1.75,4.25) circle (1.07);\n\\draw (4.75,4.25) circle (1.07);\n\\draw (1.75,1.25) circle (1.07);\n\\draw (3,3) circle (2.12);\n\n% \\draw [blue,line width=0.7mm] (0,6)--++(3,0)--++(0,-3)--++(-3,0)--cycle;\n% \\draw [blue,line width=0.7mm] (3,6)--++(3,0)--++(0,-3)--++(-3,0)--cycle;\n% \\draw [blue,line width=0.7mm] (0,3)--++(3,0)--++(0,-3)--++(-3,0)--cycle;\n\n\\end{tikzpicture}\n\\caption{A map $T^7 \\to \\config{9}{6}{6}$, realizing the point $(x,y)=(1/4,7/36)$.}\n\\label{fig:7966}\n\\end{figure}\n\nFinally, we show that we can rationally interpolate between all the points we have described.\nLet $S$ be the set of points $$S = \\left\\{ \\left( \\frac{3}{4k},\\frac{3}{4k}- \\frac{1}{2k^2} \\right) \\,\\middle\\vert\\,  k \\ge 1 \\right\\}.$$\nLet $I$ be the closed interval\n$$ I = \\{ (x,y) \\mid 0 \\le  x \\le 1 \\mathrm{\\ and\\ } y \\ge 0 \\}.$$ \n\n\\nonvanish*\n\n\\begin{proof}\nBy Cartheodory's theorem, if $(r_1,r_2)$ is in the convex hull of $S \\cup I$, then $(r_1,r_2)$ is in the convex hull of three points of $S \\cup I$. Write $(r_1,r_2)$ as a rational convex combination of these three points, i.e.,\n\\[\n(r_1,r_2) = \\lambda_1 (u_1, v_1) + \\lambda_2 (u_2, v_2) + \\lambda_3 (u_3,v_3)\n\\]\nwith\n\\begin{enumerate}\n    \\item $(u_1,v_1),(u_2,v_2),(u_3,v_3) \\in S \\cup I$,\n    \\item $0 \\le \\lambda_1, \\lambda_2, \\lambda_3 \\le 1$ with $\\lambda_1 + \\lambda_2 + \\lambda_3 = 1$, and\n    \\item $\\lambda_1, \\lambda_2, \\lambda_3$ all rational.\n\\end{enumerate}\nBy the previous lemmas, $(u_i,v_i)$ is realizable as a nontrivial homology class for hard squares in a square for $i=1, 2, 3$. Let $n_i,p_i, j_i$ be such that $u_i = n_i /p_i^2$ and $v_i = j_i / p_i^2$ for $i=1,2,3$.\nLet $\\lambda_i = a_i / b_i$ for $i=1,2,3$.\nSet \n\\begin{align*}\nP &= p_1p_2p_3,\\\\\nB &= b_1b_2b_3,\\\\\nR &= PB,\n\\end{align*}\nthen let \n\\[N = r_1 R^2 ,\\]\nand \\[J = r_2 R^2.\\]\nIf we can find a nontrivial class in \n\\[H_J [ \\config{N}{R}{R}],\\]\nwe are done.\n\nPartition the $R \\times R$ square into $B^2$ smaller squares, each of dimension $P \\times P$.\nIn a $\\lambda_1$ fraction of these smaller squares (i.e., in $\\lambda_1 B^2 = a_1 b_1 b_2^2 b_3^2$ of them), we realize $(u_1,v_1)$ as follows. Further partition each $P \\times P$ square into $p_2^2 p_3^2$ squares, of dimensions $p_1 \\times p_1$. In each of these squares, we can place $n_1$ squares and can then describe a map from a torus giving a nontrivial class in $H_{j_1} [ \\config{n_1}{p_1}{p_1}]$. So in total, we place \n\\[ (a_1 b_1 b_2^2 b_3^2)(p_2^2 p_3^2)n_1 = (\\lambda_1 B^2) (P^2 / p_1^2) n_1 = \\lambda_1 (n_1 / p_1^2) (P^2 B^2) = \\lambda_1 u_1 R^2\n\\]\nsquares, and get a map from the torus of dimension \n\\[(a_1 b_1 b_2^2 b_3^2)(p_2^2 p_3^2)j_1\n= (\\lambda_1 B^2) (P^2 / p_1^2) j_1 = \\lambda_1 (j_1 / p_1^2) (P^2 B^2) = \\lambda_1 v_1 R^2.\n\\]\n\nSimilarly, in a $\\lambda_2$ fraction of these $P \\times P$ squares we can realize $(u_2, v_2)$, by dividing up into $p_1^2 p_3^2$ smaller squares of dimension $p_2 \\times p_2$, and in a $\\lambda_3$ fraction of the $P \\times P$ squares we realize $(u_3, v_3)$. \n\nAltogether, we have used\n\\[\\lambda_1 u_1 R^2 + \\lambda_2 u_2 R^2 + \\lambda_3 u_3 R^2 = r_1R^2 = N\\]\nsquares, and defined an embedded torus of dimension\n\\[\\lambda_1 v_1 R^2 + \\lambda_2 v_2 R^2 + \\lambda_3 v_3 R^2 = r_2R^2 = J.\\]\nThis describes a cycle in \n\\[H_J [ \\config{N}{P}{P}],\\]\nas desired. The cycle is nontrivial, as before -- we can compose with a map to $T^j$ such that the composed map $T^j \\to T^j$ has degree one.\n\\end{proof}\n\n%!TEX root = ./main.tex\n\n\n\\section{Betti number computations for small $n,p,q$}\\label{sec:computation}\n\nWe compute the Betti numbers $\\beta_j[C(n;p,q)]$ for $n\\leq 6$ and $p\\leq q\\leq n$.  These are provided in Table~\\ref{table:bettis}.  Another view of the Betti numbers for $n=6$ and $j=2$ with  $p$ and $q$ varying is illustrated in Figure~\\ref{fig:n6Betti}.  Finally, in  Table~\\ref{table:fvectors} we record information about the size of the complex $\\cell{n}{p}{q}$ in the form of its \\emph{$f$-vector} $(f_0, f_1, f_2, \\dots)$, where $f_i$ is the number of $i$-dimensional cells in $\\cell{n}{p}{q}$. \nAll of our computations are using coefficients in the prime field $\\Z/2\\Z$.\n\nFor our computations we employ three different software packages, and we dedicate a small section to each one. The first is a Python/Sage Jupyter notebook which uses the discrete Morse vector field of Section~\\ref{sec:dMt}.  The second is a branch of the \\textsc{PyCHomP} package, available at~\\cite{pychomp} specifically for computing the Betti numbers for these configuration spaces. The third is the \\textsc{Dipha} package with a custom script to build the configuration cell complex.\n%\\todo{provide links for both the Sage notebook and the Mathematica notebook generating DIPHA input files.}\nFinally, note that in the case when $n=q$ the configuration space $\\config{n}{p}{q}$ is homotopy equivalent to the configuration space of disks in a strip addressed in~\\cite{AKM19}; in this case, one can use the Salvetti complex to compute the Betti numbers as done in~\\cite{AKM19}.\n\n\\begin{table}[h!]\n\\caption{The Betti numbers of $C(n;p,q)$ for $2 \\le n \\le 6$. The homological liquid regime is indicated in bold.}\n\\begin{tabular}{|c|c|c||c|c|c|c|c|c|} \\hline\n$n$ & $p$ & $q$ & $\\beta_0$ & $\\beta_1$ & $\\beta_2$ & $\\beta_3$ & $\\beta_4$ & $\\beta_5$ \\\\ \\hline\n2 & 2 & 2 & 1 & 1 & 0 & 0 & 0 & 0 \\\\ \\hline\n3 & 2 & 2 & \\textbf{2} & \\textbf{2} & 0 & 0 & 0 & 0 \\\\\n3 & 2 & 3 & 1 & \\textbf{7} & 0 & 0 & 0 & 0 \\\\\n3 & 3 & 3 & 1 & 3 & 2 & 0 & 0 & 0 \\\\ \\hline\n4 & 2 & 2 & \\textbf{24} & 0 & 0 & 0 & 0 & 0 \\\\\n4 & 2 & 3 & 1 & \\textbf{49} & 0 & 0 & 0 & 0 \\\\\n4 & 2 & 4 & 1 & \\textbf{31} & \\textbf{6} & 0 & 0 & 0 \\\\\n4 & 3 & 3 & 1 & \\textbf{12} & \\textbf{11} & 0 & 0 & 0 \\\\\n4 & 3 & 4 & 1 & 6 & \\textbf{29} & 0 & 0 & 0 \\\\\n4 & 4 & 4 & 1 & 6 & 11 & 6 & 0 & 0 \\\\ \\hline\n5 & 2 & 3 & \\textbf{2} & \\textbf{122} & 0 & 0 & 0 & 0 \\\\\n5 & 2 & 4 & 1 & \\textbf{161} & \\textbf{40} & 0 & 0 & 0 \\\\\n5 & 2 & 5 & 1 & \\textbf{111} & \\textbf{110} & 0 & 0 & 0 \\\\\n5 & 3 & 3 & 1 & \\textbf{68} & \\textbf{67} & 0 & 0 & 0 \\\\\n5 & 3 & 4 & 1 & 10 & \\textbf{249} & 0 & 0 & 0 \\\\\n5 & 3 & 5 & 1 & 10 & \\textbf{169} & \\textbf{40} & 0 & 0 \\\\\n5 & 4 & 4 & 1 & 10 & \\textbf{71} & \\textbf{62} & 0 & 0 \\\\\n5 & 4 & 5 & 1 & 10 & 35 & \\textbf{146} & 0 & 0 \\\\\n5 & 5 & 5 & 1 & 10 & 35 & 50 & 24 & 0 \\\\ \\hline\n6 & 2 & 3 & \\textbf{720} & 0 & 0 & 0 & 0 & 0 \\\\\n6 & 2 & 4 & 1 & \\textbf{2241} & \\textbf{80} & 0 & 0 & 0 \\\\\n6 & 2 & 5 & 1 & \\textbf{351} & \\textbf{1790} & 0 & 0 & 0 \\\\\n6 & 2 & 6 & 1 & \\textbf{351} & \\textbf{1160} & \\textbf{90} & 0 & 0 \\\\\n6 & 3 & 3 & 1 & \\textbf{458} & \\textbf{457} & 0 & 0 & 0 \\\\\n6 & 3 & 4 & 1 & 15 & \\textbf{2174} & 0 & 0 & 0 \\\\\n6 & 3 & 5 & 1 & 15 & \\textbf{714} & \\textbf{1429} & 0 & 0 \\\\\n6 & 3 & 6 & 1 & 15 & \\textbf{714} & \\textbf{780} & \\textbf{80} & 0 \\\\\n6 & 4 & 4 & 1 & 15 & \\textbf{441} & \\textbf{457} & \\textbf{30} & 0 \\\\\n6 & 4 & 5 & 1 & 15 & 85 & \\textbf{1541} & \\textbf{30} & 0 \\\\\n6 & 4 & 6 & 1 & 15 & 85 & \\textbf{1066} & \\textbf{275} & 0 \\\\\n6 & 5 & 5 & 1 & 15 & 85 & \\textbf{465} & \\textbf{394} & 0 \\\\\n6 & 5 & 6 & 1 & 15 & 85 & 225 & \\textbf{875} & 0 \\\\\n6 & 6 & 6 & 1 & 15 & 85 & 225 & 274 & 120 \\\\ \\hline\n\\end{tabular}\n\\label{table:bettis}\n\\end{table}\n\n\\begin{figure}\n\n\\centering\n\n\\begin{tikzpicture}[thick]\n\n\\draw [->] (-0.5,-0.5) -- (8,-0.5);\n\\node at (8.5, -0.5) {$p$};\n\n%\\draw[line width = 0.4mm](-0.5,-0.5)--(5.5,-0.5)--(5.5,5.5)--(-0.5,5.5)--cycle;\n\n\\draw[line width = 0.1mm] (-0.5,0.5) -- (8,0.5);\n\\draw[line width = 0.1mm] (-0.5,1.5) -- (8,1.5);\n\\draw[line width = 0.1mm] (-0.5,2.5) -- (8,2.5);\n\\draw[line width = 0.1mm] (-0.5,3.5) -- (8,3.5);\n\\draw[line width = 0.1mm] (-0.5,4.5) -- (8,4.5);\n\\draw[line width = 0.1mm] (-0.5,5.5) -- (8,5.5);\n\\draw[line width = 0.1mm] (-0.5,6.5) -- (8,6.5);\n\\draw[line width = 0.1mm] (-0.5,7.5) -- (8,7.5);\n\n\\draw[line width = 0.1mm] (0.5,-0.5) -- (0.5,8);\n\\draw[line width = 0.1mm] (1.5,-0.5) -- (1.5,8);\n\\draw[line width = 0.1mm] (2.5,-0.5) -- (2.5,8);\n\\draw[line width = 0.1mm] (3.5,-0.5) -- (3.5,8);\n\\draw[line width = 0.1mm] (4.5,-0.5) -- (4.5,8);\n\\draw[line width = 0.1mm] (5.5,-0.5) -- (5.5,8);\n\\draw[line width = 0.1mm] (6.5,-0.5) -- (6.5,8);\n\\draw[line width = 0.1mm] (7.5,-0.5) -- (7.5,8);\n\n\\draw[->]  (-0.5,-0.5) -- (-0.5,8);\n\\node at (-0.5,8.5) {$q$};\n\n\\node at (-3,4) {\\bf  $n=6, \\, j=2$};\n\n\\node at (-1/2, -1) {$0$};\n\\node at (1/2, -1) {$1$};\n\\node at (3/2, -1) {$2$};\n\\node at (5/2, -1) {$3$};\n\\node at (7/2, -1) {$4$};\n\\node at (9/2, -1) {$5$};\n\\node at (11/2, -1) {$6$};\n\\node at (13/2, -1) {$7$};\n\\node at (15/2, -1) {$8$};\n\n\\node at (-1,-1/2) {$0$};\n\\node at (-1,1/2) {$1$};\n\\node at (-1,3/2) {$2$};\n\\node at (-1,5/2) {$3$};\n\\node at (-1,7/2) {$4$};\n\\node at (-1,9/2) {$5$};\n\\node at (-1,11/2) {$6$};\n\\node at (-1,13/2) {$7$};\n\\node at (-1,15/2) {$8$};\n\n\\node at (-1/2,-1/2) {$0$};\n\\node at (1/2,-1/2) {$0$};\n\\node at (3/2,-1/2) {$0$};\n\\node at (5/2,-1/2) {$0$};\n\\node at (7/2,-1/2) {$0$};\n\\node at (9/2,-1/2) {$0$};\n\\node at (11/2,-1/2) {$0$};\n\\node at (13/2,-1/2) {$0$};\n\\node at (15/2,-1/2) {$0$};\n\n\\node at (-1/2,1/2) {$0$};\n\\node at (-1/2,3/2) {$0$};\n\\node at (-1/2,5/2) {$0$};\n\\node at (-1/2,7/2) {$0$};\n\\node at (-1/2,9/2) {$0$};\n\\node at (-1/2,11/2) {$0$};\n\\node at (-1/2,13/2) {$0$};\n\\node at (-1/2,15/2) {$0$};\n\n\\node at (1/2,1/2) {$0$};\n\\node at (3/2,1/2) {$0$};\n\\node at (5/2,1/2) {$0$};\n\\node at (7/2,1/2) {$0$};\n\\node at (9/2,1/2) {$0$};\n\\node at (11/2,1/2) {$0$};\n\\node at (13/2,1/2) {$0$};\n\\node at (15/2,1/2) {$0$};\n\n\\node at (1/2,-1/2) {$0$};\n\\node at (3/2,-1/2) {$0$};\n\\node at (5/2,-1/2) {$0$};\n\\node at (7/2,-1/2) {$0$};\n\\node at (9/2,-1/2) {$0$};\n\\node at (11/2,-1/2) {$0$};\n\\node at (13/2,-1/2) {$0$};\n\\node at (15/2,-1/2) {$0$};\n\n\\node at (1/2,3/2) {$0$};\n\\node at (3/2,3/2) {$0$};\n\\node at (5/2,3/2) {$0$};\n\\node at (7/2,3/2) {$\\bf 80$};\n\\node at (9/2,3/2) {$\\bf 1790$};\n\\node at (11/2,3/2) {$\\bf 1160$};\n\\node at (13/2,3/2) {$\\bf 1160$};\n\\node at (15/2,3/2) {$\\bf 1160$};\n\n\\node at (1/2,5/2) {$0$};\n\\node at (3/2,5/2) {$0$};\n\\node at (5/2,5/2) {$\\bf 457$};\n\\node at (7/2,5/2) {$\\bf 2174$};\n\\node at (9/2,5/2) {$\\bf 714$};\n\\node at (11/2,5/2) {$\\bf 714$};\n\\node at (13/2,5/2) {$\\bf 714$};\n\\node at (15/2,5/2) {$\\bf 714$};\n\n\\node at (1/2,7/2) {$0$};\n\\node at (3/2,7/2) {$\\bf 80$};\n\\node at (5/2,7/2) {$\\bf 2174$};\n\\node at (7/2,7/2) {$\\bf 441$};\n\\node at (9/2,7/2) {$85$};\n\\node at (11/2,7/2) {$85$};\n\\node at (13/2,7/2) {$85$};\n\\node at (15/2,7/2) {$85$};\n\n\\node at (1/2,9/2) {$0$};\n\\node at (3/2,9/2) {$\\bf 1790$};\n\\node at (5/2,9/2) {$\\bf 714$};\n\\node at (7/2,9/2) {$85$};\n\\node at (9/2,9/2) {$85$};\n\\node at (11/2,9/2) {$85$};\n\\node at (13/2,9/2) {$85$};\n\\node at (15/2,9/2) {$85$};\n\n\\node at (1/2,11/2) {$0$};\n\\node at (3/2,11/2) {$\\bf 1160$};\n\\node at (5/2,11/2) {$\\bf 714$};\n\\node at (7/2,11/2) {$85$};\n\\node at (9/2,11/2) {$85$};\n\\node at (11/2,11/2) {$85$};\n\\node at (13/2,11/2) {$85$};\n\\node at (15/2,11/2) {$85$};\n\n\\node at (1/2,13/2) {$0$};\n\\node at (3/2,13/2) {$\\bf 1160$};\n\\node at (5/2,13/2) {$\\bf 714$};\n\\node at (7/2,13/2) {$85$};\n\\node at (9/2,13/2) {$85$};\n\\node at (11/2,13/2) {$85$};\n\\node at (13/2,13/2) {$85$};\n\\node at (15/2,13/2) {$85$};\n\n\\node at (1/2,15/2) {$0$};\n\\node at (3/2,15/2) {$\\bf 1160$};\n\\node at (5/2,15/2) {$\\bf 714$};\n\\node at (7/2,15/2) {$85$};\n\\node at (9/2,15/2) {$85$};\n\\node at (11/2,15/2) {$85$};\n\\node at (13/2,15/2) {$85$};\n\\node at (15/2,15/2) {$85$};\n\n%\\draw[blue, line width = 1mm]  (1,8)--(1,3)--(2,3)--(2,2)--(3,2)--(3,1)--(8,1);\n%\\draw[blue, line width = 1mm]  (3,8)--(3,4)--(4,4)--(4,3)--(8,3);\n\\end{tikzpicture}\n\\caption{Another view of the Betti numbers. Let $n=6$ and $j=2$, and let $p$ and $q$ be the horizontal and vertical axes. Then the solid regime is in the lower left, the gas regime is in the upper right, and the liquid regime (in bold) is in between. If $p \\ge n$, then the inclusion map $\\config{n}{p}{q} \\hookrightarrow \\config{n}{p+1}{q}$ induces an isomorphism on homology. Similarly, if $q \\ge n$ then the inclusion map $\\config{n}{p}{q} \\hookrightarrow \\config{n}{p}{q+1}$ induces an isomorphism on homology.}\\label{fig:n6Betti}\n\\end{figure}\n\n\\begin{table}[h!]\n\\centering\\tiny\n\\begin{tabular}{|c|c|c||c|c|c|c|c|c|c|c|c|} \\hline\n$n$ & $p$ & $q$ & $f_0$ & $f_1$ & $f_2$ & $f_3$ & $f_4$ & $f_5$ & $f_6$ & $f_7$ & $f_8$ \\\\ \\hline\n2 & 2 & 2 & 12 & 16 & 4 & & & & & & \\\\ \\hline\n3 & 2 & 2 & 24 & 24 &  & & & & & & \\\\ \n3 & 2 & 3 & 120 & 252 & 144  & 18 & & & & & \\\\ \n3 & 3 & 3 & 504 & 1512 & 1560 & 624 & 72 & & & & \\\\ \\hline\n4 & 2 & 3 & 360 & 672 & 264  & & & & & & \\\\ \n4 & 2 & 4 & 1680 & 4800 & 4464 & 1488 & 120 & & & & \\\\ \n4 & 3 & 3 & 3024 & 10080 & 11520 & 5184 & 720 & & & &  \\\\ \n4 & 3 & 4 & 11880 & 48960 & 76608 & 56448 & 19536 & 2688 & 96 & &\\\\ \n4 & 4 & 4 & 43680 & 209664 & 402336 & 393120 & 206232 & 56640 & 7728 & 576 & 24 \\\\ \\hline \n5 & 2 & 3 & 720 & 840 &  &  &  &  &  &  &  \\\\  \n5 & 2 & 4 & 6720 & 18000 & 14280 & 3120 &  &  &  &  &  \\\\  \n5 & 2 & 5 & 30240 & 109200 & 141600 & 79200 & 17520  &  960 &  &  &  \\\\ \n5 & 3 & 3 & 15120 & 50400 & 55200 & 22080 & 2160  &   &  &  &  \\\\ \n5 & 3 & 4 & 95040 & 428400 & 735840 & 600600 & 234720  &  38040 & 1680 &  &  \\\\ \n5 & 3 & 5 & 360360 & 1887600 & 3979800 & 4322880 & 2561160  &  800400 & 114960 & 5280 &  \\\\ \n5 & 4 & 4 & 524160 & 2882880 & 6448200 & 7538400 & 4928640  &  1793280 & 345240 & 33120 & 1440 \\\\ \\hline\n6 & 3 & 3 & 60480 & 181440 & 161280 & 40320 &&&&& \\\\ \\hline\n\\end{tabular}\n\\bigskip\n\\caption{The $f$-vectors for $\\cell{n}{p}{q}$ for small $n, p, q$.}\n\\label{table:fvectors}\n\\end{table}\n\n%\\todo{make this table fit into the page width. rotate?\n%[uli] I made the font tiny instead}\n\n\\subsection{Discrete Morse Theory Sage Notebook}\n\n%\\todo{add a description of Hannah's code\n%for any n:\n%-list all ways way of placing n squares in an n x n grid\n%-check which arrangements are the apex of a critical cell (wrt our %gradient)\n%-compute boundary coefficients in the morse complex by applying %(discrete) gradient flow to the boundaries of critical cells\n%-restrict to smaller rectangles (p x q), producing subcomplexes of the %morse complex\n%-for each p x q, compute betti numbers via the ranks of boundary matrices %and dimensions of chain groups\n%}\nUsing the discrete gradient vector field from Section~\\ref{sec:dMt}, we compute the collapsed Morse chain complex for $\\cell{n}{p}{q}$ as follows.  The idea is first to find the critical cells and then to compute their boundaries in the Morse complex.  However, it turns out that most of this process depends very little on $p$ and $q$.  Thus, in order to compute for various $p$ and $q$ without duplicating effort, we first compute the Morse complex for $\\cell{n}{n}{n}$.  The Morse complex of each $\\cell{n}{p}{q}$ for $1 \\leq p, q \\leq n$ turns out to be a subcomplex of the Morse complex for $\\cell{n}{n}{n}$, obtained by selecting only the critical cells for which the apex is in the $p$ by $q$ rectangle.  This is because of the properties of our discrete gradient vector field.  Namely, we know that if a cell's apex fits into a $p$ by $q$ rectangle, so does every boundary cell of that cell (the apex takes upper right corners, and the $p$ by $q$ rectangle grows from the lower left); together with the fact that every two paired cells have the same apex, this implies that the $\\cell{n}{p}{q}$ Morse complex is a subcomplex of the $\\cell{n}{p'}{q'}$ Morse complex whenever $p \\leq p'$ and $q \\leq q'$.  The construction of the discrete gradient vector field guarantees that no apex that skips a row or column can be the apex of a critical cell---this is because every apex graph with an isolated vertex has an even number of independent sets---so the $\\cell{n}{n}{n}$ Morse complex is sufficiently large to contain the Morse complexes for all $\\cell{n}{p}{q}$.\n\nThus, the code computes as follows.  First, we list all ways of placing $n$ squares in an $n$ by $n$ grid.  Then, we check which of these arrangements are the apex of a critical cell.  For each critical cell, we compute its boundary in the Morse complex by applying discrete gradient flow to its original boundary in $\\cell{n}{n}{n}$.  Doing this for every critical cell gives all boundary coefficients for the Morse complex of $\\cell{n}{n}{n}$, computed as integers with signs.  Then we restrict to smaller $p$ by $q$ rectangles, producing subcomplexes of the Morse complex.  For each $p$ and $q$, we compute the Betti numbers from the ranks of the boundary matrices and the dimensions of the chain groups; because the matrices have integer entries, to specify the coefficient field for homology, we only need to specify the field for the rank computation, which can be done over $\\mathbb{Q}$ or modulo any choice of prime.\nThe Sage notebook is available online.\\footnote{The Sage notebook containing the described code can be found at \\url{https://gist.github.com/ubauer/87e7ee1462966127e9837c4747829a4a}.}\n\nWe found that the code runs quickly for $n \\leq 5$ and agrees with our other computation methods; for $n \\leq 6$ it becomes slow and would require more speed optimization.\n\n\\subsection{PyCHomP}\n\nWe briefly review the computations involved in \\textsc{PyCHomP}, which may be used to compute the homology of $\\cell{n}{p}{q}$ with $\\Z/2\\Z$ coefficients.\n\nLet $(P,\\leq)$ be the total order with $P=\\{0,1\\}$ and $0\\leq 1$.  As $\\cell{n}{p}{q}$ is a subcomplex of $\\ambient{n}{p}{q}$, there is an order-preserving map $\\nu$ from the face poset $(\\ambient{n}{p}{q},\\leq)$ to $(P,\\leq)$ given by\n\\[\n\\nu(\\sigma) = \n\\begin{cases}\n    0 & \\text{ if $\\sigma \\in \\cell{n}{p}{q}$ } \\\\\n    1 & \\text{ if $\\sigma \\not\\in \\cell{n}{p}{q}$.}\n\\end{cases}\n\\]\n\nIn order to construct the map $\\nu$, we use Lemma~\\ref{lem-partial-cell} to determine whether a cell belongs to the cubical complex $\\cell{n}{p}{q}$. The complex $\\ambient{n}{p}{q}$ together with the map $\\nu$ defines a $P$-graded cell complex (see~\\cite{HMS19}).   \\textsc{PyCHomP} uses iterated algebraic-discrete Morse theory to reduce $\\ambient{n}{p}{q}$ to a (chain-homotopy equivalent) $P$-graded cell complex $(A(n;p,q),\\mu)$ characterized by the condition that\n$\\partial^A|_{\\mu^{-1}(p)}=0$ for $p\\in P$.  This condition implies that the $j$-dimensional Betti number of $\\cell{n}{p}{q}$ is precisely the number of $j$-dimensional cells in $\\mu^{-1}(0)$; see~\\cite[Example 4.30]{HMS19} for more detail.\n\nTheorems~\\ref{thm:hv:pq-n}--\\ref{thm:pq3} suggest that speed ups can be obtained for any code which computes homology starting from the complex $\\cell{n}{p}{q}$ by not considering cells above a certain dimension.  The branch of \\textsc{PyCHomP} available at~\\cite{pychomp} incorporates these speed-ups; \\textsc{PyCHomP} is able to compute the Betti numbers for all the examples in Table~\\ref{table:bettis}.  A Jupyter notebook which sets up the computation of Betti numbers for $\\cell{n}{p}{q}$ is available online.\\footnote{The Jupyter notebook can be found at \\url{https://github.com/kellyspendlove/pyCHomP/blob/config/doc/config/ConfigSpacePaper.ipynb}.}\n\n\\subsection{DIPHA}\n\nFinally, we describe the homology computation of $\\cell{n}{p}{q}$ using \\textsc{Dipha}, a software package for computing persistent homology in a distributed setting \\cite{Bauer2014Distributed}.\n\\textsc{Dipha} supports the computation of persistent homology for \\emph{lower star filtrations} of cubical grids such as $\\ambient{n}{p}{q}$. The data determining a lower star filtration is a real-valued function $f$ on the vertices of $\\ambient{n}{p}{q}$, i.e., the integer points in $([1, p] \\times [1, q])^n$.\nThe filtration then consists of the full subcomplexes of the ambient cube complex $\\ambient{n}{p}{q}$ induced by sublevel sets $f^{-1}(-\\infty,t]$ of the function~$f$.\n\nOur computations make use of the fact that $\\cell{n}{p}{q}$ is a full subcomplex of the ambient cube complex $\\ambient{n}{p}{q}$ (see Corollary~\\ref{cor-full-subcomplex}).\nIn other words, the complex $\\cell{n}{p}{q}$ is determined by the set of all configurations in $\\config{n}{p}{q}$ with integer coordinates.\nThus, it suffices to enumerate all permutations of all $n$-element subsets of the $p \\times q$ possible integer coordinates for the cubes.\nThe input to \\textsc{Dipha} consists of the characteristic function of this set as a subset of all vertices of $\\ambient{n}{p}{q}$.\nA Mathematica file for generating the input to \\textsc{Dipha} is available online.\\footnote{The Mathematica notebook for generating the \\textsc{Dipha} input can be found at \\url{https://gist.github.com/ubauer/01934ad494eeb6e9ef66ca14e0301fe9}.}\n\n\n\n\n%%%% No longer needed\n% \\begin{table}\n% \\caption{Initial data for $n=4$.}\n% \\centering\n% \\begin{tabular}{c c c p{100mm}}\n% \\toprule\n%  {$(p,q)$}   & {Dim. } & {  Cells } & { $f$-polynomial  } \\\\\n% \\midrule\n% (2,3) & 2 & 1296  & $360t^0+672t^1+264t^2$ \\\\\n% (2,4) & 4 & 12552 & $1680t^0+4800t^1+4464t^2+1488t^3+120t^4$ \\\\\n% (3,3) & 4 & 30528 & $3024t^0+10080t^1+11520t^2+5184t^3+720t^4$ \\\\\n% (3,4) & 6 & 216216 & $11880t^0+48960t^1+76608t^2+56448t^3+19536t^4+2688t^5+96t^6$  \\\\\n% (4,4) & 8  & 1320000 & $43680t^0+209664t^1+402336t^2+393120t^3+206232t^4+56640t^5+7728t^6+576t^7+24t^8$ \\\\\n% % \\addlinespace[-2ex]\n% % $Q = \\begin{bmatrix}  0.1 & 0 \\\\ 0 &  0.1 \\end{bmatrix}$ &\n% % $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\\\\\n% % \\addlinespace[1.5ex]\n% % $R = 5 \\times 10^{-3}$ & $R = 5 \\times 10^{-5}$ \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n4:init}\n% \\end{table}\n\n\n\n\n% \\begin{table}[t]\n% \\caption{Experimental results for $n=4$.}\n% \\setlength{\\tabcolsep}{15pt}\n% \\centering\n% \\begin{tabular}{c c c} % @{} serves to suppress white space at ends of table\n% \\toprule\n% %   &  \\multicolumn{4}{c @{}}{Data for Configuration spaces with $n=4$ }\\\\ \n% \\cmidrule(l){1-3}\n%  {$(p,q)$}    & {\\# Tower} & { Timing  } \\\\\n% \\midrule\n% (2,3) &   3  & 70.8 (ms)  \\\\\n% (2,4) &   3   & 320 (ms)  \\\\\n% (3,3) &   4   & 694 (ms)   \\\\\n% (3,4) &   4   & 2.59 (s)   \\\\\n% (4,4) &   5   & 10.1 (s)   \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n4:results}\n% \\end{table}\n\n% \\begin{table}\n% \\caption{$f$-polynomial for first Morse Complex; $n=4$.}\n% \\centering\n% \\begin{tabular}{c  p{50mm}}\n% \\toprule\n%  {$(p,q)$}   & {$f$-polynomial } \\\\\n% \\midrule\n% (2,3) &   $48t^0+96t^1$ \\\\\n% (2,4) &   $72t^0+192t^1+96t^2$ \\\\\n% (3,3) &   $72t^0+224t^1+176t^2+24t^3$  \\\\\n% (3,4) &   $96t^0+320t^1+320t^2+72t^3$  \\\\\n% (4,4) &   $120t^0+416t^1+464t^2+168t^3$  \\\\\n% % \\addlinespace[-2ex]\n% % $Q = \\begin{bmatrix}  0.1 & 0 \\\\ 0 &  0.1 \\end{bmatrix}$ &\n% % $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\\\\\n% % \\addlinespace[1.5ex]\n% % $R = 5 \\times 10^{-3}$ & $R = 5 \\times 10^{-5}$ \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n4:fvec}\n% \\end{table}\n\n%%%%%% no longer needed???\n% \\begin{table}\n% \\caption{Initial data for $n=5$.}\n% \\centering\n% \\begin{tabular}{c c c p{100mm}}\n% \\toprule\n%  {$(p,q)$}   & {Dim. } & {  Cells } & { $f$-polynomial  } \\\\\n% \\midrule\n% (2,3)   & 1 & ~1560 & $720t^0+840t^1$  \\\\\n% (2,4)   & 3 & ~42120 & $6720t^0+18000t^1+14280t^2+3120t^3$  \\\\\n% (2,5)   & 5 & ~378720 & $30240t^0+109200t^1+141600t^2+79200t^3+17520t^4+960t^5$  \\\\\n% (3,3) & 4 & ~144960 & $15120t^0+50400t^1+55200t^2+22080t^3+2160t^4$ \\\\\n% (3,4) & 6 & ~2134320  & $95040t^0+428400t^1+735840t^2+600600t^3+234720t^4+38040t^5+1680t^6$ \\\\\n% (3,5) & 7 & ~14032440 &  $360360t^0+1887600t^1+3979800t^2+4322880t^3+2561160t^4+800400t^5+114960t^6+5280t^7$ \\\\\n% (4,4) & 8 & ~24495360 & $524160t^0+2882880t^1+6448200t^2+7538400t^3+4928640t^4+1793280t^5+345240t^6+33120t^7+1440t^8$ \\\\\n% (4,5) & 9 & ~138650040 &  $1860480t^0+11383200t^1+29164800t^2+40622400t^3+33417120t^4+16531200t^5+4815360t^6+785760t^7+67200t^8+2520t^9$ \\\\\n% (5,5) & 9 & 714641280 & $6375600t^0+42504000t^1+120976800t^2+191903040t^3+185776680t^4+113030400t^5+42955200t^6+9816000t^7+1236360t^8+67200t^9$    \\\\\n% % \\addlinespace[-2ex]\n% % $Q = \\begin{bmatrix}  0.1 & 0 \\\\ 0 &  0.1 \\end{bmatrix}$ &\n% % $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\\\\\n% % \\addlinespace[1.5ex]\n% % $R = 5 \\times 10^{-3}$ & $R = 5 \\times 10^{-5}$ \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n5:init}\n% \\end{table}\n\n\n% \\begin{table}[t]\n% \\caption{Experimental results for $n=4$.}\n% \\setlength{\\tabcolsep}{15pt}\n% \\centering\n% \\begin{tabular}{c c c} % @{} serves to suppress white space at ends of table\n% \\toprule\n% %   &  \\multicolumn{4}{c @{}}{Data for Configuration spaces with $n=4$ }\\\\ \n% \\cmidrule(l){1-3}\n%  {$(p,q)$}   & {\\# Tower} & { Timing  } \\\\\n% \\midrule\n% (2,3)   & 3  &  1.15 (s)  \\\\\n% (2,4)   & 4  &  5.92(s)  \\\\\n% (2,5)   & 5  & 21.3 (s)  \\\\\n% (3,3)   & 7  &  13 (s)   \\\\\n% (3,4)   & 9  &  1min 13s    \\\\\n% (3,5)   & 9  &   4min 36s   \\\\\n% (4,4)   & 17 &  6min 18s  \\\\\n% (4,5)   & 16 &     \\\\\n% (5,5)   & 21  &  1h 29min   \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n5:results}\n% \\end{table}\n\n% \\begin{table}\n% \\caption{$f$-polynomial for first Morse complex; $n=5$.}\n% \\centering\n% \\begin{tabular}{c  p{75mm}}\n% \\toprule\n%  {$(p,q)$}   & {$f$-polynomial } \\\\\n% \\midrule\n% (2,3) &   $120t^0+240t^1$ \\\\\n% (2,4) &   $240t^0+960t^1+600t^2$ \\\\\n% (2,5) &   $360t^0+1560t^1+1560t^2+360t^3$ \\\\\n% (3,3) &   $360t^0+1280t^1+960t^2+40t^3$  \\\\\n% (3,4) &   $480t^0+2160t^1+2960t^2+1040t^3$  \\\\\n% (3,5) &  $600t^0+2760t^1+4160t^2+2000t^3+120t^4$   \\\\\n% (4,4) &  $600t^0+3040t^1+5080t^2+3120t^3+480t^4$   \\\\\n% (4,5) &  $720t^0+3640t^1+6280t^2+4320t^3+840t^4$  \\\\\n% (5,5) &  $840t^0+4240t^1+7480t^2+5520t^3+1440t^4$  \\\\\n% % \\addlinespace[-2ex]\n% % $Q = \\begin{bmatrix}  0.1 & 0 \\\\ 0 &  0.1 \\end{bmatrix}$ &\n% % $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\\\\\n% % \\addlinespace[1.5ex]\n% % $R = 5 \\times 10^{-3}$ & $R = 5 \\times 10^{-5}$ \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n5:fvec}\n% \\end{table}\n\n\n% \\begin{table}[t]\n% \\setlength{\\tabcolsep}{10pt}\n% \\centering\n% \\begin{tabular}{@{} l SSSSSSSS @{}} % @{} serves to suppress white space at ends of table\n% \\toprule\n% %   &  \\multicolumn{4}{c @{}}{Data for Configuration spaces with $n=4$ }\\\\ \n% \\cmidrule(l){1-5}\n%  {$(p,q)$}   & {Dim. } & { \\# Cells } & {\\# Reductions} & { Timing  } \\\\\n% \\midrule\n% (2,3)   & 1 & ~1560 &  1.15 (s)  \\\\\n% (2,4)   & 3 & ~42120 &  5.92(s)  \\\\\n% (2,5)   & 5 & ~378720 &  21.3 (s)  \\\\\n% (3,3) & 4 & ~144960 &  13 (s)   \\\\\n% (3,4) & 6 & ~2134320  &  1min 13s    \\\\\n% (3,5) & 7 & ~14032440 &   4min 36s   \\\\\n% (4,4) & 8 & ~24495360 &  6min 18s  \\\\\n% (4,5) & 9 & ~138650040 &     \\\\\n% (5,5) &  &  &     \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\caption{Data for Configuration space for $n=5$.}\n% \\label{tab:n5}\n% \\end{table}\n\n\n\n%%%% no longer needed??\n% \\begin{table}\n% \\caption{Initial data for $n=6$.}\n% \\centering\n% \\begin{tabular}{c c c p{100mm}}\n% \\toprule\n%  {$(p,q)$}   & {Dim. } & {  Cells } & { $f$-polynomial  } \\\\\n% \\midrule\n% (3,3) & 3 & 443520 & $60480t^0+181440t^1+161280t^2+40320t^3$\n%      \\\\\n% (3,4) & 6 & 15427440 & $665280t^0+3084480t^1+5382720t^2+4384800t^3+1658880t^4+243360t^5+7920t^6$ \\\\\n% (4,4) &  &  &     \\\\\n% (4,5) &  &  &     \\\\\n% (5,5) &  &  &     \\\\\n% (6,5) &  &  &     \\\\\n% (6,6) &  &  &     \\\\\n% % \\addlinespace[-2ex]\n% % $Q = \\begin{bmatrix}  0.1 & 0 \\\\ 0 &  0.1 \\end{bmatrix}$ &\n% % $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\\\\\n% % \\addlinespace[1.5ex]\n% % $R = 5 \\times 10^{-3}$ & $R = 5 \\times 10^{-5}$ \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n5:init}\n% \\end{table}\n\n\n\n% \\begin{table}[t]\n% \\caption{Data for Configuration space for $n=6$.}\n% \\setlength{\\tabcolsep}{10pt}\n% \\centering\n% \\begin{tabular}{c c c} % @{} serves to suppress white space at ends of table\n% \\toprule\n% %   &  \\multicolumn{4}{c @{}}{Data for Configuration spaces with $n=4$ }\\\\ \n% \\cmidrule(l){1-3}\n%  {$(p,q)$}   & {\\# Tower} & {  Timing   }\\\\\n% \\midrule\n% (3,3) &  12 &   5min 42s    \\\\\n% (3,4) &  27 &  41min 14s  \\\\\n% (4,4) &   &     \\\\\n% (4,5) &   &     \\\\\n% (5,5) &   &     \\\\\n% (6,5) &   &     \\\\\n% (6,6) &   &     \\\\\n% \\bottomrule\n% \\end{tabular}\n% \\label{tab:n6:results}\n% \\end{table}\n \n\n\n\\bibliographystyle{plain}\n\\bibliography{refs}\n%\\nocite{*}\n\n\\todos\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:44", "yymm": "2010", "arxiv_id": "2010.14480", "url": "https://arxiv.org/abs/2010.14480", "source": "arxiv"}}
{"text": "% Template for ICASSP-2019 paper; to be used with:\n%          spconf.sty  - ICASSP/ICIP LaTeX style file, and\n%          IEEEbib.bst - IEEE bibliography style file.\n% --------------------------------------------------------------------------\n\\documentclass{article}\n\\usepackage{spconf}\n\n%\\\\\\\\ PACKAGES\n\n% Language\n\\usepackage[english]{babel}\n\n% Utilities\n\\usepackage{ifpdf}\n\n% Citation and Linking\n\\usepackage{cite} % Orders citations.\n\\usepackage{url}\n\\usepackage{hyperref}\n\n% Graphics\n\\usepackage[pdftex]{graphicx}\n\\graphicspath{{./figures/}}\n\\usepackage{color}\n\\usepackage{pgf, tikz, pgfplots}\n\\usetikzlibrary{shapes, arrows, automata, plotmarks}\n\\usetikzlibrary{calc,hobby,decorations}\n%    \\pgfplotsset{compat=1.15}\n%\\usepackage[caption=false,font=footnotesize]{subfig}\n%\\usepackage{fixltx2e}\n%\\usepackage{stfloats}\n%\\usepackage{dblfloatfix}\n\n% Math\n\\usepackage[cmex10]{amsmath}\n\\usepackage{amsfonts, amssymb, amsthm}\n\\usepackage{mathrsfs}\n%\\usepackage{upgreek}\n% \\usepackage{theorem} % OBS: \"Enhancements to LATEX's theorem environments, giving more choice in theorem layout. This package is no longer recommended by its author; he suggests users should use the AMS LATEX amsthm package instead; another widely-used alternative is ntheoremq.\" https://www.ctan.org/pkg/theorem?lang=en 2015-08-04\n\n% Lists\n%\\usepackage{algorithm,algorithmic}\n%\\usepackage[]{algorithm2e}\n\\usepackage{algorithm,algpseudocode}\n\\algnewcommand{\\LeftComment}[1]{\\Statex \\(\\triangleright\\) #1}\n\n% Alignment\n\\usepackage[margin=15mm]{geometry}\n%\\usepackage{array}\n\\usepackage{enumerate}\n%\\usepackage{caption}\n\\usepackage{multirow}\n\\usepackage{rotating}\n\\usepackage{subcaption}\n\\captionsetup[sub]{font=footnotesize}\n\\captionsetup[figure]{font=small,labelsep=period,subrefformat=parens}\n\n%\\addtolength{\\textwidth}     {5mm}\n%\\addtolength{\\evensidemargin}{-5mm}\n%\\addtolength{\\oddsidemargin} {-5mm}\n%\\addtolength{\\textheight}    {5mm}\n%\\addtolength{\\topmargin}     {-5mm}\n%\n%\\def\\interparagraph{0mm}\n%\\def\\intersection{-1mm}\n%\\def\\belowfigure{-4mm}\n%\n%\\linespread{0.99}\n\n% correct bad hyphenation here\n\\hyphenation{op-tical net-works semi-conduc-tor}\n\n% Definitions\n\\definecolor{penndarkestblue}{cmyk}{1,0.74,0,0.77}\n\t% RGB = (0,15,58); #000f3a\n\\definecolor{penndarkerblue}{cmyk}{1,0.74,0,0.70}\n\t% RGB = (0,20,77); #00144d\n\\definecolor{pennblue}{cmyk}{0.99,0.66,0,0.57} \n\t% RGB = (1,37,110) ; #01256e\n\\definecolor{pennlighterblue}{cmyk}{0.98,0.44,0,0.35}\n\t% RGB = (4,94,167); #045ea7\n\\definecolor{pennlightestblue}{cmyk}{0.38,0.17,0,0.17} \n\t% RGB = (130,175,211); #82afd3\n\n\\definecolor{penndarkestred}{cmyk}{0,1,0.89,0.66}\n\t% RGB = (87,0,10); #57000a\n\\definecolor{penndarkerred}{cmyk}{0,1,0.88,0.55}\n\t% RGB = (116,0,14); #74000e\n\\definecolor{pennred}{cmyk}{0,1,0.83,0.42} \n\t% RGB = (149,0,26); #95001a\n\\definecolor{pennlighterred}{cmyk}{0,1,0.6,0.24}\n\t% RGB = (194,0,77); #c2004d\n\\definecolor{pennlightestred}{cmyk}{0,0.43,0.26,0.12} \n\t% RGB = (225,128,166); #e180a6\n\n\\definecolor{penndarkestgreen}{cmyk}{1,0,1,0.68}\n\t% RGB = (0,82,0); #005200\n\\definecolor{penndarkergreen}{cmyk}{1,0,1,0.57}\n\t% RGB = (0,110,0); #006e00\n\\definecolor{penngreen}{cmyk}{1,0,1,0.44} \n\t% RGB = (0,142,0); #008e00\n\\definecolor{pennlightergreen}{cmyk}{1,0,1,0.25}\n\t% RGB = (0,190,0); #00be00\n\\definecolor{pennlightestgreen}{cmyk}{0.43,0,0.43,0.13}\n\t% RGB = (128,223,128); #80df80\n\n\\definecolor{penndarkestorange}{cmyk}{0,0.65,1,0.49}\n\t% RGB = (129,45,0); #812d00\n\\definecolor{penndarkerorange}{cmyk}{0,0.65,1,0.33}\n\t% RGB = (172,60,0); #ac3c00\n\\definecolor{pennorange}{cmyk}{0,0.54,1,0.24} \n\t% RGB = (195,90,0); #c35a00\n\\definecolor{pennlighterorange}{cmyk}{0,0.32,1,0.13}\n\t% RGB = (223,151,0); #df9700\n\\definecolor{pennlightestorange}{cmyk}{0,0.15,0.46,0.06}\n\t% RGB = (239,203,128); #efcb80\n\t\n\\definecolor{penndarkestpurple}{cmyk}{0,1,0.11,0.86}\n\t% RGB = (35,0,31); #23001f\n\\definecolor{penndarkerpurple}{cmyk}{0,1,0.13,0.82}\n\t% RGB = (47,0,41); #2f0029\n\\definecolor{pennpurple}{cmyk}{0,1,0.11,0.71} \n\t% RGB = (74,0,66); #4a0042\n\\definecolor{pennlighterpurple}{cmyk}{0,1,0.05,0.46}\n\t% RGB= (137,0,130); #890082\n\\definecolor{pennlightestpurple}{cmyk}{0,0.35,0.02,0.23}\n\t% RGB = (196,128,193); #c480c1\n\t\n\\definecolor{pennyellow}{cmyk}{0,0.20,1,0.05} \n\t% RGB = (242,193,0); #f2c100\n\\definecolor{pennlightgray1}{cmyk}{0,0,0,0.05}\n\t% RGB = (242,242,243); #f2f2f3\n\\definecolor{pennlightgray3}{cmyk}{0.01,0.01,0,0.18}\n\t% RGB = (207,208,210); #cfd0d2\n\\definecolor{pennmediumgray1}{cmyk}{0.04,0.03,0,0.31}\n\t% RGB = (168,170,175); #a8aaaf\n\\definecolor{pennmediumgray4}{cmyk}{0.08,0.06,0,0.54}\n\t% RGB = (108,111,118); #6c6f76\n\\definecolor{penndarkgray2}{cmyk}{0.09,0.07,0,0.71}\n\t% RGB = (68,70,75); #44464b\n\\definecolor{penndarkgray4}{cmyk}{0.1,0.1,0,0.92}\n\t% RGB = (19,19,21); #131315\n \\usepackage{needspace}\n\n% \\nbsubsubsection{} provides a numbered subsection in bold without a line break. The section will contain at least three lines of text before a pagebreak\n\\newcommand{\\nbsubsubsection}[1]{\\needspace{1\\baselineskip}\\color{white}\\subsubsection{#1}\\vspace{-3\\baselineskip}\\color{black}\\medskip{\\noindent \\bf \\thesubsubsection. #1.}}\n\n% \\myparagraph provides a paragraph title in italics. \n\\newcommand{\\myparagraph}[1]{\\needspace{1\\baselineskip}\\medskip\\noindent {\\bf #1}}\n\n% \\myindenetedparagraph provides an indented paragraph with title in italics.\n\\newcommand{\\myindentedparagraph}[1]{\\needspace{1\\baselineskip}\\medskip \\hangindent=11pt \\hangafter=0 \\noindent{\\it #1.}}\n\n% \\myparagraphtc provides a paragraph title in italics. It adds an enter to the table of contents\n\\newcommand{\\myparagraphtc}[1]{\\needspace{1\\baselineskip}\\medskip\\noindent {\\it #1.}\\addcontentsline{toc}{subsubsection}{\\qquad\\qquad\\quad#1}}\n\n \n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%theorem environments\n%\\newtheorem{assumption}{\\hspace{0pt}\\bf AS\\hspace{-0.15cm}}\n%\\newtheorem{lemma}{\\hspace{0pt}\\bf Lemma}\n%\\newtheorem{proposition}{\\hspace{0pt}\\bf Proposition}\n%\\newtheorem{observation}{\\hspace{0pt}\\bf Observation}\n%\\newtheorem{theorem}{\\hspace{0pt}\\bf Theorem}\n%\\newtheorem{corollary}{\\hspace{0pt}\\bf Corollary}\n%\\newtheorem{fact}{\\hspace{0pt}\\bf Fact}\n%\\newtheorem{remark}{\\hspace{0pt}\\bf Remark}\n%\\newtheorem{test}{\\hspace{0pt}\\it Test Case}\n%\\newtheorem{definition}{\\hspace{0pt}\\bf Definition}\n%\\newtheorem{property}{\\hspace{0pt}\\bf Property}\n%\\newcommand {\\mysubsubsection} [1] {\\vspace{0.4cm}\\noindent{\\bf #1.}\\addcontentsline{toc}{subsubsection}{\\hspace{0pt}#1}}\n%\\newcommand {\\mysubsection} [1]    {\\vspace{0.4cm}\\noindent{\\bf #1.}\\addcontentsline{toc}{subsection}{\\hspace{0pt}#1}}\n\n\\theoremstyle{definition}\n\\newtheorem{defn}{Definition}[section]\n\\newtheorem{conj}{Conjecture}[section]\n\\newtheorem{exmp}{Example}[section]\n\n%%% Luana's commands, specific to this paper $$$\n\n\\newcommand{\\sample}[3]{\\mathbf{{#1}}_{{#2},{#3}}}\n\\newcommand{\\feat}[3]{\\tilde{\\mathbf{{#1}}}_{{#2},{#3}}}\n\n%\n\n\n\n\n\\newenvironment{myproof}[1][$\\!\\!$]{{\\noindent\\bf Proof #1: }}\n                         {\\hfill\\QED\\medskip}\n                         \n\\newenvironment{myproofnoname}{{\\noindent\\bf Proof:}}\n                         {\\hfill\\QED\\medskip}\n                         \n\\newenvironment{myproof2}[1][\\proofname]{%\n  \\noindent \\proof[ \\bf{Proof #1}]%\n}{\\endproof}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%list environment\n\\newenvironment{mylist}\n{\\begin{list}{}{\n   \\setlength{\\itemsep  }{2pt} \\setlength{\\parsep    }{0in}\n   \\setlength{\\parskip  }{0in} \\setlength{\\topsep    }{5pt}\n   \\setlength{\\partopsep}{0in} \\setlength{\\leftmargin}{11pt}\n   \\setlength{\\labelsep }{5pt} \\setlength{\\labelwidth}{-5pt}}}\n{\\end{list}\\medskip}\n\n\\newcounter{excercise}\n\\newcounter{excercisepart}\n\\newcommand \\excercise[1]{\\addtocounter{excercise}{1} \\setcounter{excercisepart}{0} \\medskip\n\t\t\t\t\t\t  \\noindent {\\bf \\theexcercise\\ \\, #1}}\n\\newcommand \\excercisepart[1]{\\addtocounter{excercisepart}{1} \\medskip\n\t\t\t\t\t\t      \\noindent {\\it \\Alph{excercisepart}\\ \\, #1}}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%list environment\n%\\newcounter{example}\n%\\newenvironment{example}[1]{\\addtocounter{example}{1}\\medskip \\noindent{\\it Example \\theexample. #1.}}\n%                           {\\hfill\\QED}%\\newline\\vspace{-2mm}\\newline}\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%slide equation environment\n\\newenvironment{slideeq} {              \\begin{equation*}} {\\end{equation*}            }\n\\newenvironment{nslideeq}{              \\begin{equation*}} {\\end{equation*}            }\n\\newenvironment{sslideeq}{\\small        \\begin{equation*}} {\\end{equation*} \\normalfont}\n\\newenvironment{fslideeq}{\\footnotesize \\begin{equation*}} {\\end{equation*} \\normalfont}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%slide equation environment\n\\newenvironment{slidealign} {              \\begin{align*}} {\\end{align*}            }\n\\newenvironment{nslidealign}{              \\begin{align*}} {\\end{align*}            }\n\\newenvironment{sslidealign}{\\small        \\begin{align*}} {\\end{align*} \\normalfont}\n\\newenvironment{fslidealign}{\\footnotesize \\begin{align*}} {\\end{align*} \\normalfont}\n\n% Color definitions used in presentations\n\\definecolor{pennblue}{cmyk}{1,0.65,0,0.30}\n\\definecolor{pennred}{cmyk}{0,1,0.65,0.34}\n\\definecolor{mygreen}{rgb}{0.10,0.50,0.10}\n\\newcommand \\red[1]         {{\\color{red}#1}}\n\\newcommand \\black[1]         {{\\color{black}#1}}\n\\newcommand \\blue[1]        {{\\color{blue}#1}}\n\\newcommand \\grey[1]        {{\\color[rgb]{0.80,0.80,0.80}#1}}\n\\newcommand \\gray[1]        {{\\color[rgb]{0.80,0.80,0.80}#1}}\n\\newcommand \\green[1]       {{\\color[rgb]{0.10,0.50,0.10}#1}}\n\\newcommand \\bulletcolor[1] {{\\color{pennblue}#1}}\n\\def \\arrowbullet {\\bulletcolor{$\\ \\Rightarrow\\ $}}\n\\def \\arrbullet   {\\bulletcolor{$\\ \\Rightarrow\\ $}}\n\\def \\ab          {\\bulletcolor{$\\ \\Rightarrow\\ $}}\n\\def \\arritem     {\\item[] \\quad \\arrowbullet}\n\\def \\ai          {\\item[] \\quad \\arrowbullet}\n\\def \\doublearrow {\\bulletcolor{$\\ \\Leftrightarrow\\ $}}\n\\def \\darrbullet  {\\bulletcolor{$\\ \\Leftrightarrow\\ $}}\n\n\n%Always used\n\\def \\defQfunction \n        {Q(u):=(1/\\sqrt{2\\pi})\\int_u^\\infty e^{-u^2/2} du}\n\\def \\intinfty  { \\int_{-\\infty}^{\\infty} }\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Overline\n%\n\\def \\ovP {\\overline{P}}\n\\def \\ovl {\\overline{l}}\n\\def \\ovbbl {\\overline{\\bbl}}\n\\def \\ovX {\\overline{X}}\n\\def \\ovbbX {\\overline{\\bbX}}\n\\def \\ovp {\\overline{p}}\n\\def \\ovbbp {\\overline{\\bbp}}\n\\def \\ovr {\\overline{r}}\n\\def \\ova {\\overline{a}}\n\\def \\ovc {\\overline{c}}\n\\def \\ovalpha {\\overline{\\alpha}}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Underline\n%\n\\def \\undP {\\underline{P}}\n\\def \\undl {\\underline{l}}\n\\def \\undbbl {\\underline{\\bbl}}\n\\def \\undX {\\underline{X}}\n\\def \\undbbX {\\underline{\\bbX}}\n\\def \\undp {\\underline{p}}\n\\def \\undbbp {\\underline{\\bbp}}\n\\def \\undr {\\underline{r}}\n\\def \\unda {\\underline{a}}\n\\def \\undc {\\underline{c}}\n\\def \\undalpha {\\underline{\\alpha}}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Overline and Underline\n%\n\\def \\undovP     {\\underline{\\ovP}}\n\\def \\undovX     {\\underline{\\ovX}}\n\\def \\undovbbX   {\\underline{\\ovbbX}}\n\\def \\undovp     {\\underline{\\ovp}}\n\\def \\undovbbp   {\\underline{\\ovbbp}}\n\\def \\undovr     {\\underline{\\ovr}}\n\\def \\undova     {\\underline{\\ova}}\n\\def \\undovc     {\\underline{\\ovc}}\n\\def \\undovalpha {\\underline{\\ovalpha}}\n\n%roman symbols\n\\def \\SNR     {\\text{\\normalfont SNR}   }\n\\def \\ap      {\\text{\\normalfont ap}   }\n\\def \\best    {\\text{\\normalfont best} }\n\\def \\Co      {\\text{\\normalfont Co}   }\n\\def \\Cov     {\\text{\\normalfont Cov}  }\n\\def \\cov     {\\text{\\normalfont cov}  }\n\\def \\dest    {\\text{\\normalfont dest} }\n\\def \\diag    {\\text{\\normalfont diag} }\n\\def \\eig     {\\text{\\normalfont eig}  }\n\\def \\for     {\\text{\\normalfont for}  }\n%\\def \\forall  {\\text{\\normalfont for all}  }\n\\def \\forsome {\\text{\\normalfont for some}  }\n\\def \\ML      {\\text{\\normalfont ML}   }\n\\def \\MLE     {\\text{\\normalfont MLE}  }\n\\def \\ml      {\\text{\\normalfont ml}   }\n\\def \\mse     {\\text{\\normalfont mse}  }\n\\def \\rank    {\\text{\\normalfont rank} }\n\\def \\sign    {\\text{\\normalfont sign} }\n\\def \\tr      {\\text{\\normalfont tr}   }\n\n%units\n\\def \\dB      {\\, \\text{\\normalfont dB} }\n\\def \\ms      {\\, \\text{\\normalfont m}/ \\text{\\normalfont s}}\n\\def \\kmh     {\\, \\text{\\normalfont km}/ \\text{\\normalfont h}}\n\\def \\m       {\\, \\text{\\normalfont m} }\n\\def \\s       {\\, \\text{\\normalfont s} }\n\\def \\sec     {\\, \\text{\\normalfont sec.} }\n\\def \\msec    {\\, \\text{\\normalfont msec.} }\n\\def \\cm      {\\, \\text{\\normalfont cm} }\n\\def \\km      {\\, \\text{\\normalfont km} }\n\\def \\GHz     {\\, \\text{\\normalfont GHz} }\n\\def \\Hz      {\\, \\text{\\normalfont Hz} }\n\\def \\MHZ     {\\, \\text{\\normalfont MHz} }\n\\def \\kHZ     {\\, \\text{\\normalfont kHz} }\n\n\n%Probability operators\n\\newcommand   \\E     [1] {{\\mathbb E}\\left[#1\\right]}\n\\newcommand   \\Ec    [1] {{\\mathbb E}\\left(#1\\right)}\n\\newcommand   \\ind   [1] {{\\mathbb I \\left\\{#1\\right\\}  } }\n\\renewcommand \\Pr    [1] {\\text{\\normalfont Pr}  \\left[#1\\right]}\n\\newcommand   \\Prc   [1] {\\text{\\normalfont Pr}  \\left(#1\\right)}\n\\renewcommand \\P     [1] {\\text{\\normalfont P}   \\left[#1\\right]}\n\\newcommand   \\Pc    [1] {\\text{\\normalfont P}   \\left(#1\\right)}\n\\newcommand   \\Pcbig [1] {\\text{\\normalfont P}   \\big(#1 \\big)}\n\\newcommand   \\PcBig [1] {\\text{\\normalfont P}   \\Big(#1 \\Big)}\n\\newcommand   \\var   [1] {\\text{\\normalfont var} \\left[#1\\right]}\n\\newcommand   \\varc  [1] {\\text{\\normalfont var} \\left(#1\\right)}\n\\renewcommand \\Re    [1] {\\text{\\normalfont Re} \\left(#1\\right)}\n\\renewcommand \\Im    [1] {\\text{\\normalfont Im} \\left(#1\\right)}\n\\newcommand   \\der         [2] {\\frac{\\partial#1}{\\partial#2}}\n\\newcommand   \\inlineder   [2] {\\partial#1/\\partial#2}\n\n\n%miscellaneous\n\\def \\naturals {{\\mathbb N}}\n\\def \\reals    {{\\mathbb R}}\n\\def \\blog { {\\bf \\log   } }\n\\def \\given{ {\\,\\big|\\,  } }\n\\newcommand{\\st}{\\operatornamewithlimits{s.t.}}\n\\newcommand{\\argmax}{\\operatornamewithlimits{argmax}}\n\\newcommand{\\argmin}{\\operatornamewithlimits{argmin}}\n\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%bar version\n%capital alphabet\n\\def\\bbarA{{\\ensuremath{\\bar A}}}\n\\def\\bbarB{{\\ensuremath{\\bar B}}}\n\\def\\bbarC{{\\ensuremath{\\bar C}}}\n\\def\\bbarD{{\\ensuremath{\\bar D}}}\n\\def\\bbarE{{\\ensuremath{\\bar E}}}\n\\def\\bbarF{{\\ensuremath{\\bar F}}}\n\\def\\bbarG{{\\ensuremath{\\bar G}}}\n\\def\\bbarH{{\\ensuremath{\\bar H}}}\n\\def\\bbarI{{\\ensuremath{\\bar I}}}\n\\def\\bbarJ{{\\ensuremath{\\bar J}}}\n\\def\\bbarK{{\\ensuremath{\\bar K}}}\n\\def\\bbarL{{\\ensuremath{\\bar L}}}\n\\def\\bbarM{{\\ensuremath{\\bar M}}}\n\\def\\bbarN{{\\ensuremath{\\bar N}}}\n\\def\\bbarO{{\\ensuremath{\\bar O}}}\n\\def\\bbarP{{\\ensuremath{\\bar P}}}\n\\def\\bbarQ{{\\ensuremath{\\bar Q}}}\n\\def\\bbarR{{\\ensuremath{\\bar R}}}\n\\def\\bbarW{{\\ensuremath{\\bar W}}}\n\\def\\bbarU{{\\ensuremath{\\bar U}}}\n\\def\\bbarV{{\\ensuremath{\\bar V}}}\n\\def\\bbarS{{\\ensuremath{\\bar S}}}\n\\def\\bbarT{{\\ensuremath{\\bar T}}}\n\\def\\bbarX{{\\ensuremath{\\bar X}}}\n\\def\\bbarY{{\\ensuremath{\\bar Y}}}\n\\def\\bbarZ{{\\ensuremath{\\bar Z}}}\n%lower case alphabet\n\\def\\bbara{{\\ensuremath{\\bar a}}}\n\\def\\bbarb{{\\ensuremath{\\bar b}}}\n\\def\\bbarc{{\\ensuremath{\\bar c}}}\n\\def\\bbard{{\\ensuremath{\\bar d}}}\n\\def\\bbare{{\\ensuremath{\\bar e}}}\n\\def\\bbarf{{\\ensuremath{\\bar f}}}\n\\def\\bbarg{{\\ensuremath{\\bar g}}}\n\\def\\bbarh{{\\ensuremath{\\bar h}}}\n\\def\\bbari{{\\ensuremath{\\bar i}}}\n\\def\\bbarj{{\\ensuremath{\\bar j}}}\n\\def\\bbark{{\\ensuremath{\\bar k}}}\n\\def\\bbarl{{\\ensuremath{\\bar l}}}\n\\def\\bbarm{{\\ensuremath{\\bar m}}}\n\\def\\bbarn{{\\ensuremath{\\bar n}}}\n\\def\\bbaro{{\\ensuremath{\\bar o}}}\n\\def\\bbarp{{\\ensuremath{\\bar p}}}\n\\def\\bbarq{{\\ensuremath{\\bar q}}}\n\\def\\bbarr{{\\ensuremath{\\bar r}}}\n\\def\\bbarw{{\\ensuremath{\\bar w}}}\n\\def\\bbaru{{\\ensuremath{\\bar u}}}\n\\def\\bbarv{{\\ensuremath{\\bar v}}}\n\\def\\bbars{{\\ensuremath{\\bar s}}}\n\\def\\bbart{{\\ensuremath{\\bar t}}}\n\\def\\bbarx{{\\ensuremath{\\bar x}}}\n\\def\\bbary{{\\ensuremath{\\bar y}}}\n\\def\\bbarz{{\\ensuremath{\\bar z}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of bar version\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%   B   L   A   C   K   B   O   A   R   D         B   O   L   D   %%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\def\\mbA{{\\ensuremath{\\mathbb A}}}\n\\def\\mbB{{\\ensuremath{\\mathbb B}}}\n\\def\\mbC{{\\ensuremath{\\mathbb C}}}\n\\def\\mbD{{\\ensuremath{\\mathbb D}}}\n\\def\\mbE{{\\ensuremath{\\mathbb E}}}\n\\def\\mbF{{\\ensuremath{\\mathbb F}}}\n\\def\\mbG{{\\ensuremath{\\mathbb G}}}\n\\def\\mbH{{\\ensuremath{\\mathbb H}}}\n\\def\\mbI{{\\ensuremath{\\mathbb I}}}\n\\def\\mbJ{{\\ensuremath{\\mathbb J}}}\n\\def\\mbK{{\\ensuremath{\\mathbb K}}}\n\\def\\mbL{{\\ensuremath{\\mathbb L}}}\n\\def\\mbM{{\\ensuremath{\\mathbb M}}}\n\\def\\mbN{{\\ensuremath{\\mathbb N}}}\n\\def\\mbO{{\\ensuremath{\\mathbb O}}}\n\\def\\mbP{{\\ensuremath{\\mathbb P}}}\n\\def\\mbQ{{\\ensuremath{\\mathbb Q}}}\n\\def\\mbR{{\\ensuremath{\\mathbb R}}}\n\\def\\mbS{{\\ensuremath{\\mathbb S}}}\n\\def\\mbT{{\\ensuremath{\\mathbb T}}}\n\\def\\mbU{{\\ensuremath{\\mathbb U}}}\n\\def\\mbV{{\\ensuremath{\\mathbb V}}}\n\\def\\mbW{{\\ensuremath{\\mathbb W}}}\n\\def\\mbX{{\\ensuremath{\\mathbb X}}}\n\\def\\mbY{{\\ensuremath{\\mathbb Y}}}\n\\def\\mbZ{{\\ensuremath{\\mathbb Z}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%   C   A   L   I   G   R   A   P   H   I   C   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\def\\ccalA{{\\ensuremath{\\mathcal A}}}\n\\def\\ccalB{{\\ensuremath{\\mathcal B}}}\n\\def\\ccalC{{\\ensuremath{\\mathcal C}}}\n\\def\\ccalD{{\\ensuremath{\\mathcal D}}}\n\\def\\ccalE{{\\ensuremath{\\mathcal E}}}\n\\def\\ccalF{{\\ensuremath{\\mathcal F}}}\n\\def\\ccalG{{\\ensuremath{\\mathcal G}}}\n\\def\\ccalH{{\\ensuremath{\\mathcal H}}}\n\\def\\ccalI{{\\ensuremath{\\mathcal I}}}\n\\def\\ccalJ{{\\ensuremath{\\mathcal J}}}\n\\def\\ccalK{{\\ensuremath{\\mathcal K}}}\n\\def\\ccalL{{\\ensuremath{\\mathcal L}}}\n\\def\\ccalM{{\\ensuremath{\\mathcal M}}}\n\\def\\ccalN{{\\ensuremath{\\mathcal N}}}\n\\def\\ccalO{{\\ensuremath{\\mathcal O}}}\n\\def\\ccalP{{\\ensuremath{\\mathcal P}}}\n\\def\\ccalQ{{\\ensuremath{\\mathcal Q}}}\n\\def\\ccalR{{\\ensuremath{\\mathcal R}}}\n\\def\\ccalW{{\\ensuremath{\\mathcal W}}}\n\\def\\ccalU{{\\ensuremath{\\mathcal U}}}\n\\def\\ccalV{{\\ensuremath{\\mathcal V}}}\n\\def\\ccalS{{\\ensuremath{\\mathcal S}}}\n\\def\\ccalT{{\\ensuremath{\\mathcal T}}}\n\\def\\ccalX{{\\ensuremath{\\mathcal X}}}\n\\def\\ccalY{{\\ensuremath{\\mathcal Y}}}\n\\def\\ccalZ{{\\ensuremath{\\mathcal Z}}}\n%lower case alphabet\n\\def\\ccala{{\\ensuremath{\\mathcal a}}}\n\\def\\ccalb{{\\ensuremath{\\mathcal b}}}\n\\def\\ccalc{{\\ensuremath{\\mathcal c}}}\n\\def\\ccald{{\\ensuremath{\\mathcal d}}}\n\\def\\ccale{{\\ensuremath{\\mathcal e}}}\n\\def\\ccalf{{\\ensuremath{\\mathcal f}}}\n\\def\\ccalg{{\\ensuremath{\\mathcal g}}}\n\\def\\ccalh{{\\ensuremath{\\mathcal h}}}\n\\def\\ccali{{\\ensuremath{\\mathcal i}}}\n\\def\\ccalj{{\\ensuremath{\\mathcal j}}}\n\\def\\ccalk{{\\ensuremath{\\mathcal k}}}\n\\def\\ccall{{\\ensuremath{\\mathcal l}}}\n\\def\\ccalm{{\\ensuremath{\\mathcal m}}}\n\\def\\ccaln{{\\ensuremath{\\mathcal n}}}\n\\def\\ccalo{{\\ensuremath{\\mathcal o}}}\n\\def\\ccalp{{\\ensuremath{\\mathcal p}}}\n\\def\\ccalq{{\\ensuremath{\\mathcal q}}}\n\\def\\ccalr{{\\ensuremath{\\mathcal r}}}\n\\def\\ccalw{{\\ensuremath{\\mathcal w}}}\n\\def\\ccalu{{\\ensuremath{\\mathcal u}}}\n\\def\\ccalv{{\\ensuremath{\\mathcal v}}}\n\\def\\ccals{{\\ensuremath{\\mathcal s}}}\n\\def\\ccalt{{\\ensuremath{\\mathcal t}}}\n\\def\\ccalx{{\\ensuremath{\\mathcal x}}}\n\\def\\ccaly{{\\ensuremath{\\mathcal y}}}\n\\def\\ccalz{{\\ensuremath{\\mathcal z}}}\n\\def\\ccal0{{\\ensuremath{\\mathcal 0}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of caligraph version\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%hat version\n%capital alphabet\n\\def\\hhatA{{\\ensuremath{\\hat A}}}\n\\def\\hhatB{{\\ensuremath{\\hat B}}}\n\\def\\hhatC{{\\ensuremath{\\hat C}}}\n\\def\\hhatD{{\\ensuremath{\\hat D}}}\n\\def\\hhatE{{\\ensuremath{\\hat E}}}\n\\def\\hhatF{{\\ensuremath{\\hat F}}}\n\\def\\hhatG{{\\ensuremath{\\hat G}}}\n\\def\\hhatH{{\\ensuremath{\\hat H}}}\n\\def\\hhatI{{\\ensuremath{\\hat I}}}\n\\def\\hhatJ{{\\ensuremath{\\hat J}}}\n\\def\\hhatK{{\\ensuremath{\\hat K}}}\n\\def\\hhatL{{\\ensuremath{\\hat L}}}\n\\def\\hhatM{{\\ensuremath{\\hat M}}}\n\\def\\hhatN{{\\ensuremath{\\hat N}}}\n\\def\\hhatO{{\\ensuremath{\\hat O}}}\n\\def\\hhatP{{\\ensuremath{\\hat P}}}\n\\def\\hhatQ{{\\ensuremath{\\hat Q}}}\n\\def\\hhatR{{\\ensuremath{\\hat R}}}\n\\def\\hhatW{{\\ensuremath{\\hat W}}}\n\\def\\hhatU{{\\ensuremath{\\hat U}}}\n\\def\\hhatV{{\\ensuremath{\\hat V}}}\n\\def\\hhatS{{\\ensuremath{\\hat S}}}\n\\def\\hhatT{{\\ensuremath{\\hat T}}}\n\\def\\hhatX{{\\ensuremath{\\hat X}}}\n\\def\\hhatY{{\\ensuremath{\\hat Y}}}\n\\def\\hhatZ{{\\ensuremath{\\hat Z}}}\n%lower case alphabet\n\\def\\hhata{{\\ensuremath{\\hat a}}}\n\\def\\hhatb{{\\ensuremath{\\hat b}}}\n\\def\\hhatc{{\\ensuremath{\\hat c}}}\n\\def\\hhatd{{\\ensuremath{\\hat d}}}\n\\def\\hhate{{\\ensuremath{\\hat e}}}\n\\def\\hhatf{{\\ensuremath{\\hat f}}}\n\\def\\hhatg{{\\ensuremath{\\hat g}}}\n\\def\\hhath{{\\ensuremath{\\hat h}}}\n\\def\\hhati{{\\ensuremath{\\hat i}}}\n\\def\\hhatj{{\\ensuremath{\\hat j}}}\n\\def\\hhatk{{\\ensuremath{\\hat k}}}\n\\def\\hhatl{{\\ensuremath{\\hat l}}}\n\\def\\hhatm{{\\ensuremath{\\hat m}}}\n\\def\\hhatn{{\\ensuremath{\\hat n}}}\n\\def\\hhato{{\\ensuremath{\\hat o}}}\n\\def\\hhatp{{\\ensuremath{\\hat p}}}\n\\def\\hhatq{{\\ensuremath{\\hat q}}}\n\\def\\hhatr{{\\ensuremath{\\hat r}}}\n\\def\\hhatw{{\\ensuremath{\\hat w}}}\n\\def\\hhatu{{\\ensuremath{\\hat u}}}\n\\def\\hhatv{{\\ensuremath{\\hat v}}}\n\\def\\hhats{{\\ensuremath{\\hat s}}}\n\\def\\hhatt{{\\ensuremath{\\hat t}}}\n\\def\\hhatx{{\\ensuremath{\\hat x}}}\n\\def\\hhaty{{\\ensuremath{\\hat y}}}\n\\def\\hhatz{{\\ensuremath{\\hat z}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of hat version\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%tilde version\n%capital alphabet\n\\def\\tdA{{\\ensuremath{\\tilde A}}}\n\\def\\tdB{{\\ensuremath{\\tilde B}}}\n\\def\\tdC{{\\ensuremath{\\tilde C}}}\n\\def\\tdD{{\\ensuremath{\\tilde D}}}\n\\def\\tdE{{\\ensuremath{\\tilde E}}}\n\\def\\tdF{{\\ensuremath{\\tilde F}}}\n\\def\\tdG{{\\ensuremath{\\tilde G}}}\n\\def\\tdH{{\\ensuremath{\\tilde H}}}\n\\def\\tdI{{\\ensuremath{\\tilde I}}}\n\\def\\tdJ{{\\ensuremath{\\tilde J}}}\n\\def\\tdK{{\\ensuremath{\\tilde K}}}\n\\def\\tdL{{\\ensuremath{\\tilde L}}}\n\\def\\tdM{{\\ensuremath{\\tilde M}}}\n\\def\\tdN{{\\ensuremath{\\tilde N}}}\n\\def\\tdO{{\\ensuremath{\\tilde O}}}\n\\def\\tdP{{\\ensuremath{\\tilde P}}}\n\\def\\tdQ{{\\ensuremath{\\tilde Q}}}\n\\def\\tdR{{\\ensuremath{\\tilde R}}}\n\\def\\tdW{{\\ensuremath{\\tilde W}}}\n\\def\\tdU{{\\ensuremath{\\tilde U}}}\n\\def\\tdV{{\\ensuremath{\\tilde V}}}\n\\def\\tdS{{\\ensuremath{\\tilde S}}}\n\\def\\tdT{{\\ensuremath{\\tilde T}}}\n\\def\\tdX{{\\ensuremath{\\tilde X}}}\n\\def\\tdY{{\\ensuremath{\\tilde Y}}}\n\\def\\tdZ{{\\ensuremath{\\tilde Z}}}\n%lower case alphabet\n\\def\\tda{{\\ensuremath{\\tilde a}}}\n\\def\\tdb{{\\ensuremath{\\tilde b}}}\n\\def\\tdc{{\\ensuremath{\\tilde c}}}\n\\def\\tdd{{\\ensuremath{\\tilde d}}}\n\\def\\tde{{\\ensuremath{\\tilde e}}}\n\\def\\tdf{{\\ensuremath{\\tilde f}}}\n\\def\\tdg{{\\ensuremath{\\tilde g}}}\n\\def\\tdh{{\\ensuremath{\\tilde h}}}\n\\def\\tdi{{\\ensuremath{\\tilde i}}}\n\\def\\tdj{{\\ensuremath{\\tilde j}}}\n\\def\\tdk{{\\ensuremath{\\tilde k}}}\n\\def\\tdl{{\\ensuremath{\\tilde l}}}\n\\def\\tdm{{\\ensuremath{\\tilde m}}}\n\\def\\tdn{{\\ensuremath{\\tilde n}}}\n\\def\\tdo{{\\ensuremath{\\tilde o}}}\n\\def\\tdp{{\\ensuremath{\\tilde p}}}\n\\def\\tdq{{\\ensuremath{\\tilde q}}}\n\\def\\tdr{{\\ensuremath{\\tilde r}}}\n\\def\\tdw{{\\ensuremath{\\tilde w}}}\n\\def\\tdu{{\\ensuremath{\\tilde u}}}\n\\def\\tdv{{\\ensuremath{\\tilde r}}}\n\\def\\tds{{\\ensuremath{\\tilde s}}}\n\\def\\tdt{{\\ensuremath{\\tilde t}}}\n\\def\\tdx{{\\ensuremath{\\tilde x}}}\n\\def\\tdy{{\\ensuremath{\\tilde y}}}\n\\def\\tdz{{\\ensuremath{\\tilde z}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of tilde version\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%check version\n%lower case alphabet\n\\def\\chka{{\\ensuremath{\\check a}}}\n\\def\\chkb{{\\ensuremath{\\check b}}}\n\\def\\chkc{{\\ensuremath{\\check c}}}\n\\def\\chkd{{\\ensuremath{\\check d}}}\n\\def\\chke{{\\ensuremath{\\check e}}}\n\\def\\chkf{{\\ensuremath{\\check f}}}\n\\def\\chkg{{\\ensuremath{\\check g}}}\n\\def\\chkh{{\\ensuremath{\\check h}}}\n\\def\\chki{{\\ensuremath{\\check i}}}\n\\def\\chkj{{\\ensuremath{\\check j}}}\n\\def\\chkk{{\\ensuremath{\\check k}}}\n\\def\\chkl{{\\ensuremath{\\check l}}}\n\\def\\chkm{{\\ensuremath{\\check m}}}\n\\def\\chkn{{\\ensuremath{\\check n}}}\n\\def\\chko{{\\ensuremath{\\check o}}}\n\\def\\chkp{{\\ensuremath{\\check p}}}\n\\def\\chkq{{\\ensuremath{\\check q}}}\n\\def\\chkr{{\\ensuremath{\\check r}}}\n\\def\\chkw{{\\ensuremath{\\check w}}}\n\\def\\chku{{\\ensuremath{\\check u}}}\n\\def\\chkv{{\\ensuremath{\\check v}}}\n\\def\\chks{{\\ensuremath{\\check s}}}\n\\def\\chkt{{\\ensuremath{\\check t}}}\n\\def\\chkx{{\\ensuremath{\\check x}}}\n\\def\\chky{{\\ensuremath{\\check y}}}\n\\def\\chkz{{\\ensuremath{\\check z}}}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of check version\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bold version\n% upper case bold\n\\def\\bbone{{\\ensuremath{\\mathbf 1}}}\n\\def\\bbzero{{\\ensuremath{\\mathbf 0}}}\n\\def\\bbA{{\\ensuremath{\\mathbf A}}}\n\\def\\bbB{{\\ensuremath{\\mathbf B}}}\n\\def\\bbC{{\\ensuremath{\\mathbf C}}}\n\\def\\bbD{{\\ensuremath{\\mathbf D}}}\n\\def\\bbE{{\\ensuremath{\\mathbf E}}}\n\\def\\bbF{{\\ensuremath{\\mathbf F}}}\n\\def\\bbG{{\\ensuremath{\\mathbf G}}}\n\\def\\bbH{{\\ensuremath{\\mathbf H}}}\n\\def\\bbI{{\\ensuremath{\\mathbf I}}}\n\\def\\bbJ{{\\ensuremath{\\mathbf J}}}\n\\def\\bbK{{\\ensuremath{\\mathbf K}}}\n\\def\\bbL{{\\ensuremath{\\mathbf L}}}\n\\def\\bbM{{\\ensuremath{\\mathbf M}}}\n\\def\\bbN{{\\ensuremath{\\mathbf N}}}\n\\def\\bbO{{\\ensuremath{\\mathbf O}}}\n\\def\\bbP{{\\ensuremath{\\mathbf P}}}\n\\def\\bbQ{{\\ensuremath{\\mathbf Q}}}\n\\def\\bbR{{\\ensuremath{\\mathbf R}}}\n\\def\\bbW{{\\ensuremath{\\mathbf W}}}\n\\def\\bbU{{\\ensuremath{\\mathbf U}}}\n\\def\\bbV{{\\ensuremath{\\mathbf V}}}\n\\def\\bbS{{\\ensuremath{\\mathbf S}}}\n\\def\\bbT{{\\ensuremath{\\mathbf T}}}\n\\def\\bbX{{\\ensuremath{\\mathbf X}}}\n\\def\\bbY{{\\ensuremath{\\mathbf Y}}}\n\\def\\bbZ{{\\ensuremath{\\mathbf Z}}}\n%lower case bold\n\\def\\bba{{\\ensuremath{\\mathbf a}}}\n\\def\\bbb{{\\ensuremath{\\mathbf b}}}\n\\def\\bbc{{\\ensuremath{\\mathbf c}}}\n\\def\\bbd{{\\ensuremath{\\mathbf d}}}\n\\def\\bbe{{\\ensuremath{\\mathbf e}}}\n\\def\\bbf{{\\ensuremath{\\mathbf f}}}\n\\def\\bbg{{\\ensuremath{\\mathbf g}}}\n\\def\\bbh{{\\ensuremath{\\mathbf h}}}\n\\def\\bbi{{\\ensuremath{\\mathbf i}}}\n\\def\\bbj{{\\ensuremath{\\mathbf j}}}\n\\def\\bbk{{\\ensuremath{\\mathbf k}}}\n\\def\\bbl{{\\ensuremath{\\mathbf l}}}\n\\def\\bbm{{\\ensuremath{\\mathbf m}}}\n\\def\\bbn{{\\ensuremath{\\mathbf n}}}\n\\def\\bbo{{\\ensuremath{\\mathbf o}}}\n\\def\\bbp{{\\ensuremath{\\mathbf p}}}\n\\def\\bbq{{\\ensuremath{\\mathbf q}}}\n\\def\\bbr{{\\ensuremath{\\mathbf r}}}\n\\def\\bbw{{\\ensuremath{\\mathbf w}}}\n\\def\\bbu{{\\ensuremath{\\mathbf u}}}\n\\def\\bbv{{\\ensuremath{\\mathbf v}}}\n\\def\\bbs{{\\ensuremath{\\mathbf s}}}\n\\def\\bbt{{\\ensuremath{\\mathbf t}}}\n\\def\\bbx{{\\ensuremath{\\mathbf x}}}\n\\def\\bby{{\\ensuremath{\\mathbf y}}}\n\\def\\bbz{{\\ensuremath{\\mathbf z}}}\n\\def\\bb0{{\\ensuremath{\\mathbf 0}}}\n%\n\n% roman \n\\def\\rmA{{\\ensuremath\\text{A}}}\n\\def\\rmB{{\\ensuremath\\text{B}}}\n\\def\\rmC{{\\ensuremath\\text{C}}}\n\\def\\rmD{{\\ensuremath\\text{D}}}\n\\def\\rmE{{\\ensuremath\\text{E}}}\n\\def\\rmF{{\\ensuremath\\text{F}}}\n\\def\\rmG{{\\ensuremath\\text{G}}}\n\\def\\rmH{{\\ensuremath\\text{H}}}\n\\def\\rmI{{\\ensuremath\\text{I}}}\n\\def\\rmJ{{\\ensuremath\\text{J}}}\n\\def\\rmK{{\\ensuremath\\text{K}}}\n\\def\\rmL{{\\ensuremath\\text{L}}}\n\\def\\rmM{{\\ensuremath\\text{M}}}\n\\def\\rmN{{\\ensuremath\\text{N}}}\n\\def\\rmO{{\\ensuremath\\text{O}}}\n\\def\\rmP{{\\ensuremath\\text{P}}}\n\\def\\rmQ{{\\ensuremath\\text{Q}}}\n\\def\\rmR{{\\ensuremath\\text{R}}}\n\\def\\rmW{{\\ensuremath\\text{W}}}\n\\def\\rmU{{\\ensuremath\\text{U}}}\n\\def\\rmV{{\\ensuremath\\text{V}}}\n\\def\\rmS{{\\ensuremath\\text{S}}}\n\\def\\rmT{{\\ensuremath\\text{T}}}\n\\def\\rmX{{\\ensuremath\\text{X}}}\n\\def\\rmY{{\\ensuremath\\text{Y}}}\n\\def\\rmZ{{\\ensuremath\\text{Z}}}\n%lower case bold\n\\def\\rma{{\\ensuremath\\text{a}}}\n\\def\\rmb{{\\ensuremath\\text{b}}}\n\\def\\rmc{{\\ensuremath\\text{c}}}\n\\def\\rmd{{\\ensuremath\\text{d}}}\n\\def\\rme{{\\ensuremath\\text{e}}}\n\\def\\rmf{{\\ensuremath\\text{f}}}\n\\def\\rmg{{\\ensuremath\\text{g}}}\n\\def\\rmh{{\\ensuremath\\text{h}}}\n\\def\\rmi{{\\ensuremath\\text{i}}}\n\\def\\rmj{{\\ensuremath\\text{j}}}\n\\def\\rmk{{\\ensuremath\\text{k}}}\n\\def\\rml{{\\ensuremath\\text{l}}}\n\\def\\rmm{{\\ensuremath\\text{m}}}\n\\def\\rmn{{\\ensuremath\\text{n}}}\n\\def\\rmo{{\\ensuremath\\text{o}}}\n\\def\\rmp{{\\ensuremath\\text{p}}}\n\\def\\rmq{{\\ensuremath\\text{q}}}\n\\def\\rmr{{\\ensuremath\\text{r}}}\n\\def\\rmw{{\\ensuremath\\text{w}}}\n\\def\\rmu{{\\ensuremath\\text{u}}}\n\\def\\rmv{{\\ensuremath\\text{v}}}\n\\def\\rms{{\\ensuremath\\text{s}}}\n\\def\\rmt{{\\ensuremath\\text{t}}}\n\\def\\rmx{{\\ensuremath\\text{x}}}\n\\def\\rmy{{\\ensuremath\\text{y}}}\n\\def\\rmz{{\\ensuremath\\text{z}}}\n%\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%bar bold version\n%upper case\n%\n\\def\\barbA{{\\bar{\\ensuremath{\\mathbf A}} }}\n\\def\\barbB{{\\bar{\\ensuremath{\\mathbf B}} }}\n\\def\\barbC{{\\bar{\\ensuremath{\\mathbf C}} }}\n\\def\\barbD{{\\bar{\\ensuremath{\\mathbf D}} }}\n\\def\\barbE{{\\bar{\\ensuremath{\\mathbf E}} }}\n\\def\\barbF{{\\bar{\\ensuremath{\\mathbf F}} }}\n\\def\\barbG{{\\bar{\\ensuremath{\\mathbf G}} }}\n\\def\\barbH{{\\bar{\\ensuremath{\\mathbf H}} }}\n\\def\\barbI{{\\bar{\\ensuremath{\\mathbf I}} }}\n\\def\\barbJ{{\\bar{\\ensuremath{\\mathbf J}} }}\n\\def\\barbK{{\\bar{\\ensuremath{\\mathbf K}} }}\n\\def\\barbL{{\\bar{\\ensuremath{\\mathbf L}} }}\n\\def\\barbM{{\\bar{\\ensuremath{\\mathbf M}} }}\n\\def\\barbN{{\\bar{\\ensuremath{\\mathbf N}} }}\n\\def\\barbO{{\\bar{\\ensuremath{\\mathbf O}} }}\n\\def\\barbP{{\\bar{\\ensuremath{\\mathbf P}} }}\n\\def\\barbQ{{\\bar{\\ensuremath{\\mathbf Q}} }}\n\\def\\barbR{{\\bar{\\ensuremath{\\mathbf R}} }}\n\\def\\barbS{{\\bar{\\ensuremath{\\mathbf S}} }}\n\\def\\barbT{{\\bar{\\ensuremath{\\mathbf T}} }}\n\\def\\barbU{{\\bar{\\ensuremath{\\mathbf U}} }}\n\\def\\barbV{{\\bar{\\ensuremath{\\mathbf V}} }}\n\\def\\barbW{{\\bar{\\ensuremath{\\mathbf W}} }}\n\\def\\barbX{{\\overline{\\bbX}}}\n\\def\\barbY{{\\bar{\\ensuremath{\\mathbf Y}} }}\n\\def\\barbZ{{\\bar{\\ensuremath{\\mathbf Z}} }}\n%\n%lower case\n%\n\\def\\barba{{\\bar{\\ensuremath{\\mathbf a}} }}\n\\def\\barbb{{\\bar{\\ensuremath{\\mathbf b}} }}\n\\def\\barbc{{\\bar{\\ensuremath{\\mathbf c}} }}\n\\def\\barbd{{\\bar{\\ensuremath{\\mathbf d}} }}\n\\def\\barbe{{\\bar{\\ensuremath{\\mathbf e}} }}\n\\def\\barbf{{\\bar{\\ensuremath{\\mathbf f}} }}\n\\def\\barbg{{\\bar{\\ensuremath{\\mathbf g}} }}\n\\def\\barbh{{\\bar{\\ensuremath{\\mathbf h}} }}\n\\def\\barbi{{\\bar{\\ensuremath{\\mathbf i}} }}\n\\def\\barbj{{\\bar{\\ensuremath{\\mathbf j}} }}\n\\def\\barbk{{\\bar{\\ensuremath{\\mathbf k}} }}\n\\def\\barbl{{\\bar{\\ensuremath{\\mathbf l}} }}\n\\def\\barbm{{\\bar{\\ensuremath{\\mathbf m}} }}\n\\def\\barbn{{\\bar{\\ensuremath{\\mathbf n}} }}\n\\def\\barbo{{\\bar{\\ensuremath{\\mathbf o}} }}\n\\def\\barbp{{\\bar{\\ensuremath{\\mathbf p}} }}\n\\def\\barbq{{\\bar{\\ensuremath{\\mathbf q}} }}\n\\def\\barbr{{\\bar{\\ensuremath{\\mathbf r}} }}\n\\def\\barbs{{\\bar{\\ensuremath{\\mathbf s}} }}\n\\def\\barbt{{\\bar{\\ensuremath{\\mathbf t}} }}\n\\def\\barbu{{\\bar{\\ensuremath{\\mathbf u}} }}\n\\def\\barbv{{\\bar{\\ensuremath{\\mathbf v}} }}\n\\def\\barbw{{\\bar{\\ensuremath{\\mathbf w}} }}\n\\def\\barbx{{\\bar{\\ensuremath{\\mathbf x}} }}\n\\def\\barby{{\\bar{\\ensuremath{\\mathbf y}} }}\n\\def\\barbz{{\\bar{\\ensuremath{\\mathbf z}} }}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of bar bold bersion\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%hat bold version\n%upper case\n%\n\\def\\hbA{{\\hat{\\ensuremath{\\mathbf A}} }}\n\\def\\hbB{{\\hat{\\ensuremath{\\mathbf B}} }}\n\\def\\hbC{{\\hat{\\ensuremath{\\mathbf C}} }}\n\\def\\hbD{{\\hat{\\ensuremath{\\mathbf D}} }}\n\\def\\hbE{{\\hat{\\ensuremath{\\mathbf E}} }}\n\\def\\hbF{{\\hat{\\ensuremath{\\mathbf F}} }}\n\\def\\hbG{{\\hat{\\ensuremath{\\mathbf G}} }}\n\\def\\hbH{{\\hat{\\ensuremath{\\mathbf H}} }}\n\\def\\hbI{{\\hat{\\ensuremath{\\mathbf I}} }}\n\\def\\hbJ{{\\hat{\\ensuremath{\\mathbf J}} }}\n\\def\\hbK{{\\hat{\\ensuremath{\\mathbf K}} }}\n\\def\\hbL{{\\hat{\\ensuremath{\\mathbf L}} }}\n\\def\\hbM{{\\hat{\\ensuremath{\\mathbf M}} }}\n\\def\\hbN{{\\hat{\\ensuremath{\\mathbf N}} }}\n\\def\\hbO{{\\hat{\\ensuremath{\\mathbf O}} }}\n\\def\\hbP{{\\hat{\\ensuremath{\\mathbf P}} }}\n\\def\\hbQ{{\\hat{\\ensuremath{\\mathbf Q}} }}\n\\def\\hbR{{\\hat{\\ensuremath{\\mathbf R}} }}\n\\def\\hbS{{\\hat{\\ensuremath{\\mathbf S}} }}\n\\def\\hbT{{\\hat{\\ensuremath{\\mathbf T}} }}\n\\def\\hbU{{\\hat{\\ensuremath{\\mathbf U}} }}\n\\def\\hbV{{\\hat{\\ensuremath{\\mathbf V}} }}\n\\def\\hbW{{\\hat{\\ensuremath{\\mathbf W}} }}\n\\def\\hbX{{\\hat{\\ensuremath{\\mathbf X}} }}\n\\def\\hbY{{\\hat{\\ensuremath{\\mathbf Y}} }}\n\\def\\hbZ{{\\hat{\\ensuremath{\\mathbf Z}} }}\n%\n%lower case\n%\n\\def\\hba{{\\hat{\\ensuremath{\\mathbf a}} }}\n\\def\\hbb{{\\hat{\\ensuremath{\\mathbf b}} }}\n\\def\\hbc{{\\hat{\\ensuremath{\\mathbf c}} }}\n\\def\\hbd{{\\hat{\\ensuremath{\\mathbf d}} }}\n\\def\\hbe{{\\hat{\\ensuremath{\\mathbf e}} }}\n\\def\\hbf{{\\hat{\\ensuremath{\\mathbf f}} }}\n\\def\\hbg{{\\hat{\\ensuremath{\\mathbf g}} }}\n\\def\\hbh{{\\hat{\\ensuremath{\\mathbf h}} }}\n\\def\\hbi{{\\hat{\\ensuremath{\\mathbf i}} }}\n\\def\\hbj{{\\hat{\\ensuremath{\\mathbf j}} }}\n\\def\\hbk{{\\hat{\\ensuremath{\\mathbf k}} }}\n\\def\\hbl{{\\hat{\\ensuremath{\\mathbf l}} }}\n\\def\\hbm{{\\hat{\\ensuremath{\\mathbf m}} }}\n\\def\\hbn{{\\hat{\\ensuremath{\\mathbf n}} }}\n\\def\\hbo{{\\hat{\\ensuremath{\\mathbf o}} }}\n\\def\\hbp{{\\hat{\\ensuremath{\\mathbf p}} }}\n\\def\\hbq{{\\hat{\\ensuremath{\\mathbf q}} }}\n\\def\\hbr{{\\hat{\\ensuremath{\\mathbf r}} }}\n\\def\\hbs{{\\hat{\\ensuremath{\\mathbf s}} }}\n\\def\\hbt{{\\hat{\\ensuremath{\\mathbf t}} }}\n\\def\\hbu{{\\hat{\\ensuremath{\\mathbf u}} }}\n\\def\\hbv{{\\hat{\\ensuremath{\\mathbf v}} }}\n\\def\\hbw{{\\hat{\\ensuremath{\\mathbf w}} }}\n\\def\\hbx{{\\hat{\\ensuremath{\\mathbf x}} }}\n\\def\\hby{{\\hat{\\ensuremath{\\mathbf y}} }}\n\\def\\hbz{{\\hat{\\ensuremath{\\mathbf z}} }}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of hat bold  bersion\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%tilde bold version\n%upper case\n%\n\\def\\tbA{{\\tilde{\\ensuremath{\\mathbf A}} }}\n\\def\\tbB{{\\tilde{\\ensuremath{\\mathbf B}} }}\n\\def\\tbC{{\\tilde{\\ensuremath{\\mathbf C}} }}\n\\def\\tbD{{\\tilde{\\ensuremath{\\mathbf D}} }}\n\\def\\tbE{{\\tilde{\\ensuremath{\\mathbf E}} }}\n\\def\\tbF{{\\tilde{\\ensuremath{\\mathbf F}} }}\n\\def\\tbG{{\\tilde{\\ensuremath{\\mathbf G}} }}\n\\def\\tbH{{\\tilde{\\ensuremath{\\mathbf H}} }}\n\\def\\tbI{{\\tilde{\\ensuremath{\\mathbf I}} }}\n\\def\\tbJ{{\\tilde{\\ensuremath{\\mathbf J}} }}\n\\def\\tbK{{\\tilde{\\ensuremath{\\mathbf K}} }}\n\\def\\tbL{{\\tilde{\\ensuremath{\\mathbf L}} }}\n\\def\\tbM{{\\tilde{\\ensuremath{\\mathbf M}} }}\n\\def\\tbN{{\\tilde{\\ensuremath{\\mathbf N}} }}\n\\def\\tbO{{\\tilde{\\ensuremath{\\mathbf O}} }}\n\\def\\tbP{{\\tilde{\\ensuremath{\\mathbf P}} }}\n\\def\\tbQ{{\\tilde{\\ensuremath{\\mathbf Q}} }}\n\\def\\tbR{{\\tilde{\\ensuremath{\\mathbf R}} }}\n\\def\\tbS{{\\tilde{\\ensuremath{\\mathbf S}} }}\n\\def\\tbT{{\\tilde{\\ensuremath{\\mathbf T}} }}\n\\def\\tbU{{\\tilde{\\ensuremath{\\mathbf U}} }}\n\\def\\tbV{{\\tilde{\\ensuremath{\\mathbf V}} }}\n\\def\\tbW{{\\tilde{\\ensuremath{\\mathbf W}} }}\n\\def\\tbX{{\\tilde{\\ensuremath{\\mathbf X}} }}\n\\def\\tbY{{\\tilde{\\ensuremath{\\mathbf Y}} }}\n\\def\\tbZ{{\\tilde{\\ensuremath{\\mathbf Z}} }}\n%\n%lower case\n%\n\\def\\tba{{\\tilde{\\ensuremath{\\mathbf a}} }}\n\\def\\tbb{{\\tilde{\\ensuremath{\\mathbf b}} }}\n\\def\\tbc{{\\tilde{\\ensuremath{\\mathbf c}} }}\n\\def\\tbd{{\\tilde{\\ensuremath{\\mathbf d}} }}\n\\def\\tbe{{\\tilde{\\ensuremath{\\mathbf e}} }}\n\\def\\tbf{{\\tilde{\\ensuremath{\\mathbf f}} }}\n\\def\\tbg{{\\tilde{\\ensuremath{\\mathbf g}} }}\n\\def\\tbh{{\\tilde{\\ensuremath{\\mathbf h}} }}\n\\def\\tbi{{\\tilde{\\ensuremath{\\mathbf i}} }}\n\\def\\tbj{{\\tilde{\\ensuremath{\\mathbf j}} }}\n\\def\\tbk{{\\tilde{\\ensuremath{\\mathbf k}} }}\n\\def\\tbl{{\\tilde{\\ensuremath{\\mathbf l}} }}\n\\def\\tbm{{\\tilde{\\ensuremath{\\mathbf m}} }}\n\\def\\tbn{{\\tilde{\\ensuremath{\\mathbf n}} }}\n\\def\\tbo{{\\tilde{\\ensuremath{\\mathbf o}} }}\n\\def\\tbp{{\\tilde{\\ensuremath{\\mathbf p}} }}\n\\def\\tbq{{\\tilde{\\ensuremath{\\mathbf q}} }}\n\\def\\tbr{{\\tilde{\\ensuremath{\\mathbf r}} }}\n\\def\\tbs{{\\tilde{\\ensuremath{\\mathbf s}} }}\n\\def\\tbt{{\\tilde{\\ensuremath{\\mathbf t}} }}\n\\def\\tbu{{\\tilde{\\ensuremath{\\mathbf u}} }}\n\\def\\tbv{{\\tilde{\\ensuremath{\\mathbf v}} }}\n\\def\\tbw{{\\tilde{\\ensuremath{\\mathbf w}} }}\n\\def\\tbx{{\\tilde{\\ensuremath{\\mathbf x}} }}\n\\def\\tby{{\\tilde{\\ensuremath{\\mathbf y}} }}\n\\def\\tbz{{\\tilde{\\ensuremath{\\mathbf z}} }}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of tilde bold  bersion\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%bold caligraph\n%\n\\def\\bbcalA{\\mbox{\\boldmath $\\mathcal{A}$}}\n\\def\\bbcalB{\\mbox{\\boldmath $\\mathcal{B}$}}\n\\def\\bbcalC{\\mbox{\\boldmath $\\mathcal{C}$}}\n\\def\\bbcalD{\\mbox{\\boldmath $\\mathcal{D}$}}\n\\def\\bbcalE{\\mbox{\\boldmath $\\mathcal{E}$}}\n\\def\\bbcalF{\\mbox{\\boldmath $\\mathcal{F}$}}\n\\def\\bbcalG{\\mbox{\\boldmath $\\mathcal{G}$}}\n\\def\\bbcalH{\\mbox{\\boldmath $\\mathcal{H}$}}\n\\def\\bbcalI{\\mbox{\\boldmath $\\mathcal{I}$}}\n\\def\\bbcalJ{\\mbox{\\boldmath $\\mathcal{J}$}}\n\\def\\bbcalK{\\mbox{\\boldmath $\\mathcal{K}$}}\n\\def\\bbcalL{\\mbox{\\boldmath $\\mathcal{L}$}}\n\\def\\bbcalM{\\mbox{\\boldmath $\\mathcal{M}$}}\n\\def\\bbcalN{\\mbox{\\boldmath $\\mathcal{N}$}}\n\\def\\bbcalO{\\mbox{\\boldmath $\\mathcal{O}$}}\n\\def\\bbcalP{\\mbox{\\boldmath $\\mathcal{P}$}}\n\\def\\bbcalQ{\\mbox{\\boldmath $\\mathcal{Q}$}}\n\\def\\bbcalR{\\mbox{\\boldmath $\\mathcal{R}$}}\n\\def\\bbcalW{\\mbox{\\boldmath $\\mathcal{W}$}}\n\\def\\bbcalU{\\mbox{\\boldmath $\\mathcal{U}$}}\n\\def\\bbcalV{\\mbox{\\boldmath $\\mathcal{V}$}}\n\\def\\bbcalS{\\mbox{\\boldmath $\\mathcal{S}$}}\n\\def\\bbcalT{\\mbox{\\boldmath $\\mathcal{T}$}}\n\\def\\bbcalX{\\mbox{\\boldmath $\\mathcal{X}$}}\n\\def\\bbcalY{\\mbox{\\boldmath $\\mathcal{Y}$}}\n\\def\\bbcalZ{\\mbox{\\boldmath $\\mathcal{Z}$}}\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of caligraph\n%\n%\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%tilde Greek\n%\n\\def\\tdupsilon{\\tilde\\upsilon}\n\\def\\tdalpha{\\tilde\\alpha}\n\\def\\tbeta{\\tilde\\beta}\n\\def\\tdgamma{\\tilde\\gamma}\n\\def\\tddelta{\\tilde\\delta}\n\\def\\tdepsilon{\\tilde\\epsilon}\n\\def\\tdvarepsilon{\\tilde\\varepsilon}\n\\def\\tdzeta{\\tilde\\zeta}\n\\def\\tdeta{\\tilde\\eta}\n\\def\\tdtheta{\\tilde\\theta}\n\\def\\tdvartheta{\\tilde\\vartheta}\n\n\\def\\tdiota{\\tilde\\iota}\n\\def\\tdkappa{\\tilde\\kappa}\n\\def\\tdlambda{\\tilde\\lambda}\n\\def\\tdmu{\\tilde\\mu}\n\\def\\tdnu{\\tilde\\nu}\n\\def\\tdxi{\\tilde\\xi}\n\\def\\tdpi{\\tilde\\pi}\n\\def\\tdrho{\\tilde\\rho}\n\\def\\tdvarrho{\\tilde\\varrho}\n\\def\\tdsigma{\\tilde\\sigma}\n\\def\\tdvarsigma{\\tilde\\varsigma}\n\\def\\tdtau{\\tilde\\tau}\n\\def\\tdupsilon{\\tilde\\upsilon}\n\\def\\tdphi{\\tilde\\phi}\n\\def\\tdvarphi{\\tilde\\varphi}\n\\def\\tdchi{\\tilde\\chi}\n\\def\\tdpsi{\\tilde\\psi}\n\\def\\tdomega{\\tilde\\omega}\n\n\\def\\tdGamma{\\tilde\\Gamma}\n\\def\\tdDelta{\\tilde\\Delta}\n\\def\\tdTheta{\\tilde\\Theta}\n\\def\\tdLambda{\\tilde\\Lambda}\n\\def\\tdXi{\\tilde\\Xi}\n\\def\\tdPi{\\tilde\\Pi}\n\\def\\tdSigma{\\tilde\\Sigma}\n\\def\\tdUpsilon{\\tilde\\Upsilon}\n\\def\\tdPhi{\\tilde\\Phi}\n\\def\\tdPsi{\\tilde\\Psi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of title  Greek\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%bar Greek\n%\n\\def\\bbarupsilon{\\bar\\upsilon}\n\\def\\bbaralpha{\\bar\\alpha}\n\\def\\bbarbeta{\\bar\\beta}\n\\def\\bbargamma{\\bar\\gamma}\n\\def\\bbardelta{\\bar\\delta}\n\\def\\bbarepsilon{\\bar\\epsilon}\n\\def\\bbarvarepsilon{\\bar\\varepsilon}\n\\def\\bbarzeta{\\bar\\zeta}\n\\def\\bbareta{\\bar\\eta}\n\\def\\bbartheta{\\bar\\theta}\n\\def\\bbarvartheta{\\bar\\vartheta}\n\n\\def\\bbariota{\\bar\\iota}\n\\def\\bbarkappa{\\bar\\kappa}\n\\def\\bbarlambda{\\bar\\lambda}\n\\def\\bbarmu{\\bar\\mu}\n\\def\\bbarnu{\\bar\\nu}\n\\def\\bbarxi{\\bar\\xi}\n\\def\\bbarpi{\\bar\\pi}\n\\def\\bbarrho{\\bar\\rho}\n\\def\\bbarvarrho{\\bar\\varrho}\n\\def\\bbarvarsigma{\\bar\\varsigma}\n\\def\\bbarphi{\\bar\\phi}\n\\def\\bbarvarphi{\\bar\\varphi}\n\\def\\bbarchi{\\bar\\chi}\n\\def\\bbarpsi{\\bar\\psi}\n\\def\\bbaromega{\\bar\\omega}\n\n\\def\\bbarGamma{\\bar\\Gamma}\n\\def\\bbarDelta{\\bar\\Delta}\n\\def\\bbarTheta{\\bar\\Theta}\n\\def\\bbarLambda{\\bar\\Lambda}\n\\def\\bbarXi{\\bar\\Xi}\n\\def\\bbarPi{\\bar\\Pi}\n\\def\\bbarSigma{\\bar\\Sigma}\n\\def\\bbarUpsilon{\\bar\\Upsilon}\n\\def\\bbarPhi{\\bar\\Phi}\n\\def\\bbarPsi{\\bar\\Psi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of bar  Greek\n%\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%begion of check Greek\n%\n\\def\\chkupsilon{\\check\\upsilon}\n\\def\\chkalpha{\\check\\alpha}\n\\def\\chkbeta{\\check\\beta}\n\\def\\chkgamma{\\check\\gamma}\n\\def\\chkdelta{\\check\\delta}\n\\def\\chkepsilon{\\check\\epsilon}\n\\def\\chkvarepsilon{\\check\\varepsilon}\n\\def\\chkzeta{\\check\\zeta}\n\\def\\chketa{\\check\\eta}\n\\def\\chktheta{\\check\\theta}\n\\def\\chkvartheta{\\check\\vartheta}\n\n\\def\\chkiota{\\check\\iota}\n\\def\\chkkappa{\\check\\kappa}\n\\def\\chklambda{\\check\\lambda}\n\\def\\chkmu{\\check\\mu}\n\\def\\chknu{\\check\\nu}\n\\def\\chkxi{\\check\\xi}\n\\def\\chkpi{\\check\\pi}\n\\def\\chkrho{\\check\\rho}\n\\def\\chkvarrho{\\check\\varrho}\n\\def\\chksigma{\\check\\sigma}\n\\def\\chkvarsigma{\\check\\varsigma}\n\\def\\chktau{\\check\\tau}\n\\def\\chkupsilon{\\check\\upsilon}\n\\def\\chkphi{\\check\\phi}\n\\def\\chkvarphi{\\check\\varphi}\n\\def\\chkchi{\\check\\chi}\n\\def\\chkpsi{\\check\\psi}\n\\def\\chkomega{\\check\\omega}\n\n\\def\\chkGamma{\\check\\Gamma}\n\\def\\chkDelta{\\check\\Delta}\n\\def\\chkTheta{\\check\\Theta}\n\\def\\chkLambda{\\check\\Lambda}\n\\def\\chkXi{\\check\\Xi}\n\\def\\chkPi{\\check\\Pi}\n\\def\\chkSigma{\\check\\Sigma}\n\\def\\chkUpsilon{\\check\\Upsilon}\n\\def\\chkPhi{\\check\\Phi}\n\\def\\chkPsi{\\check\\Psi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of check Greek\n%\n%\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bold Greek letter\n%\n\n\\def\\bbalpha{\\boldsymbol{\\alpha}}\n\\def\\bbbeta{\\boldsymbol{\\beta}}\n\\def\\bbgamma{\\boldsymbol{\\gamma}}\n\\def\\bbdelta{\\boldsymbol{\\delta}}\n\\def\\bbepsilon{\\boldsymbol{\\epsilon}}\n\\def\\bbvarepsilon{\\boldsymbol{\\varepsilon}}\n\\def\\bbzeta{\\boldsymbol{\\zeta}}\n\\def\\bbeta{\\boldsymbol{\\eta}}\n\\def\\bbtheta{\\boldsymbol{\\theta}}\n\\def\\bbvartheta{\\boldsymbol{\\vartheta}}\n\\def \\bbtau {\\boldsymbol{\\tau}}\n\\def\\bbupsilon{\\boldsymbol{\\upsilon}}\n\\def\\bbiota{\\boldsymbol{\\iota}}\n\\def\\bbkappa{\\boldsymbol{\\kappa}}\n\\def\\bblambda{\\boldsymbol{\\lambda}}\n\\def\\bblam{\\boldsymbol{\\lambda}}\n\\def\\bbmu{\\boldsymbol{\\mu}}\n\\def\\bbnu{\\boldsymbol{\\nu}}\n\\def\\bbxi{\\boldsymbol{\\xi}}\n\\def\\bbpi{\\boldsymbol{\\pi}}\n\\def\\bbrho{\\boldsymbol{\\rho}}\n\\def\\bbvarrho{\\boldsymbol{\\varrho}}\n\\def\\bbvarsigma{\\boldsymbol{\\varsigma}}\n\\def\\bbphi{\\boldsymbol{\\phi}}\n\\def\\bbvarphi{\\boldsymbol{\\varphi}}\n\\def\\bbchi{\\boldsymbol{\\chi}}\n\\def\\bbpsi{\\boldsymbol{\\psi}}\n\\def\\bbomega{\\boldsymbol{\\omega}}\n\\def\\bbGamma{\\boldsymbol{\\Gamma}}\n\\def\\bbDelta{\\boldsymbol{\\Delta}}\n\\def\\bbTheta{\\boldsymbol{\\Theta}}\n\\def\\bbLambda{\\boldsymbol{\\Lambda}}\n\\def\\bbXi{\\boldsymbol{\\Xi}}\n\\def\\bbPi{\\boldsymbol{\\Pi}}\n\\def\\bbSigma{\\boldsymbol{\\Sigma}}\n\\def\\bbUpsilon{\\boldsymbol{\\Upsilon}}\n\\def\\bbPhi{\\boldsymbol{\\Phi}}\n\\def\\bbPsi{\\boldsymbol{\\Psi}}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of Bold Greek\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%bar Bold Greek\n%\n\\def\\barbupsilon{\\bar\\bbupsilon}\n\\def\\barbalpha{\\bar\\bbalpha}\n\\def\\barbbeta{\\bar\\bbbeta}\n\\def\\barbgamma{\\bar\\bbgamma}\n\\def\\barbdelta{\\bar\\bbdelta}\n\\def\\barbepsilon{\\bar\\bbepsilon}\n\\def\\barbvarepsilon{\\bar\\bbvarepsilon}\n\\def\\barbzeta{\\bar\\bbzeta}\n\\def\\barbeta{\\bar\\bbeta}\n\\def\\barbtheta{\\bar\\bbtheta}\n\\def\\barbvartheta{\\bar\\bbvartheta}\n\n\\def\\barbiota{\\bar\\bbiota}\n\\def\\barbkappa{\\bar\\bbkappa}\n\\def\\barblambda{\\bar\\bblambda}\n\\def\\barbmu{\\bar\\bbmu}\n\\def\\barbnu{\\bar\\bbnu}\n\\def\\barbxi{\\bar\\bbxi}\n\\def\\barbpi{\\bar\\bbpi}\n\\def\\barbrho{\\bar\\bbrho}\n\\def\\barbvarrho{\\bar\\bbvarrho}\n\\def\\barbvarsigma{\\bar\\bbvarsigma}\n\\def\\barbphi{\\bar\\bbphi}\n\\def\\barbvarphi{\\bar\\bbvarphi}\n\\def\\barbchi{\\bar\\bbchi}\n\\def\\barbpsi{\\bar\\bbpsi}\n\\def\\barbomega{\\bar\\bbomega}\n\n\\def\\barbGamma{\\bar\\bbGamma}\n\\def\\barbDelta{\\bar\\bbDelta}\n\\def\\barbTheta{\\bar\\bbTheta}\n\\def\\barbLambda{\\bar\\bbLambda}\n\\def\\barbXi{\\bar\\bbXi}\n\\def\\barbPi{\\bar\\bbPi}\n\\def\\barbSigma{\\bar\\bbSigma}\n\\def\\barbUpsilon{\\bar\\bbUpsilon}\n\\def\\barbPhi{\\bar\\bbPhi}\n\\def\\barbPsi{\\bar\\bbPsi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of bar Bold Greek\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%hat Bold Greek\n%\n\\def\\hbupsilon{\\hat\\bbupsilon}\n\\def\\hbalpha{\\hat\\bbalpha}\n\\def\\hbbeta{\\hat\\bbbeta}\n\\def\\hbgamma{\\hat\\bbgamma}\n\\def\\hbdelta{\\hat\\bbdelta}\n\\def\\hbepsilon{\\hat\\bbepsilon}\n\\def\\hbvarepsilon{\\hat\\bbvarepsilon}\n\\def\\hbzeta{\\hat\\bbzeta}\n\\def\\hbeta{\\hat\\bbeta}\n\\def\\hbtheta{\\hat\\bbtheta}\n\\def\\hbvartheta{\\hat\\bbvartheta}\n\n\\def\\hbiota{\\hat\\bbiota}\n\\def\\hbkappa{\\hat\\bbkappa}\n\\def\\hblambda{\\hat\\bblambda}\n\\def\\hbmu{\\hat\\bbmu}\n\\def\\hbnu{\\hat\\bbnu}\n\\def\\hbxi{\\hat\\bbxi}\n\\def\\hbpi{\\hat\\bbpi}\n\\def\\hbrho{\\hat\\bbrho}\n\\def\\hbvarrho{\\hat\\bbvarrho}\n\\def\\hbvarsigma{\\hat\\bbvarsigma}\n\\def\\hbphi{\\hat\\bbphi}\n\\def\\hbvarphi{\\hat\\bbvarphi}\n\\def\\hbchi{\\hat\\bbchi}\n\\def\\hbpsi{\\hat\\bbpsi}\n\\def\\hbomega{\\hat\\bbomega}\n\n\\def\\hbGamma{\\hat\\bbGamma}\n\\def\\hbDelta{\\hat\\bbDelta}\n\\def\\hbTheta{\\hat\\bbTheta}\n\\def\\hbLambda{\\hat\\bbLambda}\n\\def\\hbXi{\\hat\\bbXi}\n\\def\\hbPi{\\hat\\bbPi}\n\\def\\hbSigma{\\hat\\bbSigma}\n\\def\\hbUpsilon{\\hat\\bbUpsilon}\n\\def\\hbPhi{\\hat\\bbPhi}\n\\def\\hbPsi{\\hat\\bbPsi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of hat Bold Greek\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%tilde Bold Greek\n%\n\\def\\tbupsilon{\\tilde\\bbupsilon}\n\\def\\tbalpha{\\tilde\\bbalpha}\n\\def\\tbbeta{\\tilde\\bbbeta}\n\\def\\tbgamma{\\tilde\\bbgamma}\n\\def\\tbdelta{\\tilde\\bbdelta}\n\\def\\tbepsilon{\\tilde\\bbepsilon}\n\\def\\tbvarepsilon{\\tilde\\bbvarepsilon}\n\\def\\tbzeta{\\tilde\\bbzeta}\n\\def\\tbeta{\\tilde\\bbeta}\n\\def\\tbtheta{\\tilde\\bbtheta}\n\\def\\tbvartheta{\\tilde\\bbvartheta}\n\n\\def\\tbiota{\\tilde\\bbiota}\n\\def\\tbkappa{\\tilde\\bbkappa}\n\\def\\tblambda{\\tilde\\bblambda}\n\\def\\tbmu{\\tilde\\bbmu}\n\\def\\tbnu{\\tilde\\bbnu}\n\\def\\tbxi{\\tilde\\bbxi}\n\\def\\tbpi{\\tilde\\bbpi}\n\\def\\tbrho{\\tilde\\bbrho}\n\\def\\tbvarrho{\\tilde\\bbvarrho}\n\\def\\tbvarsigma{\\tilde\\bbvarsigma}\n\\def\\tbphi{\\tilde\\bbphi}\n\\def\\tbvarphi{\\tilde\\bbvarphi}\n\\def\\tbchi{\\tilde\\bbchi}\n\\def\\tbpsi{\\tilde\\bbpsi}\n\\def\\tbomega{\\tilde\\bbomega}\n\n\\def\\tbGamma{\\tilde\\bbGamma}\n\\def\\tbDelta{\\tilde\\bbDelta}\n\\def\\tbTheta{\\tilde\\bbTheta}\n\\def\\tbLambda{\\tilde\\bbLambda}\n\\def\\tbXi{\\tilde\\bbXi}\n\\def\\tbPi{\\tilde\\bbPi}\n\\def\\tbSigma{\\tilde\\bbSigma}\n\\def\\tbUpsilon{\\tilde\\bbUpsilon}\n\\def\\tbPhi{\\tilde\\bbPhi}\n\\def\\tbPsi{\\tilde\\bbPsi}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of tilde Bold Greek\n\\def \\deltat {\\triangle t}\n\\def \\eps    {\\epsilon}\n\\def \\lam    {\\lambda}\n\\def \\bblam  {\\bblambda}\n\\def \\Lam    {\\Lambda}\n\\def \\bbLam  {\\bbLambda}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%hat greek\n%\n\\def\\hhattheta{\\hat\\theta}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%end of hat greek\n\n\n\\def\\chkA{{\\ensuremath{\\check A}}}\n\\def\\chkB{{\\ensuremath{\\check B}}}\n\\def\\chkC{{\\ensuremath{\\check C}}}\n\\def\\chkD{{\\ensuremath{\\check D}}}\n\\def\\chkE{{\\ensuremath{\\check E}}}\n\\def\\chkF{{\\ensuremath{\\check F}}}\n\\def\\chkG{{\\ensuremath{\\check G}}}\n\\def\\chkH{{\\ensuremath{\\check H}}}\n\\def\\chkI{{\\ensuremath{\\check I}}}\n\\def\\chkJ{{\\ensuremath{\\check J}}}\n\\def\\chkK{{\\ensuremath{\\check K}}}\n\\def\\chkL{{\\ensuremath{\\check L}}}\n\\def\\chkM{{\\ensuremath{\\check M}}}\n\\def\\chkN{{\\ensuremath{\\check N}}}\n\\def\\chkO{{\\ensuremath{\\check O}}}\n\\def\\chkP{{\\ensuremath{\\check P}}}\n\\def\\chkQ{{\\ensuremath{\\check Q}}}\n\\def\\chkR{{\\ensuremath{\\check R}}}\n\\def\\chkW{{\\ensuremath{\\check W}}}\n\\def\\chkU{{\\ensuremath{\\check U}}}\n\\def\\chkV{{\\ensuremath{\\check V}}}\n\\def\\chkS{{\\ensuremath{\\check S}}}\n\\def\\chkT{{\\ensuremath{\\check T}}}\n\\def\\chkX{{\\ensuremath{\\check X}}}\n\\def\\chkY{{\\ensuremath{\\check Y}}}\n\\def\\chkZ{{\\ensuremath{\\check Z}}}\n\n\\def\\cba{\\check{\\bba}}\n\\def\\cbb{\\check{\\bbb}}\n\\def\\cbc{\\check{\\bbc}}\n\\def\\cbd{\\check{\\bbd}}\n\\def\\cbe{\\check{\\bbe}}\n\\def\\cbf{\\check{\\bbf}}\n\\def\\cbg{\\check{\\bbg}}\n\\def\\cbh{\\check{\\bbh}}\n\\def\\cbi{\\check{\\bbi}}\n\\def\\cbj{\\check{\\bbj}}\n\\def\\cbk{\\check{\\bbk}}\n\\def\\cbl{\\check{\\bbl}}\n\\def\\cbm{\\check{\\bbm}}\n\\def\\cbn{\\check{\\bbn}}\n\\def\\cbo{\\check{\\bbo}}\n\\def\\cbp{\\check{\\bbp}}\n\\def\\cbq{\\check{\\bbq}}\n\\def\\cbr{\\check{\\bbr}}\n\\def\\cbs{\\check{\\bbs}}\n\\def\\cbt{\\check{\\bbt}}\n\\def\\cbu{\\check{\\bbu}}\n\\def\\cbv{\\check{\\bbv}}\n\\def\\cbw{\\check{\\bbw}}\n\\def\\cbx{\\check{\\bbx}}\n\\def\\cby{\\check{\\bby}}\n\\def\\cbz{\\check{\\bbz}}\n\n\\def\\cbA{\\check{\\bbA}}\n\\def\\cbB{\\check{\\bbB}}\n\\def\\cbC{\\check{\\bbC}}\n\\def\\cbD{\\check{\\bbD}}\n\\def\\cbE{\\check{\\bbE}}\n\\def\\cbF{\\check{\\bbF}}\n\\def\\cbG{\\check{\\bbG}}\n\\def\\cbH{\\check{\\bbH}}\n\\def\\cbI{\\check{\\bbI}}\n\\def\\cbJ{\\check{\\bbJ}}\n\\def\\cbK{\\check{\\bbK}}\n\\def\\cbL{\\check{\\bbL}}\n\\def\\cbM{\\check{\\bbM}}\n\\def\\cbN{\\check{\\bbN}}\n\\def\\cbO{\\check{\\bbO}}\n\\def\\cbP{\\check{\\bbP}}\n\\def\\cbQ{\\check{\\bbQ}}\n\\def\\cbR{\\check{\\bbR}}\n\\def\\cbS{\\check{\\bbS}}\n\\def\\cbT{\\check{\\bbT}}\n\\def\\cbU{\\check{\\bbU}}\n\\def\\cbV{\\check{\\bbV}}\n\\def\\cbW{\\check{\\bbW}}\n\\def\\cbX{\\check{\\bbX}}\n\\def\\cbY{\\check{\\bbY}}\n\\def\\cbZ{\\check{\\bbZ}}\n\n\\def\\kcalA{\\check{\\ccalA}}\n\\def\\kcalB{\\check{\\ccalB}}\n\\def\\kcalC{\\check{\\ccalC}}\n\\def\\kcalD{\\check{\\ccalD}}\n\\def\\kcalE{\\check{\\ccalE}}\n\\def\\kcalF{\\check{\\ccalF}}\n\\def\\kcalG{\\check{\\ccalG}}\n\\def\\kcalH{\\check{\\ccalH}}\n\\def\\kcalI{\\check{\\ccalI}}\n\\def\\kcalJ{\\check{\\ccalJ}}\n\\def\\kcalK{\\check{\\ccalK}}\n\\def\\kcalL{\\check{\\ccalL}}\n\\def\\kcalM{\\check{\\ccalM}}\n\\def\\kcalN{\\check{\\ccalN}}\n\\def\\kcalO{\\check{\\ccalO}}\n\\def\\kcalP{\\check{\\ccalP}}\n\\def\\kcalQ{\\check{\\ccalQ}}\n\\def\\kcalR{\\check{\\ccalR}}\n\\def\\kcalS{\\check{\\ccalS}}\n\\def\\kcalT{\\check{\\ccalT}}\n\\def\\kcalU{\\check{\\ccalU}}\n\\def\\kcalV{\\check{\\ccalV}}\n\\def\\kcalW{\\check{\\ccalW}}\n\\def\\kcalX{\\check{\\ccalX}}\n\\def\\kcalY{\\check{\\ccalY}}\n\\def\\kcalZ{\\check{\\ccalZ}}\n\n\\def\\hcalA{\\hat{\\ccalA}}\n\\def\\hcalB{\\hat{\\ccalB}}\n\\def\\hcalC{\\hat{\\ccalC}}\n\\def\\hcalD{\\hat{\\ccalD}}\n\\def\\hcalE{\\hat{\\ccalE}}\n\\def\\hcalF{\\hat{\\ccalF}}\n\\def\\hcalG{\\hat{\\ccalG}}\n\\def\\hcalH{\\hat{\\ccalH}}\n\\def\\hcalI{\\hat{\\ccalI}}\n\\def\\hcalJ{\\hat{\\ccalJ}}\n\\def\\hcalK{\\hat{\\ccalK}}\n\\def\\hcalL{\\hat{\\ccalL}}\n\\def\\hcalM{\\hat{\\ccalM}}\n\\def\\hcalN{\\hat{\\ccalN}}\n\\def\\hcalO{\\hat{\\ccalO}}\n\\def\\hcalP{\\hat{\\ccalP}}\n\\def\\hcalQ{\\hat{\\ccalQ}}\n\\def\\hcalR{\\hat{\\ccalR}}\n\\def\\hcalS{\\hat{\\ccalS}}\n\\def\\hcalT{\\hat{\\ccalT}}\n\\def\\hcalU{\\hat{\\ccalU}}\n\\def\\hcalV{\\hat{\\ccalV}}\n\\def\\hcalW{\\hat{\\ccalW}}\n\\def\\hcalX{\\hat{\\ccalX}}\n\\def\\hcalY{\\hat{\\ccalY}}\n\\def\\hcalZ{\\hat{\\ccalZ}}\n\n\\def\\hhatsigma{\\hat{\\sigma}}\n\\def\\chksigma{\\check{\\sigma}} \n% This is a global control on the scale of plots. The constant \\myfactor can be defined inside of an individual picture. It is good practice to reset \\myfactor to 1 after the end of the picture.\n\\def\\myfactor{1.0}\n\\def\\unit{\\myfactor cm}\n\n\n% This command sets the appearance of axis on pgfplots\n\\pgfplotsset{ ylabel near ticks,                 % Make x axis label appear close to figure\n              xlabel near ticks,                 % Make y axis label appear close to figure\n              tick label style = {font=\\footnotesize},   % Write numbers in tiny font\n              label style = {font=\\footnotesize}, % Write axes labels in footnote size font\n              title style = {font=\\footnotesize},\n            }\n\n% Definition of a graph node without filled in color. \n% Controls the appearance of a node in a graph plot\n\\tikzstyle{empty node} = [ circle, \n                     draw = black,\n                     text = black, \n                     minimum size = 0.8*\\unit]\n\n\n% Definition of a graph node. Controls the appearance of a node in a graph plot\n\\tikzstyle{node} = [ empty node, \n                     fill = blue!50,\n                     draw = blue!50,\n                     text = white]\n\n\\tikzstyle{blue node} = [ empty node, \n                         fill = blue!50,\n                         draw = blue!50,\n                         text = white]\n\n\\tikzstyle{red node} = [ empty node, \n                         fill = red!50,\n                         draw = red!50,\n                         text = white]\n\n\\tikzstyle{green node} = [ empty node, \n                         fill = mygreen!50,\n                         draw = mygreen!50,\n                         text = white]\n\n\n\\tikzstyle{black node} = [ empty node, \n                           fill = black!40,\n                           draw = black!40,\n                           text = white]\n\n                         \n% Definition of a graph signal dot value without filled in color.\n% These are smaller than the nodes and do not allow for text.\n% Controls the appearance of a graph signal dot value in a graph plot\n\\tikzstyle{empty dot} = [ circle, \n                           draw = black,\n                           inner sep = 0pt,\n                           anchor = center,\n                           minimum size = 0.4*\\unit]\n\n\n% Definition of a graph signal dot value.\n% Controls the appearance of a graph signal dot value in a graph plot\n\\tikzstyle{dot} = [ empty dot, \n                    fill = blue!50,\n                    draw = blue!50]\n\n\\tikzstyle{blue dot} = [ empty dot, \n                         fill = blue!50,\n                         draw = blue!50]\n\n\\tikzstyle{red dot} = [ empty dot, \n                        fill = red!50,\n                        draw = red!50]\n\n\\tikzstyle{black dot} = [ empty dot, \n                          fill = black!50,\n                          draw = black!50]\n\n\n% Definition of graph edges. An edge is undirected and doesn't contain arrows. A directed edge has an arrow at the end and a double directed edge contains two arrows. The latter is to be used when we want to emphasize the double directivity.\n\\tikzstyle{edge}                 = [shorten >=1pt, shorten <=1pt]\n\\tikzstyle{directed edge}        = [edge, -stealth]\n\\tikzstyle{double directed edge} = [edge, stealth-stealth]\n\\tikzstyle{tight edge}                 = [shorten >=0pt, shorten <=0pt]\n\n\n% Definition of a block for block diagrams\n\\tikzstyle{block} = [ rectangle,\n                      minimum width = \\unit,\n                      minimum height = \\unit,\n                      fill = blue!15,\n                      draw = black,\n                      text = black]\n \n\\def\\Tr{\\mathsf{T}}\n\\def\\Hr{\\mathsf{H}}\n\\def\\Nul{\\mathrm{Nul}}\n\n\\def\\pcite{{\\color{pennpurple}[X]}}\n\n% Import from Santi S's \"diffusion_distance.tex\"\n\\newtheorem{assumption}{\\hspace{0pt}\\bf Assumption}\n\\newtheorem{lemma}{\\hspace{0pt}\\bf Lemma}\n\\newtheorem{proposition}{\\hspace{0pt}\\bf Proposition}\n\\newtheorem{example}{\\hspace{0pt}\\bf Example}\n\\newtheorem{observation}{\\hspace{0pt}\\bf Observation}\n\\newtheorem{theorem}{\\hspace{0pt}\\bf Theorem}\n\\newtheorem{corollary}{\\hspace{0pt}\\bf Corollary}\n\\newtheorem{fact}{\\hspace{0pt}\\bf Fact}\n\\newtheorem{remark}{\\hspace{0pt}\\bf Remark}\n\\newtheorem{test}{\\hspace{0pt}\\it Test Case}\n\\newtheorem{definition}{\\hspace{0pt}\\bf Definition}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                           TITLE AND AUTHORS                            %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n% Title.\n% ------\n\\title{NONLINEAR STATE-SPACE GENERALIZATIONS OF GRAPH CONVOLUTIONAL NEURAL NETWORKS}\n%\n% Single address.\n% ---------------\n\\name{Luana Ruiz$^{*}$, Fernando Gama$^\\dagger$, Alejandro Ribeiro$^{*}$ and Elvin Isufi$^\\ddagger$\\thanks{Supported by USA NSF CCF 1717120, ARL DCIST CRA W911NF-17-2-0181. \n        %Email contact: \\{rubruiz,fgama,aribeiro\\}@seas.upenn.edu, antonio.garcia.marques@urjc.es.\n    }\n}\n\\address{$^{*}$Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, USA \\\\\n    $^{\\dagger}$Electrical Engineering and Computer Sciences Department, University of California, Berkeley, USA \\\\\n    $^{\\ddagger}$Department of Intelligent Systems, Delft University of Technology, Netherlands\n}\n%\n% For example:\n% ------------\n%\\address{School\\\\\n%\tDepartment\\\\\n%\tAddress}\n%\n% Two addresses (uncomment and modify for two-address case).\n% ----------------------------------------------------------\n%\\twoauthors\n%{Luana Ruiz, Alejandro Ribeiro\\thanks{Supported by NSF CCF 1717120, ARO W911NF1710438, ARL DCIST CRA W911NF-17-2-0181, ISTC-WAS and Intel DevCloud.}}\n%{University of Pennsylvania\\\\\n%    Dept. of Electrical and Systems Engineering\\\\\n%    Philadelphia, PA}\n%{Fer\\hspace{0.015cm}nando Gama}\n%{University of California, Berkeley\\\\\n%    Electrical Eng. and Computer Sci. Dept.\\\\\n%    Berkeley, CA}\n%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                             BEGIN DOCUMENT                             %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\\begin{document}\n\\ninept\n%\n\\maketitle\n%\n\\begin{abstract}\nGraph convolutional neural networks (GCNNs) learn compositional representations from network data by nesting linear graph convolutions into nonlinearities. In this work, we approach GCNNs from a state-space perspective revealing that the graph convolutional module is a minimalistic linear state-space model, in which the state update matrix is the graph shift operator. We show this state update may be problematic because it is nonparametric, and depending on the graph spectrum it may explode or vanish. Therefore, the GCNN has to trade its degrees of freedom between extracting features from data and handling these instabilities. To improve such trade-off, we propose a novel family of nodal aggregation rules that aggregates node features within a layer in a nonlinear state-space parametric fashion, and allowing for a better trade-off. We develop two architectures within this family inspired by the recursive ideas with and without nodal gating mechanisms. The proposed solutions generalize the GCNN and provide an additional handle to control the state update and learn from the data. Numerical results on source localization and authorship attribution show the superiority of the nonlinear state-space generalization models over the baseline GCNN.\n\\end{abstract}\n%\n\\begin{keywords}\n    graph neural networks, state-space models, nonlinear systems, graph signal processing\n\\end{keywords}\n%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                              INTRODUCTION                              %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{Introduction}\n\\label{sec:intro}\n\n%!TEX root = 00-rsn-ICASSP21.tex\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                              INTRODUCTION                              %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sec:intro %%%%\n%%%%%%%%%%%%%%%%%%%\n\nGraph convolutional neural networks (GCNNs) learn a parametric map from high-dimensional data whose dependencies can be represented by a graph, e.g., biological data, financial data, and social network data \\cite{newman2010networks, bullmore2009complex, jackson2010social}. The GCNN map is a compositional layered function of simpler ones, where each layer is composed of a linear graph convolutional filter nested into a nonlinearity \\cite{gama2020graphs}. The graph serves as the prior about the data structure and restricts the space of functions to those exploiting this prior so that to bias learning effectively. \n\nGCNNs have been developed from different equivalent viewpoints either in the graph spectral domain or in the vertex domain. The work in \\cite{bruna2013spectral} leveraged spectral graph theory to convolve the data with a learnable filter as a pointwise multiplication in the Laplacian eigenspace. Subsequently, \\cite{defferrard2016convolutional, du2017topology, gama2018convolutional, xu2018powerful} built upon the shift-and-sum structure to perform convolutions directly in the vertex domain; an operation known also as finite impulse response (FIR) graph filtering \\cite{shuman2013emerging, sandryhaila2013discrete}. Changing the filter type to an autoregressive moving average (ARMA) form \\cite{isufi2017autoregressive}, the works in \\cite{levie2017cayleynets, wijesinghe2019dfnets, isufi2020edgenets} implemented GCNNs with a rational spectral response in the convolutional layer. Differently, the work in \\cite{velickovic2017graph} followed the attention idea \\cite{vaswani2017attention} to aggregate nodal features, which turns out to be also an FIR graph convolutional filter of order one on a graph whose edge weights are learned from data \\cite{isufi2020edgenets}.\n\nSince the graph filter is the tool that exploits the \\emph{graph-data coupling} within GCNNs, most of the contributions proposed filters operating with different graph representation matrices or with different implementations. While beneficial in specific applications, this strategy narrows the view towards the linear nodal feature aggregation, consequently, it overshadows the implicit state-space model present in graph convolutions. Unveiling and analyzing this state-space model can bring new insight into how graph convolutions operate and can allow the proposal of more general nodal aggregation schemes. In fact, state-space models have resulted fundamental in advancing Markov chains, Kalman filtering \\cite{Simon2006}, and recurrent neural networks \\cite{goodfellow2016deep}. \n\nInspired by the coupling between state-space models and sequential statistical learning, we put forth a similar interplay for graph convolutional filters. The state-space model considers the graph representation matrix (e.g., adjacency, Laplacian) as the state transition matrix while the intermediate nodal aggregations as system outputs (Section~\\ref{sec:prelims}). We then show the GCNN state-space convolutional module is rather limiting and propose appropriate generalizations towards a full-fledged non-linear state-space propagation rule (Section~\\ref{sec:rsns}). Concretely, the contributions of this paper are twofold. First, it proposes a state-space analysis of graph convolutions, revealing the GCNN is limited to linear nodal aggregations where the input signal of a specific layer vanishes/explodes with the filter order. Consequently, the filter coefficients have also to mitigate such effect. Second, it develops a new family of graph neural networks (GNNs), which considers non-linear nodal aggregations within a layer and have intra-layer residual bridges to account for the layer input signal in the higher-order aggregations. By making parallelisms with nonlinear state-space models and with conventional RNNs, we further introduce a gating mechanism to increase the nonlinear filter order but still account for multi-resolution information in a data-driven manner. These contributions have been corroborated with numerical results in source localization and authorship attribution (Section~\\ref{sec:sims}). Conclusions are drawn in Section~\\ref{sec:conclusions}. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                   GRAPH CONVOLUTIONAL NEURAL NETWORKS                  %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{Graph Convolutional neural networks}\n\\label{sec:prelims}\n\n%!TEX root = 00-rsn-ICASSP21.tex\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                   GRAPH CONVOLUTIONAL NEURAL NETWORKS                  %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sec:prelims %%%%\n%%%%%%%%%%%%%%%%%%%%%\n\nConsider a graph $\\ccalG = (\\ccalV, \\ccalE)$ with node set $\\ccalV = \\{1, \\ldots, N\\}$, edge set $\\ccalE \\subseteq \\ccalV \\times \\ccalV$, and shift operator matrix $\\bbS \\in \\reals^{N \\times N}$ such that entry $(i,j)$ satisfies $S_{ij} \\neq 0$ if $(j,i) \\in \\ccalE$ or $i = j$. Common choices for $\\bbS$ include the graph adjacency matrix $\\bbA$ or the graph Laplacian matrix $\\bbL$. Along with the graph, we are interested in learning from signals $\\bbx = [x_1, \\ldots x_N]^\\top$ residing on the vertices $\\ccalV$, in which entry $x_i$ corresponds to the signal at node $i$. The GSO $\\bbS$ plays a role to learn from this signal because the graph encodes pairwise relationships between signal components, which in turn serve as inductive prior.\nIn particular, if we consider a vector of coefficients $\\bbh = [h_0, \\ldots, h_{K}]^T$, we can use $\\bbS$ to define graph convolutional filters as \\cite{sandryhaila2013discrete}\n%\n\\begin{equation}\\label{eq:FIRout}\n\\bby = \\bbh *_\\bbS \\bbx = \\sum_{k = 0}^Kh_k\\bbS^k\\bbx := \\bbH(\\bbS)\\bbx\n\\end{equation}\n%\nwhere $\\bby$ is the filter output and $\\bbH(\\bbS) := \\sum_{k = 0}^Kh_k\\bbS^k$ is the filter matrix representation. \n%\nThe convolutional filter in \\eqref{eq:FIRout} leverages locally the graph-data coupling. To see this, consider operation $\\bbw_1 = \\bbS\\bbx$, which diffuses the input to neighboring vertices to produce another graph signal whose value $w_{1i}$ at node $i$ is a linear combination of signal values at the $1$-hop neighbors. Likewise, operation $\\bbw_k = \\bbS^k\\bbx$ shifts the input $k$ times to produce a graph signal whose value $w_{ki}$ at node $i$ is a linear combination of the input signal on neighbors that are at most $k$ hops away But since $\\bbw_k$ can also be obtained as $\\bbw_{k-1}$ as $\\bbw_k =\\bbS^k\\bbx = \\bbS\\bbw_{k-1}$, it implies an aggregation from one-hop neighbors of the former shifted signal $\\bbw_{k-1}$.\n\nLeveraging the graph convolutional filter in \\eqref{eq:FIRout}, we can define graph convolutional neural networks (GCNNs) as a compositional architecture of $L$ convolutional filters and nonlinearities. At layer $l$, the GCNN takes as input a collection of $F$ signal features input signals $\\{\\bbx_{l-1}^g\\}_{g =1}^F$ from the previous layer, processes them in parallel with a bank of $F^2$ graph convolutional filters $\\{\\bbH^{fg}_l\\}_{f=1}^F$, and passes these outputs to a nonlinearity to obtain the propagation rule\n%\n\\begin{equation}\\label{eq:convLay}\n\\bbx_l^f = \\sigma \\bigg(\\sum_{g = 1}^{F}\\bbH^{fg}_l(\\bbS)\\bbx^g_{l-1}\t\\bigg) = \\sigma \\bigg(\\sum_{g = 1}^{F}\\sum_{k = 0}^Kh^{fg}_{lk}\\bbS^k\\bbx^g_{l-1}\t\\bigg)\n\\end{equation}\n%\nfor $f = 1, \\ldots, F$. The $F$ outputs of layer $l$, $\\{\\bbx_l^f \\}_f$, are inputs to the subsequent layer $l+1$, and this process repeats itself until the last layer, $l = L$, is reached. If we consider for simplicity only one input feature $\\bbx_{0}:=\\bbx \\in \\reals^{N}$ and one output feature $\\bbx_L := \\bbx_L^1 \\in \\reals^{N}$, this GCNN can be written succinctly as the map $\\bbx_L = \\bbPhi(\\bbS; \\bbx; \\ccalH)$. This notation emphasizes the dependence of the parametrization on the GSO $\\bbS$ and on the filter coefficients $\\ccalH = \\{\\bbh_l^{fg}\\}_{fgl}$ for all layers $l$ and filter pairs $f,g$. Graph convolutional neural networks exhibit several desirable properties. Namely, they are local and distributed information processing architectures, making them perfectly suited for distributed learning \\cite{Owerko20-Power, Gama20-Distributed}. They are also permutation equivariant \\cite{Gama20-Stability, ZouLerman18-Scattering} and stable to changes in the underlying graph support \\cite{Gama20-Stability}. They also have isomorphic properties \\cite{xu2018powerful, Villar19-EquivIsomorphism, Hamilton19-Weisfeiler} and are found to be more discriminable than the corresponding graph filters \\cite{Pfrommer20-Discriminability}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%               THE STATE-SPACE MODEL OF GRAPH CONVOLUTIONS              %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\subsection{The State-Space Model of Graph Convolutions}\n\nA discrete linear system with inputs $\\bbu_k \\in \\reals^N$ and outputs $\\bby_k \\in \\reals^N$ can be expressed through its \\textit{state-space representation} \n%\n\\begin{align}\\label{eq:ssFormLinearSys}\n\\begin{split}\n\\bbw_k &= \\bbA\\bbw_{k-1}+\\bbB\\bbu_k\\\\\n\\bby_k &= \\bbC\\bbw_k + \\bbD\\bbu_k\n\\end{split} \\qquad k = 1, \\ldots, K\n\\end{align}\n%\nwhere $\\bbw_k \\in \\reals^N$ is the system state and $\\bbA$, $\\bbB$, $\\bbC,\\bbD \\in \\reals^{N\\times N}$ are the state-to-state, input-to-state, state-to-output, and input-to-output transition matrices, respectively.\nComparing the recursive implementation of \\eqref{eq:FIRout} with \\eqref{eq:ssFormLinearSys}, we see that the convolutional module of the GCNN layer can be represented as a discrete linear system where the steps $k$ correspond to graph shifts. Explicitly, the filter output $\\bby = \\bbH(\\bbS)\\bbx$ can be formulated as \n%\n\\begin{subequations}\\label{eq:ssFormComp}\n\\begin{align}\\label{eq:ssForm}\n\\begin{split}\n\\bbw_k &= \\bbS\\bbw_{k-1}\\\\\n\\bby_k &= h_k\\bbw_k\n\\end{split} \\qquad k = 1, \\ldots, K\\\\\n \\bby &= \\sum_{k = 0}^K\\bby_k \\label{eq:ssFormOverall}\n\\end{align}\n\\end{subequations}\n%\nwhere $\\bbu_k = \\boldsymbol{0}$, $\\bbA=\\bbS$ and $\\bbC=h_k\\bbI$. The state is initialized as $\\bbw_0 = \\bbx$, and the instantaneous output as $\\bby_0 = h_0\\bbw_0$. The overall filter output $\\bby$ is calculated as the sum of the $K+1$ instantaneous outputs $\\{\\bby_k\\}_k$. Equation \\eqref{eq:ssFormComp} makes for an interesting parallel between linear systems and graph convolutions. At the same time, it shows that the linear components of the layers of a GNN are rather simple dynamical systems. While this is not necessarily a disadvantage, it reveals the opportunity of increasing the expressive power of GNNs by modifying the linear system in \\eqref{eq:ssFormComp}.\n\nMoreover, we can see that if $\\bbS$ has eigenvalues greater than one in magnitude, the instantaneous state $\\bbw_k$ explodes. This implies the instantaneous outputs $\\bby_k$ will see little the input signal for larger $k$. In turn, this will force the network coefficients $\\bbh$, on one hand, to learn convolutional representations of the input, while, on the other hand, to mitigate the explosive states for larger order states. Likewise, a similar trade-off is present if $\\bbS$ has eigenvalues smaller than one in magnitude. In that case, we have to face with vanishing states, therefore, higher-order shifts from multi-hop neighbors will play little role in the final output. These trade-offs limit implicitly the degrees of freedom of the GCNN, consequently, the model captures only partially the coupling between the signal and the topology. This translates to limited expressive power. In the sequel, our goal is to generalize the convolutional state-space model \\eqref{eq:ssFormComp} to forms closer to a full-flagged non-linear state-space representation that still captures the coupling between the signal and the underlying topology. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                NONLINEAR STATE-SPACE EXTENSIONS OF GCNNS               %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{Nonlinear state-space extensions of GCNNs}\n\\label{sec:rsns} \n\n%!TEX root = 00-rsn-ICASSP21.tex\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                NONLINEAR STATE-SPACE EXTENSIONS OF GCNNS               %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sec:rsns %%%%\n%%%%%%%%%%%%%%%%%%\n\nIn this paper, we work towards extending the graph convolutional neural network to propagation rules within a layer that can be represented as the $N$-state discrete \\textit{nonlinear} system\n%\n\\begin{align}\\label{eq:ssRnn}\n\\begin{split}\n\\bbw_k &= \\sigma_w\\big(\\bbA\\bbw_{k-1} + \\bbB\\bbx_k\\big)\\\\\n\\bby_k &= \\sigma_y\\big(\\bbC\\bbw_k + \\bbD\\bbx_k \\big)\n\\end{split}.\n\\end{align}\n%\nContrasting \\eqref{eq:ssRnn} with the state space GCNN model \\eqref{eq:ssFormComp}, we can point out three key differences. \n\nFirst, system \\eqref{eq:ssFormComp} is linear in all of its components. The GCNN applies the nonlinearity only to the filter output $\\bby$, but not to the shifted signals $\\bbw_k$ nor to the instantaneous outputs $\\bby_k$. Thus, graph convolutions limit nodal feature aggregations to the linear space. \n\nSecond, in \\eqref{eq:ssFormComp} both the state $\\bbw_k$ and the instantaneous output $\\bby_k$ are disconnected from the input $\\bbx$. In fact, the input is only considered when initializing the state as $\\bbw_0 = \\bbx$. Therefore, its contribution to high-order shifts $\\bbw_k$ and instantaneous outputs $\\bby_k$ is small and affected by the shift operator spectra.\n%, because  vanishes quickly for $k \\gg 0$. \nAdditionally, nodes only learn weights to scale the influence of the values of the shifted signals $\\bbS^k\\bbx$ in their immediate neighborhood but leave unexploited any direct relationship with the input signal components of their $k$-hop neighbors. \n\nThird, while in \\eqref{eq:ssFormComp} the state $\\bbw_{k-1}$ is diffused through the graph to produce the next state $\\bbw_k$, there is no parametric relationship between state updates; i.e., $\\bbw_{k-1}$ and $\\bbw_{k}$. In turn, this leads to the instabilities related to the state-transition matrix $\\bbS$ discussed earlier. Making $\\bbw_k$ a graph parametric update of $\\bbw_{k-1}$ improves our control over the stability of the state-transition matrix as a whole. \n\nIn the GNN architectures we develop next, the nodal aggregation schemes emulate a nonlinear state-space model [cf. \\eqref{eq:ssRnn}] that accounts for the graph structure in a similar fashion to graph convolutions [cf. \\eqref{eq:ssFormComp}]. Approaching GNNs from this state-space perspective allows changing the family of propagation rules, which are generalized from the linear form in \\eqref{eq:convLay} to nonlinear node updates. As we will illustrate with the numerical experiments in Section \\ref{sec:sims}, these modifications significantly improve GNN performance in a variety of application scenarios. \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                     RSNs: RECURSIVE SHIFT NETWORKS                     %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sbs:rsns %%%%\n%%%%%%%%%%%%%%%%%%\n\n\\subsection{RSNs: Recursive Shift Networks} \\label{sbs:rsns}\n\nIn the so-called \\textit{recursive shift networks} (RSNs), we enhance the capacity of the filter \\eqref{eq:ssFormComp} by making both the state $\\bbw_k$ and the instantaneous output $\\bby_k$ nonlinear on the state $\\bbw_{k-1}$ and input $\\bbx$. Explicitly, the non-linear state-space model for an RSN has the form\n%\n\\begin{subequations}\\label{eq:singleShift}\n\\begin{align}\n\\begin{split}\n\\bbw_k &= \\sigma_w \\bigg(h_{kww}\\bbS\\bbw_{k-1} + h_{kwx}\\bbx\t\\bigg)\\\\\n\\bby_k &= \\sigma_y\\bigg(h_{kyw}\\bbw_k + h_{kyx}\\bbx\\bigg)\\qquad k = 1, \\ldots, K\n\\end{split}\\\\\n\\bby &= \\sigma_y\\bigg(\\sum_{k = 0}^K\\bby_k\\bigg)\n\\end{align}\n\\end{subequations}\n%\nwhere $h_{kww}$, $h_{kwx}$ are scalar weights encoding the dependency of state $\\bbw_k$ on state $\\bbw_{k-1}$ and the input $\\bbx$, respectively, while $h_{kyw}$, $h_{kyx}$ are scalar weights encoding the dependency of the instantaneous output $\\bby_k$ on the state $\\bbw_k$ and the input $\\bbx$, respectively. \nOn the one hand, \\eqref{eq:singleShift} retains the simplicity and efficiency of the convolutional graph filter \\eqref{eq:ssFormComp}; on the other, it improves the expressive power of the graph convolution by including nonlinearities. These additional parameters as well as the nonlinearities endow the RNS with minimal degrees of freedom that are enough to control with a better trade-off the explosion/vanishing of the state $\\bbw_k$.\n\nDespite looking similar to the conventional recurrent neural network (RNN) propagation rule, RSNs and RNNs are very different. RNNs have $N \\times N$ parameter matrices, whereas in \\eqref{eq:singleShift} the parameters of the nonlinear graph filters are independent of the graph dimensions. The nonlinear graph filters we consider share parameters across nodes---not shifts. This property is inherited from the graph convolutional filter [cf. \\eqref{eq:ssFormComp}], in which the parameters $h_k$ are distinct for different $\\bby_k$. These differences notwithstanding, we leverage the analogy with RNNs to consider gating mechanisms in Section \\ref{sbs:lssms}. \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                    LSSMs: LONG SHORT SHIFT MEMORIES                    %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sbs:lssms %%%%\n%%%%%%%%%%%%%%%%%%%\n\n\\subsection{LSSMs: Long Short Shift Memories} \\label{sbs:lssms}\n\nIn both \\eqref{eq:ssFormComp} and \\eqref{eq:singleShift}, the filter order $K$  controls the information locality in the vertex and spectral domains. In the vertex domain, the order implies that state $[\\bbw_K]_i$ at node $i$ receives information from nodes up to $K$ hops away; i.e., it defines a ``local window'' around the nodes. In the spectral domain, it controls the sharpness of the filter frequency response \\cite{shuman2013emerging, sandryhaila2013discrete}. When the information at a particular layer is localized around a few graph frequencies (eigenvalues of $\\bbS$), higher filter orders are needed; i.e., the filter order imposes a ``local window'' around the graph frequencies. This is in agreement with the uncertainty principle of signal localization \\cite{agaskar2013spectral, tsitsvero2016signals, teke2017uncertainty}, which states that low values of $K$ correspond to localized windows in the vertex domain, but not in the spectral domain (and vice-versa).\n\nIncreasing the filter order is thus necessary to capture more information in the vertex domain while retaining localized responses in the spectral domain. However, large $K$ usually leads to numerical instabilities associated with large powers $\\bbS^K$ and, depending on the eigenvalues of $\\bbS$, we also have to cope with vanishing or exploding gradients. These challenges are similar to those encountered in RNNs. There, they are typically addressed by gating mechanisms that introduce an additional set of parameters to control how the information propagates in different state updates \\cite{hochreiter1997long}. Here, we will use gates \\emph{within} the GNN layer to capture long dependencies over the graph because of the high order of \\eqref{eq:singleShift}. \n\nIn analogy with long-short term memories (LSTMs), we call our architecture \\emph{long-short shift memory} (LSSM). LSSMs comprise learnable gating parameters taking values in the interval $[0,1]$. These parameters control the information passed to state $\\bbw_k$ and instantaneous output $\\bby_k$ in \\eqref{eq:singleShift}. An LSSM filter comprises:\n%\n\\begin{itemize}\n\\item Updating the $N\\times 1$ internal memory variable $\\tbc[k]$ as\n%\n\\begin{equation}\\label{eq:insMem}\n\\tbc_k = \\tanh\\big(\th_{kcw}\\bbS\\bbw_{k-1} + h_{kcx}\\bbx\t\\big)\n\\end{equation}\n%\nto track the state update.\n\\item Updating the $N \\times 1$ forget gate $\\bbgamma_\\text{f}[k]$, update gate $\\bbgamma_\\text{u}[k]$, and state gate $\\bbgamma_\\text{w}[k]$ respectively as\n%\n\\begin{subequations}\\label{eq:gatesLSSM}\n\\begin{align}\n\\bbgamma_{\\text{fk}} &= \\text{sigmoid} \\big(h_{kfw}\\bbS\\bbw_{k-1} + h_{kfx}\\bbx\t\\big)\\\\\n\\bbgamma_{\\text{u}k} &= \\text{sigmoid} \\big(h_{kuw}\\bbS\\bbw_{k-1} + h_{kux}\\bbx\t\\big)\\\\\n\\bbgamma_{\\text{w}k} &= \\text{sigmoid} \\big(h_{kww}\\bbS\\bbw_{k-1} + h_{kwx}\\bbx\t\\big)\n\\end{align}\n\\end{subequations}\n%\nwhich are internal variables that track the system evolution with their own set of parameters. The sigmoid nonlinearity ensures that the values are in the interval $[0,1]$.\n\\item Updating the $N\\!\\times\\!1$ global memory variable $\\bbc_k$ and state $\\bbw_k$\n\\begin{subequations}\\label{eq:memStateLSSM}\n\\begin{align}\n\\bbc_k &= \\bbgamma_{\\text{f}k}~\\circ~\\bbc_{k-1} + \\bbgamma_{\\text{u}k}~\\circ~\\tbc_k \\\\\n\\bbw_k &= \\bbgamma_{\\text{w}k} \\circ \\tanh(\\bbc_k)\n\\end{align}\n\\end{subequations}\nwhere $``\\circ\"$ denotes the element-wise Hadamard product. The forget gate $\\bbgamma_{\\text{f}k}$ and update gate $\\bbgamma_{\\text{u}k}$ control which entries of the former global memory $\\bbc_{k-1}$ to propagate and which entries to update through the internal memory $\\tbc_k$ [cf. \\eqref{eq:insMem}]. The global memory variable is then used to update the state $\\bbw_k $, whose value is in turn controlled by the state update gate $ \\bbgamma_{\\text{w}k}$.\n\\item Setting the instantaneous output $\\bby_k$ to\n%\n\\begin{equation}\\label{eq.LSSS_instOut}\n\\bby_k = \\sigma_y\\bigg(h_{kyw}\\bbw_k + h_{kyx}\\bbx\t\\bigg).\n\\end{equation}\n%\n\\item Setting the overall LSSM output to\n%\n\\begin{equation}\\label{eq:outLSSM}\n\\bby = \\sigma_y\\big(\\sum_{k = 0}^K\\bby_k\\big).\n\\end{equation}\n%\n\\end{itemize}\n\nIn summary, the LSSM filter is defined by steps \\eqref{eq:insMem}--\\eqref{eq:outLSSM}. Note that this \\emph{nonlinear graph filter} updates the state $\\bbw_k$ as a nonlinear, shifted version of the former state while prioritizing information coming from certain nodes and, thus, only learning state updates on nodes that are relevant for the task at hand. The update is controlled by the gating mechanisms [cf. \\eqref{eq:gatesLSSM}], which are graph-based state-space models themselves. The additional parameters increase further the LSSM degrees of freedom compared with the RSNs to control both the state updates but also allow it to learn where a higher vertex-spectra locality is needed. Substituting $\\bbH^{fg}_l(\\bbS)$ for the LSSM filter in \\eqref{eq:convLay} leads to an LSSM-GNN layer update rule. Because of gating, the LSSM-GNN can be parametrized with higher values of $K$. This \\emph{longer memory} over the graph endows the LSSM-GNN with a better accuracy-robustness trade-off than the GCNN and the RSN. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                          NUMERICAL EXPERIMENTS                         %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\\section{Numerical Experiments}\n\\label{sec:sims}\n\n%!TEX root = 00-rsn-ICASSP21.tex\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                          NUMERICAL EXPERIMENTS                         %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sec:sims %%%%\n%%%%%%%%%%%%%%%%%%\n\nIn the following, we describe the scenarios and respective experimental setups used to corroborate the proposed solutions. The baseline setups are those of \\cite{isufi2020edgenets}, which compares the GCNN with different state-of-the-art approaches. The models we evaluate are: $(i)$ the conventional GCNN with linear filters [cf. \\eqref{eq:ssFormComp}]; $(ii)$ the RSN [cf. \\eqref{eq:singleShift}]; $(iii)$ the LSSM [cf. \\eqref{eq:insMem}-\\eqref{eq:outLSSM}]. All models have ReLU nonlinearities between layers and are trained using the ADAM optimizer with parameters $\\beta_1 = 0.9$ and $\\beta_2 = 0.999$ \\cite{kingma2014adam}.\n\n\\smallskip\n\\noindent\\textbf{Source localization.} The goal of this experiment is to identify the source community of a signal diffused over the graph given a snapshot of the signal at an arbitrary time step. The graph is an undirected stochastic block model (SBM) with $N = 50$ nodes divided into $C = 5$ blocks, each representing a community $\\{c_1, \\ldots, c_5\\}$. The intra-community probability is $p = 0.8$ and the inter-community probability is $q = 0.2$. The source signal $\\bbx[0]$ is a Kronecker delta centered at one source node and diffused at time $t \\in [0, 50]$ as $\\bbx[t] = \\bbS^t\\bbx[0]$, where $\\bbS$ is the graph adjacency matrix normalized by the maximum eigenvalue. The training set comprises $10,240$ tuples of the form $(\\bbx[i], c_i)$ for a random $t$ and $i \\in \\{1, 2, 3, 4, 5\\}$. The validation and the test sets are both composed of $2,560$ tuples. The models are trained with batch sizes of $100$ samples for $40$ epochs and a learning rate $10^{-3}$, which is tuned for the GNN but not for the proposed models. The performances are averaged over ten different graph realizations and ten data splits, for a total of $100$ realizations.\n\nWe vary the filter order $K$ in the set $\\{4, 16, 32\\}$ to compare the accuracy-robustness trade-off of the GCNN, RSN ,and LSSM in the source localization scenario. All architectures have $L=1$ layer and $F=4$ features. The nonlinearities $\\sigma_w$ and $\\sigma_y$ are the ReLU in \\eqref{eq:singleShift}; and $\\sigma_y$ is the ReLU in \\eqref{eq.LSSS_instOut} and \\eqref{eq:outLSSM}. At the output of each architecture, a readout layer maps the output signal to a one-hot vector of dimension $C$, which is then fed to a softmax.\n\nThe average test accuracies are shown in Figure \\ref{fig:source_loc}. Both the RSN and the LSSM outperform the GCNN by a significant margin for all values of $K$. While the RSN achieves the best accuracy for $K=4$, the LSSM exhibits a better performance for larger values of $K$, which indicates its better robustness-accuracy trade-off for high-order filters. This is further validated by the fact that they present the smallest standard deviation for $K=16$ and $K=32$.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%   F   I   G   U   R   E   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n\\begin{figure}[t]\n\\centering\n    \\includegraphics[width=0.75\\columnwidth]{figures/source_loc_k.pdf}\n    \\caption{Source localization accuracy for $K=4$, $16$ and $32$. Error bars have been scaled by $0.5$.}\n    \\label{fig:source_loc}\n\\end{figure}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\noindent\\textbf{Authorship attribution.} In authorship attribution, the learning task is to decide whether a $1,000$-word text excerpt has been authored by a specific author or by any of the other $20$ contemporary authors in the author pool, given their word adjacency network (WAN) \\cite{segarra2015authorship}. WANs are author-specific directed graphs whose nodes are function words without semantic meaning (e.g., prepositions, pronouns, conjunctions) and whose directed edges capture the transition probabilities between pairs of function words. An example of WAN is shown in Figure \\ref{fig:wan} and the graph signal is the word frequency count.\n\nLike in \\cite{isufi2020edgenets}, we classify texts for: Jane Austen, Emily Bronte, and Edgar Alan Poe. The WANs of these authors have from $N = 190$ to $N = 210$ function word nodes. We consider a train-test split of $95\\% - 5\\%$ of the available texts per author and around $8.7\\%$ of the train samples are used for validation. This leads to around $1,000$ training samples and $100$ validation and test samples. For each author, we extend the training, validation, and test sets by the same number of text samples taken at random from the author pool. All models are trained with batches of $100$ samples for $25$ epochs, and the learning rate is $5 \\times 10^{-3}$. The loss function is the cross-entropy and we report average test accuracies for $30$ data splits.\n\nIn this experiment, we fix the parameters so that the GCNN achieved the best performance in the source localization experiment---$L=1$, $F=4$, and $K=32$---to make for a fair comparison. The results are presented in Table \\ref{tab:authorship}. We observe that the RSN outperforms the GNN for all authors except Br\\\"onte, and the LSSM exhibits the best performance by a large margin.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%   F   I   G   U   R   E   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[height=0.24\\textheight]{figures/wan_fig.pdf}\n    \\caption{Example of word adjacency network for the author Robert Louis Stevenson.}\n    \\label{fig:wan}\n\\end{figure}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\n%\\begin{table}[t]\n%\\caption{Authorship attribution accuracy (\\%).}\n%\\label{tab:authorship}\n%\\begin{tabular}{l|ccc}\n%\\hline\n%     & Austen        & Bronte        & Poe          \\\\ \\hline\n%GCNN  & $63.76  \\pm 20.13$ & $71.08  \\pm 15.85$ & $63.73 \\pm 18.19$ \\\\\n%RSN  & $80.38  \\pm 18.66$ & $67.65  \\pm 16.02$ & $71.51 \\pm 18.55$ \\\\\n%LSSM & $\\mathbf{86.54  \\pm 14.28}$ & $\\mathbf{73.04  \\pm 14.64}$ & $\\mathbf{83.49 \\pm 13.69}$ \\\\ \\hline\n%\\end{tabular}\n%\\end{table} \n\n\\begin{table}[t]\n    \\centering\n    \\caption{Authorship attribution accuracy (\\%).}\n    \\label{tab:authorship}\n    \\begin{tabular}{l|ccc}\n        \\hline\n        & Austen        & Bronte        & Poe          \\\\ \\hline\n        GCNN  & $64  \\pm 20$ & $71  \\pm 16$ & $64 \\pm 18$ \\\\\n        RSN  & $80  \\pm 19$ & $68  \\pm 16$ & $72 \\pm 19$ \\\\\n        LSSM & $\\mathbf{87  \\pm 14}$ & $\\mathbf{73  \\pm 15}$ & $\\mathbf{83 \\pm 14}$ \\\\ \\hline\n    \\end{tabular}\n\\end{table} \n\n\n \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                               CONCLUSIONS                              %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{Conclusions}\n\\label{sec:conclusions}\n\n%!TEX root = 00-rsn-ICASSP21.tex\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                               CONCLUSIONS                              %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%% sec:conclusions %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%\n\nGraph convolutional neural networks carry implicitly a state-space model in their convolutional module. In this paper, we explicitly reveal such model and analyze its behavior from an internal state perspective. Highlighting that the internal state may explode or vanish depending on the spectrum of the shift operator, we argued the GCNN parameters need to be learned to also control the latter, which leads to a stability-performance trade-off. We then built further links with discrete state-space models to develop a new family of graph neural networks, in which nodal aggregations are performed in a nonlinear and parametric manner. The latter leads to higher degrees of freedom to control the stability-performance trade-off and allows developing new solutions to improve the expressivity of the GCNNs. We proposed two such solutions, namely, $i)$ a recursive shift network that includes the input signal in every state update contrarily to the GCNN; $ii)$ a long-short term shift memory that allows for increasing further the filter order within a layer through the introduction of the gating mechanisms in a form akin to conventional LSTMs. Numerical results on source localization and authorship attribution corroborate the models, while in the future we plan to investigate the theoretical benefits of these nonlinear aggregation rules. \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%                                                                        %%%%\n%%%%                               BIBLIOGRAPHY                             %%%%\n%%%%                                                                        %%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n% References should be produced using the bibtex program from suitable\n% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography\n% style file from IEEE produces unsorted bibliography list.\n% -------------------------------------------------------------------------\n\\bibliographystyle{bibFiles/IEEEbib}\n\\bibliography{bibFiles/myIEEEabrv,bibFiles/biblioRSN}\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:03:43", "yymm": "2010", "arxiv_id": "2010.14585", "url": "https://arxiv.org/abs/2010.14585", "source": "arxiv"}}
{"text": "\\documentclass[10pt]{book}\n\\usepackage{pgstylestandalone}\n\\renewcommand{\\bibname}{References}\n\n\\title{Political Geometry}\n\\author{  }\n\\date{ }\n\n\\begin{document}\n\\Urlmuskip=0mu plus 1mu\\relax % To make URLs linebreak\n\n%\\maketitle\n\n \\chapter[Political Geography and Representation -- Rodden and Weighill]{Political Geography and Representation: A Case Study of Districting in Pennsylvania}\n\\label{RoddenWeighill}\n\\chapterauthor{JONATHAN RODDEN \\\\ THOMAS WEIGHILL}\n\\authorheader{RODDEN \\& WEIGHILL}\n\\titleheader{Political Geography and Representation}\n\n\n%\\startcontents[chapters]\n%\\printcontents[chapters]{}{1}{}\n\n\\chaptersummary{This preprint offers a detailed look, both qualitative and quantitative, at districting with respect to recent voting patterns in one state: Pennsylvania. We investigate how much the partisan playing field is tilted by political geography. In particular we closely examine the role of scale. We find that partisan-neutral maps rarely give seats proportional to votes, and that making the district size smaller tends to make it even harder to find a proportional map. This preprint was prepared as a chapter in the forthcoming edited volume Political Geometry, an interdisciplinary collection of essays on redistricting.  (\\url{mggg.org/gerrybook})}\n\n%\\thanks{Professor, Department of Political Science; Senior Fellow, Hoover Institution; and Senior Fellow, SIEPR, Stanford University {\\tt jrodden@stanford.edu}}, Thomas Weighill\\thanks{MGGG postdoc, Tufts University {\\tt thomas.weighill@tufts.edu}}}\n\n\n\\section{Introduction}\nThe impressive success of recent ballot initiatives in Michigan, Missouri, Colorado, Ohio and Utah demonstrate that redistricting reform is broadly popular with voters.  But there is little agreement about what type of reform is optimal, and little knowledge about what is at stake when choosing between alternatives.  One type of reform, referred to by political and legal theorists as {\\em process-oriented} reform, focuses on creating a redistricting process that is fair and transparent, giving authority to either independent commissioners or equal numbers of Democrats and Republicans, and encouraging them to pay little attention to the potential political outcomes associated with alternative maps, or perhaps even forbidding the analysis of electoral data altogether.  An alternative approach to reform is to focus explicitly on partisan outcomes---encouraging or requiring commissioners to draw maps that are fair to both parties according to some agreed criteria about how votes should translate into seats.    \n\nAdvocates of an outcome-based approach point out that while a pure process-oriented approach may be easy to explain and implement, it does not necessarily satisfy all the definitions of fairness stakeholders may have in mind. For example, many citizen observers prefer outcomes where the seat share for the parties matches the vote share (so-called ``proportional\" outcomes), but neutral redistricting tends to lead to maps that result in representation that is far from proportional.  This phenomenon is the result of the particular way votes are distributed within a state (what we will refer to as \\emph{political geography} in this chapter). This distribution has a signature form in the United States: Democrats are often highly concentrated in city centers and educated suburbs and Republicans are more dispersed in exurbs and rural areas \\cite{rodden2019}.  \n\nThe partisan tendencies of neutral redistricting, and hence the stakes of debates about redistricting reform, are driven by each state's political geography, and perhaps especially by its urban political geography. An influential paper calling attention to quantifying the partisan tendencies of neutral redistricting was \\cite{chenrodden2013}, which dubbed the phenomenon ``unintentional gerrymandering.'' The size, structure, and geographic arrangement of cities is extremely important for political representation in the United States \\cite{rodden2019}. Moreover, it has been argued that the impact of urban geography on representation is conditioned by the geographic scale at which districts are drawn, as well as the overall level of support for the two parties \\cite{eubankrodden2018}.  \n\nAdding apparently neutral criteria like ``competitiveness'' \\cite{defordduchinsolomon2019} or the procedure for defining adjacency across bodies of water \\cite{mgggalaska2019} can have unforeseen and sometimes dramatic effects on the partisan statistics of maps drawn under a neutral process. See also \\cite{mgggvacriteria} for an extensive survey of the impact of redistricting criteria for Virginia, including compactness, population balance, racial balance and locality splits. Also included in that paper are redistricting criteria which explicitly depend on vote data such as efficiency gap and mean-median scores. It is very clear that a neutral redistricting process that focuses only on creating compact, contiguous districts and minimizing county or municipal splits, for instance, can lead to what many would deem to be a ``fair'' outcome in some states but not in others, particularly if the definition of ``fair'' under consideration is based on the ability to translate overall vote share into seat share. Moreover, the fairness or lack thereof can depend in unexpected ways on which criteria are chosen and how they are measured.\n\nWithin a given state, inferences about the fairness of the maps created through a neutral process might change as the scale of districts varies from massive 700,000-person Congressional districts to, for example, 3,000-person New Hampshire State House districts.  Reformers often point out that U.S. Congressional districts are extremely large relative to districts in other countries that use winner-take-all districts, and a popular reform proposal is to make the U.S. Congress considerably larger by reducing the size of districts.\\footnote{See, for instance, ``America Needs a Bigger House,'' New York Times, November 9, 2018.}  Part of the logic of this type of reform is the hope that disproportionalities in the transformation of votes to seats would be reduced if districts were drawn at a smaller scale. In this chapter, however, our finding will be that the Democratic disadvantage in turning votes into seats in Pennsylvania persists at every hypothetical district size, from 4 million people down to just 55,000.\n\nSocial scientists and mathematicians are in early stages of understanding the complex interplay of political geography, spatial scale, and statewide partisanship that determine patterns of political representation when districts are drawn without regard for partisanship.  This chapter makes progress by presenting a detailed case study of Pennsylvania.  We choose Pennsylvania in part because in the wake of a recent state court decision, Pennsylvania reformers are in the midst of serious debates about process-oriented versus outcome-oriented reform \\cite{nagle2019}.  We make use of modern statistical sampling methods, discussed in more depth in \\cite{defordrecombination, book}, to generate large neutral ensembles of possible districting plans in order to study the baseline of representation for each party at a wide range of feasible spatial scales.\n\nOur central conclusion is that given current patterns of political geography in Pennsylvania, purely process-oriented reforms would typically result in the Democratic Party falling significantly short of proportional representation, even when it has a majority of votes, showing that spatial effects overcome the usual ``winner's bonus\" \\footnote{The ``winner's bonus'' is the established idea in the literature that parties which win the statewide vote should generally have a seat share which exceeds their statewide vote share -- see Bernstein and Walch's chapter in \\cite{book} for more.}. We are able to draw inferences about this not only by observing outcomes of very close elections, like the 2016 presidential election, but also by examining statewide elections where Democratic candidates won significant victories, as well as elections in which Republican candidates were victorious.  We are also able to learn subtle lessons about the importance of spatial voting patterns by observing surprisingly different anticipated seat shares associated with elections held on the same day, and with very similar overall partisan vote shares, but with different underlying spatial support patterns.  \n\nSecond, we demonstrate that while the scale of districts does affect the baseline for representation, the effect is largely to decrease the variance and not to reduce the gap between expected seat share and the statewide vote share. In other words, the Democrats' geography problem does not simply go away if districts become sufficiently small. In closely contested elections, at no plausible scale of redistricting do our neutral ensembles produce Democratic seat shares that match their vote shares.  \n\nThird, the main reason for choosing Pennsylvania as our case study is that by dividing the state in half and treating Eastern and Western Pennsylvania as two separate states, we are able to gain a better understanding of what exactly lies behind the Republican advantage.  That is, we are able to gain insights by ``modularizing\" the problem into two smaller problems.  Pennsylvania gives us the opportunity to examine two very different, and perhaps somewhat representative, patterns of political geography.  Eastern Pennsylvania contains not only a large, extremely Democratic ``primate'' city, but also, due to the geography of coal and the associated 19th-century process of rail-based city formation, a series of smaller Democratic urban agglomerations located in close proximity to one another (see Figure \\ref{labelledPA}).  This pattern of smaller, geographically proximate corridors of post-industrial cities that grew up along rail lines in the periphery of larger regional primate cities resembles other early-industrializing states along the Eastern Seaboard.  In Pennsylvania, this pattern is associated with an unambiguous but relatively modest  pattern of Republican advantage in our ensembles of non-partisan redistricting plans.  \n\n\\begin{figure}\n\\centering\n\\includegraphics[width=0.7\\textwidth]{RoddenWeighill/labelledPA.png}\n\\caption{Map of Pennsylvania with results from the 2016 Presidential election.}\n\\label{labelledPA}\n\\end{figure}\n\nWestern Pennsylvania, in contrast, contains a single large ``primate'' city that is overwhelmingly Democratic, while smaller Democratic enclaves are few in number and quite isolated from one another.  This pattern of political geography is also found in other states on the Western and Southern fringes of the early 20th century manufacturing core, like Missouri, Tennessee, and Louisiana, which contain relatively large, extremely Democratic cities, but lack a network of smaller, proximate rail-based agglomerations on the order of  Allentown, Easton, and Reading.  \n\nOur analysis demonstrates that relative to the Eastern Pennsylvania pattern of dense industrialized corridors, this Western Pennsylvania structure featuring a single isolated 19th century industrial outpost is associated with a much greater under-representation of 21st century Democrats.  Non-partisan redistricting plans grant Republicans substantially more seats than proportional representation would suggest in Western Pennsylvania, with this phenomenon driving a large part of the overall story of Democratic under-representation in our ensembles of statewide maps.             \n\nWe begin with a brief discussion of American political geography and the normative challenge that it creates for a scheme of representation that relies on dividing the states up into winner-take-all districts.  Next, we describe our empirical strategy for generating samples of non-partisan redistricting plans at various spatial scales.  We then explore the key characteristics of our sampled statewide plans, paying special attention to issues of 1) spatial scale and 2) the heterogeneity in statewide partisanship and political geography associated with different statewide Pennsylvania elections. Python code relating to this chapter is available at \\url{https://github.com/political-geometry/chapter-3-political-geography}\n\n%%%\n%%%\n\\section{Urban geography and the partisan tilt of neutral redistricting}\n\nUntil recently, the debate about redistricting reform in the United States pitted those who believe that redistricting should remain in the hands of legislative majorities against those who believe it should be delegated to either non-partisan or bipartisan commissions.  The prevailing model among the latter group was that of the non-partisan commissions employed in Great Britain, Canada, and Australia, or in the U.S. context, the Iowa process.  All of these prevent those drawing the maps from having access to data on partisanship.  More recently, among those who favor redistricting reform, a new debate has emerged.  Should reformers attempt to stick with some form of party-blind process, or include some measure of anticipated partisan symmetry in the marching orders of commissions?  \n\nThis debate has been spurred by a literature that builds on observations of classic British and Australian political geographers \\cite{gudgintaylor79, johnston1977, johnston2001}.  Ever since the rise of modern parties of the left in the late 19th and early 20th centuries in the era of labor mobilization in industrialized societies, voters for these parties have been highly concentrated in city centers.  This relative concentration is widely believed to underlie their difficulty in transforming votes into seats.  \n\nIn the United States, Democrats today are still quite concentrated in the urban core of cities---large and small---that emerged in the era of rapid industrialization, railroad construction, and labor mobilization.  Much has changed since the Democrats emerged as an urban party in the New Deal era, however, and as new issues have been politicized, from civil rights to abortion to guns and now immigration and globalization, the correlation between population density and Democratic voting has increased substantially, and it has spread from the early industrializing states to the entire country, including the deep South. \n\nThe Democratic Party today often suffers from the same difficulty in transforming votes to seats as that faced by Labor parties in the Commonwealth countries in the early postwar era, and so one may wonder if this is also an effect of urban concentration. The reasons behind the under-performance of the Democrats have been hard to nail down, however, because the era of intense urban-rural polarization coincided with highly visible attempts at partisan gerrymandering.  For good reasons, Americans came to see stark disjunctures between votes and seats as phenomena that could be explained purely by partisan gerrymandering.  However, by drawing a series of alternative neutral maps through a simple automated redistricting algorithm, Chen and Rodden \\cite{chenrodden2013} showed that in a number of states, substantial Republican advantage would have emerged even in their samples of non-partisan maps, which the authors attributed to the concentration of Democrats in city centers.  This technique was then used to generate a set of comparison maps that was used in court as part of a lawsuit that led to the invalidation of Florida's Congressional redistricting plan in 2014 \\cite{chenrodden2015}. The Republican advantage in neutral redistricting is not universal, we should be careful to note. For some elections in Massachusetts, for example, no map (and hence in particular no process, neutral or otherwise) could have garnered the Republican party a congressional seat despite statewide vote shares of above 30\\% \\cite{mgggma}. \n\nSubsequently, a number of scholars have adopted a series of alternative approaches to sampling from the distribution of possible non-partisan plans, often with the goal of contrasting that distribution with the plan drawn by a state legislature in order to challenge it in court \\cite{amicus_geographers, amicus_math, cho_talisman, magleby, mattingly, pegden, pegden2017, mgggva, duchinpa}. This technique has now been used to invalidate redistricting plans in state court in Florida, North Carolina, Michigan, and Pennsylvania.  \n\nAs the body of research relying on computer-generated redistricting samples evolves and matures, and as the conversation shifts from court challenges to redistricting reform proposals, it is useful to bring these tools back to the original questions about political geography.  The key question remains: what partisan tendencies should we expect in the absence of gerrymandering intent? In other words, what is the impact of the unavoidable consequences of districts on proportionality and other fairness measures, and how does this impact change from election to election and between scales of redistricting?\n\nAlthough U.S. political geography is always changing, in the current moment, when population density and Democratic voting are correlated at unprecedented levels, the answer to this question appears to lie largely in the size, structure, and arrangement of cities and suburbs relative to their rural surroundings.  A basic problem is that large cities like Philadelphia and Pittsburgh are overwhelmingly Democratic, and neutral redistricting plans will tend to produce overwhelmingly Democratic districts.  On the other hand, ``rural'' districts often encompass not only a large number of Republicans, but also non-trivial clusters of far-flung Democrats in agglomerations like Erie and State College, Pennsylvania that are too small to produce Democratic majorities.  Moreover, districts that are largely exurban will often contain fragments of heavily Democratic parts of inner- and middle-ring suburbs.  As a result, even if their statewide vote shares are similar, Republican candidates tend to win victories by smaller margins than do Democrats, whose votes are inefficiently concentrated in the districts they win.  \n\nUrban concentration's effect on representation is highly dependent on the size, arrangement, and structure of cities as well as the scale at which districts are drawn.  When cities are very large relative to the size of districts, e.g. Philadelphia and Pittsburgh, a non-partisan process would likely create extremely Democratic urban districts.  When cities are too small relative to the size of districts, as with Erie and State College relative to Congressional districts, Democrats are unable to form majorities.  But sometimes the size of a city is better for the representation of Democrats.  For example, some of Pennsylvania's mid-sized cities, like Reading and Bethlehem, are close to the ideal size for producing comfortable but not overwhelming Democratic state Senate Seats.  But at the much smaller scale of State House districts, these cities can produce overwhelming Democratic majorities akin to Philadelphia. What is far from clear, however, is what the effects of changing redistricting scales will be on aggregate: smaller districts may lead to small Democratic towns electing Democratic representatives, but is this effect enough to change the overall seat share in the chamber in question? \n\nAs we demonstrate, it also matters a great deal how these cities are arranged in space.  In addition to Philadelphia, the cities of Eastern Pennsylvania grew up in the late 19th century along a dense web of railroads that were built around the economic geography of coal mining and heavy industry. As a result, Eastern Pennsylvania ended up with a series of small, proximate rail-based industrial towns.  Scranton and Wilkes-Barre blend together along a seam of coal to the North.  Further South, Easton, Bethlehem, and Allentown blend together into a Democratic corridor.  Continuing in a ring around Philadelphia is a series of smaller, extremely Democratic railroad cities including Reading, Lancaster, Harrisburg, and Chester.  At the scale of Congressional districts, these cities are sufficiently proximate to one another, and to some Democratic suburbs of Philadelphia, that they can string together to produce Democratic majorities.  \n\nAnother consideration is urban form.  Some 19th-century cities, like Pittsburgh, have a dense and Democratic urban core, and as one moves to the suburbs, the Republican vote share increases rapidly, which generates a highly concentrated Democratic population.  In contrast, the growth of Republican vote shares is slower as one moves from the core to the outer-ring suburbs in Philadelphia, in part because of the locations of high-technology employers, colleges, and universities, whose employees have become important parts of the Democratic coalition.  \n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{RoddenWeighill/oil_gas_pa.jpg}\n    \\caption{Oil and gas fields of Pennsylvania, from 1921. Taken from the Norman B. Leventhal Map Center Collection.}\n    \\label{fig:oil_gas_pa}\n\\end{figure}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\textwidth]{RoddenWeighill/pa_1901_railroads.jpg}\n    \\caption{Railroad map of Pennsylvania from 1901. Taken from the Norman B. Leventhal Map Center Collection.}\n    \\label{fig:pa_1901_railroads}\n\\end{figure}\n\nEven more distinct are cities like Orlando or Phoenix, where there is no 19th century core, and Democrats and Republicans are interspersed in a sprawling poly-centric metropolis.  Moreover, there are parts of the United States with important pockets of rural support for Democrats, including African-American communities in the South, tribal lands, and communities with a history of mining.      \n\nWith the continued focus on the possible detrimental effects of urban concentration on representation, we should be careful not to exclude the possibility that in some cases this concentration may \\emph{help} a party in the transformation of votes to seats, particularly in states where that party typically expects to lose the overall popular vote.  Indeed, the worst case scenario for a losing party is to have its votes perfectly evenly distributed in space, a scenario that would cause it to lose every single district.  This sounds far-fetched, but the situation is Massachusetts is not so far off \\cite{mgggma}: the Republicans are unable to gain even one seat in some cases precisely because they are too diluted, not because they are too concentrated.\n\nIn short, the location of Democrats in cities is not a sufficient condition to produce a Republican advantage in neutral redistricting plans, and the extent of that advantage, when it exists, is potentially a function of political geography, the scale at which districts are drawn, and the overall level of support for the party.  Our goal in this chapter is to take a close look at Pennsylvania, varying the spatial scale of which districts are drawn, exploring variation in overall vote shares by drawing on a diverse set of recent statewide elections, and exploring the role of heterogeneous urban structure by contrasting the Eastern and Western parts of the state.  \n\n\n\\section{Sampling Pennsylvania redistricting plans at different spatial scales}\n\n\\subsection*{Method}\n\nWe seek to understand the general properties of the universe of all redistricting plans for Pennsylvania. No computer could ever enumerate every possible redistricting plan, but we will use sampling methods that allow us to effectively sample from this vast space in a mathematically rigorous way. The algorithm we will use is the so-called recombination (or {\\sf ReCom}) Markov chain algorithm which is implemented in the freely available GerryChain software developed at MGGG and which is discussed  in \\cite{defordrecombination, book}. Beginning with a randomly generated ``seed'' plan, the algorithm merges and redivides two adjacent districts at every step, resulting in a large ensemble of randomly generated plans, all drawn without the use of any partisan data. In each case, districts are built out of fixed geographic units: precincts for low numbers of districts and census blocks for higher numbers (in order to make population-balanced plans feasible).\\footnote{Some intermediate scales of redistricting were studied with both precincts and blocks, with the two methods producing almost identical results.}\n\nTypically, this kind of algorithm is used to generate a large ensemble of districting plans with a fixed number of districts. This is because one is usually interested in studying the districts for a particular level of government (for example, U.S. Congressional districts, of which there are eighteen in Pennsylvania). For our purposes, we want to study redistricting plans with a variety of different numbers of districts. We thus run the algorithm multiple times (once for each number of districts) to generate many ensembles of 50,000 plans each. For a plan in any one of these ensembles, we can choose a past election and use the vote data to determine how many districts the Democrats would have won using that election and that redistricting plan;\\footnote{Since election data is only reported at the precinct level we prorate it down to blocks based on voting age population when needed.} dividing this number by the total number of districts in the plan gives us the \\emph{Democratic seat share}. We chose nine elections to base our analysis on: the presidential elections from 2012 and 2016 (PRES12 and PRES16), the U.S. Senate elections from 2010, 2012 and 2016 (SEN12 and SEN16), the Attorney General elections from 2012 and 2016 (ATG12 and ATG16) and the Gubernatorial elections from 2010 and 2014 (GOV10 and GOV14). In each case we just treated the election as a head-to-head election between Democrats and Republicans, ignoring any third party candidates.\n\n\\subsection*{Results}\n\nFigures \\ref{scale16}, \\ref{scale12} and \\ref{scaleother} summarize the results of this multi-ensemble analysis, with each plot indicating a different choice of election. Our goal with these plots is to indicate the frequency of different seats outcomes at every scale. In order to make the mode of representation clear, first consider the plots in Figure \\ref{toyexample}, where we have isolated just one scale, 18 districts, and where we use PRES16 vote data. On the right is a histogram indicating the seats outcomes for Democrats in the ensemble. This histogram is represented vertically by the colored dots on the left hand plot: dark blue represents a low fraction, with the fraction increasing through light blue (and later to yellow and to red). Notice that we have also switched from number of seats won to fraction of seats won so that we can later compare multiple scales.\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[width=\\textwidth]{RoddenWeighill/figure_4_explainer.png}\n\\caption{An illustration of how the plots in this section are constructed. On the right is a histogram of seats outcomes for an ensemble of 18-district plans, using PRES16 vote data. Each bar of this histogram is converted to a dot in the left hand plot, with the brightness of the color indicating the bar height, the $x$-value denoting the number of districts (in this case, 18) and the $y$ axis indicating the fraction of seats won.}\n\\label{toyexample}\n\n\\end{figure}\n\n% \\begin{figure}\n% \\centering\n% \\begin{subfigure}{0.4\\textwidth}\n% \\centering\n% \\resizebox{\\columnwidth}{!}{%\n% \\begin{tikzpicture}\n% \\begin{axis}[\n% width=\\textwidth, height=\\textwidth,\n% ylabel = Democratic seat share,\n% xlabel = number of districts,\n% ]\n% \\addplot graphics [xmin=0,xmax=40,ymin=0,ymax=1] {RoddenWeighill/XY_only18.png};\n% \\end{axis}\n% \\end{tikzpicture}\n% }\n% \\end{subfigure}\n% \\begin{subfigure}{0.4\\textwidth}\n% \\centering\n% \\resizebox{\\columnwidth}{!}{%\n% \\begin{tikzpicture}\n% \\begin{axis}[\n% width=\\textwidth, height=\\textwidth,\n% xtick={5,6,7,8,9},\n% ylabel = fraction of ensemble,\n% xlabel = Democratic seats won,\n% yticklabel pos=right, ylabel near ticks\n% ]\n% \\addplot graphics [xmin=4,xmax=10,ymin=0,ymax=0.5] {RoddenWeighill/hist_18.png};\n% \\end{axis}\n% \\end{tikzpicture}\n% }\n% \\end{subfigure}\n% \\caption{An illustration of how the plots in this section are constructed. On the right is a histogram of seats outcomes for an ensemble of 18-district plans, using PRES16 vote data. Each bar of this histogram is converted to a dot in the left hand plot, with the brightness of the color indicating the bar height, the $x$-value denoting the number of districts (in this case, 18) and the $y$ axis indicating the fraction of seats won.}\n% \\label{toyexample}\n% \\end{figure}\n\n\n\nIn Figures \\ref{scale16}, \\ref{scale12} and \\ref{scaleother}, we employ this scheme to show the seats outcome for all scales at once. Each dot represents a choice of number of districts and a Democratic seat share value. The dot is colored based on what fraction of the plans with that many districts had that Democratic seat share, just as in Figure \\ref{toyexample}. Lighter colors therefore represent more common Democratic seat share outcomes for that particular number of districts. The green line represents the statewide vote share achieved by the Democrats in the specified election. Finally, even though we are including hypothetical plans with a large range of numbers of districts, we also indicate three real-world districting scales by dotted lines: U.S. Congress (18 districts), PA state Senate (50 districts) and PA state House (203 districts). \n\n%%%%%%%%%%%%%%%%%%%%%%%%2016%%%%%%%%%%%%%\n\\begin{figure}\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=PRES16,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_PRES16.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.49646) (220,0.49646)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 49.6\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=SEN16,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_SEN16.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.492846) (220,0.492846)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 49.3\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=ATG16,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_ATG16.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.5143) (220,0.5143)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 51.4\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\\caption{Democratic seat shares in neutral ensembles at various redistricting scales, 2016 elections}\n\\label{scale16}\n\\end{figure}\n%%%%%%%%%%%%\n\n\n\\begin{figure}\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=PRES12,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_PRES12.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.5271) (220,0.5271)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 52.7\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=SEN12,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_SEN12.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.5456) (220,0.5456)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 54.6\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=ATG12,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_ATG12.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.5742) (220,0.5742)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 57.4\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\\caption{Democratic seat shares in neutral ensembles at various redistricting scales, 2012 elections.}\n\\label{scale12}\n\\end{figure}\n\n%%%%%%%%%%%%\n\n\\begin{figure}\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=GOV14,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_GOV14.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.5478) (220,0.5478)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 54.8\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=GOV10,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_GOV10.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.4548) (220,0.4548)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 45.5\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\n\\begin{subfigure}{\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\ntitle=SEN10,\nxmin=0,xmax=220,\nymin=0, ymax=1,\naxis on top,\nwidth=\\textwidth, height=0.4\\textwidth,\nytick={0,0.25,0.5,0.75,1},\ncolormap/jet, mark size=1,\nylabel = Dem seat share,\nxlabel = number of districts,\npoint meta min = 0,\npoint meta min = 1,\ncolorbar\n]\n\\addplot[forget plot] graphics[xmin=0,xmax=220, ymin=0, ymax=1] {RoddenWeighill/XY_SEN10.png};\n\\addplot[green, dashed, line legend, line width=2pt] coordinates{(0,0.4895) (220,0.4895)};\n\n\\addplot[gray, forget plot, dashed] coordinates{(18,0) (18,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(50,0) (50,1)};\n\\addplot[gray, forget plot, dashed] coordinates{(203,0) (203,1)};\n\n\\legend{statewide Dem share = 49.0\\%}\n\\end{axis}\n\\end{tikzpicture}\n}\n\\caption*{}\n\\end{subfigure}\n\\caption{Democratic seat shares in neutral ensembles at various redistricting scales, other elections.}\n\\label{scaleother}\n\\end{figure}\n\n\\subsection*{Discussion}\nThe most striking conclusion to be drawn from the plots in this section is that the Democrats underperform proportional representation in seven of the nine elections considered, with the only exceptions being the ATG12 and GOV14 elections.  In those two exceptional elections, Democratic candidates performed unusually well, with 57\\% and 55\\% of the statewide vote respectively.  For elections with relatively even statewide splits between the two parties, like those in 2016, the neutral ensembles showed substantial tendencies to award more seats to the Republican Party. \n\nMoreover, the Democratic under-performance was more or less unaltered by changing district scales.  If anything, when the Democratic statewide vote share was relatively low, as in GOV10 and GOV14, the Democratic seat share increased very slightly as the scale of districts became smaller.  But when Democrats performed well, as in SEN12 and ATG12, their seat share declined as the scale of districts became smaller. This suggests that a general mismatch between smaller Democratic urban centers and particular districts sizes (for example, Congressional districts) cannot be the only reason for the Democrats' disadvantage, if it plays a role at all. Indeed, these experiments suggest the absence of any significant scale effects.  \n\nThe only clear pattern related to the scale of districts in these graphs is the much wider range of seat shares produced by the neutral ensembles when districts are larger (on the left-hand side of the graphs).  The range of outcomes produced in the neutral ensembles narrows considerably as the scale of districts becomes increasingly fine-grained.  Let us focus on the very hotly contested 2016 races, all of which were very close to an even split between the two parties, and where one might expect that a ``fair'' districting plan would produce a roughly similar number of Democratic and Republican seats.  Imagine that a redistricting commission or special master was tasked with the job of randomly selecting a plan from the ensembles.  This would likely lead to a rather large Republican advantage of roughly similar size, whether the plan was for Congress or either state legislative chamber. \n\nHowever, imagine an alternative rule in which a commissioner or special master was told to choose from among the relevant neutral ensemble a plan for which the anticipated seat share of each party was 50 percent when the vote share was 50 percent.  At the scale of Congressional districts or state senate districts, the range of outcomes in the ensemble is sufficiently large that this could be achieved by selecting one of the most pro-Democratic plans.  However, this becomes impossible as districts become smaller and more numerous.  The range of outcomes is much narrower at the scale of Pennsylvania House districts, where even the most Democratic plan falls short of proportionality.  To be clear, the lesson is not that a ``fair'' plan with 203 districts cannot be drawn in Pennsylvania.  Rather, such a plan does not emerge from the neutral ensembles, and it might take a conscious effort to consider partisanship in order to produce one.                \n\nSome interesting inferences---and questions for further analysis---emerge from comparisons of the graphs for different elections.  One lesson, explored further below, is that the statewide vote share is important.  The Democrats' seat share is especially far from proportionality when their vote share is low (e.g. GOV10), and they are still quite far from proportionality even in elections that are very close to 50 percent.  In fact, even in an election with 55 percent of the vote (SEN12), they do not achieve proportionality.  Only when they received 57 percent of the vote (ATG12) did they significantly surpass proportionality.  \n\nThis latter comparison suggests that perhaps there are differences between these two races that go beyond the difference in vote shares between SEN12 and ATG12.  In the Attorney General election, the Democratic candidate, Kathleen Kane, outperformed the Democratic Senate candidate, Bob Casey, who was on the same ballot on the same day, by 2.86 percentage points.  But the difference in seats was substantially larger.  At the scale of Congressional districts and state senate seats, Casey came out ahead, on average, in less than 55 percent of the districts, while Kane came out ahead in well over 65 percent.  This indicates that it matters not only that Kane received more votes than Casey, but also \\emph{where} she outperformed him.  That is to say, she had stronger support than Casey in some geographic areas where, in the ensembles, Casey fell below 50 percent.  For instance, Kane outperformed Casey in many of the counties surrounding her home town of Scranton, as well as in the counties along the Western border of the state.        \n\nAnother election pair that stands out as a place where subtle geographic factors play a big role is PRES16 and SEN16. These two elections were on the same ballot and their statewide shares differed by a mere 0.37 percentage points, yet the Democrats' ability to turn votes into seats in a neutral redistricting process is substantially worse in SEN16 than in PRES16.  In other words, as with Kathleen Kane vis-a-vis Bob Casey, Hillary Clinton was stronger than the Democratic Senate candidate, Katie McGinty, in parts of the state that leaned Republican---as it turns out, parts of suburban Philadelphia---in the Senate race.  \n\nWe should take this as a warning that subtle changes in voting patterns can result in significant swings in representation that elude simple explanation. It is true that in the era of polarization and nationalized politics, results of various statewide races are highly correlated.  Nevertheless, split-ticket voting is still alive and well, and the spatial distribution of votes varies across races in ways that are consequential for inferences about representation.   \n\n\\section{Seats-votes plots}\nIn the previous section, we broke down the data by election. In this section, we will plot all elections together for each of three districting scales. We organize the elections by their statewide vote-share to produce a seats-votes plot.  The values on the horizontal axis correspond to the observed statewide vote share in each of the nine statewide elections examined above. This is meant to parallel the traditional seats-votes curves used in partisan symmetry analysis (see e.g.~\\cite{grofman83}). However, our plots contain far more information than curves since they cover the full range of possibilities encountered in a neutral ensemble associated with each election.\n\nIn each of the figures in Figure \\ref{seatsvotes}, we have selected points from the plots in the previous section which correspond to a particular scale of redistricting. Each dot therefore represents a set of districting plans. The colors are the same; lighter colors represent more frequent seat share outcomes. What has changed is the $x$-axis, which now represents the statewide vote share of the election used to calculate the seat share. The dotted lines indicate two different doctrines of ``fairness'' one might adopt which are not based on ensembles. The gray dotted line indicates proportionality (that is, seat share equals vote share). The green line indicates outcomes which correspond to an efficiency gap of zero.\\footnote{This is the simplified EG formula, assuming equal turnout in each district.} Efficiency gap is a measure of fairness found in the literature based on the concept of ``wasted votes'' \\cite{stephanopoulos2015partisan}.\n\n\\begin{figure}\n\\centering\n\\foreach \\k in {18, 50, 203}\n{\n\\begin{subfigure}{0.46\\textwidth}\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tikzpicture}\n\\begin{axis}[\nxmin=0, xmax=1, ymin=0, ymax=1,\ncolormap/jet, mark size=1,\n axis equal image,\n title=\\k\\ districts\n]\n\\addplot+[scatter, only marks, mark=*, scatter src=explicit] table[x=X, y=Y, col sep=comma, meta=s, forget plot]{RoddenWeighill/seatsvotes_\\k .csv};\n\\addplot[gray, forget plot] coordinates{(0,0) (1,1)};\n\\addplot[green, forget plot] coordinates{(0.25,0) (0.75,1)};\n\\end{axis}\n\\end{tikzpicture}\n}\n\\end{subfigure}\n\n}\n\\caption{Seats-votes plots for Pennsylvania. The $x$-axis indicates statewide Democratic vote share and the $y$-axis indicates Democratic seat share in each case. Grey lines indicate proportionality, while green lines indicate an efficiency gap of zero.}\n\\label{seatsvotes}\n\\end{figure}\n\nThe Republican advantage we observed in the previous section is strikingly visible in these plots as well. Where the dots are below the gray line, Democrats are under-performing relative to proportionality: this is the case for all but the two most Democratic elections considered (ATG12 and SEN12).  A good way to appreciate the asymmetry present in these graphs is to contrast elections in which Democrats receive around 55 percent of the vote (SEN12 and GOV14) with an election in which the Republican candidate received around 55 percent of the vote (GOV10).  At the scale of Congressional districts, on average, the neutral plans produce an expected seat share of around 54 percent for Democrats, but around 77 percent for Republicans.  \n\nWhile proportionality is considered by some as the mark of a fair districting process, others recognize that a ``winner's bonus'' is a reasonable property to expect in a districted system. That is, while 50\\% of the vote should win you half the seats, 70\\% of the vote---an overwhelming victory---could easily result in far more than 70\\% of the seats depending on how the extra 20\\% advantage is spatially arranged. If it is uniform, of course, then all seats go to the majority party.  The efficiency gap boils down to a specific recommendation for this bonus: $50 + x$ percent of the vote should roughly translate into $50 + 2x$ of the seats. This is where the green line comes from. All this discussion is to say that where the dots are below the green line for Democratic vote shares less than $0.5$, the Democrats are not only failing to achieve proportionality, but are not even able to achieve the representation predicted by a common standard in the literature which takes into account the Republican winner's bonus.\n\nAn interesting but subtle scale phenomenon is visible on these plots for the most Democratic election of all---ATG12. With 57 percent of the statewide vote, Democrats exceed the efficiency gap standard for 18 and 50 districts for many plans, but far more rarely for the plans with 203 districts. In other words, the Democratic winner's bonus diminishes as the scale of redistricting grows finer for this particular election.  \n\nAnd again, these graphs demonstrate the much tighter range of outcomes produced in the neutral ensembles as districts become smaller.  As mentioned above, some reformers anticipate that smaller districts on the scale of Canadian or British parliamentary constituencies, or Pennsylvania State House districts, might reduce the level of Republican advantage observed in recent Congressional elections.  However, these graphs suggest that in Pennsylvania, neutral districting at a smaller scale might not produce any maps at all that meet a rather uncontroversial standard of partisan fairness.   \n\n\\section{East versus West}\n\n\\begin{center}\n    \\includegraphics[width=\\textwidth]{RoddenWeighill/cut_pa.png}\n\\end{center}\n\n\\subsection*{Method}\nIn this section we examine the difference in political geography between the western and eastern parts of Pennsylvania at the level of Congressional and Pennsylvania state Senate redistricting (we omit the state House level for the sake of brevity). We choose a subdivision of Pennsylvania along county boundaries which results in two pieces, West and East, as shown in Figure \\ref{divide}. Up to an error of just over 3000 people, the West has half the population of the East. Since Pennsylvania has 18 congressional districts, it thus makes sense to consider plans of six districts for the West and plans of twelve districts for the East. To best approximate state Senate plans, we consider plans of seventeen districts for the West and plans of thirty-four districts for the East, adding up to a total of fifty-one, one over the correct number of fifty. For ease of reference, the overall vote shares for each party in each piece are shown in Tables \\ref{statewidetable} and \\ref{statewidetable51}, along with the mean seat shares coming from the ensemble analyses.\n\n\\subsection*{Results}\n\nThe Figures in this section each have four histograms showing the Democratic seats outcomes for four different ensembles based on the specified election data. The ``West'' ensemble is an ensemble of 50,000 plans with a third of the targeted number of districts for the West piece of Pennsylvania only. The ``East'' ensemble is an ensemble of 50,000 plans with two-thirds of the targeted number of districts for the East piece. The ``Full state'' ensemble is an ensemble of 50,000 plans for the entire state with the targeted number of districts. Finally, the ``E-W pairs'' ensemble consists of every possible plan that can be created by putting a plan from the ``West'' ensemble and a plan from the ``East'' ensemble put together. This last ensemble should be thought of as an ensemble of plans that respect the West-East subdivision of the state we chose. As mentioned above, we chose two districting scales: 18 districts (for Congressional) and 51 districts (as the closest multiple of three to the state Senate number of 50).\n\n\\begin{table}\n\\centering\n\\begin{tabular}{|c||c|c||c|c||c|c|}\n\\hline\n& \\multicolumn{2}{c||}{West} & \\multicolumn{2}{c||}{East} & \\multicolumn{2}{c|}{Full}  \\\\ \\hline\n& seat \\%  & vote \\%  & seat \\% & vote \\% & seat \\% & vote \\% \\\\ \\hline\nPRES16  & 20.76\\% & 41.66\\% & 46.83\\% & 53.60\\% & 37.83\\% & 49.65\\% \\\\\n\\hline\nSEN16  & 22.08\\% & 43.36\\% & 36.32\\% & 52.18\\% & 31.62\\% & 49.28\\% \\\\\n\\hline\nATG16  & 27.22\\% & 46.04\\% & 51.18\\% & 54.11\\% & 43.61\\% & 51.43\\% \\\\\n\\hline\nPRES12  & 23.49\\% & 46.03\\% & 57.47\\% & 56.04\\% & 46.46\\% & 52.71\\% \\\\\n\\hline\nSEN12  & 33.64\\% & 48.83\\% & 62.79\\% & 57.45\\% & 53.05\\% & 54.56\\% \\\\\n\\hline\nATG12  & 67.55\\% & 54.00\\% & 69.74\\% & 59.12\\% & 69.23\\% & 57.42\\% \\\\\n\\hline\nGOV14  & 38.57\\% & 49.62\\% & 64.54\\% & 57.30\\% & 56.27\\% & 54.78\\% \\\\\n\\hline\nGOV10  & 10.59\\% & 40.49\\% & 29.07\\% & 48.08\\% & 22.69\\% & 45.48\\% \\\\\n\\hline\nSEN10  & 20.72\\% & 45.14\\% & 36.26\\% & 50.92\\% & 31.23\\% & 48.95\\% \\\\\n\\hline\n\\end{tabular}\n\\caption{Vote shares and mean seat shares for 18 districts (6 West, 12 East).}\n\\label{statewidetable}\n\\end{table}\n\n\\begin{table}\n\\centering\n\\begin{tabular}{|c||c|c||c|c||c|c|}\n\\hline\n& \\multicolumn{2}{c||}{West} & \\multicolumn{2}{c||}{East} & \\multicolumn{2}{c|}{Full}  \\\\ \\hline\n& seat \\%  & vote \\%  & seat \\% & vote \\% & seat \\% & vote \\% \\\\ \\hline\nPRES16  & 24.85\\% & 41.66\\% & 49.64\\% & 53.60\\% & 41.90\\% & 49.65\\% \\\\\n\\hline\nSEN16  & 20.59\\% & 43.36\\% & 42.40\\% & 52.18\\% & 35.63\\% & 49.28\\% \\\\\n\\hline\nATG16  & 28.60\\% & 46.04\\% & 51.30\\% & 54.11\\% & 43.96\\% & 51.43\\% \\\\\n\\hline\nPRES12  & 25.70\\% & 46.03\\% & 55.74\\% & 56.04\\% & 46.23\\% & 52.71\\% \\\\\n\\hline\nSEN12  & 35.02\\% & 48.83\\% & 61.57\\% & 57.45\\% & 52.91\\% & 54.56\\% \\\\\n\\hline\nATG12  & 63.25\\% & 54.00\\% & 69.84\\% & 59.12\\% & 67.30\\% & 57.42\\% \\\\\n\\hline\nGOV14  & 41.90\\% & 49.62\\% & 65.23\\% & 57.30\\% & 56.77\\% & 54.78\\% \\\\\n\\hline\nGOV10  & 17.78\\% & 40.49\\% & 32.03\\% & 48.08\\% & 27.16\\% & 45.48\\% \\\\\n\\hline\nSEN10  & 26.00\\% & 45.14\\% & 38.89\\% & 50.92\\% & 34.96\\% & 48.95\\% \\\\\n\\hline\n\\end{tabular}\n\\caption{Vote shares and mean seat shares for 51 districts (17 West, 34 East).}\n\\label{statewidetable51}\n\\end{table}\n\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[width=0.6\\textwidth]{RoddenWeighill/westeast.png}\n\\caption{Dividing Pennsylvania into West and East.}\n\\label{divide}\n\\end{figure}\n\n%%%%%E-W HISTOGRAMS%%%%%%%\n\\begin{figure}\n\\foreach \\e in {PRES16, SEN16, ATG16}\n{\n\\begin{subfigure}{\\textwidth}\n\\caption*{\\underline{\\e}}\n\n\\vspace{-0.3cm}\n\n\\centering\n\n\\begin{tikzpicture}\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (6),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=East (12),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\nlabel style={font=\\tiny} ,\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=Full state (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (17),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=East (34),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=Full state (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e _51.csv};\n\\end{axis}\n\\end{tikzpicture}\n\\end{subfigure}\n}\n\\caption{East-West comparison for 2016 elections. The $x$-axis and $y$-axis in each plot represent Democratic seats won and fraction of the ensemble respectively. Numbers in parentheses indicate the number of districts in each plan. Dotted green lines indicate proportionality.}\n\\end{figure}\n\n%%%%%%%%%%%%%%\n\\begin{figure}\n\\foreach \\e in {PRES12, SEN12, ATG12}\n{\n\\begin{subfigure}{\\textwidth}\n\\caption*{\\underline{\\e}}\n\n\\vspace{-0.3cm}\n\n\\centering\n\n\\begin{tikzpicture}\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (6),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=East (12),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\nlabel style={font=\\tiny} ,\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=Full state (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (17),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=East (34),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=Full state (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e _51.csv};\n\\end{axis}\n\\end{tikzpicture}\n\\end{subfigure}\n}\n\\caption{East-West comparison for 2012 elections. The $x$-axis and $y$-axis in each plot represent Democratic seats won and fraction of the ensemble respectively. Numbers in parentheses indicate the number of districts in each plan. Dotted green lines indicate proportionality.}\n\\end{figure}\n\n%%%%%%%%%%%%%%%%%%%\n\\begin{figure}\n\\foreach \\e in {GOV14, GOV10, SEN10}\n{\n\\begin{subfigure}{\\textwidth}\n\\caption*{\\underline{\\e}}\n\n\\vspace{-0.3cm}\n\n\\centering\n\n\\begin{tikzpicture}\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (6),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=East (12),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\nlabel style={font=\\tiny} ,\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=Full state (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (18),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny} ,\nlabel style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,3cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _18.csv};\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e .csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=1,\nymax=1, ymin=0, clip=false,\ntitle=West (17),\nwidth=3.75cm,\nheight=3.75cm,\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(0cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=W, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[black, fill=red, ybar interval] table[x=WX, y=WY, col sep=comma]{RoddenWeighill/Whist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=2,\nymax=1, ymin=0, clip=false,\ntitle=East (34),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(3cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=E, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill= green!60!black] table[x=EX, y=EY, col sep=comma]{RoddenWeighill/Ehist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=Full state (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(6cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=F, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\\addplot[ybar interval, black, fill=purple] table[x=FX, y=FY, col sep=comma]{RoddenWeighill/Fhist\\e _51.csv};\n\\end{axis}\n\n\\begin{axis}[grid=none, xtick distance=3,\nymax=1, ymin=0, clip=false,\ntitle=E-W pairs (51),\nwidth=3.75cm,\nheight=3.75cm,\nyticklabels={,,},\ntick label style={font=\\tiny},\ntitle style={font=\\footnotesize,yshift=-1ex},\nat={(9cm,0cm)}\n]\n\\addplot[green, dashed, line width=1pt] table[x=B, y=Y, col sep=comma]{RoddenWeighill/voteshares\\e _51.csv};\n\n\\addplot[ybar interval, black, fill=brown] table[x=BX, y=BY, col sep=comma]{RoddenWeighill/Bhist\\e _51.csv};\n\\end{axis}\n\\end{tikzpicture}\n\\end{subfigure}\n}\n\\caption{East-West comparison for other elections. The $x$-axis and $y$-axis in each plot represent Democratic seats won and fraction of the ensemble respectively. Numbers in parentheses indicate the number of districts in each plan. Dotted green lines indicate proportionality.}\n\\end{figure}\n\n\n\n\\subsection*{Discussion}\nOne observation we should immediately make is that the seats outcomes for the unsplit state plans and the East-West combination plans are in all cases extremely similar. In other words, forcing plans to respect our arbitrary East-West division does not have a substantial impact on the baseline for redistricting in Pennsylvania. This gives us the confidence to examine the impacts of the East and West on baseline representation separately, since combining them pairwise reproduces the redistricting phenomena we are trying to study for the whole state.\n\nThe plots reveal that the general Democratic under-performance is more pronounced in the West than in the East. In the West, in both PRES16 and SEN16, the Democrats were able to secure only one Western Congressional seat in a majority of the plans (in Pittsburgh), despite the Western vote share being well above 40\\% in both cases.  Even when the Democrats receive 49 percent of the votes in the West, as they did in SEN12, they only received 34 percent of the Congressional seats.   There is some contrast between the two elections where the Democrats achieve a higher mean seat share than vote share. For ATG12, when Kane received a statewide vote share of 57 percent, both the West and East mean seat share exceed the vote share (the West by a greater margin than the East in fact). For GOV14, when the Democratic candidate received 55 percent statewide, the mean seat share falls short of the vote share in the West but not the East, and the two combine to result in a statewide seat share that is slightly above the statewide vote share.\n\nThe political geography of Western Pennsylvania seems to make it quite difficult for the Democrats to transform votes to seats.  At the scale of Congressional districts, in a typical election, the ensembles tend to produce a single Democratic Pittsburgh seat.  Perhaps there is a hint of a scale effect here, since the Democratic seat share is somewhat higher at the scale of state Senate than Congressional districts in the West for 7 of the 9 elections.  This may have to do with the nature of the partitioning of Pittsburgh, and the greater likelihood of Democratic victories occurring in Erie at the smaller scale of state Senate districts.  To be sure, the Democrats' political geography is still quite inefficient in the East, but the Democrats' difficulty in the West is especially striking at both spatial scales analyzed here.  \n\nThe East-West comparison is also useful for shedding light on the puzzling gap, described above, between SEN16 and PRES16.  The right-hand columns of Tables 1 and 2 illuminate that in the state as a whole, Clinton's presidential vote share was more efficiently distributed than that of McGinty in the Senate race.  With very similar vote shares, on average, neutral ensembles produced a seat share about 6 percentage points higher for Clinton at both spatial scales considered here.  We can now see that McGinty outperformed Clinton in the West, and Clinton outperformed McGinty in the East.  Inspection of precinct-level maps reveals that split-ticket voters favoring the Democratic Senate candidate while favoring Donald Trump in the presidential election in the West were located in non-urban working-class areas, especially in the Southwest.  And ticket-splitting in the East, where those voting Republican in the Senate race chose Clinton in the presidential race, were located largely in educated suburbs of Philadelphia.  \n\nClinton's better overall performance than that of McGinty in transforming votes to seats is driven primarily by the East.  This is clearest at the scale of Congressional districts, where McGinty's higher vote share corresponded to a higher seat share.  In the East, on the other hand, where Clinton outpolled McGinty by 1.42 percentage points, she received a seat share that was more then 10 percentage points higher than that of McGinty.  This phenomenon persists to a lesser degree at 51 districts: both the West and East have higher mean seat shares for PRES16 than SEN16, but the difference is greater for the East (around 7 percentage points) than the West (around 4 percentage points).  It appears that Clinton's spatial pattern of support was more efficient at winning seats than McGinty's because she out-polled McGinty in marginal areas of greater Philadelphia that produced districts with small majorities for Clinton in the presidential race but small majorities for Toomey (the Republican candidate) in the Senate race. \n\n\n%%%%%%%%%%%%%%\n\n\n\\section{Conclusion}\n\nThis chapter has focused on a single state, but we have been able to exploit useful variation of several kinds:  different vote shares and spatial patterns in different elections, different spatial scales for drawing districts, and the very different political geography of Eastern and Western Pennsylvania.  \n\nPerhaps the most basic conclusion of this study is that because of the spatial distribution of partisanship, a neutral approach to redistricting would likely lead to the under-representation of the Democratic Party relative to its statewide strength.  In the vast majority of neutral redistricting ensembles, the Republican Party would be able to win a very comfortable majority of seats with a little less than half of the votes.  Democrats cannot expect to win a majority of seats until they win somewhere around 54 percent of the votes.  They do not benefit from a disproportionate ``winner's bonus'' until they obtain well over 56 percent of the statewide vote.  In contrast, the Republican Party can receive a massive winner's bonus even with very slightly more than 50 percent of the statewide vote.  This pattern can be seen both in Eastern and Western Pennsylvania, but it is more pronounced in the Western part of the state, where a large share of the Democrats are concentrated in Pittsburgh.\n\nIt was useful to examine a wide variety of elections not only in order to assess the implications of neutral ensembles at different statewide vote shares, but also to explore differences in the spatial support for candidates even when the overall vote shares were similar.  For instance, we discovered that in 2016, Hillary Clinton's support distribution led to a significantly better seat share than that of Katie McGinty in the Senate race, even though their statewide vote shares were quite similar.  This appears to be driven above all by Clinton's relative success in marginal suburban areas in Eastern Pennsylvania.  \n\nThis observation suggests that a state's political geography is not static, but constantly changing with time and between elections (even on the same ballot!).  Geographic realignments can and do take place.  Neutral redistricting ensembles might produce important differences in seat shares for the parties, even without large differences in statewide vote shares, if enough geographically proximate voters in marginal areas shift from one party to the other.  In many U.S. states, large swaths of suburbia have been marginally Republican for a period of time, but recent shifts in favor of the Democratic Party among educated voters in those areas---even if offset by losses in more rural areas--- could lead to changes in seat shares.  This is an important topic for further research.            \n\nWe have also explored the proposition that as the scale of districts becomes smaller, seat shares should come closer to mirroring statewide proportionality.  We explored the range from two districts to 220 districts for Pennsylvania, and found no consistent relationship between geographic scale and Republican advantage across elections.  It is entirely plausible, however, that scale effects might exist in other states over a similar range of district sizes.  In fact, we see a hint of a scale effect in Western Pennsylvania that we do not see in the East.      \n\nWe also note that the range of seat shares produced in the neutral ensembles narrows considerably as the state is divided up into more and more districts.  This leads to an interesting observation.  When the state is carved up into a relatively small number of districts, the range of outcomes is sufficiently wide that, if one draws from the most pro-Democratic tail in the distribution of plans in the ensemble, it is possible to select a plan in which 50 percent of the votes corresponds with 50 percent of the seats.  However, as the state is partitioned into smaller and smaller districts, even the most pro-Democratic plan still demonstrates substantial disadvantage for Democratic candidates.    \n\nThese findings have implications for debates about reform of redistricting in Pennsylvania and beyond. All the ensembles used here were generated by an algorithm which is independent of partisan data, and yet substantial deviations from proportionality occurred. This suggests that even a neutral process involving commissioners or demographers without access to partisan data might result in maps that lead to disproportionate results such as awarding a majority of the seats to a party that loses the statewide vote.  To be clear, our results do not show that political geography is so constraining that fair plans (as defined by measures like proportionality or a minimal efficiency gap) are impossible to draw.  Rather, some volition, based on analysis of partisan data, would be required.  \n\n\\section*{Acknowledgements}\nWe would like to thank Olivia Walch for the illustrations in this chapter. Thomas Weighill acknowledges the support of the NSF Convergence Accelerator Grant No. OIA-1937095.\n\n\\begin{thebibliography}{xx}\n\n\\bibitem{mgggalaska2019}\nCaldera, Sophia, Daryl DeFord, Moon Duchin \\&\\ Samuel~C. Gutekunst.\n  2019.\n\\newblock ``Mathematics of Nested Districts: The Case of Alaska.'' {\\em\n  preprint} .\n\\newblock https://mggg.org/alaska.\n\n\\bibitem{chenrodden2013}\nChen, Jowei \\&\\ Jonathan Rodden. 2013.\n\\newblock ``Unintentional Gerrymandering: Political Geography and Electoral\n  Bias in Legislatures.'' {\\em Quarterly Journal of Political Science}\n  8(3):239--269.\n\n\\bibitem{chenrodden2015}\nChen, Jowei \\&\\ Jonathan Rodden. 2015.\n\\newblock ``Cutting Through the Thicket: Redistricting Simulations and the\n  Detection of Partisan Gerrymanders.'' {\\em Election Law Journal}\n  14(4):331--345.\n\n\\bibitem{pegden}\nChikina, Maria, Alan Frieze \\&\\ Wesley Pegden. 2017.\n\\newblock ``Assessing Significance in a Markov Chain Without Mixing.'' {\\em\n  Proceedings of the National Academy of Science} 114:2860.\n\n\\bibitem{cho_talisman}\nCho, Wendy K.~Tam \\&\\ Yan~Y. Liu. 2016.\n\\newblock ``Toward a Talismanic Redistricting Tool: A Computational Method for\n  Identifying Extreme Redistricting Plans.'' {\\em Election Law Journal} 15:351.\n  \n  \\bibitem{defordrecombination} DeFord, Daryl, Moon Duchin, and Justin Solomon. \"Recombination: A family of Markov chains for redistricting.\" arXiv preprint arXiv:1911.05725 (2019).\n\n\\bibitem{mgggvacriteria}\nDeFord, Daryl \\&\\ Moon Duchin. 2019.\n\\newblock Redistricting Reform in Virginia: Districting Criteria in Context.\n  Technical report MGGG.\n\\newblock https://mggg.org/va-criteria.pdf.\n\n\\bibitem{mgggva}\nDeFord, Daryl, Moon Duchin \\&\\ Justin Solomon. 2018.\n\\newblock Comparison of districting plans for the Virginia House of Delegates.\n  Technical report MGGG.\n\\newblock https://mggg.org/VA-report.pdf.\n\n\\bibitem{defordduchinsolomon2019}\nDeFord, Daryl, Moon Duchin, and Justin Solomon. ``A Computational Approach to Measuring Vote Elasticity and Competitiveness.'' Statistics and Public Policy just-accepted (2020): 1-30. \n\n\\bibitem{book} D. Duchin and O. Walch (eds), \\emph{Political Geometry}, Birkhauser, to appear in 2021. \\url{mggg.org/gerrybook}\n\n\\bibitem{duchinpa}\nDuchin, Moon. 2018.\n\\newblock Outlier analysis for Pennsylvania congressional redistricting.\n  Technical report.\n\\newblock https://mggg.org/uploads/md-report.pdf.\n\n\\bibitem{mgggma}\nDuchin, Moon, Taissa Gladkova, Eugene Henninger-Voss, Ben Klingensmith, Heather\n  Newman \\&\\ Hannah Wheelen. 2018.\n\\newblock ``Locating the representational baseline: Republicans in\n  Massachusetts.'' {\\em arXiv preprint arXiv:1810.09051} .\n\n\\bibitem{eubankrodden2018}\nEubank, Nicholas \\&\\ Jonathan Rodden. 2019.\n\\newblock ``Who is my Neighbor? The Spatial Efficiency of Partisanship.'' {\\em\n  Working Paper} .\n  \n  \\bibitem{grofman83} Grofman, Bernard. 1983. ``Measures of bias and proportionality in seats-votes relationships''. Political Methodology,\n9(3):295-327.\n\n\\bibitem{gudgintaylor79}\nGudgin, Graham \\&\\ P.J. Taylor. 1979.\n\\newblock {\\em Seats, Votes, and the Spatial Organisation of Elections}.\n\\newblock London:  Pion Limited.\n\n\\bibitem{johnston1977}\nJohnston, Ronald. 1977.\n\\newblock ``Spatial Structure, Plurality Systems and Electoral Bias.'' {\\em The\n  Canadian Geographer} 20:310--328.\n\n\\bibitem{johnston2001}\nJohnston, Ronald, Charles Pattie, Dany Dorling \\&\\ David Rossiter.\n  2001.\n\\newblock {\\em From Votes to Seats: The Operation of the UK Electoral System\n  since 1945}.\n\\newblock Manchester and New York:  Manchester University Press.\n\n\\bibitem{magleby}\nMagleby, Daniel \\&\\ Daniel Mosesson. 2018.\n\\newblock ``A New Approach for Developing Neutral Redistricting Plans.'' {\\em\n  Political Analysis} 26(2):147--167.\n\n\\bibitem{amicus_math}\nMathematicians' Amicus~Brief, Rucho v. Common~Cause. 2018.\n\\newblock ``Amicus Brief of Mathematicians, Law Professors, and Students in\n  Support of Appelleees and Affirmance.'' Amicus Brief, Supreme Court of the\n  United States, Rucho et al. v. Common Cause et al.\n\n\\bibitem{mattingly}\nMattingly, Jonathan~C. \\&\\ Christy Vaughn. 2014.\n\\newblock ``Redistricting and the Will of the People.''\n  https://arxiv.org/abs/1410.8796.\n\n\\bibitem{nagle2019}\nNagle, John~F. 2019.\n\\newblock ``What Criteria Should be Used for Redistricting Reform?'' {\\em\n  Election Law Journal} 18(1):63--77.\n\n\\bibitem{pegden2017}\nPegden, Wesley. 2017.\n\\newblock ``Pennsylvania's Congressional Districting is an Outlier: Expert\n  Report.''.\n\\newblock Expert report submitted in Leage of Women Voters of Pennsylvania v.\n  Commonwealth of Pennsylvania.\n\n\\bibitem{amicus_geographers}\nPegden, Wesley, Jonathan Rodden \\&\\ Samuel Wang. 2018.\n\\newblock ``Brief of Amici Curiae Professors Wesley Pegden, Jonathan Rodden,\n  and Samuel Wang in Support of Appellees.'' Supreme Court of the United\n  States.\n\n\\bibitem{rodden2019}\nRodden, Jonathan. 2019.\n\\newblock {\\em Why Cities Lose: The Deep Roots of the Urban-Rural Divide}.\n\\newblock Basic Books.\n\n\\bibitem{stephanopoulos2015partisan}\nStephanopoulos, Nicholas~O \\&\\ Eric~M McGhee. 2015.\n\\newblock ``Partisan gerrymandering and the efficiency gap.'' {\\em U. chi. l.\n  Rev.} 82:831.\n\n\\end{thebibliography}     % uses subcaption\n \n\\end{document}", "meta": {"timestamp": "2020-11-05T01:26:28", "yymm": "2010", "arxiv_id": "2010.14608", "url": "https://arxiv.org/abs/2010.14608", "source": "arxiv"}}
{"text": "\\documentclass[11pt,reqno]{amsart}\r\n\\usepackage{amsmath, amsthm, amssymb}\r\n%\\usepackage{amsmath, amsthm, amssymb, stmaryrd}\r\n%\\usepackage{fullpage}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{array}\r\n\\usepackage{caption}\r\n\\topmargin 0.0cm\r\n  \\textheight 22.2cm\r\n\\oddsidemargin 0.8cm\r\n\\evensidemargin \\oddsidemargin\r\n\\marginparwidth 2cm\r\n\\textwidth 15.2cm\r\n\\def\\a{{\\mathbf a}}\r\n\\def\\c{{\\mathbf c}}\r\n\\def\\b{{\\mathbf b}}\r\n\\def\\B{\\mathcal B}\r\n\\def\\e{\\varepsilon}\r\n\\def\\bfh{{\\mathbf h}}\r\n\\def\\bfb{{\\mathbf b}}\r\n\\def\\bfc{{\\mathbf c}}\r\n\\def\\bfy{{\\mathbf y}}\r\n\\def\\bfx{{\\mathbf x}}\r\n\\def\\bfz{{\\mathbf z}}\r\n\\def\\bfr{{\\mathbf r}}\r\n\\def\\bfw{{\\mathbf w}}\r\n\\def\\bfv{{\\mathbf v}}\r\n\\def\\bfgamma{{\\boldsymbol \\gamma}}\r\n\\def\\bfalpha{{\\boldsymbol \\alpha}}\r\n\\def\\numset#1{{\\mathbb #1}}\r\n\\newtheorem{thm}{Theorem}\r\n\\newtheorem{cor}{Corollary}\r\n\\newtheorem{propos}{Proposition}\r\n\\newtheorem{problem}{Problem}\r\n\\newtheorem{remark}{Remark}\r\n\\newtheorem{lem}{Lemma}\r\n\\newtheorem{claim}{Claim}\r\n\\newtheorem{conj}{Conjecture}\r\n\\newtheorem{defn}{Definition}\r\n\\newtheorem{exam}{Example}\r\n\\newtheorem{prop}{Proposition}\r\n\\newcommand{\\E}{\\ensuremath{\\mathbb E}}\r\n\\newcommand{\\U}{\\ensuremath{\\mathcal U}}\r\n\\numberwithin{equation}{section} \\numberwithin{thm}{section}\r\n\\numberwithin{lem}{section} \\numberwithin{problem}{section}\r\n\\numberwithin{cor}{section}\r\n\\def\\grm{{\\mathfrak m}}\\def\\grM{{\\mathfrak M}}\\def\\grN{{\\mathfrak N}}\\def\\grn{{\\mathfrak n}}\\def\\grL{{\\mathfrak L}}\\def\\grl{{\\mathfrak l}}\\def\\bfgrN{{\\boldsymbol \\mathfrak N}}\\def\\bfgrn{{\\boldsymbol\\mathfrak n}}\\def\\bfgrL{{\\boldsymbol\\mathfrak L}}\\def\\bfgrl{{\\boldsymbol\\mathfrak l}}\\def\\grp{{\\mathfrak p}}\\def\\grP{{\\mathfrak P}}\\def\\grw{{\\mathfrak w}}\\def\\grW{{\\mathfrak W}}\r\n\\newcommand{\\mmod}[1]{\\,\\,(\\text{\\rm mod}\\,\\, #1)}\r\n\\newcommand{\\cc}{\\mathbf c}\r\n\\newcommand{\\ccc}{\\overline{\\mathbf c}}\r\n\\newcommand{\\aaa}{\\overline{\\alpha}}\r\n\\newcommand{\\p}{\\mathbf p}\r\n\\newcommand{\\ex}{\\text{ex}}\r\n\\def\\grm{{\\mathfrak m}}\\def\\grM{{\\mathfrak M}}\\def\\grN{{\\mathfrak N}}\\def\\grn{{\\mathfrak n}}\r\n\\newcommand{\\q}{\\mathbf q}\r\n\\newcommand{\\rr}{\\mathbf r}\r\n\\newcommand{\\pp}{\\overline{\\mathbf p}}\r\n\\newcommand{\\qq}{\\overline{\\mathbf q}}\r\n\\newcommand{\\nuu}{\\overline{\\mathbf \\nu}}\r\n\\newcommand{\\Real}{\\mathbb R}\r\n\\newcommand{\\RPlus}{\\Real^{+}}\r\n\\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert}\r\n\\newcommand{\\abs}[1]{\\left\\vert#1\\right\\vert}\r\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\r\n\\newcommand{\\seq}[1]{\\left<#1\\right>}\r\n\\newcommand{\\eps}{\\varepsilon}\r\n\\newcommand{\\To}{\\longrightarrow}\r\n\\newcommand{\\BX}{\\mathbf{B}(X)}\r\n\\newcommand{\\A}{\\mathcal{A}}\r\n\\newcommand{\\Ha}{\\mathcal{H}}\r\n\\newcommand{\\Beta}{B}\r\n\\newcommand{\\Ar}{\\text{Arc}}\r\n\\newcommand{\\M}{\\mathcal{M}}\r\n\\newcommand{\\G}{\\mathcal{G}}\r\n\\newcommand{\\W}{\\mathcal{W}}\r\n\\newcommand{\\N}{\\mathcal{N}}\r\n\\newcommand{\\Ll}{\\mathcal{L}}\r\n\\newcommand{\\Fa}{\\mathcal{F}}\r\n\\newcommand{\\Z}{\\mathbb{Z}}\r\n\\newcommand{\\Lom}{\\mathcal{L}}\r\n\\newcommand{\\Comp}{\\mathcal{K}}\r\n\\newcommand{\\Basis}{\\mathcal{B}}\r\n\\newcommand{\\nnu}{\\mathbf{\\nu^n}}\r\n\\newcommand{\\F}{\\mathbb F}\r\n\\newcommand{\\FF}{\\mathcal F}\r\n\\newcommand{\\MM}{\\mathcal M}\r\n\\def\\f{\\frac{|\\A||B|}{|G|}}\r\n\\def\\AB{|\\A\\cap B|}\r\n%%% ----------------------------------------------------------------------\r\n%\\nopagenumber\r\n%\\renewcommand{\\baselinestretch}{1.5}\r\n%\\textwidth=14cm\r\n\\parskip 1.5mm\r\n\r\n\r\n\\begin{document}\r\n\\title[Sums of three cubes]{On Waring's problem in sums of three cubes for smaller powers}\r\n\\author[Javier Pliego]{Javier Pliego}\r\n\\address{Purdue Mathematical Science Building, 150 N University St, West Lafayette, IN 47907, United States of America}\r\n\r\n\r\n\\email{jpliegog@purdue.edu}\r\n\\subjclass[2010]{11P05, 11P55}\r\n\\keywords{Waring's problem, Hardy-Littlewood method.}\r\n\r\n\r\n\\begin{abstract} We give an upper bound for the minimum $s$ with the property that every sufficiently large integer can be represented as the sum of $s$ positive $k$-th powers of integers represented as the sum of three positive cubes for the cases $2\\leq k\\leq 4.$\r\n\\end{abstract}\r\n\\maketitle\r\n\r\n\\section{Introduction}\r\nAdditive problems involving small powers of positive integers have led to a vast development of new ideas and techniques in the application of the Hardy-Littlewood method which often cannot be extended to the setting of general $k$-th powers. Finding the least number $s$ such that for every sufficiently large integer $n$ then\r\n\\begin{equation}\\label{war}n=x_{1}^{k}+\\ldots+x_{s}^{k},\\end{equation}\r\nwhere $x_{i}\\in\\mathbb{N},$ might be among the most studied examples. We denote such number $s$ by $G(k)$. Let $\\mathscr{C}$ be the set of integers represented as a sum of three positive integral cubes. In this memoir we shall be concerned with the function $G_{3}(k)$, which we define as the minimum $s$ such that (\\ref{war}) is soluble with $x_{i}\\in\\mathscr{C}$, for the cases $2\\leq k\\leq 4.$\r\n\r\nProviding the precise value of $G(k)$ is still an open question for most $k$, the cases $k=2,4$ being precisely the only ones solved. Lagrange showed in 1770 that $G(2)=4$ and Davenport \\cite{Dav} proved in 1939 the identity $G(4)=16,$ and though it is believed that $G(3)=4,$ the best current upper bound is $G(3)\\leq 7$ due to Linnik \\cite{Lin}. \r\n\r\nNot very much is known about $\\mathscr{C}$. In fact, it isn't even known whether it has positive density or not, the best current lower bound on the cardinality of the set being $$\\mathcal{N}(X)=\\lvert\\mathscr{C}\\cap [1,X]\\rvert\\gg X^{\\beta},$$ where  \r\n$\\beta=0.91709477,$ due to Wooley \\cite{Woo3}. We note that under some unproved assumptions on the zeros of some Hasse-Weil $L$-functions, Hooley (\\cite{Hol1}, \\cite{Hol2}) and Heath-Brown \\cite{Hea} showed using different procedures that\r\n$$\\sum_{n\\leq X}r_{3}(n)^{2}\\ll X^{1+\\varepsilon},$$ where $r_{3}(n)$ is the number of representations of $n$ as sums of three positive integral cubes, which implies by applying a standard Cauchy-Schwarz argument that $\\mathcal{N}(X)\\gg X^{1-\\varepsilon}.$\r\nThis lack of understanding of the cardinality of the set also prevents us from understanding its distribution over arithmetic progressions, which often comes into play on the major arc analysis. Therefore, even if the exponents $k=2,4$ are well understood for the original problem, it turns out to be much harder when we restrict the variables to lie on $\\mathscr{C}.$ In this paper we establish the following bounds for $G_{3}(k)$.\r\n\\begin{thm}\\label{thm1.1}\r\nOne has $G_{3}(2)\\leq 8,$ $G_{3}(3)\\leq 17$ and $G_{3}(4)\\leq 57.$\r\n\\end{thm}\r\nWe are far from knowing whether these estimates are good or bad, since the only lower bounds that we have for the above quantities are $4\\leq G(3)\\leq G_{3}(3)$ and $16=G(4)\\leq G_{3}(4).$ For the case $k=2$ though we can actually do better. We take, for convenience, an integer $j\\geq 0$, and observe that the only solution to \\begin{equation}\\label{este}x_{1}^{2}+x_{2}^{2}+x_{3}^{2}+x_{4}^{2}=2^{6+12j}\\end{equation} with $x_{i}\\in\\mathbb{N}$ is $x_{1}=x_{2}=x_{3}=x_{4}=2^{2+6j}.$ This can be seen by taking the equation (\\ref{este}) modulo $8$, realising that one must have $2\\mid x_{i}$ for every $i$ and iterating the process. However, one has $2^{2+6j}\\equiv 4 \\mmod{9}$, and no number congruent to $4\\mmod{9}$ can be written as the sum of three cubes. Therefore, there are infinitely many numbers for which (\\ref{este}) doesn't have any solution with $x_{i}\\in\\mathscr{C}.$ The preceding remark implies then the bound $5\\leq G_{3}(2).$\r\n\r\n\r\n\r\n\r\n\r\nOur proof of Theorem \\ref{thm1.1} is based on the application of the Hardy-Littlewood method. In the setting of this paper, the constraint which prevents us from taking fewer variables is the treatment of the minor arcs discussed in Section \\ref{sec2}. In order to analyse them we utilise an argument of Vaughan \\cite[Lemma 3.4]{Vau3} to bound certain families of exponential sums over the minor arcs together with non-optimal estimates of sums of the shape \\begin{equation*}\\sum_{x\\leq X}a_{x}^{2},  \\ \\ \\text{where} \\  a_{x}={\\rm card}\\big\\{\\mathbf{x}\\in\\mathbb{N}^{3}:\\ x=x_{1}^{3}+x_{2}^{3}+x_{3}^{3},\\ \\ x_{2},x_{3}\\in \\mathcal{A}(P,P^{\\eta})\\big\\}\\end{equation*} with $\\eta>0$ being a small enough parameter and\r\n$$\\mathcal{A}(Y,R)=\\{n\\in [1,Y]\\cap \\mathbb{N}: p\\mid n\\text{ and $p$ prime}\\Rightarrow p\\leq R\\}.$$ Here, the reader may find it useful to observe that it is a consequence of Vaughan and Montgomery \\cite[Theorem 7.2]{Mon} that \\begin{equation*}\\label{smo}\\text{card}\\big(\\mathcal{A}(P,P^{\\eta})\\big)=c_{\\eta}P+O\\big(P/\\log P\\big)\\end{equation*} for some constant $c_{\\eta}>0$ that only depends on $\\eta$. \r\nIn order to briefly discuss the outcome that follows after applying the argument of Vaughan we introduce the exponential sum \\begin{equation}\\label{Weig}W(\\alpha)=\\sum_{M/2\\leq p\\leq M}\\sum_{H/2\\leq h\\leq H}b_{h}e(\\alpha p^{3k}h^{k}),\\end{equation} where $M,H>0$ and $(b_{h})_{h}$ are weights which the reader should think of being  $(a_{h})_{h}$ and $p$ runs over prime numbers. In order to make the argument work, the parameters $M$ and $H$ must be subjected to the constraint $\\max(M^{5-1/k}, M^{2^{k-1}})\\leq H$. The saving over the natural bound $HM$ for $W(\\alpha)$ obtained with the method is roughly speaking of size $M^{1/2}H^{-1/24}$, which makes the estimate obtained worse than trivial for $k\\geq 5.$ \r\n\r\nLet $\\tilde{G}_{3}(k)$ be the minimum number such that for $s\\geq \\tilde{G}_{3}(k)$, the anticipated asymptotic formula for the number of representations in the shape (\\ref{war}) with $x_{i}\\in\\mathscr{C}$ counted with multiplicities holds. Similarly, let $\\tilde{G}(k)$ be the minimum number such that for $s\\geq \\tilde{G}(k)$, the anticipated asymptotic formula in the classical Waring's problem holds. In a forthcoming paper \\cite{Pli}, the author shows that $\\tilde{G}_{3}(k)\\leq 9k^{2}-k+2$ and $G_{3}(k)\\leq 3k\\big(\\log k+\\log\\log k+O(1)\\big),$ \r\nwhich the reader may compare to $\\tilde{G}(k)\\leq k^{2}-k+O(\\sqrt{k})$ due to Bourgain \\cite{Bou} and $G(k)\\leq k\\log k+k\\log\\log k+O(k)$ due to Wooley \\cite{Woo7}. A weakness of the underlying methods employed in that paper is that in most of the sums of three cubes employed in the representation, all but one of the cubes is fixed in the associated analysis.\r\n\r\nA naive approach to bounding $G_{3}(k)$ would then be to replace each sum of three cubes by the specialisation $3x^{3}$, and this suggests a bound of the shape $G_{3}(k)\\leq G(3k)$. With this idea in mind, the bounds $G(6)\\leq 24$ due to Vaughan and Wooley \\cite{VauWoo1}, $G(9)\\leq 47$ and $G(12)\\leq 72$ due to Wooley \\cite{Woo6} reveal that the methods used in this memoir improve what would have been the trivial approach and confirms that we are actually using the three integral cubes non-trivially in our argument. For the cases $k=2,3$ we combine the pointwise bound obtained for $W(\\alpha)$ over the minor arcs with some restriction estimates involving the coefficients $(a_{m})_{m}$. When $k=4$ we instead use a bound for a mean value of smooth Weyl sums of exponent $12$. The estimate for $W(\\alpha)$ obtained here is then robust enough to enable us to gain $15$ variables from the trivial approach over the minor arcs and allows us to prune back to a narrower set of major arcs.\r\n\r\n\r\nThe paper is organized as follows. In Section \\ref{sec2} we use Vaughan methods to estimate $W(\\alpha)$ and provide bounds for the contribution of the minor arcs which are good enough for our purposes when $k=2,3$. We approximate the generating functions of the problem on a narrower set of major arcs in Section \\ref{sec3}. In Sections \\ref{sec4}, \\ref{sec5} and \\ref{sec6} we only consider the exponents $k=2,3$, whereas in Section \\ref{sec7} we prove the theorem for $k=4.$ Sections \\ref{sec4} and \\ref{sec5} are devoted to the study of the singular series and the singular integral respectively. We then prune back to the narrower set of arcs to show a lower bound for the major arc contribution in Section \\ref{sec6}.\r\n\r\nUnless specified, any lower case letter $\\mathbf{x}$ written in bold will denote a triple of integers $(x_{1},x_{2},x_{3})$. We will write $a\\leq \\mathbf{V}\\leq b$ when $a\\leq v_{i}\\leq b$ for $1\\leq i\\leq n$. As usual in analytic number theory, for each $x\\in\\mathbb{R}$ we denote $\\exp(2\\pi i x)$ by $e(x)$, and for each natural number $q$ then $e(x/q)$ will be written as $e_{q}(x).$ We use $\\ll$ and $\\gg$ to denote Vinogradov's notation, and write $A\\asymp B$ whenever $A\\ll B\\ll A$. When $\\varepsilon$ appears in any bound, it will mean that the bound holds for every $\\varepsilon>0$, though the implicit constant then may depend on $\\varepsilon$. We adopt the convention that whenever we write $\\delta$ in the computations we mean that there exists a positive constant $\\delta$ for which the bound holds. We write $p^{r}|| n$ to denote that $p^{r}| n$ but $p^{r+1}\\nmid n.$\r\n\r\n\\emph{Acknowledgements}: The author's work was supported in part by a European Research Council Advanced\r\nGrant under the European Union\u2019s Horizon 2020 research and innovation programme via grant agreement No. 695223 during his studies at the University of Bristol. It was completed while the author was visiting Purdue University under Trevor Wooley's supervision. The author would like to thank him for his guidance and helpful comments, an anonymous referee for useful remarks and both the University of Bristol and Purdue University for their support and hospitality.\r\n\\section{Minor arc estimates}\\label{sec2}\r\nAs mentioned in the introduction, we provide an estimate for the exponential sum $W(\\alpha)$ by using methods of Vaughan. We make use of a Hardy-Littlewood dissection and combine both the bound for $W(\\alpha)$ and a restriction estimate of a certain mean value to bound the minor arc contribution for the cases $k=2,3$. We also remark that the estimate for $W(\\alpha)$ is also used in Sections \\ref{sec6} and \\ref{sec7} to prune the major arcs back to a narrower set of arcs. Before going into the proof of the main lemma, it is convenient to write\r\n\\begin{equation}\\label{Saq}S_{k}(q,a)=\\sum_{r=1}^{q}e_{q}(ar^{k}).\\end{equation} We also introduce the multiplicative function $\\tau_{k}(q)$ by defining $\\tau_{2}(q)=q^{-1/2}$ and $$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\tau_{k}(p^{uk+v})=p^{-u-1}\\ \\ \\text{when $u\\geq 0$ and $2\\leq v\\leq k$}$$ and $$\\tau_{k}(p^{uk+1})=kp^{-u-1/2}\\ \\ \\text{ when $u\\geq 0$}$$for $k=3,4.$ Observe that with this definition then one has the bound \\begin{equation}\\label{tauk}\\tau_{k}(q)\\ll q^{-1/k},\\end{equation} and the proof of Theorem 4.2 of \\cite{Vau} yields\r\n\\begin{equation}\\label{skk}q^{-1}S_{k}(q,a)\\ll \\tau_{k}(q).\\end{equation}\r\n\\begin{lem}\\label{lema1}\r\nLet $H,M>0$ such that $\\max(M^{5-1/k},M^{2^{k-1}})\\leq H.$ Let $\\alpha\\in [0,1)$. Suppose that $\\alpha=a/q+\\beta$, where $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ and such that $q\\leq Y,$ and $\\lvert \\beta\\rvert\\leq q^{-1}Y^{-1},$ where $Y$ is a parameter in the range $M^{k}\\leq Y\\leq H^{k}M^{2k}.$ Then the exponential sum $W(\\alpha)$, defined in (\\ref{Weig}), satisfies\r\n\\begin{equation}\\label{boundW}W(\\alpha)\\ll H^{\\varepsilon}\\Bigg(HM+\\frac{\\tau_{k}(q)HM^{2}}{1+M^{3k}H^{k}\\lvert \\alpha-a/q\\rvert}\\Bigg)^{1/2}\\Bigg(\\sum_{H/2\\leq h\\leq H}\\lvert b_{h}\\rvert^{2}\\Bigg)^{1/2}.\\end{equation} \r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nFor the sake of simplicity we will not write the limits of summation for $p$ and $h$ throughout the rest of the section. We apply Cauchy-Schwarz to obtain\r\n\\begin{align}\\label{2.2}W(\\alpha)&\\ll \\Big(\\sum_{h}\\lvert b_{h}\\rvert^{2}\\Big)^{1/2}\\Big(\\sum_{h}\\sum_{ p_{1},p_{2}}e\\big(\\alpha(p_{1}^{3k}-p_{2}^{3k})h^{k}\\big)\\Big)^{1/2}\\nonumber\r\n\\\\\r\n&\\ll\\Big(\\sum_{h}\\lvert b_{h}\\rvert^{2}\\Big)^{1/2}\\Big(HM+E(\\alpha)\\Big)^{1/2},\r\n\\end{align}\r\nwhere the term $HM$ comes from the diagonal contribution and $$E(\\alpha)=\\sum_{h}\\sum_{\\substack{p_{2}< p_{1}} }e\\big(\\alpha(p_{1}^{3k}-p_{2}^{3k})h^{k}\\big).$$\r\nIn order to estimate $E(\\alpha)$ we will follow closely the argument of Vaughan \\cite[Lemma 3.4]{Vau3}. For a given pair of primes $(p_{1},p_{2})$ we choose $b,r\\in\\mathbb{N}$ with $(b,r)=1$ and such that $r\\leq 2kH^{k-1}$ and $\\lvert\\alpha(p_{1}^{3k}-p_{2}^{3k})-b/r\\rvert\\leq (2k)^{-1} r^{-1}H^{1-k}$. Then if $r>H$, an application of Weyl's inequality \\cite[Lemma 2.4]{Vau} yields the bound\r\n$$\\sum_{h}e\\big(\\alpha(p_{1}^{3k}-p_{2}^{3k})h^{k}\\big)\\ll H^{1-2^{1-k}+\\varepsilon}\\ll H^{1+\\varepsilon}M^{-1},$$ where we used the restriction on $M$ at the beginning of the lemma. If on the other hand $r\\leq H$ we combine Lemmata 6.1 and 6.2 of \\cite{Vau} with (\\ref{skk}) to obtain\r\n$$\\sum_{h}e\\big(\\alpha(p_{1}^{3k}-p_{2}^{3k})h^{k}\\big)\\ll \\frac{\\tau_{k}(r)H}{1+H^{k}\\big\\lvert \\alpha(p_{1}^{3k}-p_{2}^{3k})-b/r\\big\\rvert}+r^{1/2+\\varepsilon}.$$Consequently, one has that\r\n$$E(\\alpha)\\ll E_{0}+H^{1+\\varepsilon}M+\\sum_{(p_{1},p_{2})}H^{1/2+\\varepsilon}\\ll E_{0}+H^{1+\\varepsilon}M,$$ where\r\n$$E_{0}=\\sum_{(p_{1},p_{2})\\in\\mathcal{A}}\\frac{\\tau_{k}(r)H}{1+H^{k}\\big\\lvert \\alpha(p_{1}^{3k}-p_{2}^{3k})-b/r\\big\\rvert}$$ and $\\mathcal{A}$ is the set of pairs $(p_{1},p_{2})$ with $p_{2}<p_{1}$ for which $r<(6k)^{-1}M^{k}$ and such that $\\big\\lvert \\alpha(p_{1}^{3k}-p_{2}^{3k})-b/r\\big\\rvert< 2^{-1}r^{-1/k}MH^{-k}$. Note that the contribution of the pairs for which one of the previous two restrictions doesn't hold is $O(HM).$ For each pair $(p_{1},p_{2})$, define $n=p_{2},$ $l=p_{1}-p_{2}$ and $D=\\big((n+l)^{3k}-n^{3k}\\big)/l$. Then one finds that\r\n\\begin{equation}\\label{e0}E_{0}\\ll \\sum_{(n,l)}\\frac{\\tau_{k}(r)H}{1+H^{k}\\big\\lvert \\alpha lD-b/r\\big\\rvert},\\end{equation}where $(n,l)$ runs over pairs with $1\\leq l\\leq M$ and $M/2\\leq n\\leq M$ such that $(n+l,n)=1$ and satisfying the existing bounds on $r$ and $\\big\\lvert \\alpha lD-b/r\\big\\rvert$.\r\n\r\nWe next choose for convenience $c,s\\in\\mathbb{N}$ satisfying $(c,s)=1$ and with the property that $s\\leq H^{k}M^{-k}$ and $\\lvert \\alpha l-c/s\\rvert\\leq s^{-1}M^{k}H^{-k}$. By the constraint imposed on $M$ and $H$ at the beginning of the lemma we obtain\r\n$$\\Big\\lvert \\frac{c}{s}-\\frac{b}{rD}\\Big\\rvert sDr< DrM^{k}H^{-k}+\\frac{1}{2}sr^{1-1/k}MH^{-k}< \\frac{3k}{6k}M^{5k-1}H^{-k}+\\frac{1}{2}sM^{k}H^{-k}\\leq 1.$$ Therefore, one has $crD=bs$, and hence the coprimality condition on $r$ and $b$ yields $r|s.$ Let $s_{0}= s/r$. We then have that $s_{0}\\mid D$, whence\r\n$$E_{0}\\ll \\sum_{s_{0}\\mid s}\\tau_{k}\\Big(\\frac{s}{s_{0}}\\Big)\\sum_{(n,l)}\\frac{H}{1+H^{k}D\\big\\lvert \\alpha l-c/s\\big\\rvert},$$where the sum on $(n,l)$ runs over the same range described after (\\ref{e0}) with the conditions $(n+l,n)=1$ and $\\big((n+l)^{3k}-n^{3k}\\big)/l\\equiv 0\\pmod{s_{0}}$. Once we fix $l$ then using the above constraints one has that the number of such $n$ is bounded above by $O\\big((M/s_{0}+1)s_{0}^{\\varepsilon}\\big).$ Consequently, we obtain that $E(\\alpha)\\ll H^{1+\\varepsilon}M+H^{\\varepsilon}ME_{1},$ where $$E_{1}=\\sum_{l\\in\\mathcal{L}}\\frac{\\tau_{k}(s)H}{1+H^{k}M^{3k-1}\\big\\lvert \\alpha l-c/s\\big\\rvert},$$and $\\mathcal{L}$ is the set of integers $l\\leq M$ for which $s<M^{k}/2$ and $\\lvert \\alpha l-c/s\\rvert <M^{2-3k}H^{-k}$. Now we choose $d,t$ with $(d,t)=1$ satisfying $t\\leq M^{k+1}$ and $\\big\\lvert \\alpha-d/t\\big\\rvert\\leq t^{-1}M^{-k-1}.$ One finds that \r\n$$\\Big\\lvert \\frac{c}{ls}-\\frac{d}{t}\\Big\\rvert slt< stM^{2-3k}H^{-k}+slM^{-k-1}< \\frac{1}{2}M^{3-k}H^{-k}+\\frac{1}{2}\\leq 1.$$\r\nTherefore, one has $ct=dsl$ and hence $s|t$. Let $t_{0}=t/s$. Then it follows that $t_{0}\\mid l$, and on defining $l_{0}=l/t_{0}$ we obtain\r\n$$E_{1}\\ll \\sum_{t_{0}\\mid t}\\tau_{k}\\Big(\\frac{t}{t_{0}}\\Big)\\sum_{l_{0}\\leq M/t_{0}}\\frac{H}{1+H^{k}M^{3k-1}l_{0}t_{0}\\big\\lvert \\alpha -d/t\\big\\rvert}\\ll \\frac{\\tau_{k}(t)HM^{1+\\varepsilon}}{1+H^{k}M^{3k}\\big\\lvert \\alpha-d/t\\big\\rvert}.$$\r\nIf either $t\\geq M^{k}/2$ or $\\lvert \\alpha -d/t\\rvert\\geq 2^{-1}t^{-1/k}H^{-k}M^{1-3k}$ then we get $E_{1}\\ll HM^{\\varepsilon}$ and we would be done. For the remaining cases one finds that\r\n$$\\Big\\lvert \\frac{a}{q}-\\frac{d}{t}\\Big\\rvert qt< \\frac{1}{2}qH^{-k}M^{1-3k}t^{1-1/k}+tY^{-1}< \\frac{1}{2}YH^{-k}M^{-2k}+\\frac{1}{2}M^{k}Y^{-1}\\leq 1,$$which implies that $a=d$ and $q=t$, and yields the bound\r\n$$E(\\alpha)\\ll H^{1+\\varepsilon}M+\\frac{\\tau_{k}(q)H^{1+\\varepsilon}M^{2}}{1+H^{k}M^{3k}\\big\\lvert \\alpha-a/q\\big\\rvert}.$$The combination of this estimate and (\\ref{2.2}) proves the lemma.\r\n\\end{proof}\r\nBefore describing the application of this lemma in the minor arc treatment it is convenient to introduce some notation. Let $n$ be a natural number and take $P= n^{1/3k}$. Define the parameters \\begin{equation}\\label{MH}\\gamma(k)=\\displaystyle\\frac{3}{3+\\max(5-1/k,2^{k-1})},\\ \\ \\ \\ \\ \\ M=P^{\\gamma(k)},\\ \\ \\ \\ \\ \\ H=\\max(M^{5-1/k},M^{2^{k-1}}).\\end{equation}\r\nNote that these choices for $M$ and $H$ maximize the saving obtained for $W(\\alpha)$ over the trivial bound in the previous lemma. Take $$H_{1}=\\Big(\\frac{1}{2}\\Big)^{1/3}H^{1/3},\\ \\ \\ \\ \\ \\ H_{2}=\\Big(\\frac{2}{3}\\Big)^{1/3}H^{1/3},\\ \\ \\ \\ \\ \\ H_{3}=\\Big(\\frac{1}{6}\\Big)^{1/3}H^{1/3}.$$\r\nFor every triple $\\mathbf{x}\\in\\mathbb{R}^{3}$, consider the function $T(\\mathbf{x})=x_{1}^{3}+x_{2}^{3}+x_{3}^{3}.$\r\nDefine the sets $$\\mathcal{H}=\\Big\\{(y,\\mathbf{y})\\in\\mathbb{N}^{3}:\\ \\ \\frac{P}{2}\\leq y\\leq P,\\ \\ \\ \\ \\ \\mathbf{y}\\in\\mathcal{A}(P,P^{\\eta})^{2} \\Big\\},$$\r\n$$\\mathcal{W}=\\Big\\{(y,\\mathbf{y})\\in\\mathbb{N}^{3}:\\ \\ \\ H_{1}\\leq y\\leq H_{2},\\ \\ \\ \\ \\mathbf{y}\\in\\mathcal{A}(H_{3},P^{\\eta})^{2}\\Big\\},$$ and the corresponding weights\r\n$$a_{x}=\\lvert \\{\\mathbf{x}\\in\\mathcal{H}:\\ x=T(\\mathbf{x})\\}\\rvert,\\ \\ \\ \\ \\ \\ b_{h}=\\lvert \\{\\mathbf{x}\\in\\mathcal{W}:\\ h=T(\\mathbf{x})\\}\\rvert,$$\r\nwhere $(b_{h})_{h}$ is the choice that we make for the weights of $W(\\alpha)$ in (\\ref{Weig}). We use $(a_{x})_{x}$ to define the weighted exponential sum\r\n$$h(\\alpha)=\\sum_{x\\leq 3P^{3}}a_{x}e(\\alpha x^{k}).$$\r\n\r\nBefore describing how $h(\\alpha)$ and $W(\\alpha)$ play a role in the argument we first show upper bounds on the $L^{2}$-norms of the weights which will be used to estimate the minor arc contribution. Let $X>0$, consider $$f(\\alpha;X)=\\sum_{x\\leq X}e(\\alpha x^{3}),\\ \\ \\ \\ \\ \\ \\ \\ f(\\alpha;X;X^{\\eta})=\\sum_{x\\in\\mathcal{A}(X,X^{\\eta})}e(\\alpha x^{3})$$ and define the mean value\r\n$$U(X)=\\int_{0}^{1}\\lvert f(\\alpha;X)\\rvert^{2}\\lvert  f(\\alpha;X;X^{\\eta})\\rvert^{4}d\\alpha.$$ It is a consequence of Wooley  \\cite[Theorem 1.2]{Woo3} that $U(X)\\ll X^{3+1/4-\\tau},$ where $\\tau=0.00128432.$ Consequently, on considering the underlying diophantine equations due to orthogonality, it follows that\r\n\\begin{equation}\\label{Up}\\sum_{x\\leq 3P^{3}}a_{x}^{2}\\leq U(P)\\ll P^{3+1/4-\\tau},\\ \\ \\ \\ \\ \\ \\ \\ \\sum_{H/2\\leq h\\leq H} b_{h}^{2}\\leq U(H^{1/3})\\ll H^{13/12-\\tau/3}.\\end{equation}\r\nThe reader may note that we didn't write the entire decimal expression of $\\tau$, so the bound for $U(X)$ holds for a slightly bigger $\\tau$. Therefore, whenever we encounter bounds with the mean value $U(X)$ involved, we can omit the parameter $\\varepsilon$ in the exponents.\r\n\r\nTake $s(k)=2^{k}$ when $k=2,3$ and define $t(k)$ by $t(2)=4$ and $t(3)=9$. For ease of notation we will just write $s$ and $t$ instead of $s(k)$ and $t(k)$ throughout the paper.  Let $R(n)$ be the number of solutions of the equation\r\n$$n=\\sum_{i=1}^{t}T(p_{i}\\mathbf{x}_{i})^{k}+\\sum_{i=t+1}^{s+t}T(\\mathbf{x}_{i})^{k},$$ where $\\mathbf{x}_{i}\\in \\mathcal{W}$ for $1\\leq i\\leq t$ with $M/2\\leq p_{i}\\leq M$ prime and $\\mathbf{x}_{i}\\in \\mathcal{H}$ for $t+1\\leq i\\leq s+t$. Note that by orthogonality then $$R(n)=\\int_{0}^{1}h(\\alpha)^{s}W(\\alpha)^{t}e(-\\alpha n)d\\alpha.$$\r\nOur goal throughout Sections \\ref{sec2} to \\ref{sec6} is to obtain a lower bound for $R(n)$ for all sufficiently large $n$.\r\nFor such purpose, we make use of a Hardy-Littlewood dissection in our analysis. When $1\\leq X\\leq M^{k}$, we define the major arcs $\\grM(X)$ to be the union of \r\n\\begin{equation}\\label{kioto}\\grM(a,q)=\\Big\\{ \\alpha\\in [0,1): \\Big\\lvert \\alpha-a/q\\Big\\rvert \\leq \\frac{X}{qn}\\Big\\}\\end{equation} with $0\\leq a\\leq q\\leq X$ and $(a,q)=1$. For the sake of simplicity we write \r\n$$\\grM=\\grM(M^{k}),\\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\grN=\\grM\\big((6k)^{-1}H^{1/3}\\big).$$We define the minor arcs as $\\grm=[0,1)\\setminus \\grM$ and $\\grn=[0,1)\\setminus \\grN$. This dissection remains valid for the case $k=4$ and will be used in Section \\ref{sec7}. We then take $\\alpha\\in\\grm$ and observe that by Dirichlet's approximation there exist non-negative integers $a,q$ with $(a,q)=1$ and $1\\leq q\\leq nM^{-k}$ such that $$\\lvert \\alpha-a/q\\rvert\\leq \\frac{M^{k}}{qn}.$$Consequently, one has $q>M^{k}$, and hence (\\ref{Up}) and Lemma \\ref{lema1} yield the bound\r\n\\begin{equation}\\label{Wu}W(\\alpha)\\ll H^{1/2+\\varepsilon}M^{1/2}\\Big(\\sum_{h\\leq H} b_{h}^{2}\\Big)^{1/2}\\ll H^{1+1/24-\\tau/6}M^{1/2}.\\end{equation}In the following proposition we combine this pointwise bound with some restriction estimates to bound the minor arc contribution.\r\n\\begin{prop}\\label{prop1}When $k=2,3$ then one has that\r\n\\begin{equation}\\label{min}\\int_{\\grm}\\lvert h(\\alpha)\\rvert^{s}\\lvert W(\\alpha)\\rvert^{t}d\\alpha\\ll (HM)^{t}P^{3s-3k-\\delta}.\\end{equation}\r\n\r\n\\end{prop}\r\n\\begin{proof}\r\nBy Bourgain \\cite[(1.6)]{Bou1} when $k=2$ and Hughes and Wooley \\cite[Theorem 4.1]{Hug} for the case $k=3$, we find that\r\n$$\\int_{0}^{1}\\lvert h(\\alpha)\\rvert^{s}d \\alpha\\ll P^{3s/2-3k+\\varepsilon}\\Big(\\sum_{x\\leq 3P^{3}}a_{x}^{2}\\Big)^{s/2}\\ll P^{3s-3k+s/8-\\delta}.$$ Therefore, an application of the pointwise bound on the minor arcs obtained in (\\ref{Wu}) yields the estimate\r\n$$\\int_{\\grm}\\lvert h(\\alpha)\\rvert^{s}\\lvert W(\\alpha)\\rvert^{t}d \\alpha\\ll H^{t+t/24}M^{t/2}P^{3s-3k+s/8-\\delta}.$$\r\nWe define for convenience the parameter $\\xi(k)$ as $\\xi(2)=0$ and $\\xi(3)=7/92$, and deduce that the proposition then follows after noting by (\\ref{MH}) that $H^{t/24}M^{t/2}P^{s/8}=M^{t}P^{-\\xi(k)}$. For the purpose of this paper, knowing the existence of $\\delta>0$ for which (\\ref{min}) holds suffices. The reader may observe though that the precise saving over the expected main term that we obtain here is $H^{t\\tau/6}P^{\\xi(k)+s\\tau/2-\\varepsilon}$. \r\n\\end{proof}\r\n\r\n\r\n\\section{Approximation of exponential sums over the major arcs}\\label{sec3}\r\nWe adapt the argument of Vaughan \\cite[Theorem 4.1]{Vau} to estimate the difference between the exponential sums $h(\\alpha),W(\\alpha)$ and their approximations over the major arcs. Let $\\mathbf{y}\\in [0,P]^{2}$ and set $C_{\\mathbf{y}}=y_{1}^{3}+y_{2}^{3}$. Let $\\beta\\in\\mathbb{R}$ and let $p$ be a prime number. Consider the integrals\r\n\\begin{equation}\\label{esp}v_{\\mathbf{y}}(\\beta)=\\int_{P/2}^{P}e\\Big(\\beta\\big(x^{3}+C_{\\mathbf{y}}\\big)^{k}\\Big)dx\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ v_{\\mathbf{y},p}(\\beta)=\\int_{H_{1}}^{H_{2}}e\\Big(\\beta p^{3k}\\big(x^{3}+C_{\\mathbf{y}}\\big)^{k}\\Big)dx.\\end{equation}\r\nNote that by a change of variables one finds that \\begin{equation}\\label{vyp}v_{\\mathbf{y}}(\\beta)=\\int_{M_{\\mathbf{y}}}^{N_{\\mathbf{y}}}B_{\\mathbf{y}}(\\gamma)e(\\beta \\gamma)d\\gamma,\\ \\ \\ \\ \\ \\ v_{\\mathbf{y},p}(\\beta)=\\int_{M_{\\mathbf{y},p}}^{N_{\\mathbf{y},p}}B_{\\mathbf{y},p}(\\gamma)e(\\beta \\gamma)d\\gamma,\\end{equation}where the limits of integration taken are $M_{\\mathbf{y}}=\\big(P^{3}/8+C_{\\mathbf{y}}\\big)^{k},$ $N_{\\mathbf{y}}=\\big(P^{3}+C_{\\mathbf{y}}\\big)^{k}$, $M_{\\mathbf{y},p}=\\big(Hp^{3}/2+C_{p\\mathbf{y}}\\big)^{k}$ and $N_{\\mathbf{y},p}=\\big(2Hp^{3}/3+C_{p\\mathbf{y}}\\big)^{k}$, and the functions inside the integral are defined as\r\n\\begin{equation}\\label{fun}B_{\\mathbf{y}}(\\gamma)=\\frac{1}{3k}\\gamma^{1/k-1}(\\gamma^{1/k}-C_{\\mathbf{y}})^{-2/3},\\ \\ \\ \\ B_{\\mathbf{y},p}(\\gamma)=\\frac{1}{3kp}\\gamma^{1/k-1}(\\gamma^{1/k}-C_{p\\mathbf{y}})^{-2/3}.\\end{equation}\r\nWe introduce the auxiliary multiplicative function $w_{k}(q)$ defined for prime powers by taking\r\n\\begin{equation}\\label{wuok}w_{k}(p^{3ku+v})=\\left\\{\r\n\t       \\begin{array}{ll}\r\n         p^{-u-v/3k}\\ \\ \\ \\ \\ \\ \\text{when $u\\geq 1$ and $1\\leq v\\leq 3k$,}   \\\\\r\n         p^{-1}\\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\text{when $u=0$ and $2\\leq v\\leq 3k$,}    \\\\\r\n         p^{-1/2}\\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\text{when $u=0$ and $v=1$.}    \\\\\r\n    \\end{array}  \\right. \\end{equation}\r\nIn order to discuss the approximation of $f(\\alpha)$ on the major arcs, it is convenient to consider for $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ the sums\r\n\\begin{equation}\\label{ggg}S_{\\mathbf{y}}(q,a)=\\sum_{r=1}^{q}e_{q}\\Big(a\\big(r^{3}+C_{\\mathbf{y}}\\big)^{k}\\Big)\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ V(\\alpha,q,a)=q^{-1}\\sum_{\\mathbf{y}}S_{\\mathbf{y}}(q,a)v_{\\mathbf{y}}(\\beta),\\end{equation} where $\\mathbf{y}$ runs over the set $\\mathcal{A}(P,P^{\\eta})^{2}$ of pairs of smooth numbers.\r\n\\begin{lem}\\label{lema2}\r\nSuppose that $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$. Let $\\alpha\\in [0,1)$ and $\\beta=\\alpha-a/q$. Then we have the estimate\r\n$$h(\\alpha)-V(\\alpha,q,a)\\ll P^{2}q^{1+\\varepsilon}w_{k}(q)(1+n\\lvert\\beta\\rvert)^{1/2}.$$\r\nMoreover, if $\\lvert\\beta\\rvert\\leq (2\\cdot 3^{k}kq)^{-1}Pn^{-1}$ one finds that\r\n\\begin{equation}\\label{faci}h(\\alpha)-V(\\alpha,q,a)\\ll P^{2}q^{1+\\varepsilon}w_{k}(q).\\end{equation}\r\n\r\n\\end{lem}\r\n\\begin{proof}\r\nLet $b\\in\\mathbb{N}$ and $\\mathbf{y}\\in\\mathcal{A}(P,P^{\\eta})^{2}.$ We define \\begin{equation}\\label{Syt}S_{\\mathbf{y}}(q,a,b)=\\sum_{r=1}^{q}e_{q}\\big(a\\big(r^{3}+C_{\\mathbf{y}}\\big)^{k}+br\\big)\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ I_{\\mathbf{y}}(b)=\\int_{P/2}^{P}e\\big(F(\\gamma;b)\\big)d\\gamma,\\end{equation}where the function in the argument inside the integral is taken to be\r\n$$ F(\\gamma;b)=\\beta\\big(\\gamma^{3}+C_{\\mathbf{y}})^{k}-b\\gamma/q.$$ Both the complete exponential sum and the integral play a role in the analysis of the main and the error term. Observe that $h(\\alpha)$ can be written as\r\n$$h(\\alpha)=\\sum_{\\mathbf{y}\\in\\mathcal{A}(P, P^{\\eta})}h_{\\mathbf{y}}(\\alpha),\\ \\ \\ \\ \\ \\ \\ \\text{with}\\ \\ \\ \\ \\ \\ \\ \\ h_{\\mathbf{y}}(\\alpha)=\\sum_{P/2\\leq x\\leq P}e\\big(\\alpha(x^{3}+C_{\\mathbf{y}})^{k}\\big).$$ \r\nThen by sorting the summation into arithmetic progressions modulo $q$ and applying orthogonality, it follows that\r\n$$h_{\\mathbf{y}}(\\alpha)=q^{-1}\\sum_{-q/2<b\\leq q/2}S_{\\mathbf{y}}(q,a,b)\\sum_{P/2\\leq x\\leq P}e\\big(F(x;b)\\big),$$ whence using Vaughan \\cite[Lemma 4.2]{Vau} we obtain\r\n\\begin{align}\\label{hu}h_{\\mathbf{y}}(\\alpha)-q^{-1}S_{\\mathbf{y}}(q,a)v_{\\mathbf{y}}(\\beta)=\r\n&q^{-1}\\sum_{\\substack{-B< b\\leq B\\\\ b\\neq 0}} S_{\\mathbf{y}}(q,a,b)I_{\\mathbf{y}}(b)\\nonumber\r\n\\\\\r\n&+O\\Big(\\log(H+2)q^{-1}\\sum_{-q/2< b\\leq q/2} \\big\\lvert S_{\\mathbf{y}}(q,a,b)\\big\\rvert\\Big),\r\n\\end{align}\r\n where $B=(H+1/2)q$ and $H=\\big\\lceil 3^{k}kP^{-1}n\\lvert\\beta\\rvert +1/2\\big\\rceil.$ \r\nNote that by the quasi-multiplicative property, in order to bound $S_{\\mathbf{y}}(q,a,b)$ it suffices to consider the case when $q$ is a prime power. For such purposes, we take $q=p^{3ku+v}$. We observe first that by Vaughan \\cite[Theorem 7.1]{Vau} one has that\r\n$S_{\\mathbf{y}}(q,a,b)\\ll q^{1-1/3k+\\varepsilon}.$ Moreover, when $v\\geq 2$ and $u=0$ we can deduce from the proof of the same theorem\\footnote{See in particular the argument following \\cite[(7.16)]{Vau}} that $S_{\\mathbf{y}}(p^{v},a,b)\\ll p^{v-1}$. For the case $q=p,$ the work of Weil\\footnote{See Schmidt \\cite[Corollary 2F]{Sch} for an elementary proof of this bound.} \\cite{Wei2} yields the estimate $S_{\\mathbf{y}}(p,a,b)\\ll p^{1/2}.$ Therefore, combining these bounds with the definition (\\ref{wuok}) one finds that\r\n\\begin{equation}\\label{wee}S_{\\mathbf{y}}(q,a,b)\\ll q^{1+\\varepsilon}w_{k}(q).\\end{equation} Consequently, by (\\ref{hu}) we have\r\n\\begin{equation}\\label{hyh}h_{\\mathbf{y}}(\\alpha)-q^{-1}S_{\\mathbf{y}}(q,a)v_{\\mathbf{y}}(\\beta)\\ll q^{\\varepsilon}w_{k}(q)\\sum_{\\substack{-B< b\\leq B\\\\ b\\neq 0}}\\lvert I_{\\mathbf{y}}(b)\\rvert+q^{1+\\varepsilon}w_{k}(q)\\log(H+2).\\end{equation}\r\n\r\nTo treat the sum on the right handside we use the methods of the proof of Vaughan \\cite[Theorem 4.1]{Vau}. In his analysis he classifies the range of integration of $I(b)$ according to the size of $\\lvert G'(\\gamma)\\rvert$, where $$G(\\gamma)=\\beta\\gamma^{k}-b\\gamma/q\\ \\ \\ \\ \\ \\  \\text{and}\\ \\ I(b)=\\displaystyle\\int_{0}^{X}e\\big(G(\\gamma)\\big)d\\gamma.$$ We follow Vaughan's analysis closely, dividing the range of integration of $I_{\\mathbf{y}}(b)$ according to the size of $\\lvert F'(\\gamma;b)\\rvert,$ to obtain $$\\sum_{\\substack{-B< b\\leq B\\\\ b\\neq 0}}\\lvert I_{\\mathbf{y}}(b)\\rvert\\ll q^{1+\\varepsilon}(1+n\\lvert \\beta\\rvert )^{1/2}.$$ Since $\\log(H+2)\\ll (1+n\\lvert\\beta\\rvert)^{1/2}$ then\r\n\\begin{equation*}h_{\\mathbf{y}}(\\alpha)-q^{-1}S_{\\mathbf{y}}(q,a)v_{\\mathbf{y}}(\\beta)\\ll q^{1+\\varepsilon}w_{k}(q)(1+n\\lvert\\beta\\rvert)^{1/2},\\end{equation*}\r\nwhich implies the first statement of the lemma by summing over $\\mathbf{y}\\in\\mathcal{A}(P,P^{\\eta})^{2}$.\r\nNote that when $\\lvert\\beta\\rvert\\leq (2\\cdot 3^{k}kq)^{-1}Pn^{-1}$ and $b\\neq 0$ one has $\\lvert F'(x;b)\\rvert\\geq \\lvert b\\rvert/2q$ and $H=1$. Observing that $F'(x;b)$ is monotonous then partial integration yields $$\\sum_{\\substack{-B< b\\leq B\\\\ b\\neq 0}}\\lvert I_{\\mathbf{y}}(b)\\rvert\\ll \\sum_{\\substack{-B< b\\leq B\\\\ b\\neq 0}}\\frac{q}{\\lvert b\\rvert}\\ll q^{1+\\varepsilon}.$$ Combining this estimate with (\\ref{hyh}) and summing over $\\mathbf{y}\\in\\mathcal{A}(P,P^{\\eta})^{2}$ we get (\\ref{faci}).\r\n\\end{proof}\r\nBy applying similar methods we can obtain the same type of approximation for the exponential sum $W(\\alpha).$ For $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ and recalling (\\ref{esp}) and (\\ref{ggg}) we introduce the auxiliary function \\begin{equation}\\label{Wa}W(\\alpha,q,a)=q^{-1}\\sum_{\\mathbf{y},p}S_{p\\mathbf{y}}(q,a)v_{\\mathbf{y},p}(\\beta),\\ \\ \\ \\ \\text{where}\\ \\mathbf{y}\\in\\mathcal{A}(H_{3},P^{\\eta})^{2}\\ \\text{and}\\  M/2\\leq p\\leq M.\\end{equation}\r\n\\begin{lem}\\label{lema3}\r\nSuppose that $(a,q)=1$ and $(p,q)=1$ for all primes with $M/2\\leq p\\leq M$. Let $\\alpha\\in [0,1)$ and $\\beta=\\alpha-a/q$. Then we have the estimate \r\n$$W(\\alpha)-W(\\alpha,q,a)\\ll MH^{2/3}q^{1+\\varepsilon}w_{k}(q)(1+n\\lvert\\beta\\rvert)^{1/2}(\\log P)^{-1}.$$\r\nMoreover, if $\\lvert\\beta\\rvert\\leq (6kq)^{-1}H^{1/3}n^{-1}$ one finds that\r\n$$W(\\alpha)-W(\\alpha,q,a)\\ll MH^{2/3}q^{1+\\varepsilon}w_{k}(q)(\\log P)^{-1}.$$\r\n\\end{lem}\r\n\\begin{proof}In the same way as before, we can express the exponential sum $W(\\alpha)$ as\r\n$$W(\\alpha)=\\sum_{\\substack{\\mathbf{y},p}}W_{\\mathbf{y},p}(\\alpha),\\ \\ \\ \\ \\ \\ \\ \\text{where}\\ \\  \\ W_{\\mathbf{y},p}(\\alpha)=\\sum_{H_{1}\\leq x\\leq H_{2}}e\\big(\\alpha p^{3k}(x^{3}+C_{\\mathbf{y}})^{k}\\big).$$ \r\nSorting the summation into arithmetic progressions modulo $q$ and applying orthogonality one has that\r\n$$W_{\\mathbf{y},p}(\\alpha)=q^{-1}\\sum_{-q/2<b\\leq q/2}S_{\\mathbf{y}}(q,ap^{3k},b)\\sum_{H_{1}\\leq x\\leq H_{2}}e\\Big(\\beta p^{3k}(x^{3}+C_{\\mathbf{y}})^{k}-\\frac{bx}{q}\\Big).$$ Recalling that $(q,p)=1$ then a change of variables yields $S_{\\mathbf{y}}(q,ap^{3k})=S_{p\\mathbf{y}}(q,a).$ Therefore, the application of the argument of Vaughan \\cite[Theorem 4.1]{Vau} in the same way as we did above leads to\r\n\\begin{equation*}\\label{Wy}W_{\\mathbf{y},p}(\\alpha)-q^{-1}S_{p\\mathbf{y}}(q,a)v_{\\mathbf{y},p}(\\beta)\\ll q^{1+\\varepsilon}w_{k}(q)(1+n\\lvert\\beta\\rvert)^{1/2},\\end{equation*} and if $\\lvert\\beta\\rvert\\leq (6kq)^{-1}H^{1/3}n^{-1}$ then $$W_{\\mathbf{y},p}(\\alpha)-q^{-1}S_{p\\mathbf{y}}(q,a)v_{\\mathbf{y},p}(\\beta)\\ll q^{1+\\varepsilon}w_{k}(q),$$\r\nwhich delivers the desired result by summing over the range of $(\\mathbf{y},p)$ described in (\\ref{Wa}).\r\n\\end{proof}\r\n\r\n\\section{Treatment of the singular series}\\label{sec4}\r\nUnless specified, in this section and the two upcoming ones we assume that $k=2,3.$ We introduce some exponential sums and present upper bounds which we obtain making use of the arguments in Vaughan \\cite[Theorem 7.1]{Vau}. We also discuss the congruence problem and introduce some divisibility constraints on $C_{\\mathbf{y}_{i}}$ and $C_{p_{i}\\mathbf{y}_{i}}$ to ensure local solubility. For the rest of the paper, unless specified, $\\mathbf{Y}=(\\mathbf{y}_{1},\\ldots, \\mathbf{y}_{s+t})\\in \\mathbb{N}^{2s+2t}$ and $\\mathbf{p}=(p_{1},\\dots,p_{t})$ will denote tuples with $\\mathbf{y}_{i}\\in\\mathcal{A}(P,P^{\\eta})^{2}$ for $t+1\\leq i\\leq s+t$ and $\\mathbf{y}_{i}\\in\\mathcal{A}(H_{3},P^{\\eta})^{2}$ for $1\\leq i\\leq t$, where $p_{i}$ are primes satisfying $M/2\\leq p_{i}\\leq M.$ Take $q\\in\\mathbb{N}$ and define \\begin{equation*}\\label{Syp}S_{\\mathbf{Y},\\mathbf{p}}(q)=q^{-s-t}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}e(-an/q)\\prod_{i=1}^{t} S_{p_{i}\\mathbf{y}_{i}}(q,a)\\prod_{i=t+1}^{s+t} S_{\\mathbf{y}_{i}}(q,a).\\end{equation*}The following technical lemma provides a straightforward upper bound for the previous exponential sum and will be used throughout the major arc treatment.\r\n\\begin{lem}\\label{expo}\r\nAssume that $2\\leq k\\leq 4.$ Let $m\\geq 2$. Take $\\alpha\\leq\\frac{m-1}{3k}$ when $m\\geq 3$ and $\\alpha=0$ for $m=2$. Let $Q\\geq 1$. Then, recalling (\\ref{wuok}) one has \r\n$$\\sum_{q\\leq Q}q^{\\alpha}w_{k}(q)^{m}\\ll Q^{\\varepsilon}.$$Moreover, for the case $k=4$ we also have\r\n\\begin{equation}\\label{sum}\\sum_{q\\leq Q}q\\tau_{4}(q)^{4}w_{4}(q)\\ll Q^{\\varepsilon},\\end{equation} where $\\tau_{4}(q)$ was defined just before Lemma \\ref{lema1}.\r\n\\end{lem} \r\n\\begin{proof} By the multiplicative property of $w_{k}(q)$ it follows that\r\n$$\\sum_{q\\leq Q}q^{\\alpha}w_{k}(q)^{m}\\ll \\prod_{p\\leq Q}\\big(1+\\sum_{h=1}^{\\infty}p^{h\\alpha}w_{k}(p^{h})^{m}\\big)\\ll \\prod_{p\\leq Q}\\big(1+Cp^{-1}\\big)\\ll Q^{\\varepsilon}.$$ For the second estimate we use the bound $\\tau_{4}(p^{h})^{4}\\ll p^{-h}$ when $h\\geq 2$ to obtain\r\n$$\\sum_{h=1}^{\\infty}p^{h}\\tau_{4}(p^{h})^{4}w_{4}(p^{h})\\ll p^{-3/2}+\\sum_{h\\geq 2}w_{4}(p^{h})\\ll p^{-1}.$$ Equation (\\ref{sum}) follows then combining the above bound with multiplicativity.\r\n\\end{proof}\r\n\\begin{lem}\\label{lema5}\r\nLet $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$. The functions $S_{\\mathbf{y}}(q,a)$ and $S_{\\mathbf{Y},\\mathbf{p}}(q)$ defined above satisfy\r\n\\begin{equation}\\label{Ss}S_{\\mathbf{y}}(q,a)\\ll q^{1+\\varepsilon}w_{k}(q),\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ S_{\\mathbf{Y},\\mathbf{p}}(q)\\ll q^{1+\\varepsilon}w_{k}(q)^{s+t}.\\end{equation}\r\nAs a consequence, for every $Q\\geq 1$ and every $\\alpha\\leq\\frac{s+t-1}{3k}-1$ it follows that \\begin{equation}\\label{qal}\\sum_{\\substack{q\\leq Q}}q^{\\alpha}\\lvert S_{\\mathbf{Y},\\mathbf{p}}(q)\\rvert\\ll Q^{\\varepsilon}\\ \\ \\ \\text{and}\\ \\ \\ \\ \\sum_{\\substack{q>Q}}\\lvert S_{\\mathbf{Y},\\mathbf{p}}(q)\\rvert\\ll Q^{\\varepsilon-\\alpha}.\\end{equation}\r\n\\end{lem}\r\n\\begin{proof}\r\nOn recalling (\\ref{Syt}) note that $S_{\\mathbf{y}}(q,a)=S_{\\mathbf{y}}(q,a,0)$. Therefore, (\\ref{wee}) yields $S_{\\mathbf{y}}(q,a)\\ll q^{1+\\varepsilon}w_{k}(q)$, and hence (\\ref{Ss}) holds. This estimate and Lemma \\ref{expo} imply the first inequality in (\\ref{qal}). Finally, observe that as a consequence we have\r\n$$\\sum_{\\substack{Q\\leq q\\leq 2Q}}\\lvert S_{\\mathbf{Y},\\mathbf{p}}(q)\\rvert\\ll Q^{\\varepsilon-\\alpha},$$ from where the second inequality of (\\ref{qal}) follows by summing over dyadic intervals.\r\n\\end{proof}\r\nWe apply the bounds obtained in the previous lemma to a collection of singular series and other related series. For such purpose, it is convenient to define, for tuples $(\\mathbf{Y}, \\mathbf{p})$ and each prime $p$ the sums\r\n$$\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)=\\sum_{q=1}^{\\infty}S_{\\mathbf{Y},\\mathbf{p}}(q),\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sigma(p)=\\sum_{l=0}^{\\infty}S_{\\mathbf{Y},\\mathbf{p}}(p^{l}).$$\r\n\\begin{lem}\\label{lema6}\r\nThe singular series $\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)$ converges absolutely, the identity\r\n\\begin{equation}\\label{Sin}\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)=\\prod_{p}\\sigma(p)\\end{equation}\r\nholds and $0\\leq\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)\\ll 1$. Furthermore, one has $\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)\\gg 1$ provided that:\r\n\\begin{enumerate}\r\n\\item When $k=2$ one has $C_{p_{i}\\mathbf{y}_{i}}\\equiv 28 \\pmod{108}$ for $1\\leq i\\leq t$ and $C_{\\mathbf{y}_{i}}\\equiv 28\\pmod{108}$ for $t+1\\leq i\\leq s+t$;\r\n\\item When $k=3$ one has $C_{p_{i}\\mathbf{y}_{i}}\\equiv 0 \\pmod{162}$ for $1\\leq i\\leq t$ and $C_{\\mathbf{y}_{i}}\\equiv 0\\pmod{162}$ for $t+1\\leq i\\leq s+t$.\r\n\\end{enumerate}\r\n\\end{lem}\r\nAs mentioned before, the constraints on $C_{\\mathbf{y}_{i}}$ and $C_{p_{i}\\mathbf{y}_{i}}$ ensure the local solubility of the problem. Note that the set of tuples with these divisibility conditions has positive density over the set of tuples without the restrictions since it follows from the proof of Lemma 5.4 of \\cite{Vau3} that smooth numbers are well distributed on arithmetic progressions. Therefore, we are still able to get the expected lower bound for the major arc contribution. Observe though that the choices for the constraints are not unique, but for the purpose of this exposition it will suffice to study just one of the possible restrictions.\r\n\\begin{proof}\r\nNote that the application of Lemma \\ref{lema5} yields the estimate \\begin{equation}\\label{sig}\\sigma(p)-1\\ll p^{-2}.\\end{equation} This bound and the multiplicative property of $S_{\\mathbf{Y},\\mathbf{p}}(q)$ imply (\\ref{Sin}), the convergence of the series $\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)$ and its upper bound.\r\nTo give a more arithmetic description of $\\sigma(p)$ it is convenient to introduce \r\n$$\\mathcal{M}_{n}(p^{h})=\\Big\\{\\mathbf{X}\\in [1,p^{h}]^{s+t}:\\ \\ n\\equiv\\sum_{i=1}^{t}(x_{i}^{3}+C_{p_{i}\\mathbf{y}_{i}})^{k}+\\sum_{i=t+1}^{s+t}(x_{i}^{3}+C_{\\mathbf{y}_{i}})^{k} \\pmod{p^{h}}\\Big\\}$$ and $M_{n}(p^{h})=\\lvert \\mathcal{M}_{n}(p^{h})\\rvert.$ Observe that by a standard argument making use of orthogonality we obtain the relation\r\n$$\\sum_{l=0}^{h}S_{\\mathbf{Y},\\mathbf{p}}(p^{l})=p^{(1-s-t)h}M_{n}(p^{h}).$$ \r\nIn view of (\\ref{sig}) it transpires then that in order to prove the lower bound for $\\mathfrak{S}_{\\mathbf{Y},\\mathbf{p}}(n)$ it will suffice to show that $p^{(1-s-t)h}M_{n}(p^{h})\\geq C_{p}$ for some positive constant $C_{p}$ depending on $p$. For each $p$ prime, take $\\tau\\geq 0$ for which $p^{\\tau}\\| 3k$. Define $\\gamma=\\gamma(p)=2\\tau+1$ and $$\\mathcal{M}_{n}^{*}(p^{\\gamma})=\\Big\\{\\mathbf{X}\\in\\mathcal{M}_{n}(p^{\\gamma}):\\ \\ p\\nmid x_{1},\\ \\ p\\nmid (x_{1}^{3}+C_{p_{1}\\mathbf{y}_{1}})\\Big\\}.$$ We take $h\\geq \\gamma$ for convenience. Our priority for the rest of the lemma will be to show that $\\lvert\\mathcal{M}_{n}^{*}(p^{\\gamma})\\rvert>0$, since then an application of Hensel's Lemma will yield the bound $M_{n}(p^{h})\\geq p^{(s+t-1)(h-\\gamma)}.$ \r\n\r\nFor further discussion, it is convenient to consider for a fixed number $C\\in\\mathbb{N}$ the sets $$\\mathcal{T}_{C}(p^{\\gamma})=\\Big\\{x^{3}+C\\pmod{p^{\\gamma}}\\Big\\},\\ \\  \\mathcal{T}_{C}^{*}(p^{\\gamma})=\\Big\\{x^{3}+C\\pmod{p^{\\gamma}}:\\ p\\nmid x,\\ \\ p\\nmid (x^{3}+C)\\Big\\}.$$ Let $p\\equiv 1\\pmod{3}.$ Under this condition one has $p\\geq 7$, so $\\gamma=1$ with $\\lvert\\mathcal{T}_{C}(p)\\rvert=(p+2)/3$ and $\\lvert\\mathcal{T}_{C}^{*}(p)\\rvert\\geq 1.$ If we denote the set of $k$-th powers of the above set by $$\\mathcal{T}_{C}^{k}(p^{\\gamma})=\\Big\\{y^{k} \\pmod{p^{\\gamma}}:\\ y\\in\\mathcal{T}_{C}(p^{\\gamma})\\Big\\},$$ then one finds that $\\lvert\\mathcal{T}_{C}^{k}(p)\\rvert\\geq \\big\\lceil(p+2)/3k\\big\\rceil.$ One can check that $\\lvert\\mathcal{T}_{C}^{k}(7)\\rvert\\geq 2$ for every $C\\in\\mathbb{N}$, and whenever $p>7$ we find that\r\n$$(s+t-1)\\Big(\\Big\\lceil\\frac{p+2}{3k}\\Big\\rceil-1\\Big)\\geq p,$$\r\nand hence Cauchy-Davenport delivers $\\lvert\\mathcal{M}_{n}^{*}(p)\\lvert>0$. \r\nWhen $p\\equiv 2\\pmod{3}$ and $p>2$ then $\\gamma=1$ and we further get $\\lvert\\mathcal{T}_{C}(p)\\rvert=p$ and $\\lvert\\mathcal{T}_{C}^{*}(p)\\rvert\\geq 1$, whence another application of Cauchy-Davenport yields $\\lvert\\mathcal{M}_{n}^{*}(p)\\rvert>0$. For the case $p=2$ the divisibility contraints reduce the problem to the resolution of\r\n$$y_{1}^{6}+\\dots+y_{8}^{6}\\equiv n\\pmod{8}$$ with $y_{i}\\in\\mathbb{N}$ and $2\\nmid y_{1},$ which is straightforward. The case $k=3$ is also trivial since then one would have $\\gamma(2)=1$. Likewise, if $p=3$ one finds that whenever $C\\equiv 1\\mmod{27}$ then $\\mathcal{T}_{C}^{2}(27)=\\{0,1,4,13,22\\}$ and $\\lvert\\mathcal{T}_{C}^{*}(27)\\rvert=3,$ so $\\lvert\\mathcal{M}_{n}^{*}(27)\\rvert>0$ when $k=2$ follows combining the constraints for $C_{p_{i}\\mathbf{y}_{i}}$ and $C_{\\mathbf{y}_{i}}$ described above and Vaughan \\cite[Lemma 2.14]{Vau}. Finally, when $k=3$ we make use of the conditions $ C_{\\mathbf{y}_{i}}\\equiv 0\\mmod{81}$ and $C_{p_{i}\\mathbf{y}_{i}}\\equiv 0\\mmod{81}$ to reduce the problem to finding a solution for\r\n$$y_{1}^{9}+\\ldots+y_{17}^{9}\\equiv n\\mmod{243}$$ with $y_{i}\\in\\mathbb{N}$ and $3\\nmid y_{1}$. The solubility of this congruence is again a consequence of Vaughan \\cite[Lemma 2.14]{Vau}. \r\n\\end{proof}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\\section{Singular integral}\\label{sec5}\r\nIn this section we analyse the size of the singular integral following the classical approach making use of Fourier's Integral Theorem. For each pair of tuples $(\\mathbf{Y},\\mathbf{p})$ consider \\begin{equation*}\\label{Jnn}J_{\\mathbf{Y},\\mathbf{p}}(n)=\\int_{-\\infty}^{\\infty}V_{\\mathbf{Y},\\mathbf{p}}(\\beta)e(-n\\beta)d\\beta,\\ \\ \\ \\ \\text{where}\\ \\ \\ \\\\ V_{\\mathbf{Y},\\mathbf{p}}(\\beta)=\\prod_{i=1}^{t}v_{\\mathbf{y}_{i},p_{i}}(\\beta)\\prod_{i=t+1}^{s+t}v_{\\mathbf{y}_{i}}(\\beta),\\end{equation*} and $v_{\\mathbf{y_{i}},p_{i}}(\\beta)$ and $v_{\\mathbf{y}_{i}}(\\beta)$ were defined in (\\ref{esp}).\r\n\\begin{lem}\\label{lemi}\r\nOne has that $0\\leq J_{\\mathbf{Y},\\mathbf{p}}(n)\\ll P^{s}H^{t/3}n^{-1}$. Moreover, whenever $(\\mathbf{Y},\\mathbf{p})$ satisfies $M/2\\leq p_{i}\\leq 51 M/100$ for $1\\leq i\\leq t$ and $\\mathbf{y}_{i}\\leq P/2$ for $t+1\\leq i\\leq s+t$ then \r\n\\begin{equation}\\label{jn}J_{\\mathbf{Y},\\mathbf{p}}(n)\\gg P^{s}H^{t/3}n^{-1}.\\end{equation}\r\n\\end{lem}\r\nIn the following discussion we rewrite $J_{\\mathbf{Y},\\mathbf{p}}(n)$ as an integral whose size is easier to estimate. The conditions on the tuples described before ensure that we get a suitable range of integration for such integral. Note that the set of tuples on that range has positive density over the set of tuples without the restrictions, and hence we are still able to get the expected lower bound for the major arc contribution.\r\n\\begin{proof}\r\nBy using the expression of both $v_{\\mathbf{y}}(\\beta)$ and $v_{\\mathbf{y},p}(\\beta)$ in (\\ref{vyp}) we find that\r\n$$J_{\\mathbf{Y},\\mathbf{p}}(n)=\\lim_{\\lambda\\rightarrow\\infty}\\int_{-\\lambda}^{\\lambda}\\int_{\\mathbf{x}\\in\\mathcal{S}}B_{\\mathbf{Y},\\mathbf{p}}(\\mathbf{x})e\\Big(\\beta\\Big(\\sum_{i=1}^{s+t}x_{i}-n\\Big)\\Big)d\\mathbf{x}d\\beta,$$\r\nwhere the function $B_{\\mathbf{Y},\\mathbf{p}}(\\mathbf{x})$ is taken to be $$B_{\\mathbf{Y},\\mathbf{p}}(\\mathbf{x})=\\prod_{i=1}^{t}B_{\\mathbf{y}_{i},p_{i}}(x_{i})\\prod_{i=t+1}^{s+t}B_{\\mathbf{y}_{i}}(x_{i})$$ and we integrate over the set $\\mathcal{S}=\\prod [M_{\\mathbf{y}_{i},\\mathbf{p}_{i}},N_{\\mathbf{y}_{i},\\mathbf{p}_{i}}]\\times \\prod[M_{\\mathbf{y}_{i}},N_{\\mathbf{y}_{i}}]$.\r\nThen by integrating on $\\beta$ and making the change of variables $v=\\sum_{i=1}^{s+t}x_{i}$ we obtain\r\n$$J_{\\mathbf{Y},\\mathbf{p}}(n)=\\lim_{\\lambda\\rightarrow\\infty}\\int_{S_{1}}^{S_{2}}\\phi(v)\\frac{\\sin\\big(2\\pi\\lambda(v-n)\\big)}{\\pi(v-n)}dv,$$\r\nwhere $\\phi(v)$ is defined as $$\\phi(v)=\\int_{\\mathbf{x}\\in\\mathcal{S}'(v)}B_{\\mathbf{y}_{s+t}}\\Big(v-\\sum_{i=1}^{s+t-1}x_{i}\\Big)\\prod_{i=1}^{t}B_{\\mathbf{y}_{i},p_{i}}(x_{i})\\prod_{i=t+1}^{s+t-1}B_{\\mathbf{y}_{i}}(x_{i})d\\mathbf{x}$$ and $\\mathcal{S}'(v)\\subset \\mathbb{R}^{s+t-1}$ denotes the subset of tuples satisfying $$x_{i}\\in [M_{\\mathbf{y}_{i},p_{i}}, N_{\\mathbf{y}_{i},p_{i}}]\\ \\ \\ \\ \\text{for $1\\leq i\\leq t$,} \\ \\ \\ \\ \\ x_{i}\\in [M_{\\mathbf{y}_{i}},N_{\\mathbf{y}_{i}}]\\ \\ \\ \\ \\text{for $t+1\\leq i\\leq s+t-1$},$$ and \r\n\\begin{equation}\\label{MNMN}M_{\\mathbf{y}_{s+t}}\\leq v-\\sum_{i=1}^{s+t-1}x_{i}\\leq N_{\\mathbf{y}_{s+t}}.\\end{equation}\r\nSince $\\phi(v)$ is a function of bounded variation, it follows from Fourier's Integral Theorem that\r\n$J_{\\mathbf{Y},\\mathbf{p}}(n)=\\phi(n)$, which implies positivity. Note that combining the identity $P^{3}=M^{3}H$, which is a consequence of (\\ref{MH}), the limits of integration defined after (\\ref{vyp}) and equation (\\ref{fun}), we find that whenever $\\mathbf{x}\\in\\mathcal{S}'(n)$ then it follows that $B_{\\mathbf{y}_{i},p_{i}}(x_{i})\\asymp H^{1/3}n^{-1}$ for $1\\leq i\\leq t$ and $B_{\\mathbf{y}_{i}}(x_{i})\\asymp Pn^{-1}$ for $t+1\\leq i\\leq s+t-1$, and one further has\r\n$$B_{\\mathbf{y}_{s+t}}(n-\\sum_{i=1}^{s+t-1}x_{i})\\asymp Pn^{-1}.$$\r\nTherefore, combining the previous ideas we obtain the upper bound for $J_{\\mathbf{Y},\\mathbf{p}}(n)$ stated at the beginning of the lemma. Moreover, if $(\\mathbf{Y},\\mathbf{p})$ lies in the range described right after that bound, then there exist intervals $I_{i}\\subset [M_{\\mathbf{y}_{i},p_{i}}, N_{\\mathbf{y}_{i},p_{i}}]$ for $1\\leq i\\leq t$ and $I_{i}\\subset [M_{\\mathbf{y}_{i}},N_{\\mathbf{y}_{i}}]$ for $t+1\\leq i\\leq s+t-1$ satisfying $|I_{i}|\\asymp n$ and with the property that whenever $x_{i}\\in I_{i}$ then (\\ref{MNMN}) holds for $v=n$. Consequently, the preceding discussion yields (\\ref{jn}).\r\n\\end{proof}\r\nFor the sake of brevity we define the auxiliary functions $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$ by putting\r\n\\begin{equation*}\\label{ec6.2}h^{*}(\\alpha)=V(\\alpha,q,a)\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ W^{*}(\\alpha)=W(\\alpha,q,a) \\end{equation*} when $\\alpha\\in\\grM(a,q)\\subset\\grM$ and $h^{*}(\\alpha)=W^{*}(\\alpha)=0$ for $\\alpha\\in\\grm.$ Here the reader may want to recall (\\ref{ggg}) and (\\ref{Wa}). For the rest of the section we present some bounds for these functions.\r\n\\begin{lem}\\label{lema4}\r\nLet $\\beta\\in\\mathbb{R}.$ For every prime $p$ and $\\mathbf{y}\\in \\mathbb{N}^{2}$ one has\r\n$$v_{\\mathbf{y}}(\\beta)\\ll \\frac{P}{1+n\\lvert \\beta\\rvert}\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ v_{\\mathbf{y},p}(\\beta)\\ll \\frac{H^{1/3}}{1+n\\lvert \\beta\\rvert}.$$Moreover, whenever $\\alpha\\in \\grM(a,q)\\subset \\grM$ one finds that\r\n\\begin{equation*}h^{*}(\\alpha)\\ll \\frac{q^{\\varepsilon}w_{k}(q)P^{3}}{1+n\\lvert\\alpha-a/q\\rvert}\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ W^{*}(\\alpha)\\ll \\frac{q^{\\varepsilon}w_{k}(q)MH}{(1+n\\lvert\\alpha-a/q\\rvert)(\\log P)}.\\end{equation*}\r\n\\end{lem}\r\n\\begin{proof}\r\nWhen $\\lvert \\beta\\rvert\\leq n^{-1}$, the bound for $v_{\\mathbf{y}}(\\beta)$ follows observing that by (\\ref{vyp}) and the limits of integration taken after (\\ref{vyp}) then\r\n$$v_{\\mathbf{y}}(\\beta)\\ll \\int_{M_{\\mathbf{y}}}^{ N_{\\mathbf{y}}}y^{1/k-1}\\big(y^{1/k}-C_{\\mathbf{y}}\\big)^{-2/3}dy\\ll P.$$ For the case $\\lvert \\beta\\rvert> n^{-1},$ using the fact that $B_{\\mathbf{y}}(y)$ is decreasing and integrating by parts we have that\r\n$$v_{\\mathbf{y}}(\\beta)\\ll \\lvert\\beta\\rvert^{-1}B_{\\mathbf{y}}(M_{\\mathbf{y}})\\ll \\lvert\\beta\\rvert^{-1}n^{1/3k-1},$$which proves the statement. The case $v_{\\mathbf{y},p}(\\beta)$ is done in a similar way and follows after applying the identity $P^{3}=M^{3}H,$ which is a consequence of (\\ref{MH}). Combining these estimates and Lemma \\ref{lema5} we get the bounds for $h^{*}(\\alpha)$ and $W^{*}(\\alpha)$.\r\n\\end{proof}\r\n\\section{Major arc contribution}\\label{sec6}\r\nIn this section we show that the contribution of the set of narrow arcs $\\grN$ is asymptotic to the expected main term. We prove then that the contribution of the remaining arcs is smaller by combining major and minor arc techniques and making use of Lemma \\ref{lema1}. \r\n\\begin{prop}\\label{prop2}\r\nThere exists $\\delta>0$ such that\r\n\\begin{equation*}\\label{Wh}\\int_{\\grM}h(\\alpha)^{s}W(\\alpha)^{t}e(-\\alpha n)\\alpha=\\sum_{\\mathbf{Y},\\mathbf{p}}\\mathfrak{S}_{\\mathbf{Y},\\mathbf{p}}(n)J_{\\mathbf{Y},\\mathbf{p}}(n)+O(H^{t}M^{t}P^{3s-3k-\\delta}).\\end{equation*}\r\n\\end{prop}\r\n\\begin{proof}\r\nWe note first that the triangle inequality yields\r\n$$h(\\alpha)^{s}-h^{*}(\\alpha)^{s}\\ll \\lvert h(\\alpha)-h^{*}(\\alpha)\\rvert\\big(\\lvert h^{*}(\\alpha)\\rvert^{s-1}+\\lvert h(\\alpha)-h^{*}(\\alpha)\\rvert^{s-1}\\big).$$\r\nObserve that by (\\ref{MH}) and the definition (\\ref{kioto}) then whenever $\\alpha\\in\\grN(a,q)$ one has that $(1+n\\lvert\\beta\\rvert)^{-1}\\geq qH^{-1/3}\\geq qP^{-1}$ and $\\lvert\\beta\\rvert\\leq (6kq)^{-1}H^{1/3}n^{-1}\\leq (2\\cdot 3^{k}kq)^{-1}Pn^{-1}$ for $n$ sufficiently large. Consequently, Lemma \\ref{lema2} applied to $\\lvert h(\\alpha)-h^{*}(\\alpha)\\rvert$ and Lemma \\ref{lema4} applied to $\\lvert h^{*}(\\alpha)\\rvert$ in the above equation deliver\r\n\\begin{equation}\\label{ech}\r\nh(\\alpha)^{s}-h^{*}(\\alpha)^{s}\\ll q^{1+\\varepsilon}w_{k}(q)^{s}P^{3s-1}(1+n\\lvert\\beta\\rvert)^{-s+1},\r\n\\end{equation}and by the same reason then whenever $\\alpha\\in\\grN(a,q)$ with $(p,q)=1$ for all primes $M/2\\leq p\\leq M$, Lemma \\ref{lema3} gives\r\n\\begin{equation}\\label{Wal}\r\nW(\\alpha)^{t}-W^{*}(\\alpha)^{t}\\ll M^{t}H^{t-1/3}q^{1+\\varepsilon}w_{k}(q)^{t}(1+n\\lvert\\beta\\rvert)^{-t+1}.\r\n\\end{equation}\r\nWe also need a bound on the following quantity to exploit some orthogonality relation when averaging over $q$. Denote by $N(q,P)$ the number of solutions of the congruence \r\n$$T(p_{1}\\mathbf{x}_{1})^{k}+T(p_{2}\\mathbf{x}_{2})^{k}\\equiv T(p_{3}\\mathbf{x}_{3})^{k}+T(p_{4}\\mathbf{x}_{4})^{k}\\pmod {q},$$ where $\\mathbf{x}_{i}\\in [1,H^{1/3}]^{3}$ and $M/2\\leq p_{i}\\leq M$ with $q\\in\\mathbb{N}$. By expressing $q$ as the product of prime powers, using the structure of the ring of integers of these prime powers and noting that the number of primes dividing $q$ is $O\\big((\\log q)/\\log\\log q\\big)$ we obtain\r\n\\begin{equation}\\label{NqP}N(q,P)\\ll q^{\\varepsilon}(MH)^{4}(\\log P)^{-4}\\big(q^{-1}+P^{-1}\\big),\\end{equation}where we also used the identity $P=MH^{1/3}$, and hence by orthogonality it follows that\r\n\\begin{equation}\\label{Wsa}\\sum_{a=1}^{q}\\lvert W(\\beta+a/q)\\rvert^{4}\\leq qN(q,P)\\ll q^{1+\\varepsilon}(MH)^{4}(\\log P)^{-4}\\big(q^{-1}+P^{-1}\\big).\\end{equation} Combining (\\ref{ech}) and (\\ref{Wsa}) one has that\r\n\\begin{align*}\\int_{\\grN}\\Big\\lvert h(\\alpha)^{s}-h^{*}(\\alpha)^{s}\\Big\\rvert \\lvert W(\\alpha)\\rvert^{t}d \\alpha&\r\n\\ll (HM)^{t}P^{3s-3k-1}\\sum_{q\\leq H^{1/3}}q^{1+\\varepsilon}w_{k}(q)^{s}\r\n\\\\\r\n&\\ll (HM)^{t}P^{3s-3k-\\delta},\r\n\\end{align*}\r\nwhere we used (\\ref{MH}) and Lemma \\ref{expo}. Before introducing the auxiliary function $W^{*}(\\alpha)$ to replace $W(\\alpha)$ we must ensure that the contribution of the arcs with $M/4<q\\leq (6k)^{-1}H^{1/3}$ is small enough. By doing so we avoid having to approximate $W(\\alpha)$ for the cases when $p\\mid q$ for primes $p$ appearing in the definition (\\ref{Weig}) of $W(\\alpha)$. Combining Lemma \\ref{lema4} with (\\ref{Wsa}) one finds that \\begin{align*}\\sum_{M/4<q\\leq (6k)^{-1}H^{1/3}}&\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\int_{0}^{1}\\lvert h^{*}(\\beta+a/q)\\rvert^{s}\\big\\lvert W(\\beta+a/q)\\big\\rvert^{t}d \\beta\\nonumber\r\n\\\\\r\n\\ll &(HM)^{t}P^{3s-3k+\\varepsilon}\\sum_{M/4<q\\leq (6k)^{-1}H^{1/3}}w_{k}(q)^{s}\\ll (HM)^{t}P^{3s-3k-\\delta},\r\n\\end{align*}\r\nwhere in the last step we applied the definition (\\ref{wuok}). For the range $q\\leq M/4$ we always have $(p,q)=1$ for all primes $M/2\\leq p\\leq M$, so we can use (\\ref{Wal}) and Lemma \\ref{lema4} to obtain\r\n\\begin{align*}\\sum_{q\\leq M/4}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}&\r\n\\int_{\\grN(a,q)}\\lvert h^{*}(\\alpha)\\rvert^{s}\\Big\\lvert W(\\alpha)^{t}-W^{*}(\\alpha)^{t}\\Big\\rvert d \\alpha\r\n\\\\\r\n&\\ll P^{3s-3k}M^{t}H^{t-1/3}\\sum_{q\\leq M/4}q^{2+\\varepsilon}w_{k}(q)^{s+t}\\ll (HM)^{t}P^{3s-3k-\\delta},\r\n\\end{align*} where in the last line we used (\\ref{MH}) and applied Lemma \\ref{expo}.\r\nBy Lemmata \\ref{expo} and \\ref{lema4} one has that\r\n\\begin{align*}\r\n\\sum_{q\\leq M/4}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}&\r\n\\int_{\\lvert\\alpha-a/q\\rvert>(6kq)^{-1}H^{1/3}n^{-1}}\\lvert h^{*}(\\alpha)\\rvert^{s}\\lvert W^{*}(\\alpha)\\rvert^{t}d\\alpha\r\n\\\\\r\n&\\ll H^{2t/3-s/3+1/3}M^{t}P^{3s-3k}\\sum_{q\\leq M/4}q^{s+t+\\varepsilon}w_{k}(q)^{s+t}\\ll (HM)^{t}P^{3s-3k-\\delta}.\r\n\\end{align*}\r\nTherefore, using the previous bounds, making a change of variables and combining Lemmata \\ref{lema5} and \\ref{lema4} it follows that\r\n\\begin{align}\\label{hWW}\\int_{\\grN} h(\\alpha)^{s} W(\\alpha)^{t}e(-\\alpha n)d\\alpha=\\sum_{\\mathbf{Y},\\mathbf{p}}\\frak{S}_{\\mathbf{Y},\\mathbf{p}}(n)J_{\\mathbf{Y},\\mathbf{p}}(n)+O\\big((HM)^{t}P^{3s-3k-\\delta}\\big).\r\n\\end{align} \r\n\r\nThe rest of the section is devoted to ensure that the contribution of the remaining major arcs is smaller than the main term in the previous equation. Let $R(q,P)$ be the number of solutions of the congruence \r\n$$T(\\mathbf{x}_{1})^{k}+T(\\mathbf{x}_{2})^{k}\\equiv T(\\mathbf{x}_{3})^{k}+T(\\mathbf{x}_{4})^{k}\\pmod {q},$$ where $\\mathbf{x}_{i}\\in [1,P]^{3}$. Applying the same argument we used in (\\ref{NqP}) for bounding $N(q,P)$ we find that\r\n$R(q,P)\\ll q^{\\varepsilon}P^{12}\\max(q^{-1},P^{-1}),$ and hence by orthogonality it follows that \\begin{equation}\\label{Wint}\\sum_{a=1}^{q}\\lvert h(\\beta+a/q)\\rvert^{4}\\leq qR(q,P)\\ll q^{1+\\varepsilon}P^{12}\\max(q^{-1},P^{-1}).\\end{equation} \r\nMoreover, observe that by a similar argument for the case $k=2$ we get\r\n\\begin{equation}\\label{squa}\\sum_{a=1}^{q}\\lvert h(\\beta+a/q)\\rvert^{2}\\ll q^{1+\\varepsilon}P^{6}\\max(q^{-1},P^{-1}).\\end{equation}\r\n\r\nWe consider for convenience the mean value $$I_{M}=\\int_{\\grM\\setminus\\grN}\\lvert h(\\alpha)\\rvert^{s}\\big\\lvert W(\\alpha)\\big\\rvert^{t}d \\alpha.$$Our strategy for the treatment of this integral will be to bound $W(\\alpha)$ pointwise via Lemma \\ref{lema1} and use some major arc estimates. For such purposes, we define first $\\Upsilon(\\alpha)$ for $\\alpha\\in [0,1)$ by taking\r\n$$\\Upsilon(\\alpha)=\\tau_{k}(q)(1+n\\lvert\\alpha-a/q\\lvert)^{-1}$$ when $\\alpha\\in\\grM(a,q)\\subset\\grM$ and $\\Upsilon(\\alpha)=0$ otherwise. When $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ satisfy $0\\leq a\\leq q\\leq M^{k}$ and $(a,q)=1$, consider the set of arcs\r\n\\begin{equation}\\label{kiotos}\\grM'(a,q)=\\Big\\{ \\alpha\\in [0,1): \\Big\\lvert \\alpha-a/q\\Big\\rvert \\leq \\frac{M}{q^{1/k}n}\\Big\\}\\end{equation}and take $\\grM'$ to be the union of such arcs. Note that then one has $\\grM'\\subset \\grM.$ Observe that for $\\alpha\\in \\grM\\setminus\\grM',$ the bound in the right handside of (\\ref{boundW}) corresponding to the diagonal contribution dominates over the one corresponding to the non-diagonal contribution. Therefore, we can apply the same argument that we applied in Proposition \\ref{prop1} to estimate the integral over this set. When $\\alpha\\in\\grM'$ then it is the bound corresponding to the non-diagonal term the one which dominates. Let $I'_{M}$ be the contribution of $\\grM'\\setminus\\grN$ to the integral $I_{M}$. By making use of Lemma \\ref{lema1} and (\\ref{Up}) we obtain that\r\n$$I_{M}'\\ll H^{t+t/24-\\delta}M^{t}\\int_{\\grM'\\setminus\\grN}\\lvert h(\\alpha)\\rvert^{s}\\Upsilon(\\alpha)^{t/2}d\\alpha\\ll H^{t+t/24-\\delta}M^{t}(I_{1}+I_{2}),$$where \r\n$$I_{i}=\\int_{\\grM'\\setminus\\grN}\\lvert h(\\alpha)\\rvert^{s-2}G_{i}(\\alpha)\\Upsilon(\\alpha)^{t/2}d\\alpha,\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ i=1,2$$ with $G_{1}(\\alpha)=\\lvert h^{*}(\\alpha)\\rvert^{2}$ and $G_{2}(\\alpha)=\\lvert h(\\alpha)-h^{*}(\\alpha)\\rvert^{2}.$ In view of the definitions (\\ref{kioto}) and (\\ref{kiotos}) for $\\grN$ and $\\grM'$ respectively, we make a distinction between the ranges $q\\leq (6k)^{-1}H^{1/3}$ and $(6k)^{-1}H^{1/3}<q\\leq M^{k}$. We also combine Lemmata \\ref{expo} and \\ref{lema4} with equations (\\ref{Wint}) and (\\ref{squa}) and the bound (\\ref{tauk}) to obtain\r\n\\begin{align*}I_{1}\\ll &\r\n P^{3s-3k}H^{-t/6-1/3}\\sum_{q\\leq (6k)^{-1}H^{1/3}}w_{k}(q)^{2}q^{t/2+1-t/2k+\\varepsilon}\r\n\\\\\r\n&+P^{3s-3k}\\sum_{(6k)^{-1}H^{1/3}<q\\leq M^{k}}w_{k}(q)^{2}q^{1-t/2k+\\varepsilon}\\big(q^{-1}+P^{-1}\\big)\\ll P^{3s-3k+\\varepsilon}H^{-t/6k}.\\end{align*} Likewise, combining equations (\\ref{Wint}) and (\\ref{squa}) with Lemmata \\ref{lema2} and \\ref{expo} one finds that\r\n\\begin{align*}I_{2}\\ll& P^{3s-3k-2+\\varepsilon}H^{-t/6+2/3}\\sum_{q\\leq (6k)^{-1}H^{1/3}}q^{t/2-t/2k}w_{k}(q)^{2}\r\n\\\\\r\n&+P^{3s-3k-2+\\varepsilon}\\sum_{(6k)^{-1}H^{1/3}<q\\leq M^{k}}w_{k}(q)^{2}q^{3-t/2k}\\big(q^{-1}+P^{-1}\\big)\\ll P^{3s-3k+\\varepsilon}H^{-t/6k},\\end{align*}where we made use of (\\ref{MH}). Therefore we obtain that $I'_{M}=O\\big((HM)^{t}P^{3s-3k-\\delta}\\big),$ whence the result of the proposition follows combining (\\ref{hWW}) with the previous estimates. \r\n\\end{proof}\r\n\\emph{Proof of Theorem \\ref{thm1.1} when $k=2,3$}. Note first that Lemma \\ref{lemi} ensures positivity for $J_{\\mathbf{Y},\\mathbf{p}}(n)$ and guarantees that for $(\\mathbf{Y},\\mathbf{p})$ in the range described in the lemma then $J_{\\mathbf{Y},\\mathbf{p}}(n)\\gg P^{s}H^{t/3}n^{-1}$. Similarly, Lemma \\ref{lema6}  ensures the positivity of $\\mathfrak{S}_{\\mathbf{Y},\\mathbf{p}}(n)$ and implies that for $(\\mathbf{Y},\\mathbf{p})$ satisfying the local conditions described after (\\ref{Sin}) then $\\mathfrak{S}_{\\mathbf{Y},\\mathbf{p}}(n)\\gg 1$. As observed at the beginning of the lemmas, the intersection of the sets of pairs $(\\mathbf{Y},\\mathbf{p})$ satisfying those conditions has positive density. Therefore, we find that $$\\sum_{\\mathbf{Y},\\mathbf{p}}\\mathfrak{S}_{\\mathbf{Y},\\mathbf{p}}(n)J_{\\mathbf{Y},\\mathbf{p}}(n)\\gg (HM)^{t}P^{3s-3k}(\\log P)^{-t}.$$ Propositions \\ref{prop1} and \\ref{prop2} then yield the bound $R(n)\\gg (HM)^{t}P^{3s-3k}(\\log P)^{-t},$ which proves the theorem for $k=2,3$.\r\n\r\n\\section{The case $k=4$.}\\label{sec7}\r\nIn this section we discuss the proof of the theorem for fourth powers. For such purpose, it is convenient to introduce the exponential sum\r\n$$f(\\alpha)=\\sum_{x\\in \\mathcal{A}(P,P^{\\eta})}e(x^{12}).$$\r\nLet $R_{4}(n)$ be the number of solutions of the equation\r\n$$n=\\sum_{i=1}^{11}T(p_{i}\\mathbf{x}_{i})^{4}+81\\big(y_{1}^{12}+\\dots+y_{46}^{12}\\big),$$ where $\\mathbf{x}_{i}\\in \\mathcal{W}$ with $M/2\\leq p_{i}\\leq M$ for $1\\leq i\\leq 11$ and $y_{i}\\in\\mathcal{A}(P,P^{\\eta})$ for $1\\leq i\\leq 46$. Observe that the sums of three cubes on the right handside have been replaced by the specialization $3y^{3}$. Note as well that orthogonality yields the identity $$R_{4}(n)=\\int_{0}^{1}W(\\alpha)^{11}f(81\\alpha)^{46}e(-\\alpha n)d\\alpha.$$\r\nOur goal throughout the section is to obtain a lower bound for $R_{4}(n)$ for all sufficiently large $n$. Recalling (\\ref{MH}) and (\\ref{Wu}) and using the table of permissible exponents for $k=12$ in Vaughan and Wooley \\cite{VauWoo2} we find that\r\n\\begin{align}\\label{wf}\\int_{\\grm}\\lvert W(\\alpha)\\rvert^{11}\\lvert f(81\\alpha)\\rvert^{46}d\\alpha&\r\n \\ll H^{11+11/24-\\delta}M^{11/2}\\int_{0}^{1}\\lvert f(\\alpha)\\rvert^{46}d\\alpha\\nonumber\r\n\\\\\r\n&\\ll (HM)^{11}P^{34+\\Delta_{23}-1/2-\\delta},\\end{align}where $\\Delta_{23}=0.4988383,$ and hence it follows that the minor arc contribution is then $O\\big((HM)^{11}P^{34-\\delta}\\big).$ \r\n\r\nWe define a set of narrow major arcs $\\grP$ by taking the union of\r\n\\begin{equation*}\\grP(a,q)=\\Big\\{ \\alpha\\in [0,1): \\Big\\lvert \\alpha-a/q\\Big\\rvert \\leq \\frac{R}{n}\\Big\\}\\end{equation*} with $0\\leq a\\leq q\\leq R$ and $(a,q)=1$, where $R=(\\log P)^{1/5}$, and consider $\\mathfrak{p}=[0,1)\\setminus \\grP$. In the next few lines we will combine all sort of major and minor arc techniques to prune back to the set of narrow arcs $\\grP.$ As observed after (\\ref{kiotos}), whenever $\\alpha\\in \\grM\\setminus\\grM'$ then the bound in the right handside of (\\ref{boundW}) corresponding to the diagonal contribution dominates over the one corresponding to the non-diagonal contribution. Therefore, we can apply the same argument that we applied in (\\ref{wf}) to obtain that the integral over that set is $O\\big((HM)^{11}P^{34-\\delta}\\big).$ \r\n\r\nWe next note for further purposes that Theorem 1.8 of Vaughan \\cite{Vau3} yields\r\n\\begin{equation}\\label{f81}\\sup_{\\grn}\\lvert f(81\\alpha)\\rvert\\ll P^{1-\\rho+\\varepsilon},\\end{equation} where $\\rho=0.004259.$ As experts will realise, one could obtain a slightly bigger $\\rho$ by applying the methods in \\cite{Woo}. For the sake of brevity though, we avoid that treatment and make use of the weaker version of the estimate. We also remark that such improvement in the exponent would make no impact in the argument. Observe that using the same procedure as in (\\ref{Wsa}) and (\\ref{Wint}) we deduce that\r\n\\begin{equation}\\label{fev}\\sum_{a=1}^{q}\\lvert f\\big(81(\\beta+a/q)\\big)\\rvert^{12}\\ll q^{1+\\varepsilon}P^{12}\\max(q^{-1}+P^{-1}).\\end{equation}\r\nNote as well that whenever $\\alpha\\in \\grM'\\setminus \\grN$ then $(1+n\\lvert\\beta\\rvert)^{3/2}\\geq H^{1/3}q^{-1}$, and hence Lemmata \\ref{lema3} and \\ref{lema4} yield $W(\\alpha)\\ll MH^{2/3}q^{1+\\varepsilon}w_{4}(q)(1+n\\lvert\\beta\\rvert)^{1/2}.$ By the preceding discussion together with Lemma \\ref{lema1} and equations (\\ref{f81}) and (\\ref{fev}) we obtain\r\n\\begin{align*}\\int_{\\grM'/\\grN}\\lvert W(\\alpha)\\rvert^{11}\\lvert f(81\\alpha)\\rvert^{46}d\\alpha\\ll (HM)^{11}P^{34(1-\\rho)}\\sum_{q\\leq M^{4}}q^{2}\\tau_{4}(q)^{4}w_{4}(q)(q^{-1}+P^{-1}).\r\n\\end{align*}\r\n\r\nHere the reader may find useful to observe that we applied the estimate (\\ref{boundW}) to eight copies of $W(\\alpha)$ and the bound for $W(\\alpha)$ deduced above to just one of them. Likewise, we made use of the pointwise estimate (\\ref{f81}) to bound $34$ copies of $f(81\\alpha)$ and we used the other $12$ to exploit the congruence condition via (\\ref{fev}). We get that the above sum when $q\\leq P$ is $O\\big((HM)^{11}P^{34-\\delta}\\big)$ via Lemma \\ref{expo}. Similarly, we use Lemma \\ref{expo} and the bound $qP^{-1}\\leq P^{1/11}$, which follows after (\\ref{MH}), for the range $P\\leq q\\leq M^{4}$ to obtain that such contribution is also $O\\big((HM)^{11}P^{34-\\delta}\\big)$. By the observation made before (\\ref{ech}), which is still valid for $k=4$, and Lemma \\ref{lema3} we find that whenever $\\alpha\\in\\grN$ then\r\n$$W(\\alpha)\\ll \\frac{q^{\\varepsilon}w_{4}(q)HM}{(1+n\\lvert\\beta\\rvert)(\\log P)}.$$ Therefore, the application of this bound and (\\ref{Wsa}) yield\r\n\\begin{align*}\\int_{\\grN/\\grP}\\lvert W(\\alpha)\\rvert^{11}\\lvert f(81\\alpha)\\rvert^{46}d\\alpha\\ll&\r\n (HM)^{11}P^{34}(\\log P)^{-11}R^{-6}\\sum_{q\\leq R}q^{\\varepsilon}w_{4}(q)^{7}\r\n\\\\\r\n&+(HM)^{11}P^{34}(\\log P)^{-11}\\sum_{q>R}q^{\\varepsilon}w_{4}(q)^{7}.\r\n\\end{align*}Consequently, Lemma \\ref{expo} and (\\ref{wuok}) imply that such integral is $O\\big((HM)^{11}P^{34}(\\log P)^{-11-\\delta}\\big)$.\r\n\r\nIn what follows, we will briefly describe the singular series associated to the problem. There might be other approaches that would lead to more precise asymptotic formulae, but for the sake of simplicity we avoid including the sums of three cubes in the singular series. On recalling (\\ref{Saq}), it is convenient to consider, for an integer $m\\in\\mathbb{N}$ and a prime $p$ the sums\r\n$$S_{m}(q)=q^{-46}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}S_{12}(q,81a)^{46}e_{q}\\big(-a(n-m)\\big), \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sigma_{m}(p)=\\sum_{h=0}^{\\infty}S_{m}(p^{h}).$$ Observe that whenever $3\\nmid q$ then we can make a change of variables to rewrite $S_{m}(q)$ as \r\n$$S_{m}(q)=q^{-46}\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}S_{12}(q,a)^{46}e_{q}\\big(-a\\overline{81}^{-1}(n-m)\\big),$$where $\\overline{81}^{-1}$ denotes the inverse of $81\\mmod{q}$. Note as well that Lemma 3 of \\cite{Vau1} yields the bound $S_{m}(q)\\ll q\\tau_{12}(q)^{46}$, which implies that $\\sigma_{m}(p)=1+O(p^{-22})$ and delivers the convergence of the singular series\r\n\\begin{equation}\\label{SM}\\frak{S}_{m}(n)=\\sum_{q=1}^{\\infty}S_{m}(q)\\end{equation} and its upper bound $\\frak{S}_{m}(n)\\ll 1$. Here the reader may find useful to observe that we implicitly used the multiplicativity of $S_{m}(q)$ and the expression of the singular series as the product $$\\frak{S}_{m}(n)=\\prod_{p}\\sigma_{m}(p).$$The estimate for $S_{m}(q)$ mentioned before (\\ref{SM}) also delivers, for $Q\\geq 1$, the bound\r\n\\begin{equation}\\label{ssm}\\sum_{q>Q}\\lvert S_{m}(q)\\rvert\\ll Q^{-\\alpha}\\end{equation} for some $\\alpha>0$ via the ideas employed in the proof of Lemma \\ref{lema5}. Observe that by Lemmata 2.12, 2.13 and 2.15 of \\cite{Vau} one gets for every prime $p\\neq 3$ the lower bound $\\sigma_{m}(p)\\geq p^{-45\\gamma}$, where $\\gamma=3$ when $p=2$ and $\\gamma=1$ otherwise. Likewise, note that when $m\\equiv n\\mmod{81}$ and $h\\geq 5$ orthogonality yields\r\n$$\\sum_{l=0}^{h}S_{m}(3^{l})=3^{-45h}M_{n,m}(3^{h}),$$where $M_{n,m}(3^{h})$ denotes the number of solutions of the congruence\r\n$$x_{1}^{12}+\\dots+x_{46}^{12}\\equiv (n-m)/81\\mmod{3^{h-4}}$$with $1\\leq x_{i}\\leq 3^{h}.$ Therefore, the application of Lemmata 2.13 and 2.15 of \\cite{Vau} gives $\\sigma_{m}(3)\\geq 3^{-86}.$ Consequently, combining these lower bounds with the fact that $\\sigma_{m}(p)-1=O(p^{-22})$ we obtain $\\frak{S}_{m}(n)\\gg 1.$ Observe as well that the preceding discussion yields $\\frak{S}_{m}(n)\\geq 0$ for every $m\\in\\mathbb{N}.$\r\n\r\n Before showing a lower bound of the expected size for the contribution of the set of narrow arcs, we introduce for convenience the weighted exponential sum\r\n$$w(\\beta)=\\sum_{P^{12\\eta}<x\\leq n}\\frac{1}{12}x^{-11/12}\\rho\\Big(\\frac{\\log x}{12\\eta\\log P}\\Big)e(\\beta x),$$\r\nwhere $\\rho$ denotes the Dickman's function, defined for real $x$ by\r\n$$\\rho(x)=0\\text{ when } x<0,$$\r\n$$\\rho(x)=1 \\text{ when } 0\\leq x\\leq 1,$$\r\n$$\\rho \\text{ continuous for } x>0,$$\r\n$$\\rho \\text{ differentiable for } x>1$$\r\n$$x\\rho'(x)=-\\rho(x-1) \\text{ when } x>1.$$For the sake of simplicity, we define the auxiliary function $f^{*}(\\alpha)$ by putting $f^{*}(\\alpha)=q^{-1}S(q,81a)w\\big(81(\\alpha-a/q)\\big)$ when $\\alpha\\in\\grP(a,q)\\subset\\grP$ and $f^{*}(\\alpha)=0$ for $\\alpha\\in\\grp.$ Then, it is a consequence of Vaughan\\footnote{Observe that the condition $(a,q)=1$ in Vaughan \\cite[Lemma 5.4]{Vau3} can be relaxed to $(a,q)=C$ for some constant $C$.} \\cite[Lemma 5.4]{Vau3} that for $\\alpha\\in\\grP(a,q)\\subset\\grP$ one has $f(81\\alpha)-f^{*}(\\alpha)=O\\big(PR^{-3}\\big)$ and $f^{*}(\\alpha)\\ll q^{-1/12}P(1+n\\lvert\\beta\\rvert)^{-1/12}.$ Moreover, by the methods of Vaughan \\cite[Lemma 2.8]{Vau} and the monotonicity of $\\rho$ it follows that\r\n\\begin{equation}\\label{www}w(\\beta)\\ll \\frac{P}{(1+n\\lvert\\beta\\rvert)^{1/12}}.\\end{equation} Finally, when $m\\in\\mathbb{N}$ it is convenient to introduce $K(m)$, defined as the number of solutions of the equation\r\n$$m=T(p_{1}\\mathbf{x}_{1})^{4}+\\dots+T(p_{11}\\mathbf{x}_{11})^{4}$$ for $\\mathbf{x}_{i}\\in\\mathcal{W}$ and $M/2\\leq p_{i}\\leq M.$ Combining the estimates mentioned before (\\ref{www}) we obtain that\r\n\\begin{align*}\\int_{\\grP}W(\\alpha)^{11}f(81\\alpha)^{46}e(-\\alpha n)d\\alpha=&\r\n\\sum_{m\\leq 11n}K(m)\\int_{\\grP}f^{*}(\\alpha)^{46}e\\big(-\\alpha(n-m)\\big)d\\alpha\r\n\\\\\r\n&+O\\big((HM)^{11}P^{34}(\\log P)^{-11-\\delta}\\big).\r\n\\end{align*}Observe that the main term on the right can be written as\r\n\\begin{equation}\\label{main}\\sum_{m\\leq 11n}K(m)\\sum_{q\\leq R}S_{m}(q)\\int_{\\lvert\\beta\\rvert\\leq n^{-1}R}w(81\\beta)^{46}e\\big(-\\beta (n-m)\\big)d\\beta.\\end{equation} By (\\ref{www}) we obtain that the integral on the above expression over the range $\\lvert\\beta\\rvert>n^{-1}R$ is $O(P^{34}(\\log P)^{-\\delta})$. Therefore, an application of this observation and (\\ref{ssm}) gives that the contribution of the set of narrow arcs $\\grP$ is\r\n$$\\sum_{m\\leq 11n}K(m)\\frak{S}_{m}(n)\\int_{0}^{1}w(81\\beta)^{46}e\\big(-\\beta(n-m)\\big)d\\beta+O\\big((HM)^{11}P^{34}(\\log P)^{-11-\\delta}\\big).$$ We further note that whenever $P^{12\\eta}< x\\leq n$ then $$\\rho\\Big(\\frac{\\log x}{12\\eta\\log P}\\Big)\\gg 1,$$ so combining the positivity of $\\frak{S}_{m}(n)$, orthogonality and the lower bound $\\frak{S}_{m}(n)\\gg 1$ when $m\\equiv n\\mmod{81}$ we obtain that (\\ref{main}) is bounded below by $$\\sum_{\\substack{m\\leq 11n/12\\\\ m\\equiv n\\mmod{81}}}K(m)(n-m)^{17/6}.$$One can check via an application of Hensel's Lemma\\footnote{Here the reader may find useful to observe that the set of sums of three cubes modulo $27$ are the residue classes not congruent to $4$ or $5$ modulo $9$.} and Lemma 2.14 of \\cite{Vau} that the set of numbers of the shape $T(p_{1}\\mathbf{x}_{1})^{4}+\\dots+T(p_{11}\\mathbf{x}_{11})^{4}$ with $p_{i},\\mathbf{x}_{i}\\leq 81$ covers all the residue classes modulo $81$. Consequently, by the preceding discussion we find that\r\n$$\\int_{\\grP}W(\\alpha)^{11}f(81\\alpha)^{46}e(-\\alpha n)d\\alpha\\gg (HM)^{11}P^{34}(\\log P)^{-11},$$ which combined with the estimates obtained through the pruning process yields $R_{4}(n)\\gg (HM)^{11}P^{34}(\\log P)^{-11}.$\r\n\\begin{thebibliography}{9}\r\n\\bibitem{Bou1} J. Bourgain, \\emph{On $\\Lambda(p)-$subsets of squares}, Israel J. Math. 67, No. 3 (1989), 291--311.\r\n\\bibitem{Bou} J. Bourgain, \\emph{On the Vinogradov mean value}, Tr. Mat. Inst. Steklova 296 (2017), Analiticheskaya i Kombinatornaya Teoriya Chisel, 36--46.\r\n\\bibitem{Dav} H. Davenport, \\emph{On Waring's problem for fourth powers}, Ann. of Math. (2) 40 (1939), 731--747.\r\n\\bibitem{Hea} D. R. Heath--Brown, \\emph{The circle method and diagonal cubic forms}, Phil. Trans. Roy. Soc. London Ser. A 356, No. 1738 (1998), 673--699.\r\n\\bibitem{Hol1} C. Hooley, \\emph{On Waring's problem}, Acta Math., 157 (1986), 49--97.\r\n\\bibitem{Hol2} C. Hooley, \\emph{On Hypothesis $K^{*}$ in Waring's problem}, Sieve methods, exponential sums and their applications in number theory (Cardiff, 1995), London Math. Soc. Lecture Note Ser., 237, Cambridge University Press, Cambridge 1997, 175--185.\r\n\\bibitem{Hug} K. Hughes, T. D. Wooley, \\emph{Discrete restriction for $(x,x^{3})$ and related topics}, preprint.\r\n\\bibitem{Lin} Y. V. Linnik, \\emph{On the representation of large numbers as sums of seven cubes}, Rec. Math. N. S. 12 (54), (1943), 218--224.\r\n\\bibitem{Mon} H. L. Montgomery, R. C. Vaughan, \\emph{Multiplicative Number Theory: I. Classical Theory}, Cambridge University Press, 2006.\r\n\\bibitem{Pli} J. Pliego, \\emph{On Waring's problem in sums of three cubes}, preprint.\r\n\\bibitem{Sch} W. M.  Schmidt, \\emph{Equations over finite fields. An elementary approach. Lecture Notes in Mathematics}, 536 (1976), Berlin: Springer--Verlag.\r\n\\bibitem{Vau1} R. C. Vaughan, \\emph{On Waring's problem for smaller exponents,} Proc. London Math. Soc. (3) 52 (1986), 445--463.\r\n\\bibitem{Vau3} R. C. Vaughan, \\emph{A new iterative method in Waring's problem}, Acta Math. 162 (1989), 1--71.\r\n\\bibitem{Vau} R. C. Vaughan, \\emph{The Hardy-Littlewood method}, 2nd edition, Cambridge University Press, Cambridge, 1997.\r\n\\bibitem{VauWoo1} R. C. Vaughan, T. D. Wooley, \\emph{Further improvements in Waring's problem. II. Sixth powers}, Duke Math. J. 76, No. 3 (1994), 683--710.\r\n\\bibitem{VauWoo2} R. C. Vaughan, T. D. Wooley, \\emph{Further improvements in Waring's problem. IV. Higher powers}, Acta Arith. 94, No. 3 (2000), 203--285.\r\n\\bibitem{Wei2} A. Weil, \\emph{On some exponential sums}, Proc. Nat. Acad. Sci. U.S.A. 34 (1948), 204--207.\r\n\\bibitem{Woo7} T. D. Wooley, \\emph{Large Improvements in Waring's Problem}, Annals of Math, Second Series, 135, No. 1 (1992), 131--164.\r\n\\bibitem{Woo} T. D. Wooley, \\emph{New estimates for smooth Weyl sums}, J. London Math. Soc. (2) 51, No. 1 (1995), 1--13.\r\n\\bibitem{Woo3} T. D. Wooley, \\emph{Sums of three cubes, II}, Acta Arith. 170, No. 1 (2015), 73--100.\r\n\\bibitem{Woo6} T. D. Wooley, \\emph{On Waring's problem for intermediate powers}, Acta Arith. 176, No. 3 (2016), 241--247.\r\n\r\n\\end{thebibliography}\r\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:02:34", "yymm": "2010", "arxiv_id": "2010.14559", "url": "https://arxiv.org/abs/2010.14559", "source": "arxiv"}}
{"text": "\\documentclass[12pt]{amsart}\n\\usepackage{amsmath}\n\\usepackage{amssymb,latexsym,amsthm,amsfonts,amscd,pgf,enumerate,ragged2e}\n\\usepackage{tikz,amsmath}\n\\usepackage{subcaption}\n\\usepackage{graphicx}\n\\usepackage{float}\n\\usepackage{ragged2e}\n\\usepackage{cite}\n\\usepackage{color}\n\\usetikzlibrary{calc}\n\n\\newcommand{\\vone}{\\vskip 0.5ex}\n\\newcommand{\\vtwo}{\\vskip 1.5ex}\n\\usepackage[pdftex, colorlinks, linkcolor=red,citecolor=green]{hyperref}\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{remark}[theorem]{Remark}\n\\newtheorem{remarks}[theorem]{Remarks}\n\\newtheorem{example}[theorem]{Example}\n\\newtheorem{definition}[theorem]{Definition}\n\\newtheorem{discussion}[theorem]{Discussion}\n\\def\\proof{\\paragraph{Proof.}}\n\\numberwithin{equation}{section}\n\\renewcommand{\\thesection}{\\arabic{section}}\n\n\n\\oddsidemargin -.2in\n\\renewcommand{\\baselinestretch}{0.8}\n\\parindent .4in\n\\topmargin .2in\n\\evensidemargin -.2in\n\\textwidth 6.5in\n\n\n\\def\\K{\\dim_{\\mathbb{K}}}\n\\def\\N{\\mathbb{N}}\n\\def\\FK{\\mathbb{K}}\n\\def\\R{\\mathbb{R}}\n\\def\\C{\\mathbb{C}}\n\\def\\M{\\mathcal{M}}\n\\def\\J{\\mathcal{J}}\n\\def\\kM{\\M_G^{(k)}}\n\\def\\1M{\\M_G^{(1)}}\n\\def\\Q{\\widetilde Q}\n\n%\\newcommand{\\Pp}{\\mbox{$\\mathbb P$}}\n%\\newcommand{\\Cc}{\\mbox{$\\mathbb C$}}\n%\\newcommand{\\Nn}{\\mbox{$\\mathbb N$}}\n%\\newcommand{\\Zz}{\\mbox{$\\mathbb Z$}}\n\\begin{document}\n\n\\baselineskip=15.5pt\n\n\\title[Standard monomials of $1$-skeleton ideals of multigraphs]{Standard monomials of $1$-skeleton ideals of multigraphs}\n\n%\\author[C. Kumar]{Chanchal Kumar}\n\n%\\address{IISER Mohali,\n%Knowledge City, Sector 81, SAS Nagar, Punjab -140 306, India.}\n\n%\\email{chanchal@iisermohali.ac.in}\n\n\\author[A. Roy]{Amit Roy}\n\n\\address{IISER Mohali,\nKnowledge City, Sector 81, SAS Nagar, Punjab -140 306, India.}\n\n\\email{amitroy@iisermohali.ac.in, amitiisermohali493@gmail.com}\n\\subjclass[2010]{05E40, 15B36}\n\n\n\\keywords{Standard monomials, signless Laplace matrix, parking functions.}\n\n\\date{}\n \n\\begin{abstract}\nGiven a graph $G$ on the vertex set $\\{0,1,\\ldots,n\\}$ with root vertex $0$, Postnikov and Shapiro associated a monomial ideal $\\M_G$ in the polynomial ring $R=\\FK[x_1,\\ldots,x_n]$ over a field $\\FK$ such that $\\K(R/\\M_G)=\\det\\widetilde L_G$, where $\\widetilde L_G$ is the truncated Laplace matrix of $G$. Thus the standard monomials of $R/\\M_G$ correspond bijectively to the spanning trees of $G$. Dochtermann introduced the $1$-skeleton ideal $\\M_G^{(1)}$ which satisfies the property that $\\K(R/\\M_G^{(1)})\\ge\\det\\widetilde Q_G$, where $\\widetilde Q_G$ is the truncated signless Laplace matrix of $G$. In this paper, we give one necessary condition for a multigraph $G$ to satisfy $\\K(R/\\M_G^{(1)})=\\det\\widetilde Q_G$. Consequently, we classify all subgraphs of $K_{n+1}^{a,1}$, in particular all simple graphs $G$ such that $\\K(R/\\M_G^{(1)})=\\det\\widetilde Q_G$. Some examples of families of multigraphs $G$ in which $\\K(R/\\M_G^{(1)})=\\det\\widetilde Q_G$ holds, are also given. Thus for such families of $G$, the standard monomials of $R/\\M_G^{(1)}$ are counted (in a weighted fashion) by certain $TU$-subgraphs of $G$. %analogous to the case of $R/\\M_G$.\n\n%\\noindent\n%{\\sc Key words}: Circulant graphs, Edge ideals, Betti numbers, Castelnuovo-Mumford regularity, Cohen-Macaulay, Buchsbaum, Well-covered.\n\n\n\\end{abstract}\n\\maketitle\n\n\\section{Introduction}\n\\label{introduction}\n\nA graph is given by specifying its set of vertices and the set of edges. Let $G$ be a (multi) graph on the vertex set $V=\\{0,1,\\ldots,n\\}=\\{0\\}\\cup[n]$ with root $0$ and the set of edges $E(i,j)=E(j,i)$ between $i,j\\in V$. The adjacency matrix $A(G)=[a_{i,j}]_{0\\le i,j\\le n}$, where $a_{i,j}=a_{j,i}=|E(i,j)|$ for $i\\neq j$, and $a_{i,i}=0$ for all vertex $i$ in $G$. Thus $G$ is assumed to be undirected and loopless. For any nonempty subset $S$ of $[n]=\\{1,2,\\ldots,n\\}$, let $d_S(i)=\\sum_{j\\notin S}a_{i,j}$ for $i\\in S$. In other words $d_S(i)$ is the number of edges incident to the vertex $i$ whose other end points are not in $S$. Thus $d_i=d_{\\{i\\}}(i)$ is the degree of the vertex $i$ in $G$. For a graph $G$, the Laplace matrix $L_G$ and the signless Laplace matrix $Q_G$ are defined as \n\\[\n L_G=D(G)-A(G)\\quad\\text{and}\\quad Q_G=D(G)+A(G),\n\\]\nwhere $D(G)=\\operatorname{diag}[d_0,d_1,\\ldots,d_n]$ is the diagonal matrix of order $n+1$. Let $R=\\FK[x_1,\\ldots,x_n]$ be the polynomial ring in $n$ variables over a field $\\FK$. Given a multigraph $G$ on the vertex set $V$, we consider the monomial ideal\n$\n \\M_G=\\left\\langle m_S=\\prod_{i\\in S}x_i^{d_S(i)}\\mid\\emptyset\\neq S\\subseteq[n]\\right\\rangle\n$\nin $R$, called the $G$-parking function ideal or the graphical parking function ideal \\cite{GH}. More generally, for a directed graph $G$, Postnikov and Shapiro introduced the Artinian monomial ideal $\\M_G$ and studied their combinatorial and homological properties in \\cite{PS}. The standard monomials $\\mathbf{x}^{\\mathbf{a}}=\\prod_{i=1}^nx_i^{a_i}$ of $R/\\M_G$ (i.e., $\\mathbf{x}^{\\mathbf{a}}\\notin\\M_G$) correspond to the $G$-parking functions $\\mathbf{a}=(a_1,\\ldots,a_n)\\in\\N^n$, a natural generalization of the classical parking functions introduced by Konheim and Weiss \\cite{KW}. Moreover, $\\K(R/\\M_G)=\\det\\widetilde L_G$, where $\\widetilde L_G$ is the truncated Laplace matrix obtained from $L_G$ by deleting the row and column corresponding to the vertex $0$. Thus by the Matrix-Tree theorem \\cite[Theorem 5.6.8]{RS}, number of $G$-parking functions equals the number of spanning trees of $G$. For simple graphs Perkinson, Yang and Yu \\cite{PYY} and for multigraphs Gaydarov and Hopkins \\cite{GH} have provided an explicit bijection between the set of spanning trees of $G$ and the set of $G$-parking functions. The ideals $\\M_G$ have connections to `chip firing' \\cite{BaSh} and a discrete Riemann-Roch theory for graphs \\cite{BaNo}. For example, Baker and Norine reinterpreted the $G$-parking functions as  `$q$-reduced divisors' in \\cite{BaNo}, where they proved a Riemann-Roch theorem for graphs analogous to the classical statement for Riemann surfaces. Motivated by certain constructions in `hereditary chip firing' models, Dochtermann \\cite{Do} introduced the notion of $k$-skeleton ideals $\\M_G^{(k)}$ for a simple graph $G$. However, as noted in \\cite{Do} the definitions are easily extended for a multigraph.\n\nFor $0\\le k\\le n-1$, the ideals \n\\[\n \\M_G^{(k)}:=\\left\\langle m_S=\\prod_{i\\in S}x_i^{d_S(i)}\\mid\\emptyset\\neq S\\subseteq[n]\\quad\\text{and}\\quad |S|\\le k+1\\right\\rangle\n\\]\nare by definition subideals of $\\M_G$, where $G$ is a multigraph on the vertex set $\\{0\\}\\cup[n]$. For $k=n-1$, $\\M_G^{(n-1)}=\\M_G$. In this paper we focus on the $1$-skeleton ideal $\\1M$ of an undirected multigraph $G$. Like $\\M_G$, the number of standard monomials of $R/\\1M$ has an analogous determinantal interpretation. Let $a,b\\ge 1$ be integers and $G$ be a multigraph with adjacency matrix $A(G)=[a_{i,j}]_{0\\le i,j\\le n}$ where $a_{0,i}=a$ and $a_{i,j}=b$ for $i,j\\in[n]$; $i\\neq j$. The graph $G$ is called a complete multigraph and is denoted by $K_{n+1}^{a,b}$. Dochtermann showed that for the complete simple graph $G=K_{n+1}:=K_{n+1}^{1,1}$, the equality $\\K(R/\\1M)=\\det\\Q_G$ holds, where $\\Q_G$ is the truncated signless Laplace matrix of $G$ obtained from $Q_G$ by deleting the row and column corresponding to root $0$. Moreover, based on some initial computations, he asked whether it is true that for any simple graph $G$, $\\K(R/\\1M)\\ge\\det\\Q_G$. This question has been answered affirmatively in \\cite{KLR}. In fact, it is shown that for any multigraph $G$, we have  $\\K(R/\\1M)\\ge\\det\\Q_G$; thus providing a lower bound for the number of standard monomials of $R/\\1M$. As mentioned earlier, the graph $K_{n+1}$ attains this lower bound. In this article, we wish to analyze the graphs $G$ for which $\\K(R/\\1M)=\\det\\Q_G$ holds.\n\nSimilar to the truncated Laplace matrix $\\widetilde L_G$, the determinant of $\\widetilde Q_G$ also has a graph-theoretical interpretation as follows. For any graph $G$, a {\\it $TU$-subgraph} is a subgraph of $G$ whose connected components are either trees or unicyclic graphs with odd cycles. We have $\\det\\widetilde Q_G=\\sum_H4^{c(H)}$, where $H$ is a $TU$-subgraph of $G$ with one tree component containing the root and $c(H)$ unicyclic components \\cite{Do}. Let $G$ be a graph such that $\\K(R/\\M_G^{(1)})=\\det\\Q_G$ and $H$ be a $TU$-subgraph of $G$. Then $H$ is associated to a collection of $4^{c(H)}$ standard monomials of $R/\\M_G^{(1)}$. In particular, when $H$ is a spanning tree it is assigned to $4^0=1$ standard monomial of $R/M_G^{(1)}$. Thus the standard monomials of $R/M_G^{(1)}$ are counted (in a weighted fashion) by $TU$-subgraphs of $G$ (see Section \\ref{characterizing subgraphs} for more details). In this article we have characterized all subgraphs of the complete multigraph $K_{n+1}^{a,1}$, in particular all simple graphs $G$ such that $\\K(R/\\M_G^{(1)})=\\det\\Q_G$. Further, examples of some families of multigraphs $G$ in which the equality $\\K(R/\\M_G^{(1)})=\\det\\Q_G$ holds, are also given.\n\n Let $n\\ge 1$ and $M_n(\\N)$ be the set of $n\\times n$ matrices over nonnegative integers $\\N$. Let $\\mathcal{G}_n=\\{H=[h_{i,j}]\\in M_n(\\N)\\mid H^t=H\\,\\text{and}\\, h_{ii}\\ge\\max_{j\\neq i} h_{i,j}\\,\\text{for}\\, 1\\le i\\le n\\}$. For $H=[h_{i,j}]\\in\\mathcal{G}_n$ with $\\alpha_i=h_{i,i}$, we associate a monomial ideal \n\\[\n \\mathcal{J}_H=\\left\\langle x_t^{\\alpha_t},x_i^{\\alpha_i-h_{i,j}}x_j^{\\alpha_j-h_{i,j}}\\mid 1\\le t\\le n,\\,1\\le i< j\\le n\\right\\rangle\n\\]\nin the polynomial ring $R=\\FK[x_1,\\ldots,x_n]$. Note that if we consider the matrix $H=\\widetilde Q_G$, then $\\J_H=\\M_{G}^{(1)}$. %For a positive semidefinite matrix $H$, we have the following result:\n\\begin{theorem}\\textup{\\cite[Theorem 3.3]{KLR}}\\label{inequality for multigraph}\n Let $H\\in\\mathcal{G}_n$ be positive semidefinite and $\\J_H$ be the monomial ideal in the polynomial ring $R$ associated to $H$. Then \n \\[\n  \\K\\left(\\frac{R}{\\J_H}\\right)\\ge \\det H.\n \\]\n\\end{theorem}\n\nThus for a multigraph $G$ we have $\\K(R/\\M_G^{(1)})\\ge\\det\\Q_G$, since $\\Q_G$ is a positive semidefinite matrix. The above theorem is one of the key ingredients to obtain our results for the ideals $\\M_G^{(1)}$. In fact, we obtained all our results for the ideal $\\J_H$, where $H\\in\\mathcal G_n$ and then specialized them to the $1$-skeleton ideals $M_G^{(1)}$.% using the fact that $\\J_H=\\M_G^{(1)}$ when $H=\\widetilde Q_G$. %Since $\\J_H=\\M_G^{(1)}$ for $H=\\widetilde Q_G$, we get all our results for $\\M_G^{(1)}$ as a corollary.\n \n In Section \\ref{section 2} of this paper we provide a generalization of the fact that if $G$ is a multigraph obtained from a complete multigraph $K_{n+1}^{a,b}$ by removing some rooted edges then $\\K(R/\\M_G^{(1)})=\\det\\Q_G$. We also give examples of some new families of multigraphs for which number of standard monomials of the $1$-skeleton ideal is same as the determinant of the truncated signless Laplace matrix. In Section \\ref{characterizing subgraphs} we characterize all subgraphs $G$ of $K_{n+1}^{a,1}$ which satisfy the equality  $\\K(R/\\M_G^{(1)})=\\det\\Q_G$. Consequently, such a characterization is also obtained for simple graphs.\n    \n    \\section{Some families of multigraphs}\\label{section 2}\nConsider the complete multigraph $K_{n+1}^{a,b}$ and the monomial ideal $\\M_{K_{n+1}^{a,b}}^{(1)}$ in the polynomial ring $R=\\FK[x_1,\\ldots,x_n]$. Sometimes we write $R=R_n$ to indicate the number of variables in $R$. Observe that the matrix $\\Q_{K_{n+1}^{a,b}}=[h_{i,j}]_{1\\le i,j\\le n}$, where $h_{i,i}=a+(n-1)b$ for $i\\in[n]$ and $h_{i,j}=b$ for $i\\neq j$. It has been shown in \\cite[Remark 2.7]{KLS} that $\\K\\left(R_n/\\M_{K_{n+1}^{a,b}}^{(1)}\\right)=\\det\\widetilde Q_{K_{n+1}^{a,b}}$. This result has been generalized in the following way.\n\n\\begin{theorem}\\textup{\\cite[Theorem 2.5]{KLR}}\\label{RC}\nLet $G$ be a multigraph on $V=\\{0,1,\\ldots ,n\\}$ obtained from the complete multigraph $K_{n+1}^{a,b}$ by deleting some edges through the root $0$. Then\n\\begin{equation}\\label{e2}\n\\dim_{\\mathbb K}\\left(\\frac{R_n}{\\M_G^{(1)}}\\right)=\\det\\widetilde Q_G.\n\\end{equation}\n\\end{theorem}\n\n Notice that for the graph $G$ in Theorem \\ref{RC}, the truncated signless Laplace matrix $\\Q_G=[h_{i,j}]_{1\\le i,j\\le n}$, where $b\\le h_{i,i}\\le a+(n-1)b$ for $i\\in[n]$ and $h_{i,j}=b$ for $i\\neq j$. We now proceed to give a generalization of Theorem \\ref{RC}. Recall that given a matrix $H\\in \\mathcal{G}_n$ we have associated a monomial ideal $\\J_H\\subseteq R_n$ such that $\\J_H=\\M_G^{(1)}$ when $H=\\widetilde Q_G$. The $i^{th}$ row and $j^{th}$ column of a matrix $H$ are denoted by $\\mathcal R_i$ and $\\mathcal{C}_j$, respectively.\n The elementary column operation $\\mathcal{C}_j\\pm(\\mathcal{C}_{k_1}+\\dots+\\mathcal C_{k_r})$ in $H$ means the matrix $H$ is transformed to a matrix $H'$, where only $j^{th}$ column $\\mathcal{C}_{j}'$ of $H'$ differs from the $j^{th}$ column $\\mathcal{C}_j$ of $H$ and $\\mathcal{C}_j'=\\mathcal{C}_j\\pm(\\mathcal{C}_{k_1}+\\dots+\\mathcal C_{k_r})$. The elementary row operations are also defined in a similar way. \n%Let $n\\geq 1$ and $M_n(\\mathbb{N})$ be the set of all $n\\times n$ matrices over nonnegative integers $\\mathbb{N}$. Let\n%$\\mathcal{G}_n=\\{H=[b_{ij}]\\in M_n(\\mathbb N):H^t=H ~\\text{and} ~b_{ii}\\geq\\max_{i\\neq j}b_{ij} ~\\text{for}~ 1\\leq i\\leq n\\}$.\n%For $H=[b_{ij}]_{n\\times n}\\in\\mathcal G_n$ with $\\alpha_i=b_{ii}$, we associate a monomial ideal \n%\\[\n%\\J_H=\\left\\langle x_l^{\\alpha_l},x_i^{\\alpha_i-b_{ij}}x_j^{\\alpha_j-b_{ij}}:1\\leq l\\leq n,1\\leq i<j\\leq n\\right\\rangle\n%\\]\n%in the polynomial ring $R_n=\\mathbb K[x_1,\\ldots ,x_n]$.\n%If $H=\\widetilde Q_G$, the truncated signless Laplace matrix of a multigraph $G$ on $V=\\{0,1,\\ldots,n\\}$, then $\\J_H=\\M_G^{(1)}$.\n\n %The following theorem is a generalization of Theorem \\ref{RC}.\n\n\\begin{theorem}\\label{rooted edge matrix version}\n Let $H=[h_{i,j}]_{1\\le i,j\\le n}$ \n %$H=\n %\\begin{bmatrix}\n %a_1 & b & b & \\cdots & b \\\\\n %b & a_2 & b & \\cdots & b \\\\\n %b & b & a_3 & \\cdots & b \\\\\n %\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n %b & b & b & \\cdots & a_n\n %\\end{bmatrix}_{n\\times n}\n %$\nbe a matrix over nonnegative integers such that $h_{i,i}=a_i$ for $i\\in[n]$ and $h_{i,j}=b$ for $i\\ne j$, where $a_i\\geq b$ for each $i\\in[n]$. Then\n\\[\\dim_{\\mathbb{K}}\\left(\\frac{R_n}{\\J_H}\\right)=\\det H.\\]\n\\end{theorem}\n\n\\begin{proof}\n We prove this by induction on $n$. For $n=2$, the matrix $H=\n \\begin{bmatrix}\n  a_1 & b \\\\\n  b & a_2\n \\end{bmatrix}_{2\\times 2}\n$ and the ideal $\\J_H=\\left\\langle x_1^{a_1},x_2^{a_2}, x_1^{a_1-b}x_2^{a_2-b} \\right\\rangle$. Thus $\\dim_{\\mathbb{K}}(R_2/\\J_H)=a_1a_2-b^2=\\det H$.\n\nSuppose $n\\geq 3$ and the theorem is true for any $m$ with $m<n$. If $b=0$, then $\\J_H=\\left\\langle x_i^{a_i}:1\\le i\\le n\\right\\rangle$. Thus $\\K(R_n/\\J_H)=\\prod_{i=1}^na_i=\\det H$. If $a_i=b$ for each $i$, then $\\dim_{\\mathbb{K}}(R_n/\\J_H)=0=\\det H$. Hence, without loss of generality, assume that $a_1>b>0$. Let $r=a_1-b>0$. The ideal $\\J_H=\\left\\langle x_l^{a_l}, x_i^{a_i-b}x_j^{a_j-b}: 1\\leq l\\leq n,~1\\leq i<j\\leq n \\right\\rangle$.\n\nLet $H_1=\\operatorname{diag}[b,a_2-b,a_3-b,\\ldots,a_n-b]$ be the $n\\times n$ diagonal matrix and $H_2$ be the matrix obtained from $H$ by deleting row $\\mathcal{R}_1$ and column $\\mathcal{C}_1$.\n%Let us consider two matrices \\[H_1=\n%\\begin{bmatrix}\n% b & 0 & 0 & \\cdots & 0 \\\\\n% 0 & a_2-b & 0 & \\cdots & 0 \\\\\n% 0 & 0 & a_3-b & \\cdots & 0 \\\\\n% \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n% 0 & 0 & 0 & \\cdots & a_n-b\n%\\end{bmatrix}_{n\\times n}\n% \\,\\text{and}\\quad \n% H_2=\n%\\begin{bmatrix}\n% a_2 & b & b & \\cdots & b \\\\\n% b & a_3 & b & \\cdots & b \\\\\n% \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n% b & b & b & \\cdots & a_n\n%\\end{bmatrix}_{(n-1)\\times (n-1)}.\\]\n We see that $\\left(\\J_H:x_1^r\\right)=\\J_{H_1}$ and $\\left\\langle \\J_H,x_1^r\\right\\rangle=\\langle \\J_{H_2},x_1^r\\rangle$. Therefore, $\\dim_{\\mathbb{K}}(R_n/\\left(\\J_H:x_1^r\\right))=\\dim_{\\mathbb{K}}(R_n/\\J_{H_1})=\\det H_1$. Moreover, $\\dim_{\\mathbb{K}}(R_n/\\left\\langle \\J_H,x_1^r\\right\\rangle)=r\\dim_{\\mathbb{K}}(R_{n-1}/\\J_{H_2})=r\\det H_2$ (by induction hypothesis). Consider the short exact sequence of $\\mathbb{K}$-vector spaces,\n\\begin{align}\\label{short exact sequence}\n 0\\rightarrow\\frac{R_n}{\\left(\\J_H:x_{1}^{r}\\right)}\\xrightarrow{\\mu_{x_{1}^{r}}}\\frac{R_n}{\\J_H}x\\xrightarrow{\\nu}\\frac{R_n}{\\left\\langle \\J_H,x_{1}^{r}\\right\\rangle}\\rightarrow 0,\n\\end{align}\nwhere $\\mu_{x_{1}^{r}}$ is the map induced by multiplication by $x_1^r$ and $\\nu$ is the natural quotient map. We have ,$\\dim_{\\mathbb{K}}(R_n/\\J_H)=\\K(R_n/\\left(\\J_H:x_{1}^{r}\\right))+\\K(R_n/\\left\\langle \\J_H,x_{1}^{r}\\right\\rangle)=\\K(R_n/\\J_{H_1})+r\\K(R_{n-1}/\\J_{H_2})$. Hence, \\[\\dim_{\\mathbb{K}}(R_n/\\J_H)=\\det H_1+r\\det H_2.\\]\n\nWriting $a_1=b+r$ and using the additivity property of the determinant, we see that $\\det H=r\\det H_2+\\det A$, where $A$ is the matrix obtained from $H$ by replacing the element $a_1$ with $b$. On applying elementary column and row operations, $\\mathcal{C}_2-\\mathcal{C}_1, \\mathcal{R}_2-\\mathcal{R}_1,\\ldots ,\\mathcal{C}_n-\\mathcal{C}_1, \\mathcal{R}_n-\\mathcal{R}_1$ on $A$, it reduces to the matrix $H_1$.\n%\\[\n% A'=\\begin{bmatrix}\n%     b & 0 & 0 & \\cdots & 0 \\\\\n% b & a_2-b & 0 & \\cdots & 0 \\\\\n% b & 0 & a_3-b & \\cdots & 0 \\\\\n% \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n% b & 0 & 0 & \\cdots & a_n-b\n%    \\end{bmatrix}_{n\\times n}.\n%\\]\nThus $\\det A=\\det H_1$. Hence, $\\K(R_n/\\J_H)=\\det H$. \\qed\n\n\\end{proof}\n\\vspace{4mm}\nIn the next theorem we further generalize Theorem \\ref{rooted edge matrix version}. Consequently, we provide some new families of multigraphs $G$ which satisfy $\\K(R/\\M_G^{(1)})=\\det\\Q_G$.\n\n\\begin{theorem}\\label{matrix version of join of graphs}\n Let $H_i=\\begin{bmatrix}\n           \\alpha_{i,1} & b_i & \\cdots & b_i \\\\\n           b_i & \\alpha_{i,2} & \\cdots & b_i \\\\\n           \\vdots & \\vdots & \\ddots & \\vdots \\\\\n           b_i & b_i & \\cdots & \\alpha_{i,n_i}\n          \\end{bmatrix}_{n_i\\times n_i}\n$ with $\\alpha_{i,j}\\geq b_i$ and $A_i$ be the $n_i\\times n_i$ matrix with all entries equal to $d_i$. Consider the matrix \n\\begin{align}\\label{join graph matrix}\nH=\n\\begin{bmatrix}\nH_1 & A_1 & A_2 & \\cdots & A_{r-1} \\\\\nA_1 & H_2 & A_2 & \\cdots & A_{r-1} \\\\\nA_2 & A_2 & H_3 & \\cdots & A_{r-1} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{r-1} & A_{r-1} & A_{r-1} & \\cdots & H_r\n\\end{bmatrix}_{\\sum_{i=1}^rn_i\\times\\sum_{i=1}^rn_i}\n\\end{align}\nwith $b_1\\geq d_1,\\,b_i\\geq d_{i-1}$ for $2\\leq i\\leq r$, and $d_i\\geq d_{i+1}$ for $1\\leq i\\leq r-2$. Assume that $\\alpha_{i,j},\\,b_i$ and $d_i$ are all nonnegative integers. Suppose $n=\\sum_{i=1}^rn_i$. Then $\\K(R_n/\\J_H)=\\det H$.\n\\end{theorem}\n\n\\begin{proof}\n If $n=2$, then we see that $\\K(R_2/\\J_H)=\\det H$. We prove the theorem by induction on the order $n$ of $H$. Assume that $n\\geq 3$ and the theorem holds for every $m\\times m$ matrices of the above form for $m<n$. The monomial ideal $\\J_H$ is generated by the following monomials\n \\begin{align*}\n x_{i,j}^{\\alpha_{i,j}}&: 1\\leq i\\leq r,~1\\leq j\\leq n_i\\,,\\\\\n x_{i,u}^{\\alpha_{i,u}-b_i}x_{i,v}^{\\alpha_{i,v}-b_i}&: 1\\leq i\\leq r,~1\\leq u<v\\leq n_i\\,, \\\\\n x_{s,w}^{\\alpha_{s,w}-d_{t-1}}x_{t,l}^{\\alpha_{t,l}-d_{t-1}}&: 1\\leq s\\leq r-1,~1\\leq w\\leq n_s,~s+1\\leq t\\leq r,~1\\leq l\\leq n_t\\,. \n \\end{align*} \n \n We now divide the proof into two cases:\n \n \\noindent\n {\\bf Case I :} $n_r=1$. Let $B_1$ be the matrix obtained from $H$ by deleting the row and column containing the diagonal element $\\alpha_{r1}$ and $B_2$ be an $(n-1)\\times(n-1)$ matrix whose all entries are $d_{r-1}$. Let $B_3=B_1-B_2$. We see that the ideals $\\left(\\J_H:x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right)=\\left\\langle \\J_{B_3},x_{r,1}^{d_{r-1}}\\right\\rangle$ and $\\left\\langle \\J_{H},x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle=\\left\\langle \\J_{B_1}, x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle$. By induction hypothesis,\n \n \\begin{align*}\n  \\K\\left(\\frac{R_{n-1}}{\\J_{B_3}}\\right)\n   =\\det B_3 \\quad \\text{and}\\quad \\K\\left(\\frac{R_{n-1}}{\\J_{B_1}}\\right)=\\det B_1.\n \\end{align*}\nThus $\\K\\left(R_n/(\\J_H:x_{r,1}^{\\alpha_{r,1}-d_{r-1}})\\right)=d_{r-1}\\K(R_{n-1}/\\J_{B_3})=d_{r-1}\\det B_3$. Moreover, we see that $\\K\\left(R_n/\\left\\langle \\J_{H},x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle\\right)=(\\alpha_{r,1}-d_{r-1})\\K(R_{n-1}/\\J_{B_1})=(\\alpha_{r,1}-d_{r-1})\\det B_1$.\n %\\begin{align*}\n%   \\K\\left(\\frac{R_n}{\\left(J_H:x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right)}\\right)&=d_{r-1}\\K\\left(\\frac{R_{n-1}}{J_{B_3}}\\right)\\\\\n%   &=d_{r-1}\\det B_3.  \n% \\end{align*}\n%Also, note that $\\left\\langle J_{H},x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle=\\left\\langle J_{B_1}, x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle$. Then again by the induction assumption,\n%\\begin{align*}\n% \\K\\left(\\frac{R_n}{\\left\\langle J_{H},x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle}\\right)&=(\\alpha_{r,1}-d_{r-1})\\K\\left(\\frac{R_{n-1}}{J_{B_1}}\\right)\\\\\n% &=(\\alpha_{r,1}-d_{r-1})\\det B_1.\n%\\end{align*}\nUsing the short exact sequence of $\\mathbb{K}$-vector spaces\n\\begin{align*}%\\label{short exact sequence2}\n 0\\rightarrow\\frac{R_n}{\\left(\\J_H:x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right)}\\xrightarrow{\\mu_{x_{r,1}^{\\alpha_{r,1}-d_{r-1}}}}\\frac{R_n}{\\J_H}\\rightarrow\\frac{R_n}{\\left\\langle \\J_{H},x_{r,1}^{\\alpha_{r,1}-d_{r-1}}\\right\\rangle}\\rightarrow 0,\n\\end{align*}\nwe get $\\K\\left(R_n/\\J_H\\right)=d_{r-1}\\det B_3+(\\alpha_{r,1}-d_{r-1})\\det B_1$. As determinant is linear on columns, writing $\\alpha_{r,1}=(\\alpha_{r,1}-d_{r-1})+d_{r-1}$, we have $\\det H=(\\alpha_{r,1}-d_{r-1})\\det B_1+\\det B_4$, where $B_4$ is the matrix obtained from $H$ by replacing the diagonal element $\\alpha_{r,1}$ with $d_{r-1}$. Applying elementary column and row operations, $\\mathcal{C}_1-\\mathcal{C}_n,\\mathcal{R}_1-\\mathcal{R}_n,\\ldots ,\\mathcal{C}_{n-1}-\\mathcal{C}_{n},\\mathcal{R}_{n-1}-\\mathcal{R}_n$ on $B_4$, we get $\\det B_4=d_{r-1}\\det B_3$. Consequently, $\\K(R_n/\\J_H)=\\det H$.\n\n\\noindent\n{\\bf Case II :} $n_r\\geq 2$. Let $B_5$ be the matrix obtained from $H$ by first deleting rows and columns containing the diagonal elements $\\alpha_{r,1},\\alpha_{r,2},\\ldots ,\\alpha_{r,n_r-1}$ and then replacing the diagonal element $\\alpha_{r,n_r}$ with $b_r$. Hence, $B_5$ is an $(n+1-n_r)\\times(n+1-n_r)$ matrix. Note that the ideal $\\left( \\J_H:x_{r,n_r}^{\\alpha_{r,n_r}-b_r} \\right)=\\left\\langle \\J_{B_5},x_{r,1}^{\\alpha_{r,1}-b_r},\\ldots ,x_{r,n_r-1}^{\\alpha_{r,n_r-1}-b_r} \\right\\rangle$. By induction hypothesis, $\\K\\left(R_{n+1-n_r}/\\J_{B_5}\\right)=\\det B_5$. Thus\n\\begin{align*}\n \\K\\left(\\frac{R_n}{\\left( \\J_H:x_{r,n_r}^{\\alpha_{r,n_r}-b_r} \\right)}\\right)&=\\left(\\prod_{i=1}^{n_r-1}(\\alpha_{r,i}-b_r)\\right)\\K\\left(\\frac{R_{n+1-n_r}}{\\J_{B_5}}\\right)\\\\\n &=\\left(\\prod_{i=1}^{n_r-1}(\\alpha_{r,i}-b_r)\\right)\\det B_5\n\\end{align*}\n\n Let $B_6$ be the $(n-1)\\times(n-1)$ matrix obtained from $H$ by deleting the row and column containing the diagonal element $\\alpha_{r,n_r}$. We see that $\\left\\langle \\J_H,x_{r,n_r}^{\\alpha_{r,n_r}-b_r} \\right\\rangle=\\left\\langle \\J_{B_6},x_{r,n_r}^{\\alpha_{rn_r}-b_r} \\right\\rangle$. Also, $\\K(R_{n-1}/\\J_{B_6})=\\det B_6$ (by induction hypothesis). Thus \n \\begin{align*}\n \\K\\left(\\frac{R_n}{\\left\\langle \\J_H,x_{r,n_r}^{\\alpha_{r,n_r}-b_r}\\right\\rangle}\\right)&=(\\alpha_{r,n_r}-b_r)\\K\\left(\\frac{R_{n-1}}{\\J_{B_6}}\\right)\\\\\n &=(\\alpha_{r,n_r}-b_r)\\det B_6.\n \\end{align*}\n \n \\noindent\n Now using the short exact sequence of $\\mathbb{K}$-vector spaces\n\\begin{align*}%\\label{short exact sequence2}\n 0\\rightarrow\\frac{R_n}{\\left(\\J_H:x_{r,n_r}^{\\alpha_{r,n_r}-b_r}\\right)}\\xrightarrow{\\mu_{x_{r,n_r}^{\\alpha_{r,n_r}-b_r}}}\\frac{R_n}{\\J_H}\\rightarrow\\frac{R_n}{\\left\\langle \\J_{H},x_{r,n_r}^{\\alpha_{r,n_r}-b_r}\\right\\rangle}\\rightarrow 0,\n\\end{align*}\nwe get $\\K(R_n/\\J_H)=\\left(\\prod_{i=1}^{n_r-1}(\\alpha_{r,i}-b_r)\\right)\\det B_5+(\\alpha_{r,n_r}-b_r)\\det B_6$. Writing $\\alpha_{r,n_r}=(\\alpha_{r,n_r}-b_r)+b_r$ and using the additivity property of the determinant we see that $\\det H=(\\alpha_{r,n_r}-b_r)\\det B_6+\\det B_7$, where $B_7$ is the matrix obtained from $H$ by replacing the diagonal element $\\alpha_{r,n_r}$ with $b_r$. Applying the elementary column and row operations, $\\mathcal{C}_i-\\mathcal{C}_n,\\mathcal{R}_i-\\mathcal{R}_n$ for $n-n_r< i\\leq n-1$ on $B_7$, we get, $\\det B_7=\\left(\\prod_{i=1}^{n_r-1}(\\alpha_{r,i}-b_r)\\right)\\det B_5$. Consequently, $\\K(R_n/\\J_H)=\\det H$. \\qed\n\\end{proof}\n\\vspace{4mm}\nThe above theorem provides example of a matrix $H\\in\\mathcal{G}_n$ such that $\\K(R_n/J_H)=\\det H$. However, using this result we can give some new families of multigraphs $G$ for which the number of standard monomials of $R/\\M_G^{(1)}$ is same as the determinant of the truncated signless Laplace matrix $\\Q_G$. These graphs are expressed as a certain `$d$-fold product' of some multigraphs which are obtained from complete multigraphs by removing some edges incident to the root. More precisely,\n  \\begin{definition}\n  Let $G_1$ be a multigraph on the vertex set $\\{0,1,\\ldots,n\\}$ and $G_2$ be a multigraph on the vertex set $\\{0,1,\\ldots ,m\\}$. Let $d$ be a nonnegative integer. Define the graph $G_1*_{d}G_2$ on the vertex set $\\{0,1,\\ldots,n,n+1,\\ldots ,n+m\\}$ as follows. If $1\\le i,j\\leq n$ then the number of edges between $i$ and $j$ in $G$ is same as the number of edges between $i$ and $j$ in $G_1$. If $i,j\\geq n+1$ then the number of edges between $i$ and $j$ in $G$ is same as the number of edges between $i-n$ and $j-n$ in $G_2$. For $1\\le i\\le n$ the number of edges between $0$ and $i$ in $G$ is same as the number of edges between $0$ and $i$ in $G_1$.\n  For $j\\ge n+1$ the number of edges between $0$ and $j$ in $G$ is same as the number of edges between $0$ and $j-n$ in $G_2$. For each $1\\le i\\leq n$ and $j\\geq n+1$ the number edges between $i$ and $j$ is exactly $d$. \n  \\end{definition}\n  \\begin{example}\n  We give an example of the graph constructed above in Figure \\ref{figure 123143}.\n\\begin{figure}[h!]\n\\tikzset{multi/.style={to path={\n\\pgfextra{% \n \\pgfmathsetmacro{\\startf}{-(#1-1)/2}  \n \\pgfmathsetmacro{\\endf}{-\\startf} \n \\pgfmathsetmacro{\\stepf}{\\startf+1}}\n \\ifnum 1=#1 -- (\\tikztotarget)  \\else\n\\foreach \\i in {\\startf,\\stepf,...,\\endf}\n    {%\n     (\\tikztostart)        parabola[bend pos=0.5] bend +(0,0.2*\\i)  (\\tikztotarget)\n      }\n      \\fi   \n     \\tikztonodes\n      }}}\n      \n      \\tikzset{multi1/.style={to path={\n\\pgfextra{% \n \\pgfmathsetmacro{\\startf}{-(#1-1)/2}  \n \\pgfmathsetmacro{\\endf}{-\\startf} \n \\pgfmathsetmacro{\\stepf}{\\startf+1}}\n \\ifnum 1=#1 -- (\\tikztotarget)  \\else\n     let \\p{mid}=($(\\tikztostart)!0.5!(\\tikztotarget)$) \n         in\n\\foreach \\i in {\\startf,\\stepf,...,\\endf}\n    {%\n     (\\tikztostart) .. controls ($ (\\p{mid})!\\i*6pt!90:(\\tikztotarget) $) .. (\\tikztotarget)\n      }\n      \\fi   \n     \\tikztonodes\n}}}   \n\n\\begin{tikzpicture}\n[scale=.55]\n      \\centering\n\\draw [fill] (0,1.5) circle [radius=0.1];\n\\draw [fill] (3,1.5) circle [radius=0.1];\n\\draw [fill] (1.5,-1.5) circle [radius=0.1];\n\\draw (0,1.5) edge[multi=3] (3,1.5);\n\\draw (0,1.5) edge[multi1=2] (1.5,-1.5);\n\\draw (3,1.5) edge[multi1=3] (1.5,-1.5);\n\\node at (5,0) {$*_1$};\n\\node at (1.5,-2) {$0$};\n\\node at (-0.5,1.5) {$1$};\n\\node at (3.5,1.5) {$2$};\n\\node at (1.5,-3.5) {$G_1$};\n\\draw [fill] (7,1.5) circle [radius=0.1];\n\\draw [fill] (10,1.5) circle [radius=0.1];\n\\draw [fill] (8.5,-1.5) circle [radius=0.1];\n\\draw (7,1.5) edge[multi=2] (10,1.5);\n\\draw (10,1.5) edge[multi1=2] (8.5,-1.5);\n\\node at (8.5,-2) {$0$};\n\\node at (10.5,1.5) {$2$};\n\\node at (6.5,1.5) {$1$};\n\\node at (8.5,-3.5) {$G_2$};\n\\draw (8.5,-1.5) edge[multi1=2] (7,1.5);\n\\node at (12,0) {$=$};\n\\draw [fill] (14,2) circle [radius=0.1];\n\\draw [fill] (17,2) circle [radius=0.1];\n\\draw [fill] (14,0) circle [radius=0.1];\n\\draw [fill] (17,0) circle [radius=0.1];\n\\draw [fill] (15.5,-2) circle [radius=0.1];\n\\node at (15.5,-2.5) {$0$};\n\\node at (13.5,2) {$1$};\n\\node at (17.5,2) {$2$};\n\\node at (13.5,0) {$3$};\n\\node at (17.5,0) {$4$};\n\\node at (15.5,-3.5) {$G_1*_1G_2$};\n\\draw (14,2) edge[multi=3] (17,2);\n\\draw (14,0) edge[multi=2] (17,0);\n\\draw (17,0) edge[multi1=2] (15.5,-2);\n\\draw (14,0) edge[multi1=2] (15.5,-2);\n\\draw (14,2)--(14,0)--(17,2)--(17,0)--(14,2);\n\\draw (15.5,-2) edge[multi1=3] (17,2);\n\\draw (15.5,-2) edge[multi1=2] (14,2);\n\\end{tikzpicture}\n\\caption{$G_1*_dG_2$ for $d=1$.}\\label{figure 123143}\n\\end{figure}\n  \\end{example}\n  \\begin{corollary}\n   Let $G_i$ be a multigraph on the vertex set $\\{0,1,\\ldots,n_i\\}$ obtained from a complete multigraph $K_{n_i+1}^{a_i,b_i}$ by removing some edges through the root $0$, where $1\\leq i\\leq r$. Suppose $n=\\sum_{i=1}^rn_i$. Let $G=((\\cdots(G_1*_{d_1}G_2)*_{d_2}\\cdots *_{d_{r-2}} G_{r-1})*_{d_{r-1}}G_r)$ be the multigraph on the vertex set $\\{0,1,\\ldots,n\\}$, where $d_1\\geq d_2\\geq\\dots\\geq d_{r-1}$ are nonnegative integers, $b_1\\geq d_1$, and $b_i\\geq d_{i-1}$ for $2\\le i\\le r$.  Then $\\dim_{\\FK}(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$.\n  \\end{corollary}\n  \\begin{proof}\n   The truncated signless Laplacian $\\widetilde Q_G$ of the graph $G$ is a matrix of the form \\eqref{join graph matrix}. Taking $H=\\widetilde Q_G$ in Theorem \\ref{matrix version of join of graphs} we get our result. \\qed\n  \\end{proof}\n  \n  \\vspace{4mm}\n  \\noindent\n  Thus $\\K(R/\\M_G^{(1)})=\\det\\Q_G$ for the graph $G=G_1*_1G_2$ in Figure \\ref{figure 123143}.\n  \n  \\section{Characterizing subgraphs of $K_{n+1}^{a,1}$}\\label{characterizing subgraphs}\n\nIn this section we classify all subgraphs $G$ of $K_{n+1}^{a,1}$ that satisfy $\\K(R/\\M_G^{(1)})=\\det\\widetilde Q_G$. In order to prove this we need the following results related to Hermitian matrices and their eigen values.\n\n Let $M\\in M_n(\\mathbb C)$ be a Hermitian matrix. The  eigenvalues of $M$ are arranged in a non-decreasing order $\\lambda_1(M)\\leq\\lambda_2(M)\\leq\\cdots\\leq\\lambda_n(M)$. The Courant-Weyl inequalities \\cite[Theorem 4.3.1]{HJ} compare eigenvalues of two Hermitian matrices with the eigenvalues of their sum.\n\n    \\begin{theorem}[Courant-Weyl]\\label{CW}\n    Let $M_1,M_2\\in M_n({\\mathbb C})$ be Hermitian matrices. Then\n    \\[\n    \\lambda_i(M_1+M_2)\\leq\\lambda_{i+j}(M_1)+\\lambda_{n-j}(M_2)~{\\rm for}~ j=0,1,\\ldots ,n-i.\n    \\]\n    \\end{theorem}\n    \nThe following application of the Courant-Weyl inequalities will be used in our proofs.\n\n    \\begin{lemma}\\label{replacing an element}\n    Let $M=(a_{i,j})_{n\\times n}\\in M_n(\\C)$ be a Hermitian positive semidefinite matrix. Suppose $N$ is obtained from $M$ by replacing one diagonal element, say $a_{i,i}$, with a real number $b$ such that $a_{i,i}\\geq b$. If $\\det N>0$, then $N$ is a positive definite matrix.\n    \\end{lemma}\n  \n    \\begin{proof}\n    Let $\\epsilon_{i,j}$ be the $n\\times n$ matrix with $1$ at the $(i,j)^{th}$ place and zero elsewhere. Then $M=N+N'$, where $N'=(a_{i,i}-b)\\epsilon_{i,i}$. Clearly, $\\lambda_1(N')=\\cdots=\\lambda_{n-1}(N')=0$ and $\\lambda_n(N')=a_{i,i}-b$. Since $M$ is positive semidefinite, $0\\leq \\lambda_1(M)\\leq\\cdots\\leq\\lambda_n(M)$. Taking $i=j=1$ in the Courant-Weyl inequalities with $M=N+N'$, we obtain $\\lambda_1(M)\\leq\\lambda_2(N)+\\lambda_{n-1}(N')=\\lambda_2(N)$. Thus $0\\leq \\lambda_2(N)\\leq\\ldots\\leq\\lambda_n(N)$. As $\\det N=\\prod_{i=1}^n\\lambda_i(N)>0$, $N$ must be positive definite. \\qed\n    \\end{proof}\n    \\vspace{4mm}\n    Given a block Hermitian matrix $M$ the Fischer's inequality provides an upper bound for $\\det M$.  \n%     In our proofs we use the following form of Fischer's inequality which is a generalization of Hadamard's theorem. \n%   \\begin{theorem}[Hadamard]\\textup{\\cite[Theorem 7.8.1]{HJ}}\\label{Hadamard inequality theorem}\n%    Let $M=[a_{i,j}]\\in M_n(\\C)$ be positive definite. Then \n%    \\begin{align}\\label{Hadamard}\n%     \\det A\\leq \\prod_{i=1}^na_{i,i}\n%    \\end{align}\n%    with equality if and only if $A$ is diagonal.\n%   \\end{theorem}\n\n\n   \\begin{theorem}[Fischer]\\textup{\\cite[Theorem 7.8.5]{HJ}}\\label{FI}\n    Let $M\\in M_n(\\mathbb C)$ be a positive semidefinite matrix having block decomposition \n    $M=\n    \\left(\n    \\begin{array}{c|c}\n    A & B \\\\\n\n    \\hline\n\n    B^* & C\n    \\end{array}\n    \\right)\n    $ with square matrices $A$ and $C$. Then\n    \\begin{align}\\label{definite to semidefinite}\n    \\det M\\leq\\det(A)\\det(C).\n    \\end{align}    \n    If $M$ is positive definite then equality occurs in \\eqref{definite to semidefinite} if and only if $B=0$.\n    \\end{theorem}\n    %\\begin{proof}\n    %Let $n=p+q$, i.e., $M\\in M_{p+q}(\\C)$ with $A\\in M_p(\\C)$ and $C\\in M_q(\\C)$. We follow the proof of \\cite[Theorem 7.8.5]{HJ}. First suppose that $M$ is positive definite. Let $A=U_1DU_1^*$ and $C=U_2D'U_2^*$ be spectral decomposition, in which $U_1$ and $U_2$ are unitary and $D=\\operatorname{diag}(d_1,\\ldots,d_p)$ and $D'=\\operatorname{diag}(d_1',\\ldots ,d_q')$ are positive diagonal matrices. Let $U=U_1\\oplus U_2$ and then \n     %\\[\n     %U^*MU=\n     % \\begin{bmatrix}\n     %  D & U_1^*BU_2 \\\\\n%        U_2^*B^*U_1 & D'\n%       \\end{bmatrix}.\n%      \\]\n%      Then by Hadamard's inequality \\eqref{Hadamard},\n%      \\[\n%       \\det M=\\det (U^*MU)\\leq(d_1\\cdots d_p)(d_1'\\cdots d_q')=(\\det A)(\\det C).\n%      \\]\n%      Now if $M$ is positive semidefinite then we clearly have \\eqref{definite to semidefinite} as both $A$ and $C$ are positive semidefinite. For the statement about equality, note that by Theorem \\ref{Hadamard inequality theorem}, $\\det M=\\det(U^*MU)=(\\det A)(\\det C)$ if and only if $U_1^*BU_2=0$, i.e., $B=0$ (as both $U_1$ and $U_2$ are unitary). \\qed\n%     \\end{proof}\n%      \\color{violet}\n%      \\begin{lemma}\\label{elementary operations}\n%     Let $M\\in M_n(\\C)$ be a Hermitian positive semidefinite matrix. Suppose $M'$ is a matrix obtained from $M$ by applying the elementary column and row operations $\\mathcal{C}_{i_1}-\\mathcal{C}_k,\\mathcal{R}_{i_1}-\\mathcal{R}_k,\\ldots, \\mathcal{C}_{i_r}-\\mathcal{C}_k,\\mathcal{R}_{i_r}-\\mathcal{R}_k$, where $\\{i_1,\\ldots,i_r,k\\}\\subseteq[n]$. Then $M'$ is a positive semidefinite matrix. If $M$ is positive definite then $M'$ is also positive definite.\n%    \\end{lemma}\n%    \\begin{proof}\n%     Let $I_n$ be the identity matrix of order $n$ and $\\epsilon_{i,j}$ be the $n\\times n$ matrix with $1$ at $(i,j)$th place and zero elsewhere. Then the matrix $E=I_n-(\\epsilon_{k,i_1}+\\epsilon_{k,i_2}+\\cdots+\\epsilon_{k,i_r})$ has determinant $\\det E=1$ and $E^tME=M'$. Thus $M'$ is positive semidefinite and since $E$ has full rank, the matrix $M'$ is positive definite if and only if $M$ is positive definite. \\qed\n%    \\end{proof}\n%  \\color{black}\n  \\vspace{4mm}\n   The following Lemma will show us that in order to check whether a graph $G$ satisfy $\\K(R/\\M_G^{(1)})=\\det\\Q_G$, we only need to consider those graphs which have exactly two connected components after removing all the rooted-edges. We call these graphs as `essentially connected' graphs (see Definition \\ref{defn essentially connected component}). \n\\begin{lemma}\\label{reducing to essential components}\n Let $G$ be a multigraph on $\\{0,1,\\ldots ,t\\}$ and $\\widetilde G$ be the induced subgraph on the vertex set $[t]$. Suppose the connected components of $\\widetilde G$ are $\\widetilde G_1,\\ldots ,\\widetilde G_r$ with $|V_i|=t_i$, where $V_i=V(\\widetilde G_i)$ for $1\\leq i\\leq r$. Consider the induced subgraphs $G_i=G_{V_i\\cup\\{0\\}}$ of $G$. We have, $\\K(R_t/\\M_G^{(1)})=\\det\\widetilde Q_G$ if and only if $\\K(R_{t_i}/\\M_{G_i}^{(1)})=\\det\\widetilde Q_{G_i}$ for $1\\le i\\le r$ .\n\\end{lemma}\n\n\\begin{proof}\nWe observe that the $1$-skeleton ideal $\\M_G^{(1)}=\\sum_{i=1}^r\\M_{G_i}^{(1)}$ such that\n\n\\[\\K\\left(\\frac{R}{\\M_{G}^{(1)}}\\right)=\\prod_{i=1}^r\\K\\left(\\frac{R_{t_i}}{\\M_{G_i}^{(1)}}\\right).\\]\nAlso, the truncated signless Laplace matrix $\\widetilde Q_G$ is a block-diagonal matrix with blocks being the truncated signless Laplace matrices of the graphs $G_i$. Therefore, $\\det\\widetilde Q_G=\\prod_{i=1}^r\\det\\widetilde Q_{G_i}$. By Theorem \\ref{inequality for multigraph}, $\\K(R_{t_i}/\\M_{G_i}^{(1)})\\ge\\det\\widetilde Q_{G_i}$ for $1\\le i\\le r$. Hence, $\\K(R_t/\\M_G^{(1)})=\\det\\widetilde Q_G$ if and only if $\\K(R_{t_i}/\\M_{G_i}^{(1)})=\\det\\widetilde Q_{G_i}$ for $1\\le i\\le r$. \\qed\n\\end{proof}\n\\vspace{4mm}\nWe illustrate the above result by the following example.\n\\begin{example}\nLet $G$ be the graph in Figure \\ref{figure 123465} on the vertex set $\\{0,1,\\ldots,5\\}$.\n\\begin{figure}[h!]\n\\centering\n\\begin{tikzpicture}\n[scale=.55]\n\\draw [fill] (0,0) circle [radius=0.1];\n\\draw [fill] (3,0) circle [radius=0.1];\n\\draw [fill] (5,2) circle [radius=0.1];\n\\draw [fill] (3,4) circle [radius=0.1];\n\\draw [fill] (0,4) circle [radius=0.1];\n\\draw [fill] (-2,2) circle [radius=0.1];\n\\node at (0,-0.9) {$4$};\n\\node at (3,-0.9) {$3$};\n\\node at (5.7,2) {$2$};\n\\node at (3,4.8) {$1$};\n\\node at (0,4.8) {$0$};\n\\node at (-2.7,2) {$5$};\n\\draw (0,4)--(0,0)--(3,0)--(-2,2)--(0,0);\n\\draw (3,0)--(0,4)--(5,2)--(3,4)--(0,4);\n\\end{tikzpicture}\\caption{A graph on vertex set $\\{0\\}\\cup[5]$.}\\label{figure 123465}\n\\end{figure}\n  Let $V_1=\\{1,2\\}$ and $V_2=\\{3,4,5\\}$. Consider the induced subgraphs $G_i:=G_{V_i\\cup\\{0\\}}$ for $i=1,2$. Identifying the vertex $i$ with the variable $x_i$ in the polynomial ring $R=\\FK[x_1,\\ldots,x_5]$ we see that $\\M_G^{(1)}=\\M_{G_1}^{(1)}+\\M_{G_2}^{(1)}$, where $\\M_{G_1}^{(1)}=\\langle x_1^2,x_2^2,x_1x_2\\rangle$ and $\\M_{G_2}^{(1)}=\\langle x_3^3,x_4^3,x_5^2,x_3^2x_4^2,x_3^2x_5,x_4^2x_5\\rangle$. Moreover, $\\K(R/\\M_G^{(1)})=36=3\\cdot 12=\\K(R_1/\\M_{G_1}^{(1)})\\cdot\\K(R_2/\\M_{G_2}^{(1)})$, where $R_1=\\FK[x_1,x_2]$ and $R_2=\\FK[x_3,x_4,x_5]$. We also have $\\K(R_i/\\M_{G_i}^{(1)})=\\det\\Q_{G_i}$ for each $i=1,2$.\n\\end{example}\nThe graphs $G_1$ and $G_2$ in above example are called `essentially connected component' of $G$. To be more precise,\n\\begin{definition}\\label{defn essentially connected component}\n Let $G$ be a multigraph on the vertex set $\\{0,1,\\ldots ,t\\}$ and $\\widetilde{G}$ be the induced subgraph of $G$ on the vertex set $\\{1,\\ldots ,t\\}$. If $\\widetilde G_1$ is a connected component of $\\widetilde G$ with vertex set $V_1$, then we call the induced subgraph $G_1=G_{V_1\\cup\\{0\\}}$ of $G$ an essentially connected component of $G$. Moreover, if $\\widetilde{G}$ is connected, we say that $G$ is essentially connected.\n\\end{definition}\n\nNote that essentially connected components are induced subgraphs which are not necessarily connected components.\n\n\\begin{remark}\nThe graph $G$ in Figure \\ref{figure 123465} is connected but not essentially connected. Thus a connected graph on vertex set $\\{0,1,\\ldots,t\\}$ may not be essentially connected. Further, an essentially connected graph may not be connected also. For example, let $G$ be the simple graph on the vertex set $\\{0,1,2\\}$ obtained from $K_3$ by removing all the edges attached to the root $0$. Clearly, $G$ is essentially connected but not connected. Note that an essentially connected graph $G$ is connected if and only if $G$ has at least one edge attached to the root $0$. \n\\end{remark}\nWe now proceed to prove our main result in this section. We want to understand how the two quantities, determinant of a positive semidefinite matrix $H\\in\\mathcal{G}_n$ and the number of standard monomials of the ideal $\\J_H$ are related.\n\\begin{discussion}\\label{discussion 2.9}\\normalfont\n Notice that by Lemma \\ref{reducing to essential components}, to check whether for a multigraph $G$ the equality $\\K(R/\\M_G^{(1)})=\\det\\widetilde Q_G$ holds, it is enough to check this for its essentially connected components. Suppose $G$ is an  essentially connected multigraph on the vertex set $\\{0,1,\\ldots ,t\\}$. Consider the induced subgraph $\\widetilde G=G_{\\{1,\\ldots ,t\\}}$.\nFind two vertices in $\\widetilde G$ such that the number of edges between them is maximum among the number of edges between any pair of vertices of $\\widetilde G$. Rename these two vertices as $1$ and $2$. Suppose there are $b$ number of edges between them. Now find some $i\\in V(\\widetilde G)$, if exists, such that $i\\notin\\{1,2\\}$ and there are $b$ number of edges from $i$ to both the vertices $1$ and $2$. Rename the vertex $i$ as $3$ and continue this way to find a maximal {\\em clique} (an induced subgraph which is also a complete multigraph) on the vertex set (say) $\\{1,2,\\ldots ,n\\}$ having $b$ number of edges between any two vertices. Then the truncated signless Laplace matrix of $G$ will be of the form\n\\begin{align}\\label{graph to matrix}\n H:=\\widetilde Q_G=\\begin{bmatrix}\n                    \\alpha_1 & \\cdots & b & b & d_{1,1} & d_{1,2} & \\cdots & d_{1,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    b & \\cdots & \\alpha_{n-1} & b & d_{n-1,1} & d_{n-1,2} & \\cdots & d_{n-1,m} \\\\\n                    b & \\cdots & b & \\alpha_n & d_{n,1} & d_{n,2} & \\cdots & d_{n,m} \\\\\n                    d_{1,1} & \\cdots & d_{n-1,1} & d_{n,1} & \\beta_1 & c_{1,2} & \\cdots & c_{1,m} \\\\\n                    d_{1,2} & \\cdots & d_{n-1,2} & d_{n,2} & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    d_{1,m} & \\cdots & d_{n-1,m} & d_{n,m} & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                   \\end{bmatrix}_{t\\times t},\n\\end{align}\nwhere $n+m=t$ with $n\\geq 2$. If $t=n$, then $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$ by Theorem \\ref{rooted edge matrix version}. Therefore, we may assume that $m\\geq 1$. Note that if $\\alpha_i=\\alpha_j=b$ for some $i\\neq j$, then the two vertices $i$ and $j$ will form a connected component of $\\widetilde G$ and hence $G$ will not be essentially connected. Similarly, for $i\\neq j$ we cannot have $\\beta_i=c_{i,j}=\\beta_j$ or $\\alpha_i=d_{i,j}=\\beta_j$. Also, if for some $1\\leq j\\leq m$, $d_{i,j}=b$ for each $1\\leq i\\leq n$, then the set of vertices $\\{1,\\ldots ,n\\}$ will not form a maximal clique. More precisely, the matrix $H$ given in \\eqref{graph to matrix} satisfies the following conditions.\n\n%{\\small\n\\begin{align}\n &\\text{For each}~ i\\in[n]~\\text{and}~j\\in[m],~\\alpha_i\\geq b\\geq 1,~ b\\geq d_{i,j}\\geq 0,~\\beta_j\\geq 1,~\\text{and}~\\beta_j\\geq d_{i,j}.\\label{equation 2.4a}\\\\[1em]\n &\\text{For each}~ i\\in[m],~k\\in[m],\\text{and}~r<i<j,~\\beta_i\\geq c_{i,j},~\\beta_i\\geq c_{r,i}~\\text{and}~b\\geq c_{i,k}.\\label{equation 2.4b}\\\\[1em]\n &\\text{For each}~ i,j\\in[n] ~\\text{and}~ i\\neq j,\\,\\text{either}~ \\alpha_i>b ~\\text{or}~ \\alpha_j>b.\\label{equation 2.4c}\\\\[1em]\n &\\text{For each}~ i,j\\in[m] ~\\text{and}~ i\\neq j,\\,\\text{either}~ \\beta_i>c_{i,j} ~\\text{or}~ \\beta_j>c_{i,j}.\\label{equation 2.4d}\\\\[1em]\n &\\text{For each}~ i\\in[n] ~\\text{and}~ j\\in[m],\\,\\text{either}~ \\alpha_i>d_{i,j}~ \\text{or}~ \\beta_j>d_{i,j}.\\label{equation 2.4e}\\\\[1em]\n  &\\text{For each}~j\\in[m], ~\\text{there exists some}~i\\in[n] ~\\text{such that}~ b\\neq d_{i,j}.\\label{equation 2.4f}\n\\end{align}\n\n% \n% \\begin{subequations}\n% \\begin{equation}\\label{equation 2.4a}\n%  \\text{For each}~ i\\in[n]~\\text{and}~j\\in[m],~\\alpha_i\\geq b\\geq 1,~ b\\geq d_{i,j}\\geq 0,~\\beta_j\\geq 1,~\\text{and}~\\beta_j\\geq d_{i,j}.\n%  \\end{equation}\n%  \\begin{equation}\\label{equation 2.4b}\n%  \\text{For each}~ i\\in[m],~k\\in[m],\\text{and}~r<i<j,~\\beta_i\\geq c_{i,j},~\\beta_i\\geq c_{r,i}~\\text{and}~b\\geq c_{i,k}.\n%  \\end{equation}\n%  \\begin{equation}\\label{equation 2.4c}\n%  \\text{For each}~ i,j\\in[n] ~\\text{and}~ i\\neq j,\\,\\text{either}~ \\alpha_i>b ~\\text{or}~ \\alpha_j>b.\n%  \\end{equation}\n%  \\begin{equation}\\label{equation 2.4d}\n%  \\text{For each}~ i,j\\in[m] ~\\text{and}~ i\\neq j,\\,\\text{either}~ \\beta_i>c_{i,j} ~\\text{or}~ \\beta_j>c_{i,j}.\n%  \\end{equation}\n%  \\begin{equation}\\label{equation 2.4e}\n%  \\text{For each}~ i\\in[n] ~\\text{and}~ j\\in[m],\\,\\text{either}~ \\alpha_i>d_{i,j}~ \\text{or}~ \\beta_j>d_{i,j}.\n%  \\end{equation}\n%  \\begin{equation}\\label{equation 2.4f}\n%   \\text{For each}~j\\in[m], ~\\text{there exists some}~i\\in[n] ~\\text{such that}~ b\\neq d_{i,j}.\n% \\end{equation}\n% \\end{subequations}\n\\end{discussion}\n\\vspace{4mm}\n Our aim is to prove the following theorem. The proof uses Fischer's inequality (Theorem \\ref{FI}) and Theorem \\ref{inequality for multigraph}.\n\\begin{theorem}\\label{required for simple graphs}\n Consider the matrix $H$ given in \\eqref{graph to matrix}. Assume that $H$ satisfies the conditions \\eqref{equation 2.4a} to \\eqref{equation 2.4f}. Suppose $H$ is a positive semidefinite matrix. If $\\K(R_t/\\J_H)=\\det H$, then for each $1\\leq l\\leq m$ we have $d_{r,l}=d_{s,l}$ for $1\\leq r,s\\leq n$.\n\\end{theorem}\n\n\\begin{proof}\n If possible, let $d_{r,l}\\neq d_{s,l}$ for some $l$. Without loss of generality, assume that $l=1$, i.e., $d_{r,1}\\neq d_{s,1}$ for some $1\\leq r<s\\leq n$. We first show that\n\\begin{equation}\\label{equation 2.5}\n\\alpha_i>b~\\text{for all}~i\\in[n].\n\\end{equation}\n If possible, let $\\alpha_i=b$ for some $i\\in[n]$. Without loss of generality, let $\\alpha_n=b$. Then, $\\alpha_i>b$ for each $i<n$ (by the condition \\eqref{equation 2.4c}). Moreover, the ideal $\\J_H$ is generated by the following monomials\n \\begin{align*}\n  x_i^{\\alpha_i-b},x_n^b,y_j^{\\beta_j}&:~1\\leq i<n,~j\\in[m], \\\\\n  x_n^{b-d_{n,j}}y_j^{\\beta_j-d_{n,j}}&:~j\\in[m], \\\\\n  y_i^{\\beta_i-c_{i,j}}y_j^{\\beta_j-c_{i,j}}&:~1\\leq i<j\\leq m.\n \\end{align*}\n Consider the block-diagonal matrix $H_1=\n\\left(\n\\begin{array}{c|c}\nD_{(n-1)\\times (n-1)} &  \\\\\n\n\\hline\n\n & A_{(m+1)\\times(m+1)}\n\\end{array}\n\\right),\n$ where the matrix $D=\\operatorname{diag}[\\alpha_1-b,\\alpha_2-b,\\ldots ,\\alpha_{n-1}-b]$ is diagonal and the matrix $A$ is obtained from $H$ by deleting the rows and columns $\\mathcal{R}_1, \\mathcal{C}_1, \\dots ,\\mathcal{R}_{n-1}, \\mathcal{C}_{n-1}$. We see that the ideal $\\J_{H_1}=\\J_H$. We also have $\\K(R_t/\\J_H)>0$ because of the conditions \\eqref{equation 2.4a}, \\eqref{equation 2.4c} to \\eqref{equation 2.4e}. Thus $\\det H>0$ and hence, $H$ is a positive definite matrix. Applying elementary column and row operations $\\mathcal{C}_1-\\mathcal{C}_n,\\mathcal{R}_1-\\mathcal{R}_n,\\ldots,\\mathcal{C}_{n-1}-\\mathcal{C}_n,\\mathcal{R}_{n-1}-\\mathcal{R}_n$ on $H$ we see that the reduced matrix\n\\begin{align*}\n \\begin{bmatrix}\n                    \\alpha_1-b & \\cdots & 0 & 0 & d_{1,1}-d_{n,1} & d_{1,2}-d_{n,2} & \\cdots & d_{1,m}-d_{n,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    0 & \\cdots & \\alpha_{n-1}-b & 0 & d_{n-1,1}-d_{n,1} & d_{n-1,2}-d_{n,2} & \\cdots & d_{n-1,m}-d_{n,m} \\\\\n                    0 & \\cdots & 0 & b & d_{n,1} & d_{n,2} & \\cdots & d_{n,m} \\\\\n                    d_{1,1}-d_{n,1} & \\cdots & d_{n-1,1}-d_{n,1} & d_{n,1} & \\beta_1 & c_{1,2} & \\cdots & c_{1,m} \\\\\n                    d_{1,2}-d_{n,2} & \\cdots & d_{n-1,2}-d_{n,2} & d_{n,2} & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    d_{1,m}-d_{n,m} & \\cdots & d_{n-1,m}-d_{n,m} & d_{n,m} & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                   \\end{bmatrix}\n\\end{align*}\nis a positive definite matrix. By our assumption $d_{r,1}\\neq d_{s,1}$ for some $1\\leq r<s\\leq n$, we see that $\\det H_1>\\det H$ by Fischer's inequality. The matrix $A$ is also positive definite, since $H$ is positive definite. Hence, $H_1$ is a positive definite matrix because $\\alpha_i> b$ for each $i<n$. By Theorem \\ref{inequality for multigraph}, $\\K(R_t/\\J_{H_1})\\geq\\det H_1$. Thus $\\K(R_t/\\J_H)=\\K(R_t/\\J_{H_1})\\geq\\det H_1>\\det H$, a contradiction. Therefore, the matrix $H$ given in \\eqref{graph to matrix} satisfies the condition \\eqref{equation 2.5}.\n  \nNext we claim the following.\n\\begin{equation}\\label{equation 2.6}\n\\hspace{-4.5cm}\\text{For each}~j\\in[m],~\\text{either} ~\\beta_j>d_{n,j}~\\text{or}~b> d_{n,j}.\n\\end{equation}\n  On the contrary, let $\\beta_j=b=d_{n,j}$ for some $j\\in[m]$. Without loss of generality, assume that $j=1$, i.e., $\\beta_1=b=d_{n,1}$. Then, the ideal $\\J_H$ is generated by the following monomials\n\\begin{align*}\n x_i^{\\alpha_i},x_n^{\\alpha_n-b},y_j^{\\beta_j}:&~1\\leq i< n,~j\\in[m],\\\\\n x_i^{\\alpha_i-b}x_j^{\\alpha_j-b}:&~1\\leq i<j< n,\\\\\n x_i^{\\alpha_i-d_{i,j}}y_j^{\\beta_j-d_{i,j}}:&~1\\leq i< n,~j\\in[m],\\\\\n y_i^{\\beta_i-c_{i,j}}y_j^{\\beta_j-c_{i,j}}:&~1\\leq i<j\\leq m.\n\\end{align*}\n  Let $H_2$ be the matrix obtained from $H$ by replacing the diagonal element $\\alpha_n$ with $\\alpha_n-b$ and all other element of $\\mathcal{R}_n$ and $\\mathcal{C}_n$ with zero. %, i.e.,\n  %\\begin{align*}\n %H_2=\\begin{bmatrix}\n%                    \\alpha_1 & \\cdots & b & 0 & d_{1,1} & d_{1,2} & \\cdots & d_{1,m} \\\\\n%                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n%                    b & \\cdots & \\alpha_{n-1} & 0 & d_{n-1,1} & d_{n-1,2} & \\cdots & d_{n-1,m} \\\\\n %                   0 & \\cdots & 0 & \\alpha_n-b & 0 & 0 & \\cdots & 0 \\\\\n  %                  d_{1,1} & \\cdots & d_{n-1,1} & 0 & b & c_{1,2} & \\cdots & c_{1,m} \\\\\n   %                 d_{1,2} & \\cdots & d_{n-1,2} & 0 & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n    %                \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n     %               d_{1,m} & \\cdots & d_{n-1,m} & 0 & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n      %             \\end{bmatrix}_{t\\times t}.\n%\\end{align*}\n   Then, $\\J_H=\\J_{H_2}$. We have $\\K(R_t/\\J_H)>0$ because of the conditions \\eqref{equation 2.4a}, \\eqref{equation 2.4c} to \\eqref{equation 2.4e}. Thus $\\det H>0$ and hence, $H$ is a positive definite matrix. Applying elementary column and row operations $\\mathcal{C}_n-\\mathcal{C}_{n+1}$ and $\\mathcal{R}_n-\\mathcal{R}_{n+1}$ on $H$ we see that the reduced matrix\n  \\begin{align*}\n  \\begin{bmatrix}\n                    \\alpha_1 & \\cdots & b & b-d_{1,1} & d_{1,1} & d_{1,2} & \\cdots & d_{1,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    b & \\cdots & \\alpha_{n-1} & b-d_{n-1,1} & d_{n-1,1} & d_{n-1,2} & \\cdots & d_{n-1,m} \\\\\n                    b-d_{1,1} & \\cdots & b-d_{n-1,1} & \\alpha_n-b & 0 & d_{n,2}-c_{1,2} & \\cdots & d_{n,m}-c_{1,m} \\\\\n                    d_{1,1} & \\cdots & d_{n-1,1} & 0 & b & c_{1,2} & \\cdots & c_{1,m} \\\\\n                    d_{1,2} & \\cdots & d_{n-1,2} & d_{n,2}-c_{1,2} & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    d_{1,m} & \\cdots & d_{n-1,m} & d_{n,m}-c_{1,m} & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                   \\end{bmatrix}_{t\\times t}\n\\end{align*}\n  is a positive definite matrix. Because of the condition \\eqref{equation 2.4f} we have $b\\neq d_{i,1}$, for some $1\\leq i<n$. Therefore, $\\det H<\\det H_2$ by Fischer's inequality. Since $\\alpha_n> b$ and $H$ is a positive definite matrix, $H_2$ is also positive definite. By Theorem \\ref{inequality for multigraph}, $\\K(R_t/\\J_{H_2})\\geq\\det H_2$. Thus $\\K(R_t/\\J_H)>\\det H$, a contradiction. Hence, the matrix $H$ given in \\eqref{graph to matrix} also satisfies condition \\eqref{equation 2.6}.\n\n  The ideal $\\J_H$ is generated by the monomials\n\\begin{align*}\n x_i^{\\alpha_i},y_j^{\\beta_j}&:~i\\in[n],\\, j\\in[m],\\\\\n x_i^{\\alpha_i-b}x_j^{\\alpha_j-b}&:~1\\leq i<j\\leq n,\\\\\n x_i^{\\alpha_i-d_{i,j}}y_j^{\\beta_j-d_{i,j}}&:~i\\in[n],\\, j\\in[m],\\\\\n y_i^{\\beta_i-c_{i,j}}y_j^{\\beta_j-c_{i,j}}&:~1\\leq i<j\\leq m.\n\\end{align*}\nConsider the block-diagonal matrix $H_3=\n\\left(\n\\begin{array}{c|c}\n\\widehat D_{(n-1)\\times (n-1)} &  \\\\\n\n\\hline\n\n & \\widehat A_{(m+1)\\times(m+1)}\n\\end{array}\n\\right),\n$ where the matrix $\\widehat D=\\operatorname{diag}[\\alpha_1-b,\\alpha_2-b,\\ldots ,\\alpha_{n-1}-b]$ is diagonal and the matrix $\\widehat A$ is obtained from $H$ by deleting the rows and columns $\\mathcal{R}_1, \\mathcal{C}_1, \\dots ,\\mathcal{R}_{n-1}, \\mathcal{C}_{n-1}$ and then replacing the element $\\alpha_n$ with $b$.\n  We see that $(\\J_H:x_n^{\\alpha_n-b})=\\J_{H_3}$. Let $H_4$ be the matrix obtained from $H$ by replacing the diagonal element $\\alpha_n$ with $\\alpha_n-b$ and every other elements $\\mathcal{R}_n$ and $\\mathcal{C}_n$ with zero, i.e., \n   \\begin{align*}\n  H_4=\\begin{bmatrix}\n                     \\alpha_1 & \\cdots & b & 0 & d_{1,1} & d_{1,2} & \\cdots & d_{1,m} \\\\\n                     \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                     b & \\cdots & \\alpha_{n-1} & 0 & d_{n-1,1} & d_{n-1,2} & \\cdots & d_{n-1,m} \\\\\n                     0 & \\cdots & 0 & \\alpha_n-b & 0 & 0 & \\cdots & 0 \\\\\n                     d_{1,1} & \\cdots & d_{n-1,1} & 0 & \\beta_1 & c_{1,2} & \\cdots & c_{1,m} \\\\\n                     d_{1,2} & \\cdots & d_{n-1,2} & 0 & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                     \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                     d_{1,m} & \\cdots & d_{n-1,m} & 0 & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                    \\end{bmatrix}_{t\\times t}.\n \\end{align*}\n  We have $\\J_{H_4}=\\left\\langle \\J_H,x_n^{\\alpha_n-b} \\right\\rangle$. Now, from the short exact sequence of $\\mathbb{K}$-vector spaces,\n \\begin{align*}%\\label{short exact sequence}\n 0\\rightarrow\\frac{R_t}{\\left(\\J_H:x_{n}^{\\alpha_n-b}\\right)}\\xrightarrow{\\mu_{x_{n}^{\\alpha_n-b}}}\\frac{R_t}{\\J_H}\\rightarrow\\frac{R_t}{\\left\\langle \\J_H,x_{n}^{\\alpha_n-b}\\right\\rangle}\\rightarrow 0,\n\\end{align*}\n  we have $\\K(R_t/\\J_H)=\\K(R_t/\\J_{H_3})+\\K(R_t/\\J_{H_4})$. Also, writing $\\alpha_n=(\\alpha_n-b)+b$ and using the additivity property of the determinant, we get $\\det H=\\det H_4+\\det B$, where $B$ is the matrix $H$ except the element $\\alpha_n$ is replaced with $b$. The matrix $H_4$ is positive semidefinite since $H$ is positive semidefinite and $\\alpha_n> b$. By Theorem \\ref{inequality for multigraph}, $\\K(R_t/\\J_{H_4})\\geq\\det H_4$. We also have $\\K(R_t/\\J_{H_3})>0$ because of the conditions \\eqref{equation 2.4a}, \\eqref{equation 2.4d}, \\eqref{equation 2.5} and \\eqref{equation 2.6}. Since $\\K(R_t/\\J_H)=\\det H$ we must have $\\det B>0$. By Lemma \\ref{replacing an element}, $B$ is a positive definite matrix since $\\alpha_n\\geq b$ and $H$ is a positive semidefinite matrix. Applying elementary column and row operations $\\mathcal{C}_1-\\mathcal{C}_n,\\mathcal{R}_1-\\mathcal{R}_n,\\ldots,\\mathcal{C}_{n-1}-\\mathcal{C}_n,\\mathcal{R}_{n-1}-\\mathcal{R}_n$ on $B$ we see that the reduced matrix\n  \\begin{align*}\n \\begin{bmatrix}\n                    \\alpha_1-b & \\cdots & 0 & 0 & d_{1,1}-d_{n,1} & d_{1,2}-d_{n,2} & \\cdots & d_{1,m}-d_{n,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    0 & \\cdots & \\alpha_{n-1}-b & 0 & d_{n-1,1}-d_{n,1} & d_{n-1,2}-d_{n,2} & \\cdots & d_{n-1,m}-d_{n,m} \\\\\n                    0 & \\cdots & 0 & b & d_{n,1} & d_{n,2} & \\cdots & d_{n,m} \\\\\n                    d_{1,1}-d_{n,1} & \\cdots & d_{n-1,1}-d_{n,1} & d_{n,1} & \\beta_1 & c_{1,2} & \\cdots & c_{1,m} \\\\\n                    d_{1,2}-d_{n,2} & \\cdots & d_{n-1,2}-d_{n,2} & d_{n,2} & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    d_{1,m}-d_{n,m} & \\cdots & d_{n-1,m}-d_{n,m} & d_{n,m} & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                   \\end{bmatrix}\n\\end{align*}\nis a positive definite matrix. Since $d_{r,1}\\neq d_{s,1}$ for some $1\\leq r<s\\leq n$, we have $\\det B<\\det H_3$, by Fischer's inequality. The matrix $H_3$ is positive definite since $B$ is a positive definite matrix and $\\alpha_i> b$ for $1\\leq i<n$. By Theorem \\ref{inequality for multigraph}, $\\K(R_t/\\J_{H_3})\\geq\\det H_3$. Thus $\\K(R_t/\\J_H)\\geq\\det H_3+\\det H_4>\\det B+\\det H_4=\\det H$, a contradiction, and this proves the theorem. \\qed\n\\end{proof}\n\n\\vspace{4mm}\n  In view of Theorem \\ref{RC}, if $G$ is a simple graph on the vertex set $\\{0,1,\\ldots ,n\\}$, obtained from a complete simple graph $K_{n+1}$ by deleting some edges through the root $0$, then $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$. Furthermore, by Lemma \\ref{reducing to essential components}, in order to check for a graph $G$ when the equality $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$ holds we just need to check for its essentially connected components. Now as a consequence of Theorem \\ref{required for simple graphs} we can characterize all simple graphs $G$ which satisfy the property $\\K(R_n/\\M_{G}^{(1)})=\\det\\widetilde Q_G$. More generally, we prove the following:\n  \n  \\begin{theorem}\\label{for simple graph having multiple rooted edges}\n  Let $G$ be a subgraph of the complete multigraph $K_{n+1}^{a,1}$ on the vertex set $\\{0,1,\\ldots ,n\\}$. The graph $G$ satisfies $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$ if and only if each essentially connected component $G_i$ of $G$ with $|V(G_i)|=n_i$, is obtained from a complete multigraph $K_{n_i+1}^{a_i,1}$ by deleting some edges through the root $0$.\n  \\end{theorem}\n  \n  \\begin{proof}\n    First suppose that $G$ is an essentially connected subgraph of the complete multigraph $K_{n+1}^{a,1}$ such that $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$. We proceed in same line as in Discussion \\ref{discussion 2.9}. Suppose $\\widetilde G$ is the induced subgraph $G_{\\{1,\\ldots ,n\\}}$ of $G$. We find two vertices in $\\widetilde G$ such that there is an edge between them and rename these two vertices as $1$ and $2$. Now find another vertex (if it exists) which has edges connecting both $1$ and $2$. Rename the new vertex as $3$ and continue this way to find a maximal clique on the vertex set say $\\{1,2,\\ldots ,r\\}$ for $r\\leq n$. The truncated signless Laplace matrix of $G$ will be of the form\n    \n    \\begin{align*}%\\label{graph to matrix}\n \\widetilde Q_G=\\begin{bmatrix}\n                    \\alpha_1 & \\cdots & 1 & 1 & d_{1,1} & d_{1,2} & \\cdots & d_{1,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    1 & \\cdots & \\alpha_{r-1} & 1 & d_{r-1,1} & d_{r-1,2} & \\cdots & d_{r-1,m} \\\\\n                    1 & \\cdots & 1 & \\alpha_r & d_{r,1} & d_{r,2} & \\cdots & d_{r,m} \\\\\n                    d_{1,1} & \\cdots & d_{r-1,1} & d_{r,1} & \\beta_1 & c_{1,2} & \\cdots & c_{1,m} \\\\\n                    d_{1,2} & \\cdots & d_{r-1,2} & d_{r,2} & c_{1,2} & \\beta_2 & \\cdots & c_{2,m} \\\\\n                    \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n                    d_{1,m} & \\cdots & d_{r-1,m} & d_{r,m} & c_{1,m} & c_{2,m} & \\cdots & \\beta_m\n                   \\end{bmatrix}_{n\\times n},\n\\end{align*}\n  where $r+m=n$, and for each $1\\leq j\\leq m$ there exists some $i\\in[r]$ such that $d_{i,j}=0$. Since $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$, we must have $d_{i,j}=0$ for all $i$ and $j$, by Theorem \\ref{required for simple graphs}. Hence, we have $r=n$ since $G$ is essentially connected. Thus $G$ is obtained from a complete multigraph $K_{n+1}^{a,1}$ by deleting some edges through the root $0$.\n\n  If $G$ is a subgraph of $K_{n+1}^{a,1}$ and $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$, then by Lemma \\ref{reducing to essential components} and the above discussion we see that each essential component $G_i$ of $G$ is obtained from a complete multigraph $K_{n_i+1}^{a_i,1}$ by deleting some edges through the root $0$. \n  \n  The converse follows from Lemma \\ref{reducing to essential components} and Theorem \\ref{rooted edge matrix version}. \\qed\n  \\end{proof}\n  \\vspace{4mm}\n  \n  Thus for simple graphs we have the following result:\n  \\begin{corollary}\\label{simple graph result}\n    Let $G$ be a simple graph  on $n+1$ vertices $\\{0,1,\\ldots,n\\}$. For the graph $G$, $\\K(R_n/\\M_G^{(1)})=\\det\\widetilde Q_G$ holds if and only if each essentially connected component $G_i$ of $G$ with $|V(G_i)|=n_i$, is obtained from a complete simple graph $K_{n_i+1}$ by deleting some edges through the root $0$.\n  \\end{corollary}\n  \n  \\begin{proof}\n   Taking $a=1$ in Theorem \\ref{for simple graph having multiple rooted edges} we get our result. \\qed\n  \\end{proof}\n  \n  \\vspace{4mm}\n  In the last part of this section we discuss a graph-theoretical interpretation of $\\det\\Q_G$ following Dochtermann \\cite{Do}. Recall that the determinant of the truncated Laplace matrix $\\widetilde L_G$ count the number of spanning trees of $G$. A spanning tree $T$ of $G$ is a connected spanning subgraph of $G$ which is acyclic, i.e., $T$ is a tree with vertex set $V(T)=V(G)$. For the matrix $\\Q_G$, the determinant is expressed in terms of certain $TU$-subgraphs of $G$.\n   \n   A $TU$-{\\it subgraph} is a subgraph of $G$ whose connected components are trees or unicyclic graphs with odd cycles. Thus a tree $T\\subseteq G$ is also a $TU$-subgraph of $G$. In Figure \\ref{figure 122465} below we provide examples of two spanning $TU$-subgraphs of $K_5$ which are not trees.  \n   \n   \n   \\begin{figure}[h!]\n\\centering\n\\begin{tikzpicture}\n[scale=.55]\n\\draw [fill] (0,0) circle [radius=0.1];\n\\draw [fill] (2,0) circle [radius=0.1];\n\\draw [fill] (3,1.5) circle [radius=0.1];\n\\draw [fill] (1,3) circle [radius=0.1];\n\\draw [fill] (-1,1.5) circle [radius=0.1];\n\\node at (-0.5,-0.3) {$2$};\n\\node at (2.5,-0.3) {$3$};\n\\node at (3.5,1.8) {$4$};\n\\node at (1,3.6) {$0$};\n\\node at (-1.5,1.9) {$1$};\n\\draw (1,3)--(-1,1.5);\n\\draw (0,0)--(2,0)--(3,1.5)--(0,0);\n\\draw [fill] (9,0) circle [radius=0.1];\n\\draw [fill] (11,0) circle [radius=0.1];\n\\draw [fill] (12,1.5) circle [radius=0.1];\n\\draw [fill] (10,3) circle [radius=0.1];\n\\draw [fill] (8,1.5) circle [radius=0.1];\n\\node at (8.5,-0.3) {$2$};\n\\node at (11.5,-0.3) {$3$};\n\\node at (12.5,1.8) {$4$};\n\\node at (10,3.6) {$0$};\n\\node at (7.5,1.9) {$1$};\n\\draw (8,1.5)--(12,1.5);\n\\draw (8,1.5)--(9,0)--(11,0)--(8,1.5);\n\\end{tikzpicture}\\caption{Two $TU$-subgraphs of $K_5$.}\\label{figure 122465}\n\\end{figure}\n\n\\begin{proposition}\\textup{\\cite[Proposition 3.5]{Do}}\n For any graph $G$ the determinant of $\\Q_G$ is given by\n \\[\n  \\det\\Q_G=\\sum_{H}4^{c(H)}\n \\]\nwhere the summation runs over all the spanning $TU$-subgraphs $H$ of $G$ with $c(H)$ unicyclic components, and one tree component which contains the vertex $0$.\n\\end{proposition}\nLet $G$ be a simple graph such that $\\K(R/\\M_G^{(1)})=\\det\\Q_G$. By Corollary \\ref{simple graph result}, each essentially connected component of $G$ is obtained from a complete simple graph by removing some rooted edges. For such a $G$, a bijective proof of $\\K(R/\\M_G^{(1)})=\\det\\Q_G$ would therefore assign each spanning $TU$-subgraph $H$ of $G$ to a collection of $4^{c(H)}$ standard monomials of $R/\\M_G^{(1)}$. If $H$ is a spanning tree of $G$, then $c(H)=0$. Thus a spanning tree would be associated to $4^0=1$ standard monomial of $R/\\M_G^{(1)}$. Note that the standard monomials of $R/\\M_G$ are in bijection with the spanning trees of $G$. Since $\\M_G^{(1)}\\subset\\M_G$, the standard monomials of $R/\\M_G$ are among the standard monomials of $R/\\M_G^{(1)}$. Thus a (weighted) bijection between $TU$-subgraphs of $G$ and standard monomials of $R/\\M_G^{(1)}$ would presumably extend a bijection between the $G$-parking functions and spanning trees (see \\cite{Do} for more in this direction).\n\n\\vspace{4mm}\n  \\noindent\n  {\\bf Acknowledgements:} I am grateful to Prof. Chanchal Kumar for introducing me to these problems and for his support. Many thanks to Abhay Soman and Sushil Bhunia for some helpful discussions and their suggestions. The financial support is provided by CSIR, Govt. of India.\n  \n  \\begin{thebibliography}{99}\n  \\bibitem{BaNo} Baker M. and Norine S., {\\em Riemann-Roch and Abel-Jacobi theory on a finite graph.} Adv. Math. {\\bf 215}, (2007), 766-788.\n  \n  \\bibitem{BaSh} Baker M. and Shokriech F., {\\em Chip-firing games, potential theory on graphs, and spanning trees.} J. Combin. Theory Ser. A, {\\bf 120}, (2013), 164-182.\n  \n  \\bibitem{Do} Dochtermann A., {\\em One-skeleta of $G$-parking function ideals: resolutions and standard monomials}, arXiv:1708.04712,2017.\n  \n  \\bibitem{GH} Gaydarov P. and Hopkins S., {\\em Parking functions and tree inversions revisited.}, Adv. in Appl. Math. {\\bf 80}, (2016), 151-179.\n  \n  \\bibitem{HJ} Horn R. and Johnson C. {\\em Matrix Analysis.}, Second edition. Cambridge University Press, Cambridge, (2013), xviii+643 pp.\n  \n  \\bibitem{KW} Konheim A. and Weiss B., {\\em An occupancy discipline and applications.}, SIAM J. Appl. Math. {\\bf 14}, (1966), 1266-1274.\n  \n  \\bibitem{KLR} Kumar C., Lather G. and Roy A. {\\em Standard monomials of $1$-skeleton ideals of graphs and their signless Laplace matrices}, arXiv:2006.02347,2020.\n  \n  \\bibitem{KLS} Kumar C., Lather G. and Sonica {\\em Skeleton ideals of certain graphs, standard monomials and spherical parking functions}, arXiv:2004.13814,2020.\n  \n  \\bibitem{PYY} Perkinson D., Yang Q. and Yu K., {\\em $G$-parking functions and tree inversions}, Combinatorica {\\bf 37} (2017), 269-282.\n  \n  \\bibitem{PS} Postnikov A. and Shapiro B., {\\em Trees, parking functions, syzygies, and deformations of monomial\n  ideals}, Trans. Amer. Math. Soc. {\\bf 356} (2004), 3109-3142.\n  \n  \\bibitem{RS} Stanley R. {\\em Enumerative combinatorics. Vol. 2}, Cambridge University Press, Cambridge, (1999). With a foreward by Gian-Carlo Rota and appendix by Sergey Fomin.\n \\end{thebibliography} \n%\\bibliographystyle{plain}\n%\\bibliography{biblio}\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:36", "yymm": "2010", "arxiv_id": "2010.14474", "url": "https://arxiv.org/abs/2010.14474", "source": "arxiv"}}
{"text": "\\newif\\ifIEEE\n\\newif\\ifPAGELIMIT\n\\IEEEtrue\n%%\\IEEEfalse\n\\PAGELIMITfalse\n%%\\PAGELIMITtrue\n\\ifPAGELIMIT\n\\IEEEtrue\n\\fi\n\\ifIEEE\n    \\ifPAGELIMIT\n        \\documentclass[conference,final,letterpaper]{IEEEtran}\n    \\else   \n        \\documentclass[journal,final,letterpaper]{IEEEtran}\n    \\fi\n    % Bibliography\n    \\newcommand{\\bibauthor}[1]{#1}\n    \\newcommand{\\bibpaper}[1]{``#1''}\n    \\newcommand{\\Footnotetext}[2]\n    {\n        \\begin{figure}[!b]\n        \\footnotesize\\vspace{-3ex}\\hrulefill\\hfill\n        \\makebox[0em]{}\\hfill\\makebox[0em]{}%\n                                          \\par${}^{#1}$ #2\\vspace{-.6ex}\n        \\end{figure}\n        \\addtocounter{figure}{0}\n     }\n\\else\n    \\documentclass[12pt]{article}\n    \\sloppy \n    \\textheight8.5in\n    \\textwidth6.5in\n    \\hoffset -0.6in\n    \\voffset -0.6in\n    \\parskip 8pt\n    \\newcommand{\\bibauthor}[1]{\\textsc{#1}}\n    \\newcommand{\\bibpaper}[1]{\\textsl{#1}}\n    \\newenvironment{IEEEkeywords}{\\begin{small}%\n                                  \\textbf{Index Terms} ---}{\\end{small}}\n\\fi\n\\usepackage{amsfonts,bm}\n\\usepackage{amsthm,amsmath}\n\\usepackage{pict2e}\n\\usepackage{color}\n%%\\usepackage{refcheck}\n\\newcommand{\\bibbook}[1]{\\textit{#1}}\n\\newcommand{\\bibpatent}[1]{\\textit{#1}}\n\\newcommand{\\bibperiodical}[1]{\\textit{#1}}\n\\newcommand{\\bibhyperlink}[1]{\\textsl{#1}}\n\\ifPAGELIMIT\n    \\setlength{\\abovedisplayskip}{1.0ex plus 3pt minus 1pt}\n    \\setlength{\\belowdisplayskip}{\\abovedisplayskip}\n    \\setlength{\\abovedisplayshortskip}{0pt plus 3pt}\n    \\setlength{\\belowdisplayshortskip}{1.0ex plus 3pt minus 1pt}\n    \\setlength{\\textfloatsep}{10pt plus 1pt minus 2pt}\n\\fi\n\\newtheorem{theorem}{\\indent Theorem}\n\\newtheorem{proposition}[theorem]{\\indent Proposition}\n\\newtheorem{lemma}[theorem]{\\indent Lemma}\n\\newtheorem{corollary}[theorem]{\\indent Corollary}\n\\newtheorem{problem}{\\indent Problem}\n\\theoremstyle{remark}\n\\newtheorem{remark}{\\indent Remark}\n\\theoremstyle{definition}\n\\newtheorem{example}{\\indent Example}\n\\renewcommand{\\mathbf}[1]{{\\bm{#1}}}     % Use italics-bold in formulas\n%\n\\newlength{\\figunit}\n\\setlength{\\figunit}{0.48mm}\n\\definecolor{gray}{rgb}{0.5,0.5,0.5}\n\\definecolor{brown}{rgb}{0.7,0.4,0.4}\n\\newcommand{\\figfont}{\\normalsize}\n\\newcommand{\\bldone}{{\\mathbf{1}}}\n\\newcommand{\\bldc}{{\\mathbf{c}}}\n\\newcommand{\\bldell}{{\\mathbf{\\ell}}}\n\\newcommand{\\bldy}{{\\mathbf{y}}}\n\\newcommand{\\bldY}{{\\mathbf{Y}}}\n\\newcommand{\\bldz}{{\\mathbf{z}}}\n\\newcommand{\\bldd}{{\\mathbf{d}}}\n\\newcommand{\\bldw}{{\\mathbf{w}}}\n\\newcommand{\\bldpi}{{\\mathbf{\\pi}}}\n\\newcommand{\\bldvartheta}{{\\mathbf{\\vartheta}}}\n\\newcommand{\\bldeta}{{\\mathbf{\\eta}}}\n\\newcommand{\\bldzeta}{{\\mathbf{\\zeta}}}\n\\newcommand{\\code}{{\\mathcal{C}}}\n\\newcommand{\\varcode}{{\\mathsf{C}}}\n\\newcommand{\\Code}{{\\mathbb{C}}}\n\\newcommand{\\entropy}{{\\mathsf{H}}}\n\\newcommand{\\Local}{{\\mathcal{R}}}\n\\newcommand{\\Ambient}{{\\mathsf{A}}}\n\\newcommand{\\Set}{{\\mathcal{X}}}\n\\newcommand{\\Subset}{{\\mathsf{B}}}\n\\newcommand{\\AltSet}{{\\mathcal{S}}}\n\\newcommand{\\Typical}{{\\mathcal{T}}}\n\\newcommand{\\YY}{{\\mathcal{Y}}}\n\\newcommand{\\InfSet}{{\\mathcal{L}}}\n\\newcommand{\\SupSet}{{\\mathcal{U}}}\n\\newcommand{\\Support}{{\\mathsf{Supp}}}\n\\newcommand{\\Integers}{{\\mathbb{Z}}}\n\\newcommand{\\Finitefield}{{\\mathbb{F}}}\n\\newcommand{\\Realfield}{{\\mathbb{R}}}\n\\newcommand{\\Rate}{{\\mathsf{\\textsl{R}}}}\n\\newcommand{\\x}{s}\n\\newcommand{\\Interval}{{\\mathcal{I}}}\n\\newcommand{\\LP}{{\\mathrm{LP}}}\n\\newcommand{\\CM}{{\\mathrm{CM}}}\n\\newcommand{\\SP}{{\\mathrm{SP}}}\n\\newcommand{\\LRC}{{\\mathrm{LRC}}}\n\\newcommand{\\opt}{{\\mathrm{opt}}}\n\\newcommand{\\Prob}{{\\mathsf{Prob}}}\n\\newcommand{\\Expected}{{\\mathbb{E}}}\n\\newcommand{\\weight}{{\\mathsf{w}}}\n\\newcommand{\\distance}{{\\mathsf{d}}}\n\\newcommand{\\bigcupdot}%\n                 {{\\textstyle{\\bigcup\\!\\!\\!\\!\\!\\hspace{0.25ex}\\cdot\\;}}}\n\\ifPAGELIMIT\n    \\newcommand{\\Theorem}{Thm.}\n    \\newcommand{\\Theorems}{Thms.}\n    \\newcommand{\\Proposition}{Prop.}\n    \\newcommand{\\Propositions}{Props.}\n\\else\n    \\newcommand{\\Theorem}{Theorem}\n    \\newcommand{\\Theorems}{Theorems}\n    \\newcommand{\\Proposition}{Proposition}\n    \\newcommand{\\Propositions}{Propositions}\n\\fi\n\n\\newcommand{\\Title}{Asymptotic Bounds on the Rate of\n                                               Locally Repairable Codes}\n\\newcommand{\\Namea}{Ron M. Roth}\n\\newcommand{\\Addressa}{Computer Science Department}\n\\newcommand{\\Addressatwo}{Technion, Haifa 3200003, Israel}\n\\newcommand{\\Membershipa}{, \\IEEEmembership{Fellow, IEEE}}\n\\newcommand{\\Emaila}{ronny@cs.technion.ac.il}\n\\newcommand{\\Grant}{This work was supported by \n                    Grants~1396/16 and 1713/20 from\n                    the Israel Science Foundation.}\n%%\\newcommand{\\Copyright}{Copyright \\textcopyright\\ 2019 IEEE.\n            %%Personal use of this material is permitted. \n            %%Permission from IEEE must be obtained for all other uses.}\n\\newcommand{\\Thnxa}{\\Namea\\ is with the \\Addressa, \\Addressatwo.\n                    Email: \\Emaila}\n\\newenvironment{OPENPROBLEM}{\\color{blue}}{\\color{black}}\n\n\\begin{document}\n\\ifIEEE\n    \\title{\\Title}\n       \\ifPAGELIMIT\n           \\author{\\IEEEauthorblockN{\\Namea\\vspace{-1ex}}\\\\\n                   \\IEEEauthorblockA{\\Addressa,\n                                     \\Addressatwo\\\\\n                                     \\Emaila\\vspace{-2ex}}\n           }\n       \\else\n           \\author{\\Namea%%\\Membershipa\n                   \\thanks{\\Grant}\n                   \\thanks{\\Thnxa}\n           }\n       \\fi\n\\else\n    \\title{\\textbf{\\Title}\\thanks{\\Grant}}\n    \\author{\\textsc{\\Namea}\\thanks{\\Thnxa}}\n    \\date{}\n\\fi\n\\maketitle\n% \\pagestyle{empty} alone does not remove the numbering of the title\n%  page in the two-column mode\n%%\\ifIEEE  \\thispagestyle{empty}  \\fi\n\n\\begin{abstract}\nNew asymptotic upper bounds are presented on the rate\nof sequences of locally repairable codes (LRCs)\nwith a prescribed relative minimum distance and locality\nover a finite field $F$.\nThe bounds apply to LRCs in which\nthe recovery functions are linear;\nin particular, the bounds apply to linear LRCs over $F$.\nThe new bounds are shown to improve on previously published\nresults, especially when the repair groups are\n\\ifPAGELIMIT\n    disjoint.\n\\else\ndisjoint,\nnamely, they form a partition of the set of coordinates.\n\\fi\n\\end{abstract}\n\n\\ifPAGELIMIT\n\\else\n\\begin{IEEEkeywords}\nLarge deviations,\nLinear-programming bound,\nLocally repairable codes,\nSphere-packing bound.\n\\end{IEEEkeywords}\n\\fi\n\n\\ifPAGELIMIT\n    \\Footnotetext{\\quad}{\\Grant}\n\\fi\n\n\\section{Introduction}\n\\label{sec:introduction}\n\nHereafter, we fix $F$ to be a finite field\n\\ifPAGELIMIT\n    $\\Finitefield_q$.\n\\else\n$\\Finitefield_q$ (of size $q$).\n\\fi\nFor a positive integer $a$, we denote by $[a]$ the integer set\n$\\{ 1, 2, \\ldots, a \\}$.\nFor a word (vector) $\\bldy \\in F^N$\nand a nonempty subset $\\Local \\subseteq [N]$, we let $(\\bldy)_\\Local$\ndenote the sub-word of $\\bldy$ that is indexed by $\\Local$.\n\nAn $(N,M,d)$ code of length over $F$ is\na nonempty subset $\\varcode \\subseteq F^N$ of size $M$\nand minimum (Hamming) distance $d$.\nThe rate of the code is $R = (\\log_q M)/N$\nand its relative minimum distance (r.m.d.) is $d/N$.\nWhen $\\varcode$ is linear over $F$ we will use the standard notation\n$[N,k,d]$ where $k = \\log_q M$ is the dimension of $\\varcode$.\nFor a nonempty subset $\\Local \\subseteq [N]$,\nwe let $(\\varcode)_\\Local$ be the punctured code\n$\\{ (\\bldc)_\\Local \\,:\\, \\bldc \\in \\varcode \\}$.\n\nWe say that an $(N,M,d)$ code $\\varcode$ over $F$ is\na \\emph{locally repairable code} (in short, LRC) with locality $r$\nif for every coordinate $j \\in [N]$\nthere is a subset\n\\[\n\\Local_j = \\Local_j^* \\; \\bigcupdot \\; \\{ j \\} \\subseteq [N]\n\\]\nof size at most $n = r+1$ (that contains $j$)\nsuch that for every codeword $\\bldc = (c_t)_{t \\in [N]}$,\nthe value $c_j$ is uniquely determined from\n$(\\bldc)_{\\Local_j^*}$. In other words,\nthere is a \\emph{recovery function}\n$\\varphi_j : F^{|\\Local_j^*|} \\rightarrow F$ such that\n\\ifPAGELIMIT\n    $c_j = \\varphi_j \\bigl( (\\bldc)_{\\Local_j^*} \\bigr)$.\n\\else\n\\begin{equation}\n\\label{eq:recoveryfunction}\nc_j = \\varphi_j \\left( (\\bldc)_{\\Local_j^*} \\right) .\n\\end{equation}\n\\fi\nThe set $\\Local_j$ is called the \\emph{repair group}\nof $j$ and $(\\varcode)_{\\Local_j}$ is the respective constituent code.\n\\ifPAGELIMIT\n\\else\nClearly, the constituent code $(\\varcode)_{\\Local_j}$ cannot\ncontain two codewords that differ only on position $j$.\n\\fi\n%%Moreover, if $\\Local_j$ is a minimal repair group for $j$\n%%(in the sense that no proper subset of it is a repair group for $j$)\n%%then the minimum distance of $(\\varcode)_{\\Local_j}$\n%%is at least $2$ when $q = 2$ or when $\\varcode$ is linear.\nRepair groups will usually be represented as\na list $(\\Local_j)_{j=1}^N$, where each repair group is indexed by\nthe coordinate $j \\in [N]$ that it corresponds to.\\footnote{%\n\\label{footnote:locality}%\nOccasionally, however, we will refer to the set of \\emph{distinct}\nrepair groups within this list; we will then use\nthe notation $\\{ \\Local_j \\}_{j \\in [\\ell]}$,\nwhere $\\ell$ is the number of such repair\n\\ifPAGELIMIT\n    groups.\n\\else\ngroups (this notation implicitly assumes that the first $\\ell$\ncoordinates of $\\varcode$ are associated with distinct repair groups).\nNote that a list of repair groups of an LRC $\\varcode$---and, therefore,\nthe set of distinct repair groups in such a list---may not be\nunique. Yet such a list (or set) always covers\nall the coordinates of $\\varcode$.%\n\\fi}\n\nWhen the recovery functions $\\varphi_j$ are\n\\ifPAGELIMIT\n    all linear over $F$,\n\\else\nlinear over $F$ for all $j \\in [N]$,\n\\fi\nwe say that the LRC $\\varcode$ is \\emph{linearly recoverable}.\nIn this case, each constituent code $(\\varcode)_{\\Local_j}$ is\na subcode of\na linear $[|\\Local_j|,|\\Local_j|{-}1]$ code over $F$.\nIf $\\varcode$ is a linear code over $F$ then\nit is also linearly recoverable~\\cite[Lemma~10]{ABHMT}.\nThe LRC $\\varcode$ is said to be \\emph{all-disjoint}\nif it has a list of repair groups $(\\Local_j)_{j=1}^N$\n\\ifPAGELIMIT\n    such that the set of distinct repair groups forms\n    a partition of $[N]$.\n\\else\nthat satisfies\n$\\Local_j \\cap \\Local_{j'} \\in \\{ \\emptyset, \\Local_j, \\Local_{j'} \\}$\nfor all $j, j' \\in [N]$. By possibly adding dummy elements\nto repair groups, this definition is equivalent to requiring\nthat no two distinct repair groups intersect; in this case,\nthe set of distinct repair groups $\\{ \\Local_j \\}_j$\nforms a partition of $[N]$.\nIn the all-disjoint case, each repair group $\\Local_j$ is also\na repair group for all $j' \\in \\Local_j$ and, so,\neach constituent code has minimum distance${} \\ge 2$.\n\\fi\n\nThe general study of LRCs was initiated in~\\cite{GHSY} and~\\cite{PD},\nand has generated an extensive body of literature since,\nincluding constructions of LRCs, bounds on their parameters,\nand studies of additional attributes, such as availability\nand local minimum distance of the constituent codes; see\n\\cite{ABHMT},\n\\cite{BK},\n\\cite{Blaum},\n\\cite{CM},\n\\cite{GFY},\n\\cite{GFWH},\n\\cite{GJX},\n\\cite{HYS},\n\\cite{HYUS},\n\\cite{MG},\n\\cite{PHO},\n\\cite{PKLK},\n\\cite{TB},\n\\cite{WZ},\n\\cite{WZL}.\n\nIn this work, we will be interested in asymptotic upper bounds on\nthe rate of linearly recoverable LRCs with prescribed r.m.d.\\ and\nlocality, as the code length tends to\n\\ifPAGELIMIT\n    infinity.\n\\else\ninfinity.\\footnote{%\nWhile our results are stated for linearly recoverable LRCs,\nwe shall only use the fact\nthat each recovery function $\\varphi_j$ in~(\\ref{eq:recoveryfunction})\npreserves the addition of the field $F$.\nHence, our results apply more generally to the case where $F$\nis a finite Abelian group and each $\\varphi_j$\nis a homomorphism from $F^{|\\Local_j^*|}$ to $F$.}\n\\fi\n\nHereafter, by an infinite sequence of codes over $F$\nwe mean a sequence $(\\varcode_i)_{i=1}^\\infty$,\nwhere each $\\varcode_i$ is an $(N_i,M_i,d_i)$ code over $F$\nand the length sequence $(N_i)_{i=1}^\\infty$ is strictly increasing.\nThe rate and the r.m.d.\\ of the sequence are defined, respectively,\nas $R = \\varlimsup_{i \\rightarrow \\infty} R_i$\nand $\\delta = \\varliminf_{i \\rightarrow \\infty} d_i/N_i$.\nThe supremum over all the rates of sequences of codes\nwith r.m.d.${} \\ge \\delta$ will be denoted by $\\Rate_\\opt(\\delta)$.\nGiven $\\omega \\in [0,1]$, we let $\\Rate_\\opt(\\delta,\\omega)$\nbe such a supremum for sequences $(\\varcode_i)_{i=1}^\\infty$\nof constant-weight codes, with the codewords of each $\\varcode_i$\nall having the same weight $w_i$, such that\n$\\lim_{i \\rightarrow \\infty} w_i/N_i = \\omega$.\nThere are several known upper bounds on\n$\\Rate_\\opt(\\delta)$ and $\\Rate_\\opt(\\delta,\\omega)$,\nand the best known are obtained using\nthe linear-programming method\n\\cite{Aaltonen},\n\\cite{BHL1},\n\\cite{MRRW}.\nIn particular, it is known that\n$\\Rate_\\opt(\\delta,\\omega) = \\Rate_\\opt(\\delta) = 0$\nwhen $\\delta \\ge (q{-}1)/q$;\nhence, we will implicitly assume hereafter that $\\delta < (q{-}1)/q$.\n\\ifPAGELIMIT\n\\else\nIt is also easy to see that $\\Rate_\\opt(\\delta,\\omega) = 0$\nwhen $\\omega < \\delta/2$.\n\\fi\nThe upper bounds on the rate of LRCs which are considered\nin this work will often be expressions that involve\n$\\Rate_\\opt(\\delta)$ or $\\Rate_\\opt(\\delta,\\omega)$;\nconcrete upper bounds for LRCs can then be obtained\nby replacing these terms with any upper bound on them.\n\nA \\emph{$(\\delta,n)$-LRC sequence} over $F$\nis an infinite sequence of LRCs $(\\varcode_i)_{i=1}^\\infty$ over $F$\nwith r.m.d.${} \\ge \\delta$\nwhere each LRC $\\varcode_i$ has locality $r = n-1$.\nThe sequence is said to be all-disjoint\nif each $\\varcode_i$ is all-disjoint,\nand it is linearly recoverable (respectively, linear)\nif so is each $\\varcode_i$.\nIt follows from the results of~\\cite{GHSY} and~\\cite{PD}\nthat the rate $R$ of any $(\\delta,n)$-LRC sequence\nis bounded from above by\n\\begin{equation}\n\\label{eq:Singleton}\nR \\le \\frac{n{-}1}{n} \\cdot (1 - \\delta) .\n\\end{equation}\nThis bound, which is oblivious to the field size,\n\\ifPAGELIMIT\n\\else\ncan be seen as the LRC counterpart of the Singleton bound, and it\n\\fi\napplies generally to $(\\delta,n)$-LRC sequences\n(which are not necessarily all-disjoint or linearly recoverable).\nThe bound~(\\ref{eq:Singleton}) was improved\nin~\\cite[\\Theorem~1]{CM} to\n$R \\le \\Rate_\\CM(\\delta,n)$, where\n\\begin{equation}\n\\label{eq:CM}\n\\Rate_\\CM(\\delta,n)\n= \\min_{\\tau \\in [0,1{-}\\delta]}\n\\left\\{ \n\\tau \\cdot \\frac{n{-}1}{n}\n+ (1{-}\\tau) \\cdot \\Rate_\\opt \\left( \\frac{\\delta}{1{-}\\tau} \\right)\n\\right\\} .\n\\end{equation}\nThis bound, which depends on the field size,\ncoincides with~(\\ref{eq:Singleton})\nwhen $\\delta \\mapsto \\Rate_\\opt(\\delta)$ is taken to be\nthe Singleton bound $\\delta \\mapsto 1 - \\delta$.\nSmall improvements to~(\\ref{eq:CM})\nwere obtained\n\\ifPAGELIMIT\n    in~\\cite{ABHMT}.\n\\else\nin~\\cite{ABHMT}; the latter paper considered\nthe more general setting where the constituent codes\n$(\\varcode)_{\\Local_j}$ have a prescribed minimum distance $\\rho \\ge 2$ \n(see also \\cite{GFWH}).\n\\fi\nFor non-asymptotic improvements, see~\\cite{WZL}.\n\nFor reference, we also mention the Gilbert--Varshamov-type\n\\emph{lower} bound on the largest attainable rate of LRC sequences:\nit was shown in~\\cite[\\Theorem~2]{CM} and~\\cite[\\Theorem~B]{TBF}\nthat there exists\nan all-disjoint linear $(\\delta,R)$-LRC sequence of rate\n\\begin{equation}\n\\label{eq:R0}\nR \\ge \\Rate_0(\\delta,n) = \\frac{n{-}1}{n}\n- \\lambda \\left( \\delta,n \\right) ,\n\\end{equation}\nwhere $\\lambda(\\omega,n)$ is defined\nfor every $n \\in \\Integers^+$ and $\\omega \\in \\Realfield_{\\ge 0}$ by\n\\begin{eqnarray}\n\\lefteqn{\n\\lambda(\\omega,n)\n= \\lambda_q(\\omega,n)\n= \\inf_{z \\in (0,1]} \n\\Bigl\\{\n-\\omega \\log_q z - \\frac{1}{n}\n} \\makebox[0ex]{} \\nonumber \\\\\n\\label{eq:lambda}\n&& {} + \\frac{1}{n}\n\\log_q \\Bigl( (1 + (q{-}1)z)^n + (q{-}1)(1{-}z)^n \\Bigr)\n\\Bigr\\} .\n\\end{eqnarray}\nThe function $\\omega \\mapsto \\Rate_0(\\omega,n)$ will play a role in\nour results as well. The expression $\\lambda(\\omega,n)$\nis the growth rate of the volume of a ball\nof radius $\\omega N$ in the subspace of $F^N$\nformed by the Cartesian product of copies of the $[n,n{-}1,2]$\nparity code over $F$, as\n\\ifPAGELIMIT\n    $N \\rightarrow \\infty$.\n\\else\n$N \\rightarrow \\infty$.\\footnote{%\nThe proof of the lower bound~(\\ref{eq:R0}) only requires\n$\\lambda(\\omega,n)$ to be an upper bound\non this growth rate---a relation which follows from\nthe Chernoff bound as in Eq.~(\\ref{eq:chernoff}) below. \nOn the other hand, for our results, we will need\na lower bound on this growth rate; to this end, we will use\na stronger result from large deviations theory (Eq.~(\\ref{eq:cramer})).}\nThe function $\\omega \\mapsto \\lambda_q(\\omega,n)$ is drawn\nin Figure~\\ref{fig:lambda} for $(q,n) = (2,4), (2,5), (4,5)$;\nit will follow from our analysis\nthat it is continuous, increasing, and concave\non $[0^+,\\infty]$ and its values range from $0$ at $\\omega = 0$\nto $(n{-}1)/n$ at $\\omega \\ge (q{-}1)/q$.\nAs we show in Lemma~\\ref{lem:unique} in\nAppendix~\\ref{sec:R0properties},\nfinding the infimum in~(\\ref{eq:lambda}) is computationally easy:\nit amounts to finding a root of a certain real polynomial\nof degree${} \\le n$.\n\\newcommand{\\PlotLambda}[1]{%\n    \\put(000,000){#1}\n    \\put(-10,000){\\vector(1,0){120}}\n    \\put(114,000){\\makebox(0,0)[l]{$\\omega$}}\n    \\put(000,-10){\\vector(0,1){120}}\n    \\put(-05,-04){\\makebox(0,0)[t]{$0$}}\n    \\put(100,000){\\line(0,-1){2}}\n    \\put(100,-04){\\makebox(0,0)[t]{$1.0$}}\n    \\put(000,100){\\line(-1,0){2}}\n    \\put(-04,100){\\makebox(0,0)[r]{$1.0$}}\n}%\n\\begin{figure*}[hbt]\n\\begin{center}\n\\footnotesize\n\\thicklines\n\\ifIEEE\n    \\setlength{\\unitlength}{0.4mm}\n\\else\n    \\setlength{\\unitlength}{0.35mm}\n\\fi\n\\begin{picture}(440,150)(-10,-25)\n\\put(000,000){\\PlotLambda{%\n    \\put(050,000){\\line(0,-1){2}}\n    \\put(050,-04){\\makebox(0,0)[t]{$0.5$}}\n    \\put(000,075){\\line(-1,0){2}}\n    \\put(-04,075){\\makebox(0,0)[r]{$0.75$}}\n    \\put(-04,114){\\makebox(0,0)[r]{$\\lambda_2(\\omega,4)$}}\n    \\put(050,-20){\\makebox(0,0)[t]{(a)}}\n    {\\thinlines\\color{gray}\n    \t\\qbezier(50.000,75.000)(51.002,75.000)(52.000,74.885)\n    \t\\qbezier(52.000,74.885)(52.998,74.770)(54.000,74.539)\n    \t\\qbezier(54.000,74.539)(54.998,74.310)(56.000,73.966)\n    \t\\qbezier(56.000,73.966)(56.997,73.624)(58.000,73.168)\n    \t\\qbezier(58.000,73.168)(58.997,72.715)(60.000,72.149)\n    \t\\qbezier(60.000,72.149)(60.997,71.586)(62.000,70.912)\n    \t\\qbezier(62.000,70.912)(62.997,70.242)(64.000,69.463)\n    \t\\qbezier(64.000,69.463)(64.998,68.687)(66.000,67.803)\n    \t\\qbezier(66.000,67.803)(66.999,66.923)(68.000,65.937)\n    \t\\qbezier(68.000,65.937)(69.000,64.952)(70.000,63.864)\n    \t\\qbezier(70.000,63.864)(71.001,62.776)(72.000,61.586)\n    \t\\qbezier(72.000,61.586)(73.002,60.393)(74.000,59.102)\n    \t\\qbezier(74.000,59.102)(75.003,57.804)(76.000,56.409)\n    \t\\qbezier(76.000,56.409)(77.005,55.004)(78.000,53.504)\n    \t\\qbezier(78.000,53.504)(79.007,51.987)(80.000,50.380)\n    \t\\qbezier(80.000,50.380)(81.009,48.748)(82.000,47.028)\n    \t\\qbezier(82.000,47.028)(83.011,45.274)(84.000,43.436)\n    \t\\qbezier(84.000,43.436)(85.014,41.551)(86.000,39.588)\n    \t\\qbezier(86.000,39.588)(87.018,37.561)(88.000,35.460)\n    \t\\qbezier(88.000,35.460)(89.023,33.274)(90.000,31.022)\n    \t\\qbezier(90.000,31.022)(91.030,28.650)(92.000,26.228)\n    \t\\qbezier(92.000,26.228)(93.041,23.629)(94.000,21.005)\n    \t\\qbezier(94.000,21.005)(95.061,18.104)(96.000,15.231)\n\t\\qbezier(96.000,15.231)(97.108,11.843)(98.000,8.644)\n    \t\\qbezier(98.000,8.644)(99.678,2.625)(100.000,0.000)\n    }\n    \\qbezier(0.000,0.000)(0.322,2.625)(2.000,8.644)\n    \\qbezier(2.000,8.644)(2.892,11.843)(4.000,15.231)\n    \\qbezier(4.000,15.231)(4.939,18.104)(6.000,21.005)\n    \\qbezier(6.000,21.005)(6.959,23.629)(8.000,26.228)\n    \\qbezier(8.000,26.228)(8.970,28.650)(10.000,31.022)\n    \\qbezier(10.000,31.022)(10.977,33.274)(12.000,35.460)\n    \\qbezier(12.000,35.460)(12.982,37.561)(14.000,39.588)\n    \\qbezier(14.000,39.588)(14.986,41.551)(16.000,43.436)\n    \\qbezier(16.000,43.436)(16.989,45.274)(18.000,47.028)\n    \\qbezier(18.000,47.028)(18.991,48.748)(20.000,50.380)\n    \\qbezier(20.000,50.380)(20.993,51.987)(22.000,53.504)\n    \\qbezier(22.000,53.504)(22.995,55.004)(24.000,56.409)\n    \\qbezier(24.000,56.409)(24.997,57.804)(26.000,59.102)\n    \\qbezier(26.000,59.102)(26.998,60.393)(28.000,61.586)\n    \\qbezier(28.000,61.586)(28.999,62.776)(30.000,63.864)\n    \\qbezier(30.000,63.864)(31.000,64.952)(32.000,65.937)\n    \\qbezier(32.000,65.937)(33.001,66.923)(34.000,67.803)\n    \\qbezier(34.000,67.803)(35.002,68.687)(36.000,69.463)\n    \\qbezier(36.000,69.463)(37.003,70.242)(38.000,70.912)\n    \\qbezier(38.000,70.912)(39.003,71.586)(40.000,72.149)\n    \\qbezier(40.000,72.149)(41.003,72.715)(42.000,73.168)\n    \\qbezier(42.000,73.168)(43.003,73.624)(44.000,73.966)\n    \\qbezier(44.000,73.966)(45.002,74.310)(46.000,74.539)\n    \\qbezier(46.000,74.539)(47.002,74.770)(48.000,74.885)\n    \\qbezier(48.000,74.885)(48.999,75.000)(50.000,75.000)\n    \\qbezier(50.000,75.000)(50.000,75.000)(52.000,75.000)\n    \\qbezier(52.000,75.000)(52.000,75.000)(54.000,75.000)\n    \\qbezier(54.000,75.000)(54.000,75.000)(56.000,75.000)\n    \\qbezier(56.000,75.000)(56.000,75.000)(58.000,75.000)\n    \\qbezier(58.000,75.000)(58.000,75.000)(60.000,75.000)\n    \\qbezier(60.000,75.000)(60.000,75.000)(62.000,75.000)\n    \\qbezier(62.000,75.000)(62.000,75.000)(64.000,75.000)\n    \\qbezier(64.000,75.000)(64.000,75.000)(66.000,75.000)\n    \\qbezier(66.000,75.000)(66.000,75.000)(68.000,75.000)\n    \\qbezier(68.000,75.000)(68.000,75.000)(70.000,75.000)\n    \\qbezier(70.000,75.000)(70.000,75.000)(72.000,75.000)\n    \\qbezier(72.000,75.000)(72.000,75.000)(74.000,75.000)\n    \\qbezier(74.000,75.000)(74.000,75.000)(76.000,75.000)\n    \\qbezier(76.000,75.000)(76.000,75.000)(78.000,75.000)\n    \\qbezier(78.000,75.000)(78.000,75.000)(80.000,75.000)\n    \\qbezier(80.000,75.000)(80.000,75.000)(82.000,75.000)\n    \\qbezier(82.000,75.000)(82.000,75.000)(84.000,75.000)\n    \\qbezier(84.000,75.000)(84.000,75.000)(86.000,75.000)\n    \\qbezier(86.000,75.000)(86.000,75.000)(88.000,75.000)\n    \\qbezier(88.000,75.000)(88.000,75.000)(90.000,75.000)\n    \\qbezier(90.000,75.000)(90.000,75.000)(92.000,75.000)\n    \\qbezier(92.000,75.000)(92.000,75.000)(94.000,75.000)\n    \\qbezier(94.000,75.000)(94.000,75.000)(96.000,75.000)\n    \\qbezier(96.000,75.000)(96.000,75.000)(98.000,75.000)\n    \\qbezier(98.000,75.000)(100.000,75.000)(100.000,75.000)\n}}\n\\put(155,000){\\PlotLambda{%\n    \\put(050,000){\\line(0,-1){2}}\n    \\put(050,-04){\\makebox(0,0)[t]{$0.5$}}\n    \\put(080,000){\\line(0,-1){2}}\n    \\put(080,-04){\\makebox(0,0)[t]{$0.8$}}\n    \\put(000,080){\\line(-1,0){2}}\n    \\put(-04,080){\\makebox(0,0)[r]{$0.80$}}\n    \\put(-04,114){\\makebox(0,0)[r]{$\\lambda_2(\\omega,5)$}}\n    \\put(050,-20){\\makebox(0,0)[t]{(b)}}\n    {\\thinlines\\color{gray}\n    \t\\qbezier(50.000,80.000)(51.003,80.000)(52.000,79.885)\n    \t\\qbezier(52.000,79.885)(53.001,79.769)(54.000,79.538)\n    \t\\qbezier(54.000,79.538)(55.002,79.306)(56.000,78.958)\n    \t\\qbezier(56.000,78.958)(57.003,78.608)(58.000,78.142)\n    \t\\qbezier(58.000,78.142)(59.005,77.672)(60.000,77.086)\n    \t\\qbezier(60.000,77.086)(61.007,76.492)(62.000,75.780)\n    \t\\qbezier(62.000,75.780)(63.009,75.057)(64.000,74.216)\n    \t\\qbezier(64.000,74.216)(65.012,73.356)(66.000,72.377)\n    \t\\qbezier(66.000,72.377)(67.016,71.369)(68.000,70.242)\n    \t\\qbezier(68.000,70.242)(69.021,69.071)(70.000,67.780)\n    \t\\qbezier(70.000,67.780)(71.028,66.424)(72.000,64.947)\n    \t\\qbezier(72.000,64.947)(73.039,63.368)(74.000,61.673)\n    \t\\qbezier(74.000,61.673)(75.059,59.804)(76.000,57.834)\n    \t\\qbezier(76.000,57.834)(77.107,55.518)(78.000,53.170)\n    \t\\qbezier(78.000,53.170)(79.677,48.762)(80.000,46.439)\n    }\n    \\qbezier(0.000,0.000)(0.323,2.698)(2.000,9.054)\n    \\qbezier(2.000,9.054)(2.893,12.438)(4.000,16.040)\n    \\qbezier(4.000,16.040)(4.941,19.101)(6.000,22.200)\n    \\qbezier(6.000,22.200)(6.961,25.011)(8.000,27.797)\n    \\qbezier(8.000,27.797)(8.972,30.401)(10.000,32.951)\n    \\qbezier(10.000,32.951)(10.979,35.379)(12.000,37.735)\n    \\qbezier(12.000,37.735)(12.984,40.005)(14.000,42.192)\n    \\qbezier(14.000,42.192)(14.988,44.317)(16.000,46.353)\n    \\qbezier(16.000,46.353)(16.991,48.344)(18.000,50.239)\n    \\qbezier(18.000,50.239)(18.993,52.103)(20.000,53.866)\n    \\qbezier(20.000,53.866)(20.995,55.608)(22.000,57.245)\n    \\qbezier(22.000,57.245)(22.997,58.868)(24.000,60.383)\n    \\qbezier(24.000,60.383)(24.998,61.889)(26.000,63.284)\n    \\qbezier(26.000,63.284)(26.999,64.675)(28.000,65.953)\n    \\qbezier(28.000,65.953)(29.000,67.229)(30.000,68.390)\n    \\qbezier(30.000,68.390)(31.000,69.552)(32.000,70.597)\n    \\qbezier(32.000,70.597)(33.001,71.643)(34.000,72.572)\n    \\qbezier(34.000,72.572)(35.001,73.502)(36.000,74.316)\n    \\qbezier(36.000,74.316)(37.000,75.130)(38.000,75.826)\n    \\qbezier(38.000,75.826)(39.000,76.524)(40.000,77.104)\n    \\qbezier(40.000,77.104)(41.000,77.685)(42.000,78.148)\n    \\qbezier(42.000,78.148)(43.000,78.612)(44.000,78.959)\n    \\qbezier(44.000,78.959)(44.999,79.307)(46.000,79.538)\n    \\qbezier(46.000,79.538)(46.999,79.769)(48.000,79.885)\n    \\qbezier(48.000,79.885)(48.999,80.000)(50.000,80.000)\n    \\qbezier(50.000,80.000)(50.000,80.000)(52.000,80.000)\n    \\qbezier(52.000,80.000)(52.000,80.000)(54.000,80.000)\n    \\qbezier(54.000,80.000)(54.000,80.000)(56.000,80.000)\n    \\qbezier(56.000,80.000)(56.000,80.000)(58.000,80.000)\n    \\qbezier(58.000,80.000)(58.000,80.000)(60.000,80.000)\n    \\qbezier(60.000,80.000)(60.000,80.000)(62.000,80.000)\n    \\qbezier(62.000,80.000)(62.000,80.000)(64.000,80.000)\n    \\qbezier(64.000,80.000)(64.000,80.000)(66.000,80.000)\n    \\qbezier(66.000,80.000)(66.000,80.000)(68.000,80.000)\n    \\qbezier(68.000,80.000)(68.000,80.000)(70.000,80.000)\n    \\qbezier(70.000,80.000)(70.000,80.000)(72.000,80.000)\n    \\qbezier(72.000,80.000)(72.000,80.000)(74.000,80.000)\n    \\qbezier(74.000,80.000)(74.000,80.000)(76.000,80.000)\n    \\qbezier(76.000,80.000)(76.000,80.000)(78.000,80.000)\n    \\qbezier(78.000,80.000)(78.000,80.000)(80.000,80.000)\n    \\qbezier(80.000,80.000)(80.000,80.000)(82.000,80.000)\n    \\qbezier(82.000,80.000)(82.000,80.000)(84.000,80.000)\n    \\qbezier(84.000,80.000)(84.000,80.000)(86.000,80.000)\n    \\qbezier(86.000,80.000)(86.000,80.000)(88.000,80.000)\n    \\qbezier(88.000,80.000)(88.000,80.000)(90.000,80.000)\n    \\qbezier(90.000,80.000)(90.000,80.000)(92.000,80.000)\n    \\qbezier(92.000,80.000)(92.000,80.000)(94.000,80.000)\n    \\qbezier(94.000,80.000)(94.000,80.000)(96.000,80.000)\n    \\qbezier(96.000,80.000)(96.000,80.000)(98.000,80.000)\n    \\qbezier(98.000,80.000)(98.000,80.000)(100.000,80.000)\n}}\n\\put(310,000){\\PlotLambda{%\n    \\put(075,000){\\line(0,-1){2}}\n    \\put(075,-04){\\makebox(0,0)[t]{$0.75$}}\n    \\put(000,080){\\line(-1,0){2}}\n    \\put(-04,080){\\makebox(0,0)[r]{$0.8$}}\n    \\put(-04,114){\\makebox(0,0)[r]{$\\lambda_4(\\omega,5)$}}\n    \\put(050,-20){\\makebox(0,0)[t]{(c)}}\n    {\\thinlines\\color{gray}\n    \t\\qbezier(75.000,80.000)(76.054,80.000)(77.083,79.915)\n    \t\\qbezier(77.083,79.915)(78.137,79.828)(79.167,79.652)\n    \t\\qbezier(79.167,79.652)(80.222,79.472)(81.250,79.200)\n    \t\\qbezier(81.250,79.200)(82.308,78.919)(83.333,78.540)\n    \t\\qbezier(83.333,78.540)(84.394,78.149)(85.417,77.655)\n    \t\\qbezier(85.417,77.655)(86.482,77.139)(87.500,76.515)\n    \t\\qbezier(87.500,76.515)(88.570,75.858)(89.583,75.084)\n    \t\\qbezier(89.583,75.084)(90.660,74.262)(91.667,73.311)\n    \t\\qbezier(91.667,73.311)(92.755,72.284)(93.750,71.117)\n    \t\\qbezier(93.750,71.117)(94.858,69.818)(95.833,68.368)\n    \t\\qbezier(95.833,68.368)(96.990,66.649)(97.917,64.785)\n    \t\\qbezier(97.917,64.785)(99.667,61.266)(100.000,59.069)\n    }\n    \\qbezier(0.000,0.000)(0.316,1.447)(2.000,5.376)\n    \\qbezier(2.000,5.376)(2.889,7.451)(4.000,9.766)\n    \\qbezier(4.000,9.766)(4.937,11.720)(6.000,13.775)\n    \\qbezier(6.000,13.775)(6.958,15.627)(8.000,17.529)\n    \\qbezier(8.000,17.529)(8.969,19.297)(10.000,21.088)\n    \\qbezier(10.000,21.088)(10.976,22.783)(12.000,24.485)\n    \\qbezier(12.000,24.485)(12.981,26.115)(14.000,27.742)\n    \\qbezier(14.000,27.742)(14.985,29.315)(16.000,30.876)\n    \\qbezier(16.000,30.876)(16.988,32.394)(18.000,33.896)\n    \\qbezier(18.000,33.896)(18.990,35.364)(20.000,36.811)\n    \\qbezier(20.000,36.811)(20.992,38.231)(22.000,39.626)\n    \\qbezier(22.000,39.626)(22.994,41.002)(24.000,42.348)\n    \\qbezier(24.000,42.348)(24.995,43.679)(26.000,44.979)\n    \\qbezier(26.000,44.979)(26.997,46.267)(28.000,47.521)\n    \\qbezier(28.000,47.521)(28.998,48.767)(30.000,49.977)\n    \\qbezier(30.000,49.977)(30.999,51.182)(32.000,52.347)\n    \\qbezier(32.000,52.347)(33.000,53.511)(34.000,54.633)\n    \\qbezier(34.000,54.633)(35.001,55.755)(36.000,56.834)\n    \\qbezier(36.000,56.834)(37.002,57.915)(38.000,58.949)\n    \\qbezier(38.000,58.949)(39.002,59.988)(40.000,60.979)\n    \\qbezier(40.000,60.979)(41.003,61.976)(42.000,62.922)\n    \\qbezier(42.000,62.922)(43.004,63.875)(44.000,64.776)\n    \\qbezier(44.000,64.776)(45.004,65.684)(46.000,66.539)\n    \\qbezier(46.000,66.539)(47.005,67.401)(48.000,68.209)\n    \\qbezier(48.000,68.209)(49.005,69.024)(50.000,69.783)\n    \\qbezier(50.000,69.783)(51.005,70.550)(52.000,71.259)\n    \\qbezier(52.000,71.259)(53.005,71.975)(54.000,72.632)\n    \\qbezier(54.000,72.632)(55.005,73.297)(56.000,73.901)\n    \\qbezier(56.000,73.901)(57.005,74.512)(58.000,75.062)\n    \\qbezier(58.000,75.062)(59.005,75.617)(60.000,76.110)\n    \\qbezier(60.000,76.110)(61.005,76.608)(62.000,77.043)\n    \\qbezier(62.000,77.043)(63.005,77.482)(64.000,77.856)\n    \\qbezier(64.000,77.856)(65.006,78.234)(66.000,78.546)\n    \\qbezier(66.000,78.546)(67.006,78.861)(68.000,79.108)\n    \\qbezier(68.000,79.108)(69.006,79.358)(70.000,79.538)\n    \\qbezier(70.000,79.538)(71.007,79.721)(72.000,79.831)\n    \\qbezier(72.000,79.831)(73.008,79.943)(74.000,79.981)\n    \\qbezier(74.000,79.981)(74.502,80.000)(76.000,80.000)\n    \\qbezier(76.000,80.000)(76.000,80.000)(78.000,80.000)\n    \\qbezier(78.000,80.000)(78.000,80.000)(80.000,80.000)\n    \\qbezier(80.000,80.000)(80.000,80.000)(82.000,80.000)\n    \\qbezier(82.000,80.000)(82.000,80.000)(84.000,80.000)\n    \\qbezier(84.000,80.000)(84.000,80.000)(86.000,80.000)\n    \\qbezier(86.000,80.000)(86.000,80.000)(88.000,80.000)\n    \\qbezier(88.000,80.000)(88.000,80.000)(90.000,80.000)\n    \\qbezier(90.000,80.000)(90.000,80.000)(92.000,80.000)\n    \\qbezier(92.000,80.000)(92.000,80.000)(94.000,80.000)\n    \\qbezier(94.000,80.000)(94.000,80.000)(96.000,80.000)\n    \\qbezier(96.000,80.000)(96.000,80.000)(98.000,80.000)\n    \\qbezier(98.000,80.000)(100.000,80.000)(100.000,80.000)\n}}\n\\end{picture}\n\\thinlines\n\\setlength{\\unitlength}{1pt}\n\\end{center}\n\\caption{Function $\\omega \\mapsto \\lambda_q(\\omega,n)$\nfor (a) $(q,n) = (2,4)$, (b) $(q,n) = (2,5)$,\nand (c) $(q,n) = (4,5)$. The lighter curves\ndepict the function $\\omega \\mapsto \\lambda^*_q(\\omega,n)$.}\n\\label{fig:lambda}\n\\end{figure*}\n\\fi\n\nOur first set of results pertain to linearly recoverable LRC sequences\nthat are all-disjoint.\nWe prove the next bound-enhancement theorem by using, \\emph{inter alia},\nthe generalization of~\\cite{LL} to the shortening method for\nimproving upper bounds on the rate of code sequences.\n\n\\begin{theorem}\n\\label{thm:bound1}\nLet $\\delta \\mapsto \\Rate_\\LRC(\\delta, n)$ be an upper bound on\nthe rate of any\nall-disjoint linearly recoverable $(\\delta,n)$-LRC sequence over $F$.\nThen the rate of such a sequence is bounded from above also by\n\\ifPAGELIMIT\n    \\begin{eqnarray}\n    \\Rate_1(\\delta,n)\n    & = & \\inf_{\\tau \\in (0,1)} \\min_{(\\theta,\\theta')}\n    \\Bigl\\{ \n    \\tau \\cdot \\Rate_0(\\theta/2,n)\n    \\nonumber \\\\\n    \\label{eq:bound1}\n    &&\n    \\quad \\quad \\quad\n    {}\n    + \n    (1-\\tau) \\cdot \\Rate_\\LRC(\\theta',n)\n    \\Bigr\\} ,\n\\end{eqnarray}\n\\else\n\\begin{eqnarray}\n\\Rate_1(\\delta,n)\n& = & \\inf_{\\tau \\in (0,1)} \\min_{(\\theta,\\theta')}\n\\Biggl\\{ \n\\tau \\cdot \\Rate_0 \\left( \\frac{\\theta}{2}, n \\right)\n\\nonumber \\\\\n\\label{eq:bound1}\n&&\n\\quad \\quad \\quad\n{}\n+ \n(1-\\tau) \\cdot \\Rate_\\LRC(\\theta',n)\n\\Biggr\\} ,\n\\end{eqnarray}\n\\fi\nwhere $\\Rate_0(\\cdot,n)$ is defined in~(\\ref{eq:R0})--(\\ref{eq:lambda})\nand the (inner) minimum is taken over\nall pairs $(\\theta,\\theta')$ in $[0,(q{-}1)/q]^2$ such that\n\\begin{equation}\n\\label{eq:theta}\n\\tau \\cdot \\theta + (1-\\tau) \\cdot \\theta' = \\delta .\n\\end{equation}\n\\end{theorem}\n\nIn particular, \\Theorem~\\ref{thm:bound1} holds for\n\\ifPAGELIMIT\n    $\\Rate_\\LRC(\\delta,n) = \\Rate_\\opt(\\delta)$.\n\\else\n$\\Rate_\\LRC(\\delta,n) = \\Rate_\\opt(\\delta)$\n(i.e., ignoring locality or linear recoverability).\n\\fi\nThis, in turn, yields a concrete upper bound\nfor all-disjoint linearly recoverable LRC sequences.\nWhen we do so and substitute $\\theta = 0$\nin the objective function in~(\\ref{eq:bound1}),\nwe get the expression $\\Rate_\\CM(\\delta,n)$ in~(\\ref{eq:CM}).\nYet, generally, the minimum in~(\\ref{eq:bound1}) is obtained\nat some nonzero $\\theta$, thereby yielding an improvement.\nFor $\\tau \\rightarrow 1$ (which forces $\\theta = \\delta$),\nthe objective function in~(\\ref{eq:bound1}) becomes\nthe asymptotic version of the sphere-packing bound of~\\cite{WZL}\n(see \\Theorem~\\ref{thm:spherepacking} below):\n\\ifPAGELIMIT\n    \\[\n    R \\le \\Rate_\\SP(\\delta,n) = \\Rate_0(\\delta/2,n) .\n    \\]\n\\else\n\\begin{equation}\n\\label{eq:spherepacking}\nR \\le \\Rate_\\SP(\\delta,n) = \\Rate_0 \\left( \\frac{\\delta}{2},n \\right) .\n\\end{equation}\nThus, the objective function in~(\\ref{eq:bound1}) can also be written\nas:\n\\[\n\\tau \\cdot \\Rate_\\SP(\\theta,n)\n+ (1-\\tau) \\cdot \\Rate_\\LRC(\\theta',n) .\n\\]\n\\fi\n\n\\ifPAGELIMIT\n\\else\n\\begin{remark}\n\\label{rem:bound1}\n\\Theorem~\\ref{thm:bound1} can be given the following\ngeometric interpretation (see~\\cite[pp.~77]{LL}):\nfor any distinct $\\theta_1, \\theta_2 \\in [0,(q{-}1)/q]$,\nthe line in the $(\\delta,R)$-plane\nthrough the points $(\\theta_1,\\Rate_\\SP(\\theta_1))$\nand $(\\theta_2,\\Rate_\\LRC(\\theta_2,n))$\nis an upper bound on the rate for any\n$\\delta \\in [\\min\\{\\theta_1,\\theta_2\\},\\max\\{\\theta_1,\\theta_2\\}]$.\nIn particular, if \n$\\delta \\mapsto \\Rate_\\LRC(\\delta,n)$ is convex,\nthen, from the convexity of\n$\\delta \\mapsto \\Rate_\\SP(\\delta,n)$ we get that\nthe lower convex envelope of\n$\\min \\left\\{ \\Rate_\\SP(\\delta,n), \\Rate_\\LRC(\\delta,n) \\right\\}$\nis also an upper bound.\\qed\n\\end{remark}\n\\fi\n\nOur second main result is the following bound.\n\n\\begin{theorem}\n\\label{thm:bound2}\nThe rate of any\nall-disjoint linearly recoverable $(\\delta,n)$-LRC sequence over $F$\nis bounded from above by\n\\[\n\\Rate_2(\\delta,n) = \\min_{\\omega \\in [\\delta/2,(q{-}1)/q]}\n\\Bigl\\{ \\Rate_0(\\omega,n) + \\Rate_\\opt(\\delta,\\omega) \\Bigr\\} .\n\\]\n\\end{theorem}\n\nThe bound of \\Theorem~\\ref{thm:bound2} can be further improved by\nsubstituting $\\Rate_\\LRC(\\delta,n) = \\Rate_2(\\delta,n)$\nin \\Theorem~\\ref{thm:bound1}.\n\n\\ifPAGELIMIT\n    The various bounds are summarized in Table~\\ref{tab:q=2,n=4}\n    for $q = 2$, $n = 4$, and\n    $\\delta \\in \\{ 0.07, 0.10, 0.15, 0.30 \\}$\n    (full plots can be found in~\\cite{RothFull}).\n    The bound $\\Rate_\\CM(\\delta,n)$ is computed by substituting\n    the linear-programming bound $\\Rate_\\LP(\\delta)$ of~\\cite{MRRW}\n    for $\\Rate_\\opt(\\delta)$ and, similarly,\n    $\\Rate_1(\\delta,n)$ is computed taking\n    $\\Rate_\\LRC(\\delta,n) = \\Rate_\\LP(\\delta)$ in~(\\ref{eq:bound1}).\n    The last column corresponds to the bound $\\Rate_1(\\delta,n)$,\n    now taking $\\Rate_\\LRC(\\delta,n) = \\Rate_2(\\delta,n)$.\n    The bounds of~\\cite{ABHMT} slightly improve on $\\Rate_\\CM(\\delta,n)$\n    yet not for the parameters shown in the table.\n\\else\nThe various bounds are plotted in\nFigures~\\ref{fig:q=2,n=3} and~\\ref{fig:q=2,n=4}\nfor $q = 2$ and $n = 3, 4$:\n\\begin{itemize}\n\\itemsep0ex\n\\item\ncurve~(a) presents $\\delta \\mapsto \\Rate_\\SP(\\delta,n)$;\n\\item\ncurve~(b) presents $\\delta \\mapsto \\Rate_\\CM(\\delta,n)$,\nwhere we have substituted\nthe linear-programming bound $\\Rate_\\LP(\\delta)$ of~\\cite{MRRW}\nfor $\\Rate_\\opt(\\delta)$;\n\\item\ncurve~(c) presents $\\delta \\mapsto \\Rate_1(\\delta,n)$ taking\n$\\Rate_\\LRC(\\delta,n) = \\Rate_\\LP(\\delta)$ in~(\\ref{eq:bound1})\n(the same curve is obtained also for\n$\\Rate_\\LRC(\\delta,n) = \\Rate_\\CM(\\delta,n)$);\n\\item\ncurve~(d) presents $\\delta \\mapsto \\Rate_2(\\delta,n)$;\n\\item\ncurve~(e) presents $\\delta \\mapsto \\Rate_1(\\delta,n)$ taking\n$\\Rate_\\LRC(\\delta,n) = \\Rate_2(\\delta,n)$ in~(\\ref{eq:bound1});\n\\item\nand curve~(f) presents the lower bound\n$\\delta \\mapsto \\Rate_0(\\delta,n)$.\n\\end{itemize}\nIn the range where any of the curves~(b)--(d)\nis not seen it coincides with curve~(e).\nThe values of the upper bounds for $q = 2$, $n = 4$, and\n$\\delta \\in \\{ 0.07, 0.10, 0.15, 0.30 \\}$\nare summarized in Table~\\ref{tab:q=2,n=4}.\nNotice that curve~(d) is not convex and that there is\na (small) range where it is worse than curve~(b),\nbut curve~(e) yields the best results.\nThe bounds of~\\cite{ABHMT} slightly improve on $\\Rate_\\CM(\\delta,n)$\nbut are too close to it to be seen at the scale of the figures.\n\\fi\n\\begin{table}[hbt]\n\\caption{Values of the bounds for $q = 2$ and $n = 4$.}\n\\label{tab:q=2,n=4}\n\\ifPAGELIMIT\n    \\vspace{-3ex}\n\\fi\n\\[\n\\renewcommand{\\arraystretch}{1.1}\n\\begin{array}{cccccc}\n\\hline\\hline\n\\quad\\quad \\delta \\quad\\quad &\n\\ifPAGELIMIT\n    \\Rate_\\SP & \\Rate_\\CM & \\Rate_1 & \\Rate_2 & \\Rate_{1,2} \\\\\n\\else\n\\mathrm{(a)}&\\mathrm{(b)}&\\mathrm{(c)}&\\mathrm{(d)}&\\mathrm{(e)} \\\\\n\\fi\n\\hline\n0.07 & 0.6133 & 0.6317 & 0.6131 & 0.6079 & 0.6079 \\\\\n0.10 & 0.5681 & 0.5809 & 0.5643 & 0.5576 & 0.5576 \\\\\n0.15 & 0.5004 & 0.4964 & 0.4830 & 0.4781 & 0.4781 \\\\\n0.30 & 0.3346 & 0.2427 & 0.2391 & 0.2470 & 0.2391 \\\\\n\\hline\\hline\n\\end{array}\n\\]\n\\end{table}\n\nOur second set of results includes (weaker) counterparts\nof \\Theorems~\\ref{thm:bound1} and~\\ref{thm:bound2} that apply\ngenerally to linearly recoverable LRC sequences\n(that are not necessarily all-disjoint). \n\n\\ifPAGELIMIT\n    Due to space limitations,\n    some proofs are omitted from this abstract;\n    they can be found in~\\cite{RothFull}.\n\\else\nThe rest of this work is organized as follows.\nIn Section~\\ref{sec:tools}, we present some basic tools from\nlarge deviations theory which are tailored to our needs.\nAdditional tools will be presented in Section~\\ref{sec:spherepacking},\nwhere we also prove\nthe asymptotic sphere-packing bound~(\\ref{eq:spherepacking}).\nSection~\\ref{sec:mainresults} is devoted to proving\n\\Theorems~\\ref{thm:bound1} and~\\ref{thm:bound2}.\nThen, in Section~\\ref{sec:q=2,n=3},\nwe present improved results for the special case $q = 2$ and $n = 3$.\nFinally, in Section~\\ref{sec:nondisjoint},\nwe present our bounds for\n$(\\delta,n)$-LRC sequences that are not necessarily\nall-disjoint (but are still linearly recoverable).\n\n\\section{Large deviation tools}\n\\label{sec:tools}\n\nWe summarize here several basic notions from\nlarge deviations theory (see~\\cite[Sections~2.1.2 and 2.2]{DZ}).\nLet $X$ be a random variable\nwhich takes values in a finite subset $\\Set \\subseteq \\Realfield$,\nwith $\\Prob \\{ X = x \\} = p(x) > 0$ for every $x \\in \\Set$.\nFor every $u \\in \\Realfield$, let the function\n$g_u : (0,1] \\rightarrow \\Realfield$ be defined by\n\\[\ng_u(z) = z^{-u} \\cdot \\Expected \\left\\{ z^X \\right\\}\n= \\sum_{x \\in \\Set} p(x) \\cdot z^{x - u}\n\\]\nand let\n\\begin{equation}\n\\label{eq:gamma}\n\\gamma(u) = \\gamma_X(u)\n= \\inf_{z \\in (0,1]} g_u(z) .\n\\end{equation}\n\nThe following theorem follows from\nthe Chernoff bound and Cram\\'{e}r's theorem.\n\n\\begin{theorem}\n\\label{thm:cramer}\nLet $(X_i)_{i=1}^\\infty$ be a sequence of i.i.d.\\ random variables\nwhich take values in a finite subset $\\Set \\subseteq \\Realfield$.\nThen for every real $u \\ge x_{\\min} = \\min_{x \\in \\Set} x$\nand $\\ell \\in \\Integers^+$,\n\\begin{equation}\n\\label{eq:chernoff}\n\\frac{1}{\\ell} \\log\n\\Prob \\left\\{ \\frac{1}{\\ell} \\sum_{i=1}^\\ell X_i \\le u \\right\\}\n\\le \\log \\gamma(u) .\n\\end{equation}\nMoreover,\n\\begin{equation}\n\\label{eq:cramer}\n\\lim_{\\ell \\rightarrow \\infty}\n\\frac{1}{\\ell} \\log\n\\Prob \\left\\{ \\frac{1}{\\ell} \\sum_{i=1}^\\ell X_i \\le u \\right\\}\n= \\log \\gamma(u) .\n\\end{equation}\n\\end{theorem}\n\nSome properties of $u \\mapsto \\gamma(u)$ are summarized\nin the next\n\\ifPAGELIMIT\n    lemma.\n\\else\nlemma, which is proved in Appendix~\\ref{sec:skippedproofs}.\n\\fi\n\n\\begin{lemma}\n\\label{lem:gamma}\nThe function $u \\mapsto \\gamma(u)$ is\n\\begin{itemize}\n\\item\nidentically zero when \n$u < x_{\\min} = \\min_{x \\in \\Set} x$,\n\\item\nequal to $p(x_{\\min})$ when $u = x_{\\min}$,\n\\item\nconstant $1$ when\n$u \\ge \\Expected \\{ X \\}$,\n\\item\nstrictly increasing when\n$x_{\\min} \\le u < \\Expected \\{ X \\}$,\n\\item\ncontinuous when $u \\in [x_{\\min}^+,\\infty)$, and---\n\\item\nlog-concave (i.e., $u \\mapsto \\log \\gamma(u)$ is concave)\nwhen $u \\ge x_{\\min}$.\n\\end{itemize}\n\\end{lemma}\n\nLet $\\code$ be a linear $[n,k]$ code over $F$ and denote by\n$W_\\code(z) = \\sum_{i=0}^n W_i z^i$ the weight enumerator polynomial \nof $\\code$, namely,\n\\[\nW_i = \\left| \\{ \\bldc \\in \\code \\,:\\, \\weight(\\bldc) = i \\} \\right| ,\n\\]\nwhere $\\weight(\\cdot)$ denotes Hamming weight.\nFor $\\omega \\in \\Realfield$, define\n\\[\n\\alpha(\\omega) = \\alpha_\\code(\\omega)\n= \\inf_{z \\in (0,1]} \\left\\{ z^{-n \\omega} \\cdot W_\\code(z) \\right\\} .\n\\]\nWe have $\\alpha(\\omega) = q^k \\cdot \\gamma_X(n \\omega)$,\nwhere $X$ is a random variable which equals the weight of\na codeword selected uniformly from $\\code$.\nIn particular, $\\omega \\mapsto \\alpha(\\omega)$ is\ncontinuous on $\\Realfield_{\\ge 0}$.\nMoreover, when $\\code$ has no trivial coordinates\n(i.e., none of the coordinates is identically zero\nacross all codewords) then $\\Expected \\{ X \\} = n (q{-}1)/q$;\nso, $\\omega \\mapsto \\alpha(\\omega)$ is strictly increasing\n(and therefore also positive) at any positive $\\omega < (q{-}1)/q$.\n\nFor a code $\\varcode$ of length $N$ over $F$ and\n$\\omega \\in \\Realfield_{\\ge 0}$,\nwe denote by $\\varcode(\\omega)$ the set of all codewords\nin $\\varcode$ that are contained in a Hamming ball of radius $\\omega N$:\n\\[\n\\varcode(\\omega) =\n\\left\\{ \\bldc \\in \\varcode \\,:\\, \\weight(\\bldc) \\le \\omega N \\right\\} .\n\\]\n\n\\begin{lemma}\n\\label{lem:cramer}\nLet $\\code$ be a linear code $[n,k]$ over $F$ \nand for $\\ell \\in \\Integers^+$,\nlet $\\Code^{(\\ell)}$ be the linear $[\\ell n, \\ell k]$ code over $F$\ndefined by the Cartesian product\n\\[\n\\Code^{(\\ell)} = \\code^{\\times \\ell} \n= \\underbrace{\\code \\times \\code \\cdots \\times \\code}_%\n                                              {\\ell \\; \\mathrm{times}} .\n\\]\nThen the following holds.\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textit{(ii)}}}\n\\item[(i)]\nFor any $\\omega \\in \\Realfield_{\\ge 0}$ and $\\ell \\in \\Integers^+$:\n\\[\n\\frac{1}{\\ell} \\log |\\Code^{(\\ell)}(\\omega)| \\le \\log \\alpha(\\omega) .\n\\]\n\\item[(ii)]\nFor any $\\omega \\in \\Realfield_{\\ge 0}$:\n\\[\n\\lim_{\\ell \\rightarrow \\infty}\n\\frac{1}{\\ell} \\log |\\Code^{(\\ell)}(\\omega)| = \\log \\alpha(\\omega) .\n\\]\n\\end{list}\n\\end{lemma}\n\n\\begin{proof}\nApply \\Theorem~\\ref{thm:cramer}\nwith the random variable $X_i$ taken as\nthe weight of a codeword selected uniformly from $\\code$.\n\\end{proof}\n\n\\ifPAGELIMIT\n\\else\n\\begin{remark}\n\\label{rem:variant}\nA variant of Lemma~\\ref{lem:cramer} holds also for\n$\\Code^{(\\ell)}(\\omega \\pm \\varepsilon)$,\ndefined as the set of all codewords\nin $\\Code^{(\\ell)}$ of weight within $(\\omega \\pm \\varepsilon) \\ell n$.\nAssuming that $\\code$ has no trivial coordinates,\nit follows from~\\cite[\\Theorem~2.1.24]{DZ}\nthat for any $\\omega \\in (0,(q{-}1)/q]$:\n\\[\n\\lim_{\\varepsilon \\rightarrow 0}\n\\lim_{\\ell \\rightarrow \\infty}\n\\frac{1}{\\ell} \\log |\\Code^{(\\ell)}(\\omega \\pm \\varepsilon)|\n= \\log \\alpha(\\omega) .\n\\]\nFor $(q{-}1)/q < \\omega < \\max_{\\bldc \\in \\code} \\weight(\\bldc)/n$,\nthis equality holds if we replace $\\alpha(\\omega)$ by:\n\\[\n\\alpha^*(\\omega)\n= \\inf_{z \\in (0,1]} z^{n \\omega} \\cdot W_\\code(z^{-1})\n\\]\n(this can be shown by stating \\Theorem~\\ref{thm:cramer}\nwith $X_i$ and $u$ replaced by $-X_i$ and $-u$, respectively).\\qed\n\\end{remark}\n\\fi\n\n\\begin{example}\n\\label{ex:lambda}\nLet $\\code$ be the $[n,n{-}1,2]$ parity code over $F$.\nThe weight enumerator polynomial of the $[n,1,n]$ repetition code,\nwhich is the dual code of $\\code$, is given by\n\\[\nW_{\\code^\\perp}(z) = 1 + (q{-}1) z^n .\n\\]\nHence, by MacWilliams' identities (see~\\cite[\\Theorem~4.6]{Roth}):\n\\[\nW_\\code(z)\n= \\frac{1}{q} \\Bigl( (1 + (q{-}1)z)^n + (q{-}1)(1{-}z)^n \\Bigr) .\n\\]\nThus, for the code $\\code$ we have:\n\\begin{eqnarray*}\n\\frac{1}{n} \\cdot \\log_q \\alpha(\\omega)\n& = &\n\\frac{1}{n}\n\\inf_{z \\in (0,1]}\n\\log_q \\left( z^{-n \\omega} \\cdot W_\\code(z) \\right) \\\\\n& = &\n\\lambda(\\omega,n) ,\n\\end{eqnarray*}\nwhere $\\lambda(\\omega,n)$ is defined in~(\\ref{eq:lambda}). From this\nwe can conclude that the mapping $\\omega \\mapsto \\lambda(\\omega,n)$\ntakes the value $0$ at $\\omega = 0$ and $(n{-}1)/n$\nat $\\omega = (q{-}1)/q$, and is strictly increasing in between\nfor any $n > 1$.\nFor $\\omega \\ge (q{-}1)/q$ it remains\n\\ifPAGELIMIT\na constant $(n{-}1)/n$.\\qed\n\\else\na constant $(n{-}1)/n$.\n\nIn Figure~\\ref{fig:lambda}, we have also depicted the following\nfunction, which is defined\nfor $(q{-}1)/q < \\omega < \\max_{\\bldc \\in \\code} \\weight(\\bldc)/n$:\n\\begin{eqnarray*}\n\\lambda^*(\\omega,n) = \\lambda^*_q(\\omega,n)\n& = &\n\\frac{1}{n} \\cdot \\log_q \\alpha^*(\\omega) \\\\\n& = &\n\\frac{1}{n}\n\\inf_{z \\in (0,1]}\n\\log_q \\left( z^{n \\omega} \\cdot W_\\code(z^{-1}) \\right) .\n\\end{eqnarray*}\nNote that $\\max_{\\bldc \\in \\code} \\weight(\\bldc)/n$ equals $1$,\nexcept when $q = 2$ and $n$ is odd, in which case it equals $(n{-}1)/n$.\nIt is also fairly easy to see that when $q = 2$ and $n$ is even\nwe have\n$\\lambda^*_2(\\omega,n) = \\lambda_2(1{-}\\omega,n)$.\\qed\n\\fi\n\\end{example}\n\\fi\n\n\\section{Asymptotic sphere-packing bound}\n\\label{sec:spherepacking}\n\n\\ifPAGELIMIT\n    We present in this section several tools and definitions.\n\\else\nThe purpose of this section is to present additional\ntools that will be used in this work.\n\\fi\nAlong the way, we present\nan asymptotic formulation of the sphere-packing bound of~\\cite{WZL}\nfor the all-disjoint linearly recoverable case.\n\\ifPAGELIMIT\n    We start with the next proposition, which will follow from\n    Lemma~\\ref{lem:mu} below.\n\\else\nThe following proposition will be useful for this purpose,\nas well as for other proofs in the sequel.\n\\fi\n\n\\begin{proposition}\n\\label{prop:R0}\nGiven $n \\in \\Integers^+$,\nlet $(\\Ambient_i)_{i=1}^\\infty$ be\nan infinite sequence of codes over $F$\nwhere each $\\Ambient_i$ is\na linear code of length $N_i$ over $F$ of the form\n\\[\n\\Ambient_i = \\code_{i,1} \\times \\code_{i,2}\n\\times \\cdots \\times \\code_{i,\\ell_i} ,\n\\]\nwith each constituent code $\\code_{i,j}$ being\na linear $[n_{i,j},n_{i,j}{-}1]$ code of length $n_{i,j} \\le n$\nover $F$.\nThen for any nonnegative real sequence $(\\omega_i)_{i=1}^\\infty$\nsuch that $\\varliminf_{i \\rightarrow \\infty} \\omega_i = \\omega$:\n\\ifPAGELIMIT\n    \\[\n    \\varlimsup_{i \\rightarrow \\infty}\n    \\frac{1}{N_i}\n    \\log_q\n    \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|}\n    \\le \\Rate_0(\\omega,n) ,\n    \\]\n\\else\n\\begin{equation}\n\\label{eq:limit}\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q\n\\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|}\n\\le \\Rate_0(\\omega,n) ,\n\\end{equation}\n\\fi\nwhere $\\Rate_0(\\omega,n)$ is defined\nin~(\\ref{eq:R0})--(\\ref{eq:lambda}).\n\\end{proposition}\n\n\\ifPAGELIMIT\n\\else\n\\subsection{Proof of \\Proposition~\\protect\\ref{prop:R0}}\n\\label{sec:R0}\n\nWe will prove \\Proposition~\\ref{prop:R0} in two steps.\nWe first prove it under an additional assumption\non the sequence $(\\Ambient_i)_{i=1}^\\infty$\n(Lemma~\\ref{lem:lambda}).\nWe then prove a more general claim (Lemma~\\ref{lem:mu}),\nwhich will also be needed in Section~\\ref{sec:nondisjoint}\nwhere we remove the all-disjoint assumption.\n\n\\begin{lemma}\n\\label{lem:lambda}\n\\Proposition~\\ref{prop:R0} holds when\nall the constituent codes have the same length $n_{i,j} = n$.\n\\end{lemma}\n\n\\begin{proof}\nThe claim is immediate when $\\omega = 0$, so we assume hereafter\nin the proof that $\\omega > 0$.\n\nFor $s \\in [n]$, let $\\code_s$\nbe the linear $[n,n{-}1]$ code over $F$ with the parity-check matrix\n\\[\n\\bigl( \\underbrace{1 \\, 1 \\, \\ldots \\, 1}_{s \\; \\mathrm{times}}\n0 \\, 0 \\, \\ldots \\, 0 \\bigr) .\n\\]\nWithout real loss of generality we can assume that\n$\\code_{i,j} \\in \\left\\{ \\code_s \\right\\}_{s=1}^n$\nfor each $j \\in [\\ell_i]$. Therefore, we can write\n\\begin{equation}\n\\label{eq:product}\n\\Ambient_i = \\Code_1^{(\\ell_{i,1})} \\times \\Code_2^{(\\ell_{i,2})}\n\\times \\cdots \\times \\Code_n^{(\\ell_{i,n})} ,\n\\end{equation}\nwhere $\\Code_s^{(\\ell)} = (\\code_s)^{\\times \\ell}$\nand $\\ell_{i,1}, \\ell_{i,2}, \\ldots, \\ell_{i,n}$ are nonnegative\nintegers that sum to $\\ell_i$.\n(The code $\\Code_s^{(0)}$ is taken to have zero length,\nwhich will practically mean that we remove\n$\\Code_s^{(\\ell_{i,s})}$ from the product~(\\ref{eq:product})\nin case $\\ell_{i,s} = 0$.)\n\nFor each $s \\in [n]$, the weight enumerator polynomial of\nthe dual code of $\\code_s$ is given by\n\\[\nW_{\\code_s^\\perp}(z) = 1 + (q{-}1) z^s\n\\]\nand, so, by MacWilliams' identities:\n\\[\nW_{\\code_s}(z) = \\frac{1}{q}\n(1 + (q{-}1)z)^{n-s}\n\\Bigl( (1 + (q{-}1)z)^s + (q{-}1)(1{-}z)^s \\Bigr) .\n\\]\nIn particular, for every $z \\in (0,1]$:\n\\[\nW_{\\code_s}(z) \\ge W_{\\code_n}(z) = \\frac{1}{q}\n\\Bigl( (1 + (q{-}1)z)^n + (q{-}1)(1{-}z)^n \\Bigr) .\n\\]\nHence, for every $i \\in \\Integers^+$:\n\\[\n\\log_q \\alpha_{\\code_s}(\\omega_i) \n\\ge \\log_q \\alpha_{\\code_n}(\\omega_i) \n= n \\cdot \\lambda(\\omega_i,n) .\n\\]\nFixing some $\\varepsilon \\in (0,\\omega)$,\nby Lemma~\\ref{lem:cramer}(ii) we then get that,\nwhenever $i$ and $\\ell_{i,s}$ are sufficiently large,\n\\begin{eqnarray}\n\\frac{1}{\\ell_{i,s} n} \\log_q |\\Code_s^{(\\ell_{i,s})}(\\omega_i)|\n& \\ge &\n\\frac{1}{\\ell_{i,s} n}\n\\log_q |\\Code_s^{(\\ell_{i,s})}(\\omega{-}\\varepsilon)| \\nonumber \\\\\n\\label{eq:limit-s}\n& \\ge & \\lambda(\\omega{-}\\varepsilon,n) - \\varepsilon .\n\\end{eqnarray}\n\nFor $i \\in \\Integers^+$ define\n\\[\n\\AltSet(i) =\n\\left\\{ s \\in [n] \\,:\\, \\ell_{i,s} \\ge \\sqrt{\\ell_i} \\right\\} .\n\\]\nFor sufficiently large $i$ (and, therefore,\nsufficiently large $\\ell_i$) we have:\n\\begin{eqnarray*}\n\\lefteqn{\n\\frac{1}{\\ell_i n} \\log_q |\\Ambient_i(\\omega_i)|\n} \\makebox[5ex]{} \\\\\n& \\ge &\n\\frac{1}{\\ell_i n}\n\\sum_{s=1}^n \\log_q |\\Code^{(\\ell_{i,s})}(\\omega_i)| \\\\\n& \\ge &\n\\sum_{s \\in \\AltSet(i)}\n\\frac{\\ell_{i,s}}{\\ell_i}\n\\cdot\\frac{1}{\\ell_{i,s} n}\n\\log_q |\\Code^{(\\ell_{i,s})}(\\omega_i)| \\\\\n& \\stackrel{\\textrm{(\\ref{eq:limit-s})}}{\\ge} &\n(\\lambda(\\omega{-}\\varepsilon,n) - \\varepsilon)\n\\sum_{s \\in \\AltSet(i)}\n\\frac{\\ell_{i,s}}{\\ell_i} .\n\\end{eqnarray*}\nNoting that\n\\[\n1 - \\frac{n}{\\sqrt{\\ell_i}}\n< \\sum_{s \\in \\AltSet(i)}\n\\frac{\\ell_{i,s}}{\\ell_i} \\le 1 ,\n\\]\nwe conclude that\n\\[\n\\varliminf_{i \\rightarrow \\infty}\n\\frac{1}{\\ell_i n} \\log_q |\\Ambient_i(\\omega_i)|\n\\ge \\lambda(\\omega{-}\\varepsilon,n) - \\varepsilon.\n\\]\nFinally, we get~(\\ref{eq:limit}) by taking\nthe limit $\\varepsilon \\rightarrow 0$\nand recalling that $N_i = \\ell_i n$ and that\n\\[\n\\frac{1}{\\ell_i n} \\log_q |\\Ambient_i| = \\frac{n{-}1}{n} .\n\\]\n\\end{proof}\n\n\\begin{remark}\n\\label{rem:lambda}\nIt follows from the proof that equality is\nattained in~(\\ref{eq:limit})\nwhen $\\Ambient_i = (\\code_n)^{\\times \\ell_i}$, namely,\nthe growth rate of $\\Ambient_i(\\omega)$ is minimized\nwhen each $\\code_{i,j}$ is the $[n,n{-}1,2]$ parity code.\nThis result, however, holds only asymptotically\n(namely, when $i \\rightarrow \\infty$)\nand not necessarily for individual values of $i$.\nFor example, for $q = 2$, $n = 5$, and $\\ell_i = \\ell_1 = 1$\nwe have $|\\code_5(0.4)| = 11$\nyet $|\\code_2(0.4)| = 8$ and $|\\code_3(0.4)| = 7$.\\qed\n\\end{remark}\n\nThe next lemma involves the following definition.\n\\fi\nFor $n \\in \\Integers^+$, $\\omega \\in \\Realfield_{\\ge 0}$, and\na real $\\mu \\in [1,n]$, define:\n\\begin{equation}\n\\label{eq:WZL1}\n\\overline{\\Rate}_0(\\omega,n,\\mu) = \\max_\\bldpi \\; \\min_\\bldvartheta\n\\sum_{s \\in [n]} \\pi_s \\cdot \\Rate_0(\\vartheta_s,s) ,\n\\end{equation}\nwhere $\\Rate_0(\\cdot,\\cdot)$ is as in~(\\ref{eq:R0}),\nthe maximum is taken over all vectors\n$\\bldpi = (\\pi_s)_{s \\in [n]} \\in \\Realfield_{\\ge 0}^n$\nthat satisfy\n\\ifPAGELIMIT\n    \\[\n    \\sum_{s \\in [n]} \\pi_s = 1\n    \\quad \\textrm{and} \\quad\n    \\sum_{s \\in [n]} \\frac{\\pi_s}{s} \\ge \\frac{1}{\\mu} ,\n    \\]\n\\else\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textrm{P3)}}}\n\\item[P1)]\n$\\displaystyle \\sum_{s \\in [n]} \\pi_s = 1$ and\n\\item[P2)]\n$\\displaystyle \\sum_{s \\in [n]} \\frac{\\pi_s}{s} \\ge \\frac{1}{\\mu}$,\n\\end{list}\n\\fi\nand the minimum is taken over all vectors\n$\\bldvartheta = (\\vartheta_s)_{s \\in [n]} \\in \\Realfield_{\\ge 0}^n$\nthat satisfy\n\\ifPAGELIMIT\n    \\[\n    \\sum_{s \\in [n]} \\pi_s \\cdot \\vartheta_s = \\omega .\n    \\]\n\\else\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textrm{P3)}}}\n\\item[P3)]\n$\\displaystyle \\sum_{s \\in [n]} \\pi_s \\cdot \\vartheta_s = \\omega$.\n\\end{list}\n\\fi\n\n\\begin{remark}\n\\label{rem:computations1}\nThe expression in~(\\ref{eq:WZL1}) is fairly easy to compute,\nand we provide a formula for it\n\\ifPAGELIMIT\n    in~\\cite{RothFull}.\n    In particular, we show there that\n    $\\overline{\\Rate}_0(\\omega,n,\\mu) = \\Rate_0(\\omega,\\mu)$\n    when $\\mu$ is an integer.\\qed\n\\else\nin \\Proposition~\\ref{prop:WZL} in Appendix~\\ref{sec:R0properties}.\nIn particular, we show there that the support of\nthe maximizing vector $\\bldpi$ in~(\\ref{eq:WZL1}) \nis $\\left\\{ \\lfloor\\mu\\rfloor, \\lceil\\mu\\rceil \\right\\}$; thus,\nwhen $\\mu$ is an integer then\n\\[\n\\overline{\\Rate}_0(\\omega,n,\\mu) = \\Rate_0(\\omega,\\mu).\n\\]\nIt will also follow from our analysis that\nfor given $\\omega \\in \\Realfield_{\\ge 0}$ and $\\mu \\in [1,\\infty)$,\nthe value $\\overline{\\Rate}_0(\\omega,n,\\mu)$ is the \\emph{same}\nfor all $n \\ge \\mu$.\\qed\n\\fi\n\\end{remark}\n\n\\Proposition~\\ref{prop:R0} follows by substituting $\\mu = n$\nin the next lemma.\n\n\\begin{lemma}\n\\label{lem:mu}\nLet $(\\Ambient_i)_{i=1}^\\infty$ be as in\n\\Proposition~\\ref{prop:R0}\nand assume in addition that for a prescribed $\\mu \\in [1,n]$,\nthe \\underline{average length} of the constituent codes satisfies\n\\ifPAGELIMIT\n    \\[\n    \\varlimsup_{i \\rightarrow \\infty} N_i/\\ell_i \\le \\mu .\n    \\]\n\\else\n\\begin{equation}\n\\label{eq:averagelength}\n\\varlimsup_{i \\rightarrow \\infty} \\frac{N_i}{\\ell_i} \\le \\mu .\n\\end{equation}\n\\fi\nThen for any nonnegative real sequence $(\\omega_i)_{i=1}^\\infty$\nsuch that $\\varliminf_{i \\rightarrow \\infty} \\omega_i = \\omega$:\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q\n\\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|} \\le\n\\overline{\\Rate}_0(\\omega,n,\\mu) ,\n\\]\nwhere $\\overline{\\Rate}_0(\\omega,n,\\mu)$\nis defined in~(\\ref{eq:WZL1}).\n\\end{lemma}\n\n\\ifPAGELIMIT\nRefer to~\\cite{RothFull} for a proof of the lemma.\n\\else\n\\begin{proof}\nBy possibly permuting the coordinates of $\\Ambient_i$,\nwe can write\n\\[\n\\Ambient_i =\n\\Ambient_{i,1} \\times \\Ambient_{i,2} \\times \\cdots \\times\n\\Ambient_{i,n} ,\n\\]\nwhere each $\\Ambient_{i,s}$\nis a linear $[s \\cdot \\ell_{i,s}, (s{-}1) \\cdot \\ell_{i,s}]$ code\nover $F$ of the form\n\\[\n\\Ambient_{i,s} = \\code'_{i,1} \\times \\code'_{i,2}\n\\times \\cdots \\times \\code'_{i,\\ell_{i,s}} ,\n\\]\nwith each $\\code'_{i,j}$ being\na linear $[s,s{-}1]$ code over $F$.\n\nDefine $\\bldpi_i = (\\pi_{i,s})_{s \\in [n]}$ by\n\\begin{equation}\n\\label{eq:piis}\n\\pi_{i,s} = \\frac{s \\cdot \\ell_{i,s}}{N_i}\n\\end{equation}\n(i.e., $\\pi_{i,s}$ is the fraction of coordinates of $\\Ambient_i$\nthat correspond to constituent codes of length $s$).\nWe have\n\\begin{equation}\n\\label{eq:piis1}\n\\sum_{s \\in [n]} \\pi_{i,s}\n= \\frac{1}{N_i} \\sum_{s \\in [n]} s \\cdot \\ell_{i,s}\n= \\frac{1}{N_i} \\sum_{j \\in [\\ell_i]} n_{i,j} = 1\n\\end{equation}\nand\n\\begin{equation}\n\\label{eq:piis2}\n\\varliminf_{i \\rightarrow \\infty}\n\\sum_{s \\in [n]} \\frac{\\pi_{i,s}}{s}\n=\n\\varliminf_{i \\rightarrow \\infty}\n\\frac{1}{N_i} \\sum_{s \\in [n]} \\ell_{i,s}\n=\n\\varliminf_{i \\rightarrow \\infty}\n\\frac{\\ell_i}{N_i}\n\\stackrel{\\textrm{(\\ref{eq:averagelength})}}{\\ge}\n\\frac{1}{\\mu} .\n\\end{equation}\nBy possibly restricting to a subsequence of\n$(\\Ambient_i)_{i=1}^\\infty$,\nwe can assume that the sequence $(\\bldpi_i)_{i=1}^\\infty$ converges to\na limit $\\bldpi = (\\pi_s)_{s \\in [n]}$;\nby~(\\ref{eq:piis1})--(\\ref{eq:piis2}),\nthis limit satisfies conditions~(P1) and~(P2).\n \nLet $(\\omega_i)_{i=1}^\\infty$\nbe a nonnegative real sequence\nsuch that $\\varliminf_{i \\rightarrow \\infty}\\omega_i = \\omega$\nand let $\\bldvartheta = (\\vartheta_s)_{s \\in [n]}$\nbe a vector in $\\Realfield_{\\ge 0}^n$ that satisfies condition~(P3).\nFor any $i \\in \\Integers^+$ and $s \\in [n]$, define:\n\\[\n\\vartheta_{i,s} =\n\\left\\{\n\\begin{array}{ccl}\n\\rule[0ex]{0ex}{3ex}\n\\displaystyle\n\\frac{\\pi_s}{\\pi_{i,s}} \\cdot\n\\frac{\\omega_i}{\\omega} \\cdot \\vartheta_s\n&& \\textrm{if $\\omega > 0$ and $s \\in \\Support(\\bldpi_i)$} \\\\\n0\n&& \\textrm{otherwise}\n\\end{array}\n\\right.\n,\n\\]\nwhere $\\Support(\\cdot)$ denotes the support of a vector.\nIt is easily seen that\n\\begin{equation}\n\\label{eq:vartheta}\n\\sum_{s \\in [n]} \\pi_{i,s} \\cdot \\vartheta_{i,s} \\le \\omega_i\n\\end{equation}\nand that for any $s \\in \\Support(\\bldpi)$:\n\\[\n\\lim_{i \\rightarrow \\infty} \\vartheta_{i,s} = \\vartheta_s .\n\\]\nWe then have:\n\\[\n\\frac{1}{N_i}\n\\log_q |\\Ambient_i|\n\\stackrel{\\textrm{(\\ref{eq:piis})}}{=}\n\\sum_{s \\in \\Support(\\bldpi_i)}\n\\pi_{i,s} \\cdot\n\\frac{1}{s \\cdot \\ell_{i,s}}\n\\log_q |\\Ambient_{i,s}|\n\\]\nand\n\\[\n\\frac{1}{N_i}\n\\log_q |\\Ambient_i(\\omega_i)|\n\\stackrel{\\textrm{(\\ref{eq:piis})+(\\ref{eq:vartheta})}}{\\ge}\n\\!\n\\sum_{s \\in \\Support(\\bldpi_i)}\n\\!\n\\pi_{i,s} \\cdot\n\\frac{1}{s \\cdot \\ell_{i,s}}\n\\log_q |\\Ambient_{i,s}(\\vartheta_{i,s})| .\n\\]\nHence,\n\\begin{eqnarray*}\n\\lefteqn{\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|}\n} \\makebox[0ex]{} \\\\\n& \\le &\n\\varlimsup_{i \\rightarrow \\infty}\n\\sum_{s \\in \\Support(\\bldpi_i)}\n\\pi_{i,s} \\cdot\n\\frac{1}{s \\cdot \\ell_{i,s}}\n\\log_q \\frac{|\\Ambient_{i,s}|}{|\\Ambient_{i,s}(\\vartheta_{i,s})|} \\\\\n& = &\n\\sum_{s \\in \\Support(\\bldpi)}\n\\varlimsup_{i \\rightarrow \\infty}\n\\pi_{i,s} \\cdot\n\\frac{1}{s \\cdot \\ell_{i,s}}\n\\log_q \\frac{|\\Ambient_{i,s}|}{|\\Ambient_{i,s}(\\vartheta_{i,s})|} \\\\\n& \\stackrel{\\textrm{Lemma~\\ref{lem:lambda}}}{\\le} &\n\\sum_{s \\in [n]} \\pi_s \\cdot \\Rate_0(\\vartheta_s,s) .\n\\end{eqnarray*}\nFinally, selecting $\\bldvartheta \\in \\Realfield_{\\ge 0}^n$\nthat minimizes the inner expression in~(\\ref{eq:WZL1})\n(subject to condition~(P3)), we get:\n\\begin{eqnarray*}\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|}\n& \\le &\n\\min_\\bldvartheta\n\\sum_{s \\in [n]} \\pi_s \\cdot \\Rate_0(\\vartheta_s,s) \\\\\n& \\le &\n\\overline{\\Rate}_0(\\omega,n,\\mu) ,\n\\end{eqnarray*}\nfor any $\\bldpi \\in \\Realfield_{\\ge 0}^n$\nthat satisfies conditions (P1)--(P2).\n\\end{proof}\n\n\\subsection{Ambient spaces of LRCs}\n\\label{sec:ambient}\n\\fi\n\nLet $\\varcode$ be a linearly recoverable LRC \n(which is not necessarily all-disjoint)\nof length $N$ and locality $r = n-1$ over $F$,\nand let $\\{ \\Local_j \\}_j$ be\na set of distinct repair groups of $\\varcode$.\nRecall that for each repair group $\\Local_j$,\nthe constituent code $(\\varcode)_{\\Local_j}$ is a subcode\nof a linear $[|\\Local_j|,|\\Local_j|{-}1]$ code, $\\code_j$, over $F$.\nLet $\\Ambient$ be a largest subset of $F^N$\nwhich satisfies the following linear constraints:\n\\begin{equation}\n\\label{eq:ambient}\n(\\Ambient)_{\\Local_j} \\subseteq \\code_j ,\n\\quad j \\in [\\ell] .\n\\end{equation}\nClearly, $\\Ambient$ is a linear subspace of $F^N$\n(which is defined uniquely by~(\\ref{eq:ambient}))\nand $\\varcode \\subseteq \\Ambient$.\nWe will refer hereafter to $\\Ambient$ as an \\emph{ambient space}\nof $\\varcode$ (this term is similar to the notion of\nan $\\mathcal{L}$-space defined in~\\cite{WZL}).\n\nIn the all-disjoint case, we can assume that\n$\\{ \\Local_j \\}_j$ forms a partition of $[N]$.\nBy possibly permuting the coordinates of both\n$\\varcode$ and $\\Ambient$, we can further assume that\n$\\Ambient$ takes the form\n\\[\n\\Ambient = \\code_1 \\times \\code_2 \\times \\cdots \\times \\code_\\ell .\n\\]\n\n\\ifPAGELIMIT\n\\else\n\\subsection{Sphere-packing bound}\n\\label{sec:spherepackingbound}\n\\fi\n\nAmbient spaces were used in~\\cite{WZL} as an ingredient\nin obtaining a sphere-packing bound on LRCs.\nThe asymptotic formulation of this bound is presented in\nthe next theorem.\n\n\\begin{theorem}\n\\label{thm:spherepacking}\nThe rate of any all-disjoint linearly recoverable\n$(\\delta,n)$-LRC sequence over $F$ is bounded from above by\n\\[\n\\Rate_\\SP(\\delta,n) = \n\\ifPAGELIMIT\n    \\Rate_0(\\delta/2,n)\n\\else\n\\Rate_0 \\left( \\frac{\\delta}{2} , n \\right)\n\\fi\n.\n\\]\n\\end{theorem}\n\n\\begin{proof}\nLet $(\\varcode_i)_{i=1}^\\infty$ be\nan all-disjoint linearly recoverable $(\\delta,n)$-LRC sequence,\nwith $N_i$ and $d_i$ being the length and the minimum distance\nof $\\varcode_i$.\nLetting $\\Ambient_i$ be an ambient space of $\\varcode_i$,\nby a sphere-packing argument we get:\n\\[\n|\\varcode_i| \\le \\frac{|\\Ambient_i|}{\\Ambient_i(d_i{-}1/(2N_i))} .\n\\]\nThe result follows from \\Proposition~\\ref{prop:R0}\nby taking $\\omega_i = (d_i{-}1)/(2N_i)$.\n\\end{proof}\n\n\\begin{remark}\n\\label{rem:averagelength1}\n\\ifPAGELIMIT\n    More generally, we get from Lemma~\\ref{lem:mu} that\n    $\\overline{\\Rate}_0(\\delta/2,n,\\mu)$ is a sphere-packing\n    upper bound in a setting where\n    the \\emph{average size} of the distinct (and disjoint)\n    repair groups of each code in\n    the LRC sequence is at most $\\mu$.\\qed\n\\else\nFor general $\\mu \\in [1,n]$, we get from Lemma~\\ref{lem:mu} that\n\\[\n\\overline{\\Rate}_0 \\left( \\frac{\\delta}{2} , n, \\mu \\right)\n\\]\nis an upper bound on the rate of any all-disjoint\nlinearly recoverable $(\\delta,n)$-LRC sequence\n$(\\varcode_i)_{i=1}^\\infty$ over $F$,\nwith $\\mu$ bounding from above\nthe supremum (as $i \\rightarrow \\infty$) over\nthe \\emph{average sizes}, $N_i/\\ell_i$,\nof the distinct (and disjoint) repair groups of $\\varcode_i$.\nA similar bound can be stated when the average size\nis computed per coordinate, so that each repair group\nis counted a number of times equaling its size.\nSee Remark~\\ref{rem:averagelength2}\nin Appendix~\\ref{sec:R0properties}.\\qed\n\\fi\n\\end{remark}\n\n\\section{Proofs of Theorems~\\ref{thm:bound1} and~\\ref{thm:bound2}}\n\\label{sec:mainresults}\n\nIn this section, we prove\n\\Theorems~\\ref{thm:bound1} and~\\ref{thm:bound2}.\n\nWe start with the next simple lemma, usually attributed to\n\\ifPAGELIMIT\n    Bassalygo or Elias (see a short proof in~\\cite{RothFull}).\n\\else\nBassalygo or Elias; it provides an effective tool\nin obtaining upper bounds.\n\\fi\n\n\\begin{lemma}\n\\label{lem:bassalygo}\nLet $\\Ambient$ be a subspace of $F^N$\nand let $\\Subset$ and $\\varcode$ be subsets of $\\Ambient$.\nThen there exists $\\bldy \\in \\Ambient$ for which\n\\[\n\\left| (\\bldy + \\varcode) \\cap \\Subset \\right| \\ge\n\\frac{|\\Subset|}{|\\Ambient|} \\cdot |\\varcode| .\n\\]\n\\end{lemma}\n\n\\ifPAGELIMIT\n\\else\n\\begin{proof}\nLet $\\chi_\\Subset : \\Ambient \\rightarrow \\{ 0, 1 \\}$\nbe the characteristic function of $\\Subset$, namely,\n$\\chi(\\bldy) = 1$ when $\\bldy \\in \\Subset$\nand $\\chi(\\bldy) = 0$ otherwise.\nThen,\n\\begin{eqnarray*}\n\\frac{1}{|\\Ambient|} \\cdot |\\varcode| \\cdot |\\Subset|\n& = &\n\\frac{1}{|\\Ambient|}\n\\sum_{\\bldc \\in \\varcode} \\sum_{\\bldy \\in \\Ambient}\n\\chi_\\Subset(\\bldc + \\bldy) \\\\\n& = &\n\\frac{1}{|\\Ambient|}\n\\sum_{\\bldy \\in \\Ambient} \\sum_{\\bldc \\in \\varcode}\n\\chi_\\Subset(\\bldy + \\bldc) \\\\\n& = &\n\\frac{1}{|\\Ambient|}\n\\sum_{\\bldy \\in \\Ambient}\n\\left| (\\bldy + \\varcode) \\cap \\Subset \\right| .\n\\end{eqnarray*}\nHence,\n\\[\n\\max_{\\bldy \\in \\Ambient}\n\\left| (\\bldy + \\varcode) \\cap \\Subset \\right|\n\\ge \\frac{|\\Subset|}{|\\Ambient|} \\cdot |\\varcode| .\n\\]\n\\end{proof}\n\\fi\n\n\\begin{proof}[Proof of \\Theorem~\\ref{thm:bound1}]\nWe tailor the generalization of\nthe shortening method of~\\cite[\\Theorems~1 and~2]{LL} to our setting.\nLet $(\\varcode_i)_{i=1}^\\infty$ be an all-disjoint linearly recoverable\n$(\\delta,n)$-LRC sequence over $F$\nand fix $\\tau$ in the interval $(0,1)$\nand a pair $(\\theta,\\theta') \\in [0,(q{-}1)/q]^2$\nthat satisfies~(\\ref{eq:theta}).\nFor each $i \\in \\Integers^+$, let $N_i$ and $d_i$ be\nthe length and the minimum distance of $\\varcode_i$, respectively,\nwhere\n\\begin{equation}\n\\label{eq:di}\n\\varliminf_{i \\rightarrow \\infty}\n\\ifPAGELIMIT\nd_i/N_i\n\\else\n\\frac{d_i}{N_i}\n\\fi\n\\ge \\delta .\n\\end{equation}\n\nLet $\\{ \\Local_{i,j} \\}_{j \\in [\\ell_i]}$\nbe a set of distinct (and disjoint) repair groups of $\\varcode_i$,\nand denote\n\\[\nt_i = \\left|\n{\\textstyle\\bigcup_{j \\in [\\ell'_i]}} \\Local_{i,j} \\right| ,\n\\]\nwhere $\\ell'_i$ is the smallest in $[\\ell_i]$ so that\n$t_i \\ge \\tau N_i$; in particular,\n\\begin{equation}\n\\label{eq:ti}\n\\lim_{i \\rightarrow \\infty}\n\\ifPAGELIMIT\nt_i/N_i\n\\else\n\\frac{t_i}{N_i}\n\\fi\n= \\tau .\n\\end{equation}\nBy possibly permuting the coordinates\nof $\\varcode_i$, we assume hereafter in the proof that\n$\\bigcup_{j \\in [\\ell'_i]} \\Local_{i,j}$\nindexes the first $t_i$\n\\ifPAGELIMIT\n    coordinates\n\\else\ncoordinates\\footnote{%\nNamely, we deviate here from the notational convention that we set\nin Footnote~\\ref{footnote:locality}.}\n\\fi\nof $\\varcode_i$.\nLetting $\\Ambient_i$ be an ambient space of $\\varcode_i$,\nwe denote by $\\Ambient'_i$ the set of the distinct $t_i$-prefixes of\nthe vectors in $\\Ambient_i$;\nthe sequence $(\\Ambient'_i)_{i=1}^\\infty$\nsatisfies the conditions of \\Proposition~\\ref{prop:R0}.\n\nDefine\n\\[\nw_i =\n\\min\n\\left\\{\n\\ifPAGELIMIT\n\\lfloor \\theta \\cdot t_i/2 \\rfloor ,\n\\lfloor (d_i{-}1)/2 \\rfloor \n\\else\n\\Bigl\\lfloor \\frac{\\theta}{2} \\cdot t_i \\Bigr\\rfloor ,\n\\Bigl\\lfloor \\frac{d_i-1}{2} \\Bigr\\rfloor \n\\fi\n\\right\\} .\n\\]\nBy~(\\ref{eq:di})--(\\ref{eq:ti}) (and~(\\ref{eq:theta})) we have:\n\\begin{equation}\n\\label{eq:mi}\n\\lim_{i \\rightarrow \\infty}\n\\ifPAGELIMIT\n\\omega_i/t_i = \\theta/2\n\\else\n\\frac{\\omega_i}{t_i} = \\frac{\\theta}{2}\n\\fi\n.\n\\end{equation}\nNext, we apply Lemma~\\ref{lem:bassalygo}\nwith $\\varcode \\leftarrow \\varcode_i$\nand $\\Ambient \\leftarrow \\Ambient_i$, and with\n$\\Subset$ taken as the set of all vectors in $\\Ambient_i$\nwhose $t_i$-prefixes are in\n\\ifPAGELIMIT\n    $\\Ambient'_i(w_i/t_i)$.\n\\else\n$\\Ambient'_i(w_i/t_i)$; namely,\n\\begin{equation}\n\\label{eq:Subset}\n\\Subset = \\Ambient'_i(w_i/t_i) \\times \\Ambient''_i ,\n\\end{equation}\nwhere $\\Ambient''_i$ is the set of\n$(N_i - t_i)$-suffixes of the vectors of $\\Ambient_i$.\n\\fi\nIt follows that\nthere exists $\\bldy = (\\bldy' \\; \\bldy'') \\in \\Ambient_i$\n(where $\\bldy' \\in \\Ambient'_i$)\nfor which the intersection\n\\[\n\\varcode^*_i = (\\bldy + \\varcode_i) \\cap \\Subset\n\\]\nsatisfies\n\\begin{equation}\n\\label{eq:bound1-1}\n|\\varcode_i|\n\\le\n\\frac{|\\Ambient_i| \\cdot |\\varcode^*_i|}{|\\Subset|}\n= \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|} \\cdot |\\varcode^*_i| .\n\\end{equation}\nNow, on the one hand,\nthe code $-\\bldy + \\varcode^*_i$ is\nan all-disjoint linearly recoverable LRC\nwith locality $r = n-1$ and minimum distance${} \\ge d_i$;\nyet, on the other hand, all the $t_i$-prefixes of its codewords\nare at distance at most $w_i$ from $-\\bldy'$,\nwhich means that any two prefixes are at most $2w_i$ apart.\nIt follows that all\nthe $(N_i - t_i)$-suffixes of the codewords of\n$-\\bldy + \\varcode^*_i$\nform an all-disjoint linearly recoverable LRC, $\\varcode''_i$,\n\\ifPAGELIMIT\n    of minimum distance${} \\ge d_i - 2w_i \\; (> 0)$.\n\\else\nof minimum distance${} \\ge d_i - 2w_i \\; (> 0)$\n(in particular, these suffixes are all distinct).\n\\fi\nHence,\n\\begin{equation}\n\\label{eq:bound1-2}\n|\\varcode^*_i| = |\\varcode''_i| \\le M_\\LRC(N_i - t_i, d_i - 2w_i, n) ,\n\\end{equation}\nwhere $M_\\LRC(N,D,n)$ denotes the largest size\nof any all-disjoint linearly recoverable LRC over $F$\nwith length $N$, minimum distance $D$, and locality $n-1$.\nCombining~(\\ref{eq:bound1-1}) and~(\\ref{eq:bound1-2}) leads to\n\\[\n|\\varcode_i|\n\\le\n\\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|}\n\\cdot M_\\LRC(N_i - t_i, d_i - 2w_i, n) ,\n\\]\nand taking logarithms and dividing by $N_i$ yield\nthe following upper bound on the rate,\n$R_i =  (\\log_q |\\varcode_i|)/N_i$, of $\\varcode_i$:\n\\begin{eqnarray}\nR_i\n& \\le &\n\\frac{1}{N_i}\n\\Bigl(\n\\log_q \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|} \\nonumber \\\\\n&&\n\\quad\n{} + \\log_q M_\\LRC(N_i - t_i, d_i - 2w_i, n) \\Bigr) \\nonumber \\\\\n& = &\n\\frac{t_i}{N_i} \\cdot\n\\left(\n\\frac{1}{t_i}\n\\log_q \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|} \\right) \\nonumber \\\\\n&&\n\\;\\;\n{} +\n\\left( 1 - \\frac{t_i}{N_i} \\right)\n\\cdot\n\\frac{\\log_q M_\\LRC(N_i - t_i, d_i - 2w_i, n)}{N_i - t_i} . \\nonumber \\\\\n\\label{eq:Ri1}\n&&\n\\end{eqnarray}\n\nWe now take the limit as $i \\rightarrow \\infty$\nof each of the terms in~(\\ref{eq:Ri1}).\nBy~(\\ref{eq:mi}) and \\Proposition~\\ref{prop:R0} we get\n\\ifPAGELIMIT\n    \\[\n    \\varlimsup_{i \\rightarrow \\infty}\n    \\frac{1}{t_i}\n    \\log_q \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|}\n    \\le \\Rate_0(\\theta/2,n) .\n\\]\n\\else\n\\begin{equation}\n\\label{eq:ratio}\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{t_i}\n\\log_q \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|}\n\\le \\Rate_0 \\left( \\frac{\\theta}{2} , n \\right) .\n\\end{equation}\n\\fi\nIn addition,\n\\[\n\\varliminf_{i \\rightarrow \\infty}\n\\frac{d_i - 2w_i}{N_i - t_i}\n\\stackrel{\\textrm{(\\ref{eq:di})--(\\ref{eq:mi})}}{\\ge}\n\\frac{\\delta - \\tau \\cdot \\theta}{1-\\tau}\n\\stackrel{\\textrm{(\\ref{eq:theta})}}{=}\n\\theta'\n\\]\nand, so,\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{\\log_q M_\\LRC(N_i - t_i, d_i - 2w_i, n)}{N_i - t_i}\n\\le \\Rate_\\LRC(\\theta',n) .\n\\]\nWe conclude that the rate $R$\nof the code sequence $(\\varcode_i)_{i=1}^\\infty$\nsatisfies\n\\[\nR = \\varlimsup_{i \\rightarrow \\infty} R_i \\le \\tau \\cdot\n\\ifPAGELIMIT\n\\Rate_0(\\theta/2)\n\\else\n\\Rate_0 \\left( \\frac{\\theta}{2} \\right)\n\\fi\n+ (1-\\tau) \\cdot \\Rate_\\LRC(\\theta', n) .\n\\]\nThe sought result is reached by\nminimizing over $\\theta$ and $\\tau$.\n\\end{proof}\n\nWe now turn to the proof of \\Theorem~\\ref{thm:bound2}.\nRecall that the expression $\\Rate_2(\\delta,n)$ therein\ninvolves the value $\\Rate_\\opt(\\delta,\\omega)$, being\nthe supremum over all rates of sequences $(\\varcode_i)_{i=1}^\\infty$\nwith r.m.d.${} \\ge \\delta$\nsuch that the codewords in each $\\varcode_i$ all have\nthe \\emph{same} weight${} \\approx \\omega N_i$.\nFor our purposes, it would be convenient if this definition\nwere relaxed so that the codeword weights only need to be\n\\emph{bounded from above} by\n\\ifPAGELIMIT\n    $\\omega N_i + o(N_i)$.\n    It turns out that $\\Rate_\\opt(\\delta,\\omega)$ is\n    the rate supremum also under this relaxed setting, provided that\n    $\\omega \\in [0,(q{-}1)/q]$ (see~\\cite{BCCST} and~\\cite{RothFull}).\n\\else\n(approximately) $\\omega N_i$.\nIt turns out that $\\Rate_\\opt(\\delta,\\omega)$ is\nthe rate supremum also under this relaxed setting, provided that\n$\\omega \\in [0,(q{-}1)/q]$.\nWe make this statement precise in Lemma~\\ref{lem:CW} below.\n\\fi\n\nFor $N, d, w \\in \\Integers^+$,\nlet $M_\\opt(N,d,w)$ denote the largest size of\nany code in $F^N$ with minimum distance $d$ and codeword\nweights that are all bounded from above by $w$.\n\\ifPAGELIMIT\n\\else\nDefine\n\\[\n\\Rate_\\opt(\\delta,{\\le}\\omega)\n= \\sup_{\n\\genfrac{}{}{0ex}{}{%\n                  \\bldd \\in \\InfSet(\\delta)}{\\bldw \\in \\SupSet(\\omega)}}\n\\varlimsup_{N \\rightarrow \\infty}\n\\frac{1}{N}\n\\log_q M_\\opt(N,d_N,w_N) ,\n\\]\nwhere $\\InfSet(\\delta)$\n(respectively, $\\SupSet(\\omega)$) is the set of\nall sequences $(a_N)_{N=1}^\\infty$ over $\\Integers^+$\nsatisfying $\\varliminf_{N \\rightarrow \\infty} a_N/N \\ge \\delta$\n(respectively, $\\varlimsup_{N \\rightarrow \\infty} a_N/N \\le \\omega$).\n\nWe have the following technical lemma, which is proved\nin Appendix~\\ref{sec:skippedproofs}.\n\n\\begin{lemma}\n\\label{lem:CW}\nFor every $\\delta, \\omega \\in [0,(q{-}1)/q]$,\n\\[\n\\Rate_\\opt(\\delta,{\\le}\\omega) = \\Rate_\\opt(\\delta,\\omega) .\n\\]\n\\end{lemma}\n\\fi\n\n\\begin{proof}[Proof of \\Theorem~\\ref{thm:bound2}]\nLet $(\\varcode_i)_{i=1}^\\infty$\nbe an all-disjoint linearly recoverable\n$(\\delta,n)$-LRC sequence over $F$.\nLetting $\\Ambient_i$ be an ambient space\nof $\\varcode_i$, the sequence $(\\Ambient_i)_{i=1}^\\infty$\nsatisfies the conditions of \\Proposition~\\ref{prop:R0}.\n\nFixing any\n\\ifPAGELIMIT\n    $\\omega$\n\\else\n$\\omega \\in [\\delta/2,(q{-}1)/q]$\n\\fi\nand substituting $\\varcode \\leftarrow \\varcode_i$,\n$\\Ambient \\leftarrow \\Ambient_i$, and\n$\\Subset \\leftarrow \\Ambient_i(\\omega)$\nin Lemma~\\ref{lem:bassalygo} yield\nthat there exists $\\bldy \\in \\Ambient_i$ for which\n\\begin{eqnarray*}\n|\\varcode_i| \\cdot \n|\\Ambient_i(\\omega)|\n& \\le &\n|\\Ambient_i| \\cdot \n\\left| (\\bldy + \\varcode_i)\n\\cap \\Ambient_i(\\omega) \\right| \\\\\n& \\le &\n|\\Ambient_i| \\cdot M_\\opt(N_i,d_i,\\omega) ,\n\\end{eqnarray*}\nwhere $N_i$ and $d_i$ are the length and\nthe minimum distance of $\\varcode_i$, respectively.\nTaking logarithms and dividing by $N_i$ yield\nthe following upper bound on the rate $R_i$ of $\\varcode_i$:\n\\begin{equation}\n\\label{eq:Ri2}\nR_i\n\\le\n\\frac{1}{N_i} \\log_q \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega)|}\n+ \\frac{1}{N_i} \\log_q M_\\opt(N_i,d_i,w_i) ,\n\\end{equation}\nwhere $w_i = \\lfloor \\omega N_i \\rfloor$.\nThe result is obtained by taking\nthe limit as\n\\ifPAGELIMIT\n    $i \\rightarrow \\infty$:\n    the first term in the right-hand side of~(\\ref{eq:Ri2})\n    will then be at most $\\Rate_0(\\omega,n)$\n    (by \\Proposition~\\ref{prop:R0}),\n    and the second term will be at most $\\Rate_\\opt(\\delta,\\omega)$.\n\\else\n$i \\rightarrow \\infty$.\nSpecifically, on the left-hand side of~(\\ref{eq:Ri2}) we get\nthe rate $R = \\varlimsup_{i \\rightarrow \\infty} R_i$\nof $(\\varcode_i)_{i=1}^\\infty$,\nand on the right-hand side the respective terms become\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i} \\log_q \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega)|}\n\\stackrel{\\textrm{\\Proposition~\\ref{prop:R0}}}{\\le}\n\\Rate_0(\\omega,n)\n\\]\nand\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q M_\\opt(N_i,d_i,w_i)\n\\stackrel{\\textrm{Lemma}~\\ref{lem:CW}}{\\le}\n\\Rate_\\opt(\\delta,\\omega) .\n\\]\n\\fi\n\\end{proof}\n\n\\ifPAGELIMIT\n\\else\n\\section{The case $q = 2$ and $n = 3$}\n\\label{sec:q=2,n=3}\n\nWe consider in this section\nthe case $n = 3$ over the binary field.\nWe assume that the LRCs are all-disjoint, but not\nnecessarily linearly recoverable.\n\nAs a warm-up, we start with the case $n = 2$ over any finite field.\nIt is straightforward to see that\nif an all-disjoint $(N,M,d)$ LRC $\\varcode$ over $F$\nwith locality $n-1 = 1$ has no fixed (in particular, trivial)\ncoordinates, then all the repair groups have to be of size\n(exactly) $2$, and all the constituent codes have minimum distance\n(exactly) $2$.\\footnote{%\nIf $\\varcode$ does contain trivial coordinates,\nwe can shorten it on these coordinates,\nthereby only increasing the r.m.d.\\ and the rate\nand, thus, obtaining an upper bound on that larger rate.}\nThus, both $N$ and $d$ are even and,\nwithout loss of generality,\neach constituent code is the $[2,1,2]$ repetition code over $F$.\nWe can therefore view $\\varcode$ as a concatenated code over $F$\ncomprising an outer $(N/2,M,d/2)$ code over $F$\nand an inner $[2,1,2]$ repetition code over $F$.\nWe conclude that the rate of any\nall-disjoint $(\\delta,2)$-LRC sequence over $F$ is\nbounded from above by $(1/2) \\cdot \\Rate_\\opt (\\delta)$;\nmoreover, we can get arbitrarily close to this bound\nby a concatenated code construction.\\footnote{%\nThis upper bound holds in fact also when the repair groups\nare not necessarily disjoint, as overlapping repair groups force\nall the entries that are indexed by their union to be equal.\nThis corresponds to having inner repetition codes\nof rate smaller than $1/2$.}\n\nWe now turn to the case $n = 3$ when $F = \\Finitefield_2$.\nLet $\\varcode$ be an all-disjoint $(N,M,d)$ LRC over $F$\nwith locality $n-1 = 2$ and without fixed coordinates,\nand assume first that all the repair groups have size exactly $3$.\nThen each constituent code $(\\varcode)_{\\Local_j}$,\nbeing of length $3$ and minimum distance${} \\ge 2$\nand having no fixed coordinates,\nhas size $2$, $3$, or $4$. It is rather easy to see\nthat such codes are essentially unique (up to a replacement\n$0 \\leftrightarrow 1$ at any given coordinate across all codewords).\nMoreover, any $(3,3,2)$ code over $F$ is necessarily equi-distant\n(i.e., the distance between any two distinct codewords is exactly $2$)\nand can be augmented by a fourth codeword while still remaining\nequi-distant. Hence, we assume that each constituent code\nis either the $[3,1,3]$ repetition code\nor the $[3,2,2]$ parity code (which is equi-distant).\nWe can therefore view $\\varcode$ as a concatenated code over $F$\ncomprising an outer code $\\Code$ of length $\\ell = N/3$\nand size $M$ over a \\emph{mixed alphabet}, namely:\n\\[\n\\Code \\subseteq F^t \\times (F^2)^{\\ell-t} ,\n\\]\nfor some $t \\le \\ell$. The first $t$ (binary) coordinates\nare mapped to an inner code which is the $[3,1,3]$ repetition code,\nand the remaining $\\ell-t$ (quaternary) coordinates \nare mapped to the $[3,2,2]$ parity code.\nWriting each codeword of $\\Code$ as $(\\bldc \\; \\bldc')$,\nwhere $\\bldc \\in F^t$ and $\\bldc' \\in (F^2)^{\\ell-t}$,\nthe following inequality must hold for any two distinct codewords\n$(\\bldc_1 \\; \\bldc'_1), (\\bldc_2 \\; \\bldc'_2)\\in \\Code$\nto maintain the minimum distance $d$ of $\\varcode$:\n\\begin{equation}\n\\label{eq:distance}\n3 \\distance_F(\\bldc_1,\\bldc_2)\n+ 2 \\distance_{F^2}(\\bldc'_1,\\bldc'_2) \\ge d ,\n\\end{equation}\nwhere $\\distance_Q(\\cdot,\\cdot)$ denotes Hamming distance\nover the alphabet $Q$.\nRegarding now $\\varcode$ as an element in\na $(\\delta,3)$-LRC sequence\nwhere $t/\\ell$ converges to $\\tau \\in [0,1]$,\nthe condition~(\\ref{eq:distance}) becomes\n\\begin{equation}\n\\label{eq:distance-asymptotic}\n\\tau \\cdot \\frac{\\distance_F(\\bldc_1,\\bldc_2)}{t} \n+ \\frac{2}{3}\n(1-\\tau) \\cdot \\frac{\\distance_{F^2}(\\bldc'_1,\\bldc'_2)}{\\ell-t} \n\\ge \\delta .\n\\end{equation}\nWe are interested in finding the value of $\\tau$ for which\nthe rate of the LRC sequence is maximized,\nsubject to satisfying~(\\ref{eq:distance-asymptotic}).\nWe do this using the following lemma;\nthe function $\\delta \\mapsto \\Rate_{\\LP;Q}(\\delta)$\nstands for the (second) linear-programming bound,\ndue to Aaltonen~\\cite[p.~141]{Aaltonen},\non the rate of code sequences over a finite alphabet $Q$\n(see also~\\cite[\\Theorem~1]{BHL1}).\n\n\\begin{lemma}\n\\label{lem:BHL}\nLet $Q$ and $Q'$ be finite alphabets\nand fix $\\beta, \\beta' \\in \\Realfield^+$\nand $\\tau \\in [0,1]$.\nLet $(\\Code_i)_{i=1}^\\infty$ be a code sequence such that\n\\[\n\\Code_i \\subseteq Q^{t_i} \\times (Q')^{\\ell_i-t_i},\n\\]\nwhere $\\lim_{i \\rightarrow \\infty} t_i/\\ell_i = \\tau$.\nSuppose also that\nthe (weighted) r.m.d.\\ of the sequence is at least $\\delta$,\nwhere, for the purpose of computing distances,\neach coordinate of $Q$ (respectively, $Q'$) contributes\n$\\beta$ (respectively, $\\beta'$) to the distance.\nThen\n\\begin{eqnarray}\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{\\log |\\Code_i|}{\\ell_i}\n\\!\\!\\! & \\le & \\!\\!\\!\n\\min_{(\\theta,\\theta')}\n\\Bigl\\{\n\\tau \\cdot \\Rate_{\\LP;Q}(\\theta) \\log |Q| \\nonumber \\\\\n\\label{eq:BHL}\n&&\n{}\n+ (1-\\tau) \\cdot \\Rate_{\\LP;Q'}(\\theta') \\log |Q'| \\Bigr\\} ,\n\\end{eqnarray}\nwhere the minimum is taken over\n$(\\theta,\\theta') \\in [0,1]^2$ such that\n\\[\n\\tau \\cdot \\beta \\cdot \\theta\n+ (1-\\tau) \\cdot \\beta' \\cdot \\theta' = \\delta .\n\\]\n\\end{lemma}\n\nA special case of this lemma, for the case $Q = Q'$\nand $\\beta = \\beta'$, was proved by Ben-Haim and Litsyn\nin~\\cite{BHL1}.\\footnote{%\nThis is not stated so explicitly in~\\cite{BHL1},\nbut this is what \\Theorem~7 in~\\cite{BHL1} reduces to\nwhen Eq.~(36) in that paper is plugged into Eq.~(39)\nand the result is then plugged into Eq.~(40).}\nFor this case, Lemma~\\ref{lem:BHL} states that\nthe bound $\\delta \\mapsto \\Rate_{\\LP;Q}(\\delta)$\ncan be improved by taking its lower convex envelope\n(it turns out that this bound is not convex\nfor general $Q$). With little effort,\n\\Theorem~5 in~\\cite{BHL1} can be adapted\nto the case of mixed alphabets and\nweighted distance~\\cite{BHL2}.\\footnote{%\nSpecifically, one only needs to modify the definition of\nthe function $f$ in that theorem so that\nthe first multiplicand therein is\n$\\beta (a_1 + b_1 - x_1 - y_1) + \\beta' (a_2 + b_2 - x_2 - y_2)$.\nThe proof, as is, holds also when\nthe prefixes and suffixes---of lengths $n_1$ and $n_2$---of\nthe codewords are over different alphabets.}\n\nApplying Lemma~\\ref{lem:BHL}\nwith $Q = \\Finitefield_2$,\n$Q' = \\Finitefield_4$, $\\beta = 1$, and $\\beta' = 2/3$,\nwe have verified numerically\nthat the expression~(\\ref{eq:BHL}) is maximized when $\\tau = 0$.\nHence, we get the following upper\nbound on the rate $R$ of any all-disjoint $(\\delta,3)$-LRC sequence\nover $F$ in which the repair groups are all of size $3$:\n\\begin{equation}\n\\label{eq:n=3}\nR \\le \\frac{2}{3}\n\\cdot \\Rate_{\\LP;\\Finitefield_4}\\left( \\frac{3 \\delta}{2} \\right) .\n\\end{equation}\n\nIt remains to consider the case where the $(N,M,d)$ LRC $\\varcode$\nhas repair groups of size $2$, namely,\nsome $s$ out of the $t$ coordinates of the outer code\n$\\Code \\; (\\subseteq F^t \\times (F^2)^{\\ell-t})$\nmap to the $[2,1,2]$ repetition code.\nBy adding $s$ information bits to $\\Code$\n(thereby increasing its size by a factor of $2^s$)\nwe can obtain a new concatenated code $\\varcode^*$\nin which we replace all\nthe inner instances of the $[2,1,2]$ repetition code\nby instances of the $[3,2,2]$ parity code. \nDoing so, the overall code length becomes $N + s$,\nthe minimum distance remains unchanged\n(and, so, the r.m.d.\\ reduces by a factor of $N/(N+s)$),\nand the rate becomes\n\\begin{equation}\n\\label{eq:newrate}\n\\frac{(\\log_2 M) + s} {N + s}\n= \\frac{(\\log_2 M)/N + (s/N)} {1 + (s/N)} .\n\\end{equation}\nSwitching to a code sequence $(\\varcode_i)_{i=1}^\\infty$\nwhere $\\lim_{i \\rightarrow \\infty} s_i/N_i = \\sigma$,\nwe get from~(\\ref{eq:newrate}) the following relationship\nbetween the rate $R$ of the sequence and the rate $R^*$\nof $(\\varcode^*_i)_{i=1}^\\infty$:\n\\[\nR^* = \\frac{R + \\sigma}{1 + \\sigma} .\n\\]\nOn the other hand,\nthe bound~(\\ref{eq:n=3}) applies to $(\\varcode^*_i)_{i=1}^\\infty$,\nnamely:\n\\[\nR^* \\le\n\\frac{2}{3} \\cdot \\Rate_{\\LP;\\Finitefield_4}\n\\left( \\frac{3 \\delta}{2 (1 + \\sigma)} \\right) .\n\\]\nCombining the last two equations yields:\n\\[\nR \\le\n\\frac{2(1 + \\sigma)}{3} \\cdot \\Rate_{\\LP;\\Finitefield_4}\n\\left( \\frac{3 \\delta}{2 (1 + \\sigma)} \\right) - \\sigma.\n\\]\nWe have verified numerically\nthat this expression is maximized when $\\sigma = 0$.\nWe therefore conclude that~(\\ref{eq:n=3}) holds for\nany all-disjoint $(\\delta,3)$-LRC sequence over $F$.\nThe bound~(\\ref{eq:n=3}) is depicted\nin Figure~\\ref{fig:q=2,n=3} (curve (g)).\n\\fi\n\n\\section{The general linearly recoverable case}\n\\label{sec:nondisjoint}\n\nIn this section, we present some (weaker) bounds for\n$(\\delta,n)$-LRC sequences that are not necessarily\nall-disjoint (but they are still linearly recoverable).\nOur results are based on deriving the asymptotic version\nof the sphere-packing bound of~\\cite{WZL}\n(\\Theorems~5 and~12 therein).\n\nLet $\\varcode$ be a linearly recoverable LRC of length $N$,\nminimum distance $d$, and locality $r = n-1$ over $F$\nand let $(\\Local_j)_{j \\in [N]}$ be\na list of repair groups of $\\varcode$.\nWe assume hereafter in this section (without loss of generality)\nthat this list satisfies the following conditions.\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textrm{P2)}}}\n\\item[R1)]\n$|\\Local_j| \\le n$ for each index $j \\in [N]$\n(this condition follows directly from the locality).\n\\item[R2)]\nFor each $j \\in [N]$, the repair group $\\Local_j$ is\n\\ifPAGELIMIT\n    minimal, i.e., no proper subset of it is a repair group for $j$.\n\\else\nminimal in the sense that no proper subset of it\nis a repair group for $j$; this, in turn, implies\nthat $\\Local_j$ is a repair group for all $j' \\in \\Local_j$.\n\\fi\n\\item[R3)]\nEach repair group $\\Local_j$ contains at least one index $j'$\nthat is not contained in any repair group $\\Local_i \\ne \\Local_j$\n(otherwise, $\\Local_j$ can be spared).\n\\end{list}\n\n\\ifPAGELIMIT\n    For each repair group $\\Local_j$ among\n    the distinct repair groups of $\\varcode$,\n\\else\nConsidering now only the set of distinct repair groups\n$\\{ \\Local_j \\}_{j \\in [\\ell]}$ of $\\varcode$,\nfor each repair group $\\Local_j$,\n\\fi\nthe constituent code $(\\varcode)_{\\Local_j}$ is contained in\na linear $[|\\Local_j|,|\\Local_j|{-}1]$ code over $F$,\nwhich we denote by $\\code_j$; moreover, by condition~(R2),\nthe code $\\code_j$ has minimum distance~$2$.\nAn ambient space $\\Ambient$ of $\\varcode$ is\ndefined as in~(\\ref{eq:ambient});\nby condition~(R3),\nthe containment in~(\\ref{eq:ambient}) holds in fact with equality\n\\ifPAGELIMIT\n    for all $j$.\n\\else\nfor all $j \\in [\\ell]$.\n\\fi\n\nThe method of~\\cite{WZL} for obtaining\na (non-asymptotic) sphere-packing-type\nbound on the rate of $\\varcode$ is based on shortening $\\varcode$ on\nthe set of coordinates, $\\AltSet$, on which repair groups intersect,\nthereby reducing to the all-disjoint case.\nDenoting $\\nu = |\\AltSet|/N$,\nthe resulting shortened code, $\\widehat{\\varcode}$,\nis an all-disjoint linearly recoverable LRC\nof length $(1-\\nu)N$ and minimum distance${} \\ge d$,\nwith the following $\\ell$ distinct repair groups:\n\\[\n\\widehat{\\Local}_j = \\Local_j \\setminus \\AltSet ,\n\\quad j \\in [\\ell] .\n\\]\nNow, on the one hand, we have:\n\\ifPAGELIMIT\n    \\begin{equation}\n    \\label{eq:AltSet1}\n    \\ell \\cdot n \\ge 2 |\\AltSet| + (N - |\\AltSet|) .\n    \\end{equation}\n\\else\n\\begin{eqnarray}\n\\ell \\cdot n\n& \\ge &\n\\sum_{j \\in [\\ell]} |\\Local_j|\n= \\sum_{t \\in [N]}\n\\left| \\bigl\\{  j \\in [\\ell] \\,:\\, t \\in \\Local_j \\bigr\\} \\right|\n\\nonumber \\\\\n& = &\n\\sum_{t \\in \\AltSet}\n\\left| \\bigl\\{  j \\,:\\, t \\in \\Local_j \\bigr\\} \\right|\n+ \\sum_{t \\in [N] \\setminus \\AltSet}\n\\left| \\bigl\\{  j \\,:\\, t \\in \\Local_j \\bigr\\} \\right|\n\\nonumber \\\\\n\\label{eq:AltSet1}\n& \\ge &\n2 |\\AltSet| + (N - |\\AltSet|) .\n\\end{eqnarray}\n\\fi\nOn the other hand, by condition~(R3), we also have:\n\\begin{equation}\n\\label{eq:AltSet2}\nN - |\\AltSet| \\ge \\ell .\n\\end{equation}\n   From~(\\ref{eq:AltSet1}) and~(\\ref{eq:AltSet2}) we get:\n\\begin{equation}\n\\label{eq:ell}\n\\frac{1+\\nu}{n} \\le \\frac{\\ell}{N} \\le 1-\\nu\n\\end{equation}\nand, in particular,\n\\ifPAGELIMIT\n    $0 \\le \\nu \\le (n{-}1)/(n{+}1)$.\n\\else\n\\[\n0 \\le \\nu \\le \\frac{n-1}{n+1} .\n\\]\n\\fi\nMoreover, from~(\\ref{eq:ell}) we get\nthat the average size of the distinct (and disjoint) repair groups of\n$\\widehat{\\varcode}$ satisfies\n\\begin{equation}\n\\label{eq:average}\n\\frac{1}{\\ell}\n\\sum_{j \\in [\\ell]} |\\widehat{\\Local}_j|\n= \\frac{(1-\\nu) N}{\\ell}\n\\le \\frac{1{-}\\nu}{1{+}\\nu} \\cdot n = \\mu .\n\\end{equation}\n\nThe rate $R = (\\log_q |\\varcode|)/N$\nof $\\varcode$ is related to that of $\\widehat{\\varcode}$ by:\n\\begin{equation}\n\\label{eq:hatD}\nR = \\frac{1}{N} \\cdot \\log_q |\\varcode|\n\\le\n\\frac{1}{N}\n\\left( |\\AltSet| + \\log_q |\\widehat{\\varcode}| \\right)\n=\n\\nu + (1-\\nu) \\cdot \\widehat{R} .\n\\end{equation}\nThus, given $\\nu$, any upper bound on $\\widehat{R}$\nimplies an upper bound on $R$, and the dependence on $\\nu$ can then be\neliminated by maximizing the latter bound over\n$\\nu \\in [0,(n{-}1)/(n{+}1)]$.\n\nUsing the above strategy,\nwe next turn to adapting our previous bounds\nto linearly recoverable $(\\delta,n)$-LRC sequences\nthat are not necessarily all-disjoint.\n\\ifPAGELIMIT\n\\else\nWe will make use of the following notation.\n\\fi\nFor $n \\in \\Realfield^+$ and\n$\\omega \\in \\Realfield_{\\ge 0}$, define:\n\\begin{equation}\n\\label{eq:WZL2}\n\\widehat{\\Rate}_0(\\omega,n) =\n\\max_\\nu\n\\left\\{\n\\nu + (1-\\nu) \\cdot\n\\overline{\\Rate}_0 \\left( \\frac{\\omega}{1{-}\\nu}, n, \n\\frac{1{-}\\nu}{1{+}\\nu} \\cdot n \\right) \\right\\} ,\n\\end{equation}\nwhere $\\overline{\\Rate}_0(\\cdot,\\cdot,\\cdot)$ is\nas defined in~(\\ref{eq:WZL1})\nand the maximum is taken over all $\\nu \\in [0,(n{-}1)/(n{+}1)]$.\n\n\\ifPAGELIMIT\n\\else\n\\begin{remark}\n\\label{rem:computations2}\nSubstituting $\\nu = 0$ and $\\nu = (n{-}1)/(n{+}1)$\nin the objective function in~(\\ref{eq:WZL2}),\nwe get the following \\emph{lower} bound on\n$\\widehat{\\Rate}_0(\\omega,n)$:\n\\[\n\\widehat{\\Rate}_0(\\omega,n)\n\\ge\n\\max \\left\\{\n\\Rate_0(\\omega,n),  \\frac{n{-}1}{n{+}1} \\right\\} .\n\\]\nBased on our numerical evidence,\nwe conjecture that this lower bound is tight\n(see also Remark~\\ref{rem:WZL2} in Appendix~\\ref{sec:R0properties}).\\qed\n\\end{remark}\n\\fi\n\nThe following proposition is a (weaker) counterpart\nof \\Proposition~\\ref{prop:R0} for the case where repair groups\ncan intersect.\n\n\\begin{proposition}\n\\label{prop:R0-nondisjoint}\nGiven $n \\in \\Integers^+$,\nlet $(\\Ambient_i)_{i=1}^\\infty$ be\nan infinite sequence of codes over $F$\nwhere each $\\Ambient_i$ is\na linear code of length $N_i$ over $F$ defined by\n\\[\n(\\Ambient_i)_{\\Local_{i,j}} = \\code_{i,j} ,\n\\quad j \\in [N_i] ,\n\\]\nwith the list $(\\Local_{i,j})_{j \\in [N_i]}$ satisfying\nconditions (R1)--(R3)\nand each constituent code $\\code_{i,j}$ being\na linear $[|\\Local_{i,j}|,|\\Local_{i,j}|{-}1,2]$ code over $F$.\nThen for any nonnegative real sequence $(\\omega_i)_{i=1}^\\infty$\nsuch that $\\varliminf_{i \\rightarrow \\infty} \\omega_i = \\omega$:\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q\n\\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|} \\le\n\\widehat{\\Rate}_0(\\omega,n) .\n\\]\n\\end{proposition}\n\n\\begin{proof}\nFor each $i \\in \\Integers^+$, let $\\widehat{\\Ambient}_i$\nbe obtained by shortening $\\Ambient_i$\non the set of coordinates on which\nrepair groups (i.e., subsets) $\\Local_{i,j}$\nintersect. Denoting by $\\nu_i \\; (\\in [0,(n{-}1)/(n{+}1)])$\nthe fraction of removed coordinates, by possibly restricting\nto a subsequence of the codes,\nwe can assume that $(\\nu_i)_{i=1}^\\infty$ converges to a limit $\\nu$\nand that the length, $m_i = (1{-}\\nu_i)N_i$,\nof $\\widehat{\\Ambient}_i$ strictly increases with $i$.\nWe then get that the code sequence\n$(\\widehat{\\Ambient}_i)_{i=1}^\\infty$\nsatisfies the conditions of\n\\Proposition~\\ref{prop:R0} (and, hence, of Lemma~\\ref{lem:mu});\n\\ifPAGELIMIT\n    moreover, the average length of\n    the constituent codes of each $\\widehat{\\Ambient}_i$\n\\else\nin particular, since each $\\code_{i,j}$ has minimum distance $2$,\nthe respective (shortened) constituent codes of each\n$\\widehat{\\Ambient}_i$ all (still) have redundancy $1$.\nMoreover, the average length of those constituent codes\n\\fi\nis bounded from above by\n\\[\n\\frac{1{-}\\nu_i}{1{-}\\nu_i} \\cdot n\n\\]\n(as in~(\\ref{eq:average})).\nIn addition, \n\\begin{equation}\n\\label{eq:rate}\n\\frac{1}{N_i}\n\\log_q |\\Ambient_i|\n\\le\n\\nu_i + (1-\\nu_i) \\cdot\n\\frac{1}{m_i} \\log_q |\\widehat{\\Ambient}_i|\n\\end{equation}\n(as in~(\\ref{eq:hatD})) and,\nfor any nonnegative real sequence $(\\omega_i)_{i=1}^\\infty$:\n\\begin{eqnarray}\n\\lefteqn{\n\\frac{1}{N_i}\n\\log_q |\\Ambient_i(\\omega_i)|\n\\ge\n\\frac{1}{N_i}\n\\log_q |\\widehat{\\Ambient}_i(\\omega_i/(1{-}\\nu_i))|\n} \\makebox[5ex]{} \n\\nonumber \\\\\n\\label{eq:logvolume}\n& = &\n(1-\\nu_i) \\cdot\n\\frac{1}{m_i}\n\\log_q |\\widehat{\\Ambient}_i(\\omega_i/(1{-}\\nu_i))| .\n\\end{eqnarray}\nTherefore,\n\\begin{eqnarray*}\n\\lefteqn{\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{N_i}\n\\log_q \\frac{|\\Ambient_i|}{|\\Ambient_i(\\omega_i)|}\n} \\makebox[5ex]{} \\\\\n& \\stackrel{\\textrm{(\\ref{eq:rate})+(\\ref{eq:logvolume})}}{\\le} &\n\\nu +\n(1-\\nu) \\cdot\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{m_i}\n\\log_q\n\\frac{|\\widehat{\\Ambient}_i|}%\n                          {|\\widehat{\\Ambient}_i(\\omega_i/(1{-}\\nu_i))|}\n\\\\\n& \\stackrel{\\textrm{Lemma~\\ref{lem:mu}}}{\\le} &\n\\nu + (1-\\nu) \\cdot\n\\overline{\\Rate}_0 \\left( \\frac{\\omega}{1{-}\\nu},n,\n\\frac{1{-}\\nu}{1{+}\\nu} n \\right) \\\\\n& \\stackrel{\\textrm{(\\ref{eq:WZL2})}}{\\le} &\n\\widehat{\\Rate}_0(\\omega,n) ,\n\\end{eqnarray*}\nwhere $\\omega = \\varliminf_{i \\rightarrow \\infty}\\omega_i$.\n\\end{proof}\n\nThe following sphere-packing bound is proved similarly\nto \\Theorem~\\ref{thm:spherepacking},\nexcept that we use \\Proposition~\\ref{prop:R0-nondisjoint}\ninstead of \\Proposition~\\ref{prop:R0}.\n\n\\begin{theorem}\n\\label{thm:spherepacking-nondisjoint}\nThe rate of any linearly recoverable $(\\delta,n)$-LRC sequence over $F$\nis bounded from above by\n\\[\n\\widehat{\\Rate}_\\SP(\\delta,n) =\n\\ifPAGELIMIT\n    \\widehat{\\Rate}_0(\\delta/2,n)\n\\else\n\\widehat{\\Rate}_0 \\left( \\frac{\\delta}{2} , n \\right)\n\\fi\n.\n\\]\n\\end{theorem}\n\nNext are our (weaker) versions\nof \\Theorems~\\ref{thm:bound1} and~\\ref{thm:bound2}\nfor general linearly recoverable LRC sequences.\n\n\\begin{theorem}\n\\label{thm:bound1-nondisjoint}\nThe rate of any linearly recoverable $(\\delta,n)$-LRC sequence over $F$\nis bounded from above by\n\\ifPAGELIMIT\n    \\begin{eqnarray*}\n    \\widehat{\\Rate}_1(\\delta,n)\n    & = &\n    \\inf_{\\tau \\in (0,1)} \\min_{(\\theta,\\theta')}\n    \\Bigl\\{ \n    \\tau \\cdot \\widehat{\\Rate}_0(\\theta/2,n)\n    \\\\\n    &&\n    \\quad \\quad \\quad \\quad \\quad \\quad\n    {}\n    + \n    (1-\\tau) \\cdot \\Rate_\\opt(\\theta',n)\n    \\Bigr\\} ,\n    \\end{eqnarray*}\n    where $(\\theta,\\theta')$ ranges over all pairs\n    that satisfy~(\\ref{eq:theta}).\n\\else\n\\begin{eqnarray*}\n\\widehat{\\Rate}_1(\\delta,n)\n& = &\n\\inf_{\\tau \\in (0,1)} \\min_{(\\theta,\\theta')}\n\\Biggl\\{ \n\\tau \\cdot \\widehat{\\Rate}_0 \\left( \\frac{\\theta}{2}, n \\right)\n\\\\\n&&\n\\quad \\quad \\quad \\quad \\quad \\quad\n{}\n+ \n(1-\\tau) \\cdot \\Rate_\\opt(\\theta',n)\n\\Biggr\\} ,\n\\end{eqnarray*}\nwhere the (inner) minimum is taken over\nall pairs $(\\theta,\\theta')$ in $[0,(q{-}1)/q]^2$\nthat satisfy~(\\ref{eq:theta}).\n\\fi\n\\end{theorem}\n\n\\ifPAGELIMIT\n    The proof resembles that of \\Theorem~\\ref{thm:bound1}\n    (details can be found in~\\cite{RothFull}).\n\\else\n\\begin{proof}\nThe proof resembles that of \\Theorem~\\ref{thm:bound1},\nyet requires several modifications which are described below.\nGiven a linearly recoverable $(\\delta,n)$-LRC sequence\n$(\\varcode_i)_{i=1}^\\infty$ over $F$,\nwe let $(\\Local_{i,j})_{j \\in [N_i]}$\nbe a list of repair groups of $\\varcode_i$\nthat satisfies conditions (R1)--(R3).\nLetting $\\{ \\Local_{i,j} \\}_{j \\in [\\ell_i]}$\nbe the set of distinct repair groups in the list,\nwe define (as in the proof of \\Theorem~\\ref{thm:bound1})\n\\[\nt_i = \\left|\n{\\textstyle\\bigcup_{j \\in [\\ell'_i]}} \\Local_{i,j} \\right| ,\n\\]\nwhere $\\ell'_i$ is the smallest in $[\\ell_i]$ so that\n$t_i \\ge \\tau N_i$.\nAnd by possibly permuting the coordinates\nof $\\varcode_i$, we assume that\n$\\bigcup_{j \\in [\\ell'_i]} \\Local_{i,j} = [t_i]$.\n\nWe now specify the changes to the proof of \\Theorem~\\ref{thm:bound1}.\nFirst, we need to modify\nthe argument that leads to Eq.~(\\ref{eq:bound1-1}),\nsince the decomposition~(\\ref{eq:Subset}) may no longer hold.\nStill, due to condition~(R3), the size of the following set is\nthe same for all $\\bldy' \\in \\Ambient'_i$:\n\\[\n\\left\\{\n\\bldy'' \\in F^{N_i-t_i} \\,:\\,\n(\\bldy' \\; \\bldy'') \\in \\Ambient_i \\right\\} .\n\\]\nThus,\n\\[\n\\frac{|\\Ambient_i|}{|\\Subset|}\n= \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|} ,\n\\]\nwhich justifies~(\\ref{eq:bound1-1}).\n\nSecondly, we need to weaken Eq.~(\\ref{eq:bound1-2}),\nsince the code $\\varcode''_i$ is now not necessarily an LRC.\nSpecifically, (\\ref{eq:bound1-2}) now becomes\n\\[\n|\\varcode^*_i| = |\\varcode''_i| \\le M_\\opt(N_i - t_i, d_i - 2w_i) ,\n\\]\nwhere $M_\\opt(N,D)$ denotes the largest size\nof any code over $F$ with length $N$ and minimum distance $D$.\nAccordingly, from this point in the proof of \\Theorem~\\ref{thm:bound1},\nwe change the instances of\n$\\Rate_\\LRC(\\cdot,n)$ into $\\Rate_\\opt(\\cdot)$.\n\nFinally, using \\Proposition~\\ref{prop:R0-nondisjoint},\nwe change~(\\ref{eq:ratio}) into\n\\[\n\\varlimsup_{i \\rightarrow \\infty}\n\\frac{1}{t_i}\n\\log_q \\frac{|\\Ambient'_i|}{|\\Ambient'_i(w_i/t_i)|}\n\\le \\widehat{\\Rate}_0 \\left( \\frac{\\theta}{2} , n \\right) .\n\\]\n\\end{proof}\n\n\\fi\nBelow is our variant of \\Theorem~\\ref{thm:bound2}, which\nis proved using \\Proposition~\\ref{prop:R0-nondisjoint}\ninstead of \\Proposition~\\ref{prop:R0}.\n\n\\begin{theorem}\n\\label{thm:bound2-nondisjoint}\nThe rate of any linearly recoverable $(\\delta,n)$-LRC sequence over $F$\nis bounded from above by\n\\[\n\\widehat{\\Rate}_2(\\delta,n) = \\min_{\\omega \\in [\\delta/2,(q{-}1)/q]}\n\\Bigl\\{ \\widehat{\\Rate}_0(\\omega,n) + \\Rate_\\opt(\\delta,\\omega)\\Bigr\\} .\n\\]\n\\end{theorem}\n\nNotice that unlike the all-disjoint case,\nwe \\emph{cannot} substitute $\\widehat{\\Rate}_2(\\theta',n)$\nfor $\\Rate_\\opt(\\theta',n)$ in \\Theorem~\\ref{thm:bound1-nondisjoint}.\n\n\\ifPAGELIMIT\n\\else\nThe various bounds are plotted\nin Figure~\\ref{fig:q=2,n=4-nondisjoint} for $q = 2$ and $n = 4$.\nCurve~(a) is the sphere-packing bound\nof \\Theorem~\\ref{thm:spherepacking-nondisjoint}.\nCurve~(b) is identical to its counterpart in Figure~\\ref{fig:q=2,n=4}\nand, as it turns out, curve~(c) is the same as in that figure too\n(namely, $\\widehat{\\Rate}_1(\\delta,n) = \\Rate_1(\\delta,n)$\nfor the examined parameters); this is due to the fact\nthat the minimum in \\Theorem~\\ref{thm:bound2-nondisjoint}\nis attained at values $\\theta$\nwhere $\\widehat{\\Rate}_0(\\theta,n) = \\Rate_0(\\theta,n)$.\nWhen plotting curve~(d), we have taken\nthe minimum of $\\widehat{\\Rate}_2(\\delta,n)$ and $\\Rate_\\LP(\\delta,n)$.\n\\fi\nSome values of the bounds are listed in\nTable~\\ref{tab:q=2,n=4-nondisjoint}, where\nentries that differ from those in Table~\\ref{tab:q=2,n=4} \nare marked in\n\\ifPAGELIMIT\n    italics (full plots can be found in~\\cite{RothFull}).\n\\else\nitalics.\n\\fi\nThere is still a range where\n\\Theorem~\\ref{thm:bound2-nondisjoint} yields the best upper bound,\nyet this range is smaller compared to the all-disjoint case.\n\n\\ifPAGELIMIT\n\\else\n\\begin{remark}\n\\label{rem:bound2-nondisjoint}\nA second variant of \\Theorem~\\ref{thm:bound2} can be obtained\nby first shortening the codes in a given LRC sequence\non the intersections of repair groups, and then applying\n\\Theorem~\\ref{thm:bound2} to the resulting (all-disjoint) LRC sequence.\nThis yields the upper bound\n\\begin{eqnarray*}\n\\lefteqn{\n\\widehat{\\Rate}_3(\\delta,n)\n= \\max_\\nu \\Biggl\\{ \\nu + (1 - \\nu) \\cdot\n\\min_\\omega\n\\biggl\\{\n\\overline{\\Rate}_0\n\\Bigl(\\omega,n, \\frac{1{+}\\nu}{1{-}\\nu} \\cdot n \\Bigr)\n} \\makebox[27ex]{} \\\\\n\\\\\n&&\n\\quad {}\n+ \\Rate_\\opt \\Bigl( \\frac{\\delta}{1{-}\\nu} , \\omega \\Bigr)\n\\biggr\\}\n\\Biggr\\} ,\n\\end{eqnarray*}\nwhere the outer maximum is over $\\nu \\in [0,(n{-}1)/(n{+}1)]$\nand the inner minimum is over\n$\\omega \\in [\\delta/(2{-}2\\nu),(q{-}1)/q]$.\nYet at least for the parameters that we have tested,\nwe have observed no difference between the values of\n$\\widehat{\\Rate}_2(\\delta,n)$ and $\\widehat{\\Rate}_3(\\delta,n)$.\\qed\n\\end{remark}\n\\fi\n\n\\begin{table}[hbt]\n\\caption{Values of the bounds for $q = 2$ and $n = 4$\nwithout the all-disjoint constraint.}\n\\label{tab:q=2,n=4-nondisjoint}\n\\ifPAGELIMIT\n    \\vspace{-3ex}\n\\fi\n\\[\n\\renewcommand{\\arraystretch}{1.1}\n\\begin{array}{ccccc}\n\\hline\\hline\n\\quad\\quad \\delta \\quad\\quad &\n\\ifPAGELIMIT\n    \\widehat{\\Rate}_\\SP & \\Rate_\\CM & \\widehat{\\Rate}_1 &\n    \\widehat{\\Rate}_2\\rule{0ex}{2.5ex} \\\\\n\\else\n\\mathrm{(a)}&\\mathrm{(b)}&\\mathrm{(c)}&\\mathrm{(d)} \\\\\n\\fi\n\\hline\n0.07 & 0.6133 & 0.6317 & 0.6131 & 0.6079 \\\\\n0.10 & \\mathit{0.6000} & 0.5809 & 0.5643 & \\mathit{0.6000} \\\\\n0.15 & \\mathit{0.6000} & 0.4964 & 0.4830 & \\mathit{0.6000} \\\\\n0.30 & \\mathit{0.6000} & 0.2427 & 0.2391 & \\mathit{0.6000} \\\\\n\\hline\\hline\n\\end{array}\n\\]\n\\end{table}\n\n\\section*{Acknowledgment}\n\nI would like to thank Yael Ben-Haim and Simon Litsyn\nfor helpful\n\\ifPAGELIMIT\n    discussions.\n\\else\ndiscussions and for making me aware of\nthe results of~\\cite{BCCST}.\n\n\\ifIEEE\n   \\appendices\n\\else\n   \\section*{$\\,$\\hfill Appendices\\hfill$\\,$}\n   \\appendix\n\\fi\n\n\\section{Skipped proofs}\n\\label{sec:skippedproofs}\n\n\\begin{proof}[Proof of Lemma~\\ref{lem:gamma}]\nBy convexity, for all $z \\in (0,1]$ we have\n$\\Expected \\{ z^X \\} \\ge z^{\\Expected \\{ X \\}}$,\nwith equality holding when $z = 1$; hence,\n$\\gamma(u) = 1$ when $u \\ge \\Expected \\{ X \\}$.\nWhen $u \\le x_{\\min}$,\nthe infimum in~(\\ref{eq:gamma}) is attained at $z \\rightarrow 0$\nand, so, $\\gamma(u) = 0$ when $u < x_{\\min}$\nand $\\gamma(u) = p(x_{\\min})$ when $u = x_{\\min}$.\nFor $x_{\\min} < u < \\Expected \\{ X \\}$,\nwe differentiate $g_u(z)$ with respect to $z$ to obtain\n\\[\ng'_u(z) = z^{x_{\\min} - u - 1} \\cdot f_u(z) ,\n\\]\nwhere\n\\[\nf_u(z) = \\sum_{x \\in \\Set}\n(x - u) \\cdot p(x) \\cdot z^{x - x_{\\min}} .\n\\]\nThus, $f_u(1) = \\Expected \\{ X \\} - u > 0$\nand $f_u(0) = (x_{\\min} - u) \\cdot p(x_{\\min}) < 0$,\nwhich implies that the infimum in~(\\ref{eq:gamma}) is\na proper minimum attained at an (interior) point $z_u \\in (0,1)$;\nthe point $z_u$ satisfies\n\\[\n1 \\ge g_u(z_u)\n> z_u^{x_{\\min} - u} \\cdot p(x_{\\min}) ,\n\\]\ni.e.,\n\\[\nz_u > p(x_{\\min})^{1/(u - x_{\\min})} .\n\\]\nThis means that $z_u$ is bounded away from zero whenever\n$u$ is bounded away from $x_{\\min}$.\nDefining $z_u = 1$ for $u \\ge \\Expected \\{ X \\}$,\nfor any $v > u \\ge x_{\\min}$ we have\n\\[\n\\gamma(u) \\le g_u(z_v)\n\\le z_v^{u-v} \\cdot g_u(z_v) = g_v(z_v) = \\gamma(v),\n\\]\nwith the second inequality being strict when $v < \\Expected \\{ X \\}$.\nHence, $u \\mapsto \\gamma(u)$\nis strictly increasing when $x_{\\min} \\le u < \\Expected \\{ X \\}$.\nOn the other hand, we also have\n\\[\n\\gamma(u) = g_u(z_u) \n= z_u^{v-u} g_v(z_u)\n\\ge z_u^{v-u} \\gamma(v),\n\\]\nwhich, combined with $\\gamma(u) \\le \\gamma(v)$,\nmeans that $u \\mapsto \\gamma(u)$ is continuous\nwhen $u > x_{\\min}$. Moreover, it is right-continuous\nat $u = x_{\\min}$, since\n\\[\n\\lim_{\\varepsilon \\rightarrow 0^+}\n\\gamma(x_{\\min}+\\varepsilon)\n\\le \\lim_{\\varepsilon \\rightarrow 0^+}\ng_{x_{\\min}+\\varepsilon}(\\varepsilon) = p(x_{\\min})\n= \\gamma(x_{\\min}) .\n\\]\nFinally, the concavity of $u \\mapsto \\log \\gamma(u)$\nfollows from~(\\ref{eq:cramer}) and\n\\begin{eqnarray*}\n\\lefteqn{\n\\Prob \\left\\{ \\frac{1}{\\ell_1{+}\\ell_2} \\sum_{i=1}^{\\ell_1 + \\ell_2} X_i\n\\le\n\\frac{\\ell_1}{\\ell_1{+}\\ell_2} u_1\n+\n\\frac{\\ell_2}{\\ell_1{+}\\ell_2} u_2 \\right\\}\n}\\\\\n& \\ge &\n\\!\\!\n\\Prob \\left\\{\n\\frac{1}{\\ell_1} \\sum_{i=1}^{\\ell_1} X_i \\le u_1 \\right\\}\n\\cdot\n\\Prob \\left\\{\n\\frac{1}{\\ell_2} \\sum_{i=\\ell_1+1}^{\\ell_1 + \\ell_2} X_i\n\\le u_2 \\right\\} .\n\\end{eqnarray*}\n\\end{proof}\n\nTurning to the proof of Lemma~\\ref{lem:CW}, it makes use of\nthe following theorem, which was proved in~\\cite[\\Theorem~1]{BCCST}\nfor the special case of the binary alphabet.\nFor completeness, we provide a proof of the theorem for general $q$\nright after the proof of Lemma~\\ref{lem:CW}.\n\n\\begin{theorem}\n\\label{thm:BCCST}\nFor any $\\delta \\in [0,(q{-}1)/q]$,\nthe mapping $\\omega \\mapsto \\Rate_\\opt(\\delta,\\omega)$\nis non-decreasing on $\\omega \\in [0,(q{-}1)/q]$.\n\\end{theorem}\n\n\\begin{proof}[Proof of Lemma~\\ref{lem:CW}]\nObviously,\n$\\Rate_\\opt(\\delta,\\omega) \\le \\Rate_\\opt(\\delta,{\\le}\\omega)$.\nTo prove the inequality in the other direction,\nLet $(\\varcode_i)_{i=1}^\\infty$\nbe a code sequence with r.m.d.${} \\ge \\delta$,\nwith the (length-$N_i$) codewords of each $\\varcode_i$\nall having weight at most $w_i$, such that\n$\\varlimsup_{i \\rightarrow \\infty} w_i/N_i \\le \\omega$.\nLetting $\\varcode^*_i$ be a largest constant-weight subcode\nof $\\varcode_i$ (of codeword weight $w^*_i \\le w_i$),\nwe have $|\\varcode^*_i| \\ge |\\varcode_i|/(w_i + 1)$ and\n$\\varlimsup_{i \\rightarrow \\infty} w^*_i/N_i = \\omega^* \\le \\omega$\n(and by possibly restricting to a subsequence of\n$(\\varcode^*_i)_{i=1}^\\infty$ we can assume\nthat $\\omega^*$ is a proper limit of $(w_i/N_i)_{i=1}^\\infty$).\nThus,\n\\[\n\\Rate_\\opt(\\delta,{\\le}\\omega) \\le\n\\sup_{\\omega^* \\in [0,\\omega]} \\Rate_\\opt(\\delta,\\omega^*) .\n\\]\nBy \\Theorem~\\ref{thm:BCCST} we then get that when\n$\\omega \\in [0,(q{-}1)/q]$,\nthe supremum is attained at $\\omega^* = \\omega$.\n\\end{proof}\n\n\\begin{proof}[Proof of \\Theorem~\\ref{thm:BCCST}]\nGiven an Abelian group $F$ of size $q$,\nfix $\\omega, \\theta \\in [0,(q{-}1)/q]$\nand let $\\code$ be a constant-weight code of length $N$\nand minimum distance $d$ over $F$ with codeword weight\n$\\lfloor \\omega N \\rfloor$. We show that there exists\n$\\bldy \\in F^N$ such that the translation $\\bldy + \\code$ \ncontains a constant-weight subcode $\\code^*$ of size\n\\begin{equation}\n\\label{eq:sizeratio}\n|\\code^*| \\ge \\frac{|\\code|}{(N{+}1)^3}\n\\end{equation}\nand of codeword weight $\\lfloor \\omega^* N \\rfloor$, where\n\\begin{equation}\n\\label{eq:omegastar}\n\\omega^* = \\omega + \\theta \\left( 1 - \\frac{q \\, w}{q{-}1} \\right) .\n\\end{equation}\nThe result will follow by observing\nthat $\\omega^*$ ranges over $[\\omega,(q{-}1)/q]$\nas $\\theta$ ranges over $[0,(q{-}1)/q]$.\nHereafter in the proof, we assume that $\\omega$ and $\\theta$\nare rational numbers and $N$ is such that $\\omega N$, $\\theta N$,\nand $\\theta \\omega N/(q{-}1)$ are integers\n(it is easy to see that those assumptions are allowed\nin order to obtain the asymptotic result that we seek).\n\nFor any codeword $\\bldc \\in \\code$,\nlet $\\Typical(\\bldc)$ denote the set of all words $\\bldy \\in F^N$\nthat satisfy the following conditions.\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textit{(Y3)}}}\n\\item[Y1)]\nThe subword $\\bldy' \\in F^{\\omega N}$ of $\\bldy$ that is indexed by\nthe support of $\\bldc$ has weight $\\theta \\omega N$,\n\\item[Y2)]\na fraction $1/(q{-}1)$ of the nonzero entries of $-\\bldy'$ agree \nwith the respective entries in $\\bldc$, and---\n\\item[Y3)]\nthe subword $\\bldy'' \\in F^{(1-\\omega) N}$ of $\\bldy$\nthat is indexed by the zero entries of $\\bldc$\nhas weight $\\theta (1{-}\\omega) N$.\n\\end{list}\n\nIt follows from these conditions that\nthe weight of each $\\bldy \\in \\Typical(\\bldc)$ is $\\theta N$\nand that for each $\\bldy \\in \\Typical(\\bldc)$,\nthe weight of $\\bldy + \\bldc$ is\n\\[\n\\left(\n\\frac{q{-}2}{q{-}1} \\cdot \\theta \\omega\n+ (1{-}\\theta) \\omega + \\theta(1{-}\\omega) \\right) N\n\\stackrel{\\textrm{(\\ref{eq:omegastar})}}{=} \\omega^* N .\n\\]\nWe also have:\n\\begin{eqnarray*}\n|\\Typical(\\bldc)|\n& = &\n\\binom{\\omega N}{\\theta \\omega N} \\\\\n&&\n\\quad {}\n\\cdot\n\\binom{\\theta \\omega N}{\\theta \\omega N/(q{-}1)} \n\\cdot \\left( q{-}2 \\right)^{\\theta \\omega N (q-2)/(q-1)} \\\\\n&&\n\\quad {} \\cdot \\binom{(1{-}\\omega)N}{\\theta (1{-}\\omega)N}\n\\cdot (q{-}1)^{\\theta (1{-}\\omega) N} ,\n\\end{eqnarray*}\nwhere the first term is the number of possible supports \nof a subword $\\bldy'$ that satisfies condition~(Y1)\nand, for each such support, the second term counts\nthe number of subwords $\\bldy'$ that satisfy condition~(Y2).\nThe third term counts the number of subwords $\\bldy''$\nthat satisfy condition~(Y3).\n\nWe now apply the following well known approximation\nof the binomial coefficients:\n\\[\n\\entropy \\left( \\frac{k}{m}\\right) - \\frac{\\log \\, (m{+}1)}{m}\n\\le\n\\frac{1}{m}\n\\log \\binom{m}{k} \\le \\entropy \\left( \\frac{k}{m}\\right) ,\n\\]\nwhere $x \\mapsto \\entropy(x)$\nis the (binary) entropy function\n$- x \\log x - (1{-}x) \\log \\, (1{-}x)$\n(see~\\cite[pp.~105--106]{Roth}).\nWe get:\n\\begin{eqnarray}\n\\frac{\\log |\\Typical(\\bldc)|}{N}\n& \\ge &\n\\omega \\cdot \\entropy(\\theta) \\nonumber \\\\\n&&\n\\quad {}\n+ \\theta \\omega \\left( \\entropy \\left( \\frac{1}{q{-}1} \\right)\n+ \\frac{q{-}2}{q{-}1} \\log \\, (q{-}2) \\right) \\nonumber \\\\\n&&\n\\quad {}\n+ (1{-}\\omega)\n\\cdot \\entropy(\\theta) + \\theta (1{-}\\omega) \\log \\, (q{-}1)\n\\nonumber \\\\\n&&\n\\quad {}\n- \\frac{3 \\log \\, (N{+}1)}{N} \\nonumber \\\\\n\\label{eq:Typical}\n& = &\n\\entropy(\\theta) + \\theta \\log \\, (q{-}1)\n- \\frac{3 \\log \\, (N{+}1)}{N} .\n\\end{eqnarray}\nOn the other hand, the set, $\\YY$, of all words\n$\\bldy \\in F^N$ of weight $\\theta N$ has size\n\\[\n|\\YY| = \\binom{N}{\\theta N} (q{-}1)^{\\theta N}\n\\]\nand, so,\n\\begin{equation}\n\\label{eq:Y}\n\\frac{\\log |\\YY|}{N} \n\\le \\entropy(\\theta) + \\theta \\log \\, (q{-}1) .\n\\end{equation}\nCombining~(\\ref{eq:Typical}) and~(\\ref{eq:Y})\nwe conclude that\n\\begin{equation}\n\\label{eq:typical}\n\\frac{\\Typical(\\bldc)}{|\\YY|} \\ge \\frac{1}{(N{+}1)^3}.\n\\end{equation}\nFor $\\bldy \\in \\YY$, let\n\\[\n\\code(\\bldy)\n= \\Bigl\\{ \\bldc \\in \\code \\,:\\, \\bldy \\in \\Typical(\\bldc) \\Bigr\\} .\n\\]\nThe set $\\code^*(\\bldy) = \\bldy + \\code(\\bldy)$\nforms a constant-weight code of codeword weight $\\omega^* N$\n(and of the same minimum distance $d$ as $\\code$).\nSumming now on the size of $\\code^*(\\bldy)$ over\nall $\\bldy \\in \\YY$ yields:\n\\begin{eqnarray*}\n\\sum_{\\bldy \\in \\YY} |\\code^*(\\bldy)|\n& = &\n\\sum_{\\bldy \\in \\YY} |\\code(\\bldy)| \\\\\n& = & \n\\left|\n\\bigl\\{\n(\\bldy,\\bldc) \\in \\YY \\times \\code \\,:\\, \\bldy \\in \\Typical(\\bldc)\n\\bigr\\}\n\\right| \\\\\n& = &\n\\sum_{\\bldc \\in \\code} |\\Typical(\\bldc)|\n\\end{eqnarray*}\nand, so,\n\\[\n\\frac{1}{|\\YY|}\n\\sum_{\\bldy \\in \\YY} |\\code^*(\\bldy)|\n= \n\\frac{1}{|\\YY|}\n\\sum_{\\bldc \\in \\code} |\\Typical(\\bldc)|\n\\stackrel{\\textrm{(\\ref{eq:typical})}}{\\ge}\n\\frac{|\\code|}{(N{+}1)^3} .\n\\]\nHence, there must be at least one word $\\bldy \\in \\YY$\nfor which $\\code^* = \\code^*(\\bldy)$ satisfies~(\\ref{eq:sizeratio}).\n\\end{proof}\n\n\\section{Characterization of $\\overline{\\Rate}_0(\\omega,n,\\mu)$}\n\\label{sec:R0properties}\n\nWe show here how to compute the expression~(\\ref{eq:WZL1}).\nIt is easy to see that this expression\nequals $(n{-}1)/n$ when $\\omega = 0$\n(since $\\bldvartheta$ is forced then to be all-zero\non the support of $\\bldpi$) and it vanishes\nwhen $\\omega \\ge (q{-}1)/q$ (by taking $\\vartheta_s = \\omega$\nfor all $s \\in [n]$). Hence, we can assume from now on that\n$\\omega \\in (0,(q{-}1)/q)$.\n\nWe introduce the following notation.\nFor $n \\in \\Integers^+$ and $\\omega \\in [0,(q{-}1)/q]$,\nlet $\\zeta_n(\\omega)$ denote a particular minimizing $z$ of\nthe expression for $\\lambda(\\omega,n)$ in~(\\ref{eq:lambda}).\nAlso, for $n \\in \\Integers^+$, let the polynomials $P_n(z)$ \nand $Q_n(z)$ be defined by\n\\begin{eqnarray*}\nP_n(z) & = &\n- (q{-}1) \\cdot\n\\bigl( (1 + (q{-}1)z)^{n-1} - (1{-}z)^{n-1} \\bigr) \\\\\nQ_n(z) & = & (1 + (q{-}1)z)^n + (q{-}1)(1{-}z)^n\n\\end{eqnarray*}\n(note that $n \\cdot P_n(z)$ is the derivative of $Q_n(z)$).\nThen~(\\ref{eq:lambda}) can be written as\n\\begin{eqnarray}\n\\label{eq:lambdaalt}\n\\lambda(\\omega,n)\n\\!\n& = & \\!\\!\\! \\inf_{z \\in (0,1]} \n\\Bigl\\{ -\\omega \\log_q z - \\frac{1}{n} + \\frac{1}{n} \\log_q Q_n(z)\n\\Bigr\\} \\\\\n\\nonumber\n& = &\n-\\omega \\log_q \\zeta_n(\\omega)\n- \\frac{1}{n} + \\frac{1}{n} \\log_q Q_n \\left( \\zeta_n(\\omega) \\right) .\n\\end{eqnarray}\nWe have the following lemma.\n\n\\begin{lemma}\n\\label{lem:unique}\nFor $n > 1$ and $\\omega \\in [0,(q{-}1)/q]$,\nthe value $\\zeta_n(\\omega)$ is\nthe unique real root in $[0,1]$ of the polynomial\n\\[\nU_{\\omega,n}(z) = \\omega \\cdot Q_n(z) - z \\cdot P_n(z) .\n\\]\nMoreover,\nthe mapping $\\omega \\mapsto \\zeta_n(\\omega)$ is strictly increasing. \n\\end{lemma}\n\n\\begin{proof}\nIt follows from the proof of Lemma~\\ref{lem:gamma}\nthat $\\zeta_n(0) = 0$ and $\\zeta_n((q{-}1)/q) = 1$.\nAssuming hereafter that $\\omega \\in (0,(q{-}1)/q)$,\nit also follows from that proof that\n$\\zeta_n(\\omega)$ is an (interior) point in $(0,1)$;\nas such, it is a local minimum\nof the objective function in~(\\ref{eq:lambdaalt})\nand, so, it equals a value $z$ at which\nthe derivative of that function (with respect to $z$) vanishes:\n\\begin{equation}\n\\label{eq:zetainverse}\n\\frac{\\omega}{z} - \\frac{P_n(z)}{Q_n(z)} = 0 .\n\\end{equation}\nThis equation, which is equivalent to\nrequiring that $U_{\\omega,n}(z) = 0$,\ncan be rearranged into\n\\begin{equation}\n\\label{eq:implicit}\n\\frac{(1{-}\\omega)(q{-}1) z - \\omega}{(1{-}\\omega)z + \\omega}\n= (q{-}1) \\cdot \\left(\n\\frac{1-z}{1 + (q{-}1)z}\n\\right)^{n-1} .\n\\end{equation}\nIn the range $z \\in [0,1]$,\nthe left-hand side of~(\\ref{eq:implicit}) is strictly increasing in $z$\n(from the value $-1$ at $z = 0$\nto $q{-}1 - q \\omega$ at $z = 1$)\nwhile the right-hand side of~(\\ref{eq:implicit})\nis strictly decreasing in $z$. Hence, for any\n$\\omega \\in (0,(q{-}1)/q)$, there is (at most) one $z \\in [0,1]$\nthat satisfies~(\\ref{eq:implicit}),\nand $\\zeta_n(\\omega)$ must then be that $z$.\nMoreover, since the left-hand side of~(\\ref{eq:implicit})\nis a strictly decreasing expression in $\\omega$,\nthe mapping $\\omega \\mapsto \\zeta_n(\\omega)$ is strictly increasing.\n\\end{proof}\n\n\\begin{remark}\n\\label{rem:unique}\nBy~(\\ref{eq:zetainverse}), the inverse mapping\n$z \\mapsto \\omega = \\zeta_n^{-1}(z)$ is given by\n\\[\n\\zeta_n^{-1}(z) = \\frac{z \\cdot P_n(z)}{Q_n(z)} .\n\\]\nNote also that Lemma~\\ref{lem:unique} is false when $n = 1$.\nIn this case $\\zeta_1(0)$ is arbitrary\n(and $U_{0,1}(z)$ is identically zero) while\n$\\zeta_1(\\omega) = 1$ when $\\omega > 0$\n(it is then a global---rather than local---minimum of\nthe objective function in~(\\ref{eq:lambdaalt})).\\qed\n\\end{remark}\n\nWe proceed to the characterization of the minimum in the inner\nexpression in~(\\ref{eq:WZL1}).\nWe will use the notation $[n]^*$ for the set $[n] \\setminus \\{ 1 \\}$.\n\n\\begin{lemma}\n\\label{lem:inner}\nGiven $n \\in \\Integers^+$, $\\mu \\in [n]$,\nand $\\omega \\in (0,(q{-}1)/q)$,\nlet $\\bldpi = (\\pi_s)_{s \\in [n]} \\in \\Realfield_{\\ge 0}^n$\nbe a vector that satisfies conditions (P1)--(P2)\nwith support $\\AltSet = \\Support(\\bldpi)$.\nA minimizer of the inner expression in~(\\ref{eq:WZL1})\nunder the constraint~(P3) is any vector\n$\\bldvartheta = (\\vartheta_s)_{s \\in [n]} \\in \\Realfield_{\\ge 0}^n$\nwhose subvector $(\\vartheta_s)_{s \\in \\AltSet}$\nis uniquely determined as follows:\n$\\vartheta_s = \\zeta_s^{-1}(z^*)$,\nwhere $z^*$ is the unique real in $[0,1]$ that satisfies\n\\[\n\\sum_{s \\in \\AltSet} \\pi_s \\cdot \\zeta_s^{-1}(z^*) = \\omega\n\\]\n(taking $\\zeta_1^{-1}(z^*) \\equiv 0$\nunless $\\AltSet = \\{ 1 \\}$, in which case\n$\\vartheta_1 = \\omega$).\n\\end{lemma}\n\n\\begin{proof}\nSince $\\omega \\mapsto \\Rate_0(\\omega,1)$ is identically zero,\nthe lemma holds when $\\AltSet = \\{ 1 \\}$,\nso we assume hereafter that $\\AltSet \\ne \\{ 1 \\}$\nand denote $\\AltSet^* = \\AltSet \\setminus \\{ 1 \\}$.\nBy condition~(P3), we can further assume that $\\vartheta_1 = 0$,\nsince otherwise we can reduce $\\vartheta_1$ and increase\n$\\vartheta_s$ for $s \\in [n]^*$, thereby only decreasing\nthe inner expression in~(\\ref{eq:WZL1}).\n\nDefine the function\n$\\bldvartheta = (\\vartheta_s)_{s \\in [n]^*} \\mapsto f(\\bldvartheta)$\nfor every $\\bldvartheta \\in \\Realfield_{\\ge 0}^{n-1}$\nto be the minimand in~(\\ref{eq:WZL1}):\n\\[\nf(\\bldvartheta) = f_\\bldpi(\\bldvartheta)\n= \\sum_{s \\in \\AltSet^*} \\pi_s \\cdot \\Rate_0(\\vartheta_s,s) .\n\\]\nSince $\\vartheta \\mapsto \\Rate_0(\\vartheta,s)$ is convex, so is \n$\\bldvartheta \\mapsto f(\\bldvartheta)$.\n\nWe minimize $f$ subject to condition~(P3)\nusing the method of Lagrange multipliers~\\cite[\\S 10.3]{Luenberger}:\nwe introduce a variable $\\xi$ and require that\nthe partial derivatives of the Lagrangian\n\\[\nL(\\bldvartheta,\\xi) = f(\\bldvartheta) + \\xi\n\\cdot \\Bigl( \\omega - \\sum_{s \\in [n]^*} \\pi_s \\cdot \\vartheta_s \\Bigr)\n\\]\nbe zero with respect to $\\xi$ and\nthe entries of $(\\vartheta_s)_{s \\in \\AltSet^*}$, namely,\n\\begin{equation}\n\\label{eq:lagrange1}\n\\sum_{s \\in \\AltSet^*} \\pi_s \\cdot \\vartheta_s = \\omega\n\\end{equation}\nand\n\\begin{equation}\n\\label{eq:lagrange2}\n\\frac{\\partial}{\\partial \\vartheta_s} L(\\bldvartheta,\\xi)\n= 0 , \\quad s \\in \\AltSet^* .\n\\end{equation}\nDenoting\n$\\bldzeta(\\bldvartheta)\n=\\left(\\zeta_s(\\vartheta_s)\\right)_{s \\in \\AltSet^*}$,\nwe can write $f(\\bldvartheta)$ as:\n\\[\nf(\\bldvartheta) = f(\\bldvartheta,\\bldz)\n\\bigm|_{\\bldz = \\bldzeta(\\bldvartheta)} ,\n\\]\nwhere $\\bldz = (z_s)_{s \\in \\AltSet^*}$\nis a real vector of variables and\n\\[\nf(\\bldvartheta,\\bldz)\n= 1 + \\sum_{s \\in \\AltSet^*} \\pi_s \n\\Bigl(\n\\vartheta_s \\cdot \\log_q z_s\n- \\frac{1}{s} \\log_q Q_s(z_s) \\Bigr) .\n\\]\nRecalling that\n\\[\n\\frac{\\partial}{\\partial z_i} f(\\bldvartheta,\\bldz)\n\\Bigm|_{\\bldz = \\bldzeta(\\bldvartheta)} = 0 ,\n\\quad\n\\textrm{for every $i \\in \\AltSet^*$} ,\n\\]\nwe get for every $s \\in \\AltSet^*$:\n\\begin{eqnarray*}\n\\frac{\\partial}{\\partial \\vartheta_s} f(\\bldvartheta)\n& = &\n\\frac{\\partial}{\\partial \\vartheta_s} f(\\bldvartheta,\\bldz)\n\\Bigm|_{\\bldz = \\bldzeta(\\bldvartheta)} \\\\\n&&\n\\quad {}\n+ \n\\sum_{i \\in \\AltSet^*}\n{\\underbrace{\n\\frac{\\partial}{\\partial z_i} f(\\bldvartheta,\\bldz)\n\\Bigm|_{\\bldz = \\bldzeta(\\bldvartheta)} \n}_0}\n\\cdot\n\\frac{\\partial}{\\partial \\vartheta_s}\n\\zeta_i(\\vartheta_i) \\\\\n& = &\n\\pi_s \\cdot \\log_q \\zeta_s(\\vartheta_s) .\n\\end{eqnarray*}\nHence, by~(\\ref{eq:lagrange2}),\n\\[\n\\pi_s \\cdot \\left( \\log_q \\zeta_s(\\vartheta_s) - \\xi \\right) = 0 ,\n\\]\nnamely, the values $\\zeta_s(\\vartheta_s)$\nare equal to (the same value) $z^* = q^\\xi$, for all $s \\in \\AltSet^*$.\nFinally, by~(\\ref{eq:lagrange1}), the value $z^*$ must be such that\n\\[\n\\sum_{s \\in \\AltSet^*} \\pi_s \\cdot \\zeta_s^{-1}(z^*) = \\omega .\n\\]\nThis equality determines $z^*$ uniquely,\nsince $z \\mapsto \\zeta_s^{-1}(z)$ is strictly increasing\nfor any $s \\in [n]^*$.\n\\end{proof}\n\nWe next turn to the characterization of the outer maximum\nin~(\\ref{eq:WZL1}).\n\n\\begin{lemma}\n\\label{lem:outer}\nGiven $n \\in \\Integers^+$, $\\mu \\in [n]$,\nand $\\omega \\in (0,(q{-}1)/q)$,\nlet $k = \\lfloor \\mu \\rfloor$ and\n\\begin{equation}\n\\label{eq:pik}\n\\pi =\n\\frac{k(k{+}1)}{\\mu} - k .\n\\end{equation}\nThe entries of the maximizing vector\n$\\bldpi = (\\pi_s)_{s \\in [n]} \\in \\Realfield_{\\ge 0}^n$\nin~(\\ref{eq:WZL1}) under the constraints (P1)--(P2)\nare all zero, except for\nthe entries that are indexed by $k$\nand (possibly) $k+1$, where\n\\[\n\\pi_k = \\pi\n\\quad \\textrm{and} \\quad\n\\pi_{k+1} = 1 - \\pi .\n\\]\n\\end{lemma}\n\n\\begin{proof}\nWhen $\\mu = 1$, conditions (P1)--(P2) force $\\bldpi$\nto be $(1 \\, 0 \\, 0 \\, \\ldots \\, 0)$\n(i.e., $\\Support(\\bldpi) = \\{ 1 \\}$),\nin which case $\\omega \\mapsto \\overline{\\Rate}_0(\\omega,n,1)$\nis identically zero.\nHence, we assume hereafter that $\\mu > 1$, in which case\na maximizing $\\bldpi$ must have support${} \\ne \\{ 1 \\}$\nto achieve $\\overline{\\Rate}_0(\\omega,n,\\mu) > 0$.\n\nDefine the function $\\bldpi = (\\pi_s)_{s \\in [n]} \\mapsto g(\\bldpi)$\nfor every $\\bldpi \\in \\Realfield^n_{\\ge 0}$ to be the maximand\nin~(\\ref{eq:WZL1}), namely,\n\\begin{eqnarray*}\ng(\\bldpi)\n& = &\n\\sum_{s \\in [n]} \\pi_s \\cdot \\Rate_0(\\vartheta^*_s,s) \\\\\n& = &\n1 - \\omega \\cdot \\log_q z^*\n+ \\sum_{s \\in [n]}\n\\frac{\\pi_s}{s} \\log_q Q_s(z^*) ,\n\\end{eqnarray*}\nwhere $\\vartheta^*_s = \\zeta_s^{-1}(z^*)$ for each $s \\in [n]$\nand $z^*$ is as in Lemma~\\ref{lem:inner};\nnamely, $z^*$ is determined uniquely by $\\bldpi$ (and $\\omega$)\nand, therefore, so is each $\\vartheta^*_s$\n(in particular, $\\vartheta^*_1 = 0$).\nWe do the maximization subject to the constraints (P1)--(P2)\nusing the Kuhn--Tucker conditions~\\cite[\\S 10.8]{Luenberger}:\nwe introduce a real variable $\\xi$\nand require that the partial derivatives of\n\\begin{eqnarray}\nK(\\bldpi,\\xi)\n\\!\\! & = & \\!\\!\ng(\\bldpi) \n+ \\xi \\cdot \\Bigl( 1 - \\sum_{s \\in [n]} \\pi_s \\Bigr) \\nonumber \\\\\n\\label{eq:KKT0}\n&& {}\n- \\beta\n\\cdot \\Bigl( \\frac{1}{\\mu} - \\sum_{s \\in [n]} \\frac{\\pi_s}{s} \\Bigr)\n+ \\sum_{s \\in [n]} \\eta_s \\cdot \\pi_s\n\\end{eqnarray}\nbe zero with respect to $\\xi$\nand the entries of $\\bldpi$, for some nonnegative\n$\\beta$ and $\\bldeta = (\\eta_s)_{s \\in [n]}$ that satisfy\n\\begin{equation}\n\\label{eq:KKT1}\n\\beta\n\\cdot \\Bigl( \\frac{1}{\\mu} - \\sum_{s \\in [n]} \\frac{\\pi_s}{s} \\Bigr)\n= 0\n\\end{equation}\nand\n\\begin{equation}\n\\label{eq:KKT2}\n\\eta_s \\cdot \\pi_s = 0 , \\quad \\textrm{for each $s \\in [n]$} .\n\\end{equation}\nThe second term in the right-hand side of~(\\ref{eq:KKT0})\ncorresponds to condition~(P1);\nthe third term and~(\\ref{eq:KKT1}) correspond to condition~(P2);\nand the last term and~(\\ref{eq:KKT2})\ncorrespond to requiring that $\\bldpi$ be nonnegative.\n\nSimilarly to what we have done in the proof\nof Lemma~\\ref{lem:inner}, we can write $g(\\bldpi)$ as\n\\[\ng(\\bldpi) = g(\\bldpi,\\bldz)\n\\bigm|_{\\bldz = z^* \\cdot \\bldone} ,\n\\]\nwhere $\\bldz = (z_s)_{s \\in[n]^*}$\nis a real vector of variables\nand $\\bldone$ stands for the all-one vector\nin $\\Realfield_{\\ge 0}^{n-1}$.\nRecalling that\n\\[\n\\frac{\\partial}{\\partial z_i} g(\\bldpi,\\bldz)\n\\Bigm|_{z_i = z^*} = 0 ,\n\\quad \\textrm{for every $i \\in [n]^*$} ,\n\\]\nwe get:\n\\begin{eqnarray*}\n\\frac{\\partial}{\\partial \\pi_s} g(\\bldpi)\n& = &\n\\frac{\\partial}{\\partial \\pi_s} g(\\bldpi,\\bldz)\n\\Bigm|_{\\bldz = z^* \\cdot \\bldone} \\\\\n&&\n\\;\\;\\;\n{}\n+\n\\sum_{i \\in [n]^*}\n{\\underbrace{\n\\frac{\\partial}{\\partial z_i} g(\\bldpi,\\bldz) \\Bigm|_{z_i = z^*}\n}_0}\n\\cdot\n\\frac{\\partial}{\\partial \\pi_s}\n\\zeta_i(\\vartheta^*_i(\\bldpi)) \\\\\n& = &\n\\frac{1}{s} \\log_q Q_s(z^*) .\n\\end{eqnarray*}\nReturning to the expression for $K(\\bldpi,\\xi)$ in~(\\ref{eq:KKT0}),\nwe conclude that $(\\partial K(\\bldpi,\\xi))/\\partial \\pi_s = 0$\ntranslates into\n\\begin{equation}\n\\label{eq:KKT3}\n\\eta_s = \\psi(s) ,\n\\end{equation}\nwhere\n\\[\n\\psi(s) = \\psi(s,\\beta)\n= \\frac{1}{s} \\Bigl(\n\\log_q Q_s(z^*) - \\beta \\Bigr) + \\xi .\n\\]\n\nNext, we analyze the function $s \\mapsto \\psi(s)$\nin the \\emph{real} variable $s \\in [1,\\infty)$.\nTaking the derivative of this function, we get:\n\\begin{eqnarray}\n\\psi'(s)\n& = &\n\\frac{1}{s} \\cdot \\frac{1}{Q_s(z^*)}\n\\biggl(\n(1+(q{-}1)z^*)^s \\log_q (1+(q{-}1)z^*) \\nonumber \\\\\n&& \\quad\\quad\\quad {}\n+ (q{-}1)(1{-}z^*)^s \\log_q (1{-}z^*) \\biggr) \\nonumber \\\\\n&& \\quad {}\n- \\frac{1}{s^2}\n\\left( \\log_q Q_s(z^*) - \\beta \\right) \\nonumber \\\\\n\\label{eq:psider}\n& = &\n\\frac{1}{s^2} \\bigl( \\beta - \\entropy_q(p_s) \\bigr) ,\n\\end{eqnarray}\nwhere\n\\[\np_s = \\frac{(q{-}1) (1{-}z^*)^s}{Q_s(z^*)}\n\\]\nand $x \\mapsto \\entropy_q(x)$ is the $q$-ary entropy function\n$x \\cdot \\log_q (q{-}1) - x \\log_q x - (1{-}x) \\log_q (1{-}x)$.\nThis function is strictly increasing on $[0,(q{-}1)/q]$\nand $s \\mapsto p_s$ is strictly decreasing on $[1,\\infty)$,\nwith the following maximum value attained at $s = 1$:\n\\[\np_1 = \\frac{(q{-}1)(1{-}z^*)}{Q_1(z^*)} < \\frac{q{-}1}{q} .\n\\]\nWe conclude from~(\\ref{eq:psider}) that, on the interval $[1,n]$,\nthe function $s \\mapsto \\psi(s)$ is either\n(i)~strictly increasing,\nor\n(ii)~strictly decreasing,\nor\n(iii)~unimodal with one local minimum.\nNote from~(\\ref{eq:psider}) that $\\beta = 0$ implies case~(ii).\n\nAs our next step, we turn back to~(\\ref{eq:KKT3}).\nSince $\\eta_s \\ge 0$ for all $s \\in [n]$, in case~(i)\nwe can have $\\eta_s = 0$ only when $s = 1$. Similarly, in case~(ii)\nwe can have $\\eta_s = 0$ only when $s = n$. And in case~(iii)\nwe can have $\\eta_s = 0$ only for the (one or)\ntwo consecutive indexes $s$ that are adjacent to\nthe minimum of $\\psi(\\cdot)$.\nWe conclude that $\\eta_s > 0$ for all $s$ except for those two indexes;\nthis, together with~(\\ref{eq:KKT2}), implies that the support\nof a maximizing $\\bldpi$ contains (only) those two indexes.\n\nObserve that by~(\\ref{eq:KKT1}),\na maximizing $\\bldpi$ must satisfy condition~(P2) with equality,\nunless $\\beta = 0$, in which case\n$\\bldpi = (0 \\, 0 \\, 0 \\, \\ldots \\, 1)$ (case~(ii) above).\nCondition~(P2) would then read\n$1/n = \\pi_n/n \\ge 1/\\mu$, i.e., $\\mu \\ge n$.\nYet we assume that $\\mu \\in [n]$, thereby forcing $\\mu = n$,\nso condition~(P2) holds with equality in this case too.\n\nFinally, let $k$ and (possibly) $k+1$ be the elements\nin the support of a maximizing $\\bldpi$.\nWe then get from conditions (P1) (and the equality version of) (P2)\nthat the entries $\\pi_k$ and $\\pi_{k+1}$\nsatisfy the following equations:\n\\[\n\\begin{array}{ccc}\n\\displaystyle\n\\pi_k + \\pi_{k+1} & = & 1 \\phantom{.}\\rule[-2ex]{0ex}{1ex} \\\\\n\\displaystyle\n\\frac{\\pi_k}{k} + \\frac{\\pi_{k+1}}{k{+}1}\n& = &\n\\displaystyle\n\\frac{1}{\\mu} .\n\\end{array}\n\\]\nSolving these equations yields $\\pi_k = \\pi$ and\n$\\pi_{k+1} = 1-\\pi$, where $\\pi$ is given by~(\\ref{eq:pik}),\nand the value of $k$ is determined by\n\\[\n\\renewcommand{\\arraystretch}{1.1}\n\\begin{array}{rcl}\n\\pi \\ge 0 & \\Rightarrow & \\mu \\le k+1 \\\\\n\\pi \\le 1 & \\Rightarrow & \\mu \\ge k .\n\\end{array}\n\\]\n\\end{proof}\n\nCombining Lemmas~\\ref{lem:inner} and~\\ref{lem:outer}\nleads to the following recipe for computing\nthe value of $\\overline{\\Rate}_0(\\omega,n,\\mu)$.\n\n\\begin{proposition}\n\\label{prop:WZL}\nGiven $n \\in \\Integers^+$, $\\mu \\in [n]$,\nand $\\omega \\in [0,(q{-}1)/q]$,\nlet $k = \\lfloor \\mu \\rfloor$\nand let $\\pi$ be as in (\\ref{eq:pik}).\nAlso, let $z^*$ be the unique real in $[0,1]$ that satisfies\n\\begin{equation}\n\\label{eq:zstar}\n\\pi \\cdot \\zeta_k^{-1}(z^*)\n+ (1-\\pi) \\cdot \\zeta_{k+1}^{-1}(z^*) = \\omega\n\\end{equation}\n(taking $\\zeta_1^{-1}(z^*) \\equiv 0$ when $\\mu \\in (1,2)$\nand $\\zeta_1^{-1}(z^*) = \\omega$ when $\\mu = 1$).\nThen\n\\[\n\\overline{\\Rate}_0(\\omega,n,\\mu) =\n\\pi \\cdot \\Rate_0(\\vartheta, k)\n+ (1-\\pi) \\cdot \\Rate_0(\\vartheta',k{+}1) ,\n\\]\nwhere\n\\[\n\\vartheta = \\zeta_k^{-1}(z^*)\n\\quad \\textrm{and} \\quad\n\\vartheta' = \\zeta_{k+1}^{-1}(z^*) .\n\\]\nIn particular, when $\\mu$ is an integer then\n\\[\n\\overline{\\Rate}_0(\\omega,n,\\mu) = \\Rate_0(\\omega,\\mu) .\n\\]\n\\end{proposition}\n\n\\begin{remark}\n\\label{rem:WZL}\nBy Remark~\\ref{rem:unique},\nsolving~(\\ref{eq:zstar}) for $z^*$ amounts\nto finding the (unique) real root in $[0,1]$ of the polynomial\n\\begin{eqnarray*}\n\\lefteqn{\n\\omega \\cdot Q_k(z) \\cdot Q_{k+1}(z) \n} \\makebox[0ex]{} \\\\\n&& \n\\!\\! {}\n- z \\cdot \\bigl( \\pi \\cdot P_k(z) \\cdot Q_{k+1}(z)\n+ (1-\\pi) \\cdot P_{k+1}(z) \\cdot Q_k(z) \\bigr) .\n\\end{eqnarray*}\\qed\n\\end{remark}\n\n\\begin{remark}\n\\label{rem:WZL2}\nUsing \\Proposition~\\ref{prop:WZL}, it is fairly easy\nto compute the maximization in~(\\ref{eq:WZL2}) numerically.\nGiven $n \\in \\Integers^+$,\nwe next argue that for sufficiently small positive $\\omega$\n(within an interval whose length depends on $n$),\nthe maximum in~(\\ref{eq:WZL2}) is attained at $\\nu = 0$.\nFor any $\\nu \\in [0,(n{-}1)/(n{+}1)]$,\nlet $\\mu(\\nu)$ denote the value $((1{-}\\nu)/(1{+}\\nu)) n \\; (\\in [n])$.\nGiven $\\omega \\in [0,2(q{-}1)/(q (n{+}1))]$,\nthe objective function in~(\\ref{eq:WZL2})\ncan be verified to be (continuous and)\npiecewise differentiable in $\\nu$.\nSpecifically, at any $\\nu \\in [0,(n{-}1)/(n{+}1)]$\nfor which $\\mu(\\nu)$ is not an integer, the derivative is given by\n\\begin{equation}\n\\label{eq:derivative}\n\\left( 1 + \\frac{k}{n} \\right) \\log_q Q_{k+1}(z^*)\n- \\left( 1 + \\frac{k{+}1}{n} \\right) \\log_q Q_k(z^*) ,\n\\end{equation}\nwhere $k$ and $z^*$ are as in \\Proposition~\\ref{prop:WZL},\nwith $\\mu$ and $\\omega$ therein taken \nas $\\mu = \\mu(\\nu)$\nand $\\omega/(1{-}\\nu) \\; (\\in [0,(q{-}1)/q])$, respectively.\nNow, by~(\\ref{eq:zetainverse})\nand~(\\ref{eq:zstar}) it follows that $z^* \\rightarrow 0$\nas $\\omega \\rightarrow 0$ (uniformly in $\\nu$).\nAnd since the expression~(\\ref{eq:derivative}) is negative\nat $z^* = 0$ for any $k \\in [n{-}1]$, we conclude that\nfor sufficiently small $\\omega > 0$, the objective function\nin~(\\ref{eq:WZL2}) is decreasing in $\\nu$.\nThus, the maximum therein is attained at $\\nu = 0$, in which case\n\\[\n\\widehat{\\Rate}_0(\\omega,n) = \\Rate_0(\\omega,n) .\n\\]\\qed\n\\end{remark}\n\n\\begin{remark}\n\\label{rem:averagelength2}\nAs we pointed out in Remark~\\ref{rem:averagelength1},\nthe value $\\overline{\\Rate}_0(\\delta/2,n,\\mu)$\nbounds from above the rate of any all-disjoint\nlinearly recoverable $(\\delta,n)$-LRC sequence\n$(\\varcode_i)_{i=1}^\\infty$ under the additional\ncondition that the average size of the repair groups\nof each $\\varcode_i$ is at most $\\mu$\n(in the limit when $i \\rightarrow \\infty$).\nA related relevant problem is obtaining such a bound\nwhen the average is computed per coordinate, i.e.,\nthe average is taken over the whole list of the $N_i$ repair groups\nof $\\varcode_i$; thus, each of the distinct repair groups\nis counted a number of times which equals\nthe number of coordinates that it covers\n(namely, its size). \nA counterpart of the bound~(\\ref{eq:Singleton})\nfor this setting was presented in~\\cite{SKA}.\n\nA sphere-packing upper bound for this setting\nis obtained by substituting $\\omega = \\delta/2$\nin~(\\ref{eq:WZL1}), except that condition~(P2) is replaced by\n\\begin{list}{}{\\settowidth{\\labelwidth}{\\textrm{P2)}}}\n\\item[P2)]\n$\\displaystyle \\sum_{s \\in [n]} s \\cdot \\pi_s \\le \\mu$.\n\\end{list}\n\\Proposition~\\ref{prop:WZL} still holds, except that\nthe value of $\\pi$ in~(\\ref{eq:pik}) is changed into\n\\[\n\\pi = k + 1 - \\mu .\n\\]\nSpecifically, Lemma~\\ref{lem:inner} holds as is;\nas for Lemma~\\ref{lem:outer},\nthe third term in~(\\ref{eq:KKT0})\n(and, accordingly, the left-hand side of~(\\ref{eq:KKT1})) is replaced by\n\\[\n\\beta \\cdot \\Bigl( \\mu - \\sum_{s \\in [n]} s \\cdot \\pi_s \\Bigr)\n\\]\n(with a plus sign). Consequently, (\\ref{eq:psider}) becomes\n\\[\n\\beta - \\frac{1}{s^2} \\cdot \\entropy_q(p_s)\n\\]\nwhich, in turn, leads to the same conclusions about the function\n$s \\mapsto \\psi(s)$ (cases (i)--(iii)).\nThus, the support of a maximizing $\\bldpi$ contains up to\ntwo indexes, $k$ and $k+1$, and, by (P1)--(P2), the values of\n$\\pi_k$ and $\\pi_{k+1}$ are the solutions of\n\\[\n\\begin{array}{c@{\\;}c@{\\;}ccc}\n\\displaystyle\n\\pi_k & + & \\pi_{k+1} & = & 1 \\phantom{.}\\rule[-2ex]{0ex}{1ex} \\\\\n\\displaystyle\nk \\cdot \\pi_k & + & (k{+}1) \\cdot \\pi_{k+1}\n& = &\n\\mu .\n\\end{array}\n\\]\\qed\n\\end{remark}\n\\fi\n\n\\begin{thebibliography}{99}\n\\bibitem{Aaltonen}\n    \\bibauthor{M. Aaltonen,}\n    \\bibpaper{A new upper bound on nonbinary block codes,}\n    \\bibperiodical{Discrete Math.,} 83 (1990) 139--160.\n\\bibitem{ABHMT}\n    \\bibauthor{A. Agarwal, A. Barg, S. Hu, A. Mazumdar, I. Tamo,}\n    \\bibpaper{Combinatorial alphabet-dependent bounds\n    for locally recoverable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 64 (2018), 3481--3492.\n\\bibitem{BK}\n    \\bibauthor{S.B. Balaji, P.V. Kumar,}\n    \\bibpaper{Bounds on the rate and minimum distance of\n    codes with availability,}\n    \\bibperiodical{Proc.\\ 2017 IEEE Int'l Symp.\\ Inf.\\ Theory\n    (ISIT 2017),}\n    Aachen, Germany (June 2017), 3155--3159.\n\\bibitem{BHL1}\n    \\bibauthor{Y. Ben-Haim, S. Litsyn,}\n    \\bibpaper{A new upper bound on the rate of non-binary codes,}\n    \\bibperiodical{Adv.\\ Math.\\ Commun.,} 1 (2007), 83--92.\n\\ifPAGELIMIT\n\\else\n\\bibitem{BHL2}\n    \\bibauthor{Y. Ben-Haim, S. Litsyn,}\n    private communication, 2020.\n\\fi\n\\bibitem{BCCST}\n    \\bibauthor{C. Bachoc, V. Chandar, G. Cohen, P. Sol\\'{e},\n     A. Tchamkerten,}\n    \\bibpaper{On balanced weight codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 57 (2011), 6780--6787.\n\\bibitem{Blaum}\n    \\bibauthor{M. Blaum,}\n    \\bibpaper{Extended integrated interleaved codes over any\n    field with applications to locally recoverable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 66 (2020), 936--956.\n\\bibitem{CM}\n    \\bibauthor{V. Cadambe, A. Mazumdar,}\n    \\bibpaper{Bounds on the size of locally recoverable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 61 (2015), 5787--5794.\n\\ifPAGELIMIT\n\\else\n\\bibitem{DZ}\n    \\bibauthor{A. Dembo, O. Zeitouni,}\n    \\bibbook{Large Deviations Techniques and Applications,}\n    Second Edition,\n    Springer, Berlin, 2010.\n\\fi\n\\bibitem{GHSY}\n    \\bibauthor{P. Gopalan, C. Huang, H. Simitci, S. Yekhanin,}\n    \\bibpaper{On the locality of codeword symbols,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 58 (2012), 6925--6934.\n\\bibitem{GFY}\n    \\bibauthor{S. Gopi, V. Guruswami, S. Yekhanin,}\n    \\bibpaper{Maximally recoverable LRCs: A field size\n    lower bound and constructions for few heavy parities,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 66 (2020), 6066--6083.\n\\bibitem{GFWH}\n    \\bibauthor{M. Grezet, R. Freij-Hollanti, T. Westerb\\\"{a}ck,\n    C. Hollanti,}\n    \\bibpaper{Alphabet-dependent bounds for linear locally\n    repairable codes based on residual codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 65 (2019), 6089--6100.\n\\bibitem{GJX}\n    \\bibauthor{V. Guruswami, L. Jin, C. Xing,}\n    \\bibpaper{Constructions of maximally recoverable local\n    reconstruction codes via function fields,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} to appear.\n\\bibitem{HYS}\n    \\bibauthor{P. Huang, E. Yaakobi, P.H. Siegel,}\n    \\bibpaper{Multi-erasure locally recoverable codes over\n    small fields: A tensor product approach,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 66 (2020), 2609--2624.\n\\bibitem{HYUS}\n    \\bibauthor{P. Huang, E. Yaakobi, H. Uchikawa, P.H. Siegel,}\n    \\bibpaper{Binary linear locally repairable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 62 (2016), 6268--6283.\n\\bibitem{LL}\n    \\bibauthor{T. Laihonen, S. Litsyn,}\n    \\bibpaper{On upper bounds for minimum distance and\n    covering radius of non-binary codes,}\n    \\bibperiodical{Des.\\ Codes, Cryptogr.,}  14 (1998), 71-\u201380.\n\\ifPAGELIMIT\n\\else\n\\bibitem{Luenberger}\n    \\bibauthor{D.G. Luenberger}\n    \\bibbook{Linear and Nonlinear Programming,}\n    Second Edition,\n    Addison-Wesley, Reading, Massachusetts, 1984.\n\\fi\n\\bibitem{MRRW}\n    \\bibauthor{R.J. McEliece, E.R. Rodemich, H. Rumsey, Jr.,\n    L.R. Welch,} \n    \\bibpaper{New upper bounds on the rate of a code via\n    the Delsarte--MacWilliams inequalities,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 23 (1977), 157--166.\n\\bibitem{MG}\n    \\bibauthor{J. Ma, G. Ge,}\n    \\bibpaper{Optimal binary linear locally repairable codes with\n    disjoint repair groups,}\n    \\bibperiodical{SIAM J. Discrete Math.,}  33 (2019), 2509--2529.\n\\bibitem{PHO}\n    \\bibauthor{L. Pamies-Juarez, H.D.L. Hollmann, F. Oggier,}\n    \\bibpaper{Locally repairable codes with multiple repair\n    alternatives,}\n    \\bibperiodical{Proc.\\ 2013 IEEE Int'l Symp.\\ Inf.\\ Theory\n    (ISIT 2013),}\n    Istanbul, Turkey (July 2013), 892--896.\n\\bibitem{PD}\n    \\bibauthor{D.S. Papailiopoulos, A.G. Dimakis,}\n    \\bibpaper{Locally repairable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 60 (2014), 5843--5855.\n\\bibitem{PKLK}\n    \\bibauthor{N. Prakash, G.M. Kamath, V. Lalitha, P.V. Kumar,}\n    \\bibpaper{Optimal linear codes with a local-error-correction\n    property,}\n    \\bibperiodical{Proc.\\ 2012 IEEE Int'l Symp.\\ Inf.\\ Theory\n    (ISIT 2012),}\n    Cambridge, Massachusetts (July 2012), 2776--2780.\n\\ifPAGELIMIT\n    \\bibitem{RothFull}\n        \\bibauthor{R.M. Roth,}\n        \\bibpaper{Asymptotic bounds on the rate of locally repairable \n        codes,}\n        available online.\n\\else\n\\bibitem{Roth}\n    \\bibauthor{R.M. Roth,}\n    \\bibbook{Introduction to Coding Theory,}\n    Cambridge University Press, Cambridge, UK, 2006.\n\\bibitem{SKA}\n    \\bibauthor{M. Shahabinejad, M. Khabbazian, M. Ardakani,}\n    \\bibpaper{On the average locality of locally repairable codes,}\n    \\bibperiodical{IEEE Trans.\\ Commun.,} 66 (2018), 2773--2783.\n\\fi\n\\bibitem{TBF}\n    \\bibauthor{I. Tamo, A. Barg, A. Frolov,}\n    \\bibpaper{Bounds on the parameters of locally recoverable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 62 (2016), 3070--3083.\n\\bibitem{TB}\n    \\bibauthor{I. Tamo, A. Barg,}\n    \\bibpaper{A family of optimal locally recoverable codes,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 60 (2014), 4661--4676.\n\\bibitem{WZ}\n    \\bibauthor{A. Wang, Z. Zhang,}\n    \\bibpaper{Repair locality with multiple erasure tolerance,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 60 (2014), 6979--6987.\n\\bibitem{WZL}\n    \\bibauthor{A. Wang, Z. Zhang, D. Lin,}\n    \\bibpaper{Bounds for binary linear locally repairable\n    codes via a sphere-packing approach,}\n    \\bibperiodical{IEEE Trans.\\ Inf.\\ Theory,} 65 (2019), 4167--4179.\n\\end{thebibliography}\n%\n%   Gray  -- SP\n%   Green -- CM\n%   Blue  -- Shortening of LP\n%   Red   -- New bound\n%   Cyan  -- Shortening of new bound\n%\n\\newcommand{\\Bfull}{\\circle*{0.80}}\n%%\\newcommand{\\Bbox}{{\\put(-.04,-.04){\\framebox(0.08,0.08){$\\cdot$}}}}\n\\newcommand{\\Bbox}{{\\put(-.05,-.05){\\framebox(0.1,0.1){$\\cdot$}}}}\n\\newcommand{\\Bdiam}{{\\multiput(-.07,-.33)(-.13,.13){3}{\\line(1,1){.4}}}}\n\\newcommand{\\Bplus}{{\\thinlines%\n            \\put(-.38,0){\\line(1,0){.76}}\\put(0,-.38){\\line(0,1){.76}}}}\n\\newcommand{\\Bprod}{{\\thinlines%\n            \\put(-.4,-.4){\\line(1,1){.8}}\\put(-.4,.4){\\line(1,-1){.8}}}}\n\\newcommand{\\Bempty}{{\\color{gray}\\circle{0.6}}}\n\\newcommand{\\Plot}[1]{%\n    \\begin{center}\n    \\small\n    \\thicklines\n    \\ifIEEE\n        \\setlength{\\unitlength}{1.3mm}\n    \\else\n        \\setlength{\\unitlength}{1.2mm}\n    \\fi\n    \\begin{picture}(135,135)(-10,-10)\n    \\put(-10,000){\\vector(1,0){120}}\n    \\put(114,000){\\makebox(0,0)[l]{$\\delta$}}\n    \\put(000,-10){\\vector(0,1){120}}\n    \\put(-04,114){\\makebox(0,0)[r]{$R$}}\n    \\put(-05,-04){\\makebox(0,0)[t]{$0$}}\n    \\multiput(020,000)(020,000){5}{\\line(0,-1){2}}\n    \\put(020,-04){\\makebox(0,0)[t]{$0.1$}}\n    \\put(040,-04){\\makebox(0,0)[t]{$0.2$}}\n    \\put(060,-04){\\makebox(0,0)[t]{$0.3$}}\n    \\put(080,-04){\\makebox(0,0)[t]{$0.4$}}\n    \\put(100,-04){\\makebox(0,0)[t]{$0.5$}}\n    \\multiput(000,010)(000,010){10}{\\line(-1,0){2}}\n    \\put(-04,050){\\makebox(0,0)[r]{$0.5$}}\n    \\put(-04,100){\\makebox(0,0)[r]{$1.0$}}\n    \\put(000,000){#1}\n    \\end{picture}\n    \\thinlines\n    \\setlength{\\unitlength}{1pt}\n    \\end{center}\n}\n\\newcommand{\\Legend}{%\n        %%\\put(000,000){\\color{brown}\\line(1,0){10}}\n        \\put(000,000){\\multiput(.2,0)(1.92,000){6}{\\color{brown}\\Bbox}}\n        \\put(013,000){\\makebox(0,0){(a)}}\n        \\put(016,000){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_\\SP(\\delta,n)$}}\n        \\put(000,-04){\\color{green}\\line(1,0){10}}\n        \\put(000,-04){\\multiput(.28,0)(1.89,00){6}{\\color{green}\\Bdiam}}\n        \\put(013,-04){\\makebox(0,0){(b)}}\n        \\put(016,-04){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_\\CM(\\delta,n)$\n                    with $\\Rate_\\opt(\\delta) = \\Rate_\\LP(\\delta)$}}\n        \\put(000,-08){\\color{blue}\\line(1,0){10}}\n        \\put(000,-08){\\multiput(.4,0)(1.84,000){6}{\\color{blue}\\Bprod}}\n        \\put(013,-08){\\makebox(0,0){(c)}}\n        \\put(016,-08){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_1(\\delta,n)$\n                    with $\\Rate_\\LRC(\\delta,n) = \\Rate_\\LP(\\delta)$}}\n        \\put(000,-12){\\color{red}\\line(1,0){10}}\n        \\put(013,-12){\\makebox(0,0){(d)}}\n        \\put(016,-12){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_2(\\delta,n)$}}\n        \\put(000,-16){\\color{cyan}\\line(1,0){10}}\n        \\put(013,-16){\\makebox(0,0){(e)}}\n        \\put(016,-16){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_1(\\delta,n)$\n                    with $\\Rate_\\LRC(\\delta,n) = \\Rate_2(\\delta,n)$}}\n        \\put(000,-16){\\multiput(.2,0)(1.92,000){6}{\\color{cyan}\\Bfull}}\n        \\put(013,-20){\\makebox(0,0){(f)}}\n        \\put(016,-20){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_0(\\delta,n)$ (lower bound)}}\n        \\put(000,-20){\\multiput(.2,0)(1.92,000){6}{\\color{black}\\Bfull}}\n}\n\\newcommand{\\LegendAlt}{%\n        %%\\put(000,000){\\color{brown}\\line(1,0){10}}\n        \\put(000,000){\\multiput(.2,0)(1.92,000){6}{\\color{brown}\\Bbox}}\n        \\put(013,000){\\makebox(0,0){(a)}}\n        \\put(016,000){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\widehat{\\Rate}_0(\\delta/2,n)$\n                    (sphere-packing bound)}}\n        \\put(000,-04){\\color{green}\\line(1,0){10}}\n        \\put(000,-04){\\multiput(.3,0)(1.88,000){6}{\\color{green}\\Bdiam}}\n        \\put(013,-04){\\makebox(0,0){(b)}}\n        \\put(016,-04){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_\\CM(\\delta,n)$\n                    with $\\Rate_\\opt(\\delta) = \\Rate_\\LP(\\delta)$}}\n        \\put(000,-08){\\color{blue}\\line(1,0){10}}\n        \\put(000,-08){\\multiput(.4,0)(1.84,000){6}{\\color{blue}\\Bprod}}\n        \\put(013,-08){\\makebox(0,0){(c)}}\n        \\put(016,-08){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\widehat{\\Rate}_1(\\delta,n)$\n                    with $\\Rate_\\opt(\\delta,n) = \\Rate_\\LP(\\delta)$}}\n        \\put(000,-12){\\color{red}\\line(1,0){10}}\n        \\put(013,-12){\\makebox(0,0){(d)}}\n        \\put(016,-12){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\min \\bigl\\{\n                    \\widehat{\\Rate}_2(\\delta,n),\n                    \\Rate_\\LP(\\delta,n) \\bigr\\}$}}\n        \\put(013,-16){\\makebox(0,0){(e)}}\n        \\put(016,-16){\\makebox(0,0)[l]{%\n                    $\\delta \\mapsto \\Rate_0(\\delta,n)$ (lower bound)}}\n        \\put(000,-16){\\multiput(.2,0)(1.92,000){6}{\\color{black}\\Bfull}}\n}\n\\ifPAGELIMIT\n\\else\n\\begin{figure*}[hbt]\n%% q = 2, n =  3:\n\\Plot{%\n    \\put(035,095){\n\t\\put(000,000){\\Legend}\n        \\put(000,-24){\\multiput(0.3,000)(1.88,000){6}{\\Bempty}}\n        \\put(013,-24){\\makebox(0,0){(g)}}\n        \\put(016,-24){\\makebox(0,0)[l]{Eq.~(\\ref{eq:n=3})}}\n    }\n%%  Aaltonen:\n    \\put(0.000,66.667){\\Bempty}\\put(2.000,64.129){\\Bempty}\n    \\put(4.000,62.065){\\Bempty}\\put(6.000,60.169){\\Bempty}\n    \\put(8.000,58.375){\\Bempty}\\put(10.000,56.654){\\Bempty}\n    \\put(12.000,54.988){\\Bempty}\\put(14.000,53.366){\\Bempty}\n    \\put(16.000,51.779){\\Bempty}\\put(18.000,50.221){\\Bempty}\n    \\put(20.000,48.688){\\Bempty}\\put(22.000,47.175){\\Bempty}\n    \\put(24.000,45.680){\\Bempty}\\put(26.000,44.200){\\Bempty}\n    \\put(28.000,42.734){\\Bempty}\\put(30.000,41.278){\\Bempty}\n    \\put(32.000,39.832){\\Bempty}\\put(34.000,38.394){\\Bempty}\n    \\put(36.000,36.962){\\Bempty}\\put(38.000,35.537){\\Bempty}\n    \\put(40.000,34.116){\\Bempty}\\put(42.000,32.700){\\Bempty}\n    \\put(44.000,31.286){\\Bempty}\\put(46.000,29.874){\\Bempty}\n    \\put(48.000,28.465){\\Bempty}\\put(50.000,27.056){\\Bempty}\n    \\put(52.000,25.647){\\Bempty}\\put(54.000,24.236){\\Bempty}\n    \\put(56.000,22.825){\\Bempty}\\put(58.000,21.408){\\Bempty}\n    \\put(60.000,19.981){\\Bempty}\\put(62.000,18.568){\\Bempty}\n    \\put(64.000,17.176){\\Bempty}\\put(66.000,15.809){\\Bempty}\n    \\put(68.000,14.467){\\Bempty}\\put(70.000,13.154){\\Bempty}\n    \\put(72.000,11.871){\\Bempty}\\put(74.000,10.622){\\Bempty}\n    \\put(76.000,9.410){\\Bempty}\\put(78.000,8.238){\\Bempty}\n    \\put(80.000,7.111){\\Bempty}\\put(82.000,6.033){\\Bempty}\n    \\put(84.000,5.010){\\Bempty}\\put(86.000,4.048){\\Bempty}\n    \\put(88.000,3.155){\\Bempty}\\put(90.000,2.340){\\Bempty}\n    \\put(92.000,1.614){\\Bempty}\\put(94.000,0.992){\\Bempty}\n    \\put(96.000,0.493){\\Bempty}\\put(98.000,0.145){\\Bempty}\n    \\put(100.000,0.000){\\Bempty}\n % n =  3:\n    \\put(000,000){\\color{brown}\n        %%\\qbezier(0.000,66.667)(0.358,65.919)(2.000,64.146)\n        %%\\qbezier(2.000,64.146)(2.887,63.190)(4.000,62.129)\n        %%\\qbezier(4.000,62.129)(4.934,61.239)(6.000,60.303)\n        %%\\qbezier(6.000,60.303)(6.953,59.465)(8.000,58.602)\n        %%\\qbezier(8.000,58.602)(8.964,57.807)(10.000,56.995)\n        %%\\qbezier(10.000,56.995)(10.971,56.235)(12.000,55.464)\n        %%\\qbezier(12.000,55.464)(12.976,54.733)(14.000,53.996)\n        %%\\qbezier(14.000,53.996)(14.979,53.291)(16.000,52.582)\n        %%\\qbezier(16.000,52.582)(16.982,51.900)(18.000,51.216)\n        %%\\qbezier(18.000,51.216)(18.984,50.556)(20.000,49.894)\n        %%\\qbezier(20.000,49.894)(20.985,49.252)(22.000,48.610)\n        %%\\qbezier(22.000,48.610)(22.987,47.986)(24.000,47.363)\n        %%\\qbezier(24.000,47.363)(24.988,46.755)(26.000,46.148)\n        %%\\qbezier(26.000,46.148)(26.989,45.555)(28.000,44.964)\n        %%\\qbezier(28.000,44.964)(28.990,44.386)(30.000,43.809)\n        %%\\qbezier(30.000,43.809)(30.991,43.244)(32.000,42.681)\n        %%\\qbezier(32.000,42.681)(32.991,42.129)(34.000,41.579)\n        %%\\qbezier(34.000,41.579)(34.992,41.039)(36.000,40.501)\n        %%\\qbezier(36.000,40.501)(36.992,39.972)(38.000,39.446)\n        %%\\qbezier(38.000,39.446)(38.993,38.928)(40.000,38.414)\n        %%\\qbezier(40.000,38.414)(40.993,37.906)(42.000,37.402)\n        %%\\qbezier(42.000,37.402)(42.994,36.905)(44.000,36.411)\n        %%\\qbezier(44.000,36.411)(44.994,35.924)(46.000,35.440)\n        %%\\qbezier(46.000,35.440)(46.994,34.962)(48.000,34.488)\n        %%\\qbezier(48.000,34.488)(48.995,34.019)(50.000,33.554)\n        %%\\qbezier(50.000,33.554)(50.995,33.093)(52.000,32.637)\n        %%\\qbezier(52.000,32.637)(52.995,32.186)(54.000,31.738)\n        %%\\qbezier(54.000,31.738)(54.996,31.295)(56.000,30.856)\n        %%\\qbezier(56.000,30.856)(56.996,30.421)(58.000,29.990)\n        %%\\qbezier(58.000,29.990)(58.996,29.563)(60.000,29.140)\n        %%\\qbezier(60.000,29.140)(60.996,28.720)(62.000,28.305)\n        %%\\qbezier(62.000,28.305)(62.996,27.893)(64.000,27.486)\n        %%\\qbezier(64.000,27.486)(64.997,27.081)(66.000,26.681)\n        %%\\qbezier(66.000,26.681)(66.997,26.284)(68.000,25.891)\n        %%\\qbezier(68.000,25.891)(68.997,25.501)(70.000,25.115)\n        %%\\qbezier(70.000,25.115)(70.997,24.732)(72.000,24.353)\n        %%\\qbezier(72.000,24.353)(72.997,23.977)(74.000,23.605)\n        %%\\qbezier(74.000,23.605)(74.997,23.235)(76.000,22.870)\n        %%\\qbezier(76.000,22.870)(76.997,22.507)(78.000,22.149)\n        %%\\qbezier(78.000,22.149)(78.998,21.792)(80.000,21.441)\n        %%\\qbezier(80.000,21.441)(80.998,21.091)(82.000,20.745)\n        %%\\qbezier(82.000,20.745)(82.998,20.401)(84.000,20.063)\n        %%\\qbezier(84.000,20.063)(84.998,19.725)(86.000,19.392)\n        %%\\qbezier(86.000,19.392)(86.998,19.061)(88.000,18.735)\n        %%\\qbezier(88.000,18.735)(88.998,18.409)(90.000,18.089)\n        %%\\qbezier(90.000,18.089)(90.998,17.770)(92.000,17.455)\n        %%\\qbezier(92.000,17.455)(92.998,17.142)(94.000,16.834)\n        %%\\qbezier(94.000,16.834)(94.998,16.527)(96.000,16.224)\n        %%\\qbezier(96.000,16.224)(96.999,15.923)(98.000,15.626)\n        %%\\qbezier(98.000,15.626)(100.000,15.034)(100.000,15.040)\n        \\put(0.000,66.667){\\Bbox}\\put(2.000,64.146){\\Bbox}\n        \\put(4.000,62.129){\\Bbox}\\put(6.000,60.303){\\Bbox}\n        \\put(8.000,58.602){\\Bbox}\\put(10.000,56.995){\\Bbox}\n        \\put(12.000,55.464){\\Bbox}\\put(14.000,53.996){\\Bbox}\n        \\put(16.000,52.582){\\Bbox}\\put(18.000,51.216){\\Bbox}\n        \\put(20.000,49.894){\\Bbox}\\put(22.000,48.610){\\Bbox}\n        \\put(24.000,47.363){\\Bbox}\\put(26.000,46.148){\\Bbox}\n        \\put(28.000,44.964){\\Bbox}\\put(30.000,43.809){\\Bbox}\n        \\put(32.000,42.681){\\Bbox}\\put(34.000,41.579){\\Bbox}\n        \\put(36.000,40.501){\\Bbox}\\put(38.000,39.446){\\Bbox}\n        \\put(40.000,38.414){\\Bbox}\\put(42.000,37.402){\\Bbox}\n        \\put(44.000,36.411){\\Bbox}\\put(46.000,35.440){\\Bbox}\n        \\put(48.000,34.488){\\Bbox}\\put(50.000,33.554){\\Bbox}\n        \\put(52.000,32.637){\\Bbox}\\put(54.000,31.738){\\Bbox}\n        \\put(56.000,30.856){\\Bbox}\\put(58.000,29.990){\\Bbox}\n        \\put(60.000,29.140){\\Bbox}\\put(62.000,28.305){\\Bbox}\n        \\put(64.000,27.486){\\Bbox}\\put(66.000,26.681){\\Bbox}\n        \\put(68.000,25.891){\\Bbox}\\put(70.000,25.115){\\Bbox}\n        \\put(72.000,24.353){\\Bbox}\\put(74.000,23.605){\\Bbox}\n        \\put(76.000,22.870){\\Bbox}\\put(78.000,22.149){\\Bbox}\n        \\put(80.000,21.441){\\Bbox}\\put(82.000,20.745){\\Bbox}\n        \\put(84.000,20.063){\\Bbox}\\put(86.000,19.392){\\Bbox}\n        \\put(88.000,18.735){\\Bbox}\\put(90.000,18.089){\\Bbox}\n        \\put(92.000,17.455){\\Bbox}\\put(94.000,16.834){\\Bbox}\n        \\put(96.000,16.224){\\Bbox}\\put(98.000,15.626){\\Bbox}\n        \\put(100.000,15.040){\\Bbox}\n    \\color{black}\n        \\put(0.000,66.667){\\Bfull}\\put(2.000,62.129){\\Bfull}\n        \\put(4.000,58.602){\\Bfull}\\put(6.000,55.464){\\Bfull}\n        \\put(8.000,52.582){\\Bfull}\\put(10.000,49.894){\\Bfull}\n        \\put(12.000,47.363){\\Bfull}\\put(14.000,44.964){\\Bfull}\n        \\put(16.000,42.681){\\Bfull}\\put(18.000,40.501){\\Bfull}\n        \\put(20.000,38.414){\\Bfull}\\put(22.000,36.411){\\Bfull}\n        \\put(24.000,34.488){\\Bfull}\\put(26.000,32.637){\\Bfull}\n        \\put(28.000,30.856){\\Bfull}\\put(30.000,29.140){\\Bfull}\n        \\put(32.000,27.486){\\Bfull}\\put(34.000,25.891){\\Bfull}\n        \\put(36.000,24.353){\\Bfull}\\put(38.000,22.870){\\Bfull}\n        \\put(40.000,21.441){\\Bfull}\\put(42.000,20.063){\\Bfull}\n        \\put(44.000,18.735){\\Bfull}\\put(46.000,17.455){\\Bfull}\n        \\put(48.000,16.224){\\Bfull}\\put(50.000,15.040){\\Bfull}\n        \\put(52.000,13.902){\\Bfull}\\put(54.000,12.810){\\Bfull}\n        \\put(56.000,11.762){\\Bfull}\\put(58.000,10.759){\\Bfull}\n        \\put(60.000,9.800){\\Bfull}\\put(62.000,8.884){\\Bfull}\n        \\put(64.000,8.012){\\Bfull}\\put(66.000,7.184){\\Bfull}\n        \\put(68.000,6.399){\\Bfull}\\put(70.000,5.657){\\Bfull}\n        \\put(72.000,4.958){\\Bfull}\\put(74.000,4.303){\\Bfull}\n        \\put(76.000,3.692){\\Bfull}\\put(78.000,3.125){\\Bfull}\n        \\put(80.000,2.602){\\Bfull}\\put(82.000,2.125){\\Bfull}\n        \\put(84.000,1.693){\\Bfull}\\put(86.000,1.308){\\Bfull}\n        \\put(88.000,0.970){\\Bfull}\\put(90.000,0.680){\\Bfull}\n        \\put(92.000,0.440){\\Bfull}\\put(94.000,0.250){\\Bfull}\n        \\put(96.000,0.113){\\Bfull}\\put(98.000,0.028){\\Bfull}\n        \\put(100.000,0.000){\\Bfull}\n    \\color{green}\n        \\qbezier(0.000,66.667)(1.000,65.934)(2.000,65.202)\n        \\qbezier(2.000,65.202)(2.966,64.494)(4.000,63.736)\n        \\qbezier(4.000,63.736)(4.316,63.505)(6.000,62.271)\n        \\qbezier(6.000,62.271)(7.921,60.864)(8.000,60.806)\n        \\qbezier(8.000,60.806)(9.000,60.074)(10.000,59.341)\n        \\qbezier(10.000,59.341)(11.146,58.502)(12.000,57.876)\n        \\qbezier(12.000,57.876)(13.000,57.143)(14.000,56.411)\n        \\qbezier(14.000,56.411)(14.809,55.819)(16.000,54.946)\n        \\qbezier(16.000,54.946)(17.001,54.212)(18.000,53.481)\n        \\qbezier(18.000,53.481)(19.000,52.748)(20.000,52.016)\n        \\qbezier(20.000,52.016)(20.423,51.705)(22.000,50.551)\n        \\qbezier(22.000,50.551)(22.004,50.547)(24.000,49.085)\n        \\qbezier(24.000,49.085)(25.000,48.353)(26.000,47.620)\n        \\qbezier(26.000,47.620)(27.917,46.216)(28.000,46.155)\n        \\qbezier(28.000,46.155)(29.000,45.423)(30.000,44.690)\n        \\qbezier(30.000,44.690)(30.883,44.043)(32.000,43.225)\n        \\qbezier(32.000,43.225)(32.721,42.697)(34.000,41.760)\n        \\qbezier(34.000,41.760)(35.000,41.027)(36.000,40.295)\n        \\qbezier(36.000,40.295)(37.000,39.562)(38.000,38.830)\n        \\qbezier(38.000,38.830)(39.000,38.097)(40.000,37.365)\n        \\qbezier(40.000,37.365)(41.000,36.632)(42.000,35.899)\n        \\qbezier(42.000,35.899)(43.179,35.036)(44.000,34.434)\n        \\qbezier(44.000,34.434)(44.474,34.087)(46.000,32.969)\n        \\qbezier(46.000,32.969)(47.093,32.169)(48.000,31.504)\n        \\qbezier(48.000,31.504)(48.568,31.088)(50.000,30.039)\n        \\qbezier(50.000,30.039)(50.088,29.974)(52.000,28.574)\n        \\qbezier(52.000,28.574)(53.965,27.134)(54.000,27.109)\n        \\qbezier(54.000,27.109)(55.000,26.376)(56.000,25.644)\n        \\qbezier(56.000,25.644)(57.208,24.759)(58.000,24.179)\n        \\qbezier(58.000,24.179)(58.582,23.752)(60.000,22.713)\n        \\qbezier(60.000,22.713)(61.000,21.981)(62.000,21.248)\n        \\qbezier(62.000,21.248)(63.000,20.516)(64.000,19.783)\n        \\qbezier(64.000,19.783)(64.399,19.491)(66.000,18.318)\n        \\qbezier(66.000,18.318)(67.798,17.001)(68.000,16.853)\n        \\qbezier(68.000,16.853)(68.054,16.814)(70.000,15.388)\n        \\qbezier(70.000,15.388)(71.000,14.655)(72.000,13.923)\n        \\qbezier(72.000,13.923)(73.000,13.190)(74.000,12.458)\n        \\qbezier(74.000,12.458)(75.048,11.690)(76.000,10.993)\n        \\qbezier(76.000,10.993)(77.510,9.887)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.013,8.813)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.022,7.457)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.014,6.195)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.006,5.022)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.007,3.938)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.027,2.948)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.028,2.081)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.013,1.342)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.018,0.732)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.029,0.277)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.094,0.002)(100.000,0.000)\n        \\put(0.000,66.667){\\Bbox}\\put(2.000,65.202){\\Bbox}\n        \\put(4.000,63.736){\\Bbox}\\put(6.000,62.271){\\Bbox}\n        \\put(8.000,60.806){\\Bbox}\\put(10.000,59.341){\\Bbox}\n        \\put(12.000,57.876){\\Bbox}\\put(14.000,56.411){\\Bbox}\n        \\put(16.000,54.946){\\Bbox}\\put(18.000,53.481){\\Bbox}\n        \\put(20.000,52.016){\\Bbox}\\put(22.000,50.550){\\Bbox}\n        \\put(24.000,49.085){\\Bbox}\\put(26.000,47.620){\\Bbox}\n        \\put(28.000,46.155){\\Bbox}\\put(30.000,44.690){\\Bbox}\n        \\put(32.000,43.225){\\Bbox}\\put(34.000,41.760){\\Bbox}\n        \\put(36.000,40.295){\\Bbox}\\put(38.000,38.830){\\Bbox}\n        \\put(40.000,37.365){\\Bbox}\\put(42.000,35.899){\\Bbox}\n        \\put(44.000,34.434){\\Bbox}\\put(46.000,32.969){\\Bbox}\n        \\put(48.000,31.504){\\Bbox}\\put(50.000,30.039){\\Bbox}\n        \\put(52.000,28.574){\\Bbox}\\put(54.000,27.109){\\Bbox}\n        \\put(56.000,25.644){\\Bbox}\\put(58.000,24.179){\\Bbox}\n        \\put(60.000,22.713){\\Bbox}\\put(62.000,21.248){\\Bbox}\n        \\put(64.000,19.783){\\Bbox}\\put(66.000,18.318){\\Bbox}\n        \\put(68.000,16.853){\\Bbox}\\put(70.000,15.388){\\Bbox}\n        \\put(72.000,13.923){\\Bbox}\\put(74.000,12.458){\\Bbox}\n        \\put(76.000,10.993){\\Bbox}\\put(78.000,9.537){\\Bbox}\n        \\put(80.000,8.147){\\Bbox}\\put(82.000,6.838){\\Bbox}\n        \\put(84.000,5.615){\\Bbox}\\put(86.000,4.484){\\Bbox}\n        \\put(88.000,3.451){\\Bbox}\\put(90.000,2.527){\\Bbox}\n        \\put(92.000,1.719){\\Bbox}\\put(94.000,1.041){\\Bbox}\n        \\put(96.000,0.509){\\Bbox}\\put(98.000,0.147){\\Bbox}\n        \\put(100.000,0.000){\\Bbox}\n    \\color{red}\n        \\qbezier(0.000,66.667)(0.351,65.933)(2.000,64.133)\n        \\qbezier(2.000,64.133)(2.879,63.173)(4.000,62.080)\n        \\qbezier(4.000,62.080)(4.927,61.176)(6.000,60.200)\n        \\qbezier(6.000,60.200)(6.947,59.339)(8.000,58.429)\n        \\qbezier(8.000,58.429)(8.958,57.601)(10.000,56.736)\n        \\qbezier(10.000,56.736)(10.965,55.935)(12.000,55.103)\n        \\qbezier(12.000,55.103)(12.969,54.325)(14.000,53.519)\n        \\qbezier(14.000,53.519)(14.972,52.759)(16.000,51.976)\n        \\qbezier(16.000,51.976)(16.975,51.232)(18.000,50.466)\n        \\qbezier(18.000,50.466)(18.977,49.737)(20.000,48.987)\n        \\qbezier(20.000,48.987)(20.978,48.269)(22.000,47.532)\n        \\qbezier(22.000,47.532)(22.979,46.826)(24.000,46.101)\n        \\qbezier(24.000,46.101)(24.980,45.404)(26.000,44.688)\n        \\qbezier(26.000,44.688)(26.980,44.001)(28.000,43.294)\n        \\qbezier(28.000,43.294)(28.980,42.614)(30.000,41.915)\n        \\qbezier(30.000,41.915)(30.980,41.243)(32.000,40.550)\n        \\qbezier(32.000,40.550)(32.980,39.884)(34.000,39.197)\n        \\qbezier(34.000,39.197)(34.979,38.538)(36.000,37.856)\n        \\qbezier(36.000,37.856)(36.978,37.202)(38.000,36.524)\n        \\qbezier(38.000,36.524)(38.976,35.876)(40.000,35.200)\n        \\qbezier(40.000,35.200)(40.973,34.558)(42.000,33.883)\n        \\qbezier(42.000,33.883)(42.969,33.247)(44.000,32.573)\n        \\qbezier(44.000,32.573)(44.963,31.944)(46.000,31.268)\n        \\qbezier(46.000,31.268)(46.951,30.649)(48.000,29.967)\n        \\qbezier(48.000,29.967)(48.929,29.364)(50.000,28.670)\n        \\qbezier(50.000,28.670)(50.868,28.107)(52.000,27.374)\n        \\qbezier(52.000,27.374)(52.225,27.228)(54.000,26.079)\n        \\qbezier(54.000,26.079)(55.220,25.288)(56.000,24.783)\n        \\qbezier(56.000,24.783)(57.104,24.068)(58.000,23.486)\n        \\qbezier(58.000,23.486)(59.073,22.790)(60.000,22.186)\n        \\qbezier(60.000,22.186)(61.060,21.496)(62.000,20.881)\n        \\qbezier(62.000,20.881)(63.055,20.190)(64.000,19.568)\n        \\qbezier(64.000,19.568)(65.055,18.873)(66.000,18.245)\n        \\qbezier(66.000,18.245)(67.061,17.541)(68.000,16.909)\n        \\qbezier(68.000,16.909)(69.077,16.184)(70.000,15.552)\n        \\qbezier(70.000,15.552)(71.138,14.771)(72.000,14.161)\n        \\qbezier(72.000,14.161)(73.000,13.350)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.009,11.746)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.010,10.244)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.010,8.815)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.099,0.001)(100.000,0.000)\n    \\color{blue}\n        \\qbezier(0.000,66.667)(0.362,65.915)(2.000,64.147)\n        \\qbezier(2.000,64.147)(2.887,63.189)(4.000,62.129)\n        \\qbezier(4.000,62.129)(4.934,61.239)(6.000,60.303)\n        \\qbezier(6.000,60.303)(6.951,59.467)(8.000,58.602)\n        \\qbezier(8.000,58.602)(8.964,57.807)(10.000,56.995)\n        \\qbezier(10.000,56.995)(10.971,56.235)(12.000,55.464)\n        \\qbezier(12.000,55.464)(12.976,54.733)(14.000,53.996)\n        \\qbezier(14.000,53.996)(14.971,53.297)(16.000,52.582)\n        \\qbezier(16.000,52.582)(16.043,52.552)(18.000,51.193)\n        \\qbezier(18.000,51.193)(19.752,49.977)(20.000,49.804)\n        \\qbezier(20.000,49.804)(21.000,49.110)(22.000,48.415)\n        \\qbezier(22.000,48.415)(23.000,47.721)(24.000,47.026)\n        \\qbezier(24.000,47.026)(25.790,45.784)(26.000,45.637)\n        \\qbezier(26.000,45.637)(26.082,45.581)(28.000,44.249)\n        \\qbezier(28.000,44.249)(29.644,43.107)(30.000,42.860)\n        \\qbezier(30.000,42.860)(31.000,42.165)(32.000,41.471)\n        \\qbezier(32.000,41.471)(33.000,40.776)(34.000,40.082)\n        \\qbezier(34.000,40.082)(35.000,39.387)(36.000,38.693)\n        \\qbezier(36.000,38.693)(37.023,37.982)(38.000,37.304)\n        \\qbezier(38.000,37.304)(38.481,36.970)(40.000,35.915)\n        \\qbezier(40.000,35.915)(41.000,35.221)(42.000,34.526)\n        \\qbezier(42.000,34.526)(43.530,33.464)(44.000,33.137)\n        \\qbezier(44.000,33.137)(45.000,32.443)(46.000,31.749)\n        \\qbezier(46.000,31.749)(46.241,31.581)(48.000,30.360)\n        \\qbezier(48.000,30.360)(49.000,29.665)(50.000,28.971)\n        \\qbezier(50.000,28.971)(50.060,28.929)(52.000,27.582)\n        \\qbezier(52.000,27.582)(53.000,26.887)(54.000,26.193)\n        \\qbezier(54.000,26.193)(55.000,25.499)(56.000,24.804)\n        \\qbezier(56.000,24.804)(57.000,24.110)(58.000,23.415)\n        \\qbezier(58.000,23.415)(59.408,22.438)(60.000,22.026)\n        \\qbezier(60.000,22.026)(61.000,21.332)(62.000,20.637)\n        \\qbezier(62.000,20.637)(63.000,19.943)(64.000,19.249)\n        \\qbezier(64.000,19.249)(65.050,18.520)(66.000,17.860)\n        \\qbezier(66.000,17.860)(66.346,17.619)(68.000,16.471)\n        \\qbezier(68.000,16.471)(69.847,15.188)(70.000,15.082)\n        \\qbezier(70.000,15.082)(71.000,14.388)(72.000,13.693)\n        \\qbezier(72.000,13.693)(73.000,12.999)(74.000,12.304)\n        \\qbezier(74.000,12.304)(75.000,11.610)(76.000,10.915)\n        \\qbezier(76.000,10.915)(77.000,10.221)(78.000,9.526)\n        \\qbezier(78.000,9.526)(79.501,8.484)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.005,7.468)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.019,6.192)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.025,5.011)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.014,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.008,2.957)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.010,2.088)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.037,1.333)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.041,0.726)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.029,0.277)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.078,0.004)(100.000,0.000)\n        \\put(0.000,66.667){\\Bplus}\\put(2.000,64.147){\\Bplus}\n        \\put(4.000,62.129){\\Bplus}\\put(6.000,60.303){\\Bplus}\n        \\put(8.000,58.602){\\Bplus}\\put(10.000,56.995){\\Bplus}\n        \\put(12.000,55.464){\\Bplus}\\put(14.000,53.996){\\Bplus}\n        \\put(16.000,52.582){\\Bplus}\\put(18.000,51.193){\\Bplus}\n        \\put(20.000,49.804){\\Bplus}\\put(22.000,48.415){\\Bplus}\n        \\put(24.000,47.026){\\Bplus}\\put(26.000,45.637){\\Bplus}\n        \\put(28.000,44.249){\\Bplus}\\put(30.000,42.860){\\Bplus}\n        \\put(32.000,41.471){\\Bplus}\\put(34.000,40.082){\\Bplus}\n        \\put(36.000,38.693){\\Bplus}\\put(38.000,37.304){\\Bplus}\n        \\put(40.000,35.915){\\Bplus}\\put(42.000,34.526){\\Bplus}\n        \\put(44.000,33.137){\\Bplus}\\put(46.000,31.749){\\Bplus}\n        \\put(48.000,30.360){\\Bplus}\\put(50.000,28.971){\\Bplus}\n        \\put(52.000,27.582){\\Bplus}\\put(54.000,26.193){\\Bplus}\n        \\put(56.000,24.804){\\Bplus}\\put(58.000,23.415){\\Bplus}\n        \\put(60.000,22.026){\\Bplus}\\put(62.000,20.637){\\Bplus}\n        \\put(64.000,19.249){\\Bplus}\\put(66.000,17.860){\\Bplus}\n        \\put(68.000,16.471){\\Bplus}\\put(70.000,15.082){\\Bplus}\n        \\put(72.000,13.693){\\Bplus}\\put(74.000,12.304){\\Bplus}\n        \\put(76.000,10.915){\\Bplus}\\put(78.000,9.526){\\Bplus}\n        \\put(80.000,8.147){\\Bplus}\\put(82.000,6.838){\\Bplus}\n        \\put(84.000,5.615){\\Bplus}\\put(86.000,4.484){\\Bplus}\n        \\put(88.000,3.451){\\Bplus}\\put(90.000,2.527){\\Bplus}\n        \\put(92.000,1.719){\\Bplus}\\put(94.000,1.041){\\Bplus}\n        \\put(96.000,0.509){\\Bplus}\\put(98.000,0.147){\\Bplus}\n        \\put(100.000,0.000){\\Bplus}\n    \\color{cyan}\n        \\qbezier(0.000,66.667)(0.351,65.933)(2.000,64.133)\n        \\qbezier(2.000,64.133)(2.879,63.173)(4.000,62.080)\n        \\qbezier(4.000,62.080)(4.927,61.176)(6.000,60.200)\n        \\qbezier(6.000,60.200)(6.947,59.339)(8.000,58.429)\n        \\qbezier(8.000,58.429)(8.958,57.601)(10.000,56.736)\n        \\qbezier(10.000,56.736)(10.965,55.935)(12.000,55.103)\n        \\qbezier(12.000,55.103)(12.969,54.325)(14.000,53.519)\n        \\qbezier(14.000,53.519)(14.972,52.759)(16.000,51.976)\n        \\qbezier(16.000,51.976)(16.975,51.232)(18.000,50.466)\n        \\qbezier(18.000,50.466)(18.977,49.737)(20.000,48.987)\n        \\qbezier(20.000,48.987)(20.978,48.269)(22.000,47.532)\n        \\qbezier(22.000,47.532)(22.979,46.826)(24.000,46.101)\n        \\qbezier(24.000,46.101)(24.980,45.404)(26.000,44.689)\n        \\qbezier(26.000,44.689)(26.980,44.001)(28.000,43.294)\n        \\qbezier(28.000,43.294)(28.980,42.614)(30.000,41.915)\n        \\qbezier(30.000,41.915)(30.980,41.243)(32.000,40.550)\n        \\qbezier(32.000,40.550)(32.980,39.885)(34.000,39.197)\n        \\qbezier(34.000,39.197)(34.979,38.538)(36.000,37.856)\n        \\qbezier(36.000,37.856)(36.978,37.202)(38.000,36.524)\n        \\qbezier(38.000,36.524)(38.976,35.876)(40.000,35.200)\n        \\qbezier(40.000,35.200)(40.973,34.558)(42.000,33.883)\n        \\qbezier(42.000,33.883)(42.969,33.247)(44.000,32.573)\n        \\qbezier(44.000,32.573)(44.963,31.944)(46.000,31.268)\n        \\qbezier(46.000,31.268)(46.951,30.649)(48.000,29.967)\n        \\qbezier(48.000,29.967)(48.929,29.364)(50.000,28.670)\n        \\qbezier(50.000,28.670)(50.868,28.107)(52.000,27.374)\n        \\qbezier(52.000,27.374)(52.225,27.228)(54.000,26.079)\n        \\qbezier(54.000,26.079)(55.220,25.288)(56.000,24.783)\n        \\qbezier(56.000,24.783)(56.449,24.492)(58.000,23.415)\n        \\qbezier(58.000,23.415)(59.000,22.721)(60.000,22.026)\n        \\qbezier(60.000,22.026)(61.000,21.332)(62.000,20.637)\n        \\qbezier(62.000,20.637)(63.000,19.943)(64.000,19.249)\n        \\qbezier(64.000,19.249)(65.000,18.554)(66.000,17.860)\n        \\qbezier(66.000,17.860)(67.000,17.165)(68.000,16.471)\n        \\qbezier(68.000,16.471)(69.000,15.776)(70.000,15.082)\n        \\qbezier(70.000,15.082)(71.000,14.387)(72.000,13.693)\n        \\qbezier(72.000,13.693)(73.000,12.999)(74.000,12.304)\n        \\qbezier(74.000,12.304)(75.000,11.610)(76.000,10.915)\n        \\qbezier(76.000,10.915)(77.000,10.221)(78.000,9.526)\n        \\qbezier(78.000,9.526)(79.514,8.475)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.097,0.002)(100.000,0.000)\n        \\put(0.000,66.667){\\Bfull}\\put(2.000,64.133){\\Bfull}\n        \\put(4.000,62.080){\\Bfull}\\put(6.000,60.200){\\Bfull}\n        \\put(8.000,58.429){\\Bfull}\\put(10.000,56.736){\\Bfull}\n        \\put(12.000,55.103){\\Bfull}\\put(14.000,53.519){\\Bfull}\n        \\put(16.000,51.976){\\Bfull}\\put(18.000,50.466){\\Bfull}\n        \\put(20.000,48.987){\\Bfull}\\put(22.000,47.532){\\Bfull}\n        \\put(24.000,46.101){\\Bfull}\\put(26.000,44.689){\\Bfull}\n        \\put(28.000,43.294){\\Bfull}\\put(30.000,41.915){\\Bfull}\n        \\put(32.000,40.550){\\Bfull}\\put(34.000,39.197){\\Bfull}\n        \\put(36.000,37.856){\\Bfull}\\put(38.000,36.524){\\Bfull}\n        \\put(40.000,35.200){\\Bfull}\\put(42.000,33.883){\\Bfull}\n        \\put(44.000,32.573){\\Bfull}\\put(46.000,31.268){\\Bfull}\n        \\put(48.000,29.967){\\Bfull}\\put(50.000,28.670){\\Bfull}\n        \\put(52.000,27.374){\\Bfull}\\put(54.000,26.079){\\Bfull}\n        \\put(56.000,24.783){\\Bfull}\\put(58.000,23.415){\\Bfull}\n        \\put(60.000,22.026){\\Bfull}\\put(62.000,20.637){\\Bfull}\n        \\put(64.000,19.249){\\Bfull}\\put(66.000,17.860){\\Bfull}\n        \\put(68.000,16.471){\\Bfull}\\put(70.000,15.082){\\Bfull}\n        \\put(72.000,13.693){\\Bfull}\\put(74.000,12.304){\\Bfull}\n        \\put(76.000,10.915){\\Bfull}\\put(78.000,9.526){\\Bfull}\n        \\put(80.000,8.147){\\Bfull}\\put(82.000,6.838){\\Bfull}\n        \\put(84.000,5.615){\\Bfull}\\put(86.000,4.484){\\Bfull}\n        \\put(88.000,3.451){\\Bfull}\\put(90.000,2.527){\\Bfull}\n        \\put(92.000,1.719){\\Bfull}\\put(94.000,1.041){\\Bfull}\n        \\put(96.000,0.509){\\Bfull}\\put(98.000,0.147){\\Bfull}\n        \\put(100.000,0.000){\\Bfull}\n    }\n}\n\\caption{Bounds for $q = 2$ and $n = 3$.}\n\\label{fig:q=2,n=3}\n\\end{figure*}\n\n\\begin{figure*}[hbt]\n%% q = 2, n =  4:\n\\Plot{%\n    \\put(035,095){\n\t\\put(000,000){\\Legend}\n    }\n    \\put(000,000){\\color{brown}\n        %%\\qbezier(0.000,75.000)(0.358,74.225)(2.000,72.334)\n        %%\\qbezier(2.000,72.334)(2.887,71.312)(4.000,70.171)\n        %%\\qbezier(4.000,70.171)(4.934,69.213)(6.000,68.201)\n        %%\\qbezier(6.000,68.201)(6.954,67.294)(8.000,66.356)\n        %%\\qbezier(8.000,66.356)(8.964,65.491)(10.000,64.606)\n        %%\\qbezier(10.000,64.606)(10.971,63.776)(12.000,62.933)\n        %%\\qbezier(12.000,62.933)(12.976,62.132)(14.000,61.323)\n        %%\\qbezier(14.000,61.323)(14.979,60.549)(16.000,59.769)\n        %%\\qbezier(16.000,59.769)(16.982,59.018)(18.000,58.263)\n        %%\\qbezier(18.000,58.263)(18.984,57.534)(20.000,56.802)\n        %%\\qbezier(20.000,56.802)(20.986,56.091)(22.000,55.380)\n        %%\\qbezier(22.000,55.380)(22.987,54.687)(24.000,53.995)\n        %%\\qbezier(24.000,53.995)(24.988,53.319)(26.000,52.644)\n        %%\\qbezier(26.000,52.644)(26.989,51.983)(28.000,51.324)\n        %%\\qbezier(28.000,51.324)(28.990,50.678)(30.000,50.034)\n        %%\\qbezier(30.000,50.034)(30.991,49.402)(32.000,48.772)\n        %%\\qbezier(32.000,48.772)(32.992,48.153)(34.000,47.537)\n        %%\\qbezier(34.000,47.537)(34.992,46.930)(36.000,46.327)\n        %%\\qbezier(36.000,46.327)(36.993,45.732)(38.000,45.141)\n        %%\\qbezier(38.000,45.141)(38.993,44.557)(40.000,43.978)\n        %%\\qbezier(40.000,43.978)(40.994,43.405)(42.000,42.837)\n        %%\\qbezier(42.000,42.837)(42.994,42.275)(44.000,41.717)\n        %%\\qbezier(44.000,41.717)(44.995,41.166)(46.000,40.619)\n        %%\\qbezier(46.000,40.619)(46.995,40.077)(48.000,39.540)\n        %%\\qbezier(48.000,39.540)(48.995,39.008)(50.000,38.480)\n        %%\\qbezier(50.000,38.480)(50.995,37.958)(52.000,37.439)\n        %%\\qbezier(52.000,37.439)(52.996,36.926)(54.000,36.417)\n        %%\\qbezier(54.000,36.417)(54.996,35.912)(56.000,35.412)\n        %%\\qbezier(56.000,35.412)(56.996,34.916)(58.000,34.425)\n        %%\\qbezier(58.000,34.425)(58.996,33.938)(60.000,33.455)\n        %%\\qbezier(60.000,33.455)(60.997,32.976)(62.000,32.501)\n        %%\\qbezier(62.000,32.501)(62.997,32.030)(64.000,31.564)\n        %%\\qbezier(64.000,31.564)(64.997,31.101)(66.000,30.643)\n        %%\\qbezier(66.000,30.643)(66.997,30.187)(68.000,29.737)\n        %%\\qbezier(68.000,29.737)(68.997,29.290)(70.000,28.847)\n        %%\\qbezier(70.000,28.847)(70.997,28.407)(72.000,27.972)\n        %%\\qbezier(72.000,27.972)(72.998,27.540)(74.000,27.112)\n        %%\\qbezier(74.000,27.112)(74.998,26.687)(76.000,26.267)\n        %%\\qbezier(76.000,26.267)(76.998,25.849)(78.000,25.436)\n        %%\\qbezier(78.000,25.436)(78.998,25.026)(80.000,24.620)\n        %%\\qbezier(80.000,24.620)(80.998,24.216)(82.000,23.818)\n        %%\\qbezier(82.000,23.818)(82.998,23.421)(84.000,23.030)\n        %%\\qbezier(84.000,23.030)(84.998,22.640)(86.000,22.256)\n        %%\\qbezier(86.000,22.256)(86.999,21.873)(88.000,21.496)\n        %%\\qbezier(88.000,21.496)(88.999,21.120)(90.000,20.749)\n        %%\\qbezier(90.000,20.749)(90.999,20.380)(92.000,20.016)\n        %%\\qbezier(92.000,20.016)(92.999,19.654)(94.000,19.297)\n        %%\\qbezier(94.000,19.297)(94.999,18.941)(96.000,18.591)\n        %%\\qbezier(96.000,18.591)(96.999,18.241)(98.000,17.898)\n        %%\\qbezier(98.000,17.898)(100.000,17.211)(100.000,17.218)\n        \\put(0.000,75.000){\\Bbox}\\put(2.000,72.334){\\Bbox}\n        \\put(4.000,70.171){\\Bbox}\\put(6.000,68.201){\\Bbox}\n        \\put(8.000,66.356){\\Bbox}\\put(10.000,64.606){\\Bbox}\n        \\put(12.000,62.933){\\Bbox}\\put(14.000,61.323){\\Bbox}\n        \\put(16.000,59.769){\\Bbox}\\put(18.000,58.263){\\Bbox}\n        \\put(20.000,56.802){\\Bbox}\\put(22.000,55.380){\\Bbox}\n        \\put(24.000,53.995){\\Bbox}\\put(26.000,52.644){\\Bbox}\n        \\put(28.000,51.324){\\Bbox}\\put(30.000,50.034){\\Bbox}\n        \\put(32.000,48.772){\\Bbox}\\put(34.000,47.537){\\Bbox}\n        \\put(36.000,46.327){\\Bbox}\\put(38.000,45.141){\\Bbox}\n        \\put(40.000,43.978){\\Bbox}\\put(42.000,42.837){\\Bbox}\n        \\put(44.000,41.717){\\Bbox}\\put(46.000,40.619){\\Bbox}\n        \\put(48.000,39.540){\\Bbox}\\put(50.000,38.480){\\Bbox}\n        \\put(52.000,37.439){\\Bbox}\\put(54.000,36.417){\\Bbox}\n        \\put(56.000,35.412){\\Bbox}\\put(58.000,34.425){\\Bbox}\n        \\put(60.000,33.455){\\Bbox}\\put(62.000,32.501){\\Bbox}\n        \\put(64.000,31.564){\\Bbox}\\put(66.000,30.643){\\Bbox}\n        \\put(68.000,29.737){\\Bbox}\\put(70.000,28.847){\\Bbox}\n        \\put(72.000,27.972){\\Bbox}\\put(74.000,27.112){\\Bbox}\n        \\put(76.000,26.267){\\Bbox}\\put(78.000,25.436){\\Bbox}\n        \\put(80.000,24.620){\\Bbox}\\put(82.000,23.818){\\Bbox}\n        \\put(84.000,23.030){\\Bbox}\\put(86.000,22.256){\\Bbox}\n        \\put(88.000,21.496){\\Bbox}\\put(90.000,20.749){\\Bbox}\n        \\put(92.000,20.016){\\Bbox}\\put(94.000,19.297){\\Bbox}\n        \\put(96.000,18.591){\\Bbox}\\put(98.000,17.898){\\Bbox}\n        \\put(100.000,17.218){\\Bbox}\n    \\color{black}\n        \\put(0.000,75.000){\\Bfull}\\put(2.000,70.171){\\Bfull}\n        \\put(4.000,66.356){\\Bfull}\\put(6.000,62.933){\\Bfull}\n        \\put(8.000,59.769){\\Bfull}\\put(10.000,56.802){\\Bfull}\n        \\put(12.000,53.995){\\Bfull}\\put(14.000,51.324){\\Bfull}\n        \\put(16.000,48.772){\\Bfull}\\put(18.000,46.327){\\Bfull}\n        \\put(20.000,43.978){\\Bfull}\\put(22.000,41.717){\\Bfull}\n        \\put(24.000,39.540){\\Bfull}\\put(26.000,37.439){\\Bfull}\n        \\put(28.000,35.412){\\Bfull}\\put(30.000,33.455){\\Bfull}\n        \\put(32.000,31.564){\\Bfull}\\put(34.000,29.737){\\Bfull}\n        \\put(36.000,27.972){\\Bfull}\\put(38.000,26.267){\\Bfull}\n        \\put(40.000,24.620){\\Bfull}\\put(42.000,23.030){\\Bfull}\n        \\put(44.000,21.496){\\Bfull}\\put(46.000,20.016){\\Bfull}\n        \\put(48.000,18.591){\\Bfull}\\put(50.000,17.218){\\Bfull}\n        \\put(52.000,15.898){\\Bfull}\\put(54.000,14.630){\\Bfull}\n        \\put(56.000,13.414){\\Bfull}\\put(58.000,12.249){\\Bfull}\n        \\put(60.000,11.136){\\Bfull}\\put(62.000,10.074){\\Bfull}\n        \\put(64.000,9.063){\\Bfull}\\put(66.000,8.104){\\Bfull}\n        \\put(68.000,7.197){\\Bfull}\\put(70.000,6.341){\\Bfull}\n        \\put(72.000,5.537){\\Bfull}\\put(74.000,4.786){\\Bfull}\n        \\put(76.000,4.088){\\Bfull}\\put(78.000,3.443){\\Bfull}\n        \\put(80.000,2.851){\\Bfull}\\put(82.000,2.314){\\Bfull}\n        \\put(84.000,1.832){\\Bfull}\\put(86.000,1.405){\\Bfull}\n        \\put(88.000,1.034){\\Bfull}\\put(90.000,0.719){\\Bfull}\n        \\put(92.000,0.461){\\Bfull}\\put(94.000,0.259){\\Bfull}\n        \\put(96.000,0.115){\\Bfull}\\put(98.000,0.029){\\Bfull}\n        \\put(100.000,0.000){\\Bfull}\n    \\color{green}\n        \\qbezier(0.000,75.000)(0.889,74.248)(2.000,73.309)\n        \\qbezier(2.000,73.309)(3.480,72.057)(4.000,71.618)\n        \\qbezier(4.000,71.618)(4.317,71.350)(6.000,69.927)\n        \\qbezier(6.000,69.927)(7.539,68.626)(8.000,68.236)\n        \\qbezier(8.000,68.236)(9.000,67.390)(10.000,66.545)\n        \\qbezier(10.000,66.545)(11.000,65.699)(12.000,64.854)\n        \\qbezier(12.000,64.854)(13.000,64.008)(14.000,63.163)\n        \\qbezier(14.000,63.163)(15.000,62.317)(16.000,61.471)\n        \\qbezier(16.000,61.471)(17.000,60.626)(18.000,59.780)\n        \\qbezier(18.000,59.780)(19.000,58.935)(20.000,58.089)\n        \\qbezier(20.000,58.089)(21.058,57.195)(22.000,56.398)\n        \\qbezier(22.000,56.398)(23.386,55.226)(24.000,54.707)\n        \\qbezier(24.000,54.707)(24.858,53.982)(26.000,53.016)\n        \\qbezier(26.000,53.016)(27.000,52.171)(28.000,51.325)\n        \\qbezier(28.000,51.325)(29.000,50.480)(30.000,49.634)\n        \\qbezier(30.000,49.634)(31.000,48.788)(32.000,47.943)\n        \\qbezier(32.000,47.943)(33.000,47.097)(34.000,46.252)\n        \\qbezier(34.000,46.252)(34.785,45.588)(36.000,44.561)\n        \\qbezier(36.000,44.561)(37.000,43.715)(38.000,42.870)\n        \\qbezier(38.000,42.870)(39.094,41.945)(40.000,41.179)\n        \\qbezier(40.000,41.179)(41.000,40.333)(42.000,39.488)\n        \\qbezier(42.000,39.488)(43.259,38.423)(44.000,37.796)\n        \\qbezier(44.000,37.796)(45.000,36.951)(46.000,36.105)\n        \\qbezier(46.000,36.105)(47.000,35.260)(48.000,34.414)\n        \\qbezier(48.000,34.414)(49.000,33.569)(50.000,32.723)\n        \\qbezier(50.000,32.723)(51.531,31.429)(52.000,31.032)\n        \\qbezier(52.000,31.032)(53.000,30.187)(54.000,29.341)\n        \\qbezier(54.000,29.341)(55.000,28.496)(56.000,27.650)\n        \\qbezier(56.000,27.650)(57.000,26.805)(58.000,25.959)\n        \\qbezier(58.000,25.959)(59.000,25.113)(60.000,24.268)\n        \\qbezier(60.000,24.268)(61.000,23.422)(62.000,22.577)\n        \\qbezier(62.000,22.577)(62.911,21.807)(64.000,20.886)\n        \\qbezier(64.000,20.886)(65.543,19.581)(66.000,19.195)\n        \\qbezier(66.000,19.195)(67.000,18.349)(68.000,17.504)\n        \\qbezier(68.000,17.504)(69.445,16.282)(70.000,15.813)\n        \\qbezier(70.000,15.813)(71.153,14.838)(72.000,14.144)\n        \\qbezier(72.000,14.144)(73.005,13.321)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.005,11.749)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.005,10.247)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.021,8.808)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.022,7.457)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.007,6.200)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.006,5.022)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.007,3.938)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.031,2.946)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.033,2.080)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.013,1.342)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.018,0.732)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.029,0.277)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.094,0.002)(100.000,0.000)\n        \\put(0.000,75.000){\\Bbox}\\put(2.000,73.309){\\Bbox}\n        \\put(4.000,71.618){\\Bbox}\\put(6.000,69.927){\\Bbox}\n        \\put(8.000,68.236){\\Bbox}\\put(10.000,66.545){\\Bbox}\n        \\put(12.000,64.854){\\Bbox}\\put(14.000,63.163){\\Bbox}\n        \\put(16.000,61.471){\\Bbox}\\put(18.000,59.780){\\Bbox}\n        \\put(20.000,58.089){\\Bbox}\\put(22.000,56.398){\\Bbox}\n        \\put(24.000,54.707){\\Bbox}\\put(26.000,53.016){\\Bbox}\n        \\put(28.000,51.325){\\Bbox}\\put(30.000,49.634){\\Bbox}\n        \\put(32.000,47.943){\\Bbox}\\put(34.000,46.252){\\Bbox}\n        \\put(36.000,44.561){\\Bbox}\\put(38.000,42.870){\\Bbox}\n        \\put(40.000,41.179){\\Bbox}\\put(42.000,39.488){\\Bbox}\n        \\put(44.000,37.796){\\Bbox}\\put(46.000,36.105){\\Bbox}\n        \\put(48.000,34.414){\\Bbox}\\put(50.000,32.723){\\Bbox}\n        \\put(52.000,31.032){\\Bbox}\\put(54.000,29.341){\\Bbox}\n        \\put(56.000,27.650){\\Bbox}\\put(58.000,25.959){\\Bbox}\n        \\put(60.000,24.268){\\Bbox}\\put(62.000,22.577){\\Bbox}\n        \\put(64.000,20.886){\\Bbox}\\put(66.000,19.195){\\Bbox}\n        \\put(68.000,17.504){\\Bbox}\\put(70.000,15.813){\\Bbox}\n        \\put(72.000,14.144){\\Bbox}\\put(74.000,12.539){\\Bbox}\n        \\put(76.000,11.002){\\Bbox}\\put(78.000,9.537){\\Bbox}\n        \\put(80.000,8.147){\\Bbox}\\put(82.000,6.838){\\Bbox}\n        \\put(84.000,5.615){\\Bbox}\\put(86.000,4.484){\\Bbox}\n        \\put(88.000,3.451){\\Bbox}\\put(90.000,2.527){\\Bbox}\n        \\put(92.000,1.719){\\Bbox}\\put(94.000,1.041){\\Bbox}\n        \\put(96.000,0.509){\\Bbox}\\put(98.000,0.147){\\Bbox}\n        \\put(100.000,0.000){\\Bbox}\n    \\color{red}\n        \\qbezier(0.000,75.000)(0.350,74.242)(2.000,72.319)\n        \\qbezier(2.000,72.319)(2.878,71.295)(4.000,70.117)\n        \\qbezier(4.000,70.117)(4.926,69.144)(6.000,68.086)\n        \\qbezier(6.000,68.086)(6.945,67.154)(8.000,66.162)\n        \\qbezier(8.000,66.162)(8.956,65.262)(10.000,64.314)\n        \\qbezier(10.000,64.314)(10.963,63.439)(12.000,62.524)\n        \\qbezier(12.000,62.524)(12.967,61.670)(14.000,60.780)\n        \\qbezier(14.000,60.780)(14.970,59.945)(16.000,59.075)\n        \\qbezier(16.000,59.075)(16.972,58.254)(18.000,57.402)\n        \\qbezier(18.000,57.402)(18.974,56.594)(20.000,55.755)\n        \\qbezier(20.000,55.755)(20.974,54.959)(22.000,54.131)\n        \\qbezier(22.000,54.131)(22.975,53.345)(24.000,52.527)\n        \\qbezier(24.000,52.527)(24.974,51.750)(26.000,50.940)\n        \\qbezier(26.000,50.940)(26.973,50.171)(28.000,49.367)\n        \\qbezier(28.000,49.367)(28.972,48.606)(30.000,47.806)\n        \\qbezier(30.000,47.806)(30.969,47.053)(32.000,46.256)\n        \\qbezier(32.000,46.256)(32.965,45.511)(34.000,44.715)\n        \\qbezier(34.000,44.715)(34.958,43.979)(36.000,43.180)\n        \\qbezier(36.000,43.180)(36.945,42.457)(38.000,41.651)\n        \\qbezier(38.000,41.651)(38.919,40.950)(40.000,40.126)\n        \\qbezier(40.000,40.126)(40.839,39.487)(42.000,38.603)\n        \\qbezier(42.000,38.603)(43.000,37.842)(44.000,37.081)\n        \\qbezier(44.000,37.081)(45.175,36.187)(46.000,35.558)\n        \\qbezier(46.000,35.558)(47.092,34.726)(48.000,34.033)\n        \\qbezier(48.000,34.033)(49.066,33.219)(50.000,32.503)\n        \\qbezier(50.000,32.503)(51.055,31.695)(52.000,30.967)\n        \\qbezier(52.000,30.967)(53.050,30.158)(54.000,29.421)\n        \\qbezier(54.000,29.421)(55.050,28.607)(56.000,27.864)\n        \\qbezier(56.000,27.864)(57.054,27.039)(58.000,26.289)\n        \\qbezier(58.000,26.289)(59.067,25.444)(60.000,24.691)\n        \\qbezier(60.000,24.691)(61.111,23.796)(62.000,23.058)\n        \\qbezier(62.000,23.058)(63.000,22.117)(64.000,21.177)\n        \\qbezier(64.000,21.177)(65.008,20.234)(66.000,19.332)\n        \\qbezier(66.000,19.332)(67.008,18.417)(68.000,17.544)\n        \\qbezier(68.000,17.544)(69.008,16.657)(70.000,15.813)\n        \\qbezier(70.000,15.813)(71.008,14.956)(72.000,14.144)\n        \\qbezier(72.000,14.144)(73.009,13.318)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.009,11.746)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.010,10.244)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.010,8.815)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.099,0.001)(100.000,0.000)\n    \\color{blue}\n        \\qbezier(0.000,75.000)(0.363,74.219)(2.000,72.334)\n        \\qbezier(2.000,72.334)(2.887,71.312)(4.000,70.171)\n        \\qbezier(4.000,70.171)(4.934,69.214)(6.000,68.201)\n        \\qbezier(6.000,68.201)(6.954,67.294)(8.000,66.356)\n        \\qbezier(8.000,66.356)(8.963,65.493)(10.000,64.606)\n        \\qbezier(10.000,64.606)(10.971,63.776)(12.000,62.933)\n        \\qbezier(12.000,62.933)(12.217,62.754)(14.000,61.305)\n        \\qbezier(14.000,61.305)(15.000,60.492)(16.000,59.679)\n        \\qbezier(16.000,59.679)(16.419,59.338)(18.000,58.052)\n        \\qbezier(18.000,58.052)(19.000,57.239)(20.000,56.426)\n        \\qbezier(20.000,56.426)(21.000,55.613)(22.000,54.800)\n        \\qbezier(22.000,54.800)(23.701,53.417)(24.000,53.174)\n        \\qbezier(24.000,53.174)(24.129,53.069)(26.000,51.547)\n        \\qbezier(26.000,51.547)(27.000,50.734)(28.000,49.921)\n        \\qbezier(28.000,49.921)(29.000,49.108)(30.000,48.295)\n        \\qbezier(30.000,48.295)(31.000,47.482)(32.000,46.668)\n        \\qbezier(32.000,46.668)(33.000,45.855)(34.000,45.042)\n        \\qbezier(34.000,45.042)(35.000,44.229)(36.000,43.416)\n        \\qbezier(36.000,43.416)(37.000,42.603)(38.000,41.790)\n        \\qbezier(38.000,41.790)(39.000,40.976)(40.000,40.163)\n        \\qbezier(40.000,40.163)(41.000,39.350)(42.000,38.537)\n        \\qbezier(42.000,38.537)(42.696,37.971)(44.000,36.911)\n        \\qbezier(44.000,36.911)(45.000,36.098)(46.000,35.285)\n        \\qbezier(46.000,35.285)(47.000,34.471)(48.000,33.658)\n        \\qbezier(48.000,33.658)(49.000,32.845)(50.000,32.032)\n        \\qbezier(50.000,32.032)(51.471,30.836)(52.000,30.406)\n        \\qbezier(52.000,30.406)(53.137,29.482)(54.000,28.779)\n        \\qbezier(54.000,28.779)(55.000,27.966)(56.000,27.153)\n        \\qbezier(56.000,27.153)(57.000,26.340)(58.000,25.527)\n        \\qbezier(58.000,25.527)(58.610,25.031)(60.000,23.901)\n        \\qbezier(60.000,23.901)(61.000,23.088)(62.000,22.274)\n        \\qbezier(62.000,22.274)(63.000,21.461)(64.000,20.648)\n        \\qbezier(64.000,20.648)(65.000,19.835)(66.000,19.022)\n        \\qbezier(66.000,19.022)(67.566,17.749)(68.000,17.396)\n        \\qbezier(68.000,17.396)(68.705,16.822)(70.000,15.769)\n        \\qbezier(70.000,15.769)(71.569,14.494)(72.000,14.143)\n        \\qbezier(72.000,14.143)(73.176,13.186)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.005,11.750)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.005,10.247)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.005,8.819)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.005,7.468)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.026,6.188)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.025,5.012)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.007,3.938)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.008,2.957)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.010,2.088)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.037,1.333)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.041,0.726)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.029,0.277)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.078,0.004)(100.000,0.000)\n        \\put(0.000,75.000){\\Bplus}\\put(2.000,72.334){\\Bplus}\n        \\put(4.000,70.171){\\Bplus}\\put(6.000,68.201){\\Bplus}\n        \\put(8.000,66.356){\\Bplus}\\put(10.000,64.606){\\Bplus}\n        \\put(12.000,62.933){\\Bplus}\\put(14.000,61.305){\\Bplus}\n        \\put(16.000,59.679){\\Bplus}\\put(18.000,58.052){\\Bplus}\n        \\put(20.000,56.426){\\Bplus}\\put(22.000,54.800){\\Bplus}\n        \\put(24.000,53.174){\\Bplus}\\put(26.000,51.547){\\Bplus}\n        \\put(28.000,49.921){\\Bplus}\\put(30.000,48.295){\\Bplus}\n        \\put(32.000,46.668){\\Bplus}\\put(34.000,45.042){\\Bplus}\n        \\put(36.000,43.416){\\Bplus}\\put(38.000,41.790){\\Bplus}\n        \\put(40.000,40.163){\\Bplus}\\put(42.000,38.537){\\Bplus}\n        \\put(44.000,36.911){\\Bplus}\\put(46.000,35.285){\\Bplus}\n        \\put(48.000,33.658){\\Bplus}\\put(50.000,32.032){\\Bplus}\n        \\put(52.000,30.406){\\Bplus}\\put(54.000,28.779){\\Bplus}\n        \\put(56.000,27.153){\\Bplus}\\put(58.000,25.527){\\Bplus}\n        \\put(60.000,23.901){\\Bplus}\\put(62.000,22.274){\\Bplus}\n        \\put(64.000,20.648){\\Bplus}\\put(66.000,19.022){\\Bplus}\n        \\put(68.000,17.396){\\Bplus}\\put(70.000,15.769){\\Bplus}\n        \\put(72.000,14.143){\\Bplus}\\put(74.000,12.539){\\Bplus}\n        \\put(76.000,11.002){\\Bplus}\\put(78.000,9.537){\\Bplus}\n        \\put(80.000,8.147){\\Bplus}\\put(82.000,6.838){\\Bplus}\n        \\put(84.000,5.615){\\Bplus}\\put(86.000,4.484){\\Bplus}\n        \\put(88.000,3.451){\\Bplus}\\put(90.000,2.527){\\Bplus}\n        \\put(92.000,1.719){\\Bplus}\\put(94.000,1.041){\\Bplus}\n        \\put(96.000,0.509){\\Bplus}\\put(98.000,0.147){\\Bplus}\n        \\put(100.000,0.000){\\Bplus}\n    \\color{cyan}\n        \\qbezier(0.000,75.000)(0.350,74.242)(2.000,72.319)\n        \\qbezier(2.000,72.319)(2.878,71.295)(4.000,70.117)\n        \\qbezier(4.000,70.117)(4.926,69.144)(6.000,68.086)\n        \\qbezier(6.000,68.086)(6.945,67.154)(8.000,66.162)\n        \\qbezier(8.000,66.162)(8.956,65.262)(10.000,64.314)\n        \\qbezier(10.000,64.314)(10.963,63.439)(12.000,62.524)\n        \\qbezier(12.000,62.524)(12.967,61.670)(14.000,60.780)\n        \\qbezier(14.000,60.780)(14.970,59.945)(16.000,59.075)\n        \\qbezier(16.000,59.075)(16.972,58.254)(18.000,57.402)\n        \\qbezier(18.000,57.402)(18.974,56.594)(20.000,55.755)\n        \\qbezier(20.000,55.755)(20.974,54.959)(22.000,54.131)\n        \\qbezier(22.000,54.131)(22.975,53.345)(24.000,52.527)\n        \\qbezier(24.000,52.527)(24.974,51.750)(26.000,50.940)\n        \\qbezier(26.000,50.940)(26.973,50.171)(28.000,49.367)\n        \\qbezier(28.000,49.367)(28.972,48.606)(30.000,47.806)\n        \\qbezier(30.000,47.806)(30.969,47.053)(32.000,46.256)\n        \\qbezier(32.000,46.256)(32.965,45.511)(34.000,44.715)\n        \\qbezier(34.000,44.715)(34.958,43.979)(36.000,43.180)\n        \\qbezier(36.000,43.180)(36.945,42.457)(38.000,41.651)\n        \\qbezier(38.000,41.651)(38.919,40.950)(40.000,40.126)\n        \\qbezier(40.000,40.126)(40.728,39.571)(42.000,38.537)\n        \\qbezier(42.000,38.537)(43.000,37.724)(44.000,36.911)\n        \\qbezier(44.000,36.911)(45.000,36.098)(46.000,35.285)\n        \\qbezier(46.000,35.285)(47.000,34.471)(48.000,33.658)\n        \\qbezier(48.000,33.658)(49.000,32.845)(50.000,32.032)\n        \\qbezier(50.000,32.032)(51.000,31.219)(52.000,30.406)\n        \\qbezier(52.000,30.406)(53.000,29.593)(54.000,28.779)\n        \\qbezier(54.000,28.779)(55.000,27.966)(56.000,27.153)\n        \\qbezier(56.000,27.153)(57.000,26.340)(58.000,25.527)\n        \\qbezier(58.000,25.527)(59.000,24.714)(60.000,23.901)\n        \\qbezier(60.000,23.901)(61.000,23.088)(62.000,22.274)\n        \\qbezier(62.000,22.274)(63.000,21.461)(64.000,20.648)\n        \\qbezier(64.000,20.648)(65.000,19.835)(66.000,19.022)\n        \\qbezier(66.000,19.022)(67.000,18.209)(68.000,17.396)\n        \\qbezier(68.000,17.396)(69.000,16.582)(70.000,15.769)\n        \\qbezier(70.000,15.769)(71.285,14.725)(72.000,14.143)\n        \\qbezier(72.000,14.143)(73.182,13.182)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.009,11.746)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.010,10.244)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.010,8.815)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.097,0.002)(100.000,0.000)\n    \\color{cyan}\n        \\put(0.000,75.000){\\Bfull}\\put(2.000,72.319){\\Bfull}\n        \\put(4.000,70.117){\\Bfull}\\put(6.000,68.086){\\Bfull}\n        \\put(8.000,66.162){\\Bfull}\\put(10.000,64.314){\\Bfull}\n        \\put(12.000,62.524){\\Bfull}\\put(14.000,60.780){\\Bfull}\n        \\put(16.000,59.075){\\Bfull}\\put(18.000,57.402){\\Bfull}\n        \\put(20.000,55.755){\\Bfull}\\put(22.000,54.131){\\Bfull}\n        \\put(24.000,52.527){\\Bfull}\\put(26.000,50.940){\\Bfull}\n        \\put(28.000,49.367){\\Bfull}\\put(30.000,47.806){\\Bfull}\n        \\put(32.000,46.256){\\Bfull}\\put(34.000,44.715){\\Bfull}\n        \\put(36.000,43.180){\\Bfull}\\put(38.000,41.651){\\Bfull}\n        \\put(40.000,40.126){\\Bfull}\\put(42.000,38.537){\\Bfull}\n        \\put(44.000,36.911){\\Bfull}\\put(46.000,35.285){\\Bfull}\n        \\put(48.000,33.658){\\Bfull}\\put(50.000,32.032){\\Bfull}\n        \\put(52.000,30.406){\\Bfull}\\put(54.000,28.779){\\Bfull}\n        \\put(56.000,27.153){\\Bfull}\\put(58.000,25.527){\\Bfull}\n        \\put(60.000,23.901){\\Bfull}\\put(62.000,22.274){\\Bfull}\n        \\put(64.000,20.648){\\Bfull}\\put(66.000,19.022){\\Bfull}\n        \\put(68.000,17.396){\\Bfull}\\put(70.000,15.769){\\Bfull}\n        \\put(72.000,14.143){\\Bfull}\\put(74.000,12.539){\\Bfull}\n        \\put(76.000,11.002){\\Bfull}\\put(78.000,9.537){\\Bfull}\n        \\put(80.000,8.147){\\Bfull}\\put(82.000,6.838){\\Bfull}\n        \\put(84.000,5.615){\\Bfull}\\put(86.000,4.484){\\Bfull}\n        \\put(88.000,3.451){\\Bfull}\\put(90.000,2.527){\\Bfull}\n        \\put(92.000,1.719){\\Bfull}\\put(94.000,1.041){\\Bfull}\n        \\put(96.000,0.509){\\Bfull}\\put(98.000,0.147){\\Bfull}\n        \\put(100.000,0.000){\\Bfull}\n    }\n}\n\\caption{Bounds for $q = 2$ and $n = 4$.}\n\\label{fig:q=2,n=4}\n\\end{figure*}\n\n\\begin{figure*}[hbt]\n%% q = 2, n =  4:\n\\Plot{%\n    \\put(035,095){\n\t\\put(000,000){\\LegendAlt}\n    }\n    \\put(000,000){\\color{brown}\n        %%\\qbezier(0.000,75.000)(0.358,74.225)(2.000,72.334)\n        %%\\qbezier(2.000,72.334)(2.887,71.312)(4.000,70.171)\n        %%\\qbezier(4.000,70.171)(4.934,69.213)(6.000,68.201)\n        %%\\qbezier(6.000,68.201)(6.954,67.294)(8.000,66.356)\n        %%\\qbezier(8.000,66.356)(8.964,65.491)(10.000,64.606)\n        %%\\qbezier(10.000,64.606)(10.971,63.776)(12.000,62.933)\n        %%\\qbezier(12.000,62.933)(12.976,62.132)(14.000,61.323)\n        %%\\qbezier(14.000,61.323)(15.674,60.000)(16.000,60.000)\n        %%\\qbezier(16.000,60.000)(17.000,60.000)(18.000,60.000)\n        %%\\qbezier(18.000,60.000)(19.000,60.000)(20.000,60.000)\n        %%\\qbezier(20.000,60.000)(21.000,60.000)(22.000,60.000)\n        %%\\qbezier(22.000,60.000)(23.000,60.000)(24.000,60.000)\n        %%\\qbezier(24.000,60.000)(25.000,60.000)(26.000,60.000)\n        %%\\qbezier(26.000,60.000)(27.000,60.000)(28.000,60.000)\n        %%\\qbezier(28.000,60.000)(29.000,60.000)(30.000,60.000)\n        %%\\qbezier(30.000,60.000)(31.000,60.000)(32.000,60.000)\n        %%\\qbezier(32.000,60.000)(33.000,60.000)(34.000,60.000)\n        %%\\qbezier(34.000,60.000)(35.000,60.000)(36.000,60.000)\n        %%\\qbezier(36.000,60.000)(37.000,60.000)(38.000,60.000)\n        %%\\qbezier(38.000,60.000)(39.000,60.000)(40.000,60.000)\n        %%\\qbezier(40.000,60.000)(41.000,60.000)(42.000,60.000)\n        %%\\qbezier(42.000,60.000)(43.000,60.000)(44.000,60.000)\n        %%\\qbezier(44.000,60.000)(45.000,60.000)(46.000,60.000)\n        %%\\qbezier(46.000,60.000)(47.000,60.000)(48.000,60.000)\n        %%\\qbezier(48.000,60.000)(49.000,60.000)(50.000,60.000)\n        %%\\qbezier(50.000,60.000)(51.000,60.000)(52.000,60.000)\n        %%\\qbezier(52.000,60.000)(53.000,60.000)(54.000,60.000)\n        %%\\qbezier(54.000,60.000)(55.000,60.000)(56.000,60.000)\n        %%\\qbezier(56.000,60.000)(57.000,60.000)(58.000,60.000)\n        %%\\qbezier(58.000,60.000)(59.000,60.000)(60.000,60.000)\n        %%\\qbezier(60.000,60.000)(61.000,60.000)(62.000,60.000)\n        %%\\qbezier(62.000,60.000)(63.000,60.000)(64.000,60.000)\n        %%\\qbezier(64.000,60.000)(65.000,60.000)(66.000,60.000)\n        %%\\qbezier(66.000,60.000)(67.000,60.000)(68.000,60.000)\n        %%\\qbezier(68.000,60.000)(69.000,60.000)(70.000,60.000)\n        %%\\qbezier(70.000,60.000)(71.000,60.000)(72.000,60.000)\n        %%\\qbezier(72.000,60.000)(73.000,60.000)(74.000,60.000)\n        %%\\qbezier(74.000,60.000)(75.000,60.000)(76.000,60.000)\n        %%\\qbezier(76.000,60.000)(77.000,60.000)(78.000,60.000)\n        %%\\qbezier(78.000,60.000)(79.000,60.000)(80.000,60.000)\n        %%\\qbezier(80.000,60.000)(81.000,60.000)(82.000,60.000)\n        %%\\qbezier(82.000,60.000)(83.000,60.000)(84.000,60.000)\n        %%\\qbezier(84.000,60.000)(85.000,60.000)(86.000,60.000)\n        %%\\qbezier(86.000,60.000)(87.000,60.000)(88.000,60.000)\n        %%\\qbezier(88.000,60.000)(89.000,60.000)(90.000,60.000)\n        %%\\qbezier(90.000,60.000)(91.000,60.000)(92.000,60.000)\n        %%\\qbezier(92.000,60.000)(93.000,60.000)(94.000,60.000)\n        %%\\qbezier(94.000,60.000)(95.000,60.000)(96.000,60.000)\n        %%\\qbezier(96.000,60.000)(97.000,60.000)(98.000,60.000)\n        %%\\qbezier(98.000,60.000)(99.000,60.000)(100.000,60.000)\n        \\put(0.000,75.000){\\Bbox}\\put(2.000,72.334){\\Bbox}\n        \\put(4.000,70.171){\\Bbox}\\put(6.000,68.201){\\Bbox}\n        \\put(8.000,66.356){\\Bbox}\\put(10.000,64.606){\\Bbox}\n        \\put(12.000,62.933){\\Bbox}\\put(14.000,61.323){\\Bbox}\n        \\put(16.000,60.000){\\Bbox}\\put(18.000,60.000){\\Bbox}\n        \\put(20.000,60.000){\\Bbox}\\put(22.000,60.000){\\Bbox}\n        \\put(24.000,60.000){\\Bbox}\\put(26.000,60.000){\\Bbox}\n        \\put(28.000,60.000){\\Bbox}\\put(30.000,60.000){\\Bbox}\n        \\put(32.000,60.000){\\Bbox}\\put(34.000,60.000){\\Bbox}\n        \\put(36.000,60.000){\\Bbox}\\put(38.000,60.000){\\Bbox}\n        \\put(40.000,60.000){\\Bbox}\\put(42.000,60.000){\\Bbox}\n        \\put(44.000,60.000){\\Bbox}\\put(46.000,60.000){\\Bbox}\n        \\put(48.000,60.000){\\Bbox}\\put(50.000,60.000){\\Bbox}\n        \\put(52.000,60.000){\\Bbox}\\put(54.000,60.000){\\Bbox}\n        \\put(56.000,60.000){\\Bbox}\\put(58.000,60.000){\\Bbox}\n        \\put(60.000,60.000){\\Bbox}\\put(62.000,60.000){\\Bbox}\n        \\put(64.000,60.000){\\Bbox}\\put(66.000,60.000){\\Bbox}\n        \\put(68.000,60.000){\\Bbox}\\put(70.000,60.000){\\Bbox}\n        \\put(72.000,60.000){\\Bbox}\\put(74.000,60.000){\\Bbox}\n        \\put(76.000,60.000){\\Bbox}\\put(78.000,60.000){\\Bbox}\n        \\put(80.000,60.000){\\Bbox}\\put(82.000,60.000){\\Bbox}\n        \\put(84.000,60.000){\\Bbox}\\put(86.000,60.000){\\Bbox}\n        \\put(88.000,60.000){\\Bbox}\\put(90.000,60.000){\\Bbox}\n        \\put(92.000,60.000){\\Bbox}\\put(94.000,60.000){\\Bbox}\n        \\put(96.000,60.000){\\Bbox}\\put(98.000,60.000){\\Bbox}\n        \\put(100.000,60.000){\\Bbox}\n    \\color{black}\n        \\put(0.000,75.000){\\Bfull}\\put(2.000,70.171){\\Bfull}\n        \\put(4.000,66.356){\\Bfull}\\put(6.000,62.933){\\Bfull}\n        \\put(8.000,59.769){\\Bfull}\\put(10.000,56.802){\\Bfull}\n        \\put(12.000,53.995){\\Bfull}\\put(14.000,51.324){\\Bfull}\n        \\put(16.000,48.772){\\Bfull}\\put(18.000,46.327){\\Bfull}\n        \\put(20.000,43.978){\\Bfull}\\put(22.000,41.717){\\Bfull}\n        \\put(24.000,39.540){\\Bfull}\\put(26.000,37.439){\\Bfull}\n        \\put(28.000,35.412){\\Bfull}\\put(30.000,33.455){\\Bfull}\n        \\put(32.000,31.564){\\Bfull}\\put(34.000,29.737){\\Bfull}\n        \\put(36.000,27.972){\\Bfull}\\put(38.000,26.267){\\Bfull}\n        \\put(40.000,24.620){\\Bfull}\\put(42.000,23.030){\\Bfull}\n        \\put(44.000,21.496){\\Bfull}\\put(46.000,20.016){\\Bfull}\n        \\put(48.000,18.591){\\Bfull}\\put(50.000,17.218){\\Bfull}\n        \\put(52.000,15.898){\\Bfull}\\put(54.000,14.630){\\Bfull}\n        \\put(56.000,13.414){\\Bfull}\\put(58.000,12.249){\\Bfull}\n        \\put(60.000,11.136){\\Bfull}\\put(62.000,10.074){\\Bfull}\n        \\put(64.000,9.063){\\Bfull}\\put(66.000,8.104){\\Bfull}\n        \\put(68.000,7.197){\\Bfull}\\put(70.000,6.341){\\Bfull}\n        \\put(72.000,5.537){\\Bfull}\\put(74.000,4.786){\\Bfull}\n        \\put(76.000,4.088){\\Bfull}\\put(78.000,3.443){\\Bfull}\n        \\put(80.000,2.851){\\Bfull}\\put(82.000,2.314){\\Bfull}\n        \\put(84.000,1.832){\\Bfull}\\put(86.000,1.405){\\Bfull}\n        \\put(88.000,1.034){\\Bfull}\\put(90.000,0.719){\\Bfull}\n        \\put(92.000,0.461){\\Bfull}\\put(94.000,0.259){\\Bfull}\n        \\put(96.000,0.115){\\Bfull}\\put(98.000,0.029){\\Bfull}\n        \\put(100.000,0.000){\\Bfull}\n    \\color{green}\n        \\qbezier(0.000,75.000)(0.889,74.248)(2.000,73.309)\n        \\qbezier(2.000,73.309)(3.480,72.057)(4.000,71.618)\n        \\qbezier(4.000,71.618)(4.317,71.350)(6.000,69.927)\n        \\qbezier(6.000,69.927)(7.539,68.626)(8.000,68.236)\n        \\qbezier(8.000,68.236)(9.000,67.390)(10.000,66.545)\n        \\qbezier(10.000,66.545)(11.000,65.699)(12.000,64.854)\n        \\qbezier(12.000,64.854)(13.000,64.008)(14.000,63.163)\n        \\qbezier(14.000,63.163)(15.000,62.317)(16.000,61.471)\n        \\qbezier(16.000,61.471)(17.000,60.626)(18.000,59.780)\n        \\qbezier(18.000,59.780)(19.000,58.935)(20.000,58.089)\n        \\qbezier(20.000,58.089)(21.058,57.195)(22.000,56.398)\n        \\qbezier(22.000,56.398)(23.386,55.226)(24.000,54.707)\n        \\qbezier(24.000,54.707)(24.858,53.982)(26.000,53.016)\n        \\qbezier(26.000,53.016)(27.000,52.171)(28.000,51.325)\n        \\qbezier(28.000,51.325)(29.000,50.480)(30.000,49.634)\n        \\qbezier(30.000,49.634)(31.000,48.788)(32.000,47.943)\n        \\qbezier(32.000,47.943)(33.000,47.097)(34.000,46.252)\n        \\qbezier(34.000,46.252)(34.785,45.588)(36.000,44.561)\n        \\qbezier(36.000,44.561)(37.000,43.715)(38.000,42.870)\n        \\qbezier(38.000,42.870)(39.094,41.945)(40.000,41.179)\n        \\qbezier(40.000,41.179)(41.000,40.333)(42.000,39.488)\n        \\qbezier(42.000,39.488)(43.259,38.423)(44.000,37.796)\n        \\qbezier(44.000,37.796)(45.000,36.951)(46.000,36.105)\n        \\qbezier(46.000,36.105)(47.000,35.260)(48.000,34.414)\n        \\qbezier(48.000,34.414)(49.000,33.569)(50.000,32.723)\n        \\qbezier(50.000,32.723)(51.531,31.429)(52.000,31.032)\n        \\qbezier(52.000,31.032)(53.000,30.187)(54.000,29.341)\n        \\qbezier(54.000,29.341)(55.000,28.496)(56.000,27.650)\n        \\qbezier(56.000,27.650)(57.000,26.805)(58.000,25.959)\n        \\qbezier(58.000,25.959)(59.000,25.113)(60.000,24.268)\n        \\qbezier(60.000,24.268)(61.000,23.422)(62.000,22.577)\n        \\qbezier(62.000,22.577)(62.911,21.807)(64.000,20.886)\n        \\qbezier(64.000,20.886)(65.543,19.581)(66.000,19.195)\n        \\qbezier(66.000,19.195)(67.000,18.349)(68.000,17.504)\n        \\qbezier(68.000,17.504)(69.445,16.282)(70.000,15.813)\n        \\qbezier(70.000,15.813)(71.153,14.838)(72.000,14.144)\n        \\qbezier(72.000,14.144)(73.005,13.321)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.005,11.749)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.005,10.247)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.021,8.808)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.022,7.457)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.007,6.200)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.006,5.022)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.007,3.938)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.031,2.946)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.033,2.080)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.013,1.342)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.018,0.732)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.029,0.277)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.094,0.002)(100.000,0.000)\n        \\put(0.000,75.000){\\Bbox}\\put(2.000,73.309){\\Bbox}\n        \\put(4.000,71.618){\\Bbox}\\put(6.000,69.927){\\Bbox}\n        \\put(8.000,68.236){\\Bbox}\\put(10.000,66.545){\\Bbox}\n        \\put(12.000,64.854){\\Bbox}\\put(14.000,63.163){\\Bbox}\n        \\put(16.000,61.471){\\Bbox}\\put(18.000,59.780){\\Bbox}\n        \\put(20.000,58.089){\\Bbox}\\put(22.000,56.398){\\Bbox}\n        \\put(24.000,54.707){\\Bbox}\\put(26.000,53.016){\\Bbox}\n        \\put(28.000,51.325){\\Bbox}\\put(30.000,49.634){\\Bbox}\n        \\put(32.000,47.943){\\Bbox}\\put(34.000,46.252){\\Bbox}\n        \\put(36.000,44.561){\\Bbox}\\put(38.000,42.870){\\Bbox}\n        \\put(40.000,41.179){\\Bbox}\\put(42.000,39.488){\\Bbox}\n        \\put(44.000,37.796){\\Bbox}\\put(46.000,36.105){\\Bbox}\n        \\put(48.000,34.414){\\Bbox}\\put(50.000,32.723){\\Bbox}\n        \\put(52.000,31.032){\\Bbox}\\put(54.000,29.341){\\Bbox}\n        \\put(56.000,27.650){\\Bbox}\\put(58.000,25.959){\\Bbox}\n        \\put(60.000,24.268){\\Bbox}\\put(62.000,22.577){\\Bbox}\n        \\put(64.000,20.886){\\Bbox}\\put(66.000,19.195){\\Bbox}\n        \\put(68.000,17.504){\\Bbox}\\put(70.000,15.813){\\Bbox}\n        \\put(72.000,14.144){\\Bbox}\\put(74.000,12.539){\\Bbox}\n        \\put(76.000,11.002){\\Bbox}\\put(78.000,9.537){\\Bbox}\n        \\put(80.000,8.147){\\Bbox}\\put(82.000,6.838){\\Bbox}\n        \\put(84.000,5.615){\\Bbox}\\put(86.000,4.484){\\Bbox}\n        \\put(88.000,3.451){\\Bbox}\\put(90.000,2.527){\\Bbox}\n        \\put(92.000,1.719){\\Bbox}\\put(94.000,1.041){\\Bbox}\n        \\put(96.000,0.509){\\Bbox}\\put(98.000,0.147){\\Bbox}\n        \\put(100.000,0.000){\\Bbox}\n    \\color{red}\n        \\qbezier(0.000,75.000)(0.350,74.242)(2.000,72.319)\n        \\qbezier(2.000,72.319)(2.878,71.295)(4.000,70.117)\n        \\qbezier(4.000,70.117)(4.926,69.144)(6.000,68.086)\n        \\qbezier(6.000,68.086)(6.945,67.154)(8.000,66.162)\n        \\qbezier(8.000,66.162)(8.956,65.262)(10.000,64.314)\n        \\qbezier(10.000,64.314)(10.963,63.439)(12.000,62.524)\n        \\qbezier(12.000,62.524)(12.967,61.670)(14.000,60.780)\n        %%\\qbezier(14.000,60.780)(14.906,60.000)(16.000,60.000)\n        %> Higher resolution at a non-differentiable point:\n        \\qbezier(14.000,60.780)(14.264,60.553)(14.500,60.351)\n        \\qbezier(14.500,60.351)(14.842,60.057)(15.000,60.013)\n        \\qbezier(15.000,60.013)(15.046,60.000)(15.250,60.000)\n        \\qbezier(15.250,60.000)(15.375,60.000)(15.500,60.000)\n        \\qbezier(15.500,60.000)(15.750,60.000)(16.000,60.000)\n        %<\n        \\qbezier(16.000,60.000)(17.000,60.000)(18.000,60.000)\n        \\qbezier(18.000,60.000)(19.000,60.000)(20.000,60.000)\n        \\qbezier(20.000,60.000)(21.000,60.000)(22.000,60.000)\n        \\qbezier(22.000,60.000)(23.000,60.000)(24.000,60.000)\n        \\qbezier(24.000,60.000)(25.000,60.000)(26.000,60.000)\n        %%\\qbezier(26.000,60.000)(27.709,60.000)(28.000,59.661)\n        %> Higher resolution at a non-differentiable point:\n        \\qbezier(26.000,60.000)(26.250,60.000)(26.500,60.000)\n        \\qbezier(26.500,60.000)(26.750,60.000)(27.000,60.000)\n        \\qbezier(27.000,60.000)(27.250,60.000)(27.500,60.000)\n        \\qbezier(27.500,60.000)(27.710,60.000)(27.750,59.953)\n        \\qbezier(27.750,59.953)(27.875,59.807)(28.000,59.661)\n        %<\n        \\qbezier(28.000,59.661)(28.983,58.516)(30.000,57.345)\n        \\qbezier(30.000,57.345)(30.983,56.213)(32.000,55.057)\n        \\qbezier(32.000,55.057)(32.984,53.938)(34.000,52.794)\n        \\qbezier(34.000,52.794)(34.984,51.686)(36.000,50.554)\n        \\qbezier(36.000,50.554)(36.985,49.457)(38.000,48.336)\n        \\qbezier(38.000,48.336)(38.985,47.248)(40.000,46.136)\n        \\qbezier(40.000,46.136)(40.985,45.057)(42.000,43.954)\n        \\qbezier(42.000,43.954)(42.985,42.883)(44.000,41.787)\n        \\qbezier(44.000,41.787)(44.985,40.724)(46.000,39.636)\n        \\qbezier(46.000,39.636)(46.985,38.580)(48.000,37.497)\n        \\qbezier(48.000,37.497)(48.985,36.448)(50.000,35.371)\n        \\qbezier(50.000,35.371)(50.984,34.327)(52.000,33.256)\n        \\qbezier(52.000,33.256)(52.984,32.218)(54.000,31.151)\n        \\qbezier(54.000,31.151)(55.222,29.868)(56.000,29.063)\n        \\qbezier(56.000,29.063)(57.007,28.023)(58.000,27.020)\n        \\qbezier(58.000,27.020)(59.007,26.002)(60.000,25.022)\n        \\qbezier(60.000,25.022)(61.007,24.029)(62.000,23.074)\n        \\qbezier(62.000,23.074)(63.007,22.106)(64.000,21.177)\n        \\qbezier(64.000,21.177)(65.008,20.234)(66.000,19.332)\n        \\qbezier(66.000,19.332)(67.008,18.417)(68.000,17.544)\n        \\qbezier(68.000,17.544)(69.008,16.657)(70.000,15.813)\n        \\qbezier(70.000,15.813)(71.008,14.956)(72.000,14.144)\n        \\qbezier(72.000,14.144)(73.009,13.318)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.009,11.746)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.010,10.244)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.010,8.815)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.099,0.001)(100.000,0.000)\n    \\color{blue}\n        \\qbezier(0.000,75.000)(0.363,74.219)(2.000,72.334)\n        \\qbezier(2.000,72.334)(2.887,71.312)(4.000,70.171)\n        \\qbezier(4.000,70.171)(4.934,69.214)(6.000,68.201)\n        \\qbezier(6.000,68.201)(6.954,67.294)(8.000,66.356)\n        \\qbezier(8.000,66.356)(8.963,65.493)(10.000,64.606)\n        \\qbezier(10.000,64.606)(10.971,63.776)(12.000,62.933)\n        \\qbezier(12.000,62.933)(12.219,62.753)(14.000,61.305)\n        \\qbezier(14.000,61.305)(15.233,60.303)(16.000,59.679)\n        \\qbezier(16.000,59.679)(17.000,58.865)(18.000,58.052)\n        \\qbezier(18.000,58.052)(19.000,57.239)(20.000,56.426)\n        \\qbezier(20.000,56.426)(21.000,55.613)(22.000,54.800)\n        \\qbezier(22.000,54.800)(23.000,53.987)(24.000,53.174)\n        \\qbezier(24.000,53.174)(25.000,52.360)(26.000,51.547)\n        \\qbezier(26.000,51.547)(27.000,50.734)(28.000,49.921)\n        \\qbezier(28.000,49.921)(29.000,49.108)(30.000,48.295)\n        \\qbezier(30.000,48.295)(31.000,47.482)(32.000,46.668)\n        \\qbezier(32.000,46.668)(33.000,45.855)(34.000,45.042)\n        \\qbezier(34.000,45.042)(35.000,44.229)(36.000,43.416)\n        \\qbezier(36.000,43.416)(37.000,42.603)(38.000,41.790)\n        \\qbezier(38.000,41.790)(39.000,40.976)(40.000,40.163)\n        \\qbezier(40.000,40.163)(41.000,39.350)(42.000,38.537)\n        \\qbezier(42.000,38.537)(43.000,37.724)(44.000,36.911)\n        \\qbezier(44.000,36.911)(45.000,36.098)(46.000,35.285)\n        \\qbezier(46.000,35.285)(47.000,34.471)(48.000,33.658)\n        \\qbezier(48.000,33.658)(49.000,32.845)(50.000,32.032)\n        \\qbezier(50.000,32.032)(51.000,31.219)(52.000,30.406)\n        \\qbezier(52.000,30.406)(53.000,29.593)(54.000,28.779)\n        \\qbezier(54.000,28.779)(55.000,27.966)(56.000,27.153)\n        \\qbezier(56.000,27.153)(57.000,26.340)(58.000,25.527)\n        \\qbezier(58.000,25.527)(59.000,24.714)(60.000,23.901)\n        \\qbezier(60.000,23.901)(61.000,23.088)(62.000,22.274)\n        \\qbezier(62.000,22.274)(63.000,21.461)(64.000,20.648)\n        \\qbezier(64.000,20.648)(65.000,19.835)(66.000,19.022)\n        \\qbezier(66.000,19.022)(67.000,18.209)(68.000,17.396)\n        \\qbezier(68.000,17.396)(69.000,16.582)(70.000,15.769)\n        \\qbezier(70.000,15.769)(71.285,14.725)(72.000,14.143)\n        \\qbezier(72.000,14.143)(73.182,13.182)(74.000,12.539)\n        \\qbezier(74.000,12.539)(75.009,11.746)(76.000,11.002)\n        \\qbezier(76.000,11.002)(77.010,10.244)(78.000,9.537)\n        \\qbezier(78.000,9.537)(79.010,8.815)(80.000,8.147)\n        \\qbezier(80.000,8.147)(81.011,7.465)(82.000,6.838)\n        \\qbezier(82.000,6.838)(83.011,6.197)(84.000,5.615)\n        \\qbezier(84.000,5.615)(85.012,5.018)(86.000,4.484)\n        \\qbezier(86.000,4.484)(87.013,3.935)(88.000,3.451)\n        \\qbezier(88.000,3.451)(89.015,2.954)(90.000,2.527)\n        \\qbezier(90.000,2.527)(91.017,2.085)(92.000,1.719)\n        \\qbezier(92.000,1.719)(93.020,1.339)(94.000,1.041)\n        \\qbezier(94.000,1.041)(95.024,0.730)(96.000,0.509)\n        \\qbezier(96.000,0.509)(97.035,0.276)(98.000,0.147)\n        \\qbezier(98.000,0.147)(99.073,0.005)(100.000,0.000)\n        \\put(0.000,75.000){\\Bplus}\\put(2.000,72.334){\\Bplus}\n        \\put(4.000,70.171){\\Bplus}\\put(6.000,68.201){\\Bplus}\n        \\put(8.000,66.356){\\Bplus}\\put(10.000,64.606){\\Bplus}\n        \\put(12.000,62.933){\\Bplus}\\put(14.000,61.305){\\Bplus}\n        \\put(16.000,59.679){\\Bplus}\\put(18.000,58.052){\\Bplus}\n        \\put(20.000,56.426){\\Bplus}\\put(22.000,54.800){\\Bplus}\n        \\put(24.000,53.174){\\Bplus}\\put(26.000,51.547){\\Bplus}\n        \\put(28.000,49.921){\\Bplus}\\put(30.000,48.295){\\Bplus}\n        \\put(32.000,46.668){\\Bplus}\\put(34.000,45.042){\\Bplus}\n        \\put(36.000,43.416){\\Bplus}\\put(38.000,41.790){\\Bplus}\n        \\put(40.000,40.163){\\Bplus}\\put(42.000,38.537){\\Bplus}\n        \\put(44.000,36.911){\\Bplus}\\put(46.000,35.285){\\Bplus}\n        \\put(48.000,33.658){\\Bplus}\\put(50.000,32.032){\\Bplus}\n        \\put(52.000,30.406){\\Bplus}\\put(54.000,28.779){\\Bplus}\n        \\put(56.000,27.153){\\Bplus}\\put(58.000,25.527){\\Bplus}\n        \\put(60.000,23.901){\\Bplus}\\put(62.000,22.274){\\Bplus}\n        \\put(64.000,20.648){\\Bplus}\\put(66.000,19.022){\\Bplus}\n        \\put(68.000,17.396){\\Bplus}\\put(70.000,15.769){\\Bplus}\n        \\put(72.000,14.143){\\Bplus}\\put(74.000,12.539){\\Bplus}\n        \\put(76.000,11.002){\\Bplus}\\put(78.000,9.537){\\Bplus}\n        \\put(80.000,8.147){\\Bplus}\\put(82.000,6.838){\\Bplus}\n        \\put(84.000,5.615){\\Bplus}\\put(86.000,4.484){\\Bplus}\n        \\put(88.000,3.451){\\Bplus}\\put(90.000,2.527){\\Bplus}\n        \\put(92.000,1.719){\\Bplus}\\put(94.000,1.041){\\Bplus}\n        \\put(96.000,0.509){\\Bplus}\\put(98.000,0.147){\\Bplus}\n        \\put(100.000,0.000){\\Bplus}\n    }\n}\n\\caption{Bounds for $q = 2$ and $n = 4$ (not necessarily all-disjoint).}\n\\label{fig:q=2,n=4-nondisjoint}\n\\end{figure*}\n\\fi\n\\end{document}\n\n\\newcommand{\\PlotRo}[1]{%\n    \\begin{center}\n    \\small\n    \\thicklines\n    \\ifIEEE\n        \\setlength{\\unitlength}{1.3mm}\n    \\else\n        \\setlength{\\unitlength}{1.2mm}\n    \\fi\n    \\begin{picture}(135,135)(-10,-10)\n    \\put(-10,000){\\vector(1,0){120}}\n    \\put(114,-.1){\\makebox(0,0)[l]{$\\x$}}\n    \\put(000,-10){\\vector(0,1){120}}\n    %%\\put(-04,114){\\makebox(0,0)[r]{$\\Rate_0(\\omega,\\x)$}}\n    \\put(-05,-04){\\makebox(0,0)[t]{$0$}}\n    \\multiput(010,000)(010,000){10}{\\line(0,-1){2}}\n    \\put(010,-04){\\makebox(0,0)[t]{$1$}}\n    \\put(020,-04){\\makebox(0,0)[t]{$2$}}\n    \\put(030,-04){\\makebox(0,0)[t]{$3$}}\n    \\put(040,-04){\\makebox(0,0)[t]{$4$}}\n    \\put(050,-04){\\makebox(0,0)[t]{$5$}}\n    \\put(060,-04){\\makebox(0,0)[t]{$6$}}\n    \\put(070,-04){\\makebox(0,0)[t]{$7$}}\n    \\put(080,-04){\\makebox(0,0)[t]{$8$}}\n    \\put(090,-04){\\makebox(0,0)[t]{$9$}}\n    \\put(100,-04){\\makebox(0,0)[t]{$10$}}\n    \\multiput(000,010)(000,010){10}{\\line(-1,0){2}}\n    \\put(-04,050){\\makebox(0,0)[r]{$0.5$}}\n    \\put(-04,100){\\makebox(0,0)[r]{$1.0$}}\n    \\put(000,000){#1}\n    \\end{picture}\n    \\thinlines\n    \\setlength{\\unitlength}{1pt}\n    \\end{center}\n}\n\\begin{figure*}[hbt]\n%% q = 2, omega = 0.00, 0.05, 0.12, 0.20, 0.30:\n\\PlotRo{%\n    \\put(000,114){\\makebox(0,0)[r]{$\\Rate_0(\\omega,\\x)$}}\n    \\put(100,000){%\n        \\put(000,092){\\makebox(0,0)[r]{$\\omega = 0.00$}}\n        \\put(000,070){\\makebox(0,0)[r]{$\\omega = 0.05$}}\n        \\put(000,048.5){\\makebox(0,0)[r]{$\\omega = 0.12$}}\n        \\put(000,030){\\makebox(0,0)[r]{$\\omega = 0.20$}}\n        \\put(000,014){\\makebox(0,0)[r]{$\\omega = 0.30$}}\n    }\n    \\put(000,000){\\color{gray}\n        \\qbezier(10.000,0.000)(10.909,9.093)(12.000,16.667)\n        \\qbezier(12.000,16.667)(12.923,23.077)(14.000,28.571)\n        \\qbezier(14.000,28.571)(14.933,33.333)(16.000,37.500)\n        \\qbezier(16.000,37.500)(16.941,41.176)(18.000,44.444)\n        \\qbezier(18.000,44.444)(18.947,47.368)(20.000,50.000)\n        \\qbezier(20.000,50.000)(20.952,52.381)(22.000,54.545)\n        \\qbezier(22.000,54.545)(22.957,56.522)(24.000,58.333)\n        \\qbezier(24.000,58.333)(24.960,60.000)(26.000,61.538)\n        \\qbezier(26.000,61.538)(26.963,62.963)(28.000,64.286)\n        \\qbezier(28.000,64.286)(28.966,65.517)(30.000,66.667)\n        \\qbezier(30.000,66.667)(30.968,67.742)(32.000,68.750)\n        \\qbezier(32.000,68.750)(32.970,69.697)(34.000,70.588)\n        \\qbezier(34.000,70.588)(34.971,71.429)(36.000,72.222)\n        \\qbezier(36.000,72.222)(36.973,72.973)(38.000,73.684)\n        \\qbezier(38.000,73.684)(38.974,74.359)(40.000,75.000)\n        \\qbezier(40.000,75.000)(40.976,75.610)(42.000,76.190)\n        \\qbezier(42.000,76.190)(42.977,76.744)(44.000,77.273)\n        \\qbezier(44.000,77.273)(44.978,77.778)(46.000,78.261)\n        \\qbezier(46.000,78.261)(46.979,78.723)(48.000,79.167)\n        \\qbezier(48.000,79.167)(48.980,79.592)(50.000,80.000)\n        \\qbezier(50.000,80.000)(50.980,80.392)(52.000,80.769)\n        \\qbezier(52.000,80.769)(52.981,81.132)(54.000,81.481)\n        \\qbezier(54.000,81.481)(54.982,81.818)(56.000,82.143)\n        \\qbezier(56.000,82.143)(56.982,82.456)(58.000,82.759)\n        \\qbezier(58.000,82.759)(58.983,83.051)(60.000,83.333)\n        \\qbezier(60.000,83.333)(60.984,83.607)(62.000,83.871)\n        \\qbezier(62.000,83.871)(62.984,84.127)(64.000,84.375)\n        \\qbezier(64.000,84.375)(64.985,84.615)(66.000,84.848)\n        \\qbezier(66.000,84.848)(66.985,85.075)(68.000,85.294)\n        \\qbezier(68.000,85.294)(68.986,85.507)(70.000,85.714)\n        \\qbezier(70.000,85.714)(70.986,85.915)(72.000,86.111)\n        \\qbezier(72.000,86.111)(72.986,86.301)(74.000,86.486)\n        \\qbezier(74.000,86.486)(74.987,86.667)(76.000,86.842)\n        \\qbezier(76.000,86.842)(76.987,87.013)(78.000,87.179)\n        \\qbezier(78.000,87.179)(78.987,87.342)(80.000,87.500)\n        \\qbezier(80.000,87.500)(80.988,87.654)(82.000,87.805)\n        \\qbezier(82.000,87.805)(82.988,87.952)(84.000,88.095)\n        \\qbezier(84.000,88.095)(84.988,88.235)(86.000,88.372)\n        \\qbezier(86.000,88.372)(86.989,88.506)(88.000,88.636)\n        \\qbezier(88.000,88.636)(88.989,88.764)(90.000,88.889)\n        \\qbezier(90.000,88.889)(90.989,89.011)(92.000,89.130)\n        \\qbezier(92.000,89.130)(92.989,89.247)(94.000,89.362)\n        \\qbezier(94.000,89.362)(94.989,89.474)(96.000,89.583)\n        \\qbezier(96.000,89.583)(96.990,89.691)(98.000,89.796)\n        \\qbezier(98.000,89.796)(98.990,89.899)(100.000,90.000)\n        \\put(10.000,0.000){\\Bfull}\n        \\put(20.000,50.000){\\Bfull}\n        \\put(30.000,66.667){\\Bfull}\n        \\put(40.000,75.000){\\Bfull}\n        \\put(50.000,80.000){\\Bfull}\n        \\put(60.000,83.333){\\Bfull}\n        \\put(70.000,85.714){\\Bfull}\n        \\put(80.000,87.500){\\Bfull}\n        \\put(90.000,88.889){\\Bfull}\n        \\put(100.000,90.000){\\Bfull}\n    }\n    \\put(000,000){\\color{green}\n        \\qbezier(10.000,-0.000)(10.469,0.000)(12.000,8.000)\n        \\qbezier(12.000,8.000)(13.043,13.448)(14.000,17.490)\n        \\qbezier(14.000,17.490)(14.954,21.520)(16.000,24.989)\n        \\qbezier(16.000,24.989)(16.949,28.137)(18.000,30.915)\n        \\qbezier(18.000,30.915)(18.951,33.430)(20.000,35.680)\n        \\qbezier(20.000,35.680)(20.954,37.728)(22.000,39.580)\n        \\qbezier(22.000,39.580)(22.958,41.275)(24.000,42.821)\n        \\qbezier(24.000,42.821)(24.961,44.246)(26.000,45.554)\n        \\qbezier(26.000,45.554)(26.963,46.766)(28.000,47.885)\n        \\qbezier(28.000,47.885)(28.966,48.927)(30.000,49.894)\n        \\qbezier(30.000,49.894)(30.968,50.798)(32.000,51.641)\n        \\qbezier(32.000,51.641)(32.969,52.433)(34.000,53.173)\n        \\qbezier(34.000,53.173)(34.971,53.871)(36.000,54.526)\n        \\qbezier(36.000,54.526)(36.973,55.145)(38.000,55.728)\n        \\qbezier(38.000,55.728)(38.974,56.280)(40.000,56.802)\n        \\qbezier(40.000,56.802)(40.975,57.297)(42.000,57.766)\n        \\qbezier(42.000,57.766)(42.976,58.213)(44.000,58.637)\n        \\qbezier(44.000,58.637)(44.977,59.041)(46.000,59.426)\n        \\qbezier(46.000,59.426)(46.978,59.793)(48.000,60.143)\n        \\qbezier(48.000,60.143)(48.979,60.479)(50.000,60.799)\n        \\qbezier(50.000,60.799)(50.980,61.105)(52.000,61.399)\n        \\qbezier(52.000,61.399)(52.981,61.680)(54.000,61.950)\n        \\qbezier(54.000,61.950)(54.981,62.209)(56.000,62.458)\n        \\qbezier(56.000,62.458)(56.982,62.697)(58.000,62.926)\n        \\qbezier(58.000,62.926)(58.982,63.148)(60.000,63.361)\n        \\qbezier(60.000,63.361)(60.983,63.566)(62.000,63.763)\n        \\qbezier(62.000,63.763)(62.984,63.954)(64.000,64.138)\n        \\qbezier(64.000,64.138)(64.984,64.316)(66.000,64.487)\n        \\qbezier(66.000,64.487)(66.984,64.653)(68.000,64.813)\n        \\qbezier(68.000,64.813)(68.985,64.968)(70.000,65.117)\n        \\qbezier(70.000,65.117)(70.985,65.262)(72.000,65.403)\n        \\qbezier(72.000,65.403)(72.986,65.539)(74.000,65.670)\n        \\qbezier(74.000,65.670)(74.986,65.798)(76.000,65.921)\n        \\qbezier(76.000,65.921)(76.986,66.041)(78.000,66.158)\n        \\qbezier(78.000,66.158)(78.987,66.271)(80.000,66.380)\n        \\qbezier(80.000,66.380)(80.987,66.487)(82.000,66.590)\n        \\qbezier(82.000,66.590)(82.987,66.691)(84.000,66.788)\n        \\qbezier(84.000,66.788)(84.987,66.884)(86.000,66.976)\n        \\qbezier(86.000,66.976)(86.988,67.066)(88.000,67.153)\n        \\qbezier(88.000,67.153)(88.988,67.238)(90.000,67.321)\n        \\qbezier(90.000,67.321)(90.988,67.402)(92.000,67.480)\n        \\qbezier(92.000,67.480)(92.989,67.557)(94.000,67.631)\n        \\qbezier(94.000,67.631)(94.989,67.704)(96.000,67.774)\n        \\qbezier(96.000,67.774)(96.989,67.844)(98.000,67.911)\n        \\qbezier(98.000,67.911)(98.989,67.977)(100.000,68.040)\n        \\put(10.000,0.000){\\Bfull}\n        \\put(20.000,35.680){\\Bfull}\n        \\put(30.000,49.894){\\Bfull}\n        \\put(40.000,56.802){\\Bfull}\n        \\put(50.000,60.799){\\Bfull}\n        \\put(60.000,63.361){\\Bfull}\n        \\put(70.000,65.117){\\Bfull}\n        \\put(80.000,66.380){\\Bfull}\n        \\put(90.000,67.321){\\Bfull}\n        \\put(100.000,68.040){\\Bfull}\n    }\n    \\put(000,000){\\color{blue}\n        \\qbezier(10.000,-0.000)(10.988,0.000)(12.000,3.184)\n        \\qbezier(12.000,3.184)(13.000,6.407)(14.000,9.629)\n        \\qbezier(14.000,9.629)(15.006,12.727)(16.000,15.249)\n        \\qbezier(16.000,15.249)(16.964,17.695)(18.000,19.822)\n        \\qbezier(18.000,19.822)(18.958,21.789)(20.000,23.532)\n        \\qbezier(20.000,23.532)(20.958,25.134)(22.000,26.570)\n        \\qbezier(22.000,26.570)(22.960,27.891)(24.000,29.084)\n        \\qbezier(24.000,29.084)(24.962,30.187)(26.000,31.189)\n        \\qbezier(26.000,31.189)(26.964,32.119)(28.000,32.969)\n        \\qbezier(28.000,32.969)(28.966,33.761)(30.000,34.488)\n        \\qbezier(30.000,34.488)(30.967,35.167)(32.000,35.794)\n        \\qbezier(32.000,35.794)(32.969,36.382)(34.000,36.925)\n        \\qbezier(34.000,36.925)(34.971,37.437)(36.000,37.912)\n        \\qbezier(36.000,37.912)(36.972,38.360)(38.000,38.777)\n        \\qbezier(38.000,38.777)(38.973,39.172)(40.000,39.540)\n        \\qbezier(40.000,39.540)(40.974,39.889)(42.000,40.215)\n        \\qbezier(42.000,40.215)(42.975,40.525)(44.000,40.816)\n        \\qbezier(44.000,40.816)(44.976,41.093)(46.000,41.353)\n        \\qbezier(46.000,41.353)(46.977,41.600)(48.000,41.833)\n        \\qbezier(48.000,41.833)(48.978,42.056)(50.000,42.265)\n        \\qbezier(50.000,42.265)(50.979,42.466)(52.000,42.655)\n        \\qbezier(52.000,42.655)(52.979,42.836)(54.000,43.007)\n        \\qbezier(54.000,43.007)(54.980,43.171)(56.000,43.326)\n        \\qbezier(56.000,43.326)(56.980,43.475)(58.000,43.616)\n        \\qbezier(58.000,43.616)(58.981,43.751)(60.000,43.880)\n        \\qbezier(60.000,43.880)(60.982,44.003)(62.000,44.120)\n        \\qbezier(62.000,44.120)(62.982,44.233)(64.000,44.340)\n        \\qbezier(64.000,44.340)(64.982,44.443)(66.000,44.541)\n        \\qbezier(66.000,44.541)(66.983,44.636)(68.000,44.726)\n        \\qbezier(68.000,44.726)(68.983,44.812)(70.000,44.895)\n        \\qbezier(70.000,44.895)(70.984,44.974)(72.000,45.050)\n        \\qbezier(72.000,45.050)(72.984,45.124)(74.000,45.193)\n        \\qbezier(74.000,45.193)(74.984,45.261)(76.000,45.325)\n        \\qbezier(76.000,45.325)(76.984,45.388)(78.000,45.447)\n        \\qbezier(78.000,45.447)(78.985,45.505)(80.000,45.559)\n        \\qbezier(80.000,45.559)(80.985,45.613)(82.000,45.663)\n        \\qbezier(82.000,45.663)(82.985,45.712)(84.000,45.759)\n        \\qbezier(84.000,45.759)(84.986,45.805)(86.000,45.848)\n        \\qbezier(86.000,45.848)(86.986,45.890)(88.000,45.931)\n        \\qbezier(88.000,45.931)(88.986,45.970)(90.000,46.007)\n        \\qbezier(90.000,46.007)(90.986,46.043)(92.000,46.078)\n        \\qbezier(92.000,46.078)(92.986,46.112)(94.000,46.144)\n        \\qbezier(94.000,46.144)(94.987,46.175)(96.000,46.205)\n        \\qbezier(96.000,46.205)(96.987,46.234)(98.000,46.262)\n        \\qbezier(98.000,46.262)(98.987,46.289)(100.000,46.315)\n        \\put(10.000,0.000){\\Bfull}\n        \\put(20.000,23.532){\\Bfull}\n        \\put(30.000,34.488){\\Bfull}\n        \\put(40.000,39.540){\\Bfull}\n        \\put(50.000,42.265){\\Bfull}\n        \\put(60.000,43.880){\\Bfull}\n        \\put(70.000,44.895){\\Bfull}\n        \\put(80.000,45.559){\\Bfull}\n        \\put(90.000,46.007){\\Bfull}\n        \\put(100.000,46.315){\\Bfull}\n    }\n    \\put(000,000){\\color{red}\n        \\qbezier(10.000,-0.000)(11.345,0.000)(12.000,0.901)\n        \\qbezier(12.000,0.901)(12.523,1.621)(14.000,4.469)\n        \\qbezier(14.000,4.469)(15.186,6.754)(16.000,8.156)\n        \\qbezier(16.000,8.156)(16.995,9.871)(18.000,11.308)\n        \\qbezier(18.000,11.308)(18.970,12.696)(20.000,13.904)\n        \\qbezier(20.000,13.904)(20.963,15.033)(22.000,16.030)\n        \\qbezier(22.000,16.030)(22.962,16.955)(24.000,17.778)\n        \\qbezier(24.000,17.778)(24.963,18.542)(26.000,19.225)\n        \\qbezier(26.000,19.225)(26.964,19.860)(28.000,20.430)\n        \\qbezier(28.000,20.430)(28.965,20.961)(30.000,21.441)\n        \\qbezier(30.000,21.441)(30.967,21.888)(32.000,22.294)\n        \\qbezier(32.000,22.294)(32.968,22.673)(34.000,23.018)\n        \\qbezier(34.000,23.018)(34.969,23.341)(36.000,23.635)\n        \\qbezier(36.000,23.635)(36.970,23.912)(38.000,24.165)\n        \\qbezier(38.000,24.165)(38.971,24.403)(40.000,24.620)\n        \\qbezier(40.000,24.620)(40.972,24.826)(42.000,25.014)\n        \\qbezier(42.000,25.014)(42.973,25.191)(44.000,25.354)\n        \\qbezier(44.000,25.354)(44.974,25.509)(46.000,25.650)\n        \\qbezier(46.000,25.650)(46.974,25.785)(48.000,25.908)\n        \\qbezier(48.000,25.908)(48.975,26.026)(50.000,26.134)\n        \\qbezier(50.000,26.134)(50.976,26.236)(52.000,26.331)\n        \\qbezier(52.000,26.331)(52.976,26.421)(54.000,26.503)\n        \\qbezier(54.000,26.503)(54.977,26.582)(56.000,26.655)\n        \\qbezier(56.000,26.655)(56.977,26.724)(58.000,26.788)\n        \\qbezier(58.000,26.788)(58.977,26.849)(60.000,26.906)\n        \\qbezier(60.000,26.906)(60.978,26.960)(62.000,27.009)\n        \\qbezier(62.000,27.009)(62.978,27.057)(64.000,27.100)\n        \\qbezier(64.000,27.100)(64.978,27.142)(66.000,27.181)\n        \\qbezier(66.000,27.181)(66.979,27.218)(68.000,27.252)\n        \\qbezier(68.000,27.252)(68.979,27.285)(70.000,27.315)\n        \\qbezier(70.000,27.315)(70.979,27.344)(72.000,27.371)\n        \\qbezier(72.000,27.371)(72.979,27.396)(74.000,27.420)\n        \\qbezier(74.000,27.420)(74.979,27.443)(76.000,27.464)\n        \\qbezier(76.000,27.464)(76.979,27.484)(78.000,27.502)\n        \\qbezier(78.000,27.502)(78.979,27.520)(80.000,27.537)\n        \\qbezier(80.000,27.537)(80.980,27.552)(82.000,27.567)\n        \\qbezier(82.000,27.567)(82.980,27.581)(84.000,27.594)\n        \\qbezier(84.000,27.594)(84.980,27.606)(86.000,27.618)\n        \\qbezier(86.000,27.618)(86.980,27.629)(88.000,27.639)\n        \\qbezier(88.000,27.639)(88.980,27.649)(90.000,27.658)\n        \\qbezier(90.000,27.658)(90.980,27.666)(92.000,27.675)\n        \\qbezier(92.000,27.675)(92.980,27.682)(94.000,27.689)\n        \\qbezier(94.000,27.689)(94.980,27.696)(96.000,27.702)\n        \\qbezier(96.000,27.702)(96.980,27.709)(98.000,27.714)\n        \\qbezier(98.000,27.714)(98.980,27.720)(100.000,27.724)\n        \\put(10.000,0.000){\\Bfull}\n        \\put(20.000,13.904){\\Bfull}\n        \\put(30.000,21.441){\\Bfull}\n        \\put(40.000,24.620){\\Bfull}\n        \\put(50.000,26.134){\\Bfull}\n        \\put(60.000,26.906){\\Bfull}\n        \\put(70.000,27.315){\\Bfull}\n        \\put(80.000,27.537){\\Bfull}\n        \\put(90.000,27.658){\\Bfull}\n        \\put(100.000,27.724){\\Bfull}\n    }\n    \\put(000,000){\\color{cyan}\n        \\qbezier(10.000,-0.000)(11.616,0.000)(12.000,0.093)\n        \\qbezier(12.000,0.093)(12.817,0.289)(14.000,1.232)\n        \\qbezier(14.000,1.232)(14.165,1.364)(16.000,2.936)\n        \\qbezier(16.000,2.936)(17.104,3.881)(18.000,4.556)\n        \\qbezier(18.000,4.556)(18.998,5.309)(20.000,5.935)\n        \\qbezier(20.000,5.935)(20.975,6.545)(22.000,7.067)\n        \\qbezier(22.000,7.067)(22.967,7.559)(24.000,7.983)\n        \\qbezier(24.000,7.983)(24.964,8.379)(26.000,8.722)\n        \\qbezier(26.000,8.722)(26.963,9.041)(28.000,9.318)\n        \\qbezier(28.000,9.318)(28.963,9.576)(30.000,9.800)\n        \\qbezier(30.000,9.800)(30.963,10.008)(32.000,10.189)\n        \\qbezier(32.000,10.189)(32.964,10.357)(34.000,10.504)\n        \\qbezier(34.000,10.504)(34.964,10.641)(36.000,10.760)\n        \\qbezier(36.000,10.760)(36.965,10.871)(38.000,10.967)\n        \\qbezier(38.000,10.967)(38.965,11.057)(40.000,11.136)\n        \\qbezier(40.000,11.136)(40.965,11.209)(42.000,11.273)\n        \\qbezier(42.000,11.273)(42.965,11.333)(44.000,11.385)\n        \\qbezier(44.000,11.385)(44.966,11.433)(46.000,11.476)\n        \\qbezier(46.000,11.476)(46.966,11.515)(48.000,11.550)\n        \\qbezier(48.000,11.550)(48.966,11.582)(50.000,11.610)\n        \\qbezier(50.000,11.610)(50.966,11.636)(52.000,11.659)\n        \\qbezier(52.000,11.659)(52.966,11.680)(54.000,11.698)\n        \\qbezier(54.000,11.698)(54.966,11.716)(56.000,11.731)\n        \\qbezier(56.000,11.731)(56.966,11.745)(58.000,11.757)\n        \\qbezier(58.000,11.757)(58.966,11.768)(60.000,11.778)\n        \\qbezier(60.000,11.778)(60.966,11.788)(62.000,11.796)\n        \\qbezier(62.000,11.796)(62.965,11.803)(64.000,11.810)\n        \\qbezier(64.000,11.810)(64.965,11.816)(66.000,11.821)\n        \\qbezier(66.000,11.821)(66.965,11.826)(68.000,11.831)\n        \\qbezier(68.000,11.831)(68.965,11.835)(70.000,11.838)\n        \\qbezier(70.000,11.838)(70.965,11.841)(72.000,11.844)\n        \\qbezier(72.000,11.844)(72.965,11.847)(74.000,11.849)\n        \\qbezier(74.000,11.849)(74.965,11.851)(76.000,11.853)\n        \\qbezier(76.000,11.853)(76.965,11.855)(78.000,11.857)\n        \\qbezier(78.000,11.857)(78.965,11.858)(80.000,11.859)\n        \\qbezier(80.000,11.859)(80.965,11.860)(82.000,11.861)\n        \\qbezier(82.000,11.861)(82.965,11.862)(84.000,11.863)\n        \\qbezier(84.000,11.863)(84.965,11.864)(86.000,11.865)\n        \\qbezier(86.000,11.865)(86.965,11.865)(88.000,11.866)\n        \\qbezier(88.000,11.866)(88.965,11.866)(90.000,11.867)\n        \\qbezier(90.000,11.867)(90.965,11.867)(92.000,11.868)\n        \\qbezier(92.000,11.868)(92.965,11.868)(94.000,11.868)\n        \\qbezier(94.000,11.868)(94.966,11.868)(96.000,11.869)\n        \\qbezier(96.000,11.869)(96.966,11.869)(98.000,11.869)\n        \\qbezier(98.000,11.869)(98.965,11.869)(100.000,11.869)\n        \\put(10.000,0.000){\\Bfull}\n        \\put(20.000,5.935){\\Bfull}\n        \\put(30.000,9.800){\\Bfull}\n        \\put(40.000,11.136){\\Bfull}\n        \\put(50.000,11.610){\\Bfull}\n        \\put(60.000,11.778){\\Bfull}\n        \\put(70.000,11.838){\\Bfull}\n        \\put(80.000,11.859){\\Bfull}\n        \\put(90.000,11.867){\\Bfull}\n        \\put(100.000,11.869){\\Bfull}\n    }\n}\n\\caption{Mapping $\\x \\mapsto \\Rate_0(\\omega,\\x)$ over\nthe domain $(1,\\infty)$ for $q = 2$ and several values of $\\omega$.}\n\\label{fig:q=2,omega}\n\\end{figure*}\n\n\\begin{figure*}[hbt]\n%% Maximum values of \\x \\mapsto (\\x/(\\x-1)) R_0(\\omega,\\x):\n%% omega = 0.01  mu = 7.6\n%% omega = 0.02  mu = 6.8\n%% omega = 0.03  mu = 6.4\n%% omega = 0.04  mu = 6.0\n%% omega = 0.05  mu = 5.8\n%% omega = 0.12  mu = 4.8\n%% omega = 0.20  mu = 4.2\n%% omega = 0.30  mu = 3.6\n%% omega = 0.40  mu = 3.2\n%% q = 2, omega = 0.00, 0.01, 0.05, 0.12, 0.20, 0.30, 0.40:\n\\PlotRo{%\n    \\put(000,114){\\makebox(0,0){$(\\x/(\\x{-}1)\\cdot\\Rate_0(\\omega,\\x)$}}\n    \\put(100,000){%\n        \\put(000,102){\\makebox(0,0)[r]{$\\omega = 0.00$}}\n        \\put(000,096){\\makebox(0,0)[r]{$\\omega = 0.01$}}\n        \\put(000,078){\\makebox(0,0)[r]{$\\omega = 0.05$}}\n        \\put(000,054){\\makebox(0,0)[r]{$\\omega = 0.12$}}\n        \\put(000,033){\\makebox(0,0)[r]{$\\omega = 0.20$}}\n        \\put(000,015.5){\\makebox(0,0)[r]{$\\omega = 0.30$}}\n        \\put(000,005.5){\\makebox(0,0)[r]{$\\omega = 0.40$}}\n    }\n    \\put(000,000){\\color{gray}\n\t\\put(10.000,000.00){\\line(0,1){100}}\n\t\\put(10.000,100.00){\\line(1,0){090}}\n    }\n    \\put(000,000){\\color{yellow}\n        %%\\qbezier(10.010,-0.001)(11.005,41.346)(12.000,82.693)\n        \\qbezier(10.000,0.000)(11.005,41.346)(12.000,82.693)\n        \\qbezier(12.000,82.693)(12.699,86.233)(14.000,88.166)\n        \\qbezier(14.000,88.166)(14.815,89.377)(16.000,90.207)\n        \\qbezier(16.000,90.207)(16.866,90.814)(18.000,91.272)\n        \\qbezier(18.000,91.272)(18.895,91.633)(20.000,91.921)\n        \\qbezier(20.000,91.921)(20.913,92.158)(22.000,92.354)\n        \\qbezier(22.000,92.354)(22.925,92.520)(24.000,92.660)\n        \\qbezier(24.000,92.660)(24.935,92.782)(26.000,92.887)\n        \\qbezier(26.000,92.887)(26.942,92.979)(28.000,93.059)\n        \\qbezier(28.000,93.059)(28.948,93.131)(30.000,93.193)\n        \\qbezier(30.000,93.193)(30.952,93.250)(32.000,93.300)\n        \\qbezier(32.000,93.300)(32.956,93.346)(34.000,93.386)\n        \\qbezier(34.000,93.386)(34.959,93.423)(36.000,93.456)\n        \\qbezier(36.000,93.456)(36.962,93.486)(38.000,93.514)\n        \\qbezier(38.000,93.514)(38.964,93.539)(40.000,93.561)\n        \\qbezier(40.000,93.561)(40.966,93.582)(42.000,93.601)\n        \\qbezier(42.000,93.601)(42.968,93.619)(44.000,93.635)\n        \\qbezier(44.000,93.635)(44.969,93.649)(46.000,93.663)\n        \\qbezier(46.000,93.663)(46.971,93.675)(48.000,93.686)\n        \\qbezier(48.000,93.686)(48.972,93.697)(50.000,93.706)\n        \\qbezier(50.000,93.706)(50.973,93.715)(52.000,93.723)\n        \\qbezier(52.000,93.723)(52.974,93.730)(54.000,93.737)\n        \\qbezier(54.000,93.737)(54.975,93.743)(56.000,93.749)\n        \\qbezier(56.000,93.749)(56.976,93.754)(58.000,93.758)\n        \\qbezier(58.000,93.758)(58.977,93.763)(60.000,93.766)\n        \\qbezier(60.000,93.766)(60.977,93.770)(62.000,93.773)\n        \\qbezier(62.000,93.773)(62.978,93.776)(64.000,93.778)\n        \\qbezier(64.000,93.778)(64.979,93.780)(66.000,93.782)\n        \\qbezier(66.000,93.782)(66.980,93.784)(68.000,93.785)\n        \\qbezier(68.000,93.785)(68.980,93.787)(70.000,93.787)\n        \\qbezier(70.000,93.787)(70.980,93.788)(72.000,93.789)\n        \\qbezier(72.000,93.789)(72.980,93.789)(74.000,93.790)\n        \\qbezier(74.000,93.790)(74.980,93.790)(76.000,93.790)\n        \\qbezier(76.000,93.790)(76.980,93.790)(78.000,93.789)\n        \\qbezier(78.000,93.789)(78.980,93.789)(80.000,93.789)\n        \\qbezier(80.000,93.789)(80.982,93.788)(82.000,93.787)\n        \\qbezier(82.000,93.787)(82.981,93.787)(84.000,93.786)\n        \\qbezier(84.000,93.786)(84.980,93.785)(86.000,93.784)\n        \\qbezier(86.000,93.784)(86.979,93.783)(88.000,93.781)\n        \\qbezier(88.000,93.781)(88.981,93.780)(90.000,93.779)\n        \\qbezier(90.000,93.779)(90.981,93.777)(92.000,93.776)\n        \\qbezier(92.000,93.776)(92.979,93.774)(94.000,93.773)\n        \\qbezier(94.000,93.773)(94.980,93.771)(96.000,93.769)\n        \\qbezier(96.000,93.769)(96.982,93.768)(98.000,93.766)\n        \\qbezier(98.000,93.766)(100.000,93.763)(100.000,93.762)\n    }\n    \\put(000,000){\\color{green}\n        %%\\qbezier(10.000,-0.013)(11.005,23.993)(12.000,47.998)\n        \\qbezier(10.000,0.000)(11.005,23.993)(12.000,47.998)\n        \\qbezier(12.000,47.998)(12.736,56.350)(14.000,61.217)\n        \\qbezier(14.000,61.217)(14.829,64.408)(16.000,66.638)\n        \\qbezier(16.000,66.638)(16.873,68.300)(18.000,69.559)\n        \\qbezier(18.000,69.559)(18.899,70.564)(20.000,71.360)\n        \\qbezier(20.000,71.360)(20.915,72.022)(22.000,72.562)\n        \\qbezier(22.000,72.562)(22.927,73.024)(24.000,73.408)\n        \\qbezier(24.000,73.408)(24.936,73.743)(26.000,74.025)\n        \\qbezier(26.000,74.025)(26.942,74.275)(28.000,74.488)\n        \\qbezier(28.000,74.488)(28.948,74.678)(30.000,74.841)\n        \\qbezier(30.000,74.841)(30.952,74.988)(32.000,75.114)\n        \\qbezier(32.000,75.114)(32.955,75.230)(34.000,75.329)\n        \\qbezier(34.000,75.329)(34.958,75.419)(36.000,75.497)\n        \\qbezier(36.000,75.497)(36.961,75.569)(38.000,75.630)\n        \\qbezier(38.000,75.630)(38.963,75.687)(40.000,75.736)\n        \\qbezier(40.000,75.736)(40.965,75.780)(42.000,75.818)\n        \\qbezier(42.000,75.818)(42.966,75.854)(44.000,75.883)\n        \\qbezier(44.000,75.883)(44.968,75.911)(46.000,75.933)\n        \\qbezier(46.000,75.933)(46.969,75.954)(48.000,75.971)\n        \\qbezier(48.000,75.971)(48.970,75.986)(50.000,75.998)\n        \\qbezier(50.000,75.998)(50.971,76.009)(52.000,76.017)\n        \\qbezier(52.000,76.017)(52.972,76.025)(54.000,76.029)\n        \\qbezier(54.000,76.029)(54.972,76.034)(56.000,76.035)\n        \\qbezier(56.000,76.035)(56.973,76.037)(58.000,76.036)\n        \\qbezier(58.000,76.036)(58.973,76.035)(60.000,76.033)\n        \\qbezier(60.000,76.033)(60.974,76.030)(62.000,76.026)\n        \\qbezier(62.000,76.026)(62.974,76.021)(64.000,76.015)\n        \\qbezier(64.000,76.015)(64.974,76.010)(66.000,76.003)\n        \\qbezier(66.000,76.003)(66.974,75.996)(68.000,75.987)\n        \\qbezier(68.000,75.987)(68.974,75.979)(70.000,75.970)\n        \\qbezier(70.000,75.970)(70.975,75.961)(72.000,75.951)\n        \\qbezier(72.000,75.951)(72.974,75.942)(74.000,75.931)\n        \\qbezier(74.000,75.931)(74.974,75.921)(76.000,75.909)\n        \\qbezier(76.000,75.909)(76.973,75.899)(78.000,75.887)\n        \\qbezier(78.000,75.887)(78.973,75.875)(80.000,75.863)\n        \\qbezier(80.000,75.863)(80.972,75.852)(82.000,75.839)\n        \\qbezier(82.000,75.839)(82.971,75.827)(84.000,75.814)\n        \\qbezier(84.000,75.814)(84.969,75.802)(86.000,75.788)\n        \\qbezier(86.000,75.788)(86.968,75.776)(88.000,75.762)\n        \\qbezier(88.000,75.762)(88.966,75.750)(90.000,75.736)\n        \\qbezier(90.000,75.736)(90.963,75.723)(92.000,75.709)\n        \\qbezier(92.000,75.709)(92.961,75.696)(94.000,75.682)\n        \\qbezier(94.000,75.682)(94.953,75.669)(96.000,75.655)\n        \\qbezier(96.000,75.655)(96.945,75.642)(98.000,75.628)\n        \\qbezier(98.000,75.628)(100.000,75.601)(100.000,75.601)\n    }\n    \\put(000,000){\\color{blue}\n        %%\\qbezier(10.010,-0.033)(10.247,-0.033)(12.000,19.106)\n        \\qbezier(10.000,0.000)(10.247,0.000)(12.000,19.106)\n        \\qbezier(12.000,19.106)(12.824,28.099)(14.000,33.701)\n        \\qbezier(14.000,33.701)(14.853,37.763)(16.000,40.663)\n        \\qbezier(16.000,40.663)(16.884,42.899)(18.000,44.599)\n        \\qbezier(18.000,44.599)(18.905,45.977)(20.000,47.064)\n        \\qbezier(20.000,47.064)(20.919,47.976)(22.000,48.711)\n        \\qbezier(22.000,48.711)(22.929,49.343)(24.000,49.859)\n        \\qbezier(24.000,49.859)(24.937,50.311)(26.000,50.683)\n        \\qbezier(26.000,50.683)(26.943,51.013)(28.000,51.285)\n        \\qbezier(28.000,51.285)(28.948,51.530)(30.000,51.731)\n        \\qbezier(30.000,51.731)(30.951,51.914)(32.000,52.064)\n        \\qbezier(32.000,52.064)(32.954,52.200)(34.000,52.311)\n        \\qbezier(34.000,52.311)(34.957,52.412)(36.000,52.493)\n        \\qbezier(36.000,52.493)(36.959,52.568)(38.000,52.626)\n        \\qbezier(38.000,52.626)(38.961,52.680)(40.000,52.720)\n        \\qbezier(40.000,52.720)(40.962,52.757)(42.000,52.782)\n        \\qbezier(42.000,52.782)(42.964,52.806)(44.000,52.821)\n        \\qbezier(44.000,52.821)(44.965,52.834)(46.000,52.839)\n        \\qbezier(46.000,52.839)(46.965,52.844)(48.000,52.842)\n        \\qbezier(48.000,52.842)(48.966,52.840)(50.000,52.832)\n        \\qbezier(50.000,52.832)(50.966,52.824)(52.000,52.811)\n        \\qbezier(52.000,52.811)(52.966,52.798)(54.000,52.781)\n        \\qbezier(54.000,52.781)(54.966,52.765)(56.000,52.745)\n        \\qbezier(56.000,52.745)(56.966,52.726)(58.000,52.702)\n        \\qbezier(58.000,52.702)(58.965,52.681)(60.000,52.656)\n        \\qbezier(60.000,52.656)(60.964,52.632)(62.000,52.605)\n        \\qbezier(62.000,52.605)(62.963,52.580)(64.000,52.551)\n        \\qbezier(64.000,52.551)(64.961,52.525)(66.000,52.495)\n        \\qbezier(66.000,52.495)(66.957,52.468)(68.000,52.437)\n        \\qbezier(68.000,52.437)(68.953,52.409)(70.000,52.377)\n        \\qbezier(70.000,52.377)(70.946,52.349)(72.000,52.316)\n        \\qbezier(72.000,52.316)(72.935,52.288)(74.000,52.255)\n        \\qbezier(74.000,52.255)(74.914,52.227)(76.000,52.193)\n        \\qbezier(76.000,52.193)(76.860,52.166)(78.000,52.130)\n        \\qbezier(78.000,52.130)(78.468,52.116)(80.000,52.068)\n        \\qbezier(80.000,52.068)(81.232,52.029)(82.000,52.005)\n        \\qbezier(82.000,52.005)(83.087,51.971)(84.000,51.943)\n        \\qbezier(84.000,51.943)(85.050,51.910)(86.000,51.881)\n        \\qbezier(86.000,51.881)(87.033,51.849)(88.000,51.819)\n        \\qbezier(88.000,51.819)(89.023,51.788)(90.000,51.758)\n        \\qbezier(90.000,51.758)(91.018,51.727)(92.000,51.697)\n        \\qbezier(92.000,51.697)(93.013,51.667)(94.000,51.637)\n        \\qbezier(94.000,51.637)(95.010,51.607)(96.000,51.578)\n        \\qbezier(96.000,51.578)(97.008,51.548)(98.000,51.519)\n        \\qbezier(98.000,51.519)(99.000,51.490)(100.000,51.461)\n    }\n    \\put(000,000){\\color{red}\n        %%\\qbezier(10.010,-0.057)(11.089,-0.057)(12.000,5.409)\n        \\qbezier(10.000,0.000)(11.089,0.000)(12.000,5.409)\n        \\qbezier(12.000,5.409)(13.134,12.215)(14.000,15.640)\n        \\qbezier(14.000,15.640)(14.896,19.182)(16.000,21.751)\n        \\qbezier(16.000,21.751)(16.901,23.846)(18.000,25.443)\n        \\qbezier(18.000,25.443)(18.913,26.770)(20.000,27.807)\n        \\qbezier(20.000,27.807)(20.924,28.689)(22.000,29.388)\n        \\qbezier(22.000,29.388)(22.932,29.994)(24.000,30.477)\n        \\qbezier(24.000,30.477)(24.938,30.901)(26.000,31.240)\n        \\qbezier(26.000,31.240)(26.943,31.541)(28.000,31.780)\n        \\qbezier(28.000,31.780)(28.947,31.994)(30.000,32.161)\n        \\qbezier(30.000,32.161)(30.950,32.312)(32.000,32.427)\n        \\qbezier(32.000,32.427)(32.952,32.532)(34.000,32.608)\n        \\qbezier(34.000,32.608)(34.954,32.678)(36.000,32.726)\n        \\qbezier(36.000,32.726)(36.956,32.769)(38.000,32.795)\n        \\qbezier(38.000,32.795)(38.957,32.818)(40.000,32.827)\n        \\qbezier(40.000,32.827)(40.957,32.835)(42.000,32.830)\n        \\qbezier(42.000,32.830)(42.957,32.826)(44.000,32.811)\n        \\qbezier(44.000,32.811)(44.957,32.798)(46.000,32.776)\n        \\qbezier(46.000,32.776)(46.956,32.755)(48.000,32.726)\n        \\qbezier(48.000,32.726)(48.955,32.700)(50.000,32.667)\n        \\qbezier(50.000,32.667)(50.953,32.637)(52.000,32.600)\n        \\qbezier(52.000,32.600)(52.949,32.567)(54.000,32.527)\n        \\qbezier(54.000,32.527)(54.943,32.491)(56.000,32.450)\n        \\qbezier(56.000,32.450)(56.934,32.413)(58.000,32.369)\n        \\qbezier(58.000,32.369)(58.917,32.332)(60.000,32.287)\n        \\qbezier(60.000,32.287)(60.878,32.250)(62.000,32.203)\n        \\qbezier(62.000,32.203)(62.709,32.173)(64.000,32.119)\n        \\qbezier(64.000,32.119)(65.410,32.060)(66.000,32.035)\n        \\qbezier(66.000,32.035)(67.103,31.988)(68.000,31.951)\n        \\qbezier(68.000,31.951)(69.053,31.907)(70.000,31.868)\n        \\qbezier(70.000,31.868)(71.033,31.825)(72.000,31.785)\n        \\qbezier(72.000,31.785)(73.022,31.744)(74.000,31.704)\n        \\qbezier(74.000,31.704)(75.015,31.664)(76.000,31.625)\n        \\qbezier(76.000,31.625)(77.011,31.585)(78.000,31.547)\n        \\qbezier(78.000,31.547)(79.008,31.508)(80.000,31.470)\n        \\qbezier(80.000,31.470)(81.005,31.432)(82.000,31.396)\n        \\qbezier(82.000,31.396)(83.003,31.359)(84.000,31.323)\n        \\qbezier(84.000,31.323)(85.002,31.287)(86.000,31.252)\n        \\qbezier(86.000,31.252)(87.001,31.217)(88.000,31.182)\n        \\qbezier(88.000,31.182)(89.000,31.148)(90.000,31.115)\n        \\qbezier(90.000,31.115)(90.999,31.082)(92.000,31.049)\n        \\qbezier(92.000,31.049)(92.998,31.017)(94.000,30.986)\n        \\qbezier(94.000,30.986)(94.998,30.954)(96.000,30.924)\n        \\qbezier(96.000,30.924)(96.997,30.893)(98.000,30.863)\n        \\qbezier(98.000,30.863)(99.000,30.834)(100.000,30.805)\n    }\n    \\put(000,000){\\color{cyan}\n        %%\\qbezier(10.010,-0.087)(11.470,-0.087)(12.000,0.555)\n        \\qbezier(10.100,0.000)(11.535,0.000)(12.000,0.555)\n        \\qbezier(12.000,0.555)(12.350,0.979)(14.000,4.313)\n        \\qbezier(14.000,4.313)(15.047,6.428)(16.000,7.828)\n        \\qbezier(16.000,7.828)(16.941,9.210)(18.000,10.252)\n        \\qbezier(18.000,10.252)(18.931,11.168)(20.000,11.871)\n        \\qbezier(20.000,11.871)(20.932,12.484)(22.000,12.956)\n        \\qbezier(22.000,12.956)(22.936,13.369)(24.000,13.685)\n        \\qbezier(24.000,13.685)(24.939,13.964)(26.000,14.174)\n        \\qbezier(26.000,14.174)(26.942,14.360)(28.000,14.495)\n        \\qbezier(28.000,14.495)(28.944,14.616)(30.000,14.700)\n        \\qbezier(30.000,14.700)(30.945,14.774)(32.000,14.820)\n        \\qbezier(32.000,14.820)(32.946,14.862)(34.000,14.881)\n        \\qbezier(34.000,14.881)(34.945,14.898)(36.000,14.898)\n        \\qbezier(36.000,14.898)(36.944,14.898)(38.000,14.884)\n        \\qbezier(38.000,14.884)(38.942,14.872)(40.000,14.848)\n        \\qbezier(40.000,14.848)(40.938,14.827)(42.000,14.796)\n        \\qbezier(42.000,14.796)(42.932,14.769)(44.000,14.733)\n        \\qbezier(44.000,14.733)(44.920,14.702)(46.000,14.663)\n        \\qbezier(46.000,14.663)(46.897,14.631)(48.000,14.589)\n        \\qbezier(48.000,14.589)(48.834,14.557)(50.000,14.512)\n        \\qbezier(50.000,14.512)(50.114,14.508)(52.000,14.434)\n        \\qbezier(52.000,14.434)(53.181,14.389)(54.000,14.357)\n        \\qbezier(54.000,14.357)(55.067,14.316)(56.000,14.281)\n        \\qbezier(56.000,14.281)(57.035,14.242)(58.000,14.206)\n        \\qbezier(58.000,14.206)(59.020,14.169)(60.000,14.134)\n        \\qbezier(60.000,14.134)(61.011,14.098)(62.000,14.064)\n        \\qbezier(62.000,14.064)(63.006,14.030)(64.000,13.997)\n        \\qbezier(64.000,13.997)(65.002,13.964)(66.000,13.932)\n        \\qbezier(66.000,13.932)(66.999,13.901)(68.000,13.870)\n        \\qbezier(68.000,13.870)(68.997,13.840)(70.000,13.811)\n        \\qbezier(70.000,13.811)(70.995,13.782)(72.000,13.755)\n        \\qbezier(72.000,13.755)(72.994,13.727)(74.000,13.701)\n        \\qbezier(74.000,13.701)(74.993,13.675)(76.000,13.649)\n        \\qbezier(76.000,13.649)(76.992,13.624)(78.000,13.600)\n        \\qbezier(78.000,13.600)(78.992,13.576)(80.000,13.553)\n        \\qbezier(80.000,13.553)(80.991,13.531)(82.000,13.509)\n        \\qbezier(82.000,13.509)(82.991,13.487)(84.000,13.466)\n        \\qbezier(84.000,13.466)(84.991,13.446)(86.000,13.426)\n        \\qbezier(86.000,13.426)(86.991,13.406)(88.000,13.387)\n        \\qbezier(88.000,13.387)(88.990,13.368)(90.000,13.350)\n        \\qbezier(90.000,13.350)(90.990,13.332)(92.000,13.315)\n        \\qbezier(92.000,13.315)(92.990,13.298)(94.000,13.281)\n        \\qbezier(94.000,13.281)(94.990,13.265)(96.000,13.249)\n        \\qbezier(96.000,13.249)(96.990,13.233)(98.000,13.218)\n        \\qbezier(98.000,13.218)(99.000,13.203)(100.000,13.188)\n    }\n    \\put(000,000){\\color{black}\n        %%\\qbezier(10.010,-0.116)(11.005,-0.054)(12.000,0.009)\n        \\qbezier(10.000,0.000)(11.000,0.000)(12.000,0.009)\n        \\qbezier(12.000,0.009)(13.008,0.046)(14.000,0.451)\n        \\qbezier(14.000,0.451)(14.255,0.555)(16.000,1.397)\n        \\qbezier(16.000,1.397)(17.092,1.924)(18.000,2.268)\n        \\qbezier(18.000,2.268)(18.973,2.636)(20.000,2.905)\n        \\qbezier(20.000,2.905)(20.949,3.154)(22.000,3.334)\n        \\qbezier(22.000,3.334)(22.940,3.495)(24.000,3.607)\n        \\qbezier(24.000,3.607)(24.937,3.707)(26.000,3.772)\n        \\qbezier(26.000,3.772)(26.934,3.830)(28.000,3.863)\n        \\qbezier(28.000,3.863)(28.930,3.892)(30.000,3.904)\n        \\qbezier(30.000,3.904)(30.926,3.914)(32.000,3.911)\n        \\qbezier(32.000,3.911)(32.919,3.909)(34.000,3.898)\n        \\qbezier(34.000,3.898)(34.907,3.889)(36.000,3.872)\n        \\qbezier(36.000,3.872)(36.885,3.859)(38.000,3.839)\n        \\qbezier(38.000,3.839)(38.828,3.824)(40.000,3.802)\n        \\qbezier(40.000,3.802)(40.346,3.795)(42.000,3.763)\n        \\qbezier(42.000,3.763)(43.188,3.740)(44.000,3.725)\n        \\qbezier(44.000,3.725)(45.057,3.705)(46.000,3.688)\n        \\qbezier(46.000,3.688)(47.022,3.670)(48.000,3.653)\n        \\qbezier(48.000,3.653)(49.007,3.636)(50.000,3.620)\n        \\qbezier(50.000,3.620)(50.999,3.604)(52.000,3.589)\n        \\qbezier(52.000,3.589)(52.993,3.574)(54.000,3.560)\n        \\qbezier(54.000,3.560)(54.990,3.546)(56.000,3.533)\n        \\qbezier(56.000,3.533)(56.988,3.520)(58.000,3.507)\n        \\qbezier(58.000,3.507)(58.987,3.496)(60.000,3.484)\n        \\qbezier(60.000,3.484)(60.986,3.473)(62.000,3.462)\n        \\qbezier(62.000,3.462)(62.985,3.452)(64.000,3.442)\n        \\qbezier(64.000,3.442)(64.985,3.432)(66.000,3.423)\n        \\qbezier(66.000,3.423)(66.985,3.414)(68.000,3.405)\n        \\qbezier(68.000,3.405)(68.985,3.397)(70.000,3.389)\n        \\qbezier(70.000,3.389)(70.985,3.381)(72.000,3.373)\n        \\qbezier(72.000,3.373)(72.985,3.366)(74.000,3.359)\n        \\qbezier(74.000,3.359)(74.985,3.352)(76.000,3.345)\n        \\qbezier(76.000,3.345)(76.986,3.338)(78.000,3.332)\n        \\qbezier(78.000,3.332)(78.986,3.326)(80.000,3.320)\n        \\qbezier(80.000,3.320)(80.986,3.314)(82.000,3.308)\n        \\qbezier(82.000,3.308)(82.987,3.303)(84.000,3.297)\n        \\qbezier(84.000,3.297)(84.987,3.292)(86.000,3.287)\n        \\qbezier(86.000,3.287)(86.987,3.282)(88.000,3.277)\n        \\qbezier(88.000,3.277)(88.987,3.273)(90.000,3.268)\n        \\qbezier(90.000,3.268)(90.988,3.264)(92.000,3.259)\n        \\qbezier(92.000,3.259)(92.988,3.255)(94.000,3.251)\n        \\qbezier(94.000,3.251)(94.988,3.247)(96.000,3.243)\n        \\qbezier(96.000,3.243)(96.989,3.239)(98.000,3.235)\n        \\qbezier(98.000,3.235)(99.000,3.231)(100.000,3.228)\n    }\n}\n\\caption{Mapping $\\x \\mapsto (\\x/(\\x{-}1)) \\cdot \\Rate_0(\\omega,\\x)$\nover the domain $(1,\\infty)$\nfor $q = 2$ and several values of $\\omega$.}\n\\label{fig:q=2,omega,pi1>0}\n\\end{figure*}", "meta": {"timestamp": "2020-10-28T00:31:58", "yymm": "2010", "arxiv_id": "2010.14492", "url": "https://arxiv.org/abs/2010.14492", "source": "arxiv"}}
{"text": "\\documentclass[11pt]{article}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\date{}\r\n\r\n\r\n\\usepackage{graphicx}\r\n\\usepackage{tabularx}\r\n\\usepackage{url}\r\n\\usepackage{amsthm}\r\n\\usepackage{amsmath}\r\n\\usepackage{amsfonts}\r\n\\usepackage{hyperref}\r\n\\usepackage{subcaption}\r\n\r\n\r\n\\usepackage{color}\r\n\\usepackage{xspace}\r\n\\usepackage{tikz}\r\n\\usetikzlibrary{decorations,decorations.pathmorphing,decorations.pathreplacing,fit,positioning,arrows}\r\n\r\n\\theoremstyle{plain}\r\n\\newtheorem{theorem}{Theorem}\r\n\\newtheorem{lemma}{Lemma}\r\n\\newtheorem{proposition}{Proposition}\r\n\\newtheorem{claim}{Claim}\r\n\\newtheorem{fact}{Fact}\r\n\\newtheorem{observation}{Observation}\r\n\\newtheorem{corollary}{Corollary}\r\n\\theoremstyle{definition}\r\n\\newtheorem{definition}{Definition}\r\n\\newtheorem{conjecture}{Conjecture}\r\n\\newtheorem{question}{Question}\r\n\\newtheorem{problem}{Open problem}\r\n\\newtheorem*{ex}{Example}\r\n\\theoremstyle{remark}\r\n\\newtheorem*{rem}{Remark}\r\n\\newtheorem*{note}{Note}\r\n\\newtheorem{case}{Case}\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\usepackage{graphicx}\r\n\\usepackage{tabularx}\r\n\\usepackage{url}\r\n%\\usepackage{amsthm}\r\n\\usepackage{amsmath}\r\n\\usepackage{amsfonts}\r\n\\usepackage{amssymb}\r\n\\usepackage{tikz}\r\n%\\usepackage{hyperref}\r\n%\\usepackage{makecell}\r\n\\usepackage{hhline}\r\n\\usepackage{array}\r\n\\usetikzlibrary{decorations.pathreplacing}\r\n\\usetikzlibrary{shapes}\r\n\\usetikzlibrary{shapes.multipart}\r\n\\tikzstyle{vertex}=[circle,fill=black!100,text=white,inner sep=0.8mm]\r\n\\tikzstyle{point}=[circle,fill=black,inner sep=0.1mm]\r\n\r\n\\DeclareMathOperator{\\cont}{cont}\r\n\\DeclareMathOperator{\\boxi}{box}\r\n\\DeclareMathOperator{\\Free}{Free}\r\n\\DeclareMathOperator{\\Sun}{Sun}\r\n\\DeclareMathOperator{\\size}{size}\r\n\r\n\r\n\r\n\\textheight=20.5cm\r\n\\topmargin=-1cm\r\n\\oddsidemargin=0.7cm\r\n\\textwidth=15.2cm\r\n\r\n\\begin{document}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\title{Critical properties of bipartite permutation graphs}\r\n\\author{Bogdan Alecu\\thanks{Mathematics Institute, University of Warwick, Coventry, CV4 7AL, UK. Email: B.Alecu@warwick.ac.uk} \\and\r\n\tVadim Lozin\\thanks{Mathematics Institute, University of Warwick, Coventry, CV4 7AL, UK. Email: V.Lozin@warwick.ac.uk} \\and\r\n\tDmitriy Malyshev\\thanks{Laboratory of Algorithms and Technologies for Networks Analysis, National Research University\r\nHigher School of Economics, 136 Rodionova Str., 603093, Nizhny Novgorod, Russia. Email: dsmalyshev@rambler.ru}$~^,$\\thanks{The work of Malyshev D.S. \r\nwas conducted within the framework of the Basic Research Program at the National Research University Higher School of Economics (HSE).}}\r\n\\maketitle\r\n\r\n\\begin{abstract}\r\nThe class of bipartite permutation graphs enjoys many nice and important properties.\r\nIn particular, this class is critically important in the study of clique- and rank-width of graphs, because it is one of the minimal hereditary classes\r\nof graphs of unbounded clique- and rank-width. It also contains a number of important subclasses, which are critical with respect to\r\nother parameters, such as graph lettericity or shrub-depth, and with respect to other notions, such as well-quasi-ordering or complexity of algorithmic problems.\r\nIn the present paper we identify critical subclasses of bipartite permutation graphs of various types.\r\n\\end{abstract}\r\n\r\n{\\it Keywords}: bipartite permutation graphs; well-quasi-ordering; universal graph\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\section{Introduction}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\nA {\\it graph property}, also known as a {\\it class of graphs}, is an infinite set of graphs closed under isomorphism.\r\nA property is {\\it hereditary} if it is closed under taking induced subgraphs. The universe of hereditary properties is\r\nrich and diverse, and it contains various classes of theoretical or practical importance, such as perfect graphs, interval graphs,\r\npermutation graphs, bipartite graphs, planar graphs, threshold graphs, split graphs, graphs of bounded vertex degree, graphs of bounded clique-width, etc. \r\nIt also contains all classes closed under taking subgraphs, minors, induced minors, vertex-minors, etc.\r\n\r\nA class of particular interest in this paper is the class of \\emph{bipartite permutation graphs}, i.e., graphs that are simultaneously\r\nbipartite and permutation graphs. This class was introduced by Spinrad, Brandst\\\"adt, and Stewart \\cite{BPG} in 1987\r\nand since then it appears frequently in the mathematical and computer science literature. Partly, this is because bipartite permutation\r\ngraphs have a nice structure allowing solutions to many problems that are notoriously difficult for general graphs. For instance:\r\n\\begin{itemize}\r\n\\item the reconstruction conjecture, which is wide open in general, holds true for bipartite permutation graphs \\cite{reconstruction};\r\n\\item many algorithmic problems that are generally NP-hard admit polynomial-time solutions when restricted to bipartite permutation graphs \\cite{buffer,weed};\r\n\\item bipartite permutation graphs have bounded contiguity, a complexity measure, which is important in biological applications \\cite{contiguity};\r\n\\item bipartite permutation graphs have a universal element of small order: there is a bipartite permutation graph with $n^2$ vertices containing all $n$-vertex bipartite permutation graphs as induced subgraphs.\r\n\\end{itemize}\r\nOn the other hand, in spite of the many attractive properties of bipartite permutation graphs, they represent a complex world. Indeed, in this world some algorithmic problems remain NP-hard,\r\nfor instance {\\sc induced subgraph isomorphism}, and some parameters that measure complexity of the graphs take arbitrarily large values, for instance clique-width.\r\nMoreover, the class of bipartite permutation graphs is critical with respect to clique-width in the sense that in every proper hereditary subclass of bipartite permutation graphs,\r\nclique-width is bounded by a constant \\cite{Loz11}. In other words, the class of bipartite permutation graphs is a minimal hereditary class of graphs of unbounded clique-width.\r\nThe same is true with respect to the notion of rank-width, because rank-width is bounded in a class of graphs if and only of clique-width is. Moreover, in the terminology of \r\nvertex-minors, bipartite permutation graphs constitute the {\\it only} obstacle to bounding rank-width of bipartite graphs, because every bipartite graph of large rank-width \r\ncontains a large universal bipartite permutation graph as a vertex-minor, see Corollary 3.9 in \\cite{localcomp}.\r\n\r\nThis class, however, is not critical with respect to complexity of the  {\\sc induced subgraph isomorphism} problem, because\r\nthe problem remains NP-hard when further restricting to the class of linear forests, a proper subclass of bipartite permutation graphs. One of the results of the present paper\r\nis that the class of linear forests is a minimal hereditary class where the problem is NP-hard.\r\n\r\nIs it always possible to find minimal ``difficult'' classes? In the universe of minor-closed classes of graphs the answer to this question is `yes', because graphs are well-quasi-ordered\r\nunder the minor relation \\cite{minor-wqo}. In particular, in the family of minor-closed classes of graphs the planar graphs constitute a unique minimal class of unbounded tree-width \\cite{planar}.\r\nHowever, the induced subgraph relation is not a well-quasi-order, because it contains infinite antichains of graphs. As a result,\r\nthe universe of hereditary classes contains infinite strictly descending chains of classes. The intersection of all classes in such a chain is called a {\\it limit class} and\r\na minimal limit class is called a {\\it boundary class}.\r\nUnfortunately, limit classes can be found even within bipartite permutation graphs. On the other hand, fortunately, there is only one boundary class in this universe, as we show\r\nin the present paper. We also show that this unique boundary class is the only obstacle to finding minimal classes in the universe of bipartite permutation graphs.\r\n\r\nIn this paper, we study diverse problems and identify a variety of minimal ``difficult'' classes with respect to these problems.\r\nIn particular, in Section~\\ref{sec:wqo} we identify the unique boundary subclass of bipartite permutation graphs.\r\nSection~\\ref{sec:parameters} is devoted to graph parameters and minimal classes where these parameters are unbounded.\r\nIn Section~\\ref{sec:algo}, we  deal with algorithmic problems and prove that the linear forests constitute a minimal ``difficult'' classes for {\\sc induced subgraph isomorphism}.\r\nIn Section~\\ref{sec:uni}, we identify a minimal subclass of bipartite permutation graphs that do not admit a universal graph of linear order.\r\nVarious subclasses of bipartite permutation graphs that play an important role in this paper are presented in Section~\\ref{sec:bpg}. \r\n%In the rest of the current section, we introduce basic terminology and notation used in the paper.\r\n\r\nAll graphs in this paper are \\emph{simple}, i.e., finite, undirected, without loops and without multiple edges. The vertex set and the edge set of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.\r\n\r\nAs usual, $P_n,C_n,K_n$ denote the chordless path, the chordless cycle, and the complete graph with $n$ vertices, respectively.\r\nAlso, $K_{n,m}$ is the complete bipartite graphs with parts of size $n$ and $m$. By $S_{i,j,k}$, we denote the graph represented in Figure~\\ref{fig:S}.\r\n\r\n\\begin{figure}[ht]\r\n\\begin{center} \\begin{picture}(240,80)\r\n\\put(110,15){\\circle*{3}}\r\n\\put(110,26){\\circle*{3}}\r\n\\put(110,37){\\circle*{3}}\r\n\\put(110,55){\\circle*{3}}\r\n\\put(110,66){\\circle*{3}}\r\n\\put(110,42){\\circle*{1}}\r\n\\put(110,46){\\circle*{1}}\r\n\\put(110,50){\\circle*{1}}\r\n\\put(110,15){\\line(0,1){11}}\r\n\\put(110,26){\\line(0,1){11}}\r\n\\put(110,55){\\line(0,1){11}}\r\n\\put(100,10){\\circle*{3}}\r\n\\put(90,5){\\circle*{3}}\r\n\\put(70,-5){\\circle*{3}}\r\n\\put(60,-10){\\circle*{3}}\r\n\\put(85,2){\\circle*{1}}\r\n\\put(80,0){\\circle*{1}}\r\n\\put(75,-2){\\circle*{1}}\r\n\\put(110,15){\\line(-2,-1){10}}\r\n\\put(100,10){\\line(-2,-1){10}}\r\n\\put(70,-5){\\line(-2,-1){10}}\r\n\\put(120,10){\\circle*{3}}\r\n\\put(130,5){\\circle*{3}}\r\n\\put(150,-5){\\circle*{3}}\r\n\\put(160,-10){\\circle*{3}}\r\n\\put(135,2){\\circle*{1}}\r\n\\put(140,0){\\circle*{1}}\r\n\\put(145,-2){\\circle*{1}}\r\n\\put(110,15){\\line(2,-1){10}}\r\n\\put(120,10){\\line(2,-1){10}}\r\n\\put(150,-5){\\line(2,-1){10}}\r\n%\\put(104,5){(a)}\r\n\\put(113,26){$_1$}\r\n\\put(113,37){$_2$}\r\n\\put(113,55){$_{i-1}$}\r\n\\put(113,66){$_i$}\r\n\\put(98,3){$_1$}\r\n\\put(88,-2){$_2$}\r\n\\put(68,-12){$_{j-1}$}\r\n\\put(58,-17){$_j$}\r\n\\put(120,15){$_1$}\r\n\\put(130,10){$_2$}\r\n\\put(148,1){$_{k-1}$}\r\n\\put(162,-7){$_k$}\r\n%\\put(105,1){(a)}\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{The graph $S_{i,j,k}$ }\r\n\\label{fig:S}\r\n\\end{figure}\r\n\r\nThe disjoint union of two graphs $G_1$ and $G_2$ \r\n%with $V(G_1)\\cap V(G_2)=\\emptyset$ \r\nwill be denoted by $G_1+G_2$,\r\nand the disjoint union of $k$ copies of $G$ will be denoted by $kG$.\r\n\r\nAn {\\it induced subgraph} of a graph $G$ is a subgraph obtained from $G$ by a (possibly empty) sequence of vertex deletions.\r\nWe say that $G$ contains a graph $H$ as an induced subgraph if $H$ is isomorphic to an induced subgraph of $G$.\r\nOtherwise, we say that  $G$ is \\emph{$H$-free} \r\nand that $H$ is a forbidden induced subgraph for $G$. \r\n\r\nIt is well-known (and not difficult to see) that a class of graphs is hereditary if and only \r\nif it can be characterized by means of minimal forbidden induced subgraphs, i.e., graphs that do not belong to the class and which are minimal with this property (with respect to the induced subgraph relation).\r\nThe class containing no induced subgraphs from a set $M$ will be denoted $\\Free(M)$, and given graphs $G_1, G_2, \\dots$, we will write $\\Free(G_1, G_2, \\dots)$ to mean $\\Free(\\{G_1, G_2, \\dots\\})$.\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\section{Bipartite permutation graphs and their subclasses}\r\n\\label{sec:bpg}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\nThroughout the paper we denote the class of all bipartite permutation graphs by $\\cal BP$. \r\nThis class was introduced in \\cite{BPG} and also appeared in the literature under various other names such as \r\nproper interval bigraphs \\cite{Pavol}, monotone graphs \\cite{Haiko}, Parikh word representable graphs \\cite{Parikh}.\r\nThis class admits various characterizations, many of which can be found in \\cite{BPG}. \r\nFor the purpose of the present paper, we are interested in the induced subgraph characterization and the structure of \r\na `typical' graph in this class.\r\n\r\nIn terms of forbidden induced subgraphs the class of bipartite permutation graphs is precisely the class of\r\n$$\r\n(S_{2,2,2},\\Sun_3,\\Phi,C_3,C_5,C_6,C_7,\\ldots)\\mbox{-free graphs},\r\n$$\r\nwhere $\\Sun_3$ and $\\Phi$ are the graphs represented in Figure~\\ref{fig:Sun}.\r\n\\begin{figure}[ht]\r\n\\begin{center}\r\n\\begin{picture}(130,50)\r\n\\setlength{\\unitlength}{0.5mm}\r\n%\\put(20,30){\\circle*{3}}\r\n\\put(30,17){\\circle*{3}}\r\n\\put(40,17){\\circle*{3}}\r\n%\\put(50,0){\\circle*{3}}\r\n\\put(50,-3){\\circle*{3}}\r\n\\put(50,7){\\circle*{3}}\r\n\\put(50,27){\\circle*{3}}\r\n%\\put(50,37){\\circle*{3}}\r\n%\\put(50,60){\\circle*{3}}\r\n\\put(60,17){\\circle*{3}}\r\n\\put(70,17){\\circle*{3}}\r\n%\\put(80,30){\\circle*{3}}\r\n\\put(40,17){\\line(-1,0){10}}\r\n\\put(40,17){\\line(1,1){10}}\r\n\\put(40,17){\\line(1,-1){10}}\r\n\\put(60,17){\\line(1,0){10}}\r\n\\put(60,17){\\line(-1,1){10}}\r\n\\put(60,17){\\line(-1,-1){10}}\r\n\\put(50,-3){\\line(0,1){10}}\r\n%\\put(50,50){\\line(0,1){10}}\r\n%\\put(50,10){\\line(0,-1){10}}\r\n%\\put(50,-3){\\line(0,1){10}}\r\n\\end{picture}\r\n\\begin{picture}(130,50)\r\n\\setlength{\\unitlength}{0.5mm}\r\n\\put(60,30){\\circle*{3}}\r\n\\put(60,10){\\circle*{3}}\r\n\\put(80,30){\\circle*{3}}\r\n\\put(80,10){\\circle*{3}}\r\n\\put(100,30){\\circle*{3}}\r\n\\put(100,10){\\circle*{3}}\r\n\\put(80,-10){\\circle*{3}}\r\n\r\n\\put(60,30){\\line(1,0){20}}\r\n\\put(100,30){\\line(-1,0){20}}\r\n\\put(60,30){\\line(0,-1){20}}\r\n\\put(100,10){\\line(0,1){20}}\r\n\\put(80,10){\\line(0,-1){20}}\r\n\\put(80,10){\\line(0,1){20}}\r\n\\put(100,10){\\line(-1,0){20}}\r\n\\put(60,10){\\line(1,0){20}}\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{Graphs $\\Sun_3$ (left) and $\\Phi$ (right)}\r\n\\label{fig:Sun}\r\n\\end{figure}\r\n\r\n%\\newpage\r\nA `typical' bipartite permutation graph is represented in Figure~\\ref{fig:H55}. \r\nWe emphasize that this figure contains two representations of the {\\it same} graph. \r\nIn most of our considerations the square representation is more preferable and we \r\ndenote a graph of this form with $n$ columns and $n$ rows by $H_{n,n}$.\r\nThe graph $H_{n,n}$ is typical in the sense that it contains all $n$-vertex bipartite permutation graphs as induced subgraphs, i.e., this is an $n$-universal \r\nbipartite permutation graph, which was shown in \\cite{universal}.\r\n\r\n\\begin{figure}[ht]\r\n\\begin{center}\r\n\\begin{picture}(200,100)\r\n\\setlength{\\unitlength}{0.2mm}\r\n\\put(0,0){\\circle*{5}}\r\n\r\n\\put(50,0){\\circle*{5}}\r\n\\put(100,0){\\circle*{5}}\r\n\\put(150,0){\\circle*{5}}\r\n\\put(200,0){\\circle*{5}}\r\n\\put(250,0){\\circle*{5}}\r\n\r\n%\\put(500,50){\\circle*{5}}\r\n\\put(100,50){\\circle*{5}}\r\n\\put(150,50){\\circle*{5}}\r\n\\put(200,50){\\circle*{5}}\r\n\\put(250,50){\\circle*{5}}\r\n\\put(50,50){\\circle*{5}}\r\n\\put(0,50){\\circle*{5}}\r\n\r\n\\put(300,50){\\circle*{5}}\r\n\\put(300,0){\\circle*{5}}\r\n\r\n\\put(350,50){\\circle*{5}}\r\n\\put(350,0){\\circle*{5}}\r\n\r\n\\put(200,0){\\line(0,1){50}}\r\n\\put(200,0){\\line(-1,1){50}}\r\n\\put(200,0){\\line(-2,1){100}}\r\n\\put(200,0){\\line(-3,1){150}}\r\n\\put(200,0){\\line(-4,1){200}}\r\n\r\n\\put(150,0){\\line(0,1){50}}\r\n\\put(150,0){\\line(-1,1){50}}\r\n\\put(150,0){\\line(-2,1){100}}\r\n\\put(150,0){\\line(-3,1){150}}\r\n\r\n\\put(100,0){\\line(0,1){50}}\r\n\\put(100,0){\\line(-1,1){50}}\r\n\\put(100,0){\\line(-2,1){100}}\r\n\r\n\\put(50,0){\\line(0,1){50}}\r\n\\put(50,0){\\line(-1,1){50}}\r\n\\put(0,0){\\line(0,1){50}}\r\n\r\n\\put(250,0){\\line(0,1){50}}\r\n\\put(250,0){\\line(-1,1){50}}\r\n\\put(250,0){\\line(-2,1){100}}\r\n\\put(250,0){\\line(-3,1){150}}\r\n\\put(250,0){\\line(-4,1){200}}\r\n\r\n\\put(300,0){\\line(0,1){50}}\r\n\\put(300,0){\\line(-1,1){50}}\r\n\\put(300,0){\\line(-2,1){100}}\r\n\\put(300,0){\\line(-3,1){150}}\r\n\\put(300,0){\\line(-4,1){200}}\r\n\\put(350,0){\\line(0,1){50}}\r\n\\put(350,0){\\line(-1,1){50}}\r\n\\put(350,0){\\line(-2,1){100}}\r\n\\put(350,0){\\line(-3,1){150}}\r\n\\put(350,0){\\line(-4,1){200}}\r\n\\end{picture}\r\n\\begin{picture}(150,100)\r\n\\setlength{\\unitlength}{0.2mm}\r\n\\put(50,0){\\circle*{5}}\r\n\\put(100,0){\\circle*{5}}\r\n\\put(150,0){\\circle*{5}}\r\n\\put(200,0){\\circle*{5}}\r\n%\\put(250,0){\\circle*{5}}\r\n\r\n%\\put(500,50){\\circle*{5}}\r\n\\put(100,50){\\circle*{5}}\r\n\\put(150,50){\\circle*{5}}\r\n\\put(200,50){\\circle*{5}}\r\n%\\put(250,50){\\circle*{5}}\r\n\\put(50,50){\\circle*{5}}\r\n\r\n\\put(50,100){\\circle*{5}}\r\n\\put(100,100){\\circle*{5}}\r\n\\put(150,100){\\circle*{5}}\r\n\\put(200,100){\\circle*{5}}\r\n%\\put(250,100){\\circle*{5}}\r\n\\put(50,150){\\circle*{5}}\r\n\\put(100,150){\\circle*{5}}\r\n\\put(150,150){\\circle*{5}}\r\n\\put(200,150){\\circle*{5}}\r\n%\\put(250,150){\\circle*{5}}\r\n% \\put(50,200){\\circle*{5}}\r\n% \\put(100,200){\\circle*{5}}\r\n% \\put(150,200){\\circle*{5}}\r\n% \\put(200,200){\\circle*{5}}\r\n%\\put(150,200){\\circle*{5}}\r\n%\\put(250,200){\\circle*{5}}\r\n\\put(200,0){\\line(0,1){50}}\r\n\\put(200,0){\\line(-1,1){50}}\r\n\\put(200,0){\\line(-2,1){100}}\r\n\\put(200,0){\\line(-3,1){150}}\r\n%\\put(200,0){\\line(-4,1){200}}\r\n\r\n\\put(150,0){\\line(0,1){50}}\r\n\\put(150,0){\\line(-1,1){50}}\r\n\\put(150,0){\\line(-2,1){100}}\r\n%\\put(150,0){\\line(-3,1){150}}\r\n\r\n\\put(100,0){\\line(0,1){50}}\r\n\\put(100,0){\\line(-1,1){50}}\r\n%\\put(100,0){\\line(-2,1){100}}\r\n\r\n\\put(50,0){\\line(0,1){50}}\r\n%\\put(50,0){\\line(-1,1){50}}\r\n%\\put(250,0){\\line(0,1){50}}\r\n\r\n\\put(200,50){\\line(0,1){50}}\r\n\\put(200,50){\\line(-1,1){50}}\r\n\\put(200,50){\\line(-2,1){100}}\r\n\\put(200,50){\\line(-3,1){150}}\r\n%\\put(200,0){\\line(-4,1){200}}\r\n\r\n\\put(150,50){\\line(0,1){50}}\r\n\\put(150,50){\\line(-1,1){50}}\r\n\\put(150,50){\\line(-2,1){100}}\r\n%\\put(150,0){\\line(-3,1){150}}\r\n\r\n\\put(100,50){\\line(0,1){50}}\r\n\\put(100,50){\\line(-1,1){50}}\r\n%\\put(100,0){\\line(-2,1){100}}\r\n\r\n\\put(50,50){\\line(0,1){50}}\r\n\r\n\\put(200,100){\\line(0,1){50}}\r\n\\put(200,100){\\line(-1,1){50}}\r\n\\put(200,100){\\line(-2,1){100}}\r\n\\put(200,100){\\line(-3,1){150}}\r\n%\\put(200,0){\\line(-4,1){200}}\r\n\r\n\\put(150,100){\\line(0,1){50}}\r\n\\put(150,100){\\line(-1,1){50}}\r\n\\put(150,100){\\line(-2,1){100}}\r\n%\\put(150,0){\\line(-3,1){150}}\r\n\r\n\\put(100,100){\\line(0,1){50}}\r\n\\put(100,100){\\line(-1,1){50}}\r\n%\\put(100,0){\\line(-2,1){100}}\r\n\r\n\\put(50,100){\\line(0,1){50}}\r\n\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{Universal bipartite permutation graph $H_{n,n}$ for $n=4$.}\r\n\\label{fig:H55}\r\n\\end{figure}\r\n\r\n\r\n\r\nBelow, we list a number of subclasses of bipartite permutation graphs that play an important role in this paper.\r\n\\begin{itemize}\r\n\\item {\\it Chain graphs} are bipartite graphs for which the vertices in each part are linearly ordered under inclusion of their neighbourhoods.\r\nThese are precisely $2K_2$-free bipartite graphs.\r\n\\item {\\it Graphs of vertex degree at most $1$} are graphs in which every connected component is either $K_2$ or $K_1$. Alternatively, they can be\r\ndescribed as $(P_3,K_3)$-free graphs.\r\n\\end{itemize}\r\nAs we shall see in Section~\\ref{sec:parameters}, both these classes are critical with respect to a parameter known as neighbourhood diversity.\r\nGraphs of degree at most $1$ admit two important extensions.\r\n\\begin{itemize}\r\n\\item {\\it Linear forests}, also known as {\\it path forests}, are graphs in which every connected component is a path $P_k$, for some $k$. These are\r\nprecisely $(K_{1,3},C_3,C_4,C_5,\\ldots)$-free graphs, or alternatively, $(K_{1,3},C_4)$-free bipartite permutation graphs.\r\n\\item {\\it Star forests} are graphs in which every connected component is a star $K_{1,p}$, for some $p$. In the terminology of forbidden induced subgraphs\r\nthis class can be described as the class of  $(P_4,C_4)$-free bipartite permutation graphs.\r\n\\end{itemize}\r\nBoth linear forests and star forests are special cases of caterpillar forests.\r\n\\begin{itemize}\r\n\\item {\\it Caterpillar forests} are graphs in which every connected component is a caterpillar, i.e., a tree containing a dominating path.\r\nIn terms of forbidden induced subgraphs caterpillar forests can be described as the class of  $C_4$-free bipartite permutation graphs.\r\n\\end{itemize}\r\nAn interesting class between star forests and bipartite permutation graphs is the class of $P_5$-free graphs: these are graphs in which every connected\r\ncomponent is a chain graph. The inclusion relationships between the above listed classes is represented in Figure~\\ref{fig:inclusion}.\r\n\\begin{figure}\r\n\\begin{center}\r\n\\begin{picture}(400,150)\r\n\\put(200,130)\r\n{\\oval(300,20)\r\n\\makebox(0,0)\r\n{Bipartite permutation graphs}}\r\n\\put(110,90){\\oval(100,20)\r\n\\makebox(0,0)\r\n{$P_5$-free bipartite}}\r\n\\put(275,90){\\oval(150,20)\r\n\\makebox(0,0)\r\n{Caterpillar forests}}\r\n\\put(110,10){\\oval(100,20)\r\n\\makebox(0,0)\r\n{Chain graphs}}\r\n\\put(185,50){\\oval(100,20)\r\n\\makebox(0,0)\r\n{Star forests}}\r\n\\put(300,50){\\oval(100,20)\r\n\\makebox(0,0)\r\n{Linear forests}}\r\n\\put(250,10){\\oval(104,20)\r\n\\makebox(0,0)\r\n{Graphs of degree $\\le 1$}}\r\n\\put(110,120){\\line(0,-1){20}}\r\n\\put(110,80){\\line(0,-1){60}}\r\n\\put(275,120){\\line(0,-1){20}}\r\n\\put(150,80){\\line(0,-1){20}}\r\n\\put(220,80){\\line(0,-1){20}}\r\n\\put(275,80){\\line(0,-1){20}}\r\n\\put(220,40){\\line(0,-1){20}}\r\n\\put(275,40){\\line(0,-1){20}}\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{Inclusion relationships between subclasses of bipartite permutation graphs}\r\n\\label{fig:inclusion}\r\n\\end{figure}\r\n\r\n\r\n\\section{Well-quasi-ordering and boundary classes}\r\n\\label{sec:wqo}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\nIn this section, we look for critical classes of bipartite permutation graphs with respect to the notion of well-quasi-ordering by induced subgraphs.\r\nWe start with basic definitions.\r\n\r\nA binary relation $\\le$ on a set $W$ is a {\\it quasi-order} (also known as {\\it preorder})\r\nif it is reflexive and transitive. Two elements $x,y \\in W$ are said to be {\\it comparable}\r\nwith respect to $\\le$ if either $x\\le y$ or $y\\le x$. Otherwise, $x$ and $y$ are {\\it incomparable}.\r\nA set of pairwise comparable elements is called a {\\it chain}, and a set of pairwise incomparable elements\r\nis an {\\it antichain}. If $x\\le y$ and $y\\not\\le x$, we write $x<y$. A chain $x_1> x_2> \\ldots$ is called {\\it strictly descending}.\r\nA quasi-order $(W,\\le)$ is a {\\it well-quasi-order} (``wqo'', for short) if it contains neither infinite strictly descending chains nor infinite antichains.\r\n\r\nThe celebrated result of Robertson and Seymour \\cite{minor-wqo} states that the set of all simple graphs is well-quasi-ordered with respect to the minor relation.\r\nHowever, the induced subgraph relation is not a wqo, as the cycles create an infinite antichain with respect to this relation.\r\nThis example does not apply to the class of bipartite permutation graphs, since all chordless cycles are forbidden in this class, except for $C_4$.\r\nNonetheless, graphs in this class are not well-quasi-ordered under induced subgraphs, because they contain the infinite antichain of \\emph{$H$-graphs},\r\ni.e., graphs of the form $H_k$ represented in Figure~\\ref{fig:H}.\r\n\r\n\\begin{figure}[ht]\r\n\\begin{center}\r\n\\begin{picture}(250,85)\r\n%Graph Hn\r\n\\put(50,40){\\circle*{3}} \\put(80,40){\\circle*{3}} \\put(110,40){\\circle*{3}}\r\n\\put(130,40){\\circle*{1}} \\put(140,40){\\circle*{1}} \\put(150,40){\\circle*{1}}\r\n\\put(170,40){\\circle*{3}} \\put(200,40){\\circle*{3}} \\put(50,70){\\circle*{3}}\r\n\\put(50,10){\\circle*{3}} \\put(200,70){\\circle*{3}} \\put(200,10){\\circle*{3}}\r\n\\put(50,40){\\line(1,0){30}} \\put(80,40){\\line(1,0){30}} \\put(110,40){\\line(1,0){10}}\r\n\\put(160,40){\\line(1,0){10}} \\put(170,40){\\line(1,0){30}}\r\n\\put(50,40){\\line(0,1){30}} \\put(50,40){\\line(0,-1){30}}\r\n\\put(200,40){\\line(0,1){30}} \\put(200,40){\\line(0,-1){30}} \\put(60,45){1}\r\n\\put(90,45){2} \\put(180,45){$k$}\r\n%\\put(130,1){(a)}\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{The graph $H_k$}\r\n\\label{fig:H}\r\n\\end{figure}\r\n\r\nOn the other hand, if we restrict ourselves to the class of chain graphs, we find ourselves in the well-quasi-ordered world,\r\nbecause chain graphs have lettericity at most $2$, as we shall see in Section~\\ref{sec:lettericity},\r\nand graphs of bounded lettericity are known to be well-quasi-ordered by induced subgraphs \\cite{Pet02}. Unfortunately, the boundary\r\nseparating wqo classes from non-wqo ones cannot be described in the terminology of minimal non-wqo\r\nclasses, because such classes do not exist. Indeed, if $\\cal X$ is a non-wqo class, then it contains an infinite antichain of graphs.\r\nExcluding these graphs one by one, we obtain an infinite strictly descending sequence of subclasses of $\\cal X$, none of which is wqo.\r\n\r\nTo overcome this difficulty, we employ the notion of boundary classes, which can be viewed as a relaxation of the notion of minimal classes.\r\nThis notion was introduced in \\cite{Ale03} to study the maximum independent set\r\nproblem in hereditary classes. Later, this notion was applied to some other graph\r\nproblems of both algorithmic \\cite{AKL04,ABKL07,KLMT11,M13,M14,M16,MP16} and combinatorial \\cite{boundary-wqo,Loz08} nature.\r\nIn particular, in \\cite{boundary-wqo} it was applied to the study of well-quasi-ordered classes and was defined as follows.\r\n\r\nTo simplify the discussion, we use the term {\\it bad} to refer to classes of graphs\r\nthat are not well-quasi-ordered by the induced subgraph relation and the term {\\it good}\r\nto refer to those classes that are well-quasi-ordered.\r\n\r\n\r\n\\begin{definition}\r\nWe say that $\\cal X$ is a {\\it limit class} if $\\cal X$ is the intersection of any sequence\r\n${\\cal X}_1\\supseteq {\\cal X}_2\\supseteq {\\cal X}_3\\supseteq\\ldots$ of bad classes.\r\n\\end{definition}\r\n\r\nIn \\cite{boundary-wqo}, it was shown that every bad class contains a minimal limit class.\r\n\r\n\\begin{definition}\r\nA minimal limit class is called a {\\it boundary class}.\r\n\\end{definition}\r\n\r\nThe importance of this notion is due to the following theorem, also proved in \\cite{boundary-wqo}.\r\n\r\n\\begin{theorem}\\label{thm:finite}\r\nA  class of graphs defined by finitely many forbidden induced subgraphs is good if and only if it contains no boundary classes.\r\n\\end{theorem}\r\n\r\nOne of the boundary classes identified in \\cite{boundary-wqo} is the class of linear forests.\r\nIt is the limit of the sequence $\\Free(K_{1,3},C_3,\\ldots,C_k)$ with $k$ tending to infinity.\r\nEach class of this sequence is bad, since each of them contains infinitely many cycles.\r\nHowever, the class of linear forests is not boundary in the universe of bipartite permutation graphs,\r\nsince none  of the classes $\\Free(K_{1,3},C_3,\\ldots,C_k)$ belongs to this universe.\r\n\r\nIn order to identify a boundary class $\\cal X$ in the universe of  bipartite permutation graphs,\r\nwe need to construct a sequence of bad subclasses of bipartite permutation graphs converging to $\\cal X$\r\nand to show that $\\cal X$ is a minimal limit class. To this end, we consider the following sequence:\r\n$$\r\n{\\cal BP}\\cap \\Free(C_4,K_{1,4},S_{1,2,2},3K_{1,3},H_1,\\ldots,H_k).\r\n$$\r\n\r\nWe denote the limit class of this sequence with $k$ tending to infinity by $\\cal L$.\r\n\r\n\\begin{lemma}\\label{lem:X-structure}\r\n$\\cal L$ is the class of graphs, in which every connected component is a path, except possibly for two components of the form $S_{1,1,k}$ for some $k$.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\nBy forbidding $C_4$ in the universe of  bipartite permutation graphs we restrict ourselves to caterpillar forests.\r\nBy forbidding  $K_{1,4}$ we further restrict ourselves to caterpillar forests of vertex degree at most $3$.\r\nIf, additionally, we forbid an $S_{1,2,2}$, then every connected graph becomes an $H_k$ or an $S_{1,1,k}$ or a $P_k$.\r\nSince all graphs of the form $H_k$ are forbidden, every connected graph is either an $S_{1,1,k}$ or a $P_k$.\r\nFinally, since  $3K_{1,3}$ is forbidden, at most two components have the form $S_{1,1,k}$.\r\n\\end{proof}\r\n\r\nTo show the minimality of the class $\\cal L$, we use the following criterion proved in \\cite{boundary-wqo}.\r\n\r\n\\begin{lemma}\\label{lem:minimality-criterion}\r\nA limit class ${\\cal X}=\\Free(\\cal M)$ is minimal (i.e., boundary) if and only if\r\nfor every graph $G\\in {\\cal X}$ there is a finite set $\\cal T\\subseteq \\cal M$,\r\nsuch that $\\Free(\\{G\\}\\cup \\cal T)$ is good.\r\n\\end{lemma}\r\n\r\n\r\n\\begin{theorem}\r\n$\\cal L$ is the only boundary class in the universe of bipartite permutation graphs.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nLet $G$ be a graph in $\\cal L$. According to Lemma~\\ref{lem:X-structure}, there is a $k$ such that $G$ is an induced subgraph of $H_i$ for all $i\\ge k$.\r\nTherefore, $\\Free(G,C_4,K_{1,4},S_{1,2,2},3K_{1,3},H_1,\\ldots,H_{k-1})$ is a subclass of $\\cal L$. It is well-known that graphs in a class are well-quasi-ordered\r\nif and only if connected graphs in that class are well-quasi-ordered. Clearly, connected graphs in $\\cal L$ are well-quasi-ordered,\r\nand, hence, by Lemma~\\ref{lem:minimality-criterion}, $\\cal L$  is a boundary class in the universe of bipartite permutation graphs.\r\n\r\nTo prove the uniqueness of $\\cal L$, we observe that the antichain of $H$-graphs is canonical in the universe of bipartite permutation graphs\r\nin the sense that every hereditary subclass of bipartite permutation graphs containing finitely many $H$-graphs is well-quasi-ordered under induced\r\nsubgraphs \\cite{canonical}. Therefore, by forbidding any graph from $\\cal L$, we obtain a class which is well-quasi-ordered. This implies by Theorem~\\ref{thm:finite} that\r\n$\\cal L$ is a unique boundary class in the universe of bipartite permutation graphs.\r\n\\end{proof}\r\n\r\n\r\n\r\n\\begin{theorem}\\label{thm:classes-wqo}\r\nLet $\\Free(\\mathcal L)$ denote the family of hereditary subclasses of bipartite permutation graphs, none of which contains $\\cal L$ as a subclass.\r\nThen $\\Free(\\mathcal L)$ is well-founded with respect to inclusion, i.e.,  it contains no strictly descending infinite chains of classes.\r\n\\end{theorem}\r\n\r\n\\begin{proof} \t\r\nNote that any class $\\mathcal X \\in \\Free(\\mathcal L)$ is wqo, since it contains only finitely many $H$\\nobreakdash -graphs. \r\nIt is well-known (and not difficult to see) that a class of graphs is wqo if and only if the set of its subclasses is well-founded under inclusion. \r\nThis immediately implies that $\\Free(\\mathcal L)$ itself is well-founded under inclusion.\r\n\\end{proof}\r\n\r\nTheorem~\\ref{thm:classes-wqo} shows that in the universe of bipartite permutation graphs the unique boundary class $\\cal L$ is the only obstacle to finding minimal ``difficult'' classes.\r\nNote, however, that the number of minimal classes may in principle be infinite: an example of an infinite antichain of classes with respect to inclusion in $\\Free(\\mathcal L)$ \r\nis given by the sequence $(\\mathcal X_i)_{i \\geq 1}$, with $\\mathcal X_i := \\mathcal{BP} \\cap \\Free(P_{4 + i}, H_1, \\dots, H_{i - 1})$ \r\n(in particular, we have $\\mathcal X_1 = \\mathcal{BP}\\cap \\Free(P_5)$). We remark that the above antichain is constructed in such a way that $H_i \\in \\mathcal X_i \\setminus \\bigcup_{j \\neq i} \\mathcal X_j$. \r\nThe dependence of the construction on the canonical antichain of $H$-graphs raises the following question.\r\n\r\n\\begin{problem}\r\nIs the antichain $(\\mathcal X_i)_{i \\geq 1}$ canonical in $\\mathcal \\Free(\\mathcal L)$?\r\n\\end{problem}\r\n\r\nOne more open problem related to the notion of well-quasi-ordering comes from the fact that the set of $H$-graphs, which forms a (canonical) antichain\r\nwith respect to induced subgraphs, is a chain with respect to induced minors, where an induced minor of a graph $G$ is any graph obtained from $G$ by \r\na (possibly empty) sequence of vertex deletions and edge contractions. \r\n\r\nWell-quasi-orderability under induced minors has been studied before -- see, for instance, \\cite{induced-minor}, where it was shown that interval graphs are not wqo under the relation, \r\nbut chordal graphs of bounded clique number are. We note that the class of bipartite permutation graphs is not closed under taking \r\ninduced minors, but this should not stop us from investigating its orderability with respect to the induced minor relation, \r\nespecially given its similarity with the class of unit interval graphs (see, e.g., \\cite{canonical}). In particular, we ask the following question.\r\n\r\n% fact does not prevent the class from containing an infinite antichain with respect to induced minors, which also must be \r\n%an antichain with respect to induced subgraphs.  \r\n\r\n\\begin{problem}\r\nIs the class of bipartite permutation graphs well-quasi-ordered under the induced minor relation?\r\n\\end{problem}\r\n\r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\section{Graph parameters and minimal classes}\r\n\\label{sec:parameters}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\nMany important parameters are bounded in the class of bipartite permutation graphs, which is the case for the size of a maximum clique, chromatic number, contiguity, etc.\r\nMany other parameters can be arbitrarily large in this class. In the present section, we characterize several such parameters in terms of minimal subclasses of\r\nbipartite permutation graphs where these parameters are unbounded.\r\nWe start by reporting in Section~\\ref{sec:known} some known results, which will be helpful in the subsequent sections. \r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\subsection{Neighbourhood diversity, distinguishing number and uniformicity}\r\n\\label{sec:known}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\nThe notion of {\\it neighbourhood diversity} was introduced in \\cite{Lampis} and  can be defined as follows.\r\n\r\n\\begin{definition}\r\nWe say that two vertices $x$ and $y$ are {\\it similar} if there is no vertex $z \\neq x, y$ distinguishing them,\r\ni.e., if there is no vertex $z \\neq x, y$ adjacent to exactly one of $x$ and $y$. Vertex similarity is an equivalence relation. We denote by\r\n$nd(G)$ the number of similarity classes in $G$ and call it the {\\it neighbourhood diversity} of $G$.\r\n\\end{definition}\r\n\r\nNeighbourhood diversity was characterized in \\cite{parameters} by means of nine minimal hereditary classes of graphs\r\nwhere this parameter is unbounded. Three of these classes are subclasses of bipartite graphs: \r\n\\begin{itemize}\r\n\\item the class ${\\cal X}_1$ of chain graphs,\r\n\\item the class ${\\cal X}_2$ of graphs of vertex degree at most $1$,\r\n\\item the class ${\\cal X}_3$ of bipartite complements of graphs of vertex degree at most $1$, i.e.,\r\nbipartite graphs, in which every vertex has at most one non-neighbour in the opposite part. \r\n\\end{itemize}\r\nThree other classes are complements of graphs in  ${\\cal X}_1$, ${\\cal X}_2$ and ${\\cal X}_3$, \r\nand the remaining three classes are subclasses of split graphs obtained by creating a clique \r\nin one of the parts in a bipartition of graphs in  ${\\cal X}_1$, ${\\cal X}_2$ and ${\\cal X}_3$.\r\nThe subclass of split graphs obtained in this way from graphs in ${\\cal X}_1$ is known as {\\it threshold graphs}.\r\nOnly two of the nine listed classes are subclasses of bipartite permutation graphs,\r\nwhich allows us to make the following conclusion. \r\n\r\n\\begin{theorem}\\label{thm:nbd}\r\nThe classes of chain graphs and graphs of vertex degree at most $1$  are\r\nthe only two minimal hereditary subclasses of bipartite permutation graphs of unbounded neighbourhood diversity.\r\n\\end{theorem}\r\n\r\n\r\n\\medskip \r\nThe notion of distinguishing number appeared implicitly in \\cite{Jump} and was given its name in \\cite{Bell}.\r\nTo define this notion, consider a graph $G$, a subset $U \\subseteq V(G)$, a collection of pairwise disjoint subsets $U_1$,~\\dots,~$U_m$ of~$V(G)$, also disjoint from $U$. \r\nWe will say that  $U$~\\emph{distinguishes} the sets $U_1$, $U_2$,~\\dots,~$U_m$  if for each~$i$, all vertices of~$U_i$\r\nhave the same neighbourhood in $U$, and for each $i \\neq j$,\r\nvertices $x \\in U_i$ and $y \\in U_j$ have different neighbourhoods in~$U$.\r\n\r\n\\begin{definition}\r\nThe {\\it distinguishing number} of $G$ is the maximum $k$ such that $G$ contains a subset $U\\subset V(G)$ that \r\ndistinguishes at least $k$ subsets of $V(G)$, each of size at least $k$.\r\n\\end{definition}\r\n\r\nThe paper~\\cite{Jump} provides a complete description of minimal classes of unbounded distinguishing number, of which there are precisely 13:\r\n\r\n\\begin{itemize}\r\n\\item the class of graphs every connected component of which is a clique,\r\n\\item the class of chain graphs,\r\n\\item the class of threshold graphs,\r\n\\item the class of star forests,\r\n\\item the class of graphs obtained from star forests by creating a clique on the leaves of the stars,\r\n\\item the class of graphs obtained from star forests by creating a clique on the centers of the stars,\r\n\\item the class of graphs obtained from star forests by creating a clique on the leaves of the stars and a clique on the centers of the stars,\r\n\\item the classes of complements of graphs in the above listed classes (note that the complements of threshold graphs are threshold graphs).\r\n\\end{itemize}\r\n\r\n\r\n\r\n\r\nThe global structure of graphs of bounded distinguishing number can informally be described as follows: the vertex set of every graph admits a partition into finitely many subsets\r\nsuch that each subset induces a graph of bounded degree or co-degree (i.e., degree in the complement) and the edges between any two subsets form a bipartite graph of bounded degree or co-degree.\r\nNote that bounded neighbourhood diversity is the special case where we require the degree or co-degree to equal 0, so that bounded neighbourhood diversity implies bounded distinguishing number (the same conclusion \r\ncan be obtained by comparing the respective lists of minimal classes).\r\n\r\n\\medskip\r\nOne can define a parameter between neighbourhood diversity and distinguishing number, known as {\\it uniformicity}, as follows.  \r\nLet $k$ be a natural number,  $F$ \r\na simple graph on the vertex set $\\{1, 2, \\ldots, k\\}$, and $K$ a graph on $\\{1, 2, \\ldots, k\\}$ with loops allowed. \r\nLet $U(F)$ be the disjoint union of infinitely many copies of $F$, and for $i = 1, \\ldots,k$, let $V_i$ be the subset of\r\nvertices of $U(F)$ containing vertex $i$ from each copy of $F$. % We call $V_1,\\ldots,V_k$ the {\\it bags} of $U(F_k)$.\r\nNow we construct from $U(F)$ an infinite graph $U(F,K)$ on the same vertex set\r\nby connecting two vertices $u \\in V_i$ and $v \\in V_j$ if and only if \r\n\\begin{itemize}\r\n\\item either $uv \\in E(U(F))$ and $ij\\not\\in E(K)$,\r\n\\item or $uv \\not\\in E(U(F))$ and $ij\\in E(K)$.\r\n\\end{itemize}\r\n\r\nIntuitively, we start with independent sets $V_i$ corresponding to the vertices of $F$, and for $i \\neq j$, \r\nthe sets $V_i$ and $V_j$ have an induced matching between them wherever $F$ has an edge. \r\nWe then apply complementations according to the edges of $K$: if $ij\\in E(K)$, we complement the edges between $V_i$ and $V_j$ (replacing $V_i$ with a clique if $i = j$). \r\n\r\nFinally, we let ${\\cal P}(F,K)$ be the hereditary class consisting of all the finite induced subgraphs of $U(F,K)$.    \r\nAs an example, if $k=2$, $F=K_2$ and $E(K)=\\emptyset$, then ${\\cal P}(F,K)$ is the class of graphs of vertex degree at most $1$, \r\nand if $E(K)=\\{12\\}$ instead, then ${\\cal P}(F,K)$ is the class of bipartite complements of graphs of vertex degree at most $1$.\r\n\r\n\\begin{definition}\r\nA graph $G$ is called $k$-{\\it uniform} if there is a number $k$ such that $G \\in {\\cal P}(F,K)$ for some $F$ and $K$.\r\nThe minimum $k$ such that $G$ is $k$-uniform is the {\\it uniformicity} of $G$.\r\n\\end{definition}\r\n\r\n\r\n\r\nFrom the results in  \\cite{SpHerProp} and \\cite{Jump} it follows that classes of bounded uniformicity are precisely the classes whose speed (i.e., the number of $n$-vertex labelled graphs) is below the Bell number. \r\nThe set of minimal hereditary classes with speed at least the Bell number, and hence of unbounded uniformicity, consists of the 13 minimal classes of unbounded distinguishing number together with \r\nan infinite collection of classes, which can be described as follows. \r\n\r\nLet $A$ be a finite alphabet, $w=w_1w_2\\ldots$ an infinite word over $A$, and $K$ an undirected graph with loops allowed and with vertex set $V(K)=A$.\r\nWe define the graph $U(w,K)$ as follows: the vertex set of $U(w,K)$ is the set of natural numbers and the edge set consists of pairs of distinct numbers $i,j$\r\nsuch that\r\n\\begin{itemize}\r\n\\item either $|i-j|=1$ and $w_{i}w_{j} \\notin{E(K)}$,\r\n\\item or $|i-j| > 1$ and $w_{i}w_{j} \\in E(K)$.\r\n\\end{itemize}\r\nTo illustrate this notion, consider the case of $A=\\{a\\}$ and $E(K)=\\emptyset$. \r\nThen the infinite word $w=aaa\\ldots$ defines the infinite path $U(w,K)$. In fact, if $E(K)=\\emptyset$, then $U(w,K)$ is an infinite path for any $w$.\r\n\r\n\r\nDefine ${\\cal P}(w, K)$ to be the hereditary class consisting of all \r\nthe finite induced subgraphs of $U(w,K)$. In particular, if $E(K)=\\emptyset$, then ${\\cal P}(w, K)$ is the class of linear forests. \r\n\r\n\r\nA {\\it factor} in a word $w$ is a contiguous subword, i.e., a subword whose letters appear consecutively in $w$.\r\nA word~$w$ is called \\emph{almost periodic} if for any factor~$f$\r\nof~$w$ there is a constant~$k_f$ such that any factor of~$w$\r\nof size at least~$k_f$ contains~$f$ as a factor.\r\n\r\n\\begin{theorem}{\\rm \\cite{Bell}}\\label{thm:minimal-bell}\r\nLet $X$ be a class of graphs with finite distinguishing number. Then $X$ is a minimal hereditary\r\nclass with speed at least the Bell number if and only if there exists a finite graph $K$ with loops allowed\r\nand an infinite almost periodic word $w$ over $V(K)$ such that $X ={\\cal P}(w,K)$.\r\n\\end{theorem}\r\n\r\n\r\n\\begin{definition}\r\nAny class of the form ${\\cal P}(w,K)$, where  $K$ is a finite graph with loops allowed\r\nand $w$  is an infinite almost periodic word over $V(K)$, will be called a {\\it class of folded linear forests}.\r\n\\end{definition}\r\n\r\n\r\nWe observe that each class of folded linear forests is a boundary class for well-quasi-orderability by induced subgraphs,\r\nand in the world of classes with finite distinguishing number there are no other boundary classes, which was shown in \\cite{finite}.\r\n\r\n\r\nSummarising the discussion, we make the following conclusion.\r\n\r\n\\begin{theorem} \r\nThe list of minimal hereditary classes of unbounded uniformicity consists of the 13 classes of unbounded distinguishing number and all the classes of \r\nfolded linear forests.\r\n\\end{theorem}\r\n\r\nWith the restriction to bipartite permutation graphs, distinguishing number and uniformicity can be characterized in terms minimal classes as follows.\r\n\r\n\\begin{theorem} \r\nIn the universe of bipartite permutation graphs, the list of minimal hereditary subclasses of unbounded distinguishing number consists of star forests and chain graphs, \r\nand the list of minimal hereditary subclasses of unbounded uniformicity consists of star forests, chain graphs and linear forests. \r\n\\end{theorem}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\subsection{Lettericity and Parikh word representability}\r\n\\label{sec:lettericity}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\nParikh word representable graphs were introduced in \\cite{Parikh} as follows. Let $A=\\{a_1<a_2<\\ldots <a_k\\}$ be an ordered alphabet,\r\nand let $w=w_1w_2\\ldots w_n$ be a word over $A$. The \\emph{Parikh graph} of $w$ has $\\{1,2,\\ldots,n\\}$ as its vertex set\r\nand two vertices $i < j$ are adjacent if and only if there is $p\\in \\{1,2,\\ldots,k-1\\}$, such that $w_i=a_p$ and $w_j=a_{p+1}$.\r\n\r\nIn \\cite{Parikh-bpg}, it was shown that the class of Parikh word representable graphs coincides with the class of bipartite permutation graphs\r\nand was conjectured that every bipartite permutation graph with $n$ vertices admits a Parikh word representation over an alphabet of $\\lfloor \\frac{n}{2}\\rfloor +1$ letters.\r\nIn this section, we prove the conjecture. To this end, we use the related notion of letter graphs, which was introduced in \\cite{Pet02} and can be defined as follows.\r\n\r\nAs before, $A$ is a finite alphabet, but this time we do not assume any order on the letters of $A$. \r\nLet $D$  be a subset of $A^2$ and $w=w_1w_2\\ldots w_n$ a word over $A$. \r\nThe \\emph{letter graph} $G(D,w)$ associated with $w$ has $\\{1,2,\\ldots,n\\}$ as its vertex set, \r\nand two vertices $i < j$ are adjacent if and only if the ordered pair $(w_i,w_j)$ belongs to $D$. \r\nA graph $G$ is said to be a \\emph{letter graph} if there exist an alphabet $A$, a subset $D\\subseteq A^2$ and a word $w=w_1w_2\\ldots w_n$ over $A$ such that $G$ is isomorphic to $G(D,w)$.\r\n\r\nThe role of $D$ is to decode (transform) a word into a graph and therefore we refer to $D$ as a decoder.\r\nEvery graph $G$ is trivially a letter graph over the alphabet $A = V(G)$ with the decoder $D = \\{(v, w), (w, v): \\{v, w\\} \\in E(G)\\}$.\r\nThe \\emph{lettericity} of $G$, denoted by $\\ell(G)$, is the minimum $k$ such that $G$ is representable as a letter graph over an alphabet of $k$ letters.\r\n\r\n\r\nTo give a less trivial example, consider the alphabet $A=\\{a,b\\}$ and the decoder $D=\\{(a,b)\\}$.  Then, the word $ababababab$\r\ndescribes the graph represented in Figure~\\ref{fig:T5}. Clearly, this is a chain graph. Moreover, a chain graph of this form with $n$ vertices\r\nin each part, which we denote by $Z_n$, is $n$-universal, i.e., it contains every $n$-vertex chain graph as an induced subgraph, as was shown in \\cite{universal}.\r\nTherefore a graph is a chain graph if and only if it is a letter graph over the alphabet $A=\\{a,b\\}$ with the decoder $D=\\{(a,b)\\}$.\r\n\\begin{figure}[ht]\r\n\\begin{center}\r\n\\begin{picture}(300,60)\r\n\\put(50,0){\\circle*{5}}\r\n\\put(100,0){\\circle*{5}}\r\n\\put(150,0){\\circle*{5}}\r\n\\put(200,0){\\circle*{5}}\r\n\\put(250,0){\\circle*{5}}\r\n\\put(48,53){$a_1$}\r\n\\put(98,53){$a_2$}\r\n\\put(148,53){$a_3$}\r\n\\put(198,53){$a_4$}\r\n\\put(248,53){$a_5$}\r\n\r\n\r\n%\\put(150,50){\\oval(250,10)}\r\n%\\put(150,100){\\oval(250,10)}\r\n%\\put(150,150){\\oval(250,10)}\r\n%\\put(150,200){\\oval(250,10)}\r\n\r\n%\\put(150,52){\\oval(230,20)}\r\n\r\n\\put(48,-12){$b_1$}\r\n\\put(98,-12){$b_2$}\r\n\\put(148,-12){$b_3$}\r\n\\put(198,-12){$b_4$}\r\n\\put(248,-12){$b_5$}\r\n\\put(50,50){\\circle*{5}}\r\n\\put(100,50){\\circle*{5}}\r\n\\put(150,50){\\circle*{5}}\r\n\\put(200,50){\\circle*{5}}\r\n\\put(250,50){\\circle*{5}}\r\n\r\n\\put(50,0){\\line(0,1){50}}\r\n\\put(250,0){\\line(-1,1){50}}\r\n\\put(250,0){\\line(-2,1){100}}\r\n\\put(250,0){\\line(-3,1){150}}\r\n\\put(250,0){\\line(-4,1){200}}\r\n\\put(100,0){\\line(0,1){50}}\r\n\\put(200,0){\\line(-1,1){50}}\r\n\\put(200,0){\\line(-2,1){100}}\r\n\\put(200,0){\\line(-3,1){150}}\r\n\\put(150,0){\\line(0,1){50}}\r\n\\put(150,0){\\line(-1,1){50}}\r\n\\put(150,0){\\line(-2,1){100}}\r\n\\put(200,0){\\line(0,1){50}}\r\n\\put(100,0){\\line(-1,1){50}}\r\n\\put(250,0){\\line(0,1){50}}\r\n\r\n\\end{picture}\r\n\\end{center}\r\n\\caption{The letter graph of the word $ababababab$.\r\nWe use indices to indicate in which order the $a$-letters and the $b$-letters appear in the word.}\r\n\\label{fig:T5}\r\n\\end{figure}\r\n\r\n\r\nThe $n$-universal bipartite permutation graph $H_{n,n}$ (Figure~\\ref{fig:H55}) can be viewed as a sequence \r\nof $n$ copies of the $n$-universal chain graphs and hence it\r\ncan be expressed as a letter graph on letters $a_1, \\dots, a_n$ with decoder $\\{(a_i, a_{i + 1}): 1 \\leq i \\leq n - 1\\}$. The word representing $H_{n,n}$ consists of\r\nthe concatenation of $n$ copies of $a_1a_2\\ldots a_n$. The same word represents $H_{n,n}$ as a Parikh graph over the ordered alphabet $A=\\{a_1<a_2<\\ldots <a_n\\}$.\r\nThis discussion provides an alternative proof of the fact that the class of Parikh word representable graphs is precisely the class of bipartite permutation graphs.\r\n\r\n\r\n\r\n\r\n\\begin{theorem}\\label{thm:lettericity-bound}\r\nLet $G$ be a bipartite permutation graph with $n$ vertices. Then $G$ has lettericity bounded above by $\\lfloor\\frac{n}{2}\\rfloor + 1$.\r\n\\end{theorem}\r\n\t\r\n\\begin{proof}\r\nWe first deal with the case when $G$ is connected, and assume $n \\geq 2$.\r\nWe know that $G$ can be expressed as a letter graph on letters $a_1, \\dots, a_n$ with decoder $\\{(a_i, a_{i + 1}): 1 \\leq i \\leq n - 1\\}$.\r\n\t\t\r\nAmong all expressions $w_1w_2\\dots w_n$ with that decoder, writing $l(j)$ for the index of the letter in position $j$ of the word,\r\npick one that minimises $\\sum\\limits_{j = 1}^n l(j)$ (i.e., an expression that minimises the sum of the indices of the letters in $w$).\r\nLet us state some properties of this expression:\r\n\\begin{itemize}\r\n\\item $a_1$ appears at least once in $w$. If not, we can shift all indices down by 1.\r\n\\item The last letter is $a_2$. Indeed, the last letter cannot be $a_1$, since that would mean $G$ has an isolated vertex.\r\nIf the last letter is $a_t$, for some $t \\geq 3$, we can remove it, and add an $a_{t - 2}$ at the beginning of $w$: this new expression still represents $G$, but the sum of indices is smaller.\r\n\\item Let $t \\geq 2$, and let $w_j = a_t$ be the rightmost appearance of $a_t$ in $w$.\r\nThen there is an $a_{t - 1}$ to the right of $w_j$ in $w$.\r\nOtherwise, as before, we can (by going more to the right if necessary) find an $a_t$ to the right of every $a_{t - 1}$ and of every $a_{t + 1}$,\r\nwhich can be replaced by an $a_{t - 2}$ in the beginning of the word.\r\nIt follows that the rightmost occurrence of $a_t$ has to its right at least one $a_i$ for each $2 \\leq i \\leq t$, and no $a_i$ for $i > t$.\r\n\\item Let $t \\geq 2$, and let $w_j = a_t$ be the rightmost occurrence of $a_t$.\r\nThen, there is an $a_{t - 1}$ to the left of $a_t$.\r\nIndeed, since $G$ is connected, the vertex $j$ has a neighbour.\r\nBut as seen above, there are no $a_{t + 1}$s to the right of $w_j$, hence that neighbour must be an $a_{i - 1}$ to its left.\r\n\\end{itemize}\r\n\t\r\nPutting $r := \\max_{1 \\leq j \\leq n} l(j)$, the above discussion implies that $w$ uses letters $2, \\dots, r - 1$ at least twice, and letters $1, r$ at least once.\r\nSince $G$ has $n$ vertices, this implies $r \\leq \\frac{n}{2} + 1$.\r\n\t\t\r\nIf $G$ is disconnected, writing $G_i$, $1 \\leq i \\leq s$ for its connected components,\r\nwe can produce words $w(G_i)$ as above for each $G_i$, where $G_1$ uses letters 1 to $a_{r_1}$, $G_2$ uses letters $a_{r_1}$ to $a_{r_2}$, and so on.\r\nWe then obtain a word representing $G$ by concatenating $w(G_s), w(G_{s - 1}), \\dots, w(G_1)$ in that order.\r\nThe resulting word uses once more each letter twice, except for possibly the first and the last one.\r\n\\end{proof}\r\n\r\nThe upper bound in Theorem~\\ref{thm:lettericity-bound} is tight and attained on graphs of vertex degree at most 1 (see \\cite{Parikh-bpg} for arguments\r\ngiven in the terminology of Parikh word representability or \\cite{cographs} for arguments given in the terminology of lettericity). In the rest of\r\nthis section we show that, within the universe of bipartite permutation graphs, the class of graphs of vertex degree at most 1 is the only obstacle\r\nfor bounded lettericity, i.e., it is the unique minimal subclass of bipartite permutation graphs of unbounded lettericity.\r\n\r\n\\begin{theorem}\r\nFor each $p$, there is an $f(p)$ such that the lettericity of $pK_2$-free bipartite permutation graphs is at most $f(p)$.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nLet $G$ be a $pK_2$-free bipartite permutation graph. Then $G$ has at most $p-1$ nontrivial connected components, i.e., components of\r\nsize at least 2. Each component can be embedded, as an induced subgraph, into the universal graph $H_{n,n}$ with at most $3p-2$ rows,\r\nsince any connected induced subgraph of the universal graph occupying at least $3p-1$ rows contains an induced $P_{3p-1}$ and, hence,\r\nan induced $pK_2$. Therefore, any component of $G$ requires at most $3p-2$ letters to represent it. Altogether, we need at most $(p-1)(3p-2)+1$\r\nletters to represent $G$.\r\n\\end{proof}\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\subsection{Shrub-depth and related parameters}\r\n\\label{sec:shrub}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\n\r\nIn this section, we analyse various width and depth parameters and characterize them in terms of minimal hereditary\r\nclasses of bipartite permutation graphs where these parameters are unbounded.\r\n\r\nWe start by repeating that the class of all bipartite permutation graphs is a minimal hereditary class of unbounded clique-width.\r\n{\\it Tree-width} is a restriction of clique-width in the sense that bounded tree-width implies bounded clique-width, but not necessarily vice versa.\r\n\r\n\r\n\\begin{proposition}\r\nThe class of complete bipartite graphs is the only minimal hereditary subclass of bipartite permutation graphs of unbounded tree-width.\r\n\\end{proposition}\r\n\r\n\\begin{proof}\r\nIt is well-known that tree-width can be arbitrarily large for complete bipartite graphs. On the other hand,\r\nit was shown in \\cite{cw-bound} that for graphs that do not contain $K_{n,n}$ as a subgraph, tree-width is bounded by a function of $n$ and its clique-width. \r\nTherefore, for every subclass of bipartite permutation\r\ngraphs excluding at least one complete bipartite graph tree-width is bounded, since clique-width is bounded.\r\n\\end{proof}\r\n\r\n\r\n{\\it Tree-depth} is a restriction of tree-width in the sense that bounded tree-depth implies bounded tree-width, but not necessarily vice versa.\r\nLet us define the {\\it path number} of $G$ to be the length of a longest (not necessarily induced) path in $G$.\r\nIn the terminology of minimal classes, the two parameters are equivalent, as shown in the following proposition.\r\n\r\n\\begin{proposition}\r\nThe classes of complete graphs, complete bipartite graphs and linear forests are the only three minimal hereditary classes of graphs of unbounded tree-depth and path number.\r\nIn the universe of bipartite permutation graphs, complete bipartite graphs and linear forests are the only two minimal hereditary classes of graphs of unbounded tree-depth and path number.\r\n\\end{proposition}\r\n\r\n\\begin{proof}\r\nIt is known \\cite{tree-depth} that tree-depth is unbounded in a class $\\cal X$ if and only if graphs in $\\cal X$ contain arbitrarily long paths as subgraphs.\r\nAlso, it was shown in \\cite{Razgon} that for every $t, p, s$, there exists a $z=z(t,p,s)$,\r\nsuch that every graph with a (not necessarily induced) path of length at least $z$ contains either an induced path of length $t$\r\nor an induced complete bipartite graph with color classes of size $p$ or a clique of size $s$.\r\nThe proposition then follows.\r\n\\end{proof}\r\n\r\n\r\n\r\n\r\n\r\n{\\it Shrub-depth} is an extension of tree-depth for dense graphs (see \\cite{shrub} for the original definition). {\\it Rank-depth} is a related parameter, which is equivalent to shrub-depth in the following sense.\r\n\r\n\\begin{theorem}{\\rm \\cite{rank-depth}}\r\nA class of graphs has bounded rank-depth if and only if it has bounded shrub-depth.\r\n\\end{theorem}\r\n\r\n\r\n\r\nOur next result characterizes both parameters in the terminology of minimal classes within the universe of bipartite permutation graphs.\r\n\r\n\\begin{theorem}\\label{thm:shrub-depth}\r\nThe classes of chain graphs and linear forests are the only two minimal hereditary subclasses of bipartite permutation graphs of unbounded shrub-depth and rank-depth.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nIt was shown in \\cite{rank-depth} that paths, and therefore linear forests, have unbounded rank-depth. \r\n\r\n%every positive integer $t$, there exists $N$ such that every\r\n%graph of rank-depth at least $N$ contains a vertex-minor isomorphic to the path on $t$ vertices. Thus, the rank- and shrub-depth are unbounded in\r\n%the class of linear forests.\r\n\r\nTo show that the parameters are unbounded in the class of chain graphs, we use the notions of local complementations and local equivalence. \r\nA {\\em local complementation} is the operation of complementing the subgraph induced by the neighbourhood of a vertex, \r\nand two graphs $G$ and $H$ are said to be {\\em locally equivalent} if $G$ can be obtained from $H$ by a sequence of local complementations (and vice-versa). \r\nIt was also pointed out in \\cite{rank-depth} that, as a consequence of a result from \\cite{localcomp}, rank-depth is invariant under local complementations, hence it suffices to show that there are arbitrarily \r\nlong paths that are locally equivalent to chain graphs.\r\n\r\nThere is one specific sequence of local complementations known as a pivot.\r\nApplied to an edge $uv$ of a graph, the pivot consists of complementing the neighbourhoods of $u$, $v$ and then $u$ again. \r\nIts net effect is to complement the edges between $N(u)\\setminus\\{v\\}$ and $N(v)\\setminus\\{u\\}$; if the starting graph is bipartite, it remains so after the pivot. \r\n\r\nWe observe that the universal chain graph $Z_n$ (Figure~\\ref{fig:T5}) can be pivoted to a path $P_{2n}$ and vice versa.\r\nTo transform $Z_n$ into $P_{2n}$, one can apply pivoting on the edges $a_2b_2,a_3b_3,\\ldots,a_{n-1}b_{n-1}$.  \r\nTherefore, rank- and shrub-depth are unbounded in the class of chain graphs as claimed.\r\n\r\n\\medskip\r\nIt remains to show that by excluding a path $P_k$ and a chain graph $Z_t$ within the universe of bipartite permutation graphs, we obtain a class $\\cal X$ of bounded rank- and shrub-depth.\r\nImmediately from the definition, we note that bounded neighbourhood diversity implies bounded shrub-depth, and that it is enough to prove that shrub-depth is bounded for connected graphs in $\\mathcal X$.  \r\n\r\nLet $G$ be a connected graph in $\\mathcal X$.  \r\nSince $P_k$ is forbidden, $G$ has lettericity at most $k - 1$, i.e., it can be embedded into the universal construction $H_{n,n}$ using at most $k-1$ consecutive rows. \r\nEvery two consecutive rows induce a chain graph, and since $Z_t$ is forbidden, this chain graph has neighbourhood diversity bounded by a constant, by Theorem \\ref{thm:nbd}. \r\nIt follows that the neighbourhood diversity of $G$ is bounded, as required. \r\n\\end{proof}\r\n\r\nOutside of the universe of bipartite permutation graphs there exist other minimal classes of unbounded shrub-depth and rank-depth related to linear forests and chain graphs, \r\nsuch as classes of folded linear forests (defined in Section~\\ref{sec:known}), the class of complements of chain graphs and the class of threshold graphs.\r\nTheorem~\\ref{thm:shrub-depth} suggests the following conjecture.\r\n\r\n\\begin{conjecture}\r\nShrub-depth and rank-depth are unbounded in a hereditary class $\\cal X$ if and only if $\\cal X$ contains a minimal hereditary class of unbounded shrub-depth and rank-depth.\r\nThe set of minimal classes is infinite and consists of all the classes of folded linear forests,  as well as  the classes of chain graphs, \r\ncomplements of chain graphs and threshold graphs. \r\n\\end{conjecture} \r\n   \r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\section{Algorithmic problems and minimal classes}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\label{sec:algo}\r\n\r\nThe simple structure of bipartite permutation graphs allows efficient solutions for many algorithmic problems that are generally NP-hard.\r\nHowever, some NP-hard problems remain intractable in this class, which is the case, for instance, for {\\sc pair-complete coloring} (also known as\r\n{\\sc achromatic number}), {\\sc harmonious coloring} \\cite{harmonious}, and {\\sc induced subgraph isomorphism} \\cite{isi}. In this section, we focus on the latter\r\nof these problems and identify a minimal hereditary subclass of bipartite permutation graphs where the problem is NP-hard.\r\n\r\nThe {\\sc induced subgraph isomorphism} ({\\sc ISI}, for short) problem can be stated as follows: given two graphs $H$ and $G$, decide whether $H$\r\nis an induced subgraph of $G$ or not. A hereditary class $\\cal X$ will be called \\emph{{\\sc ISI}-easy} if, for every instance $(G, H)$ with $G \\in \\cal X$, the problem can be solved in time\r\npolynomial in  $|V(G)|$, where the polynomial is independent of $|V(H)|$. Otherwise, $\\cal X$  will be called \\emph{{\\sc ISI}-hard}.\r\nAn inclusion-wise minimal {\\sc ISI}-hard class will be called \\emph{minimal {\\sc ISI}-hard}.\r\n\r\nThe {\\sc induced subgraph isomorphism} is known to be NP-complete in the class of linear forests, which is a proper subclass of bipartite permutation graphs \\cite{isi}. \r\nIn this section, we show that the class of linear forests is a minimal {\\sc ISI}-hard hereditary class. To do so, we express the ISI problem in proper subclasses of linear forests as a linear programming problem.\r\n\r\n\\bigskip\r\n\r\nWe represent a $P_{n+1}$-free linear forest as $\\alpha_1P_1+\\alpha_2P_2+\\ldots+\\alpha_{n-1}P_{n-1}+\\alpha_nP_n$, \r\nwhere $\\alpha_i \\in \\mathbb N_{\\geq 0}$, and the forest contains exactly $\\alpha_i$ connected components isomorphic to $P_i$.\r\n\r\n\r\nIf $G$ is a $P_{n+1}$-free linear forest, then all its induced subgraphs are also $P_{n+1}$-free linear forests, and the recognition problem for the class of $P_{n+1}$-free linear forests can be solved in polynomial time. So, we may assume that\r\n$$H=\\alpha_1P_1+\\alpha_2P_2+\\ldots+\\alpha_{n-1}P_{n-1}+\\alpha_nP_n,~\\text{and}$$\r\n$$G=\\beta_1P_1+\\beta_2P_2+\\ldots+\\beta_{n-1}P_{n-1}+\\beta_nP_n.$$\r\n\r\nNow, for each $1 \\leq i \\leq n$ we construct an integer matrix $A_i$ whose columns correspond to induced subgraphs of the path $P_i$. Specifically, $A_i$ has a column $(\\gamma_1, \\gamma_2, \\dots, \\gamma_n)$ for each linear forest $\\gamma_1 P_1 + \\gamma_2 P_2 + \\dots + \\gamma_n P_n$ that is an induced subgraph of the path $P_i$. Write $m_i$ for the number of columns of $A_i$, and let $A = (a_{ij}) := (A_1|A_2|\\ldots|A_n)$ be the horizontal concatenation of the $A_i$, with $m := m_1 + \\dots + m_n$ columns.\r\n\r\n\r\n%For any $1\\leq i \\leq n$, let us form an integer matrix $A_i$ with $n$ rows and $m_i$ columns.\r\n%We consider all the linear forests $\\gamma_1P_1+\\gamma_2P_2+\\ldots+\\gamma_{n-1}P_{n-1}+\\gamma_nP_n$, which are\r\n%induced subgraphs of $P_i$. Each column of $A_i$ corresponds to such a forest, and it is naturally filled with\r\n%the coefficients $\\gamma_1,\\gamma_2,\\ldots,\\gamma_n$. The number of these forests is denoted by $m_i$.\r\n%Let $A$ be the matrix $(A_1|A_2|\\ldots|A_n)$, i.e., the sequential join of the matrices $A_1,\\ldots,A_n$. It has\r\n%$n$ rows and $m=m_1+\\ldots+m_n$ columns. Hence, $A=(a_{ij})^{n\\times m}\\in \\mathbb{Z}_{+}^{n\\times m}$.\r\n\r\n%To solve the {\\sc ISI} problem for the pair $(H,G)$, we state some integer linear programming problem. \r\n\r\nFinally, consider the following system of linear constraints:\r\n\\begin{equation}\r\n\\label{s1}\r\n\\begin{cases}\r\n\\sum\\limits_{j=1}^{m}a_{ij}x_j\\geq \\alpha_i,\\forall i\\in \\{1,2,\\ldots,n\\},\\\\\r\n\\sum\\limits_{j=m_1+\\ldots+m_{i-1}+1}^{m_1+\\ldots+m_{i}}x_j\\leq \\beta_i,\\forall i\\in \\{1,2,\\ldots,n\\}.\r\n\\end{cases}\r\n\\end{equation}\r\n\r\n\\begin{lemma}\r\n\t\\label{l1a}\r\n\tThe graph $H$ is an induced subgraph of $G$ if and only if the system (\\ref{s1}) is compatible.\r\n\\end{lemma}\r\n\r\n\\begin{proof} \r\n\tWe interpret each column vector $(x_1, \\dots, x_m)^T \\in \\mathbb{N}^m$ as an attempt to embed, for each $j$, $x_j$ copies of the forest $a_{1,j}P_1+\\ldots+a_{n,j}P_n$ into different components of $G$. A sufficient condition for a simultaneous embedding to exist where each copy (across all $j$) uses a different component of $G$ is that, for each $i \\in \\{1, \\dots, n\\}$,\r\n\t$$\\sum\\limits_{j=m_1+\\ldots+m_{i-1}+1}^{m_1+\\ldots+m_{i}}x_j\\leq \\beta_i.$$\r\n\t\r\n\tNote that, if such an embedding exists, $G$ must contain the forest $$\\sum\\limits_{j=1}^{m}a_{1j}x_jP_1+\\sum\\limits_{j=1}^{m}a_{2j}x_jP_2+\\ldots+\\sum\\limits_{j=1}^{m}a_{nj}x_jP_n.$$ If, in addition,  we have for each $i \\in \\{1, \\dots, n\\}$ $$\\sum\\limits_{j=1}^{m}a_{ij}x_j\\geq \\alpha_i,$$ then the above forest, and hence $G$, must contain $H$ as an induced subgraph. This shows that a feasible solution to the system implies the existence of an embedding of $H$ into $G$.\r\n\t\r\n\t\\medskip\r\n\t\r\n\tConversely, assume that $H$ has an induced subgraph embedding $\\iota : H \\hookrightarrow G$. To produce a feasible solution to the system, write $G_1, \\dots, G_t$ for the connected components of $G$. For $1 \\leq s \\leq t$, let $v_s$ be the standard basis (column) vector in $\\mathbb{N}^m$ described as follows: if $G_s$ is isomorphic to $P_i$, then $v_s$ has a 1 in the row between $m_1 + \\dots + m_{i - 1} + 1$ and $m_1 + \\dots + m_i$ corresponding to the forest induced by $\\iota(H) \\cap G_s$. \r\n\t\r\n\tNow let $x := \\sum_{s = 1}^t v_s$. It can be checked that, by construction, $x$ is a feasible solution (with equality for the constraints involving the $\\alpha_i$).\r\n%\t\r\n%\t\r\n%\t\r\n%\tThen each connected component $P_i$ of $G$ contains some linear\r\n%\tsubforest of $H$, corresponding to a column in the matrix $A_i$. Write $x_j$ (with the appropriate index $j$)\r\n%\tthe number of the same linear forests, contained in distinct connected components of $G$, each isomorphic to $P_i$.\r\n%\tThen, for this vector of $x$'s, the $\\leq$-inequalities of the system (\\ref{s1}) hold and its $\\geq$-inequalities\r\n%\tare performed as equalities. Therefore, the lemma holds.\r\n\\end{proof}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n%For any $1\\leq j\\leq m$, we let the integer variable $x_j$ represent the number of connected components of $G$, each isomorphic to $P_j$,\r\n%in each of which the forest $a_{1,j}P_1+\\ldots+a_{n,j}P_n$\r\n%will be embedded. \r\n%The graph $H$ is an induced subgraph of $G$ if and only if $\\alpha_iP_i$ can be embedded in $G$\r\n%as an induced subgraph without problems with the other parts of $H$ and a connected component $P_i$ is not frequently used in $G$, for any $1\\leq i\\leq n$.\r\n%It can be described by the following system of constraints:\r\n\r\n%\\begin{equation}\r\n%\\label{s1}\r\n%\\begin{cases}\r\n%\\sum\\limits_{j=1}^{m}a_{ij}x_j\\geq \\alpha_i,\\forall i\\in \\{1,2,\\ldots,n\\},\\\\\r\n%\\sum\\limits_{j=m_1+\\ldots+m_{i-1}+1}^{m_1+\\ldots+m_{i}}x_j\\leq \\beta_i,\\forall i\\in \\{1,2,\\ldots,n\\}.\r\n%\\end{cases}\r\n%\\end{equation}\r\n%\r\n%\\begin{lemma}\r\n%\\label{l1a}\r\n%The graph $H$ is an induced subgraph of $G$ if and only if the system (\\ref{s1}) is compatible.\r\n%\\end{lemma}\r\n\r\n%\\begin{proof} If the system (\\ref{s1}) is compatible, then, by its $\\leq$-inequalities, the graph $G$ contains\r\n%$$\\sum\\limits_{j=1}^{m}a_{1j}x_jP_1+\\sum\\limits_{j=1}^{m}a_{2j}x_jP_2+\\ldots+\\sum\\limits_{j=1}^{m}a_{nj}x_jP_n$$\r\n%as an induced subgraph. By  $\\geq$-inequalities of the system (\\ref{s1}), this induced linear forest contains $H$\r\n%as an induced subgraph. Hence, $H$ is an induced subgraph of $G$.\r\n%\r\n%Conversely, assume that $H$ has an induced subgraph embedding into $G$. Then, any connected component $P_i$ of $G$ contains some linear\r\n%subforest of $H$, corresponding to a column in the matrix $A_i$. Denote by $x$ (with some index)\r\n%the number of the same linear forests, contained in distinct connected components of $G$, each isomorphic to $P_i$.\r\n%Then, for this vector of $x$'s, the $\\leq$-inequalities of the system (\\ref{s1}) hold and its $\\geq$-inequalities\r\n%are performed as equalities. Therefore, the lemma holds.\r\n%\\end{proof}\r\n\r\n\\begin{lemma}\r\n\\label{l2a}\r\nFor any fixed $n$, the {\\sc ISI} problem can be solved in polynomial time for $P_{n+1}$-free linear forests.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\nClearly, $m_i\\leq 2^i$, for any $i$. Therefore, $m\\leq n2^n$. The integer linear programming problem is known to be polynomial for a fixed number of variables \\cite{D12,GM19,K87,L83,VGZC19}. \r\nMore precisely, its best known complexity bound for $k$ variables is $O(k^k)$, multiplied by a polynomial in the length of the input data \\cite{D12,GM19,VGZC19}. \r\nBy these facts and Lemma~\\ref{l1a}, the result holds.\r\n\\end{proof}\r\n\r\n\r\n\r\nThe following statement is the main result of this section.\r\n\r\n\\begin{theorem}\r\n\\label{t1}\r\nThe class of linear forests is minimal hard for the {\\sc ISI} problem.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nThe class of all linear forests is known to be hard for the {\\sc ISI} problem \\cite{isi}.\r\nFor any proper hereditary subclass $\\cal X$ of  this class, a linear forest $F$ is forbidden.\r\nIf $F$ has $n$ vertices, then $F$ is an induced subgraph of $P_{2n}$\r\nand, hence, all graphs in $\\cal X$ are $P_{2n}$-free.\r\nThe theorem then follows from Lemma~\\ref{l2a}.\r\n\\end{proof}\r\n\r\nIf there exist {\\sc ISI}-hard subclasses of bipartite permutation graphs not containing the class of linear forests, then,\r\naccording to Theorem~\\ref{thm:classes-wqo}, each such subclass contains a minimal {\\sc ISI}-hard class. In other words,\r\nin the universe of bipartite permutation graphs the {\\sc ISI} problem can be characterized by a set of minimal {\\sc ISI}-hard classes.\r\nWe believe that this set consists of a single class.\r\n\r\n\\begin{conjecture}\r\nUnless P=NP, the {\\sc induced subgraph isomorphism} problem is NP-hard in a hereditary subclass $\\cal X$ of bipartite permutation graphs\r\nif and only if $\\cal X$ contains all linear forests. Equivalently, for any fixed $k$, the problem can be solved in polynomial time for $P_k$-free bipartite permutation graphs.\r\n\\end{conjecture}\r\n\r\nTo support the conjecture, we solve the problem for $P_5$-free bipartite graphs. \r\n\r\n\\begin{proposition}\r\nIf both $G$ and $H$ are $P_5$-free bipartite graphs, then the {\\sc induced subgraph isomorphism} problem\r\ncan be solved for the pair $(G,H)$ in polynomial time. \r\n\\end{proposition}\r\n\r\n\\begin{proof}\r\nWe reduce the problem to finding a maximum weight one-sided-perfect matching in an auxiliary edge-weighted complete bipartite graph $B$ with order linear in $|V_G|$. \r\nThis is equivalent to the assignment problem, which is well-known to take polynomial time. We first describe the graph $B$, then show how it can be constructed in polynomial time.\r\n\t\r\n\\smallskip\r\n\r\nNote that every connected component $G'$ of $G$ can accommodate at most one \r\nnon-trivial \r\n% (i.e., of size at least 2)\r\ncomponent $H'$ of $H$ as an induced subgraph, and potentially some isolated vertices of $H$. \r\nThe graph $B = (V_G \\cup V_H, E = V_G \\times V_H, \\omega:E \\to \\mathbb Z \\cup \\{-\\infty\\})$ is defined as follows: \r\n$V_G$ represents non-trivial connected components of $G$, while $V_H$ represents non-trivial connected components of $H$. The weight $\\omega((G', H'))$ of \r\nthe edge between components $G'$ and $H'$ indicates the maximum number of isolated vertices that can be accommodated by $G'$ in addition to $H'$, \r\nwith $-\\infty$ if $H'$ cannot be embedded into $G'$\\footnote{As is usual in these situations, $-\\infty$ is to be replaced, \r\nin practice, with a large enough negative number, say $-(|V(G)||V_G||V_H| + 1)$, that guarantees the weight of an optimal matching is negative if $H$ does not embed into $G$. \r\nFor notational reasons, we will keep it as $-\\infty$.}. \r\nWith this set-up, one easily checks that $H$ has an induced embedding in $G$ if and only if $B$ has a matching of size $|V_H|$ whose weight is at least the number of isolated vertices of $H$.  \r\n\r\n\\smallskip\r\n\r\nIt remains to show that $B$ can be constructed in polynomial time. The only non-trivial part is determining the edge weights. \r\nIn other words, for each of the $O(|V(G)||V(H)|)$ pairs $(G', H')$ of connected components, we must determine in polynomial time whether $H'$ can be embedded into $G'$, \r\nand if yes, we must find the maximum number of isolated vertices that can be embedded into $G'$ in addition to $H'$. \r\n\r\nGiven an embedding $\\iota : H' \\hookrightarrow G'$, write $\\mu(\\iota)$ for the size of a maximum independent set in $G' \\setminus N[\\iota(H')]$, \r\nwhere $N[A]$ denotes the closed neighbourhood of a set $A$ (i.e., $A$ together with all vertices having at least a neighbour in $A$). \r\nOur edge weight $\\omega((G', H'))$ is thus $\\max\\limits_{\\iota : H' \\hookrightarrow G'} (\\mu(\\iota))$ (with $-\\infty$ for a maximum over an empty set). \r\n\r\nTo compute the edge weights, we note that any connected $P_5$-free bipartite graph is $2K_2$-free (i.e., a chain graph), \r\nso we may encode it as a letter graph on the alphabet $\\{a, b\\}$ with decoder $\\{(a, b)\\}$ (see Section~\\ref{sec:lettericity} for details). \r\nAny connected chain graph admits at most two such representations (depending on which letter represents which side). \r\nGiven components $G'$ and $H'$, write $w_{H'}^1$ and $w_{H'}^2$ for the two words representing $H'$, and write $w_{G'}$ for one of the two words representing $G'$. \r\nThis gives a one to one correspondence between the set of induced subgraph embeddings $\\iota : H' \\hookrightarrow G'$ and \r\nthe union of the sets of subword embeddings $\\iota_w : w_{H'}^i \\hookrightarrow w_{G'}$ for $i = 1, 2$. \r\nIn particular, $H'$ has an induced subgraph embedding $\\iota$ into $G'$ if and only if one of $w_{H'}^1$ and $w_{H'}^2$ has a corresponding subword embedding $\\iota_w$ into $w_{G'}$.\r\n\r\nDetermining whether such an embedding $\\iota_w$ exists can be done greedily in linear time, but that only tells us whether the corresponding edge in $B$ has weight $-\\infty$ or not. \r\nWe claim that, for any embedding $\\iota$, $\\mu(\\iota)$ can be easily computed from the corresponding subword embedding $\\iota_w$. \r\nTo see this, note that, since $H'$ is connected, the first letter of $w_{H'}$ is an $a$, while the last letter is a $b$. \r\nThen $\\mu(\\iota)$ is the number of $b$'s before the first $a$ in $\\iota_w(w_{H'})$ plus the number of $a$'s after the last $b$. \r\nIndeed, those $b$s in the prefix $a$s in the suffix correspond to an independent set, and every other vertex is adjacent to at least one of the initial $a$ and final $b$ of $\\iota_w(w_{H'})$. \r\n\r\nThus $\\mu(\\iota)$ only depends on the positions of the first and last letters of the embedding $\\iota_w$. This gives us the following way of determining $\\omega((G', H'))$ in polynomial time:\r\n\\begin{enumerate}\r\n\t\\item Set $\\nu = -\\infty$.\r\n\r\n\t\\item Check (in linear time) if any of the two $w_{H'}^i$ embeds as a subword in $w_{G'}$. If not, return $\\nu$.\r\n\t\r\n\t\\item For each pair of letters $l_i, l_j$ in $w_{G'} = l_1l_2 \\dots l_t$ with $i < j$, $l_i = a$ and $l_j = b$:\r\n\t\r\n\t\\begin{enumerate}\r\n\t\t\\item Write $w_{G'}$ as a concatenation $w_1w_2w_3$, where $w_2$ is the substring that starts with $l_i$ and ends with $l_j$. \r\n\t\t\r\n\t\t\\item Determine (in linear time) whether any of the two $w_{H'}^i$ embeds in $w_2$. \r\nIf not, continue to the next pair. If yes, let $\\nu'$ be the number of $b$s in $w_1$ plus the number of $a$s in $w_3$, and set $\\nu := \\max(\\nu, \\nu')$.\r\n\t\\end{enumerate} \r\n\t\r\n\t\\item Return $\\nu$.\r\n\\end{enumerate}\r\n\r\nIt is routine to check that the above procedure terminates in polynomial time, and that the value returned is $\\max\\limits_{\\iota : H' \\hookrightarrow G'} (\\mu(\\iota))$ as required.\r\n% It was shown in \\cite{isi} that the ISI problem can be solved in polynomial time provided $H$ is connected. Since finding connected components and maximum independent sets in bipartite graphs is easy, this implies that the graph $B$ can be constructed in polynomial time. The initial problem then reduces to finding a matching of maximum weight in $B$, which can also be done in polynomial time. \r\n%Since identifying the respective components is easy, it suffices to show that, given {\\emph connected} $P_5$-free graphs $G$ and $H$, Every connected $P_5$-free bipartite graphs is $2K_2$-free, i.e., a chain graph.\r\n%Since $H$ may contain isolated vertices, the problem reduces \r\n%to the question of determining what is the maximum number of isolated vertices that can be accommodated by $G'$ in addition to $H'$. This can be done\r\n%by encoding a chain graph as a $2$-letter graph. Every connected chain graph admits at most 2 such representations (one with top vertices labelled $a$\r\n%and bottom vertices labelled $b$, and vice versa). If a chain graph contains isolated vertices, then they can appear in a  $2$-letter representation\r\n%either as $b$ vertices in the prefix or as $a$ vertices in the suffix (with the decoder  from Section~\\ref{sec:lettericity}). Which isolated vertex \r\n%is placed in the prefix and which in the suffix does not matter. What matters is the length of the prefix and the suffix only. Once an encoding is \r\n%fixed, one can decide in linear time if one word (graph) contains the other word (graph) as a subword (an induced subgraph). Therefore, for each component \r\n%$G'$ of $G$ and each component $H'$ of $H$ one can determine in polynomial time whether $H'$ is an induced subgraph of $G'$ and \r\n%what is the maximum number of isolated vertices that can be accommodated by $G'$ together with $H'$. \r\n%\r\n%Finally, we construct an auxiliary edge-weighted bipartite graph, one part of which represents non-trivial connected components of $G$, the other part\r\n%represents non-trivial connected components of $H$, an edge between $G'$ and $H'$ indicates that $G'$ contains $H'$ as an induced subgraph and the weight of \r\n%the edge indicates the maximum number of isolated vertices that can be accommodated by $G'$ together with $H'$. \r\n%Thus, the initial problem reduces to finding a matching of maximum weight in this auxiliary graphs, which can be solved in polynomial time. \r\n\\end{proof}\r\n\r\n\r\n%Let us repeat that the class of linear forests is one of the infinitely many classes of \r\n%the form ${\\cal P}(w,K)$, where $K$ is a finite graph with loops allowed and $w$ is an infinite almost periodic word over $V(K)$, called in Section~\\ref{sec:known} folded linear forests.\r\nLet us repeat that the class of linear forests is one of the infinitely many classes ${\\cal P}(w, K)$ of folded linear forests, defined in Section~\\ref{sec:known}. \r\nWe conjecture that all classes of this form are minimal hard for the {\\sc induced subgraph isomorphism} problem. \r\n\r\n\\begin{conjecture}\r\nEach class of folded linear forests is a minimal hard class for the {\\sc induced subgraph isomorphism} problem.\r\n\\end{conjecture}\r\n\r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\section{Universal graphs and minimal classes}\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\label{sec:uni}\r\n\r\nAs we have seen earlier, the class of bipartite permutation graphs contains a universal element of quadratic order, i.e.,\r\na graph with $n^2$ vertices that contains all $n$-vertex bipartite permutation graphs as induced subgraphs. On the other\r\nhand, for the class of chain graphs, we have an $n$-universal graph on $2n$ vertices, i.e., a universal graph of linear order. \r\nThis raises many questions regarding the growth rates of order-optimal universal graphs for subclasses of bipartite permutation graphs. One of the most immediate questions is identifying a boundary separating classes with a universal graph of linear order from classes where the smallest universal graph is super-linear.\r\nIn this section, we show that the class of star forests is a minimal hereditary class with a super-linear universal graph.\r\n\r\nBefore we present the result for star forests, let us observe that in general not every hereditary class $\\cal X$ contains a universal graph, \r\nand even if it does, an optimal universal construction for $\\cal X$ does not necessarily belong to $\\cal X$. \r\nIn order to circumvent these difficulties (and to ensure downwards closure of the set of classes with, say, linear universal graphs), \r\nwe will only consider universal constructions consisting of bipartite permutation graphs. In other words, whenever we look for universal constructions \r\nfor some class $\\mathcal X \\subseteq \\mathcal{BP}$, we allow {\\em any} bipartite permutation graphs,  and {\\em only} bipartite permutation graphs, to appear in our universal constructions.\r\n\r\n\\medskip\r\n\r\nIn the following lemma we first describe a star forest of order $O(n\\cdot \\log(n))$ containing all $n$-vertex star forests as induced subgraphs,\r\nand then we show that this construction is (asymptotically) order-optimal in the universe of all bipartite permutation graphs. To simplify notation, throughout this section we denote the star $K_{1,n}$ by $S_{n}$.\r\n\r\n\\begin{lemma}\\label{l2}\r\nThe minimum number of vertices in a bipartite permutation graph containing all $n$-vertex star forests is $\\Theta(n\\cdot \\log(n))$.  \r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\nLet $F^*$ be the star forest $S_{\\left\\lfloor\\frac{n}{1}\\right\\rfloor}+S_{\\left\\lfloor\\frac{n}{2}\\right\\rfloor}+\\ldots+S_{\\left\\lfloor\\frac{n}{n-1}\\right\\rfloor}+S_{\\left\\lfloor\\frac{n}{n}\\right\\rfloor}$.\r\nIt is a bipartite permutation graph, and it has $n$ connected components and $\\sum\\limits_{i=1}^{n} (\\lfloor\\frac{n}{i}\\rfloor+1)$ vertices.\r\nAs $\\lfloor x\\rfloor<x$, for any $x$, $F^*$ has $O(\\sum\\limits_{i=1}^{n} \\frac{n}{i})$ vertices. Recall that the $n$-th harmonic number $\\sum\\limits_{i=1}^{n} \\frac{1}{i}$ \r\nis equal to\t$\\ln(n)+\\gamma+\\epsilon_n$, where $\\gamma=0.577\\ldots$ is the Euler--Mascheroni constant and $\\epsilon_n$ tends to $0$ with $n$ tending to infinity.\r\nTherefore, $F^*$ has $O(n\\cdot \\log(n))$ vertices.\r\n\t\r\nLet us show that $F^*$ is a universal graph for $n$-vertex star forests. Indeed, let $F=S_{a_1}+S_{a_2}+\\ldots+S_{a_p}$ be an $n$-vertex star forest,\r\nwhere $a_1\\geq a_2\\geq \\ldots \\geq a_p$. Clearly, $i\\cdot a_i\\leq a_1+\\ldots+a_i<n$, for any $1\\leq i\\leq p\\leq n$.\r\nHence, $a_i<\\frac{n}{i}$ and $a_i\\leq \\left\\lfloor\\frac{n}{i}\\right\\rfloor$, as $a_i$ is an integer. \r\nTherefore, for any $i$, $S_{a_i}$ is an induced subgraph of $S_{\\left\\lfloor\\frac{n}{i}\\right\\rfloor}$. Thus, $F$ is an induced subgraph of $F^*$. \r\n\r\n\\medskip\t\r\nTo prove a lower bound, let $H$ be a bipartite permutation graph containing all $n$-vertex star forests. \r\nIt can be embedded, as an induced subgraph, into $H_{n',n'}$  for some $n'$ (see Figure \\ref{fig:H55}). \r\nNow let $n_1, n_2, \\dots$ be a list in non-increasing order of the numbers of vertices of $H$ embedded in each row of $H_{n', n'}$ \r\n(so that $n_1$ is the number of vertices of $H$ in a row of $H_{n', n}$ with the most vertices of $H$, and so on).\r\nWe show that $n_i \\geq \\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{10i}\\right\\rfloor-1\\right)$ for any $1 \\leq i \\leq \\left\\lfloor\\frac{n}{20} \\right\\rfloor$, \r\nimplying that the graph $H$ has $\\Omega(n\\cdot \\log(n))$ vertices.\r\n\t\r\n\r\nLet $t \\in \\{10i: i \\in \\mathbb N\\} \\cap \\{1, \\dots, \\left\\lfloor\\frac{n}{2}\\right\\rfloor\\}$. \r\nBy $F_t$, we denote the star forest with $t$ connected components, each isomorphic to $S_{\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$. \r\nFor any $t$, the graph $F_t$ is an induced subgraph of $H$ and hence $F_t$ must embed into $H_{n',n'}$. \r\nSince any two consecutive rows of $H_{n',n'}$ induce a chain graph, i.e., a $2K_2$-free graph,  \r\nany row of $H_{n',n'}$ contains the centres of at most two  stars of $F_t$. \r\nEach star intersects at most 3 consecutive rows of $H_{n', n}$, hence a star can intersect the same row as at most 9 other stars. It is therefore possible to find  $\\frac{t}{10}$ stars\r\n$S_{\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$ in $F_t$ such that no two of them intersect the same row of $H_{n',n'}$, and thus there are at least  $\\frac{t}{10}$ \r\npairwise distinct rows in $H_{n',n'}$, each of which contains at least $\\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1\\right)$ vertices of $H$. \r\nIt follows that $n_{t/10} \\geq \\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1\\right)$ or, \r\nchanging indices, that $n_i \\geq \\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{10i}\\right\\rfloor-1\\right)$ for any $1 \\leq i \\leq \\left\\lfloor\\frac{n}{20} \\right\\rfloor$ as required.\r\n%By $F_t$, where $1\\leq t\\leq \\left\\lfloor\\frac{n}{2}\\right\\rfloor$, we denote the $n$-vertex star forest with $t$ connected components, \r\n%each isomorphic to $S_{\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$, and, possibly, one connected component $S_{n-n\\cdot\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$, whenever $t$ does not divide $n$. \r\n%Notice that $S_{\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$ has at least two vertices. For any $t$, the graph $F_t$ is an induced subgraph of $H$ and hence $F_t$ must embed into $H_{n',n'}$. Since any two consecutive rows of $H_{n',n'}$ induce a chain graph, i.e., a $2K_2$-free graph,  \r\n%any row of $H_{n',n'}$ contains the centres of at most two  stars of $F_t$. Each star intersects at most 3 consecutive rows of $H_{n', n}$, hence a star can use the same row as at most 9 other stars. It is therefore possible to find  $\\left\\lfloor\\frac{t}{10}\\right\\rfloor$ stars\r\n%$S_{\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1}$ in $F_t$ such that no two of them share a row of $H_{n',n'}$, and thus there are at least  $\\left\\lfloor\\frac{t}{10}\\right\\rfloor$ \r\n%pairwise distinct rows in $H_{n',n'}$, each of which contains at least $\\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1\\right)$ vertices of $H$. Hence $n_{\\left\\lfloor\\frac{t}{10}\\right\\rfloor} \\geq \\frac{1}{2}\\left(\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1\\right)$ for any $1 \\leq t \\leq \\left\\lfloor\\frac{n}{2}\\right\\rfloor$. In particular, changing indices, $n_i \\geq \\frac{1}{20}\\left(\\left\\lfloor\\frac{n}{t}\\right\\rfloor-1\\right)$ for any $1 \\leq i \\leq \\left\\lfloor\\frac{n}{2}\\right\\rfloor$ %for any $1 \\leq i \\leq \\left\\lfloor\\frac{t}{10}\\right\\rfloor$\r\n%\r\n%\r\n% Therefore, there are $\\lfloor\\frac{t}{6}\\rfloor$ stars\r\n%$S_{\\lfloor\\frac{n}{t}\\rfloor-1}$ in $F_t$ such that no two of them share a row of $H_{n',n'}$.  \r\n%Every induced subgraph $S_{\\lfloor\\frac{n}{t}\\rfloor-1}$ is located in at most three consecutive rows in  $H_{n',n'}$, \r\n%and one of them contains at least $\\frac{1}{2}(\\lfloor\\frac{n}{t}\\rfloor-1)$ vertices of $S_{\\lfloor\\frac{n}{t}\\rfloor-1}$. \r\n%Therefore, for any $1\\leq t\\leq \\lfloor\\frac{n}{2}\\rfloor$, there are $\\lfloor\\frac{1}{2}\\lfloor\\frac{t}{6}\\rfloor\\rfloor$ \r\n%pairwise distinct rows in $H_{n',n'}$, each of which contains $\\frac{1}{2}(\\lfloor\\frac{n}{t}\\rfloor-1)$ vertices of $H$. \r\n%Hence, $n_i\\geq \\frac{1}{2}(\\lfloor\\frac{n}{i}\\rfloor-1)$, for any $1\\leq i\\leq \\lfloor\\frac{1}{2}\\lfloor\\frac{\\lfloor\\frac{n}{2}\\rfloor}{6}\\rfloor\\rfloor$. \t\r\n\\end{proof}\r\n\r\n \r\n\r\n\\begin{theorem}\r\n\\label{l4}\r\nThe class of star forests is a minimal hereditary class that does not admit a universal bipartite permutation graph of linear order.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nLet ${\\mathcal X}$ be any proper hereditary subclass of the class $\\mathcal{SF}$ of star forests. Then, ${\\mathcal X}\\subseteq \\mathcal{SF}\\cap \\Free(kS_k)$\r\nfor some $k$. Therefore, every graph in $X$ consists of at most $k-1$ stars with at least $k$ leaves and arbitrarily many stars with at most $k-1$ leaves. \r\nBut then $(k-1)S_n+nS_{k-1}$ is an $n$-universal graph for $\\cal X$ of linear order.\r\n\\end{proof}\r\n\r\n\r\nThe class of star forests is not the only obstruction to admitting a universal graph of linear order.\r\nTo see this, we show that the class of $3S_6$-free bipartite permutation graphs requires a super-linear universal graph. \r\n\r\n\\begin{lemma}\\label{lem:univlowerbound}\r\n\tSuppose $H$ is a bipartite permutation graph containing all $n$-vertex $3S_6$-free graphs as induced subgraphs. Then $|V(H)| = \\Omega(n^{3/2})$.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\nTo prove the statement, we will show there must be $\\Omega(n^3)$ pairs of vertices in $H$, from which we immediately get $$|V(H)|^2 \\geq {|V(H)| \\choose 2} \\geq \\Omega(n^3)$$ and so $|V(H)| = \\Omega(n^{3/2})$.\r\n\r\n\\bigskip\r\n\r\nWe know $H$ can be embedded as an induced subgraph into a universal graph $H_{n', n'}$ for some $n'$. \r\nThe main idea is to construct a structure that is ``rigid'', in the sense that we can guarantee the distance (within the structure) \r\nbetween certain vertices is not much greater than the distance in $H_{n', n'}$ between the embeddings of those vertices. \r\nTo this end, we use a result due to Ferguson \\cite{pathlet}, that states the lettericity of the path $P_s$, for $s \\geq 3$, \r\nis precisely $\\left\\lfloor\\frac{s + 4}{3}\\right\\rfloor$.\\footnote{The bounds from \\cite{Pet02} are sufficient for the proof, \r\nbut make it a bit messier.} In our language, it follows that any embedding of a chordless path $P_s$ into $H_{n',n'}$ uses \r\nat least $\\left\\lfloor\\frac{s + 4}{3}\\right\\rfloor$ layers (rows). \r\n\r\nSince edges appear only between successive layers, the set of layers used by an embedding of the path is an interval. \r\nMoreover, the ends of a chordless path do not appear more than one layer away from the extremal layers in the interval, \r\notherwise a $2K_2$ forms between two of the layers. This implies that the distance between the ends of a chordless path $P_s$ \r\nmust be at least $\\left\\lfloor\\frac{s + 4}{3}\\right\\rfloor - 3 = \\left\\lfloor\\frac{s - 5}{3}\\right\\rfloor$.\r\n\r\n\\bigskip\r\n\r\nFor each $t$, we construct in two steps a graph $Q_t$ as depicted in Figure \\ref{fig:rigidgraph}.\r\n\r\n\r\n\\begin{figure}[ht]\r\n\t\\centering\r\n\t\\begin{subfigure}[t]{0.49\\linewidth}\r\n\t\t\\centering\r\n\t\t\\begin{tikzpicture}[scale=1, transform shape]\r\n\t\t\r\n\t\t%all vertices\r\n\t\t\\foreach \\i in {1,...,6}{\r\n\t\t\t\\filldraw (\\i, \\i) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {1,...,5}{\r\n\t\t\t\\filldraw (\\i + 1, \\i) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {1,...,5}{\r\n\t\t\t\\filldraw (\\i, \\i + 1) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t%all edges\r\n\t\t\\foreach \\i in {1,...,5}{\r\n\t\t\t\\draw (\\i, \\i + 1) -- (\\i + 1, \\i);\r\n\t\t\t\\draw (\\i, \\i) -- (\\i, \\i + 1);\r\n\t\t\t\\draw (\\i + 1, \\i) -- (\\i + 1, \\i + 1);\r\n\t\t}\r\n\t\t\r\n\t\t%labels for vertices\r\n\t\t\\draw (1, 1) node[below left] {$q$};\r\n\t\t\\draw (6, 6) node[above right] {$p$};\r\n\t\t\r\n\t\t\r\n\t\t\\end{tikzpicture}\r\n\t\t\\captionsetup{justification=centering}\r\n\t\t\\caption*{Step 1: Start with a chordless path on \\\\ $3t + 7$ vertices.}\r\n\t\\end{subfigure}\t\r\n\t\\begin{subfigure}[t]{0.49\\linewidth}\r\n\t\t\\centering\r\n\t\t\\begin{tikzpicture}[scale=1, transform shape]\r\n\t\t\r\n\t\t%all vertices\r\n\t\t\\foreach \\i in {0,...,5}{\r\n\t\t\t\\filldraw (\\i, \\i) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {0,...,4}{\r\n\t\t\t\\filldraw (\\i + 1, \\i) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {0,...,4}{\r\n\t\t\t\\filldraw (\\i, \\i + 1) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\r\n\t\t%all edges\r\n\t\t\\foreach \\i in {0,...,4}{\r\n\t\t\t\\draw (\\i, \\i + 1) -- (\\i + 1, \\i);\r\n\t\t\t\\draw (\\i, \\i) -- (\\i, \\i + 1);\r\n\t\t\t\\draw (\\i + 1, \\i) -- (\\i + 1, \\i + 1);\r\n\t\t}\r\n\t\t\r\n\t\t%new path\r\n\t\t\\foreach \\i in {1,...,6}{\r\n\t\t\t\\filldraw (-1, \\i) circle (2pt) node[below left] {};\r\n\t\t}\r\n\t\t\\draw (-1, 1) -- (-1, 6);\r\n\t\t\r\n\t\t%connection to old path\r\n\t\t\\foreach \\i in {2,...,6}{\r\n\t\t\t\\draw (-1, \\i) -- (\\i - 2, \\i - 1);\t\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {1,...,6}{\r\n\t\t\t\\draw (-1, \\i) -- (\\i - 1, \\i - 1);\r\n\t\t}\r\n\t\t\r\n\t\t\\foreach \\i in {1,...,5}{\r\n\t\t\t\\draw (-1, \\i) -- (\\i, \\i - 1);\r\n\t\t}\r\n\t\t\r\n\t\t%labels for vertices\r\n\t\t\\draw (-1, 1) node[below left] {$y$};\r\n\t\t\\draw (-1, 6) node[above left] {$x$};\r\n\t\t\\draw (0, 0) node[below left] {$q$};\r\n\t\t\\draw (5, 5) node[above right] {$p$};\r\n\t\t\r\n\t\t\\end{tikzpicture}\r\n\t\t\\captionsetup{justification=centering}\r\n\t\t\\caption*{Step 2: Add a chordless path on $t + 3$ vertices, connecting it to the previous path as above.}\t\r\n\t\\end{subfigure}\r\n\t\\caption{The graph $Q_t$ for $t = 3$}\r\n\t\\label{fig:rigidgraph}\r\n\\end{figure}\t\r\n\r\n\r\nIt is easy to see that $Q_t$ is a bipartite permutation graph, since we can embed the rows in the figure into successive layers of the universal graph. \r\nMoreover, writing $d_G$ for the distance in a graph $G$, we have (using the triangle inequality and the above discussion, and assuming for now that $Q_t$ embeds into $H$), \r\n$$d_H(x, y) \\geq d_H(p, q) - 2 \\geq t - 2$$ and $$d_H(x, y) \\leq d_{Q_t}(x, y) = t + 2.$$\r\n\r\n\\bigskip \r\n\r\nWe now construct bipartite permutation graphs $R_{n, t}$ from $Q_t$ by replacing $x$ and $y$ with independent sets \r\n$X$, $Y$ of twins of size $\\left\\lfloor\\frac{n - 4t - 8}{2}\\right\\rfloor$ each, with the same adjacencies as $x$ and \r\n$y$ respectively (we only construct those $R_{n, t}$ for which the above quantity is positive). \r\nWe note that $|V(R_{n, t})| \\leq n$ by construction, and $R_{n, t}$ is easily seen to be $3S_6$-free, so that $R_{n, t}$ is an induced subgraph of $H$. \r\nIn addition, like with the original $x$ and $y$, each new pair $x \\in X$ and $y \\in Y$ has $|d_H(x, y) - t| \\leq 2$.\r\n\r\nFor $3 \\leq t \\leq \\left\\lfloor\\frac{n}{6}\\right\\rfloor - 2$, we have $|X| = |Y| \\geq \\left\\lfloor\\frac{n}{6}\\right\\rfloor$. \r\nIn particular, each choice of $t \\in I := \\{3, 4, \\dots, \\left\\lfloor\\frac{n}{6}\\right\\rfloor - 2\\} \\cap \\{3 + 5i : i \\in \\mathbb N\\}$ \r\nwitnesses the existence in $H$ of $|X||Y| \\geq \\left\\lfloor\\frac{n}{6}\\right\\rfloor^2$ pairs of vertices, and since \r\nthe pairs' distance ranges for different $t \\in I$ do not overlap, the sets of pairs are disjoint. \r\nHence $H$ must contain in total at least \r\n$$|I|\\left\\lfloor\\frac{n}{6}\\right\\rfloor^2 \\geq  \\frac{1}{5}\\left(\\left\\lfloor\\frac{n}{6}\\right\\rfloor - 5\\right)\\left\\lfloor\\frac{n}{6}\\right\\rfloor^2 = \\Omega(n^3)$$ pairs, as claimed.\r\n\\end{proof}\r\n\r\nLemma \\ref{lem:univlowerbound} shows indeed that there are other obstructions to a linear universal graph, \r\nbut it is not yet clear what those obstructions are. For instance, the existence of a linear universal graph \r\nis a non-trivial question even for $S_t$-free graphs, i.e., bipartite permutation graphs of maximum degree at most $t - 1$. \r\nIn fact, it is not clear whether every class with super-linear universal graphs contains a minimal such class, \r\nsince the boundary class $\\cal L$ described in Section~\\ref{sec:wqo} has linear universal graphs. We leave the continuation of this study as an open problem.\r\n\r\n\\begin{problem}\r\nCharacterise the family of hereditary subclasses of bipartite permutation graphs that admit a universal bipartite permutation graph of linear order.\r\n\\end{problem}\r\n\r\nWe conclude the paper with one more related open problem. Theorem~\\ref{thm:lettericity-bound} shows that the graph $H_{n,n}$ is not an optimal \r\nuniversal construction for the class of bipartite permutation graphs, because all graphs in this class can be embedded into \r\n$H_{n/2+1,n}$ as induced subgraphs. However, this construction is still quadratic. On the other hand, the following result provides an almost quadratic lower bound on the size of a universal graph.\r\n\r\n\\begin{theorem}\\label{lem:univlowerbound2}\r\n\tSuppose $H$ is a bipartite permutation graph that contains all $n$-vertex bipartite permutation graphs as induced subgraphs. Then $|V(H)| = \\Omega(n^\\alpha)$ for any $\\alpha < 2$.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\nWe show $|V(H)| = \\Omega(n^{2a-1/a})$ for each $a \\in \\mathbb N$. This is a generalisation of Lemma~\\ref{lem:univlowerbound}, which deals with the case $a = 2$. \r\n\t\r\nThe proof of Lemma~\\ref{lem:univlowerbound} generalises as follows.\r\nFor $a \\in \\mathbb N$, we get $|V(H)| = \\Omega(n^{2a-1/a})$ by counting $a$-sets of vertices. \r\nTo do this, we associate to each $a$-set the $a \\choose 2$-multiset consisting of distances between pairs of its vertices; \r\nwe will refer to this $a \\choose 2$-multiset as the ``distance multiset (in $H$)'' of the original $a$-tuple. \r\nIn order to determine that two $a$-sets are distinct, it is enough to show they have distinct distance multisets.\r\n\t\r\nWe generalise the construction of the graphs $R_{n, t}$ to graphs $R_{n, T}$, where $T$ is a set of $a - 1$ natural numbers, \r\neach at least $3$. To construct $R_{n, T}$, we start with $Q_{\\max(T)}$, but instead of inflating just the endpoints of the second path, \r\nwe inflate the first vertex, then the $j + 3$rd, for each $j \\in T$. \r\nBy putting an appropriate upper bound (linear in $n$) on the size of elements in $T$, say $\\lambda n$, \r\nwe can arrange that each inflated set $X_j$ has size linear in $n$, while ensuring $|V(R_{n, T})| \\leq n$. \r\n\t\r\nThe set $T$ can be viewed as a condition on the distance multiset in $R_{n, T}$ of certain $a$-sets: \r\nan $a$-set consisting of one vertex from each inflated set $X_j$ has $\\{t + 2: t \\in T\\}$ as a subset of its distance multiset in $R_{n, T}$. \r\nThe distance multiset in $H$ might differ from the one in $R_{n, T}$, but like before, rigidity of the structure ensures the two are within a small tolerance of each other. \r\nTherefore, as long as we are careful in choosing what sets $T$ we consider, we can ensure that different choices of $T$ will give rise to different distance multiset subsets in $H$. \r\nThis is achieved by choosing, like before, $T \\subseteq \\{3, \\dots, \\lambda n\\} \\cap \\{3 + 5i : i \\in \\mathbb N\\}$.\r\n\t\r\nOne last hurdle is the following: in order to decide that two $a$-sets of vertices are distinct, \r\nwe actually need to compare them via their whole distance multisets, not just via the $a - 1$-subsets \r\ncoming from the choice of $T$. We notice, however, that the same distance multiset can account (conservatively) for at most ${a \\choose 2} \\choose a  - 1$ different choices of $T$.\r\n\t\r\nAltogether,\teach choice of $T \\subseteq \\{3, \\dots, \\lambda n\\} \\cap \\{3 + 5i : i \\in \\mathbb N\\}$ \r\nwitnesses the existence of $\\Omega(n^a)$ $a$-sets of vertices in $H$, and each $a$-set is repeated overall \r\nat most a constant number of times. Since there are $\\Omega(n^{a - 1})$ choices for $T$, \r\nthis shows $|V(H)|^a \\geq {|V(H)| \\choose a} = \\Omega(n^{2a - 1})$, from which $|V(H)| = \\Omega(n^{2a - 1/a})$ as required.  \r\n\\end{proof}\r\n\r\nWe conjecture that the optimal universal graph is, in fact, quadratic. \r\n\r\n\\begin{conjecture}\r\n\tThe minimum number of vertices in a bipartite permutation graph containing all $n$ vertex bipartite permutation graphs is $\\Omega(n^2)$. \r\n\\end{conjecture}\r\n\r\nEstablishing the optimal constant would then be a problem analogous to the study of superpatterns from the world of permutations \r\n(see, for instance, \\cite{superpattern321free, superpattern}\\footnote{We remark that the study of superpatterns is usually done \r\nin the universe of {\\it all} permutations, while in this paper we restrict ourselves to {\\it bipartite} permutation graphs - \r\nthis is the reason behind the apparent discrepancy between the upper bound from \\cite{superpattern321free} and our lower bound from Lemma~\\ref{lem:univlowerbound2}.}). \r\n\r\n\r\n\r\n\r\n\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\begin{thebibliography}{99}\r\n\t%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\t\r\n\\bibitem{cographs}\r\nB. Alecu, V. Lozin, D. de Werra,\r\nThe micro-world of cographs,\r\n{\\it Lecture Notes in Computer Science} 12126 (2020) 30--42.\r\n\t\r\n\t\r\n\\bibitem{Ale03}\r\nV.E. Alekseev,\r\nOn easy and hard hereditary classes of graphs with respect to the independent set problem,\r\n{\\it Discrete Applied Mathematics}, 132 (2003) 17--26.\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\bibitem{AKL04}\r\nV.E. Alekseev, D.V. Korobitsyn,  V.V. Lozin,\r\nBoundary classes of graphs for the dominating set problem,\r\n{\\it Discrete Mathematics}, 285 (2004) 1--6.\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\bibitem{ABKL07}\r\nV.E. Alekseev, R. Boliac, D.V. Korobitsyn, V.V. Lozin,\r\nNP-hard graph problems and boundary classes of graphs,\r\n{\\it  Theoret. Comput. Sci}. 389 (2007) 219--236.\r\n\r\n\r\n\\bibitem{harmonious}\t\r\nK. Asdre, S.D. Nikolopoulos,\r\nNP-completeness results for some problems on subclasses of bipartite and chordal graphs,\r\n{\\it Theoret. Comput. Sci.} 381 (2007) 248--259.\r\n\r\n\\bibitem{finite}\r\nA. Atminas, R. Brignall, Well-quasi-ordering and finite distinguishing number,\r\n{\\it J. Graph Theory}, 95 (2020) 5--26. \r\n\r\n\\bibitem{Bell}\t\r\nA. Atminas, A. Collins, J. Foniok, and V. Lozin,\r\nDeciding the Bell number for hereditary graph properties,\r\n{\\it SIAM J. Discrete Mathematics}, 30 (2016) 1015--1031.\t\r\n\t\r\n\\bibitem{Razgon}\r\nA. Atminas, V.V. Lozin, and I. Razgon,\r\nLinear time algorithm for computing a small biclique in graphs without long induced paths.\r\n{\\it Lecture Notes in Computer Science}, 7357 (2012) 142--152.\r\n\r\n\r\n\r\n\r\n\\bibitem{SpHerProp}\r\nJ. Balogh, B. Bollob\\'as, D. Weinreich, \r\nThe speed of hereditary properties of graphs. \r\n{\\it J. Combin. Theory Ser. B} 79 (2000), no. 2, 131--156.\r\n\r\n\\bibitem{Jump}\r\nJ. Balogh, B. Bollob\\'as, D. Weinreich, \r\nA jump to the Bell number for hereditary graph properties.\r\n{\\it J. Combin. Theory Ser. B}  95  (2005),  no. 1, 29--48.\r\n\r\n\r\n\r\n \\bibitem{superpattern321free}\r\n M. J. Bannister, W. E. Devanny, D. Eppstein, Small Superpatterns for Dominance Drawing, {\\it 2014 Proceedings of the Meeting on Analytic Algorithmics and Combinatorics (ANALCO)} (2014)  92--103.\r\n\t\r\n\\bibitem{ISI}\r\nR. Belmonte, P. Heggernes, P. van 't Hof,\r\nEdge contractions in subclasses of chordal graphs,\r\n{\\it Discrete Appl. Math}. 160 (2012) 999--1010.\r\n\t\r\n\r\n\r\n\\bibitem{Parikh}\r\nS. Bera, K. Mahalingam,\r\nStructural properties of word representable graphs,\r\n{\\it Math. Comput. Sci.} 10 (2016) 209--222.\r\n\r\n\r\n% \\bibitem{achromatic}\r\n% H.L. Bodlaender,\r\n% Achromatic number is NP-complete for cographs and interval graphs.\r\n% {\\it Information Processing Letters}, 31 (1989)  135--138.\r\n\r\n\\bibitem{cw-bound}\r\nB. Courcelle, S. Olariu,\r\nUpper bounds to the clique width of graphs,\r\n{\\it Discrete Applied Mathematics} 101 (2000) 77--114.\r\n\r\n\r\n\r\n\\bibitem{D12}\r\nD. Dadush,\r\nInteger programming, lattice algorithms, and deterministic volume estimation.\r\nProQuest LLC, Ann Arbor, MI. Thesis (Ph.D.), Georgia Institute of Technology\r\n\r\n\\bibitem{rank-depth}\r\nM. DeVos, O. Kwon, and S. Oum,\r\nBranch-depth: Generalizing tree-depth of graphs.\r\n{\\it arXiv:1903.11988, 2019}.\r\n\r\n\\bibitem{induced-minor}\r\nG. Ding, Chordal graphs, interval graphs, and wqo. {\\it J. Graph Theory} 28 (1998) 105--114. \r\n\r\n\\bibitem{Haiko}\r\nM. Dyer, H. M\\\"uller, Quasi-monotone graphs,\r\n{\\it Discrete Applied Mathematics} 271 (2019)  25--48.\r\n\r\n\\bibitem{superpattern}\r\nM. Engen, V. Vatter, Containing all permutations. Preprint available at \\url{https://arxiv.org/abs/1810.08252v4} (2018).\r\n\r\n\\bibitem{pathlet}\r\nR. Ferguson, On the lettericity of paths. Preprint available at \\url{https://arxiv.org/abs/2007.03636v1} (2020).\r\n\r\n\r\n% \\bibitem{fraisse}\r\n% R. Fra\\\"{i}ss\\'{e}, Sur l'extension aux relations de quelques propri\\'{e}t\\'{e}s des ordres. {\\it Ann. Sci. Ecole Norm. Sup.} 71(3) (1954), 363--388. \r\n\r\n% \\bibitem{Ding92}\r\n% G. Ding},\r\n% Subgraphs and Well-Quasi-Ordering,\r\n% {\\it J. Graph Theory}, 16 (1992) 489--502.\r\n\r\n\\bibitem{shrub}\r\nR. Ganian, P. Hlin\\v{e}n\\'{y}, J. Ne\\v{s}et\\v{r}il, J. Obdr\\v{z}\\'{a}lek, P. Ossona de Mendez,\r\nShrub-depth: capturing height of dense graphs,\r\n{\\it Logical Methods in Computer Science} 15 (2019) 7:1--7:25.\r\n\t\r\n% \t\r\n% \t\r\n\\bibitem{contiguity}\r\nP. Goldberg, M. Golumbic, H. Kaplan, R. Shamir,\r\nFour strikes against physical mapping of DNA,\r\n{\\it Journal of Computational Biology} 2 (1995) 139--152.\r\n\r\n\\bibitem{GM19}\r\nD.V.~Gribanov, D.S. Malyshev,\r\nInteger conic function minimization based on the comparison oracle,\r\nInternational Conference on Mathematical Optimization Theory and Operations Research, 2019, 218--231.\r\n\r\n\r\n\\bibitem{isi}\r\nP. Heggernes, P. van 't Hof, D. Meister, Y. Villanger,\r\nInduced Subgraph Isomorphism on proper interval and bipartite permutation graphs,\r\n{\\it Theoretical Computer Science}, 562 (2015) 252--269.\r\n\r\n\\bibitem{Pavol}\r\nP. Hell, J. Huang, Interval bigraphs and circular arc graphs, \r\n{\\it J. Graph Theory} 46 (2004) 313--327.\r\n\r\n\\bibitem{K87}\r\nR. Kannan,\r\nMinkowski's convex body theorem and integer programming,\r\n{\\it Mathematics of Operations Research} 12:3 (1987) 415--440.\r\n\r\n\r\n\\bibitem{reconstruction}\r\nM. Kiyomi, T. Saitoh, R. Uehara,\r\nBipartite permutation graphs are reconstructible,\r\n{\\it Discrete Math. Algorithms Appl.} 4 (2012), no. 3, 1250039, 14 pp.\r\n\r\n\r\n\r\n\\bibitem{KLMT11}\r\nN. Korpelainen, V. V. Lozin, D. S. Malyshev, A. Tiskin,\r\nBoundary properties of graphs for algorithmic graph problems,\r\n{\\it Theoretical Computer Science}, 412 (2011) 3545--3554.\r\n\r\n\\bibitem{boundary-wqo}\r\nN. Korpelainen, V.Lozin, I. Razgon,\r\nBoundary properties of well-quasi-ordered sets of graphs,\r\n{\\it Order}, 30 (2013) 723--735.\r\n\r\n%\\bibitem{shrub-depth}\r\n%O-j. Kwon, R. McCarty, S.-i. Oum, and P. Wollan,\r\n%Obstructions for bounded shrub-depth and rank-depth.\r\n%{\\it arXiv:1911.00230v2, 2019}.\r\n\r\n\r\n\r\n\\bibitem{Lampis}\r\nM. Lampis, Algorithmic meta-theorems for restrictions of treewidth.\r\n{\\it Algorithmica} 64 (2012), 19--37.\r\n\r\n\r\n\\bibitem{buffer}\r\nT.-H. Lai, S.-S. Wei,\r\nBipartite permutation graphs with application to the minimum buffer size problem,\r\n{\\it Discrete Appl. Math.} 74 (1997) 33--55.\r\n\r\n\r\n\\bibitem{L83}\r\nH. Lenstra,\r\nInteger programming with a fixed number of variables,\r\n{\\it Mathematics of Operations Research} 8:4 (1983) 538--548.\r\n\r\n\\bibitem{parameters}\r\nV. Lozin, Graph parameters and Ramsey theory.\r\n{\\it Lecture Notes in Computer Science} 10765 (2018), 185--194.\r\n\r\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n\\bibitem{Loz08}\r\nV.V. Lozin, Boundary classes of planar graphs,\r\n{\\it Combinatorics, Probability and Computing}, 17 (2008) 287--295.\r\n\r\n\\bibitem{Loz11}\r\nV. Lozin,\r\nMinimal classes of graphs of unbounded clique-width,\r\n{\\it Ann. Comb}. 15 (2011) 707--722.\r\n\r\n\\bibitem{canonical}\r\nV. Lozin, C. Mayhill,\r\nCanonical antichains of unit interval and bipartite permutation graphs,\r\n{\\it Order} 28 (2011) 513--522.\r\n\r\n\\bibitem{universal}\r\nV. Lozin, G. Rudolf,\r\nMinimal universal bipartite graphs.\r\n{\\it Ars Combin.}  84  (2007), 345--356.\r\n\r\n\\bibitem{weed}\r\nC.L. Lu, C.Y. Tang,\r\nSolving the weighted efficient edge domination problem on bipartite permutation graphs,\r\n{\\it Discrete Appl. Math.} 87 (1998) 203--211.\r\n\r\n\\bibitem{M13}\r\nD. Malyshev,\r\nA study of the boundary graph classes for colorability problems,\r\n{\\it Journal of Applied and Industrial Mathematics} 7:2 (2013) 221--228.\r\n\r\n\\bibitem{M14}\r\nD. Malyshev,\r\nClasses of graphs critical for the edge list-ranking problem,\r\n{\\it Journal of Applied and Industrial Mathematics} 8:2 (2014) 245--255.\r\n\r\n\\bibitem{M16}\r\nD. Malyshev,\r\nA complexity dichotomy and a new boundary class for the dominating set problem,\r\n{\\it Journal of Combinatorial Optimization} 32:1 (2016) 226--243.\r\n\r\n\\bibitem{MP16}\r\nD. Malyshev, P.M. Pardalos,\r\nCritical hereditary graph classes: a survey\r\n{\\it Optimization Letters} 10:8 (2016) 1593--1612.\r\n\t\r\n\\bibitem{tree-depth}\t\r\nJ. Ne\\v set\\v ril and P. Ossona de Mendez,\r\nOn low tree-depth decompositions,\r\n{\\it Graphs Combin.} 31 (2015) 1941--1963.\r\n\r\n\r\n\\bibitem{Pet02}\r\nM. Petkov\\v sek, Letter graphs and well-quasi-order by induced subgraphs,\r\n{\\it Discrete Math}. 244 (2002) 375--388.\r\n\r\n\\bibitem{planar}\r\nN. Robertson and P. Seymour, Graph minors. V. Excluding a planar graph. {\\it J. Combin. Theory Ser. B} 41 (1986) 92--114.\r\n\t\r\n\\bibitem{minor-wqo}\r\nN. Robertson and P. Seymour,\r\nGraph Minors. XX. Wagner's conjecture,\r\n{\\it J. Combinatorial Theory B}, 92 (2004) 325--357.\r\n\t\r\n\\bibitem{localcomp}\r\nS. Oum, Rank-width and vertex-minors. {\\it J. Combin. Theory Ser. B} 95 (2005), no. 1, 79--100. \r\n\t\r\n\\bibitem{BPG}\r\nJ. Spinrad, A. Brandst\\\"adt, L. Stewart,\r\nBipartite permutation graphs,\r\n{\\it  Discrete Appl. Math.} 18 (1987) 279--292.\r\n\r\n\\bibitem{Parikh-bpg}\r\nWen Chean Teh, Zhen Chuan Ng, Muhammad Javaid, Zi Jing Chern,\r\nParikh word representability of bipartite permutation graphs,\r\n{\\it Discrete Appl. Math.} 282 (2020) 208--221.\r\n\r\n\r\n\\bibitem{VGZC19}\r\nS.I. Veselov, D.V. Gribanov, N.Y. Zolotykh, A.Y. Chirkov,\r\nA polynomial algorithm for minimizing discrete conic functions in fixed dimension,\r\n{\\it Discrete Appl. Math.}  283 (2020) 11--19.\r\n\r\n\t\r\n\\end{thebibliography}\r\n\r\n\\end{document}\r\n\r\n% \t\\bibitem{linearity}\r\n% \tC. Crespelle, P. Gambette,\r\n% \t(Nearly-)tight bounds on the contiguity and linearity of cographs.\r\n% \t{\\it Theoretical Computer Science},\r\n% \t522 (2014) 1--12.\r\n% \t\r\n% \t\\bibitem{matchings}\r\n% \tK. Dabrowski, M. Demange, V.V. Lozin,\r\n% \tNew results on maximum induced matchings in bipartite graphs and beyond.\r\n% \t{\\it Theoretical Computer Science}, 478 (2013) 33--40.\r\n% \t\r\n% \t\\bibitem{Damaschke}\r\n% \tP. Damaschke, Induced subgraphs and well-quasi-ordering.\r\n% \t{\\it J. Graph Theory} 14(4), (1990) 427--435.\r\n% \t\r\n% \t\\bibitem{hindex}\r\n% \tD. Eppstein, E.S. Spiro,\r\n% \tThe $h$-index of a graph and its application to dynamic subgraph statistics.\r\n% \t{\\it J. Graph Algorithms and Applications}, 16 (2012) 543--567.\r\n% \t\r\n% \t\\bibitem{Erdos}\r\n% \tP. Erd\\H{o}s, Graph theory and probability. {\\it Canad. J. Math}. 11 (1959) 34--38.\r\n% \t\r\n% \t\\bibitem{cochromatic}\r\n% \tP. Erd\\H os, J. Gimbel H.J. Straight,\r\n% \tChromatic number versus cochromatic number in graphs with bounded clique number.\r\n% \t{\\it European J. Combinatorics}, 11 (1990) 235--240.\r\n% \t\r\n% \t\\bibitem{Fellows}\r\n% \tM.R. Fellows, M.A. Langston,  On search, decision and the efficiency of polynomial-time algorithms (extended abstract). In: STOC, pp. 501--512 (1989).\r\n% \t\r\n% \t\\bibitem{cover}\r\n% \tP. C. Fishburn, P. L. Hammer, Bipartite dimensions and bipartite degrees of graphs.\r\n% \t{\\it Discrete Math}. 160 (1996) 127--148.\r\n\t\r\n\t\t% \\bibitem{Ramsey}\r\n\t% F.P. Ramsey, On a problem of formal logic, Proceedings of the London Mathematical Society, 30 (1930) 264--286.\r\n\t\r\n% \t\\bibitem{box}\r\n% \tF.S. Roberts, On the boxicity and cubicity of a graph, {\\it Recent Progress in Combinatorics}, Academic Press (1969), pp. 301--310\r\n\t\r\n\t\r\n% \\bibitem{metric}\t\r\n% Vietz, D.; Wanke, E.\r\n% The fault-tolerant metric dimension of cographs.\r\n% {\\it Lecture Notes in Comput. Sci.} 11651 (2019)  350--364.\r\n% \t\r\n% \t\r\n% \t\\bibitem{QT}\r\n% \tJ.-H. Yan, J.-J. Chen, G.J. Chang, Quasi-threshold graphs.\r\n% \t{\\it Discrete Appl. Math}.  69  (1996) 247--255.\r\n\r\n%   \\bibitem{Golumbic}\r\n% \tM.C. Golumbic, Trivially perfect graphs. {\\it Discrete Math}.  24  (1978) 105--107.\r\n% \t\r\n% \t\\bibitem{Golumbic1}\r\n% \tGolumbic, Martin Charles; Mintz, Aviad; Rotics, Udi,\r\n% \tFactoring and recognition of read-once functions using cographs and normality and the readability of functions associated\r\n% \twith partial $k$-trees. {\\it Discrete Appl. Math}. 154 (2006), no. 10, 1465--1477.\r\n\t\r\n\t% \\bibitem{threshold-universal}\r\n\t% P.L. Hammer, A.K. Kelmans,  On universal threshold graphs. Combin. Probab. Comput.  3  (1994),  no. 3, 327--344.\r\n\t\r\n% \t\\bibitem{community}\r\n% \tSongwei Jia, Lin Gao, Yong Gao, James Nastos, Yijie Wang, Xindong Zhang, Haiyang Wang,\r\n% \tDefining and identifying cograph communities in complex networks,\r\n% \t{\\it New J.Phys.} 17 (2015) 013044.\r\n% \t\r\n% \t\r\n% \t\\bibitem{Lampis}\r\n% \tM. Lampis, Algorithmic meta-theorems for restrictions of treewidth.\r\n% \t{\\it Algorithmica}, 64 (2012) 19--37.\r\n% \t\r\n% \t\\bibitem{parameters}\r\n% \tV. Lozin, Graph parameters and Ramsey theory,\r\n% \t{\\it Lecture Notes in Computer Science}, 10765 (2018) 185--194.\r\n\t\r\n\t% \\bibitem{dilworth}\t\r\n% Ghorbani, E. Cographs: eigenvalues and Dilworth number. {\\it Discrete Math.} 342 (2019), no. 10, 2797--2803.\r\n\r\n% \t\\bibitem{bicograph}\r\n% \tV. Giakoumakis, J. Vanherpe,\r\n% \tBi-complement Reducible Graphs.\r\n% \t{\\it Advances in Applied Mathematics}, 18 (1997)  389--402.\r\n\r\n% \t\r\n% \t\\bibitem{distinguishing}\r\n% \tA. Atminas  R. Brignall,\r\n% \tWell-quasi-ordering and finite distinguishing number,\r\n% \t{\\it J. Graph Theory}, accepted. DOI:  https://doi.org/10.1002/jgt.22523\r\n% \t\r\n% \t\\bibitem{fewP4s}\r\n% \tBabel, Luitpold; Olariu, Stephan,\r\n% \tOn the structure of graphs with few $P_4$s.\r\n% \t{\\it Discrete Appl. Math.} 84 (1998), no. 1-3, 1--13.\r\n\r\n% \t\\bibitem{separable}\r\n% \tAlbert, Michael H.; Atkinson, M. D.; Vatter, Vincent\r\n% \tSubclasses of the separable permutations. {\\it Bull. Lond. Math. Soc.} 43 (2011), no. 5, 859--870.\r\n% \t\r\n% \t\\bibitem{entropy}\r\n% \tV.E. Alekseev,  Range of values of entropy of hereditary classes of graphs. (Russian) {\\it Diskret. Mat}. 4 (1992), no. 2, 148--157; translation in {\\it Discrete Math. Appl.} 3 (1993), no. 2, 191--199.", "meta": {"timestamp": "2020-10-28T00:31:21", "yymm": "2010", "arxiv_id": "2010.14467", "url": "https://arxiv.org/abs/2010.14467", "source": "arxiv"}}
{"text": "\\documentclass{article} % For LaTeX2e\n\\usepackage{arxiv,times}\n\n% Optional math commands from https://github.com/goodfeli/dlbook_notation.\n%%%%% NEW MATH DEFINITIONS %%%%%\n\n\\usepackage{amsmath,amsfonts,bm}\n\n% Mark sections of captions for referring to divisions of figures\n\\newcommand{\\figleft}{{\\em (Left)}}\n\\newcommand{\\figcenter}{{\\em (Center)}}\n\\newcommand{\\figright}{{\\em (Right)}}\n\\newcommand{\\figtop}{{\\em (Top)}}\n\\newcommand{\\figbottom}{{\\em (Bottom)}}\n\\newcommand{\\captiona}{{\\em (a)}}\n\\newcommand{\\captionb}{{\\em (b)}}\n\\newcommand{\\captionc}{{\\em (c)}}\n\\newcommand{\\captiond}{{\\em (d)}}\n\n% Highlight a newly defined term\n\\newcommand{\\newterm}[1]{{\\bf #1}}\n\n\n% Figure reference, lower-case.\n\\def\\figref#1{figure~\\ref{#1}}\n% Figure reference, capital. For start of sentence\n\\def\\Figref#1{Figure~\\ref{#1}}\n\\def\\twofigref#1#2{figures \\ref{#1} and \\ref{#2}}\n\\def\\quadfigref#1#2#3#4{figures \\ref{#1}, \\ref{#2}, \\ref{#3} and \\ref{#4}}\n% Section reference, lower-case.\n\\def\\secref#1{section~\\ref{#1}}\n% Section reference, capital.\n\\def\\Secref#1{Section~\\ref{#1}}\n% Reference to two sections.\n\\def\\twosecrefs#1#2{sections \\ref{#1} and \\ref{#2}}\n% Reference to three sections.\n\\def\\secrefs#1#2#3{sections \\ref{#1}, \\ref{#2} and \\ref{#3}}\n% Reference to an equation, lower-case.\n\\def\\eqref#1{equation~\\ref{#1}}\n% Reference to an equation, upper case\n\\def\\Eqref#1{Equation~\\ref{#1}}\n% A raw reference to an equation---avoid using if possible\n\\def\\plaineqref#1{\\ref{#1}}\n% Reference to a chapter, lower-case.\n\\def\\chapref#1{chapter~\\ref{#1}}\n% Reference to an equation, upper case.\n\\def\\Chapref#1{Chapter~\\ref{#1}}\n% Reference to a range of chapters\n\\def\\rangechapref#1#2{chapters\\ref{#1}--\\ref{#2}}\n% Reference to an algorithm, lower-case.\n\\def\\algref#1{algorithm~\\ref{#1}}\n% Reference to an algorithm, upper case.\n\\def\\Algref#1{Algorithm~\\ref{#1}}\n\\def\\twoalgref#1#2{algorithms \\ref{#1} and \\ref{#2}}\n\\def\\Twoalgref#1#2{Algorithms \\ref{#1} and \\ref{#2}}\n% Reference to a part, lower case\n\\def\\partref#1{part~\\ref{#1}}\n% Reference to a part, upper case\n\\def\\Partref#1{Part~\\ref{#1}}\n\\def\\twopartref#1#2{parts \\ref{#1} and \\ref{#2}}\n\n\\def\\ceil#1{\\lceil #1 \\rceil}\n\\def\\floor#1{\\lfloor #1 \\rfloor}\n\\def\\1{\\bm{1}}\n\\newcommand{\\train}{\\mathcal{D}}\n\\newcommand{\\valid}{\\mathcal{D_{\\mathrm{valid}}}}\n\\newcommand{\\test}{\\mathcal{D_{\\mathrm{test}}}}\n\n\\def\\eps{{\\epsilon}}\n\n\n% Random variables\n\\def\\reta{{\\textnormal{$\\eta$}}}\n\\def\\ra{{\\textnormal{a}}}\n\\def\\rb{{\\textnormal{b}}}\n\\def\\rc{{\\textnormal{c}}}\n\\def\\rd{{\\textnormal{d}}}\n\\def\\re{{\\textnormal{e}}}\n\\def\\rf{{\\textnormal{f}}}\n\\def\\rg{{\\textnormal{g}}}\n\\def\\rh{{\\textnormal{h}}}\n\\def\\ri{{\\textnormal{i}}}\n\\def\\rj{{\\textnormal{j}}}\n\\def\\rk{{\\textnormal{k}}}\n\\def\\rl{{\\textnormal{l}}}\n% rm is already a command, just don't name any random variables m\n\\def\\rn{{\\textnormal{n}}}\n\\def\\ro{{\\textnormal{o}}}\n\\def\\rp{{\\textnormal{p}}}\n\\def\\rq{{\\textnormal{q}}}\n\\def\\rr{{\\textnormal{r}}}\n\\def\\rs{{\\textnormal{s}}}\n\\def\\rt{{\\textnormal{t}}}\n\\def\\ru{{\\textnormal{u}}}\n\\def\\rv{{\\textnormal{v}}}\n\\def\\rw{{\\textnormal{w}}}\n\\def\\rx{{\\textnormal{x}}}\n\\def\\ry{{\\textnormal{y}}}\n\\def\\rz{{\\textnormal{z}}}\n\n% Random vectors\n\\def\\rvepsilon{{\\mathbf{\\epsilon}}}\n\\def\\rvtheta{{\\mathbf{\\theta}}}\n\\def\\rva{{\\mathbf{a}}}\n\\def\\rvb{{\\mathbf{b}}}\n\\def\\rvc{{\\mathbf{c}}}\n\\def\\rvd{{\\mathbf{d}}}\n\\def\\rve{{\\mathbf{e}}}\n\\def\\rvf{{\\mathbf{f}}}\n\\def\\rvg{{\\mathbf{g}}}\n\\def\\rvh{{\\mathbf{h}}}\n\\def\\rvu{{\\mathbf{i}}}\n\\def\\rvj{{\\mathbf{j}}}\n\\def\\rvk{{\\mathbf{k}}}\n\\def\\rvl{{\\mathbf{l}}}\n\\def\\rvm{{\\mathbf{m}}}\n\\def\\rvn{{\\mathbf{n}}}\n\\def\\rvo{{\\mathbf{o}}}\n\\def\\rvp{{\\mathbf{p}}}\n\\def\\rvq{{\\mathbf{q}}}\n\\def\\rvr{{\\mathbf{r}}}\n\\def\\rvs{{\\mathbf{s}}}\n\\def\\rvt{{\\mathbf{t}}}\n\\def\\rvu{{\\mathbf{u}}}\n\\def\\rvv{{\\mathbf{v}}}\n\\def\\rvw{{\\mathbf{w}}}\n\\def\\rvx{{\\mathbf{x}}}\n\\def\\rvy{{\\mathbf{y}}}\n\\def\\rvz{{\\mathbf{z}}}\n\n% Elements of random vectors\n\\def\\erva{{\\textnormal{a}}}\n\\def\\ervb{{\\textnormal{b}}}\n\\def\\ervc{{\\textnormal{c}}}\n\\def\\ervd{{\\textnormal{d}}}\n\\def\\erve{{\\textnormal{e}}}\n\\def\\ervf{{\\textnormal{f}}}\n\\def\\ervg{{\\textnormal{g}}}\n\\def\\ervh{{\\textnormal{h}}}\n\\def\\ervi{{\\textnormal{i}}}\n\\def\\ervj{{\\textnormal{j}}}\n\\def\\ervk{{\\textnormal{k}}}\n\\def\\ervl{{\\textnormal{l}}}\n\\def\\ervm{{\\textnormal{m}}}\n\\def\\ervn{{\\textnormal{n}}}\n\\def\\ervo{{\\textnormal{o}}}\n\\def\\ervp{{\\textnormal{p}}}\n\\def\\ervq{{\\textnormal{q}}}\n\\def\\ervr{{\\textnormal{r}}}\n\\def\\ervs{{\\textnormal{s}}}\n\\def\\ervt{{\\textnormal{t}}}\n\\def\\ervu{{\\textnormal{u}}}\n\\def\\ervv{{\\textnormal{v}}}\n\\def\\ervw{{\\textnormal{w}}}\n\\def\\ervx{{\\textnormal{x}}}\n\\def\\ervy{{\\textnormal{y}}}\n\\def\\ervz{{\\textnormal{z}}}\n\n% Random matrices\n\\def\\rmA{{\\mathbf{A}}}\n\\def\\rmB{{\\mathbf{B}}}\n\\def\\rmC{{\\mathbf{C}}}\n\\def\\rmD{{\\mathbf{D}}}\n\\def\\rmE{{\\mathbf{E}}}\n\\def\\rmF{{\\mathbf{F}}}\n\\def\\rmG{{\\mathbf{G}}}\n\\def\\rmH{{\\mathbf{H}}}\n\\def\\rmI{{\\mathbf{I}}}\n\\def\\rmJ{{\\mathbf{J}}}\n\\def\\rmK{{\\mathbf{K}}}\n\\def\\rmL{{\\mathbf{L}}}\n\\def\\rmM{{\\mathbf{M}}}\n\\def\\rmN{{\\mathbf{N}}}\n\\def\\rmO{{\\mathbf{O}}}\n\\def\\rmP{{\\mathbf{P}}}\n\\def\\rmQ{{\\mathbf{Q}}}\n\\def\\rmR{{\\mathbf{R}}}\n\\def\\rmS{{\\mathbf{S}}}\n\\def\\rmT{{\\mathbf{T}}}\n\\def\\rmU{{\\mathbf{U}}}\n\\def\\rmV{{\\mathbf{V}}}\n\\def\\rmW{{\\mathbf{W}}}\n\\def\\rmX{{\\mathbf{X}}}\n\\def\\rmY{{\\mathbf{Y}}}\n\\def\\rmZ{{\\mathbf{Z}}}\n\n% Elements of random matrices\n\\def\\ermA{{\\textnormal{A}}}\n\\def\\ermB{{\\textnormal{B}}}\n\\def\\ermC{{\\textnormal{C}}}\n\\def\\ermD{{\\textnormal{D}}}\n\\def\\ermE{{\\textnormal{E}}}\n\\def\\ermF{{\\textnormal{F}}}\n\\def\\ermG{{\\textnormal{G}}}\n\\def\\ermH{{\\textnormal{H}}}\n\\def\\ermI{{\\textnormal{I}}}\n\\def\\ermJ{{\\textnormal{J}}}\n\\def\\ermK{{\\textnormal{K}}}\n\\def\\ermL{{\\textnormal{L}}}\n\\def\\ermM{{\\textnormal{M}}}\n\\def\\ermN{{\\textnormal{N}}}\n\\def\\ermO{{\\textnormal{O}}}\n\\def\\ermP{{\\textnormal{P}}}\n\\def\\ermQ{{\\textnormal{Q}}}\n\\def\\ermR{{\\textnormal{R}}}\n\\def\\ermS{{\\textnormal{S}}}\n\\def\\ermT{{\\textnormal{T}}}\n\\def\\ermU{{\\textnormal{U}}}\n\\def\\ermV{{\\textnormal{V}}}\n\\def\\ermW{{\\textnormal{W}}}\n\\def\\ermX{{\\textnormal{X}}}\n\\def\\ermY{{\\textnormal{Y}}}\n\\def\\ermZ{{\\textnormal{Z}}}\n\n% Vectors\n\\def\\vzero{{\\bm{0}}}\n\\def\\vone{{\\bm{1}}}\n\\def\\vmu{{\\bm{\\mu}}}\n\\def\\vtheta{{\\bm{\\theta}}}\n\\def\\va{{\\bm{a}}}\n\\def\\vb{{\\bm{b}}}\n\\def\\vc{{\\bm{c}}}\n\\def\\vd{{\\bm{d}}}\n\\def\\ve{{\\bm{e}}}\n\\def\\vf{{\\bm{f}}}\n\\def\\vg{{\\bm{g}}}\n\\def\\vh{{\\bm{h}}}\n\\def\\vi{{\\bm{i}}}\n\\def\\vj{{\\bm{j}}}\n\\def\\vk{{\\bm{k}}}\n\\def\\vl{{\\bm{l}}}\n\\def\\vm{{\\bm{m}}}\n\\def\\vn{{\\bm{n}}}\n\\def\\vo{{\\bm{o}}}\n\\def\\vp{{\\bm{p}}}\n\\def\\vq{{\\bm{q}}}\n\\def\\vr{{\\bm{r}}}\n\\def\\vs{{\\bm{s}}}\n\\def\\vt{{\\bm{t}}}\n\\def\\vu{{\\bm{u}}}\n\\def\\vv{{\\bm{v}}}\n\\def\\vw{{\\bm{w}}}\n\\def\\vx{{\\bm{x}}}\n\\def\\vy{{\\bm{y}}}\n\\def\\vz{{\\bm{z}}}\n\n% Elements of vectors\n\\def\\evalpha{{\\alpha}}\n\\def\\evbeta{{\\beta}}\n\\def\\evepsilon{{\\epsilon}}\n\\def\\evlambda{{\\lambda}}\n\\def\\evomega{{\\omega}}\n\\def\\evmu{{\\mu}}\n\\def\\evpsi{{\\psi}}\n\\def\\evsigma{{\\sigma}}\n\\def\\evtheta{{\\theta}}\n\\def\\eva{{a}}\n\\def\\evb{{b}}\n\\def\\evc{{c}}\n\\def\\evd{{d}}\n\\def\\eve{{e}}\n\\def\\evf{{f}}\n\\def\\evg{{g}}\n\\def\\evh{{h}}\n\\def\\evi{{i}}\n\\def\\evj{{j}}\n\\def\\evk{{k}}\n\\def\\evl{{l}}\n\\def\\evm{{m}}\n\\def\\evn{{n}}\n\\def\\evo{{o}}\n\\def\\evp{{p}}\n\\def\\evq{{q}}\n\\def\\evr{{r}}\n\\def\\evs{{s}}\n\\def\\evt{{t}}\n\\def\\evu{{u}}\n\\def\\evv{{v}}\n\\def\\evw{{w}}\n\\def\\evx{{x}}\n\\def\\evy{{y}}\n\\def\\evz{{z}}\n\n% Matrix\n\\def\\mA{{\\bm{A}}}\n\\def\\mB{{\\bm{B}}}\n\\def\\mC{{\\bm{C}}}\n\\def\\mD{{\\bm{D}}}\n\\def\\mE{{\\bm{E}}}\n\\def\\mF{{\\bm{F}}}\n\\def\\mG{{\\bm{G}}}\n\\def\\mH{{\\bm{H}}}\n\\def\\mI{{\\bm{I}}}\n\\def\\mJ{{\\bm{J}}}\n\\def\\mK{{\\bm{K}}}\n\\def\\mL{{\\bm{L}}}\n\\def\\mM{{\\bm{M}}}\n\\def\\mN{{\\bm{N}}}\n\\def\\mO{{\\bm{O}}}\n\\def\\mP{{\\bm{P}}}\n\\def\\mQ{{\\bm{Q}}}\n\\def\\mR{{\\bm{R}}}\n\\def\\mS{{\\bm{S}}}\n\\def\\mT{{\\bm{T}}}\n\\def\\mU{{\\bm{U}}}\n\\def\\mV{{\\bm{V}}}\n\\def\\mW{{\\bm{W}}}\n\\def\\mX{{\\bm{X}}}\n\\def\\mY{{\\bm{Y}}}\n\\def\\mZ{{\\bm{Z}}}\n\\def\\mBeta{{\\bm{\\beta}}}\n\\def\\mPhi{{\\bm{\\Phi}}}\n\\def\\mLambda{{\\bm{\\Lambda}}}\n\\def\\mSigma{{\\bm{\\Sigma}}}\n\n% Tensor\n\\DeclareMathAlphabet{\\mathsfit}{\\encodingdefault}{\\sfdefault}{m}{sl}\n\\SetMathAlphabet{\\mathsfit}{bold}{\\encodingdefault}{\\sfdefault}{bx}{n}\n\\newcommand{\\tens}[1]{\\bm{\\mathsfit{#1}}}\n\\def\\tA{{\\tens{A}}}\n\\def\\tB{{\\tens{B}}}\n\\def\\tC{{\\tens{C}}}\n\\def\\tD{{\\tens{D}}}\n\\def\\tE{{\\tens{E}}}\n\\def\\tF{{\\tens{F}}}\n\\def\\tG{{\\tens{G}}}\n\\def\\tH{{\\tens{H}}}\n\\def\\tI{{\\tens{I}}}\n\\def\\tJ{{\\tens{J}}}\n\\def\\tK{{\\tens{K}}}\n\\def\\tL{{\\tens{L}}}\n\\def\\tM{{\\tens{M}}}\n\\def\\tN{{\\tens{N}}}\n\\def\\tO{{\\tens{O}}}\n\\def\\tP{{\\tens{P}}}\n\\def\\tQ{{\\tens{Q}}}\n\\def\\tR{{\\tens{R}}}\n\\def\\tS{{\\tens{S}}}\n\\def\\tT{{\\tens{T}}}\n\\def\\tU{{\\tens{U}}}\n\\def\\tV{{\\tens{V}}}\n\\def\\tW{{\\tens{W}}}\n\\def\\tX{{\\tens{X}}}\n\\def\\tY{{\\tens{Y}}}\n\\def\\tZ{{\\tens{Z}}}\n\n\n% Graph\n\\def\\gA{{\\mathcal{A}}}\n\\def\\gB{{\\mathcal{B}}}\n\\def\\gC{{\\mathcal{C}}}\n\\def\\gD{{\\mathcal{D}}}\n\\def\\gE{{\\mathcal{E}}}\n\\def\\gF{{\\mathcal{F}}}\n\\def\\gG{{\\mathcal{G}}}\n\\def\\gH{{\\mathcal{H}}}\n\\def\\gI{{\\mathcal{I}}}\n\\def\\gJ{{\\mathcal{J}}}\n\\def\\gK{{\\mathcal{K}}}\n\\def\\gL{{\\mathcal{L}}}\n\\def\\gM{{\\mathcal{M}}}\n\\def\\gN{{\\mathcal{N}}}\n\\def\\gO{{\\mathcal{O}}}\n\\def\\gP{{\\mathcal{P}}}\n\\def\\gQ{{\\mathcal{Q}}}\n\\def\\gR{{\\mathcal{R}}}\n\\def\\gS{{\\mathcal{S}}}\n\\def\\gT{{\\mathcal{T}}}\n\\def\\gU{{\\mathcal{U}}}\n\\def\\gV{{\\mathcal{V}}}\n\\def\\gW{{\\mathcal{W}}}\n\\def\\gX{{\\mathcal{X}}}\n\\def\\gY{{\\mathcal{Y}}}\n\\def\\gZ{{\\mathcal{Z}}}\n\n% Sets\n\\def\\sA{{\\mathbb{A}}}\n\\def\\sB{{\\mathbb{B}}}\n\\def\\sC{{\\mathbb{C}}}\n\\def\\sD{{\\mathbb{D}}}\n% Don't use a set called E, because this would be the same as our symbol\n% for expectation.\n\\def\\sF{{\\mathbb{F}}}\n\\def\\sG{{\\mathbb{G}}}\n\\def\\sH{{\\mathbb{H}}}\n\\def\\sI{{\\mathbb{I}}}\n\\def\\sJ{{\\mathbb{J}}}\n\\def\\sK{{\\mathbb{K}}}\n\\def\\sL{{\\mathbb{L}}}\n\\def\\sM{{\\mathbb{M}}}\n\\def\\sN{{\\mathbb{N}}}\n\\def\\sO{{\\mathbb{O}}}\n\\def\\sP{{\\mathbb{P}}}\n\\def\\sQ{{\\mathbb{Q}}}\n\\def\\sR{{\\mathbb{R}}}\n\\def\\sS{{\\mathbb{S}}}\n\\def\\sT{{\\mathbb{T}}}\n\\def\\sU{{\\mathbb{U}}}\n\\def\\sV{{\\mathbb{V}}}\n\\def\\sW{{\\mathbb{W}}}\n\\def\\sX{{\\mathbb{X}}}\n\\def\\sY{{\\mathbb{Y}}}\n\\def\\sZ{{\\mathbb{Z}}}\n\n% Entries of a matrix\n\\def\\emLambda{{\\Lambda}}\n\\def\\emA{{A}}\n\\def\\emB{{B}}\n\\def\\emC{{C}}\n\\def\\emD{{D}}\n\\def\\emE{{E}}\n\\def\\emF{{F}}\n\\def\\emG{{G}}\n\\def\\emH{{H}}\n\\def\\emI{{I}}\n\\def\\emJ{{J}}\n\\def\\emK{{K}}\n\\def\\emL{{L}}\n\\def\\emM{{M}}\n\\def\\emN{{N}}\n\\def\\emO{{O}}\n\\def\\emP{{P}}\n\\def\\emQ{{Q}}\n\\def\\emR{{R}}\n\\def\\emS{{S}}\n\\def\\emT{{T}}\n\\def\\emU{{U}}\n\\def\\emV{{V}}\n\\def\\emW{{W}}\n\\def\\emX{{X}}\n\\def\\emY{{Y}}\n\\def\\emZ{{Z}}\n\\def\\emSigma{{\\Sigma}}\n\n% entries of a tensor\n% Same font as tensor, without \\bm wrapper\n\\newcommand{\\etens}[1]{\\mathsfit{#1}}\n\\def\\etLambda{{\\etens{\\Lambda}}}\n\\def\\etA{{\\etens{A}}}\n\\def\\etB{{\\etens{B}}}\n\\def\\etC{{\\etens{C}}}\n\\def\\etD{{\\etens{D}}}\n\\def\\etE{{\\etens{E}}}\n\\def\\etF{{\\etens{F}}}\n\\def\\etG{{\\etens{G}}}\n\\def\\etH{{\\etens{H}}}\n\\def\\etI{{\\etens{I}}}\n\\def\\etJ{{\\etens{J}}}\n\\def\\etK{{\\etens{K}}}\n\\def\\etL{{\\etens{L}}}\n\\def\\etM{{\\etens{M}}}\n\\def\\etN{{\\etens{N}}}\n\\def\\etO{{\\etens{O}}}\n\\def\\etP{{\\etens{P}}}\n\\def\\etQ{{\\etens{Q}}}\n\\def\\etR{{\\etens{R}}}\n\\def\\etS{{\\etens{S}}}\n\\def\\etT{{\\etens{T}}}\n\\def\\etU{{\\etens{U}}}\n\\def\\etV{{\\etens{V}}}\n\\def\\etW{{\\etens{W}}}\n\\def\\etX{{\\etens{X}}}\n\\def\\etY{{\\etens{Y}}}\n\\def\\etZ{{\\etens{Z}}}\n\n% The true underlying data generating distribution\n\\newcommand{\\pdata}{p_{\\rm{data}}}\n% The empirical distribution defined by the training set\n\\newcommand{\\ptrain}{\\hat{p}_{\\rm{data}}}\n\\newcommand{\\Ptrain}{\\hat{P}_{\\rm{data}}}\n% The model distribution\n\\newcommand{\\pmodel}{p_{\\rm{model}}}\n\\newcommand{\\Pmodel}{P_{\\rm{model}}}\n\\newcommand{\\ptildemodel}{\\tilde{p}_{\\rm{model}}}\n% Stochastic autoencoder distributions\n\\newcommand{\\pencode}{p_{\\rm{encoder}}}\n\\newcommand{\\pdecode}{p_{\\rm{decoder}}}\n\\newcommand{\\precons}{p_{\\rm{reconstruct}}}\n\n\\newcommand{\\laplace}{\\mathrm{Laplace}} % Laplace distribution\n\n\\newcommand{\\E}{\\mathbb{E}}\n\\newcommand{\\Ls}{\\mathcal{L}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\emp}{\\tilde{p}}\n\\newcommand{\\lr}{\\alpha}\n\\newcommand{\\reg}{\\lambda}\n\\newcommand{\\rect}{\\mathrm{rectifier}}\n\\newcommand{\\softmax}{\\mathrm{softmax}}\n\\newcommand{\\sigmoid}{\\sigma}\n\\newcommand{\\softplus}{\\zeta}\n\\newcommand{\\KL}{D_{\\mathrm{KL}}}\n\\newcommand{\\Var}{\\mathrm{Var}}\n\\newcommand{\\standarderror}{\\mathrm{SE}}\n\\newcommand{\\Cov}{\\mathrm{Cov}}\n% Wolfram Mathworld says $L^2$ is for function spaces and $\\ell^2$ is for vectors\n% But then they seem to use $L^2$ for vectors throughout the site, and so does\n% wikipedia.\n\\newcommand{\\normlzero}{L^0}\n\\newcommand{\\normlone}{L^1}\n\\newcommand{\\normltwo}{L^2}\n\\newcommand{\\normlp}{L^p}\n\\newcommand{\\normmax}{L^\\infty}\n\n\\newcommand{\\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.\n\n\\DeclareMathOperator*{\\argmax}{arg\\,max}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\n\\DeclareMathOperator{\\sign}{sign}\n\\DeclareMathOperator{\\Tr}{Tr}\n\\let\\ab\\allowbreak\n \n\\usepackage{hyperref}\n\\usepackage{url}\n\n% additional packages\n\\usepackage{xspace}\n\\usepackage{multirow}\n\\usepackage{subfig}\n\n% \\newcommand{\\ra}[1]{\\renewcommand{\\arraystretch}{#1}}\n\\newcommand{\\mycaption}[2]{\\caption{\\textbf{#1}. {#2}}}\n\\newcommand{\\sref}[1]{\\S\\ref{#1}}\n\\newcommand{\\vheading}[1]{\\vspace{0.0125in}\\noindent\\textbf{#1}}\n\\newcommand{\\viheading}[1]{\\vspace{0.05in}\\noindent\\emph{#1}}\n\\newcommand{\\fsync}{\\texttt{fsync()}\\xspace}\n\\newcommand{\\etal}{\\textit{et al.}\\xspace}\n\\newcommand{\\ie}{\\textit{i.e.,}\\xspace}\n\\newcommand{\\eg}{\\textit{e.g.,}\\xspace}\n\\newcommand{\\etc}{\\textit{etc.}\\xspace}\n\\newcommand*{\\affaddr}[1]{#1} % No op here. Customize it for different styles.\n\\newcommand*{\\affmark}[1][*]{\\textsuperscript{#1}}\n\\newcommand*{\\email}[1]{\\texttt{#1}}\n\\newcommand{\\myx}{$\\times$\\xspace}\n\\newcommand{\\vtt}[1]{\\texttt{#1}\\xspace}\n\\newcommand{\\sysname}{{\\small\\textsc{MONeT}}\\xspace}\n\\newcommand{\\monet}{{MONeT}\\xspace}\n\n% label and ref\n\\newcommand{\\reffig}[1]{Fig.~\\ref{fig:#1}}\n\\newcommand{\\shortreffig}[1]{Fig.~\\ref{fig:#1}}\n\\newcommand{\\refsec}[1]{Sec.~\\ref{sec:#1}}\n\\newcommand{\\refapp}[1]{Appendix~\\ref{sec:#1}}\n\\newcommand{\\refthm}[1]{Theorem~\\ref{thm:#1}}\n\\newcommand{\\refcly}[1]{Corollary~\\ref{cly:#1}}\n\\newcommand{\\reftbl}[1]{Table~\\ref{tbl:#1}}\n\\newcommand{\\reftab}[1]{Table~\\ref{tab:#1}}\n\\newcommand{\\refalg}[1]{Alg.~\\ref{alg:#1}}\n\\newcommand{\\refline}[1]{Line~\\ref{line:#1}}\n\\newcommand{\\shortrefsec}[1]{\\S~\\ref{sec:#1}}\n\\newcommand{\\refeqn}[1]{Eq.~\\eqref{eq:#1}}\n\\newcommand{\\refeqna}[1]{Eq.~\\ref{eq:#1}}\n\\newcommand{\\refeqshort}[1]{\\eqref{eq:#1}}\n\\newcommand{\\shortrefeq}[1]{\\ref{eq:#1}}\n\\newcommand{\\lblfig}[1]{\\label{fig:#1}}\n\\newcommand{\\lblsec}[1]{\\label{sec:#1}}\n\\newcommand{\\lbleq}[1]{\\label{eq:#1}}\n\\newcommand{\\lblcly}[1]{\\label{cly:#1}}\n\\newcommand{\\lblthm}[1]{\\label{thm:#1}}\n\\newcommand{\\lbltbl}[1]{\\label{tbl:#1}}\n\\newcommand{\\lblalg}[1]{\\label{alg:#1}}\n\\newcommand{\\lblline}[1]{\\label{line:#1}}\n\n% math and notations.\n\\newcommand{\\modelparam}{\\Theta}\n\\newcommand{\\rbr}[1]{\\left(#1\\right)}\n\\newcommand{\\sbr}[1]{\\left[#1\\right]}\n\\newcommand{\\cbr}[1]{\\left\\{#1\\right\\}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\n% \\newcommand{\\abs}[1]{\\left\\lvert#1\\right\\rvert}\n\\newcommand{\\x}{\\times}\n\n\\usepackage{graphicx}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n\\usepackage[linesnumbered,ruled,noend]{algorithm2e}\n\\DontPrintSemicolon\n\\usepackage{tikz,pgfplots}\n\\usepgfplotslibrary{fillbetween}\n\n\\usepackage{tango}\n\n\\usepackage{algorithmic}\n\\usepackage{xcolor}\n\\usepackage{mathtools}\n\\usepackage{comment}\n\\usepackage{tabulary,multirow,overpic,xcolor}\n\n\\newcolumntype{x}[1]{>{\\centering\\arraybackslash}p{#1pt}}\n\\newcommand{\\dt}[1]{\\fontsize{8pt}{.1em}\\selectfont \\emph{#1}}\n\\newlength\\savewidth\\newcommand\\shline{\\noalign{\\global\\savewidth\\arrayrulewidth\n  \\global\\arrayrulewidth 1pt}\\hline\\noalign{\\global\\arrayrulewidth\\savewidth}}\n\\newcommand{\\tablestyle}[2]{\\setlength{\\tabcolsep}{#1}\\renewcommand{\\arraystretch}{#2}\\centering\\footnotesize}\n\\makeatletter\\renewcommand\\paragraph{\\@startsection{paragraph}{4}{\\z@}\n  {.5em \\@plus1ex \\@minus.2ex}{-.5em}{\\normalfont\\normalsize\\bfseries}}\\makeatother\n\\definecolor{demphcolor}{RGB}{100,100,100}\n\\newcommand{\\demph}[1]{\\textcolor{demphcolor}{#1}}\n\\newcommand{\\app}{\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}\n\\newcommand{\\mypm}[1]{{\\tiny{{\\demph{{$\\pm$#1}}}}}}\n\n\\pgfplotsset{compat = 1.3,\n          legend style={font=\\scriptsize},\n          legend cell align={left},\n          legend style={cells={align=left}, draw=black!20},\n          tick style={draw=none},\n          enlarge x limits=false,\n          enlarge y limits=false,\n          axis line style={draw=black!100},\n          grid=both,\n          grid style={dotted},\n          axis lines=left,\n          }\n\n\\pgfplotscreateplotcyclelist{mycolormarklist}{%\nscarletred3,mark=square*,mark options={solid}\\\\\nchameleon3,mark=diamond*,mark options={solid, fill=chameleon3}\\\\\nplum1,mark=triangle*,mark options={solid}\\\\\nskyblue2,mark=pentagon*,mark options={solid}\\\\\naluminium5,mark=otimes*,mark options={solid}\\\\\norange1,mark=square*,mark options={solid}\\\\\nskyblue3\\\\\nchocolate2\\\\\nmaroon\\\\\nbutter3\\\\\n}\n\\pgfplotscreateplotcyclelist{mystylelist}{%\ndensely dashdotted\\\\\nsolid\\\\\ndotted\\\\\ndensely dashed\\\\\ndashed\\\\\ndashdotted\\\\\ndensely dotted\\\\\ndensely dash dot dot\\\\\ndotted\\\\\ndash dot dot\\\\\n}\n% end additional packages\n\n\\title{Memory Optimization for Deep Networks}\n\n\\author{Aashaka Shah, Chao-Yuan Wu, Jayashree Mohan, Vijay Chidambaram, Philipp Kr\\\"ahenb\\\"uhl \\\\\nDepartment of Computer Science\\\\\nUniversity of Texas at Austin\\\\\n\\texttt{\\{aashaka,cywu,jaya,vijay,philkr\\}@cs.utexas.edu} \\\\\n}\n\n\\newcommand{\\fix}{\\marginpar{FIX}}\n\\newcommand{\\new}{\\marginpar{NEW}}\n\n\\begin{document}\n\n\n\\maketitle\n\n\\begin{abstract}\nDeep learning is slowly, but steadily, hitting a memory bottleneck.\nWhile the tensor computation in top-of-the-line GPUs increased by $32\\times$ over the last five years, the total available memory only grew by $2.5\\times$.\nThis prevents researchers from exploring larger architectures, as training large networks requires more memory for storing intermediate outputs.\nIn this paper, we present \\sysname, an automatic framework that minimizes both the memory footprint and computational overhead of deep networks.\n\\sysname jointly optimizes the checkpointing schedule and the implementation of various operators.\n\\sysname is able to outperform all prior hand-tuned operations as well as automated checkpointing.\n\\sysname reduces the overall memory requirement by $3\\times$ for various PyTorch models, with a 9-16$\\%$ overhead in computation.\nFor the same computation cost, \\sysname requires 1.2-1.8$\\times$ less memory than current state-of-the-art automated checkpointing frameworks.\nOur code is available at \\url{https://github.com/utsaslab/MONeT}.\n\n\\end{abstract}\n\n\\section{Introduction}\n\\label{sec-intro}\n\nDeep networks are widely used in domains ranging from image classification~\\citep{krizhevsky2012imagenet, simonyan2014very, he2016deep} to video recognition~\\citep{wu2019long,feichtenhofer2019slowfast} or natural language processing~\\citep{devlin2018bert, yang2019xlnet}.\nHowever, training deep networks is resource-intensive.\nIn particular, the amount of GPU memory bottlenecks training many deep networks~\\citep{dong-superres, kim-superres, chen-deeplab, child-longseq}.\nThis bottleneck requires either modifying the network architecture or scaling training to multiple nodes, incurring significant overheads.\n\nWe present \\sysname, an automatic framework to minimize memory footprint for deep networks.\n\\sysname \\emph{jointly} optimizes global compute-graph-level techniques (such as checkpointing) and local techniques (such as memory-efficient implementations of individual operator).\nAt the heart of \\sysname is a theoretical analysis that enables joint optimization and provides tight bounds on memory consumption.\nWe analyze the memory consumption and computational cost of a general forward and backward pass under changing local operator implementations and a global checkpointing schedule.\nSpecifically, we are able to tightly bound the peak memory consumption for network forward, backward, and recomputation stages.\n\\sysname uses these constraints to optimize for the most efficient forward and backward implementation both locally and globally under a fixed memory budget.\nWe linearize all memory bounds, and express both implementation selection and checkpointing as a 0-1 integer program, which we solve using standard solvers.\n\nWe conduct extensive experiments, demonstrating that \\sysname significantly outperforms existing automatic frameworks that use local or global techniques.\nOn multiple architectures (ResNet~\\citep{resnet}, VGG~\\citep{simonyan2014very}, UNet~\\citep{unet}, GoogleNet~\\citep{szegedy2015going}, MobileNet-V2~\\citep{sandler2018mobilenetv2}), memory budgets (5-10 GB), and network configurations (multiple resolutions),\n\\sysname consistently achieves lower memory footprints at equivalent or lower computational overhead.\n\\sysname reduces the overall memory requirement by \\textbf{$3\\x$} for various models, with a 9-16$\\%$ overhead in computation.\nFor the same computation cost, \\sysname requires 1.2-1.8$\\times$ less memory than the current state-of-the-art automated checkpointing framework.\nThe results achieved by \\sysname demonstrate the power of jointly optimizing global checkpointing schedules and local operator implementations.\n\n\\begin{figure*}[t]\n\\centering\n\\includegraphics[width=1.0\\linewidth]{figs/concept_fig.pdf}\n\\caption{\\textbf{Memory Optimized Network Training (MONeT)}, an automatic framework that minimizes the memory footprint of deep networks by jointly optimizing global and local techniques.\\vspace{-2mm}\n}\n\\label{fig:concept}\n\\end{figure*}\n\n\\section{Related Work}\n\nThere are two broad families of approaches to reduce the memory footprint of a deep network during training: operator-level implementation changes, and global, graph-level optimizations.\nThe novel aspect of \\sysname is that it is able to combine both approaches and find the optimal mix of local and global techniques for a given network.\n\n\\vheading{Operator-Specific Optimizations.}\nResearchers have found creative ways to implement individual operators or groups of operators in a more memory-efficient manner.\nStandard deep learning frameworks~\\citep{caffe,torch,pytorch,tensorflow} provide different implementations of certain operators that trade computation for intermediate memory use.\nThese implementation are chosen according to local search heuristics, and are not globally optimal.\nGist~\\citep{gist} proposes several hand-crafted optimizations such as storing only ReLU signs.\nRevNets~\\citep{backprop-noactivation} redesigns a ResNet~\\citep{resnet} architecture making each network block reversible, thereby eliminating the need to store intermediate activations for backpropagation.\nMemory-efficient DenseNets~\\citep{pleiss2017memory} reduce memory utilized for feature maps by recomputing all intermediate feature maps during the backward pass with a small compute overhead.\nIn-place activated batchnorm~\\citep{inplace-bn} or ReLU layers use output activations to compute their gradients, thus reusing a single memory buffer for the gradient computation in consecutive layers.\nMixed precision training~\\citep{mixed} uses half precision (FP16) instead of single precision (FP32) for all tensors and arithmetic during training, reducing the memory by nearly half.\nWhile training at precision lower than FP16 results in loss of training quality~\\citep{training-low-prec}, prior work like backpropagation with approximate activations~\\citep{approx-activations} carefully quantize certain intermediate outputs (activations) to 4 bits, resulting in significant memory savings.\nAlthough these hand-crafted techniques independently result in memory savings, there is no one-size-fits-all recipe, and different implementations perform best on different architectures.\nIn contrast, \\sysname automatically finds the best implementation for each forward and backward operator given a memory budget.\n\n\\vheading{Checkpointing.}\n\\cite{sublinear-memory-costs} proposed dividing a network into different segments, dropping all intermediate outputs within each segment, and recomputing them later.\nChen \\etal use $\\sqrt{n}$ equal segments, trading memory savings for the cost of an extra forward pass.\nCheckmate~\\citep{checkmate} solves the problem in a more general setting, using an mixed-integer linear program solver to decide which layers to recompute for a given network.\nLike Checkmate, our work optimizes a checkpointing schedule, but on a different computation graph.\nOur computation graph allows for the optimization of an entire execution plan jointly finding a checkpointing schedule and the best implementation of each forward and backward operator.\nIn Checkmate, changes in operator implementation induce a different computation graph, and could thus not directly be optimized.\nAppendix~\\ref{a:checkmate} highlights some of the difficulties of adding operator optimizations into Checkmate.\n\nIn summary, while much work has been done on local optimizations (operator implementations) and global compute-graph-level techniques (automated checkpointing), \\sysname is the first system to jointly optimize a given architecture using both local and global techniques.\n\n\n\\section{Preliminaries}\n\\lblsec{prelim}\nLet the forward pass of a CNN with parameters $\\modelparam$ be expressed as a directed-acyclic graph (DAG), where each node $i \\in \\cbr{1, \\dots, N}$ corresponds to an operator $\\mathrm{forward}_i$, and edges $(i, j) \\in \\mathbf{E}$ specify the data-flow dependencies, \\ie, the output of operator $i$ is used as input in operator $j$.\nWithout loss of generality, computational dependency $(i,j) \\in \\mathbf{E}$ implies $i < j$.\nLet $\\mathcal{N}_j = \\{i: (i,j) \\in \\mathbf{E}\\}$ be the set of all incoming edges of an operation $j$.\n\nWe will first discuss the forward pass through a network and the basic form of a backward pass using checkpointing.\nThe backward pass reverses all computational dependency expressed in our DAG, and induces certain dependencies on forward activations.\nWe call these checkpoint dependencies $\\mathcal{D}_k$.\nThey are either saved or recomputed depending on a schedule $(s, r)$.\nCheckpointing creates a trade-off between computation and memory consumption.\nTo highlight this tradeoff, we formally compute the amount of memory consumed in both forward and backward passes, which allows us to optimize for the ideal execution plan in \\refsec{main}.\n\n\\begin{figure*}[t]\n\\begin{minipage}{.48\\textwidth}\n\\begin{algorithm}[H]\n  \\algsetup{linenosize=\\tiny}\n  \\scriptsize\n    \\SetKwInOut{Input}{Input}\n    \\SetKwInOut{Output}{Output}\n    \\Input{Inputs, $\\theta$, a schedule ($s$, $r$).}\n    \\Output{Output tensor}\n    $S^N$ = \\{\\}\\tcc*{Saved tensors for backward}\n    $L$ = \\{inputs, $\\theta$\\}\\tcc*{Local tensors for forward}\n      \\BlankLine\\BlankLine\\BlankLine\n    \\For{$i=1\\ldots N$} {\n    $x_i = \\mathrm{forward}_i(L)$\\label{L:forward_forward}\\lblline{forward_forward}\\;\n      \\BlankLine\\BlankLine\\BlankLine\n    Add $x_i$ to $L$\\;\n    Remove all tensors from $L$ that are not used later\\;\n      \\BlankLine\\BlankLine\\BlankLine\n    \\If{$s^N_i$}{\n      Add $x_i$ to $S^N$\\;\n    }\n      \\BlankLine\\BlankLine\\BlankLine\n    }\n    \\Return{$L$}\\;\n    \\BlankLine\\BlankLine\\BlankLine\n    \\BlankLine\\BlankLine\\vspace{-0.5mm}\n    \\caption{Forward Pass}\n    \\lblalg{forward}\n\\end{algorithm}\n\\end{minipage}\\hfill\n\\begin{minipage}{.48\\textwidth}\n\\begin{algorithm}[H]\n  \\algsetup{linenosize=\\scriptsize}\n  \\scriptsize\n    \\SetKwInOut{Input}{Input}\n    \\SetKwInOut{Output}{Output}\n\n    \\Input{Loss gradients, inputs, $\\theta$, $S^N$, ($s$, $r$).}\n    \\Output{Output tensor}\n    $\\hat L$ = \\{loss gradients\\}\\tcc*{Local backward tensors}\n    \\For{$k=N\\ldots 1$} {\n    $L = S^{k}$\\tcc*{Local forward tensors}\n    $S^{k-1}$ = \\{\\}\\tcc*{Saved tensors}\n    \\For{$i=1\\ldots N$} {\n      \\If{$r_i^k$}{\n        $x_i = \\mathrm{forward}_i(L)$\\lblline{backward_forward}\\;\n        Add $x_i$ to $L$\\;\n      }\n      Remove all tensors from $L$ not used later\\;\n      \\If{$s^{k-1}_i$}{\n        Add $x_i$ to $S^{k-1}$\\tcc*{use $x_i \\in L$}\n      }\n    }\n    $y_k= \\mathrm{backward}_{k}(\\hat L, L)$\\lblline{backward_backward}\\;\n    Add $y_k$ to $\\hat L$\\;\n    Remove tensors from $\\hat L$ that are not used later\\;\n  }\n    \\caption{Backward Pass}\n    \\lblalg{backward}\n\\end{algorithm}\n\\end{minipage}\n\\caption{\\textbf{Schematic overview of the forward and backward passes.} The algorithms include aggressive memory savings by greedily freeing unused tensors, and allow for a general checkpointing schedule $(s,r)$ to be executed.}\n\\end{figure*}\n\n\\vheading{The Forward Pass.}\n\\refalg{forward} shows a general overview of the forward pass in a deep network, as implemented in standard deep learning frameworks~\\citep{caffe,torch,pytorch,tensorflow}.\nThe algorithm proceeds in increasing order of index $i$.\nEach operator $\\mathrm{forward}_i(\\cdot)$ depends on a set of tensors $L$ stored in local memory.\nThese tensors include model parameters $\\modelparam$, computational dependencies $\\mathcal{N}_i$, and tensors stored for later forward operators, i.e. skip or residual activations~\\citep{resnet}.\nAt each iteration, we add any output tensors of $\\mathrm{forward}_i$ to the local memory $L$.\nEarly deep learning frameworks~\\citep{caffe, torch} strictly grew the set of local tensors $L$ leading to an unnecessarily high memory consumption.\nModern graph-based frameworks~\\citep{pytorch,tensorflow} reduce the memory footprint by aggressively pruning local memory $L$ and freeing any tensor that is no longer used in later computations.\nSome output activations $x_i$ are used in the backward pass, and have to be saved for later.\nWe use a checkpointing schedule $s^N$ to determine which.\nFormally, $s^N_i \\in \\cbr{0, 1}$ indicates whether the activation of node $i$ is stored during the forward pass.\nAn activation which is not stored will be recomputed if it is needed during the backward pass.\n\n\\vheading{Analyzing peak memory consumption of the forward pass.}\nOnly the $\\textrm{forward}_i$ operator (Alg. \\ref{alg:forward} L. \\ref{line:forward_forward}) allocates memory.\nAll other operators perform mere bookkeeping on existing tensor.\nIt is thus sufficient to study the peak memory consumption $m^N_i$ in $\\textrm{forward}_i$ for each node $i$.\nLet $L_i, S^N_i$ be the set of local tensors $L$ and saved tensors $S$ while calling $\\textrm{forward}_i$ respectively.\n$L_i$ includes all parameters and computational dependencies for this and later forward passes $L_i = \\Theta \\cup \\{x_j : j \\in \\mathcal{N}_t\\text{ for any }t \\ge i\\text{ and }j<i\\}$.\n$L_i$ is constant and computed ahead of time.\nThe schedule $s^N$ determines the set of saved tensors $S^N_i = \\{x_j : s^N_j = 1 \\text{ for } j < i\\}$.\nIn addition, each forward operator uses a certain amount of workspace memory $c_i$ to store intermediate results.\nThe total memory consumption of a forward operator is thus\n\\begin{equation}\n m_i = c_i + |x_i| + |S^N_i \\cup L_i| = c_i + |x_i| + \\sum_{x_j \\in L_i} |x_j| + \\sum_{j<i: x_j \\notin L_i} |x_j| s^N_j,\\lbleq{forward_mem}\n\\end{equation}\nwhere $|\\cdot|$ refers to the memory consumed by a tensor or set of tensors.\nMost of the memory consumption is constant and does not depend on the schedule.\n\n\n\\vheading{The Backward Pass.}\nThe backward pass proceeds in a reverse order, as summarized in \\refalg{backward}.\n$\\mathrm{backward}_{k}(\\cdot)$ of each node $k$ depends on a set of gradient tensors $\\hat L$ and forward tensors $\\{x_i: i \\in \\mathcal{D}_k\\}$.\nAny gradients required by the current and later backward passes are stored in local memory $\\hat{L}$.\nDependencies $\\mathcal{D}_k$ may either be stored in $S^{k}$ or need to be recomputed from checkpoints in $S^{k}$.\nRecomputation involves forward computation of one or more nodes, which increases computational overhead, and allows for a new set of tensors $S^{k-1}$ to be saved.\nAfter recomputation, all dependencies $\\mathcal{D}_k$ are kept in memory.\nThe backward operation produces a gradient for each input tensor of the original forward operation, which is added to $\\hat{L}$ if required for a later backward computation.\nWe aggressively remove tensors in $\\hat{L}$ that are not required.\n\n\\vheading{Analyzing the peak memory consumption of the backward pass.}\nPeak memory consumption $\\hat m_k$ again only depends on the $\\mathrm{forward}_i$ (Alg. \\ref{alg:backward} L. \\ref{line:backward_forward}) and $\\mathrm{backward}_{k}$ (Alg. \\ref{alg:backward} L. \\ref{line:backward_backward}) operations.\nFor the $\\mathrm{backward}_{k}$ operation, let $\\hat c_k$ be the workspace memory, $\\hat L_k$ be the set of gradient tensors stored, $D_k = \\{x_i: i \\in \\mathcal{D}_k\\}$ be the forward tensors used, and $S^{k-1}$ be the set of newly saved tensors.\nHere $\\hat L_k$ and $D_k$ can be pre-computed.\nThe total memory consumption for the $\\mathrm{backward}_{k}$ call is\n\\begin{equation}\n  \\hat m_k = \\hat c_k + |y_k| + |S^{k-1} \\cup \\hat L_k \\cup D_k| = \\hat c_k + |y_k| + \\sum_{y_l \\in \\hat L_k}\\!|y_l| + \\sum_{x_i \\in D_k}\\!|x_i| + \\sum_{x_i \\notin D_k}\\!s_i^{k-1} |x_i|.\\lbleq{backward_mem}\n\\end{equation}\nHere again, only the last term depends on the checkpointing schedule, while the rest is a constant.\n\n\\vheading{Analyzing the peak memory consumption of the recomputation.}\nFinally, the peak memory $\\tilde m^k_i$ for the $\\textrm{forward}_i$ call (Alg. \\ref{alg:backward} L. \\ref{line:backward_forward}) depends on the set of local tensors $L$, checkpoint dependencies $D$, saved tensors $S$, and gradient tensors $\\hat L$, named $L_i^k$, $D_k$, $S_i^{k-1}$, $\\hat L_k$ respectively.\nFollowing the forward pass:\n\\begin{align}\n \\tilde m_i^k &= c_i + |x_i| + |\\hat L_k| + |S^{k-1}_i \\cup L_i^k \\cup D_k|\\notag\\\\\n &= c_i + |x_i| + |\\hat L_k| +\\sum_{j<i: x_j \\notin L_i^k \\cup D_k}s^{k-1}_j |x_j| + \\sum_{j<i: x_j \\in L_i^k \\cup D_k} |x_j|+\\sum_{j>i} s^{k}_j |x_j| \\lbleq{recompute_mem}.\n\\end{align}\nUnlike the forward pass, $L_i^k$ is no longer constant, but instead depends on past saved tensors and future recomputations in the schedule $(s, r)$:\n$L_i^k = \\Theta \\cup \\{x_j : j \\in \\mathcal{N}_t\\text{ for any }t \\ge i\\text{ with }r^k_t=1\\text{ and }j<i\\}$.\n\nIn the next section, we show how to take this formalization of the forward and backward pass, and find an optimal execution plan including checkpointing schedule $(s, r)$, $\\mathrm{forward}_i$ implementations, and $\\mathrm{backward}_k$ implementations, under a fixed memory budget.\n\n\\section{Method}\n\\lblsec{main}\n\nOur goal is to find a global checkpointing schedule $(s, r)$ and local $\\textrm{forward}_i$/$\\textrm{backward}_k$ implementations that jointly minimize the computation cost $\\tau$ within a memory budget $M$.\nWe show how to express this optimization in a 0-1 integer program and efficiently solve it.\nTo this end, we linearize any peak memory consumption constraints, ensure that the checkpointing schedule is valid, and solve to minimize a computation cost objective.\nWe keep track of the three contributors to memory and computational cost - forward pass, backward pass, and recomputation of forward operators.\n\n\\vheading{Memory Constraints.}\nConsider the case of basic checkpointing using only a single implementation for $\\textrm{forward}_i$ and $\\textrm{backward}_k$.\nThe memory consumption of the forward (\\shortrefeq{forward_mem}) and backward (\\shortrefeq{backward_mem}) pass are linear in $s$, and thus efficiently expressed in an integer program.\nHowever, recomputation depends both on $s^{k-1}$ and $r^k$ in a non-linear manner through the local memory $L_i^k$.\nThis joint dependence on optimization variables gives rise to quadratic constraints, which cannot directly be incorporated into an integer program.\nFor simplicity in this derivation, we bound the set of local tensors from above, assuming every future tensor is recomputed.\nWe give more information about this in Appendix \\ref{appendix:tighten}.\nThe upper bound $\\bar L_i^k$ is constant, yielding a linear upper bound $\\bar m_i^k$ of the recomputation memory $\\tilde m_i^k$ analogous to \\refeqna{recompute_mem}.\nThe set of memory constraints is thus\n\\begin{equation}\n  \\begin{split}\n  m_i \\le M \\quad \\forall_{i} \\qquad \\text{and} \\qquad \\hat m_k \\le M \\quad \\forall_{k} \\qquad \\text{and} \\qquad  \\bar m_i^k \\le M \\quad \\forall_{k,i} \\lbleq{memconstr}\n  \\end{split}\n\\end{equation}\nTo enable operator optimization, we use a bit-vector $\\delta$ to indicate the selection of an operator implementation.\nWe add $\\delta$ to the constraints which allows us to jointly optimize checkpointing $(s,r)$ and operator implementations $\\delta$.\n\n\\vheading{Forward Operator Optimization.}\nLet each forward operator $\\textrm{forward}_i$ have multiple different implementations $\\mathcal{I}_i = \\{a, b, c, \\ldots\\}$.\nFor examples, convolution may be implemented using matrix multiplication, the Winograd algorithm~\\citep{winograd}, a Fourier transform, etc.~\\citep{cudnn}.\nAll implementations follow the same DAG structure, and thus use the same dependencies $\\mathcal{N}_i$.\nHowever, each implementation trades workspace memory $\\{c_i^a, c_i^b, \\ldots\\}$ for computational efficiency $\\{\\tau_i^a, \\tau_i^b, \\ldots\\}$ in a different manner.\nOur experiments show that this tradeoff is often complex.\n\nOur goal is to represent the peak memory when using multiple $\\textrm{forward}_i$ implementations in the forward pass and recomputation.\nLet $\\delta_{i,a} \\in \\{0, 1\\}$ indicate that implementation $a \\in \\mathcal{I}_i$ is used for $\\textrm{forward}_i$ in the forward pass.\nEach forward operator should use exactly one implementation $\\sum_l \\delta_{i,l} = 1$.\nThe choice of implementation determines the operator's computational cost $\\sum_l \\tau_i^l \\delta_{i,l}$ and workspace memory $c_i = \\sum_l c_i^l \\delta_{i,l}$.\nAnalogously, each recomputation of $\\textrm{forward}_i$ during $\\textrm{backward}_k$ chooses between implementations $\\delta_{i,a}^k \\in \\{0, 1\\}$ when needed $\\sum_l \\delta_{i,l}^k = r_i^k$, with equivalent cost estimates $\\sum_l \\tau_i^l \\delta_{i,l}^k$ and workspace memory use $c_i^k = \\sum_l c_i^l \\delta_{i,l}^k$.\nIn this formulation, all additional memory requirements remain linear and are directly integrated into the linear memory constraints or their linear relaxations (\\refeqna{memconstr}).\n\n\\vheading{Backward Operator Optimization.}\nLet each backward operator $\\textrm{backward}_k$ have a set of different implementations $\\hat{\\mathcal{I}}_k = \\{a, b, c, \\ldots\\}$.\nEach implementation again trades workspace memory  $\\{\\hat c_k^a, \\hat c_k^b, \\ldots\\}$ for computational cost $\\{\\hat \\tau_k^a, \\hat \\tau_k^b, \\ldots\\}$.\nWhile gradient tensors follow the fixed DAG structure, different implementations may depend on different forward activations $\\{\\mathcal{D}_k^a, \\mathcal{D}_k^b, \\ldots\\}$.\nFor example, in-place activated operators~\\citep{inplace-bn} depend on their output activation, while regular operators use the input activation.\nThis change in the dependency structure makes optimizing for backward-operator implementations challenging.\n\nWe again aim to represent memory in terms of implementations for each $\\textrm{backward}_k$ operator.\nLet $\\hat \\delta_{k,a} \\in \\{0, 1\\}$ indicate that implementation $a \\in \\hat{\\mathcal{I}}_k$ is used at node $k$ in the backward pass.\nEach backward operator should use exactly one implementation $\\sum_l \\hat\\delta_{k,l} = 1$, with a computational cost $\\sum_l \\hat \\tau_k^l \\hat \\delta_{k,l}$ and workspace memory $\\hat c_k = \\sum_l \\hat c_k^l \\hat \\delta_{k,l}$.\nThe workspace memory adds a linear constraint to the memory consumption $\\hat m_k$ \\refeqshort{backward_mem}.\n\nThe biggest changes to the optimization problem, comes from the \\textit{changing dependency structure}.\n$\\mathcal{D}_k$ is no longer constant.\nInstead, the implementation of a backward operator changes the set of computational dependencies $D_k$ obtained from $\\mathcal{D}_k^l$.\nTo deal with this changing dependency structure, we use the indicator vector $\\hat \\delta_{k}$ to select memory contribution of dependencies from the chosen implementation.\nThis changes the backward memory consumption to\n\\begin{equation}\n  \\hat m_k  = \\underbrace{\\sum_l \\hat c_k^l \\hat \\delta_{k,l}}_{\\hat c_k} + |y_k| + |\\hat L_k| + \\sum_l \\hat \\delta_{k,l} . | D_k^l \\cup S^{k-1}|,\\lbleq{sw_backward_mem}\n\\end{equation}\nand the corresponding peak recomputation memory $\\bar m_i^k$ to\n \\begin{align}\n  \\bar m_i^k = c_i + |x_i| + |\\hat L_k| + \\sum_l \\hat \\delta_{k,l} . | S_i^{k-1} \\cup \\bar L_i^k \\cup D_k^l|.\\lbleq{sw_recompute_mem}\n \\end{align}\nNote, the last term of \\refeqshort{sw_backward_mem} and \\refeqshort{sw_recompute_mem} are quadratic in the original optimization variables $s_i^{k-1}$, which determines $S^{k-1}$, and $\\hat\\delta_{k,l}$.\nHowever, for binary variables, it can be linearized using an auxiliary variable (see Appendix \\ref{appendix:linearization}).\nWe show the full equation expansion in Appendix \\ref{appendix:equations}.\n\n\\vheading{Checkpointing Constraints.}\nThe computational dependencies of forward and backward operators impose strict constraints on the checkpointing schedule.\nAny schedule violating these constraints cannot be executed, while any schedule following them can.\nRecomputation $r_i^k$ requires saved $s^{k-1}_j$ or recomputed $r_j^k$ dependencies $j \\in \\mathcal{N}_i$, and only previously stored or recomputed tensors can be saved:\n\\begin{equation}\nr_i^k \\le s^{k-1}_j + r_j^k \\quad \\forall_{i, k, j \\in \\mathcal{N}_i} \\qquad \\qquad \\text{and} \\qquad \\qquad s^{k-2}_i \\le s^{k-1}_i + r^k_i \\quad \\forall_{i, k} \\lbleq{first_constr}.\n\\end{equation}\nFurthermore, all forward tensors $\\mathcal{D}_k^l$ required by $\\textrm{backward}_k$ need to be stored or computed\n\\begin{equation}\ns^{k-1}_i + r^k_i \\ge \\hat \\delta_{k,l} \\quad \\forall_{k, l, i \\in \\mathcal{D}_k^l}.\\lbleq{switch_bwd}\n\\end{equation}\n\n\\vheading{Objective.}\nOur goal is to minimize the amount of computation required for the forward and backward pass.\nThis is represented as the sum of computational costs of all operators:\n\\begin{equation}\n  \\underbrace{\\sum_i \\sum_l \\tau_i^l \\delta_{i,l}}_\\text{forward pass} + \\underbrace{\\sum_k \\sum_l \\hat \\delta_{k,l} \\hat \\tau_k^l}_\\text{backward pass} + \\underbrace{\\sum_k\\sum_l \\tau_i^l \\delta_{i,l}^k}_\\text{recomputation} \\lbleq{objective_bwd}.\n\\end{equation}\n\nObjective (\\shortrefeq{objective_bwd}) with constraints  (\\shortrefeq{memconstr}), (\\shortrefeq{first_constr}), (\\shortrefeq{switch_bwd}), and definitions (\\shortrefeq{forward_mem}), (\\shortrefeq{sw_backward_mem}), (\\shortrefeq{sw_recompute_mem}) form our final optimization objective.\nIt jointly solves for the optimal implementation of each forward and backward operator, as well as an efficient checkpointing schedule.\n\n\\section{Experiments}\n\n\\vheading{Implementation Details.}\nWe develop \\sysname in the PyTorch framework.\nWe obtain a checkpointing schedule with optimal operator implementations by solving the joint optimization problem using the \\citet{gurobi} solver.\nAppendix \\ref{appendix:workflow} provides more implementation details and the full list of optimized operators.\n\nThe UNet experiments use 608$\\x$416 inputs following prior work~\\citep{checkmate}.\nAll other experiments use 224$\\x$224 inputs following conventions~\\citep{krizhevsky2012imagenet,simonyan2014very,resnet}.\nBatch size for the experiments is fixed to be the maximum at which the model can be trained using baseline PyTorch on a 16 GB GPU.\nWe reimplement Checkmate~\\citep{checkmate} in PyTorch for our comparisons.\nOur Checkmate implementation is competitive and uses the same network structure as \\sysname.\nCheckmate does not optimize for operator implementations like convolutions, so we show its runtime using the default convolution algorithm (Checkmate-D).\nFor a stronger comparison, we also show the runtime of a Checkmate schedule that is post-optimized to greedily run the fastest convolution algorithm (Checkmate-O).\nWherever not explicitly specified, we compare with Checkmate-O.\nAll checkpointing schedules are run using the same software implementations and costs are profiled on the same hardware (NVIDIA P100 GPUs).\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\begin{table}[b]\n  \\tablestyle{5pt}{1.12}\\begin{tabular}{@{}x{120}x{40}x{40}x{40}x{40}x{60}@{}}\n    & ResNet-50 & GoogleNet & UNet & VGG-16 & MobileNet-V2\\\\\n    \\shline\n    PyTorch & 15.1 & 14.9 & 14.3 & 14.1 & 14.5\\\\\n    \\hline\n    Checkmate~\\citep{checkmate} & 8.2 & 10.5 & 9.1 & 9.9 & 5.8\\\\\n    \\textbf{MONeT} & \\textbf{5.7} & \\textbf{6.9} & \\textbf{5.2} & \\textbf{5.5} & \\textbf{4.8}\\\\\n  \\end{tabular}\n  \\captionof{table}{\\textbf{Memory usage comparison (in GB) for a fixed compute overhead.}\n  At 10\\% compute overhead over PyTorch, MONeT uses \\textbf{2-3$\\times$} less memory than PyTorch.\n  At the same overhead, MONeT can train models using 1.2-1.8$\\times$ less memory than Checkmate.\n  }\n  \\label{tab:10pct}\n\\end{table}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\begin{figure}[t]\n\\small\n\\subfloat[\\textbf{ResNet-50} (184)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\nheight=4.0cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=1.0,\nymin=0,\nclip=false,\nymax=40,\nxlabel={Memory ratio},\nylabel={Overhead (\\%)},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={very thick ,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/pytorch.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/r50_184_checkmate_default.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/r50_184_checkmate.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/r50_184_monet.data};\n\\end{axis}\n\\end{tikzpicture}}\\hspace{-3mm}\n%%%%%%%%%%%\n\\subfloat[\\textbf{GoogleNet} (320)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\nheight=4.0cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=1.0,\nymin=0,\nclip=false,\nymax=36,\nxlabel={Memory ratio},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={very thick,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/pytorch.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/googlenet_320_checkmate_default.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/googlenet_320_checkmate.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/googlenet_320_monet.data};\n\\end{axis}\n\\end{tikzpicture}}\\hspace{-3mm}\n%%%%%%%%%%%\n\\subfloat[\\textbf{UNet} (11)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\nname=ax1,\nheight=4.0cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=1.0,\nymin=-5,\nclip=false,\nymax=82,\nxlabel={Memory ratio},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={very thick,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/pytorch.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/unet_11_checkmate_default.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/unet_11_checkmate.data};\n\\addplot%+[only\tmarks]\ntable[x index=0, y index=1] {plotdata/unet_11_monet.data};\n\\end{axis}\n\\end{tikzpicture}}\\hspace{-3mm}\n%%%%%%%%%%%\n\\subfloat[\\textbf{VGG-16} (176)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\nheight=4.0cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=1.0,\nymin=-6,\nclip=false,\nymax=82,\nxlabel={Memory ratio},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={very thick,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/pytorch.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/vgg16_176_checkmate_default.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/vgg16_176_checkmate.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/vgg16_176_monet.data};\n\\end{axis}\n\\end{tikzpicture}}\\hspace{-3mm}\n%%%%%%%%%%%\n\\subfloat[\\textbf{Mobile-V2} (272)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\nlegend style={at={(1.25,1.0)},anchor=north east,nodes={scale=0.85, transform shape}},\nheight=4.0cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=1.0,\nymin=0,\nclip=false,\nymax=36,\nxlabel={Memory ratio},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={very thick,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/pytorch.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/mobilenet_272_checkmate_default.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/mobilenet_272_checkmate.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/mobilenet_272_monet.data};\n\\legend{PyTorch, Checkmate-D, Checkmate-O,\\textbf{MONeT}}\n\\end{axis}\n\\end{tikzpicture}}\n  \\caption{\\textbf{Comparison of MONeT with PyTorch and Checkmate.} MONeT reduces memory by $3\\x$ compared to PyTorch, with 9-16$\\%$ compute overhead. It achieves a better memory-compute tradeoff than default Checkmate-D and also conv-optimized Checkmate-O.}\n  \\label{fig:exp:archi}\n\\end{figure}\\vspace{2mm}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n  \\begin{figure}[t]\n  \\small\n  \\subfloat[\\textbf{ResNet-50}]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[\n      ybar,\n      enlargelimits=0.2,\n      bar shift=0pt,\n      ylabel={Overhead (\\%)},\n      height=3.3cm,\n      width=0.35\\linewidth,\n      symbolic x coords={none,conv,out,int,all},\n      xtick={none,conv,out,int,all},\n      xticklabels={none,conv,out,int,\\textbf{all}},\n      bar width=10pt,\n      x tick label style={rotate=45,anchor=east},\n      nodes near coords,\n      nodes near coords align={vertical},\n      ]\n  \\addplot[ybar, fill=scarletred3] coordinates {  (none, 9.21)};\n  \\addplot[ybar, fill=chameleon3] coordinates { (conv, 6.99)};\n  \\addplot[ybar, fill=skyblue2] coordinates { (out, 6.37)};\n  \\addplot[ybar, fill=plum1] coordinates { (int, 9.30)};\n  \\addplot[ybar, fill=aluminium5] coordinates { (all, 5.53)};\n  \\end{axis}\n  \\end{tikzpicture}}\\hfill\n  \\subfloat[\\textbf{GoogleNet}]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[\n      ybar,\n      enlargelimits=0.2,\n      bar shift=0pt,\n      height=3.3cm,\n      width=0.35\\linewidth,\n      symbolic x coords={none,conv,out,int,all},\n      bar width=10pt,\n      xtick={none,conv,out,int,all},\n      xticklabels={none,conv,out,int,\\textbf{all}},\n      x tick label style={rotate=45,anchor=east},\n      nodes near coords,\n      nodes near coords align={vertical},\n      ]\n  \\addplot[ybar, fill=scarletred3] coordinates {  (none, 11.78)};\n  \\addplot[ybar, fill=chameleon3] coordinates { (conv, 10.67)};\n  \\addplot[ybar, fill=skyblue2] coordinates { (out, 8.78)};\n  \\addplot[ybar, fill=plum1] coordinates { (int, 11.29)};\n  \\addplot[ybar, fill=aluminium5] coordinates { (all, 8.45)};\n  \\end{axis}\n  \\end{tikzpicture}}\\hfill\n  \\subfloat[\\textbf{VGG-16}]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[\n      ybar,\n      enlargelimits=0.2,\n      bar shift=0pt,\n      height=3.3cm,\n      width=0.35\\linewidth,\n      symbolic x coords={none,conv,out,int,all},\n      bar width=10pt,\n      xtick={none,conv,out,int,all},\n      xticklabels={none,conv,out,int,\\textbf{all}},\n      x tick label style={rotate=45,anchor=east},\n      nodes near coords,\n      nodes near coords align={vertical},\n      point meta=explicit symbolic,\n      yticklabel={\\pgfmathparse{\\tick-3}\\pgfmathprintnumber{\\pgfmathresult}},\n      ]\n  \\addplot[ybar, fill=scarletred3] coordinates {  (none, 49.48) [39.48]};\n  \\addplot[ybar, fill=chameleon3] coordinates { (conv, 9.3) [-0.70]};\n  \\addplot[ybar, fill=skyblue2] coordinates { (out, 42.58) [32.58]};\n  \\addplot[ybar, fill=plum1] coordinates { (int, 32.67) [22.67]};\n  \\addplot[ybar, fill=aluminium5] coordinates { (all, 7.82) [-2.18]};\n  \\end{axis}\n  \\end{tikzpicture}}\n      \\captionof{figure}{\\textbf{Ablation results for memory ratio 0.53.} Lowest compute overhead across models is seen only when all optimizations are jointly optimized.}\n      \\label{fig:exp:ablation}\n  \\end{figure}\n\n  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\vheading{Detailed Comparison to Baselines.}\n\\reftab{10pct} compares the memory savings obtained by \\sysname and Checkmate for ResNet-50, GoogleNet, UNet, VGG-16, and MobileNet-V2, when computational overhead over PyTorch is fixed to be 10\\%.\n\\sysname schedules use \\textbf{2-3$\\times$} less memory than PyTorch.\nFor the same computational overhead, \\sysname uses 1.2-1.8$\\times$ less memory than Checkmate.\n\n\\reffig{exp:archi} shows more detailed runtime-memory trade-offs of \\sysname to PyTorch and Checkmate for different models.\nWe plot the average iteration time of training as \\% overhead over PyTorch for \\sysname and Checkmate schedules.\nThe memory budgets range from 5 GB to 10 GB, or equivalently, 0.33$\\times$ to 0.70$\\times$ PyTorch memory consumption.\nBatch size for these models is mentioned in paranthesis.\nFor all models, \\sysname reduces memory usage by $3\\x$ (0.33 memory ratio) as compared to baseline PyTorch with $9-16\\%$ compute overhead.\nFor the same memory budget, \\sysname schedules are up-to 34\\% faster than Checkmate schedules.\n\nWe measure the empirical performance of the checkpointed schedules running on GPUs instead of just providing the solver values; this is important since Checkmate doesn't consider workspace cost and overestimates its savings.\nAt tighter memory budgets for non-linear models like ResNet-50 and GoogleNet, Checkmate is unable to find feasible solutions within an hour of solver time.\nHence, we show the results with solver running for 1 day for both \\sysname and Checkmate.\nIn contrast, \\sysname finds the execution plans efficiently, its 1-hr solution already close to the 1-day solution with a small difference of 1-2\\%.\n\nFor networks with individual memory-intensive layers, like VGG-16, operator optimization becomes even more important for reducing memory; Checkmate can reduce memory for VGG-16 only upto 7 GB, whereas \\sysname with its optimizations is able to run VGG-16 with only 5.5 GB memory.\nThe small runtime improvement of \\sysname schedules over PyTorch for VGG-16 and UNet at higher memory budgets is mainly because of choosing faster convolution algorithms.\nMobilenet-V2 uses depthwise convolutions, and hence does not significantly benefit from joint convolution-optimization.\nAs a result, the performance of \\sysname and Checkmate is closer for Mobilenet-V2.\n\n\\begin{figure*}\n\\small\n\\begin{tikzpicture}\n\\begin{axis}[\n    legend style={at={(1.0,1.11)},anchor=north east,nodes={scale=1.0, transform shape}},\n    height=4.5cm,\n    legend columns=1,\n    width=0.98\\linewidth,\n    clip=false,\n    ylabel style={align=center},\n    ylabel={Mem. (MB)\\\\\\vspace{-1.5mm}},\n    ymax=18000,\n    xticklabels={,,},\n]\n\n\\addplot+[const plot mark mid, no marks, scarletred3, semithick]\nfile {plotdata/viz/pytorch_mem.data};\n\n\\addplot+[name path=monet, const plot mark mid, no marks, chameleon1, semithick]\nfile {plotdata/viz/monet_check_mem.data};\n\n\\addplot+[name path=monet, const plot mark mid, no marks, skyblue2, semithick]\nfile {plotdata/viz/monet_mem.data};\n\n\\legend{PyTorch (860 ms), MONeT-chpt-only (939 ms), \\textbf{MONeT (908 ms)}}\n\n\\node[] at (axis cs: 130,16000) {\\scriptsize{PyTorch (14.7 GB)}};\n\\node[] at (axis cs: 130,9000) {\\scriptsize{\\textbf{MONeT} (\\textbf{8.0 GB})}};\n\n\\addplot[mark=none, scarletred3!40, dashed, semithick] coordinates {(1, 15048.39) (349, 15048.39)};\n\\addplot[mark=none, skyblue2!40, dashed, semithick] coordinates {(1, 8196.19) (349, 8196.19)};\n\n\\end{axis}\n\\end{tikzpicture}\n\\begin{tikzpicture}\n\\begin{axis}[\n    legend style={at={(1.0,0.45)},anchor=north east,nodes={scale=0.9, transform shape}},\n    height=3.5cm,\n    width=0.98\\linewidth,\n    clip=false,\n    ylabel style={align=center},\n    ylabel={Mem. Diff (MB)},\n    ymax=700,\n    xticklabels={,,},\n    x axis line style={-,draw opacity=0},\n    scaled y ticks = true,\n    scaled y ticks=base 10:-2,\n]\n\\draw[->,>=stealth] (axis cs:1,0) -- (axis cs:349,0);\n\\path[name path=axis] (axis cs:1,0) -- (axis cs:349,0);\n\\addplot+[name path=saving, const plot mark mid, no marks, skyblue2]\nfile {plotdata/viz/monet_saving_viz.data};\n\\addplot[fill=skyblue2] fill between[\n  of = saving and axis,\n];\n\\end{axis}\n\\end{tikzpicture}\n\\begin{tikzpicture}\n\\begin{axis}[\n    height=2.5cm,\n    width=0.98\\linewidth,\n    clip=false,\n    ymax=5,\n    ylabel style={align=center},\n    ylabel={Overhead\\\\(\\%)\\vspace{1mm}},\n    xlabel={Network Layer Index},\n]\n\n\\path[name path=xaxis] (axis cs:1,0) -- (axis cs:349,0);\n\\addplot+[name path=compute, const plot mark mid, no marks, skyblue2]\nfile {plotdata/viz/monet_compute.data};\n\\addplot[fill=skyblue2] fill between[\n  of = compute and xaxis,\n];\n\\end{axis}\n\\end{tikzpicture}\n\\caption{\\textbf{Detailed case study on ResNet-50.}\nTop : memory usage along execution (forward and backward).\nMiddle: memory saving of MONeT over PyTorch for each layer.\nBottom: compute overhead of MONeT over PyTorch.\nMONeT saves memory in early layers to reduce peak memory.\nMost compute overhead happens at recomputation during backward (right-hand-side of the figure).\n}\n\\label{fig:case}\n\\end{figure*}\n\n\\vheading{Ablation Experiments.}\n\\reffig{exp:ablation} shows additional ablation experiments.\nWe show the \\% compute overhead over PyTorch on ResNet-50, GoogleNet, and VGG-16 for different types of \\sysname checkpointing schedules with a memory budget of 8 GB -\nwith no operator optimizations enabled, with only one type of operator optimization enabled (conv-optimized, output-activated optimized, intermediate-activated optimized), and with all optimizations enabled.\nSchedules which don't jointly optimize convolution algorithms are run with greedily post-optimized convolution algorithm.\nPlots for other models look similar to that of ResNet-50 and GoogleNet.\nThe only difference between 'none' and 'conv' is that convolution algorithms are jointly optimized in the latter.\nHowever, this fact leads to significant improvement in compute time for all cases.\nIn fact, convolution algorithms have complex workspace memory - compute characteristics, reserving slightly more memory for convolution workspace while checkpointing can allow for a much faster convolution (see Appendix \\ref{appendix:cudnn}).\nThis makes it important to jointly optimize conv algorithms with checkpointing.\nSimilarly, output-activated optimization also provides significant benefits over vanilla checkpointing, since it effectively reduces the number of recomputations required.\nFor memory-intensive networks, intermediate-activated optimization becomes more important.\nJointly optimizing all strategies together gives the least computational overhead.\nSee Appendix \\ref{appendix:ablation} for detailed ablation plots.\n\n\\vheading{Detailed Case Study.}\nThe top graph of \\reffig{case} shows memory usage while executing PyTorch, \\sysname without operator optimization, and \\sysname for ResNet-50 at batch size 184.\nAs the training progresses along network layers represented on X-axis, PyTorch and both \\sysname schedules store forward-pass outputs, leading to an increasing memory footprint.\n\\sysname reaches peak memory of 8 GB, whereas PyTorch requires 14.7 GB.\nStored forward outputs are freed up one after other as backward pass proceeds, leading to reduced usage of memory.\nAccording to the checkpointing schedule, \\sysname saves only a subset of the outputs stored by PyTorch, resulting in the memory saving shown in the middle graph for layer outputs that are not stored.\nThe bottom graph shows the per-layer compute overhead of recomputation of \\sysname over PyTorch.\nFor \\sysname, later layers which are backward operators result in a recomputation of the forward, and have higher overhead.\n\n\n\\section{Conclusion}\n\nWe present \\sysname, a system for automatically reducing memory requirements for training deep networks.\n\\sysname jointly optimizes local (operator-level) and global (graph-level) optimizations to yield a compute- and memory-efficient checkpointing schedule.\n\\sysname reduces memory usage by 3$\\x$ over PyTorch, with a compute overhead of $9-16\\%$.\nIt can also use 1.2-1.8$\\times$ less memory than the state-of-the-art automated checkpointing framework for the same computational cost.\nOur experimental results show that \\sysname leads to better memory-computation trade-offs compared to the state-of-the-art.\n\n\\def\\UrlBreaks{\\do\\/\\do-}\n\\bibliography{main}\n\\bibliographystyle{arxiv}\n\n\\appendix\n\\section{Bounds on local memory}\n\\label{appendix:tighten}\nIn Section \\ref{sec:prelim}, we mentioned that local memory $L_i^k$ is dependent on solver variable $r^k_t$.\n$$\nL_i^k = \\Theta \\cup \\{x_j : j \\in \\mathcal{N}_t\\text{ for any }t \\ge i\\text{ with }r^k_t=1\\text{ and }j<i\\}.\n$$\nIn order to remove this dependence, we can get an upper bound $\\bar L_i^k$ on $L_i^k$ by assuming that all future tensors after $i$ will always be recomputed, that is $r^k_t=1 \\forall t>i$\n$$\nL_i^k \\subseteq \\bar L_i^k = \\Theta \\cup \\{x_j : j \\in \\mathcal{N}_t\\text{ for any }t \\ge i\\text{ and }j<i\\}.\n$$\nOur experiments also use this upper bound.\nIt is possible to tighten the upper bound by noting that $r^k_t$ may be $1$ only in the case when $t \\le  k$.\nThat is, forward node $t$ will not be recomputed before computing backward of node $k$ if node $t$ lies after node $k$.\nThus, a tighter bound to $L_i^k$ follows\n$$\nL_i^k \\subseteq \\dot L_i^k = \\Theta \\cup \\{x_j : j \\in \\mathcal{N}_t\\text{ for any }t \\ge i\\text{ and }t \\le k\\text{ and }j<i\\} \\subseteq \\bar L_i^k.\n$$\n\n\\section{Detailed constraints}\n\\subsection{Expanded backward pass memory constraints}\n\\label{appendix:equations}\n\\refsec{main} formulates backward peak memory $\\hat m_k$ and recomputation peak memory $\\bar m_i^k$ as sum of memory of a set of tensors.\nWe expand the memory formulation and represent it in the terms of optimization variables here:\n\\begin{align}\n  \\hat m_k  &= \\sum_l \\hat c_k^l \\hat \\delta_{k,l} + |y_k| + |\\hat L_k| + \\sum_l \\hat \\delta_{k,l} . | D_k^l \\cup S^{k-1}|\\notag\\\\\n            &= \\sum_l \\hat c_k^l \\hat \\delta_{k,l} + |y_k| + \\sum_{y_l \\in \\hat L_k}\\!|y_l| + \\sum_l\\sum_{x_i \\in D_k^l}\\! \\hat \\delta_{k,l} |x_i| + \\sum_l \\sum_{x_i \\notin D_k^l}\\!\\underbrace{\\hat\\delta_{k,l} s_i^{k-1}}_{\\sigma_{k,l,s}} |x_i|,\n\\end{align}\n \\begin{align}\n  \\bar m_i^k &= c_i + |x_i| + |\\hat L_k| + \\sum_l \\hat \\delta_{k,l} . | S_i^{k-1} \\cup \\bar L_i^k \\cup D_k^l|\\notag\\\\\n            &=c_i + |x_i| + |\\hat L_k| + \\sum_l \\sum_{\\mathclap{\\substack{j<i: \\\\x_j \\notin \\bar L_i^k \\cup D_k^l}}} \\hat \\delta_{k,l} s^{k-1}_j |x_j| + \\sum_l \\sum_{\\mathclap{\\substack{j<i: \\\\x_j \\in \\bar L_i^k \\cup D_k^l}}} \\hat \\delta_{k,l} |x_j|+\\sum_{j>i} s^{k}_j |x_j|.\n\\end{align}\n\n\\subsection{Complete memory constraints}\nIn this section, we present the complete memory constraints which we use for \\sysname optimization.\nThese constraints include the recomputation variable $r_i^k$, which was excluded from the main text to make understanding simpler.\nAs discussed in \\refsec{prelim}, the peak memory of a $\\mathrm{forward}_i$ recomputation before computing $\\mathrm{backward}_k$ is denoted by $\\tilde{m}_i^k$.\nThis represents the recomputation memory (renamed to $m_{Ri}^k$) when $\\mathrm{forward}_i$ is actually recomputed, that is, $r_i^k = 1$.\nWhen this is not true, the peak memory ($\\tilde m_{Si}^k$) only depends on stored checkpoints $S_i^{k-1}$, checkpoint dependencies for $D_k$, and gradient tensors $\\hat L_k$.\nThus,\n\\begin{align}\n  \\tilde m_{Ri}^k &= c_i + |x_i| + |\\hat L_k| + |S^{k-1}_i \\cup L_i^k \\cup D_k|\\notag\\\\\n  &= r_i^k c_i + r_i^k |x_i| + |\\hat L_k| + \\quad \\sum_{\\mathclap{j<i: x_j \\notin L_i^k \\cup D_k}}s^{k-1}_j |x_j| + \\quad \\sum_{\\mathclap{j<i: x_j \\in L_i^k}} r_i^k |x_j|+ \\quad \\sum_{\\mathclap{j<i: x_j \\in D_k - L_i^k}} |x_j| +\\sum_{j>i} s^{k}_j |x_j| \\label{recompute_mem_full}.\\\\\n  \\tilde m_{Si}^k &= |\\hat L_k| + |S^{k-1}_i  \\cup D_k|\\notag\\\\\n  &= |\\hat L_k| +\\sum_{j \\le i: x_j \\notin D_k}s^{k-1}_j |x_j| + \\sum_{j \\le i: x_j \\in D_k} |x_j| +\\sum_{j>i} s^{k}_j |x_j| \\lbleq{checkpoint_mem_full}.\n \\end{align}\n\nLocal memory $L_k$ can be bounded by $\\bar L_k$, which gives us $\\bar m_{Ri}^k$.\nTo add forward operator optimizations to $\\bar m_{Ri}^k$, recall the tradeoff between workspace memory and compute time.\nWe replace the workspace memory contributor $r_i^k c_i$ in equation \\ref{recompute_mem_full} with $\\sum_l \\delta_{i,l}^k c_i^l$.\n\nThe complete memory constraints are:\n\\begin{equation}\n  \\begin{split}\n  m_i \\le M \\quad \\forall_{i} \\quad \\text{and} \\quad \\hat m_k \\le M \\quad \\forall_{k} \\quad \\text{and} \\quad  \\bar m_{Ri}^k \\le M \\quad \\forall_{k,i} \\quad \\text{and} \\quad \\tilde m_{Si}^k \\le M \\quad \\forall_{k,i}\n  \\end{split}\n\\end{equation}\n\n\\section{Implementation}\n\\label{appendix:workflow}\nWe develop \\sysname in the PyTorch framework.\nWe use PyTorch's default Autograd package for backward implementation of elementary functions when the autograd implementation is stateless.\nIn all other cases, we implement custom forward and backward functions leveraging PyTorch ATen library functions to flexibly support multiple operators and execution schedules.\nEach backward operator implementation is annotated with its computational dependencies, which is generally the input or the output of its corresponding forward operator.\nCertain backward operators implementations may have dependencies on intermediate activations generated in the forward pass.\nFor example, an intermediate-activated ReLU backward uses an encoded bitmask representing the sign of forward operator's input.\nWe annotate this as an intermediate storage node and add it to our optimization problem, with a strict recomputation dependency of the interemediate storage node on its creator node.\nOur operator optimizations select from different backward operator implementations, convolution algorithms, in-place operators etc.\nFurther, we separate the parameter gradient operators and input gradient operators for convolution in the graph during optimization.\nSince the input gradient computation does not depend on any output from the forward pass, we can agressively free the forward input tensor after the parameter gradient is computed.\nWe also reuse BatchNorm statistics in case of their recomputation.\nFor our experiments, we limit ourselves to full precision training as quantization or lower precision computations introduce additional noise into SGD and change its convergence properties.\nWe solve the joint optimization problem using the CVXPY\\citep{diamond2016cvxpy,agrawal2018rewriting} solver with \\citet{gurobi} backend.\n\n\n\\vheading{\\sysname workflow.}\nWe obtain the forward pass dependencies in \\sysname by JIT tracing a model to obtain its graph.\nWe profile each layer for workspace memory and compute cost, and obtain memory usage of the tensors from their shape and type.\nNote that the workspace memory for many convolution operators in VGG-16 is greater than 2GB, making it an important factor to model.\nUnlike prior approaches like Checkmate, we account for this workspace memory in our optimization problem, bringing the memory model very close to actual memory allocation.\nWe phrase a boolean integer programming problem using the generated graph and the profiled compute cost and workspace memory and solve it using the CVXPY\\citep{diamond2016cvxpy,agrawal2018rewriting} solver and GUROBI\\citep{gurobi} backend.\nThe solution is used to generate a schedule that can be run by the \\sysname scheduler.\n\n\\vheading{Operator optimizations.}\nWe divide operator optimizations according to the different type of implementations they select from.\n(1) \\textit{Output-activated}: Backward calculation of operators like ReLU and BatchNorm can have computational dependency either on on their forward node's inputs or outputs.\n(2) \\textit{Intermediate-activated}: Backward of ReLU has computational dependency on a 1-bit encoding of the sign of its forward node's input.\nBackward of MaxPool is calculated using an intermediate 8-bit output-shaped tensor which contains the kernel-index of the maximum element.\n(3) \\textit{Convolution algorithms}: We choose from 8 forward and 6 backward cuDNN convolution algorithms.\n(4) \\textit{Inplace operations}: The solver can choose to do inplace computation for operators like ReLU forward.\n  We discuss constraints for in-place operator selection in \\ref{appendix:inplace}.\n  All \\sysname experiments enable in-place operation selection.\n\n\\subsection{In-place constraints}\n\\label{appendix:inplace}\nWe show how to represent the decision of computing an operator using an in-place or out-of-place implementation.\nIf an operator like ReLU uses an in-place implementation, its input tensor is overwritten with its output.\nIn this case, its input tensor cannot be stored or used as input to a computation in this stage.\nThis needs to be reflected in our constraints.\nWe introduce two new binary variables to model in-place computations: $q_i^k$ represents if $\\mathrm{forward}_i$ is recomputed in-place when computing $\\mathrm{backward}_k$.\n$p_i^k$ represents that the output of $\\mathrm{forward}_i$ has been computed and will not be overwritten by any other forward node recomputations in this stage.\nIf $q_i^k$ is true, then $p_j^k$ will be false else $p_j^k$ will be the same as $r_j^k$, where $j \\in \\mathcal{N}_i$.\nFurther, $s_j^{k-1}$ will also be false if $q_i^k$ is true.\nThis can be written in the form of boolean constraints as follows:\n\\begin{equation}\n  \\begin{split}\n    p_j^k \\ge r_j^k - 2 q_i^k \\qquad \\text{and} \\qquad p_j^k \\le 2 - 2 q_i^k \\qquad \\text{and} \\qquad s_k^{k-1} \\le 2 - 2 q_i^k.\n  \\end{split}\n\\end{equation}\n\nThe checkpointing constraint \\shortrefeq{first_constr} changes, with $p_j^k$ replacing $r_j^k$ on the RHS.\nFurther, $q_i^k$ (or $p_j^k$) can only be true if $\\mathrm{forward}_i$ (or $\\mathrm{forward}_j$) is actually recomputed prior to computing backward node k.\nThus,\n\\begin{equation}\n  \\begin{split}\n    p_j^k \\le r_j^k  \\qquad \\text{and} \\qquad q_i^k \\le r_i^k.\n\\end{split}\n\\end{equation}\n\n\\section{Detailed ablations}\n\\label{appendix:ablation}\n\\reffig{exp:ablation:appendix} shows a detailed plot of our ablation experiments comparing the compute overhead of variants of \\sysname across a range of memory limits.\nY-axis shows the compute overhead over PyTorch and X-axis shows the memory ratio to a PyTorch model.\nAll variants which are not conv-optimized are greedily post-optimized to use the fastest convolution.\nWe see that \\sysname with no operator optimization (NoOp) is generally slower than the other variants for all models and memory limits.\nConvolution and output-activated optimizations are both important in reducing compute overhead.\nMobilenet-V2 uses depthwise separable convolutions, and hence does not significantly benefit from convolution-optimization.\nFurther, Mobilenet-V2 has \\texttt{hardtanh} operators instead of ReLU operators, for which we have not implemented intermediate-activated backward optimization.\nInteremediate-activated optimizations provide memory savings in memory-intensive models, allowing models like VGG-16 to reach memory savings which are not attainable by other optimizations.\nAll optimizations together result in the least compute overhead for any model or memory limit.\n\\begin{figure}[thb]\n  \\small\n\\subfloat[\\textbf{ResNet-50} (184)]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[%\n  legend style={at={(1.1,1.1)},anchor=north east},\n  height=4.5cm,\n  width=0.2583\\linewidth,\n  xmin=0.3,\n  xmax=0.8,\n  ymin=3,\n  clip=false,\n  ymax=17,\n  xlabel={Memory ratio},\n  ylabel={Compute overhead (\\%)},\n  cycle multiindex* list={%no unwanted space\n    mycolormarklist\n        \\nextlist\n    mystylelist\n  },\n  every axis plot/.append style={thick,mark options={scale=0.5, solid}},\n  mark size=2pt,\n  ]\n  \\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_r50_184_no.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_r50_184_int.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_r50_184_out.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_r50_184_conv.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_r50_184_monet.data};\n  \\end{axis}\n  \\end{tikzpicture}}\\hspace{-3mm}\n\\subfloat[\\textbf{GoogleNet} (320)]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[%\n  height=4.5cm,\n  width=0.2583\\linewidth,\n  xmin=0.3,\n  xmax=0.8,\n  ymin=6.5,\n  clip=false,\n  ymax=18,\n  xlabel={Memory ratio},\n  cycle multiindex* list={%no unwanted space\n    mycolormarklist\n        \\nextlist\n    mystylelist\n  },\n  every axis plot/.append style={thick,mark options={scale=0.5, solid}},\n  mark size=2pt,\n  ]\n  \\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_googlenet_320_no.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_googlenet_320_int.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_googlenet_320_out.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_googlenet_320_conv.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_googlenet_320_monet.data};\n  \\end{axis}\n  \\end{tikzpicture}}\\hspace{-3mm}\n\\subfloat[\\textbf{UNet} (11)]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[%\n  height=4.5cm,\n  width=0.2583\\linewidth,\n  xmin=0.3,\n  xmax=0.8,\n  ymin=-5,\n  clip=false,\n  ymax=20,\n  xlabel={Memory ratio},\n  cycle multiindex* list={%no unwanted space\n    mycolormarklist\n        \\nextlist\n    mystylelist\n  },\n  every axis plot/.append style={thick,mark options={scale=0.5, solid}},\n  mark size=2pt,\n  ]\n  \\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_unet_11_no.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_unet_11_int.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_unet_11_out.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_unet_11_conv.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_unet_11_monet.data};\n  \\end{axis}\n  \\end{tikzpicture}}\\hspace{-3mm}\n\\subfloat[\\textbf{VGG-16} (176)]{%no unwanted space\n  \\begin{tikzpicture}\n  \\begin{axis}[%\n  height=4.5cm,\n  width=0.2583\\linewidth,\n  xmin=0.3,\n  xmax=1,\n  ymin=-7,\n  clip=false,\n  ymax=42,\n  xlabel={Memory ratio},\n  cycle multiindex* list={%no unwanted space\n    mycolormarklist\n        \\nextlist\n    mystylelist\n  },\n  every axis plot/.append style={thick,mark options={scale=0.5, solid}},\n  mark size=2pt,\n  ]\n  \\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_vgg_176_no.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_vgg_176_int.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_vgg_176_out.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_vgg_176_conv.data};\n  \\addplot%+[only marks]\n  table[x index=0, y index=1] {plotdata/abl_vgg_176_monet.data};\n\\end{axis}\n\\end{tikzpicture}}\\hspace{-3mm}\n\\subfloat[\\textbf{Mobile-V2} (272)]{%no unwanted space\n\\begin{tikzpicture}\n\\begin{axis}[%\n  legend style={at={(1.1,1.05)},anchor=north east,nodes={scale=0.85, transform shape}},\nheight=4.5cm,\nwidth=0.2583\\linewidth,\nxmin=0.3,\nxmax=0.8,\nymin=2,\nclip=false,\nymax=14,\nxlabel={Memory ratio},\ncycle multiindex* list={%no unwanted space\n  mycolormarklist\n      \\nextlist\n  mystylelist\n},\nevery axis plot/.append style={thick,mark options={scale=0.5, solid}},\nmark size=2pt,\n]\n\\pgfplotsset{every tick label/.append style={font=\\scriptsize}}\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/abl_mobilenet_272_no.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/abl_mobilenet_272_int.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/abl_mobilenet_272_out.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/abl_mobilenet_272_conv.data};\n\\addplot%+[only marks]\ntable[x index=0, y index=1] {plotdata/abl_mobilenet_272_monet.data};\n  \\legend{NoOp, Int, Out, Conv, \\textbf{All}}\n\\end{axis}\n\\end{tikzpicture}}\n    \\caption{\\textbf{Ablation results on ResNet-50, GoogleNet, UNet, VGG-16, MobileNet-V2.}}\n    \\label{fig:exp:ablation:appendix}\n  \\end{figure}\n\n\\section{On operator selection for checkmate}\n\\label{a:checkmate}\nIn this section, we briefly explain the difficulties of including operator selection directly into checkmate~\\cite{}.\nWe will refer directly to notation and equations in the checkmate paper (arxiv v3; 14 May 2020).\nThe most direct way to incorporate operator selection into checkmate is to introduce an auxiliary variable $R_{t,i}^v \\in \\{0,1\\}$ that refers to re-computing layer $i$ at time $t$ using implementation $v$.\nMost constraints in equation 1 could stay the same, given $R_{t,i} = \\sum_v R_{t,i}^v$, and loss (1a) $\\sum_t\\sum_i\\sum_v R_{t,i}^v C_i^v$.\nSome of our operators produce a different kind of checkpoint (e.g. binary activated ReLUs), which could be handled in check-mate by splitting $S_{t,i}^v$.\nThe main issues in checkmate arise in the memory modeling and its relaxations (eq 4,5,7).\nThe memory consumed by a specific checkpoint may depend on the operator implementation: $\\mathrm{DEPS[k]}$ and $\\mathrm{USERS[i]}$ both depend on the operator implementation (output activated, input activated, ...).\nIn short, the checkmate computation graph is dynamic and depends on operator implementations.\nThe most direct way to address this is to $\\mathrm{mem\\_freed}_t(v_k) = \\sum_v R_{t,i}^v \\mathrm{mem\\_freed}_t(v_k)$ in a implementation dependent way $\\mathrm{mem\\_freed}^v_t(v_k)$, and select the right version dependent on the operator used.\nLikewise, we need to extend $\\mathrm{FREE}_{i,t,k}^v$ to account for different operator implementations in $R_{t,k}^v$.\nLikewise the product in equation (5) will now go over all implementations $R_{i,j}^v$ using different $\\mathrm{USERS}$ sets.\nThis leads to a linear blowup in the number of constraints, and number of auxiliary variables, leading to an at least quadratic expansion on computational costs.\nFurthermore, $\\mathrm{mem\\_freed}_t(v_k) = \\sum_v R_{t,i}^v \\mathrm{mem\\_freed}_t(v_k)$ is a quadratic constrain that further needs to be resolved using additional auxiliary variables.\nGiven that Checkmate already pushes the limits of current solvers, it is unlikely able to handle this explosion in constraints and variables, without significant modifications.\n\\sysname in the other hand represents the compute-graph more compactly and efficiently integrates different operator implementations.\n\n\n\\section{Constraint Linearization}\n\\label{appendix:linearization}\nThe memory constraints we introduce in Section \\ref{sec:main} contain\nquadratic terms in the form of $x_i\\cdot x_j$, with $x_i, x_j \\in \\cbr{0, 1}$.\nThe quadratic terms cannot directly be incorporated into an integer program.\nHowever, we can linearize these terms by replacing each quadratic term $x_i\\cdot x_j$ by an auxiliary variable $\\alpha_{i,j} \\in \\cbr{0,1}$ and introducing additional linear constraints $\\alpha_{i, j} \\geq x_i + x_j - 1$,\n$ \\alpha_{i, j} \\leq x_i $, and\n$ \\alpha_{i, j} \\leq x_j$.\nAfter this substitution for all quadratic terms, all constraints in \\sysname are linear.\n\n\\section{Convolution Algorithms}\n\\label{appendix:cudnn}\n\\reffig{exp:cudnn} shows the complex workspace memory - compute tradeoff for different convolution algorithms.\nThe memory used is not always inversely proportional to the compute requirement.\nJointly optimizing convolution algorithms enables \\sysname to make the best decisions for which convolution algorithm to select.\n\n\\begin{figure}[thb]\n  \\small\n  \\begin{center}\n  \\begin{tikzpicture}\n    \\begin{axis}[%\n    ymin=0,\n    ymax=0.45,\n    xmin=0,\n    xmax=2.5,\n    height=3.5cm,\n    width=3.5cm,\n    xlabel={Workspace memory (GB)},\n    ylabel={Time (ms)},\n    scatter/classes={%\n      a={mark=square*,skyblue2},%\n      b={mark=triangle*,red},%\n      c={mark=o,draw=black}}]\n    \\addplot[scatter,only marks,%\n      scatter src=explicit symbolic]%\n    table[meta=label] {\n  x     y      label\n  2.30  0.39 a\n  1.22  0.07 a\n  0.86  0.05 a\n  0.57  0.18 a\n  0.57  0.08 a\n  0.58  0.06 a\n  1.44  0.05 a\n    };\n  \\end{axis}\n  \\end{tikzpicture}\n  \\end{center}\n  \\captionof{figure}{\\textbf{Memory vs. compute}\n  for 7 conv algorithms with 256$\\x$64$\\x$56$\\x$56 input, 3$\\x$3 kernel, 64 output channels.}\n  \\label{fig:exp:cudnn}\n\\end{figure}\n\\section{Notations}\n\\label{a:notation}\n\\reftab{not} gives a brief explanation of some of the notations used in the paper.\n\n\\begin{table}[thb]\n  \\tablestyle{5pt}{1.12}\\begin{tabular}{@{}x{70}p{250pt}@{}}\n    Notation & Meaning \\\\\n    \\shline\n    Solver variables & \\\\\n    $s_i^{N}$             & Output of $\\mathrm{forward}_i$ is stored in memory in the forward pass \\\\\n    $s_i^{k-1}$             & Output of $\\mathrm{forward}_i$ is stored in memory when computing $\\mathrm{backward}_k$ \\\\\n    $r_i^k$             & $\\mathrm{forward}_i$ is recomputed before computing $\\mathrm{backward}_k$ \\\\\n    $\\delta_{i,l}$      & $\\mathrm{forward}_i$ uses implementation $l$ in the forward pass \\\\\n    $\\delta_{i,l}^k$      & $\\mathrm{forward}_i$ uses implementation $l$ when recomputed before $\\mathrm{backward}_k$\\\\\n    $\\hat \\delta_{k,l}$ & $\\mathrm{backward}_k$ uses implementation $l$ \\\\\n    \\\\\n    Memory formulations & \\\\\n    $m_i$ &  Peak memory of $\\mathrm{forward}_i$ in forward pass \\\\\n    $\\bar m_i^k$ &  Peak memory of $\\mathrm{forward}_i$  when it is recomputed before $\\mathrm{backward}_k$ \\\\\n    $\\hat m_k$ & Peak memory of $\\mathrm{backward}_k$ \\\\\n  \\end{tabular}\n  \\vspace{-1mm}\n  \\captionof{table}{\\textbf{Notations.}\n\\vspace{-3mm}\n  }\n  \\label{tab:not}\n\\end{table}\n\n\\end{document}", "meta": {"timestamp": "2020-10-30T00:27:49", "yymm": "2010", "arxiv_id": "2010.14501", "url": "https://arxiv.org/abs/2010.14501", "source": "arxiv"}}
{"text": "%\n% File acl2020.tex\n%\n%% Based on the style files for ACL 2020, which were\n%% Based on the style files for ACL 2018, NAACL 2018/19, which were\n%% Based on the style files for ACL-2015, with some improvements\n%%  taken from the NAACL-2016 style\n%% Based on the style files for ACL-2014, which were, in turn,\n%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,\n%% EACL-2009, IJCNLP-2008...\n%% Based on the style files for EACL 2006 by \n%%e.agirre@ehu.es or Sergi.Balari@uab.es\n%% and that of ACL 08 by Joakim Nivre and Noah Smith\n\n\\documentclass[11pt,a4paper]{article}\n\\usepackage[hyperref]{acl2020}\n\\usepackage{times}\n\\usepackage{latexsym}\n\\usepackage{multirow}\n\\usepackage{graphicx}\n\\usepackage{enumitem,titlesec,xcolor}\n\\usepackage[object=vectorian]{pgfornament}\n\\usepackage{tikz}\n\n\\newcommand{\\sectionlinetwo}[2]{%\n  \\nointerlineskip \\vspace{.5\\baselineskip}\\hspace{\\fill}\n  {\\color{#1}\n    \\resizebox{0.5\\linewidth}{2ex}\n    {{%\n    {\\begin{tikzpicture}\n    \\node  (C) at (0,0) {};\n    \\node (D) at (9,0) {};\n    \\path (C) to [ornament=#2] (D);\n    \\end{tikzpicture}}}}}%\n    \\hspace{\\fill}\n    \\par\\nointerlineskip \\vspace{.5\\baselineskip}\n  }\n\n\\renewcommand{\\UrlFont}{\\ttfamily\\small}\n\n% This is not strictly necessary, and may be commented out,\n% but it will improve the layout of the manuscript,\n% and will typically save some space.\n\\usepackage{microtype}\n\n\n\\usepackage{float}\n\\floatstyle{boxed} \n\\restylefloat{figure}\n\n\\aclfinalcopy % Uncomment this line for the final submission\n%\\def\\aclpaperid{***} %  Enter the acl Paper ID here\n\n%\\setlength\\titlebox{5cm}\n% You can expand the titlebox if you need extra space\n% to show all the authors. Please do not make the titlebox\n% smaller than 5cm (the original size); we will check this\n% in the camera-ready version and ask you to change it back.\n\n\\newcommand\\BibTeX{B\\textsc{ib}\\TeX}\n\n\n\\title{Unmasking Contextual Stereotypes:\\\\ Measuring and Mitigating BERT's Gender Bias}\n\n\n\\author{Marion Bartl \\\\\n  University of Groningen \\\\\n  University of Malta \\\\\n  \\texttt{\\small marion.bartl.18@um.edu.mt} \\\\\\And\n  Malvina Nissim \\\\\n  University of Groningen \\\\\n  \\texttt{m.nissim@rug.nl} \\\\\\And\n  Albert Gatt \\\\\n  University of Malta \\\\\n  \\texttt{albert.gatt@um.edu.mt} \\\\}\n\n\\date{}\n\n\\begin{document}\n\\maketitle\n\\begin{abstract}\nContextualized word embeddings have been replacing standard embeddings as the representational knowledge source of choice in NLP systems. Since a variety of biases have previously been found in standard word embeddings, it is crucial to assess biases encoded in their replacements as well. Focusing on BERT \\citep{devlin2018bert}, we measure gender bias by studying associations between gender-denoting target words and names of professions in English and German, comparing the findings with real-world workforce statistics. We mitigate bias by fine-tuning BERT on the GAP corpus \\citep{webster2018gap}, after applying Counterfactual Data Substitution (CDS) \\citep{maudslay2019CDS}. We show that our method of measuring bias is appropriate for languages such as English, but not for languages with a rich morphology and gender-marking, such as German. Our results highlight the importance of investigating bias and mitigation techniques cross-linguistically, especially in view of the current emphasis on large-scale, multilingual language models.\n\\end{abstract}\n\n%===========================================================\n\n\\section{Introduction}\nThe biases present in the large masses of language data that are used to train Natural Language Processing (NLP) models naturally leak into NLP systems. \nThese systematic biases can have real-life consequences when such systems are e.g. used to rank the resumes of possible candidates for a vacancy in order to aid the hiring decision \\citep{bolukbasi2016man}. If, for example, a model does not associate female terms with engineering professions, because these do not often co-occur in the same context in the training corpus, then the system is likely to rank male candidates for an engineering position higher than equally qualified female candidates.\n\nAs NLP applications reach more and more users directly \\citep{sun2019litreview}, bias in NLP and as well as resulting societal implications, have become an area of research \\citep{hovy-spruit-2016-social,shah2019predictive}. The ACL conference includes a workshop on ethics in NLP since 2017 \\citep{2017-acl-gender} and one that specifically addresses gender bias since 2019 \\citep{gender-workshop-2019}.\n\nThe present work contributes to promoting fairness in NLP by exploring methods to measure and mitigate gender bias in BERT \\citep{devlin2018bert}, a contextualized word embedding model.\nIts widespread and quick adoption by the research community as the backbone for a variety of tasks calls for an assessment of possible biases encoded in it.\n\n\\paragraph{Research Questions} We combine researching how we can measure gender bias in BERT (RQ1) and how such potential gender bias can be mitigated (RQ2), with two further perspectives: a comparison with real-world statistics and a cross-lingual approach. We investigate whether gender bias in BERT is statistically related to actual women's workforce participation (RQ3), and whether a method that we successfully apply to assess gender bias in English is portable to a language with rich morphology and gender marking such as German, since such languages have proven challenging to existing methods \\citep{gonen2019gendermarking, zmigrod2019counterfactual, zhou2019examining} (RQ4).\n\n\n\\paragraph{Contributions} This work makes the following contributions:\n(i) We present and release the Bias Evaluation Corpus with Professions (BEC-Pro), a template-based corpus in English and German, which we created to measure gender bias with respect to different profession groups. We make the dataset and code for all experiments publicly available at \\url{https://github.com/marionbartl/gender-bias-BERT}. \n(ii) Through a more diverse sentence context in our corpus than in previous research, we confirm that the method of querying BERT's underlying MLM (Masked Language Model), proposed by \\citet{kurita2019measuring}, can be used for bias detection in contextualized word embeddings. \n(iii) We test our bias analysis on BERT against actual U.S. workforce statistics, which helps us to observe that the BERT language model does not only encode biases that reflect real-world data, but also those that are based on stereotypes.\nFor bias mitigation, (iv) we show the success of a technique on BERT, which was previously applied on ELMo \\citep{elmo_main_paper,zhao2019gender}. Finally, (v) we attempt the cross-lingual transfer of a bias measuring method proposed for English,  \nand show how this method is impaired by the morphological marking of gender in German.\n\n\n\\paragraph{Bias Statement}\\label{sec:bias_statement}\n\nThe present work focuses on gender bias specifically. Gender bias is the systematic unequal treatment on the basis of gender \\citep{moss2012science, sun2019litreview}. \nWhile we are treating gender as binary in this study, we are aware that this does not include people who identify as non-binary, which can create representational harm \\citep{blodgett-etal-2020-language}.\nIn the context of our study of the BERT language model, gender bias occurs when one gender is more closely associated with a profession than another in language use, resulting in biased language models. Before the backdrop of gender participation statistics, we can assess whether a biased representation is related to the employment situation in the real world or based on stereotypes. In the latter case, this constitutes representational harm, because actual participation in the workforce is rendered invisible \\citep{blodgett-etal-2020-language}. Moreover, if word representations are used in downstream systems that affect hiring decisions, gender bias, irrespective of whether it is representative of real-world data, may lead to allocational harm, because male and female candidates are not equally associated with a profession from the start \\citep{blodgett-etal-2020-language}.\n\n%===========================================================\n\n\\section{Background and Previous Work}\\label{sec:prev_work}\n\nApproaches to gender bias in contextualized word embeddings borrow techniques originally developed for standard embedding models. However, they need to rely on sentence contexts since contextualized word representations are conditioned on the sentence the word occurs in. Previous research uses either templates \\citep{may2019measuring, kurita2019measuring} or sentences randomly sampled from a corpus \\citep{zhao2019gender, basta2019evaluating}. \\citet{may2019measuring} adapt the Word Embedding Association Test \\citep[WEAT;][]{caliskan2017semantics} to pooled sentence representations, resulting in the SEAT (Sentence Encoder Association Test). However, the authors express concerns about the validity of this method.\n\\citet{zhao2019gender} analyze the gender subspace following \\citet{bolukbasi2016man}, and also classify the vectors of occupation words that occur in the same context with male and female pronouns, using coreference resolution as an extrinsic measure of gender bias. They mitigate bias via Counterfactual Data Augmentation (CDA) and neutralization.\\footnote{Neutralization means that at test time, gender-swapping is applied to an input sentence, and the ELMo representation for both sentences are averaged \\citep{zhao2019gender}.} Results show that CDA was more effective.\n\\citet{basta2019evaluating} measure gender bias by projection onto the gender direction \\citep{bolukbasi2016man} as well as clustering and classification, following \\citet{gonen2019lipstick}. \nResults from these adapted methods show that contextualized embeddings encode biases just like standard word embeddings \\citep{zhao2019gender, basta2019evaluating}. \n\n\nInstead of adapting bias measuring methods from standard word embeddings, \\citet{kurita2019measuring} exploit the Masked Language Model (MLM), native to BERT \\cite{devlin2018bert}. Unlike ELMo \\citep{elmo_main_paper} or GPT-2 \\citep{radford2019language}, BERT learns contextualized word representations using a masked language modelling objective \\citep{devlin2018bert}, making the model bi-directional. Crucially, this makes it possible to obtain the probability of a single token in a sentence.\n\\citet{kurita2019measuring} use the MLM to estimate the probability of a masked, gendered target word being associated with an attribute word in a sentence. This method was shown to capture differences in association across the categories covered by \\citet{caliskan2017semantics} in an interpretable way.\n\nOne of the problems of current research in NLP is that most work focuses on English \\citep{hovy2016social,sun2019litreview}. \nMethods developed to study gender bias in English do not translate well to languages that have grammatical gender, since grammatical gender can have a veiling effect on the semantics of a word. For example, \\citet{gonen2019gendermarking} find that words with the same grammatical gender were regarded as more similar, as opposed to words that have similar meanings. This can occur, for instance, because gender agreement between articles and adjectives \\citep{corbett_nr_genders30} renders the contexts in which nouns with the same grammatical gender occur more similar.\n\\citet{gonen2019gendermarking} also found that due to this grammatical gender bias, the debiasing method of \\citet{bolukbasi2016man} was ineffective on Italian and German word embeddings. \n\\citet{zmigrod2019counterfactual} propose to use CDA as a debiasing method for gender-marking languages, because it is a pre-processing method and as such independent from the resulting vectors. The researchers measure gender bias extrinsically by using a neural language model, following \\citet{lu2018CDA}. \n\n\\paragraph{Present Work}\nIn the present research, we follow \\citet{kurita2019measuring} in measuring gender bias. We apply their method of querying the MLM for a more diverse range of sentence templates from a professional context. Additionally, we base the choice of professions on workforce statistics, in order to compare bias to the real-world situation. For mitigating gender bias, we apply \\citeauthor{maudslay2019CDS}'s \\citeyearpar{maudslay2019CDS} version of CDA to fine-tuning data for BERT, because it has shown promising results for both mitigating bias in English ELMo \\citep{zhao2019gender} and in embeddings of morphologically rich languages \\citep{zmigrod2019counterfactual}.\n\n%===========================================================\n\n\n\\section{Data}\\label{sec:data}\n\nIn line with previous research \\citep{kurita2019measuring, zhao2019gender, basta2019evaluating}, we measure gender bias in BERT using sentence templates. For this purpose we create the \\textbf{Bias Evaluation Corpus with Professions (BEC-Pro)}, containing English and German sentences built from templates (Section~\\ref{ssec:becpro}).\nWe also use two previously existing corpora, which are described in Section~\\ref{sec:existing-corpora}.\n\n\n\\subsection{Existing Corpora}\n\\label{sec:existing-corpora}\nThe Equity Evaluation Corpus (EEC) was developed by \\citet{kiritchenko2018EEC} as a benchmark corpus for testing gender and racial bias in NLP systems in connection with emotions. It contains 8,640 sentences constructed using 11 sentence templates with the variables \\textless{}person\\textgreater{}, which is instantiated by a male- or female-denoting NP; and \\textless{}emotion word\\textgreater{}, whose values can be one of the basic emotions. We use this corpus for preliminary bias assessment.\\footnote{The templates from the EEC corpus were used in preliminary experiments to test the validity of our method. For the sake of space, and to focus on the association with professions, we do not discuss here the results on the EEC data.} This corpus also inspired the structure of the BEC-Pro, and we borrow from it the person words used in our templates.\n\nThe GAP corpus \\citep{webster2018gap} was developed as a benchmark for measuring gender bias in coreference resolution systems. It contains 8,908 ambiguous pronoun-name pairs in 4,454 contexts sampled from Wikipedia. An example sentence can be found in Figure~\\ref{fig:gap_example_sent}.\n\n\\begin{figure}\n\\footnotesize\nThe historical Octavia Minor's first husband was Gaius Claudius Marcellus Minor, and she bore him three children, Marcellus, Claudia Marcella Major and [Claudia Marcella Minor]; the [\\underline{Octavia}] in Rome is married to a nobleman named Glabius, with whom [\\underline{she}] has no children.\n    \\caption{GAP example sentence}\n    \\label{fig:gap_example_sent}\n\\end{figure}\nWe use this corpus to fine-tune BERT (Section~\\ref{sec:fine-tuning}).\n\n\n\\subsection{BEC-Pro}\\label{ssec:becpro}\nIn order to measure bias in BERT, we created a template-based corpus in two languages, English and German. The sentence templates contain a gender-denoting noun phrase, or \\textless{}person word\\textgreater{}, as well as a \\textless{}profession\\textgreater{}. \n\nWe obtained 2019 data on gender and race participation for a detailed list of professions from the U.S. \\citet{labor_statistics}\\footnote{\\url{https://www.bls.gov/cps/cpsaat11.htm}}. This overview shows, among others, the percentage of female employees for professions with more than 50,000 employed across the United States.\nFrom the lowest-level subgroup profession terms, we selected three groups of 20 professions each: those with highest female participation (88.3\\%-98.7\\%), those with lowest female participation (0.7\\%-3.3\\%), and those with a roughly 50-50 distribution of male and female employees (48.5\\%-53.3\\%). Profession terms were subsequently shortened to increase the likelihood that they would form part of the BERT vocabulary and make them easier to integrate in templates.\n\nFor example, the phrase `Bookkeeping, accounting, and auditing clerks', was shortened to `bookkeeper'. \n\nTo maximize comparability, we translated the shortened English professions into both their masculine and feminine German counterparts, using the online dictionary \\textit{dict.cc}\\footnote{\\url{https://www.dict.cc/}}. Translations were corrected by a native speaker of German. \nFeminine word forms were mostly created using the highly productive suffix \\textit{-in}.\nWe note that feminine forms can have a low frequency, which can influence the probability assigned by the language model.\nThe full list of German professions alongside their English original and shortened counterparts can be found in Table \\ref{A:tab:full_professions} in the Appendix.\n%1 of Supplementary Materials.\n\nFollowing the template-based approach in the EEC \\citep{kiritchenko2018EEC}, we created five sentence templates that include a person word, i.e. a noun phrase that describes a person and carries explicit gender information, and a profession term. These templates are shown in Table~\\ref{tab:sentence_patterns}. The sentences were first constructed in English and then translated to German. Person words were taken from the EEC and translated into German.\\footnote{The phrases `this girl/this boy' were excluded, because they denote children and are therefore less likely to appear in sentences that refer to a professional context. Even though the word `girl' is often used to refer to grown women, this does not apply to the word `boy' to a similar extent.}\n\n\n\\begin{table*}[!ht]\n\\footnotesize\n\\centering\n\\resizebox{\\textwidth}{!}{%\n\\begin{tabular}{p{.06cm}ll}\n\\hline\n& %{\\textbf{no.}} &\n\\multicolumn{1}{c}{\\textbf{English}} &\n\\multicolumn{1}{c}{\\textbf{German}} \\\\ \\hline\n\\textbf{1} &\n  \\textless{}person\\textgreater is a \\textless{}profession\\textgreater{}. &\n  \\textless{}person\\textgreater ist \\textless{}profession\\textgreater{}. \\\\\n\\textbf{2} &\n  \\textless{}person\\textgreater{} works as a \\textless{}profession\\textgreater{}. &\n  \\textless{}person\\textgreater arbeitet als \\textless{}profession\\textgreater{}. \\\\\n\\textbf{3} &\n  \\textless{}person\\textgreater applied for the position of \\textless{}profession\\textgreater{}. & \\textless{}person\\textgreater hat sich auf die Stelle als \\textless{}profession\\textgreater beworben. \\\\\n\\textbf{4} &\n  \\textless{}person\\textgreater{}, the \\textless{}profession\\textgreater{}, had a good day at work. &\n  \\textless{}person\\textgreater{}, die/der \\textless{}profession\\textgreater{}, hatte einen guten Arbeitstag.\\\\\n\\textbf{5} &\n  \\textless{}person\\textgreater wants to become a \\textless{}profession\\textgreater{}. &\n  \\textless{}person\\textgreater will \\textless{}profession\\textgreater werden. \\\\ \\hline\n\\end{tabular}}\n\\caption{Sentence patterns for English and German}\\label{tab:sentence_patterns}\n\\end{table*}\n\nFor example, in English, template 4 in Table \\ref{tab:sentence_patterns} could generate the sentence `[My mother], \\underline{the} [firefighter], had a good day at work.' The same German template would then generate the sentence \\textit{[Meine Mutter], \\underline{die} [Feuerwehrfrau], hatte einen guten Arbeitstag.} \n\n\nFor each language, this led to a combined number of 5,400 sentences (5 sentence templates $\\times$ 18 person words $\\times$ 20 professions $\\times$ 3 profession groups).\n\n%===========================================================\n\n\\section{Method}\\label{sec:method}\n\n\\subsection{Technical Specifications and Models}\\label{ssec:preprocessing}\n\nWe use the Huggingface \\texttt{transformers} library \\citep{Wolf2019HuggingFacesTS} for \\texttt{PyTorch} with a default random seed of 42 for all experiments \\citep{adams2017ultimate}.\n\nThe model used for bias evaluation and fine-tuning is a pre-trained BERT\\textsubscript{BASE} model \\citep{devlin2018bert} with a language modelling head on top. For reasons of simplicity, this model will be referred to as \\textit{BERT language model} from here on. \n\nFor English, the tokenizer and model are loaded with the standard pre-trained uncased BERT\\textsubscript{BASE} model.\nUnlike in English, where capitalization for nouns is only relevant for proper names (which we do not use), in German capitalization is an integral part of the orthography \\citep{stocker2012grammar}. For German we use the cased model provided by DBMDZ.\\footnote{\\url{https://github.com/dbmdz/berts}}\n\n\n\\subsection{Masking for Bias Evaluation}\nThe method for measuring bias used in this work is based on the prediction of masked tokens and moreover relies on masking tokens to create potentially neutral settings to be used as prior. In all our experimental settings, \\textit{targets} are person words, and \\textit{attributes} are professions.\n\nWe apply masking to a sentence in three stages, illustrated in Table~\\ref{tab:masking}, and add the different masked versions to the BEC-Pro.\nNote that only target words (not determiners) are masked. If an attribute contains more than one token, all tokens of the respective phrase are masked individually.\n\n\\begin{table}[h]\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tabular}{ll}\n\\hline\n\\textbf{original}         & My son is a medical records technician.        \\\\\n\\textbf{T masked}    & My \\texttt{[MASK]} is a medical records technician. \\\\\n\\textbf{A masked} & My son is a \\texttt{[MASK]} \\texttt{[MASK]} \\texttt{[MASK]}.  \\\\\n\\textbf{T+A masked} & My \\texttt{[MASK]} is a \\texttt{[MASK]} \\texttt{[MASK]} \\texttt{[MASK]}. \\\\ \\hline\n\\end{tabular}%\n}\n\\caption{Masking example}\n\\label{tab:masking}\n\\end{table}\n\n\\subsection{Pre-processing}\\label{sec:input_processing}\nThe inputs for both measuring and mitigating gender bias largely go through the same pre-processing steps. For GAP corpus instances, which can contain several sentences, we precede these steps by splitting instances into sentences.\n\nAs a first step, the fixed input sequence length is determined as the smallest power of two greater than or equal to the maximum sequence length.\nIn a second step, the inputs are tokenized by the pre-trained \\texttt{BertTokenizer} and padded to the previously determined fixed sequence length.\nFrom the padded and encoded inputs, attention masks are created. \nAttention mask tensors have the same size as the input tensors. For each index of the input tensor, non-pad tokens are marked with a \\texttt{1} and pad tokens with a \\texttt{0} in the attention mask tensor.\n\n\\subsection{Measuring Association Bias}\\label{ssec:measure_bias}\n\nFollowing \\citet{kurita2019measuring}, who take inspiration from the WEAT \\citep{caliskan2017semantics}, we measure the influence of the attribute (A), which can be a profession or emotion, on the likelihood of the target (T), which denotes a male or female person: $P(T|A)$.\nIt is assumed that in the BERT language model, the likelihood of a token is influenced by all other tokens in the sentence. Thus, we assume that the target likelihood is different depending on whether or not an attribute is present: $P(T) \\neq P(T|A)$.\nMoreover, we assume that the likelihoods of male- and female-denoting targets are influenced differently by the same attribute word: $P(T_{female} | A) \\neq P(T_{male} | A)$.\n\nFollowing \\citet{kurita2019measuring}, we will go on to call the probability of a target word in connection with an attribute word the \\textit{association} of the target with the attribute. \n\nThe sentence templates from the BEC-Pro (Section~\\ref{ssec:becpro}), are used to measure the association of target and attribute in a sentence. For measuring the association, we need to obtain the likelihood of the masked target from the BERT language model in two different settings: with the attribute masked (prior probability) and not masked (target probability). \nThe prior and target probabilities are obtained by applying the softmax function to the logits that were predicted by the BERT language model for the position of the target in the sentence. This produces a probability distribution over the BERT vocabulary for that position in the sentence. We then obtain the (prior) probability of the respective target word by using its vocabulary index. \nThe steps to calculate the association are shown in Figure~\\ref{fig:logprobsteps}.\n\n\\begin{figure}[t]\n\\footnotesize\n\\begin{enumerate}[leftmargin=.5cm]\n    \\item Take a sentence with a target and attribute word\\\\\n    \\textit{``He is a kindergarten teacher.''}\n    \\item Mask the target word\\\\\n    \\textit{``[MASK] is a kindergarten teacher.''}\n    \\item Obtain the probability of target word in the sentence\\\\\n    $p_{T} = P(he = [MASK] | sent)$\n    \\item Mask both target and attribute word. In compounds, mask each component separately. \\\\\n    \\textit{``[MASK] is a [MASK] [MASK].''}\n    \\item Obtain the prior probability, i.e. the probability of the target word when the attribute is masked\\\\\n    $p_{prior} = P(he = [MASK] | masked\\_sent)$\n    \\item Calculate the association by dividing the target probability by the prior and take the natural logarithm\\\\\n    $\\log \\frac{p_{T}}{p_{prior}}$\n\\end{enumerate}\n\\caption{Procedure to calculate the log probability score, after \\citet{kurita2019measuring}.}\\label{fig:logprobsteps}\n\\end{figure}\n\nFor interpretation, a negative association between a target and an attribute means that the probability of the target is lower than the prior probability, i.e. the probability of the target \\textit{decreased} through the combination with the attribute. A positive association value means that the probability of the target \\textit{increased} through the combination with the attribute, with respect to the prior probability. \nOur hypotheses are summarized in Table~\\ref{tab:hypotheses}.\n\n\\begin{table*}[]\n\\centering\n\\resizebox{\\textwidth}{!}{%\n\\begin{tabular}{lll}\n\\hline\n\\multicolumn{1}{c}{\\textbf{id}} &\n  \\multicolumn{1}{c}{\\textbf{hypothesis}} &\n  \\multicolumn{1}{c}{\\textbf{expected observation}} \\\\ \\hline\n\\textbf{H1} &\n  \\begin{tabular}[c]{@{}l@{}}There is a strong association of female (male) \\\\ person-denoting noun phrases (NPs) with \\\\ statistically female (male) professions, which \\\\ is reduced through fine-tuning.\\end{tabular} &\n  \\begin{tabular}[c]{@{}l@{}}Positive association scores between female (male) \\\\ NPs and statistically female (male) professions,\\\\ which decrease after fine-tuning.\\end{tabular} \\\\ \\hline\n\\textbf{H2} &\n  \\begin{tabular}[c]{@{}l@{}}There is a weak association of female (male) NPs \\\\ with statistically male (female) professions, which \\\\ is strengthened through fine-tuning.\\end{tabular} &\n  \\begin{tabular}[c]{@{}l@{}}Negative association scores between female (male) \\\\ NPs and statistically male (female) professions, \\\\ which increase after fine-tuning.\\end{tabular} \\\\ \\hline\n\\textbf{H3} &\n  \\begin{tabular}[c]{@{}l@{}}There is no difference between the associations \\\\ of female and male person-denoting NPs with \\\\ statistically gender-balanced professions. \\\\ Associations do not change much after fine-tuning.\\end{tabular} &\n  \\begin{tabular}[c]{@{}l@{}}Both association scores of female and male NPs \\\\ have approx. the same value, which is likely located \\\\ around zero. After fine-tuning, the association score \\\\ does not deviate much from its original value.\\end{tabular} \\\\ \\hline\n\\end{tabular}%\n}\n\\caption{Hypotheses on associations between targets (person words) and attributes (professions) in the BEC-Pro}\n\\label{tab:hypotheses}\n\\end{table*}\n\n\n\\subsection{Bias Mitigation}\\label{ssec:bias_mitigation}\n\nIt has been shown that one of the more effective strategies for removing bias in traditional word embeddings involves modifying the training data instead of trying to change the resulting vector representation \\citep{gonen2019lipstick}. One such strategy is a derivative of CDA \\citep{lu2018CDA}, Name-based Counterfactual Data Substitution (CDS) \\citep{maudslay2019CDS} in which the gender of words denoting persons in a training corpus is swapped in place in order to counterbalance bias. First names are exchanged as well.\n\nTo apply CDS in the context of English BERT, we use \\citeauthor{maudslay2019CDS}'s \\citeyearpar{maudslay2019CDS} code for applying CDS to the GAP corpus \\citep{webster2018gap}. Subsequently, these gender-swapped data are used for fine-tuning the English BERT language model. \nTable \\ref{tab:hypotheses} illustrates how we expect fine-tuning to influence associations in the English BERT language model. Since GAP instances are balanced between male and female genders, we expect this balance to be preserved after CDS, which would in turn influence male and female entities in the English BERT model to the same extent during fine-tuning. \n\n\\subsection{Fine-tuning}\n\\label{sec:fine-tuning}\n\nFor fine-tuning, each instance in the gender-swapped GAP corpus is tokenized into sentences. Subsequently, the sentences are pre-processed and attention masks are created.\nFor training, the inputs need to undergo a masking procedure in order to be compatible with BERT's MLM. We follow the standard procedure for masking the inputs, as outlined by \\citet{devlin2018bert}.\nThe masking is carried out using the \\texttt{mask\\_tokens} function from code by \\citet{dontstoppretraining2020}.\\footnote{\\url{https://github.com/allenai/dont-stop-pretraining/blob/master/scripts/mlm_study.py}} The unchanged input sentences then function as labels.\n\nFor training, the instances are randomly sampled and a batch size of one is used. The model is trained for three epochs using an AdamW optimizer with a learning rate of $5 \\times 10^{-5}$ and a linear scheduler with warm-up. The fine-tuned model is subsequently used to carry out the exact same bias evaluation as outlined in Section \\ref{ssec:measure_bias}.\n\n\n%===========================================================\n\n\\section{Results}\\label{sec:results}\n\nTable~\\ref{tab:results_EN} displays the mean association scores between targets (person words) and attributes (professions) before and after fine-tuning the English BERT language model on the GAP corpus, to which CDS was applied (\\textit{pre-association} vs. \\textit{post-association}). \nThe difference between these two association scores is used to perform the statistical analysis using the Wilcoxon signed-rank test ($W$) for all three profession groups individually.\nThe effect size $r$ is calculated following \\citet{rosenthal1991applied} and \\citet{field2012statistics}.\nA positive difference score means that the association has increased after fine-tuning, a negative value indicates a decrease in association after fine-tuning. \n\n\\subsection{Overall results}\n\\begin{table}[h]\n\\centering\n\\renewcommand\\arraystretch{1.1}\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tabular}{ccrrrrc}\n\\hline\n\\textbf{} &\n  \\textbf{} &\n%   \\textbf{} &\n  \\textbf{pre} &\n  \\textbf{post} &\n  \\textbf{diff.} &\n  \\multicolumn{2}{c}{\\textbf{Wilcoxon test}} \\\\ \\hline\n\\textbf{jobs} &\n  \\textbf{person} &\n%   \\textit{N} &\n  \\textit{mean} &\n  \\textit{mean} &\n  \\textit{mean} &\n%   \\textit{p} &\n  \\textit{W} &\n  \\textit{r} \\\\ \\hline\n\\multirow{2}{*}{\\textbf{B}} &\n  f &\n%   900 &\n  -0.35 &\n  0.20 &\n  0.55 &\n%   \\multirow{2}{*}{2e-16} &\n  \\multirow{2}{*}{359188} &\n  \\multirow{2}{*}{-0.47} \\\\\n &\n  m &\n%   900 &\n  0.05 &\n  0.07 &\n  0.01 &\n   &\n   \\\\ \\hline\n\\multirow{2}{*}{\\textbf{F}} &\n  f &\n%   900 &\n  0.50 &\n  0.36 &\n  -0.14 &\n%   \\multirow{2}{*}{2e-16} &\n  \\multirow{2}{*}{96428} &\n  \\multirow{2}{*}{-0.32} \\\\\n &\n  m &\n%   900 &\n  -0.68 &\n  -0.14 &\n  0.55 &\n   &\n   \\\\ \\hline\n\\multirow{2}{*}{\\textbf{M}} &\n  f &\n%   900 &\n  -0.83 &\n  0.13 &\n  0.96 &\n%   \\multirow{2}{*}{2e-16} &\n  \\multirow{2}{*}{395974} &\n  \\multirow{2}{*}{-0.58} \\\\\n &\n  m &\n%   900 &\n  0.16 &\n  0.21 &\n  0.05 &\n   &\n   \\\\ \\hline\n\\end{tabular}%\n}\n\\caption{Results for English association scores before (pre) and after fine-tuning (post). For jobs, B=balanced, F=female, M=male. In each row, N=900. All $W$ tests are significant at $p=$2e-16.}\n\\label{tab:results_EN}\n\\end{table}\n\nSimilar to research by \\citet{rudinger2018biascoref}, Table \\ref{tab:results_EN} contains pro- and anti-typical settings, which correspond to hypotheses H1 and H2, formulated in Table \\ref{tab:hypotheses}. \nIn the pro-typical setting (H1), male (female) person words are paired with statistically male (female) profession terms. \nConversely, in the anti-typical setting (H2), male (female) person words are paired with statistically female (male) profession terms. \nTable \\ref{tab:results_EN} shows that in fact, there are positive pre-association values in both pro-typical settings and negative pre-association values in both anti-typical settings, which confirms hypotheses H1 and H2. In other words, bias in BERT corresponds to real-world workforce statistics. \n\n\nFor the balanced professions, we expected that association values would not change much as a result of fine-tuning (H3).\nThis hypothesis could only be confirmed for the male person words, while the female person words show a negative pre-association (-0.35) that changes to a positive post-association (0.20). This shows that male person words hold a neutral position with respect to gender-balanced professions. For female person terms, however, the negative pre-association shows that the gender-parity in the real world data is not reflected in the English BERT language model. \n\nIn general, male person words are relatively stable in BERT.\nAssociations for these are less strong, i.e. less affected by the presence of the profession words, and also less affected by fine-tuning. These results correspond to \\citeauthor{kurita2019measuring}'s \\citeyearpar{kurita2019measuring} finding of strong male bias in BERT. \nFurther support for this can be found in the results for the balanced profession group, which show similar behavior to those for the male group, though with lower absolute values. This suggests that workers in non-stereotypical professions are more likely to be talked about with male person terms.\n\nIn contrast, female person words have higher positive scores in pro-typical settings and lower negative scores in anti-typical settings, which are more susceptible to change after fine-tuning, resulting in positive scores for all professions after fine-tuning. \nOn one hand, the more extreme association scores of female terms, as compared to male terms, illustrate them as more marked in language; on the other hand, it shows that the representations of female person words can be more easily adapted. \n\n\n\\subsection{Profession results -- English}\n\nThis section zooms in on each individual profession group. \nThe results for all profession groups are presented as two bar graphs, the upper graph showing the pre-associations and the lower showing the post-associations. The individual professions are ordered in descending order by the absolute difference in association before and after fine-tuning. \n\n\\paragraph{Male Professions}\nFigure \\ref{fig:male_assoc_EN} shows the associations before and after fine-tuning for professions with predominantly male workers. It can be seen that there are nearly only negative associations before fine-tuning for female person words with these professions. After fine-tuning, the associations for female person words increase and almost all professions show a positive association with female person words.\nThe male person words have small positive associations which do not change drastically after fine-tuning, in contrast to female profession terms.\nGenerally, fine-tuning brings the association values of male and female person words closer, which indicates mitigation of gender bias. The exception to this trend is the word \\textit{taper}, whose behaviour can be attributed to the ambiguity of the term, whose more common sense is `narrowing towards a point', rather than the profession.\n\n\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{images/pre_post_assoc_male.png}\n    \\caption{Pre- and post-associations of female and male person words with statistically male professions}\n    \\label{fig:male_assoc_EN}\n\\end{figure*}\n\n\n\\paragraph{Female Professions}\n\n\\begin{figure*}[h]\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{images/pre_post_assoc_female.png}\n    \\caption{Pre- and post-associations of female and male person words with statistically female professions}\n    \\label{fig:female_assoc_EN}\n\\end{figure*}\n\nThe results for the statistically female professions are summarized in Figure \\ref{fig:female_assoc_EN}. Before fine-tuning, Figure \\ref{fig:female_assoc_EN} depicts very strong association values for more stereotypical professions, such as \\textit{housekeeper}, \\textit{nurse}, \\textit{receptionist} or \\textit{secretary}. For male person words, these associations are highly negative before fine-tuning and remain negative after. This could be due to the fact that the values were more extreme to begin with. Female person words show positive associations that are less extreme and have a narrower range after fine-tuning.\nIn contrast, on the far right-hand side of Figure \\ref{fig:female_assoc_EN}  (\\textit{paralegal}, \\textit{speech-language pathologist}, \\textit{billing clerk}, \\textit{dental hygienist}),  the associations are very low for both female and make person terms, suggesting they are more gender-neutral in English BERT.\nOverall, Figure \\ref{fig:female_assoc_EN} shows that female bias was reduced, but the model still retained a preference for female person words in context with these professions, which corresponds to the real-world statistics. \n \n\n\\paragraph{Balanced Professions}\n\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{images/pre_post_assoc_balanced.png}\n    \\caption{Pre- and post-associations of female and male person words with statistically balanced professions}\n    \\label{fig:balanced_assoc_EN}\n\\end{figure*}\n\nThe results for the statistically balanced professions are displayed in Figure~\\ref{fig:balanced_assoc_EN}. They are especially interesting, because strong male or female biases do not correspond to real-world data and can be ascribed to language use in BERT's training data. \n\nFigure~\\ref{fig:balanced_assoc_EN} shows that the general trend for the associations of female person words with balanced professions before fine-tuning follows the results for statistically male professions: there are mostly negative pre-associations for female person words, which exposes bias in the English BERT language model. These associations mostly become positive after fine-tuning.\n\nFor male person words, the results show both negative and positive pre-associations. Professions with negative pre-associations for male person words are generally very specific (such as \\textit{electrical assembler} or \\textit{director of religious activities}), therefore, the negative associations may be due to low frequency of these terms.\nProfessions with a positive pre-association for male person words are e.g. \\textit{crossing guard}, \\textit{medical scientist}, or \\textit{lifeguard}. These are more common, therefore, the positive association values reveal male-favoring bias in BERT for the professions in question. Figure~\\ref{fig:balanced_assoc_EN} shows converging levels of association after fine-tuning, illustrating the method's effectiveness in mitigating gender bias. \n\n\n\\subsection{Profession Results -- German}\\label{ssec:results_german}\n\nDue to the ineffectiveness of the method for German, we only report on pre- and not on post-associations in Table \\ref{tab:results_DE}. In order to statistically test the difference between associations for male and female person words, the Wilcoxon signed-rank test was again computed for each profession group separately. \n\nTable \\ref{tab:results_DE} shows that the results across all three profession groups are highly similar: the mean associations for female person words have a value of around 2.1, and the values for male person words are around 1.4. This difference between the groups of person words is significant in all three profession groups with a medium effect size. Nevertheless, the fact that all three groups follow the same pattern indicates that the associations do not capture social gender bias. This can also be observed when looking at the pre-associations for the individual professions (We show them in Figure \\ref{A:fig:assoc_DE} in the Appendix).\n%Figure~1 of the Supplementary Materials). \n\n\\begin{table}[]\n\\centering\n\\resizebox{\\columnwidth}{!}{%\n\\begin{tabular}{ccccccc}\n\\hline\n\\textbf{}            & \\textbf{}       & \\multicolumn{2}{c}{\\textbf{pre association}} & \\multicolumn{3}{c}{\\textbf{Wilcoxon}} \\\\ \\hline\n\\textbf{jobs} & \\textbf{person}  & \\textit{mean}          & \\textit{sd}         & \\textit{p}  & \\textit{W} & \\textit{r} \\\\ \\hline\n\\multirow{2}{*}{\\textbf{B}} & f  & 2.14 & 2.4  & \\multirow{2}{*}{2e-16} & \\multirow{2}{*}{315,058} & \\multirow{2}{*}{-0.34} \\\\\n                     & m                  & 1.36                   & 2.06                &             &            &            \\\\ \\hline\n\\multirow{2}{*}{\\textbf{F}}   & f  & 2.05 & 2.45 & \\multirow{2}{*}{2e-16} & \\multirow{2}{*}{304,635} & \\multirow{2}{*}{-0.31} \\\\\n                     & m                    & 1.34                   & 2.09                &             &            &            \\\\ \\hline\n\\multirow{2}{*}{\\textbf{M}}     & f  & 2.14 & 2.46 & \\multirow{2}{*}{2e-16} & \\multirow{2}{*}{297,605} & \\multirow{2}{*}{-0.29} \\\\\n                     & m                    & 1.46                   & 2.15                &             &            &            \\\\ \\hline\n\\end{tabular}%\n}\n\\caption{Results and statistical evaluation for German associations across professions and person words. For jobs, B=balanced, F=female, M=male. The number of instances for each row is 900.}\n\\label{tab:results_DE}\n\\end{table}\n\nThe common pattern points to the main difference between the German and English profession terms: German terms are divided into masculine and feminine forms (Section~\\ref{ssec:becpro}), because they agree with the grammatical gender of the corresponding person word. We believe that this grammatical difference generates similar association values across the three profession groups.\n\nSpecifically, the gender marker of the attribute (profession) influences the likelihood of the target (person word). The fact that the associations for female person words are consistently higher corresponds to the marking of the feminine noun form, e.g. with the suffix \\textit{-in}, which is attached to the unmarked masculine form. However, even though it is the unmarked word form, the masculine profession term also carries grammatical gender information, which we assume causes high positive associations across all profession groups. \n\n\n%===========================================================\n\n\\section{Discussion and Conclusions}\\label{sec:discussion}\n\n\nThe goal of this work is to measure and mitigate gender bias in English and German BERT models \\citep{devlin2018bert}.\n\n% measuring\nFor measuring gender bias, we use a method first proposed by \\citet{kurita2019measuring}: word probabilities taken from the BERT language model are used to calculate association bias between a gender-denoting target word and an attribute word, such as a profession. Our success in making gender bias in the English BERT model visible supports the establishment of the method as a unified metric. \nMoreover, we create the BEC-Pro (Bias Evaluation Corpus with Professions), a template-based corpus set in a professional context, which includes professions from three different statistical groups as well as several male and female person words. With this corpus, which we make available to the community, we contribute to streamlining the visualization of gender bias in other contextualized word embedding models.\n\n% mitigating\nFor mitigating gender bias, we first apply CDS \\citep{maudslay2019CDS} to the GAP corpus \\citep{webster2018gap} and then fine-tune the English BERT language model on this corpus. We confirm \\citeauthor{zhao2019gender}'s \\citeyearpar{zhao2019gender} finding that CDA, or CDS in this case, is useful for mitigating gender bias in the English BERT model. \n\nUsing professions based on workforce statistics allows for a comparison of bias in the BERT language model with real-world data.\nWe find that the English BERT language model reflects the real-world bias of the male- and female-typical profession groups through positive pro-typical associations and negative anti-typical associations before fine-tuning. After fine-tuning, we observe a reduction in association only for female person words and female-typical professions, but there is an increase in association in both anti-typical settings. This lends support to the effectiveness of our bias mitigation method.\n\n% female group\nHowever, we also observe that female person words have higher absolute pre-association values in both the pro- and anti-typical settings, and also show greater changes in post-association.\n\nOne possible reason could be BERT's male bias, which has been previously investigated by \\citet{kurita2019measuring}. Male person terms seem to have a more stable position in BERT, which could cause their probabilities in the model to not vary much depending on the context and make them less susceptible to change through fine-tuning. \nAnother explanation for female terms being more affected by fine-tuning could be that the GAP corpus contained somewhat more female pronouns and nouns, but especially first names, after CDS. Fine-tuning on a corpus with a slight surplus of female person words and first names could have made the likelihood of these terms more sensitive to change. \n\n% balanced group\nIn the balanced profession group before fine-tuning, we observe that the BERT language model does not only encode biases that reflect real-world data, but also those that are based on stereotypes.\nDespite the fact that all of the balanced professions have an approximately even distribution of male and female employees in the U.S. \\citep{labor_statistics}, there is a significantly lower, negative association for female person words before fine-tuning. This signifies that women's visibility in these professions is inhibited, i.e. that women are seen as less likely to carry out such a profession.\nIn general, the associations in the balanced profession group behave similarly to those in the male-typical profession group. Thus, unless a profession is typically carried out by women, such as the professions \\textit{kindergarten teacher} or \\textit{nurse}, the default `worker' is culturally seen as male.\n\n% German\nOur results moreover show that a method that works well for English is not necessarily transferable to other languages. Since German is a gender-marking language, the agreement between the grammatical gender of the person word and the profession influences the associations. Still, the consistently higher associations of female person words compared to male person words illustrate the linguistic markedness of feminine word forms, as opposed to the default masculine forms, in German. \n\nFurthermore, the fact that English and German both belong to the Germanic language family \\citep{wals} highlights that (genetic) linguistic relatedness does not predict the cross-linguistic success of a method. Especially for a relatively new model such as BERT, developing language-specific methods to assess its limitations is crucial to prevent bias propagation to downstream applications in the language concerned. Our lack of success in transferring the method to German emphasizes the need for more typological variety in NLP research as well as language-specific solutions \\citep{sun2019litreview, hovy2016social}. \n\n\n% limitations\nNaturally, there are a number of limitations of this work. We specifically focus on two, here.\nFirstly, we work with only one very specific English BERT model, namely the uncased BERT\\textsubscript{BASE}. There are many more contextualized word embedding models besides BERT, such as GPT-2 \\citep{radford2019language} or ELMo \\citep{elmo_main_paper}. Moreover, there have been various developments and enhancements of the initial BERT model, such as DistilBERT \\citep{sanh2019distilbert}, ALBERT \\citep{lan2019albert}, or RoBERTa \\citep{liu2019roberta}. Therefore, future work could focus on gender bias in a variety of models and investigate whether there are common patterns.\n\nSecondly, the present work extensively relies on choices made by the researchers, due to the template-based method of measuring bias. On one hand, the method is dependent on curated lists of person words and profession terms, which already introduce human bias \\citep{sun2019litreview}. We tried to partially counteract this bias by basing the choice of professions on recent labor statistics.\nOn the other hand, the words in the templates themselves influence the target likelihood, because word representations in BERT are dependent on the entire sentence context \\citep{devlin2018bert}. Therefore, future research could include a broader variety of sentences, which could also be randomly sampled.\n\n\n\\clearpage\n\\section*{Acknowledgments}\nThis work is based on the first author's master thesis, which was conducted under the ERASMUS Mundus Program Language and Communication Technologies (EMLCT). \nWe would like to thank the Center for Information Technology of the University of Groningen for providing access to the Peregrine high performance computing cluster.\n\n\\bibliography{anthology,acl2020,extra}\n\\bibliographystyle{acl_natbib}\n\n%\\clearpage\n\n\\vspace*{1cm}\n\n\\hrule\n\n\\vspace*{1cm}\n\n\n\\appendix\n\n\n\\section*{Appendix}\n\\label{sec:appendix}\n\nThis appendix contains the detailed list of all professions used in this paper in Table \\ref{A:tab:full_professions}. The professions were chosen from a list of professions provided by the U.S. \\citet{labor_statistics} based on the percentage of women employed, shortened and subsequently translated into German masculine and feminine forms. Table \\ref{A:tab:full_professions} is referred in Section~\\ref{ssec:becpro}, where we describe how our template-based BEC-Pro was created.\n\nAdditionally, we provide an illustration of the associations for the German individual professions of the three profession groups in Figure~\\ref{A:fig:assoc_DE}. Figure~\\ref{A:fig:assoc_DE} is referred in Section~\\ref{ssec:results_german} when discussing that the associations do not capture gender bias for the German model due to grammatical agreement. \n\n\\begin{table*}[p]\n\\centering\n\\renewcommand\\arraystretch{1.1}\n\\resizebox{\\textwidth}{!}{%\n\\begin{tabular}{llrl}\n\\hline\n\\multicolumn{1}{c}{\\textbf{original profession}} &\n  \\multicolumn{1}{c}{\\textbf{shortened profession}} &\n  \\textbf{\\begin{tabular}[c]{@{}c@{}}\\% \\\\ women\\end{tabular}} &\n  \\multicolumn{1}{c}{\\textbf{\\begin{tabular}[c]{@{}c@{}}German profession\\\\ (masc./fem.)\\end{tabular}}} \\\\ \\hline\nPreschool and kindergarten teachers &\n  kindergarten teacher &\n  98.7 &\n  Kinderg\u00e4rtner/Kinderg\u00e4rtnerin \\\\\nDental hygienists &\n  dental hygienist &\n  96.0 &\n  Dentalhygieniker/Dentalhygienikerin \\\\\nSpeech-language pathologists &\n  speech-language pathologist &\n  95.8 &\n  Logop\u00e4de/Logop\u00e4din \\\\\nDental assistants &\n  dental assistant &\n  94.9 &\n  Zahnarzthelfer/Zahnarzthelferin \\\\\nChildcare workers &\n  childcare worker &\n  93.4 &\n  Kinderbetreuer/Kinderbetreuerin \\\\\nMedical records and health information technicians &\n  medical records technician &\n  93.3 &\n  Medizintechniker/Medizintechnikerin \\\\\nSecretaries and administrative assistants &\n  secretary &\n  93.2 &\n  Sekret\u00e4r/Sekret\u00e4rin \\\\\nMedical assistants &\n  medical assistant &\n  92.7 &\n  Arzthelfer/Arzthelferin \\\\\nHairdressers, hairstylists, and cosmetologists &\n  hairdresser &\n  92.3 &\n  Friseur/Friseurin \\\\\nDietitians and nutritionists &\n  dietitian &\n  92.1 &\n  Ern\u00e4hrungsberater/Ern\u00e4hrungsberaterin \\\\\nLicensed practical and licensed vocational nurses &\n  vocational nurse &\n  90.8 &\n  Berufskrankenpfleger/Berufskrankenpflegerin \\\\\nTeacher assistants &\n  teacher assistant &\n  89.7 &\n  Betreuungslehrer/Betreuungslehrerin \\\\\nParalegals and legal assistants &\n  paralegal &\n  89.6 &\n  Rechtsanwaltsgehilfe/Rechtsanwaltsgehilfin \\\\\nBilling and posting clerks &\n  billing clerk &\n  89.5 &\n  Fakturist/Fakturistin \\\\\nPhlebotomists &\n  phlebotomist &\n  89.3 &\n  Phlebologe/Phlebologin \\\\\nReceptionists and information clerks &\n  receptionist &\n  89.3 &\n  Rezeptionist/Rezeptionist \\\\\nMaids and housekeeping cleaners &\n  housekeeper &\n  89.0 &\n  Haush\u00e4lter/Haush\u00e4lterin \\\\\nRegistered nurses &\n  registered nurse &\n  88.9 &\n  \\begin{tabular}[c]{@{}l@{}}staatlich gepr\u00fcfter Krankenpfleger/\\\\ staatlich gepr\u00fcfte Krankenpflegerin\\end{tabular} \\\\\nBookkeeping, accounting, and auditing clerks &\n  bookkeeper &\n  88.5 &\n  Buchhalter/Buchhalterin \\\\\nNursing, psychiatric, and home health aides &\n  health aide &\n  88.3 &\n  Gesundheitsberater/Gesundheitsberaterin \\\\ \\hline\nDrywall installers, ceiling tile installers, and tapers &\n  taper &\n  0.7 &\n  Trockenbaumonteur/Trockenbaumonteurin \\\\\nStructural iron and steel workers &\n  steel worker &\n  0.9 &\n  Stahlarbeiter/Stahlarbeiterin \\\\\n\\begin{tabular}[c]{@{}l@{}}Miscellaneous vehicle and mobile equipment \\\\ mechanics, installers, and repairers\\end{tabular} &\n  mobile equipment mechanic &\n  1.3 &\n  \\begin{tabular}[c]{@{}l@{}}Mechaniker f\u00fcr mobile Ger\u00e4te/\\\\ Mechanikerin f\u00fcr mobile Ger\u00e4te\\end{tabular} \\\\\nBus and truck mechanics and diesel engine specialists &\n  bus mechanic &\n  1.5 &\n  Busmechaniker/Busmechanikerin \\\\\n\\begin{tabular}[c]{@{}l@{}}Heavy vehicle and mobile equipment service technicians \\\\ and mechanics + Automotive service technicians and mechanics\\end{tabular} &\n  service technician &\n  1.5 &\n  \\begin{tabular}[c]{@{}l@{}}Kfz-Servicetechniker/\\\\ Kfz-Servicetechnikerin\\end{tabular} \\\\\n\\begin{tabular}[c]{@{}l@{}}Heating, air conditioning, and \\\\ refrigeration mechanics and installers\\end{tabular} &\n  heating mechanic &\n  1.5 &\n  \\begin{tabular}[c]{@{}l@{}}Heizungsmechaniker/\\\\ Heizungsmechanikerin\\end{tabular} \\\\\nElectrical power-line installers and repairers &\n  electrical installer &\n  1.6 &\n  Elektroinstallateur/Elektroinstallateurin \\\\\nOperating engineers and other construction equipment operators &\n  operating engineer &\n  1.7 &\n  Betriebsingenieur/Betriebsingenieurin \\\\\nLogging workers &\n  logging worker &\n  1.8 &\n  Holzf\u00e4ller/Holzf\u00e4llerin \\\\\nCarpet, floor, and tile installers and finishers &\n  floor installer &\n  1.9 &\n  Bodenleger/Bodenlegerin \\\\\nRoofers &\n  roofer &\n  1.9 &\n  Dachedecker/Dachdeckerin \\\\\nMining machine operators &\n  mining machine operator &\n  2.0 &\n  \\begin{tabular}[c]{@{}l@{}}Bergbaumaschinentechniker/\\\\ Bergbaumaschinentechnikerin\\end{tabular} \\\\\nElectricians &\n  electrician &\n  2.2 &\n  Elektriker/Elektrikerin \\\\\nAutomotive body and related repairers &\n  repairer &\n  2.2 &\n  Kfz-Mechaniker/Kfz-Mechanikerin \\\\\nRailroad conductors and yardmasters &\n  conductor &\n  2.4 &\n  Schaffner/Schaffnerin \\\\\nPipelayers, plumbers, pipefitters, and steamfitters &\n  plumber &\n  2.7 &\n  Klempner/Klempnerin \\\\\nCarpenters &\n  carpenter &\n  2.8 &\n  Zimmermann/Zimmerin \\\\\nSecurity and fire alarm systems installers &\n  security system installer &\n  2.9 &\n  \\begin{tabular}[c]{@{}l@{}}Installateur von Sicherheitssystemen/\\\\ Installateurin von Sicherheitssystemen\\end{tabular} \\\\\nCement masons, concrete finishers, and terrazzo workers &\n  mason &\n  3.0 &\n  Maurer/Maurerin \\\\\nFirefighters &\n  firefighter &\n  3.3 &\n  Feuerwehrmann/Feuerwehrfrau \\\\ \\hline\nRetail salespersons &\n  salesperson &\n  48.5 &\n  Verk\u00e4ufer/Verk\u00e4uferin \\\\\nDirectors, religious activities and education &\n  director of religious activities &\n  48.6 &\n  \\begin{tabular}[c]{@{}l@{}}Leiter religi\u00f6ser Aktivit\u00e4ten/\\\\ Leiterin religi\u00f6ser Aktivit\u00e4ten\\end{tabular} \\\\\nCrossing guards &\n  crossing guard &\n  48.6 &\n  Verkehrslotse/Verkehrslotsin \\\\\nPhotographers &\n  photographer &\n  49.3 &\n  Fotograf/Fotografin \\\\\n\\begin{tabular}[c]{@{}l@{}}Lifeguards and other recreational, \\\\ \\\\ and all other protective service workers\\end{tabular} &\n  lifeguard &\n  49.4 &\n  Bademeister/Bademeisterin \\\\\nLodging managers &\n  lodging manager &\n  49.5 &\n  Herbergsverwalter/Herbergsverwalterin \\\\\nOther healthcare practitioners and technical occupations &\n  healthcare practitioner &\n  49.5 &\n  Heilpraktiker/Heilpraktikerin \\\\\nAdvertising sales agents &\n  sales agent &\n  49.7 &\n  Vertriebsmitarbeiter/Vertriebsmitarbeiterin \\\\\nMail clerks and mail machine operators, except postal service &\n  mail clerk &\n  49.8 &\n  Postbeamter/Postbeamtin \\\\\nElectrical, electronics, and electromechanical assemblers &\n  electrical assembler &\n  50.4 &\n  Elektro-Monteur/Elektro-Monteurin \\\\\nInsurance sales agents &\n  insurance sales agent &\n  50.6 &\n  Versicherungskaufmann/Versicherungskauffrau \\\\\nInsurance underwriters &\n  insurance underwriter &\n  51.1 &\n  Versicherungsvermittler/Versicherungsvermittlerin \\\\\nMedical scientists &\n  medical scientist &\n  51.8 &\n  \\begin{tabular}[c]{@{}l@{}}medizinischer Wissenschaftler/\\\\ medizinische Wissenschaftlerin\\end{tabular} \\\\\nStatisticians &\n  statistician &\n  52.4 &\n  Statistiker/Statistikerin \\\\\nTraining and development specialists &\n  training specialist &\n  52.5 &\n  Ausbilder/Ausbilderin \\\\\nJudges, magistrates, and other judicial workers &\n  judge &\n  52.5 &\n  Richter/Richterin \\\\\nBartenders &\n  bartender &\n  53.1 &\n  Barkeeper/Barkeeperin \\\\\nDispatchers &\n  dispatcher &\n  53.1 &\n  Fahrdienstleiter/Fahrdienstleiterin \\\\\nOrder clerks &\n  order clerk &\n  53.3 &\n  Auftragssachbearbeiter/Auftragssachbearbeiterin \\\\\n\\begin{tabular}[c]{@{}l@{}}Postal service mail sorters, processors, \\\\ and processing machine operators\\end{tabular} &\n  mail sorter &\n  53.3 &\n  Postsortierer/Postsortiererin \\\\ \\hline\n\\end{tabular}%\n}\n\\caption{Shortening and translation of English profession terms into German masculine and feminine forms}\n\\label{A:tab:full_professions}\n\\end{table*}\n\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[height=0.9\\textheight]{images/german_results.png}\n    \\caption{Mean associations for single professions of balanceed, female and male profession groups for German BERT language model}\n    \\label{A:fig:assoc_DE}\n\\end{figure*}\n\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:00:52", "yymm": "2010", "arxiv_id": "2010.14534", "url": "https://arxiv.org/abs/2010.14534", "source": "arxiv"}}
{"text": "% !TEX TS-program = pdflatex\n% !TEX encoding = UTF-8 Unicode\n\n% This is a simple template for a LaTeX document using the \"article\" class.\n% See \"book\", \"report\", \"letter\" for other types of document.\n\n\\documentclass{article} %doublespace\n\\usepackage{moreverb}\n\n\n\\newcommand\\BibTeX{{\\rmfamily B\\kern-.05em \\textsc{i\\kern-.025em b}\\kern-.08em\nT\\kern-.1667em\\lower.7ex\\hbox{E}\\kern-.125emX}}\n\n%\\articletype{Article Type}%\n%\n%\\received{<day> <Month>, <year>}\n%\\revised{<day> <Month>, <year>}\n%\\accepted{<day> <Month>, <year>}\n\n\\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)\n\n%%% Examples of Article customizations\n% These packages are optional, depending whether you want the features they provide.\n% See the LaTeX Companion or other references for full information.\n\n%%% PAGE DIMENSIONS\n\\usepackage{geometry} % to change the page dimensions\n\\geometry{a4paper} % or letterpaper (US) or a5paper or....\n\\geometry{margin=1in} % for example, change the margins to 2 inches all round\n% \\geometry{landscape} % set up the page for landscape\n%   read geometry.pdf for detailed page layout information\n\n\\usepackage{graphicx} % support the \\includegraphics command and options\n\n\\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent\n\n%%% PACKAGES\n\\usepackage{booktabs} % for much better looking tables\n\\usepackage{array} % for better arrays (eg matrices) in maths\n\\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)\n\\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim\n\\usepackage{subcaption} % make it possible to include more than one captioned figure/table in a single float\n\\usepackage{amsmath, amsthm, amssymb} \n\\usepackage{color}\n\\usepackage{float}\n%\\usepackage{csquotes}\n%\\usepackage{qtree}\n\\usepackage{mathtools}\n\\usepackage{mathrsfs}\n\\usepackage{pgfplots}\n\\usepackage{textcomp}\n\\usepackage{multirow}\n\\usepackage{algorithm, algorithmicx, algpseudocode}\n%\\usepackage{todonotes}\n%\\usepackage[ruled,vlined,linesnumbered]{algorithm2e}\n%\\usepackage{hyperref}\n\\pgfplotsset{compat=1.14}\n% These packages are all incorporated in the memoir class to one degree or another...\n\n%%% HEADERS & FOOTERS\n\\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry\n\\pagestyle{fancy} % options: empty , plain , fancy\n\\renewcommand{\\headrulewidth}{0pt} % customise the layout...\n\\lhead{}\\chead{}\\rhead{}\n\\lfoot{}\\cfoot{\\thepage}\\rfoot{}\n\n%%% SECTION TITLE APPEARANCE\n%\\usepackage{sectsty}\n%\\allsectionsfont{\\normalfont\\mdseries\\upshape} % (See the fntguide.pdf for font help)\n% (This matches ConTeXt defaults)\n\n%%% ToC (table of contents) APPEARANCE\n%\\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC\n%\\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents\n%\\renewcommand{\\cftsecfont}{\\rmfamily\\mdseries\\upshape}\n%\\renewcommand{\\cftsecpagefont}{\\rmfamily\\mdseries\\upshape} % No bold!\n\n%%% END Article customizations\n\n%%% The \"real\" document content comes below...\n\\title{\\bfseries Classification and image processing with a semi-discrete scheme for fidelity forced Allen--Cahn on graphs}\n%\\author{Jeremy Budd, Yves van Gennip, Jonas Latz}\n\\author{Jeremy Budd$^1$, Yves van Gennip$^2$, Jonas Latz$^3$\\\\\n\\\\\n\\small{$^{1,2}$Delft Institute of Applied Mathematics (DIAM)},\\\\\n\\small{Technische Universiteit Delft, }\\small{Delft, The Netherlands.}\\\\\n\\small{$^3$Department of Applied Mathematics and Theoretical Physics (DAMTP)},\\\\ \n\\small{University of Cambridge, Cambridge, United Kingdom.}\\\\\n\\\\\n   \\small{ \\textup{\\texttt{$^1$j.m.budd-1@tudelft.nl \\qquad $^2$y.vangennip@tudelft.nl \\qquad $^3$jl2160@cam.ac.uk}}}\\\\\n}\n\\date{} % Activate to display a given date or no date (if empty),\n         % otherwise the current date is printed \n\\numberwithin{equation}{section}\n%%%%%%%%\n\\newtheoremstyle{exampstyle}\n  {4pt} % Space above\n  {4pt} % Space below\n  {\\itshape} % Body font\n  {} % Indent amount\n  {\\bfseries} % Theorem head font\n  {.} % Punctuation after theorem head\n  {.5em} % Space after theorem head\n  {} % Theorem head spec (can be left empty, meaning `normal')\n\\theoremstyle{exampstyle}\n\\newtheorem{thm}{Theorem}[section]\n%%%%%%%%\n\\newtheorem{mydef}[thm]{Definition}\n\\newtheorem{example}[thm]{Example}\n\n\\newtheorem{prop}[thm]{Proposition}\n\\newtheorem{prodef}[thm]{Proto-definition}\n\\newtheorem{note}[thm]{Notation}\n\\newtheorem{ax}[thm]{Axiom}\n\\newtheorem{lem}[thm]{Lemma}\n\\newtheorem{cor}[thm]{Corollary}\n%\\newtheorem*{fact}{Fact}\n\\newtheorem*{nb}{Note}\n\\newtheorem*{clm}{Claim}\n\\newtheorem*{qu}{Question}\n\\newcommand{\\be}{\\begin{equation}}\n\\newcommand{\\ee}{\\end{equation}}\n\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\G}{\\mathcal{G}}\n\\newcommand{\\V}{\\mathcal{V}}\n\\newcommand{\\E}{\\mathcal{E}}\n\\newcommand{\\bigO}{\\mathcal{O}}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\n\\DeclareMathOperator*{\\Glim}{\\Gamma-lim}\n\\DeclareMathOperator{\\supp}{supp}\n\\DeclareMathOperator{\\Ext}{Ext}\n\\DeclareMathOperator{\\divr}{div}\n\\DeclareMathOperator{\\TV}{TV}\n\\DeclareMathOperator{\\GL}{GL_{\\mathit\\varepsilon}}\n\\DeclareMathOperator{\\fGL}{GL_{\\mathit{\\varepsilon,\\mu},\\mathit{\\tilde f},\\textit{Z}}}\n\\DeclareMathOperator{\\ACEi}{ACE_{\\varepsilon,\\tau}^{imp}}\n\\DeclareMathOperator{\\ACEe}{ACE_{\\varepsilon,\\tau}^{exp}}\n\\DeclareMathOperator{\\sgn}{sgn}\n\\DeclareMathOperator{\\vol}{vol}\n\\DeclareMathOperator{\\Int}{Int}\n\\DeclarePairedDelimiter\\ceil{\\lceil}{\\rceil}\n\\DeclarePairedDelimiter\\floor{\\lfloor}{\\rfloor}\n\\DeclarePairedDelimiter\\ip{\\langle}{\\rangle_\\V}\n\\DeclarePairedDelimiter\\ipp{\\langle\\langle}{\\rangle\\rangle_\\V}\n\n\\captionsetup{font=small,labelfont={bf}}\n\\captionsetup[sub]{font=footnotesize,labelfont={bf}}\n\n%\\makeatletter\n%\\algrenewcommand\\ALG@beginalgorithmic{\\footnotesize}\n%\\makeatother\n\\makeatletter\n\\def\\@cite#1#2{{\\normalfont[{#1\\if@tempswa , #2\\fi}]}}\n\\makeatother\n\n%\\articletype{Original Article}\n\\begin{document}\n\\maketitle\n%\\papertype{Original Article}\n\n%\\protect\\thanks{}\n%}\n%\n%\\author[1]{Jeremy Budd*}\n%\n%\\author[1]{Yves van Gennip}\n%\n%\\author[2]{Jonas Latz}\n%\n%\\authormark{Budd \\textsc{et al}}\n%\n%\n%\\address[1]{\\orgdiv{Delft Institute of Applied Mathematics (DIAM)}, \\orgname{Technische Universiteit Delft}, \\orgaddress{\\state{Delft}, \\country{The Netherlands}}}\n%\n%\\address[2]{\\orgdiv{Department of Applied Mathematics and Theoretical Physics}, \\orgname{University of Cambridge}, \\orgaddress{\\state{Cambridge}, \\country{United Kingdom}}}\n%\n%\n%\\corres{*Jeremy Budd, Mathematics and Computer Science, EWI, TU Delft, Van Mourik Broekmanweg 6, Delft, 2628 XE, The Netherlands. \\email{j.m.budd-1@tudelft.nl}}\n%\\presentaddress{Present address}\n%\\fundinginfo{The work of the first and second authors was supported by the European Union's Horizon 2020 research and innovation program under Marie Sk\u0142odowska-Curie grant 777826. The work of the third author was supported by the EPSRC grant EP/S026045/1.}\n\\begin{abstract}\nThis paper introduces a semi-discrete implicit Euler (SDIE) scheme for the Allen--Cahn equation (ACE) with fidelity forcing on graphs. Bertozzi and Flenner (2012) pioneered the use of this differential equation as a method for graph classification problems, such as semi-supervised learning and image segmentation. In Merkurjev, Kosti\\'c, and Bertozzi (2013), a Merriman--Bence--Osher (MBO) scheme with fidelity forcing was used instead, as the MBO scheme is heuristically similar to the ACE. This paper rigorously establishes the graph MBO scheme with fidelity forcing as a special case of an SDIE scheme for the graph ACE with fidelity forcing. This connection requires using the double-obstacle potential in the ACE, as was shown in Budd and Van Gennip (2020) for ACE without fidelity forcing. We also prove that solutions of the SDIE scheme converge to solutions of the graph ACE with fidelity forcing as the SDIE time step tends to zero.\n\nNext, we develop the SDIE scheme as a classification algorithm. We also introduce some innovations into the algorithms for the SDIE and MBO schemes. For large graphs, we use a QR decomposition method to compute an eigendecomposition from a Nystr\\\"om extension, which outperforms the method used in e.g. Bertozzi and Flenner (2012) in accuracy, stability, and speed. Moreover, we replace the Euler discretisation for the scheme's diffusion step by a computation based on the Strang formula for matrix exponentials. We apply this algorithm to a number of image segmentation problems, and compare the performance of the SDIE and MBO schemes. We find that whilst the general SDIE scheme does not perform better than the MBO special case at this task, our other innovations lead to a significantly better segmentation than that from previous literature. We also empirically quantify the uncertainty that this segmentation inherits from the randomness in the Nystr\\\"om extension.\n\n\n\n\n\n{\\bf 2010 AMS Classification.} 34B45, 35R02, 34A12, 65N12, 05C99.\n\n{\\bf Key words.} Allen\u2013Cahn equation, fidelity constraint, threshold dynamics, graph dynamics, Strang formula, Nystr\\\"om extension.\n\\end{abstract}\n%\n%\n%\n%\\jnlcitation{\\cname{%\n%\\author{Budd, J.}, \n%\\author{Van Gennip, Y.}, % and \n%\\author{Latz, J.} }(\\cyear{2020}). \n%\\ctitle{Classification and image processing with a semi-discrete scheme for fidelity forced Allen--Cahn on graphs}. \\cjournal{JOURNAL}, \\cvol{VOLUME, PP}.}\n\n\n%\\footnotetext{\\textbf{Abbreviations:} ANA, anti-nuclear antibodies; APC, antigen-presenting cells; IRF, interferon regulatory factor}\n%\\todo[inline]{This is indeed the worst citation style I know. Idea: Whenever a citation does not make sense as a footnote. ``The method from$^{2}$.\" would be such a case, we put the name of the authors. ``The method from Bertozzi and Flenner$^{2}$\" looks much better.}\n\\section{Introduction}\nIn this paper, we investigate the Allen--Cahn gradient flow of the Ginzburg--Landau functional on a graph, and the Merriman--Bence--Osher (MBO) scheme on a graph, with fidelity forcing. We extend  to the case of fidelity forcing the definition of the semi-discrete implicit Euler (SDIE) scheme  introduced in \\cite{Budd} for the graph Allen--Cahn equation (ACE), and prove that the key results of \\cite{Budd} hold true in the fidelity forced setting, i.e.\n\\begin{itemize}\n\\item the MBO scheme with fidelity forcing is a special case of the SDIE scheme with fidelity forcing; and\n\\item the SDIE solution converges to the solution of Allen--Cahn with fidelity forcing as the SDIE time step tends to zero. \n\\end{itemize}\n\nWe then demonstrate how to employ the SDIE scheme as a classification algorithm, making a number of improvements upon the MBO-based classification in \\cite{MKB}. In particular, we have developed a stable method for extracting an eigendecomposition or singular value decomposition (SVD) from the Nystr\\\"om extension \\cite{Nys,FBCM} that is both faster and more accurate than the previous method used in \\cite{MKB,BF}. Finally, we test the performance of this scheme as an alternative to graph MBO as a method for image processing on the ``two cows'' segmentation task considered in \\cite{MKB,BF}.\n\nGiven an edge-weighted graph, the goal of two-class graph classification is to partition the vertex set into two subsets in such a way that the total weight of edges within each subset is high and the weight of edges between the two subsets is low. Classification differs from clustering by the addition of some {a priori} knowledge, i.e. for certain vertices the correct classification is known beforehand. Graph classification has many applications, such as semi-supervised learning and image segmentation \\cite{BF,birdspot}.\n\nAll programming for this paper was done in \\textsc{Matlab}R2019a. Except within algorithm environments and URLs, all uses of \\texttt{typewriter font} indicate in-built \\textsc{Matlab} functions. \n\\subsection{Contributions of this work}\nIn this paper we have:\n\\begin{itemize}\n\\item Defined a double-obstacle ACE with fidelity forcing (Definition \\ref{ACEdef}), and extended the theory of \\cite{Budd} to this equation (Theorem \\ref{fACEthm}).\n\\item Defined an SDIE scheme for this ACE (Definition \\ref{fSDdef}) and following \\cite{Budd} proved that this scheme is a generalisation of the fidelity forced MBO scheme (Theorem \\ref{obsMMthm}), derived a Lyapunov functional for the SDIE scheme (Theorem \\ref{fLyapthm}), and proved that the scheme converges to the ACE solution as the time-step tends to zero (Theorem \\ref{SDlimit}).\n\\item Described how to employ the SDIE scheme as a generalisation of the MBO-based classification algorithm in \\cite{MKB}. \n\\item Developed a method,  inspired by \\cite{BK}, using the QR decomposition to extract an approximate SVD of the normalised graph Laplacian from the Nystr\\\"om extension (Algorithm \\ref{nysQR}), which avoids the potential for errors in the method from \\cite{MKB,BF} that can arise from taking the square root of a non-positive-semi-definite matrix, and empirically produces much better performance than the \\cite{MKB,BF} method (Fig. \\ref{Fig_Timings_Error_LR}) in  accuracy, stability, and speed.\n\\item Developed a method using the quadratic error Strang formula for matrix exponentials \\cite{Strang} for computing fidelity forced graph diffusion (Algorithm \\ref{SDalg}), which empirically incurs a lower error than the error incurred by the semi-implicit Euler method used in \\cite{MKB} (Fig. \\ref{LPFfig}), and explored other techniques with the potential to further reduce error (Table \\ref{btable}).\n\\item Demonstrated the application of these algorithms to image segmentation, particularly the ``two cows'' images from \\cite{MKB,BF}, compared the quality of the segmentation to those produced in \\cite{MKB,BF} (Fig. \\ref{fig:usvsBFMKB}), and investigated the uncertainty in these segmentations (Fig. \\ref{Fig_MonteCarlo}), which is inherited from the randomisation in Nystr\\\"om.\n\\end{itemize}\n\nThis work extends the work in \\cite{Budd} in four key ways. Firstly, introducing fidelity forcing changes the character of the dynamics, e.g. making graph diffusion affine, which changes a number of results/proofs, and it is thus of interest that the SDIE link continues to hold between the MBO scheme and the ACE. Secondly, this work for the first time considers the SDIE scheme as a tool for applications. Thirdly, in developing the scheme for applications we have made a number of improvements to the methods used in the previous literature \\cite{MKB} for MBO-based classification, which result in a better segmentation of the ``two cows'' image than that produced in \\cite{MKB} or \\cite{BF}. Fourthly, we quantify the randomness that the segmentation inherits from the Nystr\\\"om extension.\n\n\n\n\n%\\hrule\n\\subsection{Background}\n%\\begin{itemize}\n%\\item CONTINUUM STUFF:\n%\\item Clustering and segmentation, TV methods: Mumford--Shah, Chan--Vese  \n%\\item Use of GL in place of TV (via $\\Gamma$-convergence link)\n%\\item ET2006 use of MBO for Chan--Vese\n%\\item GRAPH STUFF:\n%\\item Graph clustering via spectral clustering\n%\\item Bertozzi puts GL-based stuff on graphs ($\\Gamma$-convergence link still holds), MBO stuff a year later\n%\\item Recent work \n%\\end{itemize}\n\nIn the continuum, a major class of techniques for classification problems relies upon the minimisation of total variation (TV), e.g. the famous Mumford--Shah \\cite{MS} and Chan--Vese \\cite{CV} algorithms. These methods are linked to Ginzburg--Landau methods by the fact that the Ginzburg--Landau functional $\\Gamma$-converges to TV \\cite{MM,KS} (a result that continues to hold in the graph context \\cite{vGB}). This motivated a common technique of minimising the Ginzburg--Landau functional in place of TV, e.g. in \\cite{ET} two-class Chan--Vese segmentation was implemented by replacing TV with the Ginzburg--Landau functional; the resulting energy was minimised by using a fidelity forced MBO scheme.  \n\n\nInspired by this continuum work, in \\cite{BF} a method for graph classification was introduced based on minimising the Ginzburg--Landau functional on a graph by evolving the graph Allen--Cahn equation (ACE). The {a priori} information was incorporated by including a fidelity forcing term, leading to the equation\n\\[\n\\frac{du}{dt} = -\\Delta u - \\frac1\\varepsilon W'\\circ u - \\mu P_Z (u-f),\n\\]\nwhere $u$ is a labelling function which, due to the influence of a double-well potential (e.g. $W(x) = x^2 (x-1)^2$) will take values close to $0$ and $1$, indicating the two classes. The {a priori} knowledge is encoded in the reference $f$ which is supported on $Z$, a subset of the node set with corresponding projection operator $P_Z$. In the first term $\\Delta$ denotes the graph Laplacian and $\\varepsilon, \\mu>0$ are parameters. All these ingredients will be explained in more detail in Sections~\\ref{Gwork} and~\\ref{ACEsec}.\n\nIn \\cite{MKB} an alternative method was introduced: a graph Merriman--Bence--Osher (MBO) scheme with fidelity forcing. The original MBO scheme, introduced in a continuum setting in \\cite{MBO92} to approximate motion by mean curvature, is an iterative scheme consisting of diffusion alternated with a thresholding step. In \\cite{MKB} this scheme was discretised for use on graphs and the fidelity forcing term $- \\mu P_Z (u-f)$ was added to the diffusion. Heuristically, this MBO scheme was expected to behave similarly to the graph ACE as the thresholding step resembles a ``hard'' version of the ``soft'' double-well potential nonlinearity in the ACE.\n\nIn \\cite{Budd} it was shown that the graph MBO scheme {\\it without} fidelity forcing could be obtained as a special case of a semi-discrete implicit Euler (SDIE) scheme for the ACE (without fidelity forcing), if the smooth double-well potential was replaced by the double-obstacle potential defined in \\eqref{Wobs}, and that solutions to the SDIE scheme converge to the solution of the graph ACE as the time step converges to zero. This double-obstacle potential was studied for the continuum ACE in \\cite{BE1991,BE1992,BE1993} and was used in the graph context in \\cite{BKS2018}. In \\cite{volumeBudd} a result similar to that obtained in \\cite{Budd} was obtained for a mass-conserving graph MBO scheme. In this paper such a result will be established for the graph MBO scheme {\\it with} fidelity forcing.\n\n%Following similar results in \\cite{Budd,volumeBudd} we also prove that the solution of each SDIE scheme for graph ACE with fidelity converges to the solution of the continuous-in-time graph ACE as the time step converges to zero. Compared to the earlier papers, the presence of the fidelity forcing term requires some extra care to ensure all the relevant estimates hold. Overall, however, a similar strategy is followed here as in \\cite{Budd}.\n\nIn \\cite{vGGOB} it was shown that the graph MBO scheme {\\it pins} (or {\\it freezes}) when the diffusion time is chosen too small, meaning that a single iteration of the scheme will not introduce any change as the diffusion step will not have pushed the value at any node past the threshold. In \\cite{Budd} it was argued that the SDIE scheme for graph ACE provides a relaxation of the MBO scheme: The hard threshold is replaced by a gradual threshold, which should allow for the use of smaller diffusion times without experiencing pinning. The current paper investigates what impact that has in practical problems. %We compare the performance of SDIE schemes for the graph ACE with fidelity forcing with that of the graph MBO scheme with fidelity forcing on an image segmentation problem. \n\n%The current paper also improves the implementation of the SDIE (and thus also MBO) scheme in two ways compared to earlier implementions in \\cite{BF,MKB}: (a) A QR decomposition is used to implement the Nystr\\\"om extension and (b) the Lie product formula for matrix exponentials is used to improve on the Euler discretisation of the diffusion step.\n%\n%The Nystr\\\"om extension \\cite{Nystrom...Belongie...} was used in \\cite{BF} to be able to handle large graphs without running into memory problems. It approximates the full weight matrix of the graph by a using a smaller weight matrix built from a randomly sampled subset of the node set. Inspired by \\cite{BK}, we combine a QR decomposition with the Nystr\\\"om extension to efficiently compute the approximate eigenvalue decomposition of the weight matrix which is required for the SDIE scheme. This also avoids the potential for errors in the algorithm from \\cite{BF} which comes from having to take a square root of a matrix which might not be positive semi-definite, depending on the randomly sampled subset of nodes.\n%\n%In \\cite{MKB} the diffusion step with fidelity forcing term in the MBO scheme was computed using an Euler discretisation. In this paper we show that the Euler discretisation in this case can be interpreted as an approximation of the Lie product formula for matrix exponentials \\cite{Hall}, which itself provides an approximation for the exponential of the sum of two matrices, in terms of products of matrix exponentials. We thus improve upon the accuracy of computation of the diffusion step by replacing the Euler discretisation by a direct application of the Lie product formula.\n\n\n\n\n\n\n\n%\n%\n%[[[Previous  draft]]]\n%\n%Ginzburg--Landau-based methods on graphs were introduced as classification algorithms by Bertozzi and Flenner in \\cite{BF}. The philosophy behind this is that the vertex set $V$ represents the collection of individuals we seek to classify, whether these be vertices in an image or points in space, or human beings, etc. The edge weights $\\omega_{ij}$ encode the relationships between these individuals. A (binary) classification/clustering problem is a problem that seeks to find some $u:V\\rightarrow \\{0,1\\}$ which is in some sense the ``optimal\" way of classifying these individuals into two groups. This problem may be ``(semi-)supervised\", i.e. there is some (in the semi-supervised case, small) $Z\\subseteq V$ which is the \\emph{training data}, and on which some classifier $f:Z\\rightarrow \\{0,1\\}$ is known. \n%\n%[[HISTORY LESSON OF REPLACING TV BY GL]]\n%\n%[[ET2006 CONNECTS CV TO MBO]]\n%\n%A major traditional approach for characterising the optimality of $u$, seen for example in the classic Chan--Vese method \\cite{CV}, centred around minimising the \\emph{total variation} (TV) of $u$, subject to fidelity contraints. In graph theoretic terms, this corresponds to minimising the \\emph{graph cut} between the $\\{u=0\\} $ and $\\{u=1\\}$ sets (i.e. the total edge weight from edges from one set to the other) \\cite{vGGOB}. The key idea of \\cite{BF} was to exploit the fact that the Ginzburg--Landau energy $\\Gamma$-converges to TV, see [ModicaMortola,KohnSternberg] in the continuum case and \\cite{vGB} for a proof in the graph context, to replace this $\\TV(u) $ term with a $\\GL(u)$ term (plus fidelity terms), though they did not use the same $W$ as in this paper.  Taking the ACE gradient flow of this then gave an algorithm for classifying the vertices of as graph, as the solution to the ACE will tend towards a minimiser of the Ginzburg--Landau energy, i.e. a function which takes values near the wells of the potential but also, via the Dirichlet energy term, has a small graph cut. This method proved fruitful in the applications tested on in \\cite{BF}, and also in more real-life [[PHRASING]] applications such as \\cite{birdspot} [[ADD MORE?]], however computing the ACE solutions could be more expensive than desired. In \\cite{MKB}, Merkurjev, Kostic, and Bertozzi introduced a cheaper algorithm, replacing the evolution of the ACE with iterations of the MBO scheme. \n\n\\subsection{Groundwork}\\label{Gwork}\nWe briefly summarise the framework for analysis on graphs, following the summary in \\cite{Budd} of the detailed presentation in \\cite{vGGOB}. \nA graph $G = (V,E)$ will henceforth be defined to be a finite, simple, undirected, weighted, and connected graph without self-loops with vertex set $V$, edge set $E\\subseteq V^2$, and weights $\\{\\omega_{ij}\\}_{i,j\\in V}$ with $\\omega_{ij}\\geq 0$, $\\omega_{ij} = \\omega_{ji}$, $\\omega_{ii}=0$, and $\\omega_{ij} > 0$ if and only if $ij\\in E$. We define the following  function spaces on $G$  (where $X\\subseteq \\mathbb{R}$, and $T\\subseteq\\mathbb{R}$ an interval):\n\\begin{align*}\n\t&\\V := \\left\\{ u: V\\rightarrow\\mathbb{R} \\right\\} , &\\V_{X} := \\left\\{ u: V\\rightarrow X \\right\\}&,  &\\mathcal{E} := \\left\\{ \\varphi: E\\rightarrow\\mathbb{R} %|\\varphi_{ij} = -\\varphi_{ji} \n\\right\\}.&\\\\\n\t&\\V_{t\\in T} := \\left\\{ u: T\\rightarrow\\V \\right\\} , &\\V_{X,t\\in T} := \\left\\{ u: T\\rightarrow \\V_X \\right\\}.&\n\\end{align*}\nDefining $d_i := \\sum_{j\\in V} \\omega_{ij}$ to be the \\emph{degree} of vertex $i\\in V$, we define inner products on $\\V$ (or $\\V_X$) and $\\E$ (where $r\\in [0,1]$):\n\\begin{align*}\n\t&\\ip{u,v} := \\sum_{i\\in V} u_i v_i d_i^r, &\\langle\\varphi,\\phi\\rangle_\\mathcal{E}:=\\frac{1}{2}\\sum_{i,j\\in V} \\varphi_{ij} \\phi_{ij}\\omega_{ij},&\n\\end{align*} and define the inner product on $\\V_{t\\in T}$ (or $\\V_{X,t\\in T}$) \\[ (u,v)_{t\\in T}:=\\int_T \\left\\langle u(t),v(t)\\right\\rangle_\\V \\;dt = \\sum_{i\\in V} d_i^r\\, (u_i,v_i)_{L^2(T;\\mathbb{R})}.\\] \nThese induce inner product norms $||\\cdot||_\\V$, $||\\cdot||_\\mathcal{E}$, and $||\\cdot||_{t\\in T}$. %and also define on $\\V$ the norm $ ||u||_\\infty := \\max_{i\\in V} |u_i|$.\nNext, we define the $L^2$ %and $L^\\infty$ \nspace: \\begin{align*} &L^2(T;\\V) : =\\left\\{ u\\in\\V_{t\\in T} \\mid ||u||_{t\\in T} <\\infty \\right\\}, \n%\\\\&L^\\infty(T;\\V) : =\\left\\{ u\\in\\V_{t\\in T}\\mid \\exists C\\in\\mathbb{R}, || u(t)||_{\\infty} <C\\text{ for a.e. } t \\in T  \\right\\}.\n\\end{align*}\nand, for $T$ an open interval, we define the {Sobolev space} $H^1(T;\\V)$ as the set of $u \\in L^2(T;\\V)$ with weak derivative $du/dt \\in L^2(T;\\V)$ defined by\n\\[  \\forall \\varphi\\in C^\\infty_c(T;\\V)\\:\\:\\left(u,\\frac{d\\varphi}{dt}\\right)_{t\\in T} = -\\left(\\frac{du}{dt},\\varphi\\right)_{t\\in T} \\] \nwhere $C^\\infty_c(T;\\V)$ is the set of $\\varphi \\in \\V_{t\\in T}$ that are infinitely differentiable with respect to time $t\\in T$ and are compactly supported in $T$. By \\cite[Proposition 2.1]{Budd},\n$u\\in H^1(T;\\V)$ if and only if $u_i \\in H^1(T;\\mathbb{R})$ for each $i\\in V$. \n%Then $H^1(T;\\V)$ has inner product:\\[ (u,v)_{H^1(T;\\V)} := (u,v)_{t\\in T} + \\left(\\frac{du}{dt},\\frac{dv}{dt}\\right)_{t\\in T} = \\sum_{i\\in V} d_i^r (u_i,v_i)_{H^1(T;\\mathbb{R})}.\\] \nWe define the local $H^1$ space on any interval $T$ (and likewise define the local $L^2$ space $L^2_{loc}(T;\\V)$): \\[ H^1_{loc}(T;\\V) :=\\left\\{u\\in \\V_{t\\in T}\\,\\middle|\\,\\forall a,b\\in T, \\: u\\in H^1((a,b);\\V) \\right\\}.\\] %and $L^\\infty_{loc}(T;\\V)$. \n\nFor $A\\subseteq V$, we define the \\emph{characteristic function} of $A$, $\\chi_A\\in\\V$, by\n\\[ (\\chi_A)_i := \\begin{cases} 1, & \\text{if }i\\in A,\\\\\n 0, & \\text{if }i\\notin A.\\end{cases}\\]\nNext, we introduce the graph gradient and Laplacian:\n\\begin{align*}\n\t&(\\nabla u)_{ij}:=\\begin{cases}u_j -u_i, & ij\\in E,\\\\ 0, &\\text{otherwise,} \\end{cases} &(\\Delta u)_i:=d_i^{-r}\\sum_{j\\in V}\\omega_{ij}(u_i-u_j).&\n\\end{align*}\nNote that $\\Delta$ is positive semi-definite and self-adjoint with respect to $\\V$. As shown in \\cite{vGGOB}, these operators are related via:\n\\[\n\\ip{u,\\Delta v} = \\langle \\nabla u, \\nabla v \\rangle_\\mathcal{E}.\n\\]\nWe can interpret $\\Delta$ as a matrix. Define $D := \\operatorname{diag}(d)$ (i.e. $D_{ii}:=d_i$, and $D_{ij}:=0$ otherwise) to be the \\emph{diagonal matrix of degrees}. Then writing $\\omega$ for the matrix of weights $\\omega_{ij}$ we get \n\\[\n\\Delta:= D^{-r}(D-\\omega).\n\\]\n From $\\Delta$ we define the \\emph{graph diffusion operator}: \\[e^{-t\\Delta}u:=\\sum_{n\\geq 0} \\frac{(-1)^n t^n}{n!}\\Delta^n u\\] where $v(t)=e^{-t\\Delta}u $ is the unique solution to ${dv}/{dt} = -\\Delta v$ with $v(0) = u$. Note that $e^{-t\\Delta}\\mathbf{1} = \\mathbf{1}$, where $\\mathbf{1}$ is the vector of ones.\n\tBy \\cite[Proposition 2.2]{Budd} if $u\\in H^1(T;\\V)$ and $T$ is bounded below, then $e^{-t\\Delta}u\\in H^1(T;\\V)$ with \\[\\frac{d}{dt}\\left(e^{-t\\Delta}u\\right) = e^{-t\\Delta}\\frac{du}{dt} -  e^{-t\\Delta}\\Delta u.\\] \nWe recall from functional analysis the notation, for any linear operator $F:\\V\\rightarrow\\V$,\n\\begin{align*} &\\sigma(F):=\\{\\lambda :\\text{$\\lambda$ an eigenvalue of $F$}\\}\\\\\n&\\rho(F):=\\max\\{|\\lambda| : \\lambda \\in \\sigma(F)\\}\\\\\n&||F|| := \\sup_{||u||_\\V = 1} ||Fu||_\\V\n\\end{align*}\nand recall the standard result that if $F$ is self-adjoint then $||F|| = \\rho(F)$.\n%\n\nFinally, we recall some notation from \\cite{Budd}: for problems of the form ${\\argmin}_x\\: f(x)$ we write $f \\simeq g$ and say $f$ and $g$ are \\emph{equivalent} when $g(x) = af(x) + b$ for $a>0$ and $b$ independent of $x$. As a result, replacing $f$ by $g$ does not affect the minimisers.\n\nLastly, we define the non-fidelity-forced versions of the graph MBO scheme, the graph ACE and the SDIE scheme.  \n\nThe MBO scheme is an iterative, two-step process, originally developed in \\cite{MBO92} to approximate motion by mean curvature. On a graph, it is defined in \\cite{MKB} by the following iteration: for $u_n\\in \\V_{\\{0,1\\}}$, and $\\tau >0$ the \\emph{time step},\n\\begin{enumerate}\n\\item $v_n:= e^{-\\tau\\Delta}u_n$, i.e. the diffused state of $u_n$ after a time $\\tau$.\n\\item $(u_{n+1})_i = \\begin{cases} 1, &\\text{ if }(v_n)_i \\geq 1/2, \\\\ 0, &\\text{ if } (v_n)_i < 1/2. \\end{cases}$\n\\end{enumerate}\n\n To define the \\emph{graph Allen\\textendash Cahn equation} (\\emph{ACE}), we first define the \\emph{graph Ginzburg\\textendash Landau functional} as in {\\cite{Budd}} by \n\\begin{equation*}\n\t\\label{GL}\n\t\\GL(u) := \\frac{1}{2}\\left|\\left|\\nabla u\\right|\\right|_\\mathcal{E}^2 +\\frac{1}{\\varepsilon}\\left\\langle W\\circ u,\\mathbf{1} \\right \\rangle_\\V\n\\end{equation*}\nwhere $W$ is a double-well potential and $\\varepsilon>0$ is a scaling parameter. Then the ACE results from taking the $\\ip{\\cdot,\\cdot}$ gradient flow of $\\GL$, which for $W$ differentiable is given by the ODE (where $\\nabla_\\V$ is the Hilbert space gradient on $\\V$):\n\\begin{equation*}\n\t\\label{AC}\n\t\\frac{du}{dt} = -\\nabla_\\V\\GL(u) = -\\Delta u - \\frac{1}{\\varepsilon} W'\\circ u .\n\\end{equation*}\n\n\nTo facilitate the SDIE link from \\cite{Budd} between the ACE and the MBO scheme, we will henceforth take $W$ to be defined as:\n\\begin{equation}\n\t\\label{Wobs}\n\tW(x) := \\begin{cases}\n    \\frac{1}{2}x(1-x), & \\text{for } 0 \\leq x \\leq 1, \\\\\n    \\infty, & \\text{otherwise,}  \\end{cases}\n\\end{equation}\nthe \\emph{double-obstacle potential} studied by Blowey and Elliott \\cite{BE1991,BE1992,BE1993} in the continuum and Bosch, Klamt, and Stoll \\cite{BKS2018} on graphs.\nAs $W$ is not differentiable, we redefine the ACE via the subdifferential of $W$. As in \\cite{Budd} we say that a pair $(u,\\beta)\\in\\V_{[0,1],t\\in T}\\times\\V_{t\\in T}$ is a solution to the double-obstacle ACE on an interval $T$ if $u\\in H_{loc}^1(T;\\V)$ and for a.e. $t\\in T$ \n\\begin{align*}\n\\label{ACobs2}\n\t&\\varepsilon \\frac{du}{dt}(t) + \\varepsilon\\Delta u(t)  +\\frac{1}{2}\\mathbf{1}-u(t)= \\beta(t), &\\beta(t)\\in\\mathcal{B}(u(t))\n\\end{align*}\nwhere $\\mathcal{B}(u)$ is the set (for $I_{[0,1]}(x):=0$ if $x\\in[0,1]$ and $I_{[0,1]}(x):=\\infty$ otherwise)\n\\begin{equation}\n\\label{oldbeta}\n\t \\mathcal{B}(u) :=\\left\\{  \\alpha\\in\\V\\: \\middle|\\: \\forall i\\in V,  \\alpha_i\\in -\\partial I_{[0,1]}(u_i)\n\t\\right\\}.\n\\end{equation}\nThat is, $\\mathcal{B}(u)=\\emptyset$ if $u\\notin\\V_{[0,1]}$, and for $u\\in\\V_{[0,1]}$ it is the set of $\\beta\\in\\V$ such that \n\\[\\beta_i\\in\\begin{cases}\n\t\t%\\{\\infty\\}, & u_i<0\\\\\n\t\t[0,\\infty), & u_i=0,\\\\\n\t\t\\{0\\}, &0<u_i < 1,\\\\\n\t\t(-\\infty,0], & u_i=1.\n\t\t%\\{-\\infty\\}, &u_i>1.\n\t\\end{cases}\\]\n\nFinally, the SDIE scheme for the graph ACE is defined in \\cite{Budd} by the formula\n\\[ \tu_{n+1}=e^{-\\tau\\Delta} u_n- \\frac{\\tau}{\\varepsilon} W'\\circ u_{n+1} \\]\nor more accurately, given the above detail with the subdifferential, \n\\begin{equation*}\n\\label{SDobs}\n(1-\\lambda)u_{n+1}-e^{-\\tau\\Delta}u_n+\\frac{\\lambda}{2}\\mathbf{1} =\\lambda\\beta_{n+1}\n\\end{equation*}\nwhere $\\lambda:=\\tau/\\varepsilon$ and $\\beta_{n+1}\\in\\mathcal{B}(u_{n+1})$. The key results of \\cite{Budd} are then that:\n\\begin{itemize}\n\\item When $\\tau = \\varepsilon$, this scheme is exactly the MBO scheme. \n\\item For $\\varepsilon$ fixed and $\\tau\\downarrow 0$, this scheme converges to the solution of the double-obstacle ACE (which is a well-posed ODE).\n\\end{itemize}\n\n\\subsection{Paper outline}\nThe paper is structured as follows. In Section~\\ref{Gwork} we introduced important concepts and notation for the rest of the paper. \nSection~\\ref{ACEsec} contains the main theoretical results of this paper. It defines the graph MBO scheme with fidelity forcing, the graph ACE with fidelity forcing, and the SDIE scheme for graph ACE with fidelity forcing. It proves well-posedness for the graph ACE with fidelity forcing and establishes the rigorous link between a particular SDIE scheme and the graph MBO with fidelity forcing. Moreover, it introduces a Lypunov functional for the SDIE scheme with fidelity forcing and proves convergence of solutions of the SDIE schemes to the solution of the graph ACE with fidelity forcing. \nIn Section~\\ref{classificationsec} we explain how the SDIE schemes can be used for graph classification. In particular, the modifications to the existing MBO-based classification algorithms based on the QR decomposition and Strang formula are introduced. \nSection~\\ref{applicationsec} presents a comparison of the SDIE and MBO scheme for an image segmentation applications, and an investigation into the uncertainty in these segmentations. %, before Section~\\ref{sec:conclusion} briefly summarises the conclusions of the paper. \nIn Appendix~\\ref{MKBapp} it is shown that the application of the Euler method used in \\cite{MKB} can be seen as an approximation of the Lie product formula. \n\n%\n%In section \\ref{ACEsec}, we \n%\n%In section \\ref{classificationsec}, we \n%\n%In section \\ref{applicationsec}, we \n\n\\section{The Allen--Cahn equation, the MBO scheme, and the SDIE scheme with fidelity forcing }\\label{ACEsec}\n\\subsection{The MBO scheme with fidelity forcing}\nFollowing \\cite{MKB,ET}, we introduce fidelity forcing into the MBO scheme by first defining a fidelity forced diffusion.\n\\begin{mydef}[Fidelity forced graph diffusion]\nFor $u\\in H^1_{loc}([0,\\infty);\\V)$ and $u_0\\in \\V$ we define fidelity forced diffusion to be\\emph{:}\n\\begin{align}\\label{fdiffuse}\n&\\frac{du}{dt}(t) = -\\Delta u(t)-\\mu P_Z(u(t)-\\tilde f)) =:-Au(t) +\\mu P_Z\\tilde f, &u(0) = u_0,\n\\end{align}\nwhere $A:=\\Delta + \\mu P_Z$, $\\tilde f \\in \\V_{[0,1]}$ is the \\emph{reference}, $\\mu > 0$ paramaterises the strength of the fidelity to the reference, $\\emptyset\\neq Z\\subseteq V$ is the \\emph{reference data} we enforce fidelity on, and $P_Z$ is the projection map\\emph{:}\n\\[\n(P_Zu)_i = \\begin{cases} u_i, &\\text{if }i\\in Z,\\\\\n0, &\\text{if }i\\notin Z. \\end{cases}\n\\] For the purposes of this section we shall treat $\\mu$, $\\tilde f$, and $Z$ as fixed and given. Moreover, since $\\tilde f$ only ever appears in the presence of $P_Z$, we define $f:=P_Z\\tilde f$ which is supported only on $Z$ and so $P_Zf = f$.\n\\end{mydef}\n\\begin{prop}\\label{Aspec}\n$A$ is invertible with $ \\sigma(A)\\subseteq (0, ||\\Delta|| + \\mu ]$.\n\\end{prop}\n\\begin{proof}\n%Note that $A$ is the sum of positive semi-definite matrices, so is positive semi-definite and has non-negative eigenvalues.  \nFor the lower bound, we show that $A$ is strictly positive definite. Let $u \\neq \\mathbf{0}$ be written $u = v +\\alpha\\mathbf{1}$ for $v\\bot\\mathbf{1}$. Then \n\\[\n\\ip{u,Au} =\\ip{ v,\\Delta v} + \\mu \\ip{u,P_Z u}\n\\]\nand note that both terms on the right hand side are non-negative. Next, if $v\\neq \\mathbf{0}$ then   \n\\[\n\\ip{u,Au} \\geq \\ip{ v,\\Delta v} = ||\\nabla v||^2_\\mathcal{E} > 0\n\\]\nsince $v\\bot \\mathbf{1}$ and hence $\\nabla v \\neq \\mathbf{0}$, since $G$ is connected. Else, $v =\\mathbf{0}$ so $\\alpha \\neq 0$ and \n\\[\n\\ip{u,Au} = \\mu\\alpha^2 \\ip{\\mathbf{1},\\chi_Z}>0.\n\\]\n%since $Z$ is non-empty.\nFor the upper bound: $A$ is the sum of self-adjoint matrices, so is self-adjoint and hence has largest eigenvalue equal to $||A|| = ||\\Delta + \\mu P_Z|| \\leq ||\\Delta|| + \\mu ||P_Z|| = ||\\Delta|| + \\mu$. \n\\end{proof}\n\\begin{thm} \\label{fdiffusethm}\nFor given $u_0\\in\\V$, \\eqref{fdiffuse} has a unique solution in $H^1_{loc}([0,\\infty);\\V)$. The solution $u$ to \\eqref{fdiffuse} is $C^1((0,\\infty);\\V)$ and is given by the map \\emph{(}where $I$ denotes the identity matrix\\emph{):}\n\\be\\label{fdiffusesoln}\\begin{split}\nu(t) = \\mathcal{S}_t u_0 %&:= e^{-tA}u_0 +\\mu \\sum_{n=0}^\\infty (-1)^n\\frac{t^{n+1}}{(n+1)!}A^nf \\\\\n\t\t\t\t\t\t\t   &:=e^{-tA}u_0 + \\mu A^{-1}(I - e^{-tA})f.\n\\end{split}\\ee\nThis solution map has the following properties\\emph{:} \n\\begin{enumerate}[i.]\n\\item If $u_0 \\leq v_0$ vertexwise, then for all $t\\geq 0$, $\\mathcal{S}_tu_0 \\leq \\mathcal{S}_tv_0$ vertexwise.\n\\item $\\mathcal{S}_t:\\V_{[0,1]} \\rightarrow \\V_{[0,1]}$ for all $t\\geq 0$, i.e. if $u_0\\in\\V_{[0,1]}$ then $u(t)\\in\\V_{[0,1]}$.\n\\end{enumerate}\n\\end{thm}\n\\begin{proof} \nIt is straightforward to check directly that \\eqref{fdiffusesoln} satisfies \\eqref{fdiffuse} and is $C^1$ on $(0,\\infty)$. Uniqueness is given by a standard Picard--Lindel\\\"of argument (see e.g. \\cite[Corollary 2.6]{Teschl}).\n%Gr\\\"onwall's inequality argument (see e.g. \\cite[Chapter III]{Hartman}). \n%We note that the sum in \\eqref{fdiffusesoln} always exists for $t\\geq0$ since the sum of the absolute values can be controlled: \n%\\[ \\sum_{n=0}^\\infty \\frac{t^{n+1}}{(n+1)!}||A^nf||_\\V\\leq  \\frac{e^{t||A||}-1}{||A||} ||f||_\\V\\leq  \\frac{e^{t( ||\\Delta|| + \\mu)}-1}{ ||\\Delta|| + \\mu } ||\\mathbf{1}||_\\V \\] \n%and so the sum in \\eqref{fdiffusesoln} absolutely converges.\\footnote{Note that $A\\mathbf{1} = \\mu\\chi_Z\\neq \\mathbf{0}$ so $||A||>0$, and that $(e^{tx}-1)/x$ is monotonically increasing in $x$ for $x\\geq 0$.}  %and the second line follows from the observation that $Af = \\Delta f + P_Zf = \\Delta f + f = \\tilde A f$ and the fact that $\\tilde A$ has smallest eigenvalue $\\mu>0$ so is invertible. \n\\begin{enumerate}[i.]\n\\item By definition, $\\mathcal{S}_t v_0 - \\mathcal{S}_t u_0 = e^{-tA}(v_0-u_0)$. Thus it suffices to show that $e^{-tA}$ is a non-negative matrix for $t\\geq 0$. Note that the off-diagonal elements of $-tA$ are non-negative: for $i\\neq j$, $-tA_{ij}=-t\\Delta_{ij} = td_i^r \\omega_{ij}\\geq 0$. Thus for some $a>0$, $M:=aI-tA$ is a non-negative matrix and thus $e^M$ is a non-negative matrix.  It follows that $e^{-tA}= e^{-a}e^M$ is a non-negative matrix.\n\\item Let $u_0\\in\\V_{[0,1]}$ and recall that $f\\in\\V_{[0,1]}$. Suppose that for some $t>0$ and some $i\\in V$, $u_i(t)<0$. Then \\[ \\min_{t'\\in [0,t]} \\min_{i\\in V} u_i(t') < 0\\] and since each $u_i$ is continuous this minimum is attained at some  $t^*\\in [0,t]$ and $i^*\\in V$. Fix such a $t^*$. Then for any $i^*$ minimising $u(t^*)$, since $ u_{i^*}(t^*) < 0$ we must have $t^* >0$, so $u_{i^*}$ is differentiable at $t^*$ with $du_{i^*}/dt(t^*) = 0$. However by \\eqref{fdiffuse} \n\\[ \\frac{du_{i^*}}{dt}(t^*) = -(\\Delta u(t^*))_{i^*} + \\mu (\\chi_Z)_{i^*} (f_{i^*} - u_{i^*}(t^*)).\\]\nWe claim that we can choose a suitable minimiser $i^*$ such that this is strictly positive. First, since any such $i^*$ is a minimiser of $u(t^*)$, and $f_i \\geq 0$ for all $i$, it follows that each term is non-negative. Next, suppose such an $i^*$ has a neighbour $j$ such that $u_j(t^*) > u_{i^*}(t^*)$, then it follows that $(\\Delta u(t^*))_{i^*} <0$ and we have the claim. Otherwise, all the neighbours of that $i^*$ are also minimisers of $u(t^*)$. Repeating this same argument on each of those, we either have the claim for the above reason or we find a minimiser $i^*\\in Z$, since $G$ is connected. But in that case $\\mu(f_{i^*} - u_{i^*}(t^*))\\geq -\\mu u_{i^*}(t^*) > 0$ and we again have the claim. Hence $du_{i^*}/dt(t^*)>0$, a contradiction. Therefore $u_i(t)\\geq 0$ for all $t$. The case for $u_i(t) \\leq 1$ is likewise.\n% If $u_0\\in\\V_{[0,1]}$ then $\\mathbf{0}\\leq u_0 \\leq \\mathbf{1}$ vertexwise, so by (i.) we have $\\mathcal{S}_t\\mathbf{0}\\leq \\mathcal{S}_tu_0\\leq \\mathcal{S}_t\\mathbf{1}$ vertexwise. Thus it suffices to show that $\\mathcal{S}_t\\mathbf{0}\\geq\\mathbf{0}$ and $\\mathcal{S}_t\\mathbf{1}\\leq\\mathbf{1}$ vertexwise. To the \n\\end{enumerate}\n\\end{proof}\n\\begin{mydef}[Graph MBO with fidelity forcing]\nFor $u_0\\in \\V_{[0,1]}$ we follow \\emph{\\cite{MKB,ET}}, and define the sequence of MBO iterates by diffusing with fidelity for a time $\\tau\\geq 0$ and then thresholding, i.e. \n\\be\n\\label{fMBO}\n(u_{n+1})_i = \\begin{cases} 1, &\\text{if }(\\mathcal{S}_{\\tau}u_n)_i \\geq 1/2,\\\\\n0, &\\text{if }(\\mathcal{S}_{\\tau}u_n)_i < 1/2,  \\end{cases}\n\\ee\nwhere $\\mathcal{S}_\\tau$ is the solution map from \\eqref{fdiffusesoln}. Note that \\eqref{fMBO} has variational form similar to that given for graph MBO in \\emph{\\cite{vGGOB}}, which we can then re-write as in \\emph{\\cite{Budd}:} \n\\be\n\\label{fMBOvar}\nu_{n+1}\\in \\argmin_{u\\in\\V_{[0,1]}}\\: \\ip{\\mathbf{1}-2\\mathcal{S}_\\tau u_n,u}\\simeq  \\frac{1}{2\\tau}\\ip{\\mathbf{1}-u,u} + \\frac{\\left|\\left|u-\\mathcal{S}_\\tau u_n\\right|\\right|^2_\\V}{2\\tau}. \n\\ee\n\\end{mydef}\n\\subsection{The Allen--Cahn equation with fidelity forcing}\nTo derive the Allen--Cahn equation (ACE) with fidelity forcing, we re-define the Ginzburg--Landau energy to include a fidelity term (recalling the potential $W$ from \\eqref{Wobs}):\n\\be \n\\label{fGL}\n\\fGL(u) := \\frac{1}{2}\\left|\\left|\\nabla u\\right|\\right|_\\mathcal{E}^2 +\\frac{1}{\\varepsilon}\\left\\langle W\\circ u,\\mathbf{1} \\right \\rangle_\\V + \\frac{1}{2}\\mu\\left|\\left| P_Z(u-\\tilde f)\\right|\\right|_\\mathcal{V}^2.\n\\ee \nTaking the gradient flow of \\eqref{fGL} we obtain the Allen--Cahn equation with fidelity:\n\\begin{align}\n\\label{fACE}\n\t&\\varepsilon \\frac{du}{dt}(t) + \\varepsilon(\\Delta u(t)+\\mu P_Z(u(t)-\\tilde f)) +\\frac{1}{2}\\mathbf{1}-u(t)= \\beta(t), &\\beta(t)\\in\\mathcal{B}(u(t)).\n\\end{align}\nWhere $\\mathcal{B}(u(t))$ is defined as in \\eqref{oldbeta}.\nRecalling that $A:=\\Delta + \\mu P_Z$ and $f:=P_Z\\tilde f $, we can rewrite the ODE in \\eqref{fACE} as \n\\[\n\\varepsilon \\frac{du}{dt}(t) + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t)= \\beta(t).\n\\]\nAs in \\cite{Budd}, we can give an explicit expression for $\\beta$ given sufficient regularity on $u$.\n\\begin{thm}\\label{betathm}\nLet $(u,\\beta)$ obey \\eqref{fACE} at a.e. $t\\in T$, with $u\\in H^1_{loc}(T;\\V)\\cap C^0(T;\\V)\\cap\\V_{[0,1],t\\in T}$. Then for all $i\\in V$ and a.e. $t\\in T$, \\be\\label{beta2} \\beta_i(t) = \\begin{cases} \\frac{1}{2} +\\varepsilon(\\Delta u(t))_i-\\varepsilon\\mu f_i,&u_i(t)=0,\\\\\n0, & u_i(t)\\in(0,1),\\\\\n-\\frac{1}{2} +\\varepsilon(\\Delta u(t))_i+\\varepsilon\\mu((\\chi_Z)_i-f_i), & u_i(t) =1.\\end{cases}\\ee\nHence at a.e. $t\\in T$,\n\\[\\beta(t)\\in\\V_{[-1/2,1/2]}.\\]\n\\end{thm}\n\\begin{proof} Follows as in \\cite[Theorem 2.2]{Budd} \\emph{mutatis mutandis}.\n\\end{proof}\nThus following \\cite{Budd} we define the double-obstacle ACE with fidelity forcing. \n\\begin{mydef}[Double-obstacle ACE with fidelity forcing]\\label{ACEdef}\nLet $T$ be an interval. Then a pair $(u,\\beta)\\in\\V_{[0,1],t\\in T}\\times\\V_{t\\in T}$ is a solution to double-obstacle ACE with fidelity forcing on $T$ when $u\\in H_{loc}^1(T;\\V)\\cap C^0(T;\\V)$ and for almost every $t\\in T$, \n\\begin{align}\n\\label{fACE2}\n\t&\\varepsilon \\frac{du}{dt}(t) + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t)= \\beta(t),  &\\beta(t)\\in\\mathcal{B}(u(t)).\n\\end{align}\nWe frequently will refer to just $u$ as a solution to \\eqref{fACE2}, since $\\beta$ is a.e. uniquely determined as a function of $u$ by \\eqref{beta2}.\n\\end{mydef}\n\nWe now demonstrate that this has the same key properties, \\emph{mutatis mutandis}, as the ACE in \\cite{Budd}.\n\n\\begin{thm}\\label{fACEthm}\nLet %$(u,\\beta)$ be as in Definition \\ref{ACEdef}, with \n$T=[0,T_0]$ or $[0,\\infty)$. %and unless otherwise stated let $(u,\\beta)$ be as in Definition \\ref{ACEdef}. \nThen\\emph{:}\n\\begin{enumerate}[\\emph{(}a\\emph{)}]\n\\item \\emph{(}Existence\\emph{)} For any given $u_0\\in\\V_{[0,1]}$, there exists a $(u,\\beta)$ as in Definition \\ref{ACEdef} with $u(0)=u_0$. \n\\item \\emph{(}Comparison principle\\emph{)} If $(u,\\beta),(v,\\gamma)\\in\\V_{[0,1],t\\in T}\\times\\V_{t\\in T}$ with $u,v\\in H_{loc}^1(T;\\V)\\cap C^0(T;\\V)$ satisfy\n\\begin{align}\n\\label{fACEsuper}\n\t&\\varepsilon \\frac{du}{dt}(t) + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t)\\geq \\beta(t),  &\\beta(t)\\in\\mathcal{B}(u(t)),\\\\\n\\intertext{and}\n\\label{fACEsub}\n\t&\\varepsilon \\frac{dv}{dt}(t) + \\varepsilon Av(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-v(t)\\leq \\gamma(t),  &\\gamma(t)\\in\\mathcal{B}(v(t)),\n\\end{align}\nvertexwise at a.e. $t\\in T$, and $v(0)\\leq u(0)$ vertexwise, then $v(t) \\leq u(t)$ vertexwise for all $t\\in T$.\n\\item \\emph{(}Uniqueness\\emph{)} If $(u,\\beta)$ and $(v,\\gamma)$ are as in Definition \\ref{ACEdef} with $u(0)=v(0)$ then $u(t)=v(t)$ for all $t\\in T$ and $\\beta(t)=\\gamma(t)$ at a.e. $t\\in T$.\n\\item \\emph{(}Gradient flow\\emph{)} For $u$ as in Definition \\ref{ACEdef}, $\\fGL(u(t))$ monotonically decreases.\n\\item \\emph{(}Weak form\\emph{)} $u\\in\\V_{[0,1],t\\in T}\\cap H^1_{loc}(T;\\V)\\cap C(T;\\V)$ \\emph{(}and associated $\\beta(t)= \\varepsilon \\frac{du}{dt}(t) + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t)$ a.e.\\emph{)} is a solution to \\eqref{fACE2} if and only if for almost every $t\\in T$ and all $\\eta\\in\\V_{[0,1]}$\n\\be\\label{fACEweak}\n\\left\\langle \\varepsilon \\frac{du}{dt} + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t) ,\\eta-u(t)\\right\\rangle_\\V\\geq 0.\n\\ee\n\\item \\emph{(}Explicit form\\emph{)} $(u,\\beta)\\in\\V_{[0,1],t\\in T}\\times\\V_{t\\in T}$ satisfies Definition \\ref{ACEdef} if and only if for a.e. $t\\in T$, $\\beta(t)\\in\\mathcal{B}(u(t))$, $\\beta(t)\\in\\V_{[-1/2,1/2]}$ and \\emph{(}for $B := A - \\varepsilon^{-1}I$ and $\\varepsilon^{-1}\\notin\\sigma(A)$\\emph{):} \n\\be\n\\label{fACEsoln}\nu(t)=e^{-tB} u(0)+B^{-1}\\left(I-e^{-tB} \\right)\\left(\\mu f-\\frac{1}{2\\varepsilon}\\mathbf{1} \\right)+ \\frac{1}{\\varepsilon}\\int_0^t e^{-(t-s)B}\\beta(s) \\; ds .\n\\ee \n\\item  \\emph{(}Lipschitz regularity\\emph{)} For $u$ as in Definition \\ref{ACEdef}, if $\\varepsilon^{-1}\\notin\\sigma(A)$, then $u\\in C^{0,1}(T;\\V)$.\n\\item \\emph{(}Well-posedness\\emph{)} Let $u_0,v_0\\in\\V_{[0,1]}$ define the ACE trajectories $ u, v$ as in Definition \\ref{ACEdef}, and suppose\n$\\varepsilon^{-1}\\notin\\sigma(A)$. Then, for $\\xi_1:=\\min\\sigma(A)$, \n\\be\\label{fACEstab2}\n|| u(t)- v(t)||_\\V \\leq e^{-\\xi_1 t}e^{t/\\varepsilon}||u_0-v_0||_\\V.\n\\ee\n\\end{enumerate}\n\\end{thm}\n\\begin{proof}\n\\begin{enumerate}[(a)]\n\\item We prove this as Theorem \\ref{SDlimit}.\n\\item We follow the proof of \\cite[Theorem B.2]{Budd}. Letting $w := v-u$ and subtracting \\eqref{fACEsuper} from \\eqref{fACEsub}, we have that \n\\[\n\\varepsilon\\frac{dw}{dt}(t) + \\varepsilon A w(t) - w(t) \\leq \\gamma(t)-\\beta(t)\n\\]\nvertexwise at a.e. $t\\in T$. Next, take the inner product with $w_+:=\\operatorname{max}(w,0)$, the vertexwise positive part of $w$:\n\\[\\varepsilon\\left\\langle\\frac{dw}{dt}(t),w_+(t)\\right\\rangle_\\V+\\varepsilon\\ip{A w(t),w_+(t)} -\\ip{w(t),w_+(t)} \\leq \\ip{\\gamma(t)-\\beta(t),w_+(t)}. \\] \nAs in the proof of \\cite[Theorem B.2]{Budd}, the $RHS\\leq 0$. For the rest of the proof to go through as in that Theorem, it suffices to check that $\\ip{A w(t),w_+(t)} \\geq \\ip{A w_+(t),w_+(t)} $. But by \\cite[Proposition B.1]{Budd}, $\\ip{\\Delta w(t),w_{+}(t)} \\geq \\ip{\\Delta w_{+}(t),w_{+}(t)}$, and it is clear that $\\ip{P_Z w(t),w_{+}(t)} = \\ip{P_Z w_{+}(t),w_{+}(t)}$, so the proof follows as in \\cite[Theorem B.2]{Budd}. \n\\item Follows from (b): if $(u,\\beta)$ and $(v,\\gamma)$ have $u(0)=v(0)$ and both solve \\eqref{fACE2}, then applying the comparison principle in both directions gives that $u(t)=v(t)$ at all $t\\in T$. Then \\eqref{beta2} gives that $\\beta(t)=\\gamma(t)$ at a.e. $t\\in T$.\n\\item We prove this in Theorem \\ref{fGLthm} for the solution given by Theorem \\ref{SDlimit}, which by uniqueness is the general solution.\n\\item Let $u$ solve \\eqref{fACE2}. Then for a.e. $t\\in T$, $\\beta(t)\\in\\mathcal{B}(u(t))$, and at such $t$ we have $\\ip{\\beta(t),\\eta-u(t)}\\geq 0$ for all $\\eta\\in\\V_{[0,1]}$ as in the proof of \\cite[Theorem 3.8]{Budd}, so $u$ satisfies \\eqref{fACEweak}. Next, if $u$ satisfies \\eqref{fACEweak} at $t\\in T$, then as in the proof of \\cite[Theorem 3.8]{Budd}, $\\beta(t):= \\varepsilon \\frac{du}{dt}(t) + \\varepsilon Au(t)-\\varepsilon\\mu f +\\frac{1}{2}\\mathbf{1}-u(t)\\in\\mathcal{B}(u(t))$, as desired.\n\\item Let $(u,\\beta)\\in\\V_{[0,1],t\\in T}\\times\\V_{t\\in T}$. \\textbf{If:} We check that \\eqref{fACEsoln} satisfies \\eqref{fACE2}. Note first that we can rewrite \\eqref{fACE2} as \n\\[\n\\frac{du}{dt}(t) + Bu(t) -\\mu f + \\frac{1}{2\\varepsilon}\\mathbf{1} = \\frac{1}{\\varepsilon}\\beta(t).\n\\]\nNext, let $u$ be as in \\eqref{fACEsoln}. Then it is easy to check that \n\\[\n\\frac{du}{dt}(t) = -Be^{-tB}u(0) +e^{-tB}\\left( \\mu f - \\frac{1}{2\\varepsilon}\\mathbf{1}\\right) + \\frac{1}{\\varepsilon}\\beta(t) - \\frac{1}{\\varepsilon}B\\int_0^t e^{-(t-s)B}\\beta(s) \\; ds \n\\]\nand that this satisfies \\eqref{fACE2}. Next, we check the regularity of $u$. The continuity of $u$ is immediate, as it is a sum of two smooth terms and the integral of a locally bounded function. To check that $u\\in H^1_{loc}$: $u$ is bounded, so is locally $L^2$, and by above $du/dt$ is a sum of (respectively) two smooth functions, a bounded function and the integral of a locally bounded function, so is locally bounded and hence locally $L^2$. \\\\\n\\textbf{Only if:} We saw that \\eqref{fACEsoln} solves \\eqref{fACE2} with $\\beta(t)\\in\\mathcal{B}(u(t))$ and $\\beta(t)\\in\\V_{[-1/2,1/2]}$, and by (c) such solutions are unique.\n\\item We follow the proof of \\cite[Theorem 3.13]{Budd}. Let $0\\leq t_1<t_2$. Since \\eqref{fACE2} is time-translation invariant, we have by (f) that \n\\[\nu(t_2)= e^{-(t_2-t_1)B} u(t_1)+B^{-1}\\left(I-e^{-(t_2-t_1)B} \\right)\\left(\\mu f-\\frac{1}{2\\varepsilon}\\mathbf{1} \\right)+ \\frac{1}{\\varepsilon}\\int_0^{t_2-t_1} e^{-sB}\\beta(t_2-s) \\; ds \n\\]\nand so, writing $B_{s}:=(e^{-s B}-I)/s$ for $s>0$ (which we note commutes with $B$),\n\\[\nu(t_2)-u(t_1)= (t_2-t_1)B_{t_2-t_1}\\left( u(t_1)-B^{-1}\\left(\\mu f-\\frac{1}{2\\varepsilon}\\mathbf{1} \\right)\\right)+ \\frac{1}{\\varepsilon}\\int_0^{t_2-t_1} e^{-sB}\\beta(t_2-s) \\; ds .\n\\]\nNote that $B_s$ is self-adjoint, and as $-B$ has largest eigenvalue less than $\\varepsilon^{-1}$ we have $||B_{ s}||<(e^{s/\\varepsilon}-1)/s$, with RHS monotonically increasing in $s$ for $s>0$.\\footnote{$\\frac{d}{ds}((e^{s/\\varepsilon}-1)/s) = s^{-2}e^{s/\\varepsilon}\\left(e^{-s/\\varepsilon}-1+s/\\varepsilon\\right)>0$ for $s>0$.} Since $\\beta(t)\\in\\V_{[-1/2,1/2]}$ and $u(t),f \\in\\V_{[0,1]}$ for all $t$, for $t_2-t_1<1$ we have:\n \\begin{equation*}\\begin{split}\\frac{\\left|\\left| u(t_2)- u(t_1)\\right|\\right|_\\V}{t_2-t_1}&\\leq ||B_{t_2-t_1}||\\cdot \\left(1+\\mu ||B^{-1}||+ \\frac{1}{2\\varepsilon}||B^{-1}||\\right)||\\mathbf{1}||_\\V +\\frac{1}{\\varepsilon} \\underset{s\\in [0,t_2-t_1]}{\\text{ess sup}} \\left|\\left|e^{-sB}\\beta(t_2-s)  \\right|\\right|_\\V \\\\\n &<  \\frac{e^{(t_2-t_1)/\\varepsilon}- 1}{ t_2-t_1 }\\cdot  \\left(1+\\mu ||B^{-1}||+ \\frac{1}{2\\varepsilon}||B^{-1}||\\right)||\\mathbf{1}||_\\V + \\frac{1}{\\varepsilon}\\sup_{s\\in [0,t_2-t_1]} \\left|\\left|e^{-sB}\\right|\\right| \\cdot \\frac{1}{2}||\\mathbf{1}||_\\V \\\\\n&\\leq \\frac{e^{(t_2-t_1)/\\varepsilon}- 1}{ t_2-t_1 }\\cdot  \\left(1+\\mu ||B^{-1}||+ \\frac{1}{2\\varepsilon}||B^{-1}||\\right)||\\mathbf{1}||_\\V + \\frac{1}{\\varepsilon} e^{(t_2-t_1)/\\varepsilon}  \\cdot \\frac{1}{2}||\\mathbf{1}||_\\V \\\\\n&< \\left (\\left(1+\\mu ||B^{-1}||+ \\frac{1}{2\\varepsilon}||B^{-1}||\\right)\\left(e^{1/\\varepsilon}  -1\\right) + \\frac{1}{2\\varepsilon}e^{1/\\varepsilon}\\right)  ||\\mathbf{1}||_\\V\n\\end{split}\\end{equation*} and for $t_2 -t_1\\geq 1$ we simply have\n\\[\\frac{\\left|\\left| u(t_2)- u(t_1)\\right|\\right|_\\V}{t_2-t_1}\\leq \\left|\\left| u(t_2)- u(t_1)\\right|\\right|_\\V \\leq ||\\mathbf{1}||_\\V \\] completing the proof. \n\\item We prove this as Theorem \\ref{fACEstab} for the solution given by Theorem \\ref{SDlimit}, which by uniqueness is the general solution. \n\\end{enumerate}\n\\vspace{-1.5\\baselineskip}\n\\end{proof}\n\\begin{nb}\nGiven the various forward references in the above proof, we take care to avoid circularity by not using the corresponding results until they have been proven.\n%The comparison principle in (b) gives a justification for restricting that solutions to   \n\\end{nb}\n\\subsection{The SDIE scheme with fidelity forcing and link to the MBO scheme}\n%Following \\cite{Budd}, we define the SDIE scheme for \\eqref{fACE2}.\n\\begin{mydef}[SDIE scheme with fidelity forcing, cf. \\text{\\cite[Definition 4.1]{Budd}}]\n\\label{fSDdef}\nFor $u_0\\in\\V_{[0,1]}$, $n\\in\\mathbb{N}$, and $\\lambda:=\\tau/\\varepsilon\\in[0,1]$ we define the SDIE scheme iteratively\\emph{:}\n\\be\n\\label{fSD}\n(1-\\lambda)u_{n+1} -\\mathcal{S}_\\tau u_n+\\frac{\\lambda}{2}\\mathbf{1} =\\lambda\\beta_{n+1}\n\\ee\nfor a $\\beta_{n+1}\\in \\mathcal{B}(u_{n+1})$ to be characterised in Theorem \\ref{obsMMthm}.\n\\end{mydef}\nAs in \\cite{Budd}, we have the key theorem linking the MBO scheme and the SDIE schemes for the ACE.\n\\begin{thm}[Cf. \\text{\\cite[Theorem 4.2]{Budd}}]\n\\label{obsMMthm}\nFor $\\lambda\\in[0,1]$, the pair $(u_{n+1},\\beta_{n+1})$ is a solution to the SDIE scheme \\eqref{fSD} for some $\\beta_{n+1}\\in\\mathcal{B}(u_{n+1})$ if and only if $u_{n+1}$ solves\\emph{:}\n \\begin{equation}\n\t\\label{fSDvar}\n\tu_{n+1}\\in \\underset{u\\in \\V_{[0,1]}}{ \\argmin }  \\: \\lambda\\left\\langle u,\\mathbf{1}-u\\right \\rangle_\\V +  \\left|\\left|u-\\mathcal{S}_\\tau u_n\\right|\\right|^2_\\V.\n\\end{equation}\nNote that for $\\lambda = 1$ \\eqref{fSDvar} is equivalent to the variational problem \\eqref{fMBOvar} that defines the MBO scheme. Furthermore, \\eqref{fSDvar} has unique solution for $\\lambda\\in[0,1)$ \n\\begin{equation}\\label{fSDsoln1}\n\t(u_{n+1})_i=\\begin{cases}\n\t\t0, &\\text{if } \\left(\\mathcal{S}_\\tau u_n\\right)_i < \\frac{1}{2}\\lambda,\n\\\\\n\t\t\\frac{1}{2} + \\frac{\\left( \\mathcal{S}_\\tau u_n\\right)_i - 1/2}{1-\\lambda}\n, &\\text{if }\\frac{1}{2}\\lambda\n\\leq\\left(\\mathcal{S}_\\tau u_n\\right)_i < 1-\\frac{1}{2}\\lambda,\n\\\\\n\t\t1, &\\text{if } \\left(\\mathcal{S}_\\tau u_n\\right)_i \\geq 1-\\frac{1}{2}\\lambda,\n\t\\end{cases}\n\\end{equation}\nwith corresponding $\\beta_{n+1} = \\lambda^{-1}\\left((1-\\lambda)u -\\mathcal{S}_\\tau u_n+\\frac{\\lambda}{2}\\mathbf{1}\\right)$, and solutions for $\\lambda = 1$ \n\\be\n(u_{n+1})_i \\in \\begin{cases}\n\t\\{1\\}, &(\\mathcal{S}_\\tau u_n)_i > 1/2,\\\\\n\t[0,1], &(\\mathcal{S}_\\tau u_n)_i = 1/2,\\\\\n\t\\{0\\}, &(\\mathcal{S}_\\tau u_n)_i < 1/2.\n\\end{cases} \\ee\n(i.e. the MBO thresholding) with corresponding $\\beta_{n+1} = \\frac{1}{2}\\mathbf{1}- \\mathcal{S}_\\tau u_n $.\n\\end{thm}\n\\begin{proof}\nIdentical to the proof of \\cite[Theorem 4.2]{Budd} with the occurrences of ``$e^{-\\tau\\Delta}$'' in each instance replaced by ``$\\mathcal{S}_\\tau $''.\n%We follow \\cite{Budd}. Let $(u_{n+1},\\beta_{n+1})$ solve \\eqref{fSD}. Then $\\mathcal{B}(u_{n+1})$ is non-empty, so $u_{n+1}\\in\\V_{[0,1]}$. We now show that for $0\\leq\\lambda\\leq 1$ and $\\forall\\eta\\in\\V_{[0,1]}$:\n%\\[\n%\\lambda\\ip{u_{n+1},\\mathbf{1}-u_{n+1}}+ \\left\\langle u_{n+1}-\\mathcal{S}_\\tau u_n,u_{n+1}-\\mathcal{S}_\\tau u_n\\right \\rangle_\\V \\leq \\lambda\\ip{\\eta,\\mathbf{1}-\\eta}+ \\left\\langle \\eta-\\mathcal{S}_\\tau u_n,\\eta-\\mathcal{S}_\\tau u_n\\right \\rangle_\\V \n%\\]\n%By rearranging and cancelling this is equivalent to \\[ \\begin{split}\n%\t0& \\leq  \\left\\langle \\eta-u_{n+1},\\lambda\\mathbf{1}-2 \\mathcal{S}_\\tau u_n \\right \\rangle_\\V + (1-\\lambda)\\left(\\ip{\\eta,\\eta}-\\ip{u_{n+1},u_{n+1}}\\right)\\\\\n%\t&= \\left\\langle \\eta-u_{n+1},\\lambda\\mathbf{1}-2 \\mathcal{S}_\\tau u_n +(1-\\lambda)(\\eta+u_{n+1}) \\right \\rangle_\\V\\\\\n%\t&= \\left\\langle \\eta-u_{n+1},2\\lambda\\beta_{n+1} +(1-\\lambda)(\\eta-u_{n+1}) \\right \\rangle_\\V \\\\\n%\t&= 2\\lambda\\left\\langle \\eta-u_{n+1},\\beta_{n+1}\\right \\rangle_\\V +(1-\\lambda)||\\eta-u_{n+1}||^2_\\V \n%\\end{split}  \\] \n%but it is easy to check from \\eqref{beta} that $(\\beta_{n+1})_i$ is either zero, when $(u_{n+1})_i\\in(0,1)$, or has the same sign as $\\eta_i -(u_{n+1})_i$ since $\\eta_i\\in [0,1]$, so $\\left\\langle \\eta-u_{n+1},\\beta_{n+1}\\right \\rangle_\\V\\geq 0$.\n%\n%Now let $u$ solve \\eqref{fSDvar}. The functional in \\eqref{fSDvar} can be written \\[ \\lambda\\left\\langle u,\\mathbf{1}-u\\right \\rangle_\\V +  \\left|\\left|u-\\mathcal{S}_\\tau u_n\\right|\\right|^2_\\V = \\sum_{i\\in V} d_i^r f_i(u_i)\\] where \\[ f_i(x) :=\\lambda x(1-x) + \\left(x-\\left(\\mathcal{S}_\\tau u_n\\right)_i\\right)^2 \\] so we can reduce \t\\eqref{fSDvar} to the system of 1-dimensional problems \\[ (u_{n+1})_i \\in \\underset{x\\in [0,1]}{ \\argmin } \\:f_i(x).\\]\n%Differentiating, we get that for $0\\leq\\lambda < 1$ $f_i$ is minimised at  \n%\\[\n%\tx = \\frac{\\left(\\mathcal{S}_\\tau u_n\\right)_i - \\lambda/2}{1-\\lambda} = \\frac{1}{2} + \\frac{\\left(\\mathcal{S}_\\tau u_n\\right)_i - 1/2}{1-\\lambda}.\n%\\]\n%Therefore for $0\\leq \\lambda<1$ the solution $u$ is given by \n%\\begin{equation*}\n%\tu_i=\\begin{cases}\n%\t\t0, &\\text{ if } \\left(e^{-\\tau\\Delta}u_n\\right)_i < \\frac{1}{2}\\lambda\n%\\\\\n%\t\t\\frac{1}{2} + \\frac{\\left(e^{-\\tau\\Delta}u_n\\right)_i - 1/2}{1-\\lambda}\n%, &\\text{ if }\\frac{1}{2}\\lambda\n%\\leq\\left(e^{-\\tau\\Delta}u_n\\right)_i < 1-\\frac{1}{2}\\lambda\n%\\\\\n%\t\t1, &\\text{ if } \\left(e^{-\\tau\\Delta}u_n\\right)_i \\geq 1-\\frac{1}{2}\\lambda\n%\t\\end{cases}\n%\\end{equation*}\n%and hence \n%\\[\\lambda^{-1}\\left((1-\\lambda)u_i -(e^{-\\tau\\Delta}u_n)_i+\\frac{\\lambda}{2}\\right) =\\begin{cases}\n%\t\t\\frac{1}{2}-\\lambda^{-1}(e^{-\\tau\\Delta}u_n)_i, &\\text{ if } \\left(e^{-\\tau\\Delta}u_n\\right)_i < \\frac{1}{2}\\lambda, \\\\\n%\t\t0, &\\text{ if }\\frac{1}{2}\\lambda\n%\\leq\\left(e^{-\\tau\\Delta}u_n\\right)_i < 1-\\frac{1}{2}\\lambda,\n%\\\\\n%\t\t-\\frac{1}{2}+\\lambda^{-1}(1-(e^{-\\tau\\Delta}u_n)_i), &\\text{ if } \\left(e^{-\\tau\\Delta}u_n\\right)_i \\geq 1-\\frac{1}{2}\\lambda.\n%\t\\end{cases}\\]\n%Thus $\\beta = \\lambda^{-1}\\left((1-\\lambda)u -e^{-\\tau\\Delta}u_n+\\frac{\\lambda}{2}\\mathbf{1}\\right) \\in\\mathcal{B}(u)$, so $u$ solves \\eqref{SDobs}.\n%\n%If $\\lambda=1$ then examine the functional in \\eqref{ACEobsMM} for $\\lambda = 1$:\n%\\be\\label{lamb1}\\begin{split}\n%%\\hspace*{-0.2em}\n%&\\left\\langle u,\\mathbf{1}-u\\right \\rangle_\\V +  \\left|\\left|u-e^{-\\tau\\Delta}u_n\\right|\\right|^2_\\V\\\\&=\\ip{u,\\mathbf{1}-u}+ \\left\\langle u-e^{-\\tau\\Delta}u_n,u-e^{-\\tau\\Delta}u_n\\right \\rangle_\\V\\\\ \n%&= \\ip{u,\\mathbf{1}} -\\ip{u,u} + \\ip{u,u} - 2 \\left\\langle u,e^{-\\tau\\Delta}u_n\\right \\rangle_\\V +  \\left\\langle e^{-\\tau\\Delta}u_n,e^{-\\tau\\Delta}u_n\\right \\rangle_\\V\\\\\n%&\\simeq \\left\\langle u,\\mathbf{1}-2e^{-\\tau\\Delta}u_n\\right \\rangle_\\V, \n%\\end{split}\\ee\n%and therefore $u$ as a minimiser must obey \\[u_i \\in \\begin{cases}\n%\t\\{1\\}, &(e^{-\\tau\\Delta}u_n)_i > 1/2,\\\\\n%\t[0,1], &(e^{-\\tau\\Delta}u_n)_i = 1/2,\\\\\n%\t\\{0\\}, &(e^{-\\tau\\Delta}u_n)_i < 1/2.\n%\\end{cases} \\]\n%Hence $\\beta\\in\\mathcal{B}(u)$ if and only if for each $i\\in V$ \n%\\[\n%\\beta_i\\in\\begin{cases}\n%\t\t[0,\\infty), & (e^{-\\tau\\Delta}u_n)_i \\leq 1/2\\\\\n%\t\t\\{0\\}, &(e^{-\\tau\\Delta}u_n)_i = 1/2, u_i\\in(0,1)\\\\\n%\t\t(-\\infty,0], & (e^{-\\tau\\Delta}u_n)_i \\geq 1/2\n%\t\\end{cases}\n%\\]\n%and thus $\\frac{1}{2}\\mathbf{1}- e^{-\\tau\\Delta}u_n\\in\\mathcal{B}(u)$, so $u$ solves \\eqref{SDobs}.\n\\end{proof}\nAs in \\cite{Budd}, we can plot \\eqref{fSDsoln1} to visualise the SDIE scheme \\eqref{fSD} as a piecewise linear relaxation of the MBO thresholding rule.\n\\begin{figure}[h] \n\\centering\n\\begin{tikzpicture}\n\\begin{axis}[\n\t%scale only axis,\n\theight = 6cm,\n    axis lines = left,axis line style={-},\n    xlabel = $\\left(\\mathcal{S}_\\tau u_n\\right)_i$,\n    ylabel = {$(u_{n+1})_i$},\n    xtick={0,0.5,1},\n    ytick={0,0.5,1},\n    legend pos=south east,\n    extra x ticks={0.15,0.85},\n    extra x tick style={\n    tick label style={\n    ,anchor=north}},\n    extra x tick labels={$\\frac{1}{2}\\lambda$,$1-\\frac{1}{2}\\lambda$},\nxmin=0,xmax=1\n]\n\n\\addplot [\n    domain=0:0.15, \n    samples=100, \n    color=blue,\n]\n{0};\n\n\\addplot [\n    domain=0.15:0.85, \n    samples=100, \n    color=blue,\n]\n{0.5 + (x-0.5)/0.7};\n\\addplot [\n    domain=0.85:1, \n    samples=100, \n    color=blue,\n]\n{1};\n\\end{axis}\n\\begin{axis}[\n%scale only axis,\nheight = 6cm,\naxis y line*=right,\naxis x line=none,\n\taxis line style={-},\n    ylabel = {$(\\beta_{n+1})_i$},\n    ytick={-0.5,0,0.5},\nxmin=0,xmax=1,ymin=-0.5,ymax=0.5]\n\n\\addplot [\n    domain=0:0.15, \n    samples=100, \n    color=red,\n]\n{0.5-x/0.3};\n\n\\addplot [\n    domain=0.15:0.85, \n    samples=100, \n    color=red,\n]\n{0};\n\\addplot [\n    domain=0.85:1, \n    samples=100, \n    color=red,\n]\n{-0.5+(1-x)/0.3};\n\\end{axis}\n\\end{tikzpicture}\n\\caption{Plot of the SDIE updates $u_{n+1}$ (blue, left axis, see \\eqref{fSDsoln1}) and $\\beta_{n+1}$ (red, right axis) at vertex $i$ for $0\\leq\\lambda <1$ as a function of the fidelity forced diffused value at $i$. Cf. \\cite[Fig. 1]{Budd}.} \n\\label{SDfig}\n\\end{figure} \nNext, we note that we have the same Lipschitz continuity property from~\\cite{Budd}.\n\\begin{thm}[\\text{Cf. \\cite[Theorem 4.4]{Budd}}]\nFor $\\lambda \\in[0,1)$\\footnote{For the MBO case $\\lambda = 1$ the thresholding is discontinuous so we do not get an analogous property.} and all $n\\in\\mathbb{N}$, if $u_n$ and $v_n$ are defined according to Definition \\ref{fSDdef} with initial states $u_0,v_0\\in\\V_{[0,1]}$ and $\\xi_1 := \\min\\sigma(A)$ then \n\\be\\label{fSDstab}\n||u_n-v_n||_\\V \\leq e^{-n\\xi_1 \\tau}(1-\\lambda)^{-n}||u_0-v_0||_\\V.\n\\ee\n\\end{thm}\n\\begin{proof} Follows as in \\cite[Theorem 4.4]{Budd} \\emph{mutatis mutandis}.\n%Let $\\rho_\\lambda:\\V_{[0,1]}\\rightarrow\\V_{[0,1]}$ be the thresholding operator in \\eqref{fSDsoln1}, i.e. \n%\\[\n%(\\rho_\\lambda(u))_i:=\\begin{cases}\n%\t\t0, &\\text{if } u_i < \\frac{1}{2}\\lambda,\n%\\\\\n%\t\t\\frac{1}{2} + \\frac{u_i - 1/2}{1-\\lambda}\n%, &\\text{if }\\frac{1}{2}\\lambda\n%\\leq u_i < 1-\\frac{1}{2}\\lambda,\n%\\\\\n%\t\t1, &\\text{if } u_i \\geq 1-\\frac{1}{2}\\lambda.\n%\t\\end{cases}\n%\\]\n%Then by the above theorem it follows that \n%\\[\n%u_n = (\\rho_\\lambda \\circ \\mathcal{S}_\\tau)^n(u_0) \n%\\]\n%and likewise for $v_n$. Finally, note that $\\mathcal{S}_\\tau u$ is affine in $u$, and hence is Lipschitz with constant $e^{-\\lambda_1\\tau}$, and $\\rho_\\lambda(u)$ is piecewise affine in $u$ with greatest slope $(1-\\lambda)^{-1}$ and hence is Lipschitz with constant $(1-\\lambda)^{-1}$. Thus $(\\rho_\\lambda \\circ \\mathcal{S}_\\tau)^n$ is Lipschitz with constant $e^{-n\\tau\\lambda_1}(1-\\lambda)^{-n}$.\n\\end{proof}\n\\subsection{A Lyapunov functional for the SDIE scheme}\n\\begin{lem}[\\text{Cf. \\cite[Lemma 4.6]{vGGOB}}] The functional on $\\V$ \\begin{equation*}\n\tJ(u) := \\ip{u,\\mathbf{1}-2\\mu A^{-1}(I - e^{-\\tau A})f-e^{-\\tau A}u}\n\\end{equation*}\nhas the following properties\\emph{:}\n\\begin{enumerate}[i.]\n\\item It is strictly concave.\n\\item It has first variation at $u$ \\[ L_u(v) := \\left\\langle v,\\mathbf{1}-2\\mu A^{-1}(I - e^{-\\tau A})f-2e^{-\\tau A}u\\right \\rangle_\\V = \\left\\langle v,\\mathbf{1}-2\\mathcal{S}_\\tau u\\right \\rangle_\\V. \\] \n\\end{enumerate}\n\\end{lem}\n\\begin{proof}\nLet $w: = \\mathbf{1}-2\\mu A^{-1}(I - e^{-\\tau A})f$. We expand around $u$: \\[\\begin{split}J(u+tv) &= \\ip{u+tv, w- e^{\\tau A}(u+tv)} \\\\\n&= \\ip{u, w- e^{\\tau A}u} +t \\ip{v, w- e^{\\tau A}u}-t\\ip{u,e^{-tA}v} - t^2\\ip{v,e^{-\\tau A} v}.\\end{split}\\] \n\\begin{enumerate}[i.]\n\\item $\\frac{d^2}{dt^2}J(u+tv) = -2\\ip{v,e^{-\\tau A} v} <0$ for $v\\neq \\mathbf{0}$.\n\\item Since $e^{-tA}$ is self-adjoint, $J(u+tv) =  J(u) + tL_u(v) +\\bigO(t^2)$.\n\\end{enumerate}\n\\vspace{-1.5\\baselineskip}\n\\end{proof}\n\\begin{thm}[Cf. \\text{\\cite[Theorem 4.9]{Budd}}]\n\\label{fLyapthm}\n\tFor $0\\leq\\lambda\\leq 1$ we define on $\\V_{[0,1]}$ the functional \n\t\\begin{equation}\\label{Lyap}\n\tH(u):= J(u) + (\\lambda-1)\\ip{u,\\mathbf{1}-u} .\n\t\\end{equation}\n\tThis has uniform lower bound \\be H(u) \\geq -2\\mu \\tau||f||_\\V||\\mathbf{1}||_\\V \\ee and is a Lyapunov functional for \\eqref{fSD}, i.e. $H(u_{n+1}) \\leq H(u_n)$ with equality if and only if $u_{n+1}=u_n$ for $u_{n+1}$ defined by \\eqref{fSD}. In particular, we have that \\begin{equation}\\label{Hstep}\n\t\tH(u_n)-H(u_{n+1}) \\geq (1-\\lambda)\\left|\\left|u_{n+1}-u_n\\right|\\right|^2_\\V.\n\t\\end{equation} \n\\end{thm}\n\\begin{proof}\nWe can rewrite $H$ as:\n\\begin{align*}\nH(u) &= \\lambda\\ip{u,\\mathbf{1}-u} + \\ip{u,u-2\\mu A^{-1}(I - e^{-\\tau A})f-e^{-\\tau A}u}&&&\\\\\n&\\geq \\ip{u,(I-e^{-\\tau A})u} - 2\\mu\\ip{u,A^{-1}(I - e^{-\\tau A})f}& &\\text{since $u\\in\\V_{[0,1]}$}&\\\\ \n&\\geq - 2\\mu\\ip{u,A^{-1}(I - e^{-\\tau A})f}& &\\text{since $I - e^{-\\tau A}$ is positive definite }&\\\\\n&\\geq -2\\mu ||f||_\\V||u||_\\V\\left|\\left|A^{-1}(I-e^{-\\tau A})\\right|\\right|\\\\\n&\\geq -2\\mu ||f||_\\V||\\mathbf{1}||_\\V\\left|\\left|A^{-1}(I-e^{-\\tau A})\\right|\\right| \\geq -2\\mu \\tau ||f||_\\V ||\\mathbf{1}||_\\V\n\\end{align*}\nwhere the final line follows since $A^{-1}(I-e^{-\\tau A})$ is self-adjoint (since $A$ is) and has eigenvalues \\[\\left\\{\\frac{1-e^{-\\tau\\lambda}}{\\lambda}\t\\;\\middle|\\; \\lambda \\in\\sigma(A)\\right\\}\\]\nso we have by Proposition \\ref{Aspec} that\n\\[ \\begin{split}\\left|\\left|A^{-1}(I-e^{-\\tau A})\\right|\\right| &\\leq \\sup_{x\\in(0,||\\Delta||+\\mu]} \\frac{1-e^{-\\tau x}}{x}\\\\\n&= \\lim_{x\\rightarrow 0}  \\frac{1-e^{-\\tau x}}{x}\\quad \\text{ as $x\\mapsto x^{-1}(1-e^{-\\tau x})$ is monotonically decreasing\\footnotemark}\\\\\n&= \\tau. \n\\end{split}\\]\\footnotetext{$\\frac{d}{dx}(x^{-1}(1-e^{-\\tau x}))=x^{-2}e^{-\\tau x}(1+\\tau x-e^{\\tau x}) \\leq 0$.}\n%\\[\\begin{split}\n%\\left|\\left|A^{-1}(I-e^{-tA})\\right|\\right| &= \\left|\\left|\\sum_{n=0}^\\infty  (-1)^n \\frac{t^{n+1}}{(n+1)!} A^n\\right|\\right| \\\\\n%&\\leq \\sum_{n=0}^\\infty  \\frac{t^{n+1}}{(n+1)!} ||A||^n\\\\\n%& = ||A||^{-1}(e^{t||A||} -1) \\leq \\frac{e^{t||\\Delta|| + t\\mu}-1}{||\\Delta|| +\\mu} \\text{ by Proposition \\ref{Aspec}.}\n%\\end{split}\\]\n\tNext we show that $H$ is a Lyapunov functional. By the concavity of $J$:\n\t\\[\\begin{split}\n\tH(u_{n}) - H(u_{n+1}) &= J(u_{n}) - J(u_{n+1}) + (1-\\lambda)\\ip{u_{n+1},\\mathbf{1}-u_{n+1}} - (1-\\lambda)\\ip{u_n,\\mathbf{1}-u_n} \\\\\n\t&\\geq L_{u_n}(u_{n} - u_{n+1}) + (1-\\lambda)\\ip{u_{n+1},\\mathbf{1}-u_{n+1}} - (1-\\lambda)\\ip{u_n,\\mathbf{1}-u_n} \\:\\left(*\\right)\\\\\n%\t&=\\left(\\lambda\\left\\langle u_n,\\mathbf{1}-u_n\\right \\rangle_\\V +  \\left|\\left|u_n-\\mathcal{S}_\\tau u_n\\right|\\right|^2_\\V\\right)-\\left(\\lambda\\left\\langle u_{n+1},\\mathbf{1}-u_{n+1}\\right \\rangle_\\V +  \\left|\\left|u_{n+1}-\\mathcal{S}_\\tau u_n\\right|\\right|^2_\\V\\right)\\\\\n%\t&\\geq 0 \\text{ by \\eqref{fSDvar}}\n&= \\ip{u_{n} - u_{n+1},\\mathbf{1}-2\\mathcal{S}_\\tau u_n} + (1-\\lambda)\\ip{u_{n+1},\\mathbf{1}-u_{n+1}} - (1-\\lambda)\\ip{u_n,\\mathbf{1}-u_n} \\\\\n\t&= \\ip{u_{n} - u_{n+1},\\mathbf{1}-2\\mathcal{S}_\\tau u_n} + (1-\\lambda)(\\ip{u_{n+1}-u_n,\\mathbf{1}} +\\ip{u_n,u_n} -\\ip{u_{n+1},u_{n+1}})\\\\\n\t&= \\ip{u_{n} - u_{n+1},\\lambda\\mathbf{1}-2\\mathcal{S}_\\tau u_n + (1-\\lambda)u_{n+1} + (1-\\lambda)u_n}\\\\\n\t&= \\ip{u_{n} - u_{n+1},2\\lambda\\beta_{n+1}+ (1-\\lambda)(u_n-u_{n+1})} \\text{ by \\eqref{fSD}}\\\\\n\t&\\geq (1-\\lambda)\\left|\\left|u_{n+1}-u_n\\right|\\right|^2_\\V\\geq 0\n\t\\end{split}\n\t\\]\n\twith equality in $(*)$ if and only if $u_{n+1}=u_n$ as the concavity of $J$ is strict, and\n%\n%\t&= \\ip{u_{n} - u_{n+1},\\mathbf{1}-2\\mathcal{S}_\\tau u_n} + (1-\\lambda)\\ip{u_{n+1},\\mathbf{1}-u_{n+1}} - (1-\\lambda)\\ip{u_n,\\mathbf{1}-u_n} \\\\\n%\t&= \\ip{u_{n} - u_{n+1},\\mathbf{1}-2\\mathcal{S}_\\tau u_n} + (1-\\lambda)(\\ip{u_{n+1}-u_n,\\mathbf{1}} +\\ip{u_n,u_n} -\\ip{u_{n+1},u_{n+1}})\\\\\n%\t&= \\ip{u_{n} - u_{n+1},\\lambda\\mathbf{1}-2\\mathcal{S}_\\tau u_n + (1-\\lambda)u_{n+1} + (1-\\lambda)u_n}\\\\\n%\t&= \\ip{u_{n} - u_{n+1},2\\lambda\\beta_{n+1}+ (1-\\lambda)(u_n-u_{n+1})} \\text{ by \\eqref{fSD}}\\\\\n%\t&\\geq (1-\\lambda)\\left|\\left|u_{n+1}-u_n\\right|\\right|^2_\\V\n%\t\\end{split}\n%\t\\]\nwhere the last line follows since by $\\beta_{n+1}\\in\\mathcal{B}(u_{n+1})$\n\\[(\\beta_{n+1})_i((u_{n})_i-(u_{n+1})_i) = \\left. \\begin{cases} \\text{``}\\geq 0\\text{''} \\cdot (u_n)_i, &(u_{n+1})_i = 0\\\\\n0, &(u_{n+1})_i \\in (0,1)\\\\\n\\text{``}\\leq 0\\text{''} \\cdot \\left((u_n)_i-1\\right), &(u_{n+1})_i = 1\n\\end{cases} \\right\\} \\geq 0 \\]\nand so $\\ip{u_{n} - u_{n+1},\\beta_{n+1}}\\geq 0$.\n\\end{proof}\n\\begin{cor}\nFor $\\lambda = 1$ \\emph{(}i.e. the MBO case\\emph{)} the sequence $u_n$ defined by \\eqref{fSD} is eventually constant.\n\nFor $0\\leq \\lambda\\leq 1$, the sum\n\\[\n\\sum_{n=0}^\\infty ||u_{n+1}-u_n||_\\V^2 \n\\]\nconverges, and hence \n\\[\n\\lim_{n\\rightarrow\\infty}  ||u_{n+1}-u_n||_\\V = 0.\n\\]\n\\end{cor}\n\\begin{proof}\nFor the first claim, the proof follows as in \\cite[Proposition 4.6]{vGGOB} \\emph{mutatis mutandis}.\nFor the second claim, the proof follows as in \\cite[Corollary 4.10]{Budd} \\emph{mutatis mutandis}.\n\\end{proof}\n\\subsection{Convergence of the SDIE scheme with fidelity forcing}\nFollowing \\cite{Budd}, we first derive the $n^{\\text{th}}$ term for the semi discrete sceme. \n\\begin{prop}[Cf. \\text{\\cite[Proposition 5.1]{Budd}}]\nFor the sake of notation, define\\emph{:}\n\\[w := -\\frac{1}{2}\\lambda\\mathbf{1} + \\mu A^{-1}(I-e^{-\\tau A})f.\\]\nThen for $\\lambda\\in [0,1)$ the sequence generated by \\eqref{fSD} is given by\\emph{:}\n\\be\n\\label{fSDsoln}\n\\hspace{-2em} u_n =(1-\\lambda)^{-n}e^{-n\\tau A}u_0+\\sum_{k=1}^n (1-\\lambda)^{-k}e^{-(k-1)\\tau A}w+\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-(n-k)}e^{-(n-k)\\tau A}\\beta_k\n\\ee\n\\end{prop}\n\\begin{proof}\nWe can rewrite \\eqref{fSD} as \n\\[(1-\\lambda)u_{n+1}= e^{-\\tau A}u_n +\\mu A^{-1}(I-e^{-tA})f -\\frac{1}{2}\\lambda\\mathbf{1}+\\lambda\\beta_{n+1} = e^{-\\tau A}u_n +w+\\lambda\\beta_{n+1}.  \\]\nWe then check \\eqref{fSDsoln} inductively. The $n=0$ case is trivial, and we have that\n\\[\\begin{split}\n&(1-\\lambda)^{-1}e^{-\\tau A}u_n +\n(1-\\lambda)^{-1}w+\\frac{\\lambda}{1-\\lambda}\\beta_{n+1}\\\\\n &=  (1-\\lambda)^{-(n+1)}e^{-(n+1)\\tau A}u_0+\\sum_{k=1}^n (1-\\lambda)^{-(k+1)}e^{-k\\tau A}w+\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-((n+1)-k)}e^{-((n+1)-k)\\tau A}\\beta_k\\\\\n&\\:\\:+ (1-\\lambda)^{-1}w+\\frac{\\lambda}{1-\\lambda}\\beta_{n+1} \\\\\n&=(1-\\lambda)^{-(n+1)}e^{-(n+1)\\tau A}u_0+\\sum_{k=0}^n (1-\\lambda)^{-(k+1)}e^{-k\\tau A}w+\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^{n+1} (1-\\lambda)^{-((n+1)-k)}e^{-((n+1)-k)\\tau A}\\beta_k\\\\\n&=u_{n+1}\n\\end{split}\\]\ncompleting the proof.\n\\end{proof}\nNext, we consider the asymptotics of each term in \\eqref{fSDsoln}.\n\\begin{thm}\nConsidering $\\bigO$ relative to the limit of $\\tau\\downarrow 0$ and $n\\rightarrow \\infty$ with $n\\tau-t\\in [0,\\tau)$ for some fixed $t\\geq 0$ and for fixed $\\varepsilon>0$ \\emph{(}with $\\varepsilon^{-1}\\notin\\sigma(A)$\\emph{)}\\footnote{More precisely, we will say for real (matrix) valued $g$, $g(\\tau,n)=\\bigO(\\tau)$ if and only if $\\operatorname{limsup} ||g(\\tau,n)/\\tau|| <\\infty$ as $(\\tau,n)\\rightarrow(0,\\infty)$ in $\\{(\\rho,m)\\mid \\rho > 0,\\: m\\rho-t\\in[0,\\rho)\\}$ with the subspace topology induced by the standard topology on $ (0,\\infty)\\times\\mathbb{N}$.}, and recalling that $\\lambda:=\\tau/\\varepsilon$, $B:=A-\\varepsilon^{-1}I$ and $w := -\\frac{1}{2}\\lambda\\mathbf{1} + \\mu A^{-1}(I-e^{-\\tau A})f$\\emph{:}\n\\begin{enumerate}[i.]\n\\item $(1-\\lambda)^{-n}e^{-n\\tau A}u_0 = e^{t/\\varepsilon}e^{-tA}u_0 +\\bigO(\\tau)= e^{-tB}u_0 +\\bigO(\\tau)$.\n\\item $\\sum_{k=1}^n (1-\\lambda)^{-k}e^{-(k-1)\\tau A}w= \\mu B^{-1}(I-e^{-t B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-t B})\\mathbf{1} + \\bigO(\\tau)$.\n\\item $\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-(n-k)}e^{-(n-k)\\tau A}\\beta_k = \\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k + \\bigO(\\tau)$.\n\\end{enumerate}\nHence by \\eqref{fSDsoln}, the SDIE term obeys \n\\be\n\\label{fSDsoln2}\nu_n = e^{-tB}u_0 +  \\mu B^{-1}(I-e^{-t B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-t B})\\mathbf{1}+ \\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k +\\bigO(\\tau).\n\\ee\n\\end{thm}\n\\begin{proof}\nLet $n\\tau - t=:\\eta_n = \\bigO(\\tau)$. Note that $e^{\\eta_nX}= I + \\bigO(\\tau)$ for any bounded matrix $X$.  \n\nNote that $\\bigO(\\tau)$ is the same as $\\bigO(\\lambda)$, and also that, for bounded (in $\\tau$) invertible matrices $X$ and $Y$ with bounded (in $\\tau$) inverses, $X = Y + \\bigO(\\tau)$ if and only if $X^{-1} = Y^{-1} +\\bigO(\\tau)$.\\footnote{Suppose $X^{-1} = Y^{-1} +\\bigO(\\tau)$. Then $X = (Y^{-1} +\\bigO(\\tau))^{-1} = Y(I+\\bigO(\\tau))^{-1}=Y(I+\\bigO(\\tau)) = Y +\\bigO(\\tau)$.} \n\\begin{enumerate}[i.]\n\\item $||(1-\\lambda)^{-n}e^{-n\\tau A}u_0 - e^{-tB}u_0||_\\V \\leq ||(1-\\lambda)^{-n}e^{-n\\tau A}- e^{-tB}||\\cdot||u_0||_\\V$, so it suffices to consider  $(1-\\lambda)^{-n}e^{-n\\tau A}- e^{-tB}$. Since $(1-\\lambda)^{-n} = e^{n\\lambda} +\\bigO(\\tau^2)$ we infer that \n\\[\n(1-\\lambda)^{-n}e^{-n\\tau A} = e^{t/\\varepsilon} e^{\\eta_n/\\varepsilon} e^{-t A}e^{-\\eta_n A} +\\bigO(\\tau^2) = e^{-tB} +\\bigO(\\tau).\n\\]\n\\item We note that \\[\\sum_{k=1}^n (1-\\lambda)^{-k}e^{-(k-1)\\tau A} = ((1-\\lambda)I-e^{-\\tau A})^{-1}(I-(1-\\lambda)^{-n}e^{-n\\tau A})= ((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-tB})+\\bigO(\\tau). \\] We next consider each term of $w$ individually. First, we seek to show that  \n\\[((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-tB})\\mu A^{-1}(I-e^{-\\tau A})f = \\mu B^{-1}(I-e^{-t B})f + \\bigO(\\tau)\\]\nso it suffices to show that  \n\\[((1-\\lambda)I-e^{-\\tau A})^{-1} A^{-1}(I-e^{-\\tau A}) = B^{-1} + \\bigO(\\tau).\\]\nThis holds if and only if \n\\[ \\begin{split} B &= ((1-\\lambda)I-e^{-\\tau A}) A(I-e^{-\\tau A})^{-1} +\\bigO(\\tau)\\\\\n&= A -\\lambda A (I-e^{-\\tau A})^{-1} +\\bigO(\\tau)\\\\\n&= A -\\varepsilon^{-1}\\tau A \\left(\\tau A -\\frac{1}{2}\\tau^2 A^2 +-\\cdots\\right)^{-1}+\\bigO(\\tau)\\\\\n&= A -\\varepsilon^{-1}\\left(I -\\frac{1}{2}\\tau A+-\\cdots\\right)^{-1}+\\bigO(\\tau)\\\\\n&= A -\\varepsilon^{-1}I+\\bigO(\\tau)\n\\end{split} \\]\nand since $B= A -\\varepsilon^{-1}I$ the result follows. Next we seek to show that\n\\[\n ((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-tB})\\frac{1}{2}\\lambda\\mathbf{1} = \\frac{1}{2\\varepsilon}B^{-1}(I-e^{-tB})\\mathbf{1} +\\bigO(\\tau)\n\\]\nso it suffices to show that  \n\\[\n ((1-\\lambda)I-e^{-\\tau A})^{-1}\\tau = B^{-1} +\\bigO(\\tau)\n\\]\nwhich holds if and only if \n\\[\nB =\\tau^{-1} ((1-\\lambda)I-e^{-\\tau A}) +\\bigO(\\tau) = A -\\varepsilon^{-1}I+\\bigO(\\tau)\n\\]\nand since $B= A -\\varepsilon^{-1}I$ the result follows.\n\\item We follow \\cite[Proposition 5.1]{Budd} and consider the difference \n\\[\\begin{split}&\\left |\\left| \\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-(n-k)}e^{-(n-k)\\tau A}\\beta_k - \\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k \\right|\\right|_\\V\\\\\n&=\\lambda \\left |\\left|\\sum_{k=1}^n\\left( (1-\\lambda)^{-(n-k+1)}-e^{(n-k)\\lambda}\\right)e^{-(n-k)\\tau A}\\beta_k \\right|\\right|_\\V\\\\\n&=\\lambda \\left |\\left|\\sum_{\\ell=0}^{n-1}\\left( (1-\\lambda)^{-(\\ell+1)}-e^{\\ell\\lambda}\\right)e^{-\\ell\\tau A}\\beta_k \\right|\\right|_\\V\\\\\n&\\leq\\lambda\\sum_{\\ell=0}^{n-1}\\left( (1-\\lambda)^{-(\\ell+1)}-e^{\\ell\\lambda}\\right)\\left |\\left|e^{-\\ell\\tau A}\\beta_k \\right|\\right|_\\V\\:\\:\\text{as $(1-\\lambda)^{-(\\ell+1)}-e^{\\ell\\lambda}\\geq 0$}\\\\\n&\\leq \\frac{1}{2}\\lambda||\\mathbf{1}||_\\V\\sum_{\\ell=0}^{n-1}\\left( (1-\\lambda)^{-(\\ell+1)}-e^{\\ell\\lambda}\\right)\\:\\:\\text{as $||e^{-\\ell\\tau A}||\\leq 1$ and $||\\beta_k||_\\V\\leq \\frac{1}{2}||\\mathbf{1}||_\\V$}\\\\\n&=  \\frac{1}{2}\\lambda||\\mathbf{1}||_\\V\\left(\\frac{(1-\\lambda)^{-n}-1}{1-(1-\\lambda)}-\\frac{e^{n\\lambda}-1}{e^{\\lambda}-1} \\right)\\\\\n&=\\frac{1}{2}||\\mathbf{1}||_\\V\\left((1-\\lambda)^{-n} -e^{n\\lambda} \\right) + \\bigO(\\tau)\\:\\: \\text{as $\\lambda/(e^\\lambda -1) = 1 + \\bigO(\\tau)$}\\\\\n&=\\bigO(\\tau)\n\\end{split}\\]\nas desired.\n\\end{enumerate}\n\\vspace{-1.5\\baselineskip}\n\\end{proof}\nFollowing \\cite{Budd} we define the piecewise constant function $z_\\tau:[0,\\infty)\\rightarrow\\V$\n\\[z_\\tau(s): =\\begin{cases} e^{\\tau B}\\beta^{[\\tau]}_1, & 0\\leq s \\leq \\tau\\\\\n\t\t\t\t\t\t\t\t\te^{k\\tau B} \\beta^{[\\tau]}_k,\t& (k-1)\\tau<s\\leq k\\tau \\text{ for } k\\in\\mathbb{N}\t\t\t\t\t\t\n\\end{cases}\\]\nand the function \\[\\gamma_\\tau(s):= e^{-sB} z_\\tau(s)=\\begin{cases} e^{(\\tau-s)B}\\beta^{[\\tau]}_1, & 0\\leq s \\leq \\tau\\\\\n\t\t\t\t\t\t\t\te^{(k\\tau-s)B} \\beta^{[\\tau]}_k,\t& (k-1)\\tau<s\\leq k\\tau\t\t\t\\text{ for } k\\in\\mathbb{N}\t\t\t\t\n\\end{cases}\\]\nfollowing the bookkeeping notation of \\cite{Budd} of using the superscript $[\\tau]$ to keep track of the time-step governing $u_n$ and $\\beta_n$.\nNext, we have weak convergence of $z$, up to a subsequence, as in \\cite{Budd}.\n\\begin{thm}\n\\label{convthm}\nFor any sequence $\\tau^{(0)}_n\\downarrow 0$ with $\\tau^{(0)}_n<\\varepsilon$ for all $n$,  there exists a function $z:[0,\\infty) \\rightarrow \\V$ and a subsequence $\\tau_n$ such that $z_{\\tau_n}$ converges weakly to $z$ in $L^2_{loc}$. It follows that\\emph{:}\n\\begin{enumerate}[\\emph{(}A\\emph{)}]\n\\item $\\gamma_{\\tau_n} \\rightharpoonup \\gamma$ in $L^2_{loc}$, where $\\gamma(s) = e^{-sB}z$.\n\\item For all $t\\geq 0$, \\[\\int_0^t z_{\\tau_n}(s)\\; ds \\rightarrow \\int_0^t z(s)\\; ds.\\]\n\\item Passing to a further subsequence of $\\tau_n$, we have strong convergence of the Ces\u00e0ro sums, i.e. for all bounded $T\\subseteq[0,\\infty)$ \\begin{align*}&\\frac{1}{N}\\sum_{n=1}^N z_{\\tau_n} \\rightarrow z &\\text{and} &&\\frac{1}{N}\\sum_{n=1}^N \\gamma_{\\tau_n} \\rightarrow \\gamma && \\text { in } L^2(T;\\V)\\end{align*} as $N\\rightarrow \\infty$. \n\\end{enumerate}\n\\end{thm}\n\\begin{proof}\nFollows as in \\cite[Proposition 5.2]{Budd} and \\cite[Corollary 5.3]{Budd} \\emph{mutatis mutandis}.\n\\end{proof}\nWe thus infer convergence of the SDIE iterates as in \\cite{Budd}. Taking $\\tau$ to zero along the sequence $\\tau_n$, we can define for all $t\\geq 0$: \n\\be\n\\label{uhat}\\hat u(t) := \\lim_{n\\rightarrow\\infty, m =\\ceil{t/\\tau_n}} u^{[\\tau_n]}_m.\n\\ee\nBy the above discussion, we can rewrite this as:\n\\[ \\begin{split}\\hat u(t) &=  e^{-tB}u_0 +  \\mu B^{-1}(I-e^{-t B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-t B})\\mathbf{1}+ \\lim_{n\\rightarrow\\infty} \\frac{\\tau_n}{\\varepsilon}\\sum_{k=1}^m e^{-(m-k)\\tau_n B}\\beta^{[\\tau_n]}_k \\\\\n&= e^{-tB}u_0 +  \\mu B^{-1}(I-e^{-t B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-t B})\\mathbf{1}+ \\frac{1}{\\varepsilon} \\lim_{n\\rightarrow\\infty}e^{-m\\tau_nB}\\int_0^{m\\tau_n} z_{\\tau_n}(s)\\; ds.\n\\end{split}\\]\nNext, note that $m\\tau_n = \\tau_n\\ceil{t/\\tau_n} =: t + \\eta_n$ where $\\eta_n\\in[0,\\tau_n)$. Therefore \n\\[\\begin{split}\n&\\lim_{n\\rightarrow\\infty}e^{-m\\tau_nB}\\int_0^{m\\tau_n} z_{\\tau_n}(s)\\; ds = \\lim_{n\\rightarrow\\infty}e^{-\\eta_nB}e^{-tB}\\int_0^{t} z_{\\tau_n}(s)\\; ds + e^{-\\eta_nB}e^{-tB}\\int_t^{t+\\eta_n} z_{\\tau_n}(s)\\; ds\\\\\n&=\\lim_{n\\rightarrow\\infty}e^{-tB}\\int_0^{t} z_{\\tau_n}(s)\\; ds + e^{-tB}\\int_t^{t+\\eta_n} z_{\\tau_n}(s)\\; ds \\:\\: \\text{ as $e^{-\\eta_nB}=I +\\bigO(\\tau_n)$}\\\\\n&=\\lim_{n\\rightarrow\\infty}e^{-tB}\\int_0^{t} z_{\\tau_n}(s)\\; ds \\:\\: \\text{ as $z_{\\tau_n}(s)$ is bounded on $[t,t+\\max_{n'} \\eta_{n'}]$  uniformly in $n$}\\\\\n&=e^{-tB}\\int_0^t z(s)\\; ds \\:\\:\\text{ by Theorem \\ref{convthm}(B)}.\n\\end{split}\\]\nSo we have that \n\\be\\label{uhatsoln} \\hat u(t) = e^{-tB}u_0 +  \\mu B^{-1}(I-e^{-t B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-t B})\\mathbf{1}+ \\frac{1}{\\varepsilon}\\int_0^t e^{-(t-s)B}\\gamma(s) \\; ds.\n\\ee\nNote the similarity between \\eqref{uhatsoln} and the explicit form for ACE solutions \\eqref{fACEsoln}. Thus, to prove that $\\hat u$ is a solution to \\eqref{fACE2} it suffices to show that: \n\\begin{enumerate}[(a)]\n\\item $\\hat u(t) \\in \\V_{[0,1]}$ for all $t\\geq 0$,\n\\item $\\hat u \\in H^1_{loc}([0,\\infty);\\V) \\cap  C^0([0,\\infty);\\V)$, and\n\\item $\\gamma(t) \\in \\mathcal{B}(\\hat u(t))$ for a.e. $t\\geq 0$.\n\\end{enumerate}\nThese results follow as in \\cite{Budd}. Item (a) follows immediately from the fact that for all $n$, $u_m^{[\\tau_n]}\\in\\V_{[0,1]}$.  \n\nTowards (b), note that each term in \\eqref{uhatsoln} except for the integral is $C^\\infty([0,\\infty);\\V)$, and that $\\int_0^t z(s)\\; ds$ is continuous since $z$ is locally bounded as a weak limit of locally uniformly bounded  functions. Hence $\\hat u$ is continuous. By (a), $\\hat u$ is bounded so is locally $L^2$. Finally, it is easy to check that $\\hat u$ has weak derivative \n\\[\n\\frac{d\\hat u}{dt} = -Be^{-tB}u_0 + e^{-tB}\\left(\\mu f -\\frac{1}{2\\varepsilon}\\mathbf{1}\\right) + \\frac{1}{\\varepsilon}e^{-tB}z(t) -\\frac{1}{\\varepsilon}Be^{-tB}\\int_0^t z(s)\\; ds.\n\\]\nThis is locally $L^2$ since (for $T$ a bounded interval) $B$ and $e^{-tB}$ are bounded operators from $L^2(T;\\V)$ to $L^2(T;\\V)$, $z$ is a weak limit of locally $L^2$ functions so is locally $L^2$, and  $\\int_0^t z(s)\\; ds$ is continuous so is locally bounded.\n\nTowards (c), by Theorem \\ref{convthm}(C) and \\cite[p. 25]{Budd} \\emph{mutatis mutandis} there is a sequence $N_k \\rightarrow \\infty$, independent of $t$, with \n\\[\n\\gamma(t) = \\lim_{k\\rightarrow\\infty}  \\frac{1}{N_k} \\sum_{n=1}^{N_k} \\beta_m^{[\\tau_n]}\n\\] \nfor a.e. $t\\geq 0$. Then, at each such $t$, $\\gamma(t) \\in \\mathcal{B}(\\hat u(t))$  follows from  $u^{[\\tau_n]}_m\\rightarrow\\hat u(t)$ and $\\beta_m^{[\\tau_n]}\\in \\mathcal{B}( u^{[\\tau_n]}_m)$ as in \\cite[p. 25]{Budd}. Hence we can infer the following convergence theorem.\n\\begin{thm}[\\text{Cf. \\cite[Theorem 5.4]{Budd}}]\n\\label{SDlimit}\nFor any given $u_0\\in\\V_{[0,1]}$, $\\varepsilon>0$ \\emph{(}with $\\varepsilon^{-1}\\notin\\sigma(A)$\\emph{)} and $\\tau_n\\downarrow 0$, there exists a subsequence $\\tau'_n$ of $\\tau_n$ with $\\tau'_n<\\varepsilon$ for all $n$, along which the SDIE iterates $(u^{[\\tau'_n]}_m,\\beta^{[\\tau'_n]}_m)$ given by \\eqref{fSD} with initial state $u_0$ converge to the ACE solution with initial condition $u_0$ in the following sense\\emph{:} For each $t\\geq 0$, as $n\\rightarrow\\infty$ and $m=\\ceil{t/\\tau'_n}$, $u^{[\\tau'_n]}_m\\rightarrow \\hat u(t)$, and there is a sequence $N_k\\rightarrow\\infty$ such that for almost every $t\\geq 0$, $\\frac{1}{N_k}\\sum_{n=1}^{N_k}\\beta^{[\\tau'_n]}_m\\rightarrow \\gamma(t)$, where $(\\hat u,\\gamma)$ is the solution to \\eqref{fACE2} with $\\hat u(0) = u_0$. \n\\end{thm}\n\\begin{cor}\\label{SDlimitcor}\nLet $u_0\\in\\V_{[0,1]}$, $\\varepsilon>0$, $\\varepsilon^{-1}\\notin\\sigma(A)$ and $\\tau_n\\downarrow 0$ with $\\tau_n<\\varepsilon$ for all $n$. Then for each $t\\geq 0$, as $n\\rightarrow\\infty$, $u^{[\\tau_n]}_{\\ceil{t/\\tau_n}}\\rightarrow \\hat u(t)$.\n\\end{cor}\n\\begin{proof}\nLet $x_n:t\\mapsto u^{[\\tau_n]}_{\\ceil{t/\\tau_n}}$ and let $\\tau_{n_k}$ be any subsequence of $\\tau_n$. Then by the theorem there is a subsubsequence $\\tau_{n_{k_l}}$ such that $x_{n_{k_l}}\\rightarrow \\tilde u$ pointwise where $\\tilde u$ is a solution to \\eqref{fACE2} with initial condition $\\tilde u(0) = u_0$. By Theorem \\ref{fACEthm}(c) such solutions are unique, so $\\tilde u = \\hat u$. Thus there exists $x$ (in particular, $x=\\hat u$) such that every subsequence of $x_n$ has a convergent subsubsequence with limit $x$. It follows by a standard fact of topological spaces that $x_n \\rightarrow \\hat u$ pointwise as $n\\rightarrow\\infty$.\\footnote{Suppose $x_n\\nrightarrow x$. Then there exists $U$ which is open in the topology of pointwise convergence such that $x\\in U$ and infinitely many $x_n\\notin U$. Choose $x_{n_k}$ such that for all $k$, $x_{n_k}\\notin U$. This subsequence has no further subsubsequence converging to $x$.} \n\\end{proof}\nFinally, we follow \\cite{Budd} to use Theorem \\ref{SDlimit} to deduce that the Ginzburg--Landau energy monotonically decreases along the ACE trajectories by considering the Lyapunov functional  $H$ defined in \\eqref{Lyap}. We also deduce well-posedness of the ACE.  \n\\begin{prop}[\\text{Cf. \\cite[Proposition 5.6]{Budd}}]\n\\label{Htauprop}\nLet $H_\\tau(u):=\\frac{1}{2\\tau} H(u)$. Then for $u\\in\\V_{[0,1]}$\n\\[\nH_\\tau(u) = \\fGL(u) -\\frac{1}{2}\\mu ||f||_\\V^2 +\\frac{1}{2}\\tau\\ip{u,Q_\\tau (u -2\\mu A^{-1}f)}\n\\]\nwhere $Q_\\tau :=\\tau^{-2}(I-\\tau A -e^{-\\tau A})$. Hence $H_\\tau +\\frac{1}{2}\\mu ||f||_\\V^2\\rightarrow \\fGL$ uniformly on $\\V_{[0,1]}$ as $\\tau\\rightarrow 0$, and furthermore if $u_\\tau \\rightarrow u$ in $\\V_{[0,1]}$ then $H_\\tau(u_\\tau) +\\frac{1}{2}\\mu ||f||_\\V^2\\rightarrow \\fGL(u)$.\n\\end{prop}\n\\begin{proof}\nExpanding and collecting terms in \\eqref{fGL}, we find that for $u\\in\\V_{[0,1]}$\n\\[\n\\fGL(u) = \\frac{1}{2\\varepsilon}\\ip{u,\\mathbf{1}-u} +\\frac{1}{2}\\ip{u,Au-2\\mu f} +\\frac{1}{2}\\mu||f||_\\V^2. \n\\]\nThen by \\eqref{Lyap} and recalling that $\\lambda:=\\tau/\\varepsilon$\n\\[\\begin{split}\nH_\\tau(u) &= \\frac{1}{2\\varepsilon}\\ip{u,\\mathbf{1}-u} +\\frac{1}{2\\tau}\\ip{u,(I-e^{-\\tau A})u -2\\mu A^{-1}(I-e^{-\\tau A})f}\\\\\n&=\\frac{1}{2\\varepsilon}\\ip{u,\\mathbf{1}-u} +\\frac{1}{2\\tau}\\ip{u,(\\tau A+\\tau^2Q_\\tau)u -2\\mu A^{-1}(\\tau A+\\tau^2Q_\\tau)f}\\\\\n&=\\frac{1}{2\\varepsilon}\\ip{u,\\mathbf{1}-u} +\\frac{1}{2}\\ip{u, Au-2\\mu f} +\\frac{1}{2}\\tau\\ip{u,Q_\\tau (u -2\\mu A^{-1}f)}.\n\\end{split}\\]\nTo show the uniform convergence, note that $||u||_\\V$ and $||u-2\\mu A^{-1}f||_\\V$ are uniformly bounded in $u$ for $u\\in\\V_{[0,1]}$. Thus it suffices to prove that $||Q_\\tau||$ is uniformly bounded in $\\tau$. But $Q_\\tau$ is self-adjoint, and if $\\xi_k$ is an eigenvalue of $A$ then $Q_\\tau$ has corresponding eigenvalue $\\tau^{-2}(1-\\tau\\xi_k-e^{-\\tau\\xi_k})\\in [-\\frac{1}{2}\\xi^2_k,0] $, so $||Q_\\tau||\\leq \\frac{1}{2}||A||^2$.  \nFinally, it suffices to show that $H_\\tau(u_\\tau)-H_\\tau(u)\\rightarrow 0$, since\n\\[H_\\tau(u_\\tau) + \\frac{1}{2}\\mu||f||_\\V^2 -\\fGL(u) = H_\\tau(u_\\tau) -H_\\tau(u) +H_\\tau(u) + \\frac{1}{2}\\mu||f||_\\V^2 -\\fGL(u).\\]\nThen by the above expression for $H_\\tau$ \\[H_\\tau(u_\\tau)-H_\\tau(u) = \\frac{1}{2}\\left\\langle u_\\tau -u, \\frac{1}{\\varepsilon}\\left(1-u_\\tau-u\\right)+(A +\\tau Q_\\tau)(u_\\tau +u)-2\\mu(I+\\tau Q_\\tau A^{-1})f \\right\\rangle_\\V\\rightarrow 0\\] since the right-hand entry in the inner product is bounded uniformly in $\\tau$.  \n\\end{proof}\n\\begin{thm}[\\text{Cf. \\cite[Theorem 5.7, Remark 5.8]{Budd}}]\\label{fGLthm}\nSuppose and $\\varepsilon^{-1}\\notin\\sigma(A)$. Then the ACE trajectory $u$ defined by Definition \\ref{ACEdef} has $\\fGL(u(t))$ monotonically decreasing in $t$. More precisely\\emph{:} for all $t > s \\geq 0 $, \\be \\label{GLstep} \n \\fGL(u(s)) -  \\fGL( u(t)) \\geq \\frac{1}{2(t-s)} \\left|\\left| u(s) - u(t) \\right|\\right|_\\V^2.\n\\ee \nFurthermore, this entails an explicit $C^{0,1/2}$ condition for $ u$\n\\be \\label{C0half}\n \\left|\\left| u(s) - u(t) \\right|\\right|_\\V\\leq \\sqrt{|t-s|}\\sqrt{2\\fGL( u(0))}.\n\\ee\n\\end{thm}\n\\begin{proof} The proof is identical to that in \\cite[Theorem 5.7]{Budd} and \\cite[Remark 5.8]{Budd}.\n%We reproduce the proof from \\cite{Budd}. Let  $t > s \\geq 0 $ and $m:= \\ceil{s/\\tau_n}$ and $\\ell := \\ceil{t/\\tau_n}$. \n%As in \\cite{Budd}, we note an inner product space fact: for all sequences $v_n\\in \\V$,  \\be \\label{Plaw} \\sum_{n=1}^N  \\left|\\left|v_n \\right|\\right|_\\V^2  = \\frac{1}{N} \\left|\\left|\\sum_{n=1}^N v_n \\right|\\right|_\\V^2 + \\frac{1}{N}\\sum_{k<n} \\left|\\left|v_n - v_k \\right|\\right|_\\V^2   \\geq \\frac{1}{N} \\left|\\left|\\sum_{n=1}^N v_n \\right|\\right|_\\V^2 .%\\tag{$*$} \n%\\ee\n%Now by \\eqref{uhat}, we have $u_m^{[\\tau_n]}\\rightarrow \\hat u(s)$ and $u_\\ell^{[\\tau_n]}\\rightarrow \\hat u(t)$. It follows that:\n%\\begin{align*}\n% \\fGL(\\hat u(s)) -  \\fGL(\\hat u(t)) &=  \\lim_{n\\rightarrow\\infty} H_{\\tau_n}\\left(u_m^{[\\tau_n]}\\right) -  H_{\\tau_n}\\left(u_k^{[\\tau_n]}\\right)&&\\text{ by Proposition \\ref{Htauprop}}&\\\\\n%&\\geq \\lim_{n\\rightarrow\\infty} \\frac{1}{2\\tau_n}\\left(1-\\frac{\\tau_n}{\\varepsilon}\\right) \\sum_{k=m}^{\\ell-1} \\left|\\left|u_{k+1}^{[\\tau_n]}-u_k^{[\\tau_n]}\\right|\\right|_\\V^2 &&\\text{ by \\eqref{Hstep}}&\\\\\n%&\\geq \\lim_{n\\rightarrow\\infty}  \\frac{1}{2\\tau_n}\\left(1-\\frac{\\tau_n}{\\varepsilon}\\right) \\frac{1}{\\ell-m}\\left|\\left|u_{\\ell}^{[\\tau_n]}-u_m^{[\\tau_n]}\\right|\\right|_\\V^2&&\\text{ by \\eqref{Plaw}}& \\\\\n%&=\\frac{1}{2(t-s)} \\left|\\left|\\hat u(s) -\\hat u(t) \\right|\\right|_\\V^2 \\geq 0. &&&\n%\\end{align*}\n%Since $\\fGL(\\hat u(s))-\\fGL(\\hat u(t))\\leq \\fGL(\\hat u(s))\\leq\\fGL(\\hat u(0))$, \\eqref{C0half} follows directly from \\eqref{GLstep}.\n\\end{proof}\n\\begin{thm}[\\text{Cf. \\cite[Theorem 3.11]{Budd}}]\\label{fACEstab}\nLet $u_0,v_0\\in\\V_{[0,1]}$ define ACE trajectories $ u, v$ by Definition \\ref{ACEdef}, and suppose $\\varepsilon^{-1}\\notin\\sigma(A)$. Then, if $\\xi_1:=\\min\\sigma(A)$, then\n\\be\\label{fACEstab1}\n|| u(t)- v(t)||_\\V \\leq e^{-\\xi_1 t}e^{t/\\varepsilon}||u_0-v_0||_\\V.\n\\ee\n\\end{thm}\n\\begin{proof}\nFix $t\\geq 0$ and let $m:= \\ceil{t/\\tau_n}$. By Corollary \\ref{SDlimitcor}, we take $\\tau_n\\downarrow 0$ such that $u_m^{[\\tau_n]}\\rightarrow  u(t)$ and $v_m^{[\\tau_n]}\\rightarrow  v(t)$ as $n\\rightarrow\\infty$. Then by \\eqref{fSDstab}:\n\\[\n||u_m^{[\\tau_n]}-v_m^{[\\tau_n]}||_\\V \\leq e^{-m\\xi_1\\tau_n}(1-\\tau_n/\\varepsilon)^{-m}||u_0-v_0||_\\V\n\\]\nand taking $n\\rightarrow\\infty$ gives \\eqref{fACEstab1}.\n\\end{proof}\n%\n%\n%\n%\\[ \\begin{split}u_n &=(1-\\lambda)^{-n}e^{-n\\tau A}u_0+\\sum_{k=1}^n (1-\\lambda)^{-k}e^{-(k-1)\\tau A}z+\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-(n-k)}e^{-(n-k)\\tau A}\\beta_k \\\\\n%&= (1-\\lambda)^{-n}e^{-n\\tau A}u_0+((1-\\lambda)I-e^{-\\tau A})^{-1}(I-(1-\\lambda)^{-n}e^{-n\\tau A})z+\\frac{\\lambda}{1-\\lambda}\\sum_{k=1}^n (1-\\lambda)^{-(n-k)}e^{-(n-k)\\tau A}\\beta_k \n%\\end{split}\n%\\]\n%Using that $1-\\lambda = e^{-\\lambda} +\\bigO(\\lambda^2)$, $\\lambda/(1-\\lambda) = \\lambda +\\bigO(\\lambda^2)$ and $B = A-\\frac{\\lambda}{\\tau}I$ we get\n%\\[ \\begin{split}u_n &\\approx e^{n\\lambda}e^{-n\\tau A}u_0+((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{n\\lambda}e^{-n\\tau A})z+\\lambda\\sum_{k=1}^n e^{(n-k)\\lambda}e^{-(n-k)\\tau A}\\beta_k \\\\ \n%& =e^{-n\\tau B}u_0+((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-n\\tau B})z+\\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k \\\\\n%& =e^{-n\\tau B}u_0+((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-n\\tau B})(\\mu A^{-1}(I-e^{-\\tau A})f-\\frac{1}{2\\varepsilon}\\tau\\mathbf{1})+\\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k \\\\\n%&\\approx e^{-n\\tau B}u_0+\\mu B^{-1}(I-e^{-n\\tau B})f-\\frac{1}{2\\varepsilon}\\tau((1-\\lambda)I-e^{-\\tau A})^{-1}(I-e^{-n\\tau B})\\mathbf{1}+\\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k\\\\\n%&\\approx e^{-n\\tau B}u_0+\\mu B^{-1}(I-e^{-n\\tau B})f-\\frac{1}{2\\varepsilon}B^{-1}(I-e^{-n\\tau B})\\mathbf{1}+\\lambda\\sum_{k=1}^n e^{-(n-k)\\tau B}\\beta_k + \\bigO(\\tau)\n%\\end{split}\\]\n\n\\section{The SDIE scheme as a classification algorithm}\\label{classificationsec}\n\nAs was noted in the introduction, trajectories of the ACE and of the MBO scheme on graphs can be deployed as classification algorithms, as was originally done in work by Bertozzi and co-authors in \\cite{MKB,BF}. In the above, we have shown that the SDIE scheme \\eqref{fSD} introduced in \\cite{Budd} generalises the MBO scheme into a family of schemes, all of the same computational cost as the MBO scheme, and which as $\\tau\\downarrow 0$ become increasingly more accurate approximations of the ACE trajectories. In the remainder of this paper, we will investigate whether the use of these schemes can significantly improve on the use of the MBO scheme to segment the ``two cows'' images from \\cite{MKB,BF}. We will also discuss other potential improvements to the method of \\cite{MKB}. \n\n\\subsection{Groundwork }  \n\nIn this section, we will describe the framework for applying graph dynamics to classification problems, following \\cite{MKB,BF}. \n\nThe individuals that we seek to classify we will denote as a set $V$, upon which we have some information $x : V\\rightarrow \\mathbb{R}^q$. For example, in image segmentation $V$ is the pixels of the image, and $x$ is the greyscale/RGB/etc. values at each pixel. Furthermore, we have \\emph{labelled reference data} which we shall denote as $Z\\subseteq V$, and binary reference labels $f$ supported on $Z$. %The vertices of our graph we shall then take to be $V:=Y\\cup Z$. \n\nTo build our graph, we first construct \\emph{feature vectors}  $z:V\\rightarrow\\mathbb{R}^\\ell$. The philosophy behind these is that we want vertices which are ``similar'' (and hence should be similarly labelled) to have feature vectors that are ``close together''. What this means in practice will depend on the application, e.g. \\cite{VZ} incorporates texture into the features and \\cite{BF,birdspot} give other options.\n\nNext, we construct the weights on the graph by deciding on the edge set $E$ (e.g. $E = V^2 \\setminus \\{(i,i)\\mid i \\in V\\}$) and for each $ij\\in E$ computing $\\omega_{ij} := \\Omega({z}_i,{z}_j)$ (and for $ij\\notin E$, $\\omega_{ij}:=0$). There are a number of standard choices for the similarity function $\\Omega$, see for example \\cite{BF,Yarov,BCM,ZMP}. The similarity function we will use in this paper is the Gaussian function:\n\\[\n\\Omega(z,w) := e^{-\\frac{||z - w||^2}{\\ell\\sigma^2}}.\n\\] \n\n\nFinally, from these weights we compute the graph Laplacian so that we can employ the graph ODEs discussed in the previous sections. In particular, we compute the \\emph{normalised} (a.k.a. random walk) graph Laplacian, i.e. we will henceforth take $r=1$ and so $\\Delta = I - D^{-1}\\omega$. We will also consider the \\emph{symmetric normalised} Laplacian $\\Delta_s := I - D^{-1/2}\\omega D^{-1/2}$, though this does not fit into the above framework.   This normalisation matters because, as discussed in \\cite{BF}, the segmentation properties of diffusion-based graph dynamics are linked to the segmentation properties of the eigenvectors of the corresponding Laplacian. As shown in \\cite[Fig. 2.1]{BF}, normalisation vastly improves these segmentation properties. As that figure looked at the symmetric normalised Laplacian, we include Fig. \\ref{rwVSsym} to show the difference between the symmetric normalised and the random walk Laplacian. \n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{eigenvecs_rw_vs_sym}\n\\caption{Second, third, and fourth eigenvectors of the random walk Laplacian (left) and symmetric normalised Laplacian (right) for the graph built on one of the ``two cows'' images from Section \\ref{applicationsec}, computed using Algorithm~\\ref{nysQR}.}\n\\label{rwVSsym}\n\\end{figure} \n\\subsection{The basic classification algorithm}\n For some time step $0<\\tau\\leq\\varepsilon $ note that \n\\[\n\\mathcal{S}_\\tau u = e^{-\\tau A}u + b\n\\]\nwhere $b:= \\mu A^{-1}(I - e^{-\\tau A})f$ is independent of $u$.\n\n\\begin{enumerate}\n\\item \\textbf{Input:} Vector $x:V\\rightarrow\\mathbb{R}^q$, reference data $Z$, and labels $f$ supported on $Z$. \n\\item Convert $x$ into feature vectors $z:V\\rightarrow\\mathbb{R}^\\ell$. \n\\item Build a weight matrix $\\omega = (\\omega_{ij})$ on $V^2$ via $\\omega_{ij} :=  \\Omega({z}_i,{z}_j)$.\n\\item Compute $A$ and therefore $b$. %and $\\mathcal{S}_\\tau$. \n\\item From some initial condition $u_0$, compute the SDIE sequence $u_n$ until it meets a stopping condition at some $n = N$.\n\\item\\textbf{Output:} $u_N$. \n\\end{enumerate}\n\nUnfortunately, as written this algorithm cannot be feasibly run. The chief obstacle is that in many applications $A$ is too large to store in memory, yet we need to quickly compute $e^{-\\tau A} u$, potentially a large number of times. We also need to compute $b$ accurately%, which may involve solving the system $Ab = (I-e^{-\\tau A})f$\n. Moreover, in general $A$ does not have low numerical rank, so it cannot be well approximated by a low-rank matrix. %such as an Adaptive Cross or Nystr\\\" om approximation. \nIn the rest of this section we describe our  modifications to this basic algorithm that make it computationally efficient. \n\\subsection{Matrix compression and approximate SVDs}\n\nWe will need to compress $\\Delta$ into something we can store in memory. \n%\\textit{Method 1: Nystr\\\"om extension}\nFollowing \\cite{MKB,BF}, we employ the  Nystr\\\"om extension \\cite{Nys,FBCM}. We choose $K\\ll |V|$ to be the rank to which we will compress $\\Delta$, and choose nonempty Nystr\\\"om interpolation sets $X_1\\subseteq V\\setminus Z$ and $X_2 \\subseteq Z$ at random such that $|X|=K$ where $X:= X_1\\cup X_2$. Then using the function $ij\\mapsto \\omega_{ij}$ we compute $\\omega_{VX}:=\\omega(V,X)$ (i.e. $\\omega_{VX}:=(\\omega_{ij})_{i\\in V, j\\in X}$) and $\\omega_{XX}:=\\omega(X,X)$ %(in \\textsc{Matlab} notation) \nand then the Nystr\\\"om extension is the approximation:\n\\[\n\\omega \\approx  \\omega_{VX} \\omega_{XX}^{-1} \\omega_{VX}^T.\n\\]\n%[[NB. ACA may be a cleverer way of choosing $X$ and $X_d$.]] \nNote that this avoids having to compute the full matrix $\\omega$ which in many applications is too large to store in memory. We next compute an approximation for the degree vector $d$ and degree matrix $D:=\\operatorname{diag}(d)$ of our graph (recall that the operator diag sends a vector to the diagonal matrix with that vector as diagonal, and also \\emph{vice versa})\n\\begin{align*} \n&d\\approx \\hat d:=\\omega_{V{X}} \\omega_{{XX}}^{-1} \\omega_{V{X}}^T\\mathbf{1}, & D\\approx \\hat D := \\operatorname{diag}\\left(\\hat d\\right).\n\\end{align*}\nWe thus approximately normalise $\\omega$\n\\begin{align*}\n\\tilde \\omega &:=  D^{-1/2}\\omega D^{-1/2} \\approx \\hat D^{-1/2}   \\omega_{V{X}} \\omega_{{XX}}^{-1}  \\omega_{V{X}}^T \\hat D^{-1/2} =   \\tilde  \\omega_{V{X}} \\omega_{{XX}}^{-1} \\tilde  \\omega_{V{X}}^T\n\\end{align*}\nwhere $\\tilde  \\omega_{V{X}}:= \\hat D^{-1/2} \\omega_{V{X}}$.\n\nFollowing \\cite{MKB,BF}, we next compute an approximate eigendecomposition of $\\tilde\\omega$. We here diverge from the method of \\cite{MKB,BF}. The method used in those papers requires taking the matrix square root of $\\omega_{XX}$, but unless $\\omega_{XX}$ is the zero matrix it will not be positive semi-definite.\\footnote{It is easy to see that non-zero $\\omega_{XX}$ has negative eigenvalues, as it has zero trace.} Whilst this clearly does not prevent the method of \\cite{MKB,BF} from working in practice, it is a potential source of error and we found it conceptually troubling. We here present an improved method, adapted from the method from \\cite{BK} for computing a singular value decomposition (SVD) from an adaptive cross approximation (ACA) (see \\cite{BK} for a definition of ACA).\n\nFirst, we compute the thin QR decomposition (see \\cite[Theorem 5.2.2]{GVL})\n\\[\n\\tilde \\omega_{V{X}} = QR\n\\] \nwhere $Q\\in\\mathbb{R}^{|V|\\times K}$ is orthonormal and $R\\in\\mathbb{R}^{K\\times K}$ is upper triangular.\nNext, we compute the eigendecomposition \n\\[\nR\\omega_{{XX}}^{-1}R^T = \\Phi \\Sigma \\Phi^T\n\\]\nwhere $\\Phi\\in\\mathbb{R}^{K\\times K}$ is orthogonal and $\\Sigma\\in\\mathbb{R}^{K\\times K}$ is diagonal. It follows that $\\tilde \\omega$ has approximate eigendecomposition:\n\\[\n\\tilde \\omega \\approx Q\\Phi\\Sigma \\Phi^T Q^T = U_s \\Sigma U_s^T \n\\]\nwhere $U_s:=Q\\Phi$ is orthonormal. This gives an approximate eigendecomposition of the symmetric normalised Laplacian\n\\[\n\\Delta_s = I - \\tilde\\omega \\approx U_s(I_{K}-\\Sigma)U_s^T = U_s\\Lambda U_s^T\n\\]\nwhere $I_K$ is the $K\\times K$ identity matrix and $\\Lambda := I_{K}-\\Sigma$, and so we get an approximate SVD of the random walk Laplacian\n\\[\n\\Delta = D^{-1/2} \\Delta_s D^{1/2} \\approx U_1\\Lambda U_2^T\n\\]\nwhere $U_1:= \\hat D^{-1/2}U_s$ and $U_2:=\\hat D^{1/2}U_s$. As in \\cite{BK}, it is easy to see that this approach is $\\bigO(K|V|)$ in space and $\\bigO(K^2|V|\n+K^3)$ in time. We summarise this all as Algorithm \\ref{nysQR}.\n%\n\\begin{algorithm}[h]\n \\caption{QR decomposition-based Nystr\\\"om method for computing an approximate SVD of $\\Delta$, inspired by \\cite{BK}.\\label{nysQR}}\n\\begin{algorithmic}[1]\n\\Function{Nystr\\\"omQR}{$ij\\mapsto\\omega_{ij}, V, Z, K$}\\Comment{Computes $U_1,\\Lambda$, and $U_2$; $\\Delta\\approx U_1\\Lambda U_2^T$ is an approximate SVD of rank $K$  }\n%\\SetAlgoLined\n%\\DontPrintSemicolon\n%\\KwIn{ $ij\\mapsto\\omega_{ij}$ , $Z, K$. }\n%\\KwOut{$U,\\Lambda, V$.}\n%\\KwResult{Computes $U,\\Lambda, V$, with $\\Delta\\approx U\\Lambda V^T$ a rank $K$ approximate SVD.  }\n\\State $ X_1 = \\texttt{random\\_subset}(V\\setminus Z,K/2) $ \\Comment{A random subset of $V\\setminus Z$ of size $K/2$}\n\\State $ X_2 = \\texttt{random\\_subset}(Z,K/2) $ \\Comment{A random subset of $Z$ of size $K/2$}\n\\State $ {X} = X_1 \\cup X_2$ \n\\State $\\omega_{{XX}}=\\omega({X},{X})$ \n\\State $\\omega_{V{X}}=\\omega(V,{X})$ \n\\State $\\hat d = \\omega_{V{X}} \\left(\\omega_{{XX}}^{-1} \\left(\\omega_{V{X}}^T\\mathbf{1}\\right)\\right) $ \n\\State $ \\tilde\\omega_{VX} =\\hat d^{-1/2} \\odot \\omega_{VX}$ \\Comment{Applying $\\odot$ columnwise, i.e. $(\\tilde\\omega_{V{X}})_{ij} = \\hat d_i^{-1/2}(\\omega_{V{X}})_{ij} $ }\n\\State $ [Q,R] = \\texttt{thin\\_qr}(\\tilde \\omega_{V{X}}) $\\Comment{Computes thin QR decomoposition $\\tilde \\omega_{V{X}}=QR$}\n\\State $ S = R\\omega_{{XX}}^{-1}R^T$ \n\\State $ S = (S + S^T)/2 $ \\Comment{Corrects symmetry-breaking computational errors}\n\\State $ [\\Phi,\\Sigma] = \\texttt{eig}(S)$\\Comment{Computes eigendecomoposition $S = \\Phi\\Sigma\\Phi^T$}\n\\State $ \\Lambda = I_K -\\Sigma$ \n\\State $ U_s = Q\\Phi$ \\Comment{Note that $\\Delta_s\\approx U_s \\Lambda U_s^T$}\n\\State $ U_1 = \\hat d^{-1/2} \\odot U_s $ \\Comment{I.e. $(U_1)_{ij} =  \\hat d_i^{-1/2} (U_s)_{ij} $}\n\\State $  U_2 = \\hat d^{1/2} \\odot U_s $ \\Comment{I.e. $(U_2)_{ij} =  \\hat d_i^{1/2} (U_s)_{ij} $}\n\\State \\textbf{return} $U_1,\\Lambda,U_2$\n\\EndFunction\n\\end{algorithmic}\n\\end{algorithm}\n%\n%first compute the eigenvalue decomposition $\\tilde\\omega_{XX} = U_X \\Gamma U_X^T$ for $U_X$ unitary. The we  let $S:= U_X (\\Gamma^+)^{1/2} U_X^T$ and define  \n%\\[\n%Q:= \\tilde\\omega_{XX} + S \\tilde\\omega_{XY}\\tilde\\omega_{XY}^T S\n%\\]\n%with diagonalisation $ S=: \\hat U \\Sigma \\hat U^T$. Then defining \n%\\[\n%U_s := \\begin{pmatrix} U_X \\Gamma^{1/2} \\\\ \\tilde\\omega_{XY}^T U_X (\\Gamma^+)^{1/2} \\end{pmatrix} U_X^T \\hat U (\\Sigma^+)^{1/2}\n%\\]\n%we have that $\\tilde\\omega \\approx U_s\\Sigma U_s^T$ and $U_s$ is unitary. Finally\n%\\be\n%\\Delta = D^{-1/2} (I - \\tilde\\omega) D^{1/2} \\approx D^{-1/2}U_s(I_K-\\Sigma)U_s^TD^{1/2} =: U\\Lambda V^T\n%\\ee\n%where $\\Lambda := I_K-\\Sigma$, $U:= D^{-1/2}U_s$, and $V:=D^{1/2}U_s$. \n\\subsubsection{Numerical assessment of the matrix compression method}\nWe consider the accuracy of our Nystr\\\"om-QR approach for the compression of the symmetric normalised Laplacian $\\Delta_s$ built on the simple image in Fig.~\\ref{Fig_Image_Error_LR}, containing $|V| = 6400$ pixels, which is sufficiently small that we can compute the true value of $\\Delta_s$ to high accuracy.\nFor $K \\in \\{50, 100, \\ldots, 500\\}$, we compare the rank $K$ approximation $U_s\\Lambda U_s^T$ with the true $\\Delta_s$ in terms of the relative Frobenius distance, i.e. $||U_s\\Lambda U_s^T-\\Delta_s||_F/||\\Delta_s||_F$. \nMoreover, we compare these errors to the errors incurred by other low-rank approximations of $\\Delta_s$, namely the  Nystr\\\"om method suggested by \\cite{MKB,BF}, the Halko--Martinsson--Tropp (HMT) method\\footnote{The HMT results serve only to give an additional benchmark for the Nystr\\\"om methods: HMT requires matrix-vector-products with $\\Delta_s$, which was infeasible for us in applications. However, as we were finalising this paper we were made aware of the recent work of \\cite{BSV}, which may make computing the HMT-SVD of $\\Delta_s$ feasible.} \\cite{HMT} (a randomised algorithm), and the rank $K$ approximation of $\\Delta_s$ obtained by setting all but its $K$ leading singular values to $0$. By the Eckart--Young theorem \\cite{EY} (see also \\cite[Theorem~2.4.8]{GVL}) the latter is the optimal rank $K$ approximation of $\\Delta_s$ with respect to the Frobenius distance.\nIn addition to the methods' accuracy, we measure their complexity in terms of the elapsed time used for their execution, obtained with an implementation in \\textsc{Matlab}R2019a on the set-up described in Section~\\ref{appsetup}.\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width = 0.2\\textwidth]{image_nicetest_cropped.pdf}\n\\caption{The $80\\times 80$ image on which the Laplacian $\\Delta_s$ is constructed to test the low-rank approximations. }\n\\label{Fig_Image_Error_LR}\n\\end{figure}\n\nWe report the relative Frobenius distance in the left of Fig.~ \\ref{Fig_Timings_Error_LR}. As the Nystr\\\"om (and HMT) methods are randomised, we repeat the experiments $100$ times and plot the mean error as solid lines and the mean error $\\pm$ standard deviation as dotted lines. To expose the difference between the methods for $K \\geq 100$, we subtract the SVD error from the other errors and show this difference in the central figure. In the right figure, we compare the complexity of the algorithms in terms of their average runtime. The SVD timing is constant in $K$ as we always computed a full SVD and kept the largest $K$ singular values.%---computing a truncated SVD did not lead to a speed up.\n\n\\begin{figure}\n\\centering\n\\includegraphics[height=110pt]{error_time_nystest_HMT_left_lin_cropped.pdf}\n\\caption{Error of the low-rank approximations of $\\Delta_s$ in terms of their relative Frobenius distance to the true $\\Delta_s$ (left) and translated by the negative optimal error reached with the SVD (centre). Timings of the methods in seconds (right). In the left and the centre figure, the solid lines refer to the mean values and the dotted lines to the means $\\pm$ the standard deviations. The lower blue dotted line in the centre figure is not plotted for low $K$ as the mean $-$ standard deviation is negative and cannot be plotted on a log scale; all other solid and dotted lines are plotted but some cannot be distinguished from the others by the eye.}\n\\label{Fig_Timings_Error_LR}\n\\end{figure}\n\nWe observe that the Nystr\\\"om-QR method outperforms the Nystr\\\"om method from \\cite{MKB,BF}: it is faster, more accurate, and is stable for small $K$. In terms of accuracy, the Nystr\\\"om-QR error is equal to only $4.6 \\times 10^{-5}$ plus the optimal low-rank error. Notably, this additional error is (almost) constant, indicating that the Nystr\\\"om-QR method and the SVD converge at a similar rate.\nThe Nystr\\\"om-QR randomness has hardly any effect on the error; the standard deviation of the relative error ranges from $8.87 \\times 10^{-7}$ $(K=50)$ to $5.00 \\times 10^{-8}$ $(K=500)$. By contrast, for the Nystr\\\"om method from \\cite{MKB, BF} we see much more random variation.\n\\subsection{Implementing the SDIE scheme: a Strang formula method}\n\nTo compute the iterates of our SDIE scheme, we will need to compute an approximation for $\\mathcal{S}_\\tau u_n$. In \\cite{MKB}, at each iteration $\\mathcal{S}_\\tau u_n$ was approximated via a semi-implicit Euler method, which therefore incurred a linear (in the time step of the Euler method, i.e. $\\delta t$ in the below notation) error in both the $e^{-\\tau A}u_n$ and $b$ terms (plus a spectrum truncation error). In Appendix \\ref{MKBapp} we show that the method from \\cite{MKB} works by approximating a Lie product formula approximation (see \\cite[Theorem 2.11]{Hall}) of $e^{-\\tau A}$, therefore we propose as an improvement a scheme that directly employs the superior Strang formula\\footnote{We owe the suggestion to use this formula to Arieh Iserles, who also suggested to us the Yoshida method that we consider below.} to approximate $e^{-\\tau A}u_n$---with quadratic error (plus a spectrum truncation error). We also consider potential improvements of the accuracy of computing $b$: by expressing $b$ as an integral and using quadrature methods;\\footnote{We again thank Arieh Iserles for also making this suggestion.} by expressing $b$ as a solution to the ODE from \\eqref{fdiffuse} with initial condition $\\mathbf{0}$, and using the Euler method from \\cite{MKB} with a very small time step (or a higher-order ODE solver);\\footnote{We can afford to do this for $b$, but not generally for the $\\mathcal{S}_\\tau u_n$, because $b$ only needs to be computed once rather than at each $n$.} or by computing the closed form solution for $b$ directly using the Woodbury identity. We therefore improve on the accuracy of computing $\\mathcal{S}_\\tau u$ at low cost. \n\n\nThe Strang formula for matrix exponentials \\cite{Strang} is given, for $k >0$ a parameter and $\\bigO$ relative to the limit $k\\rightarrow \\infty$, by\n\\[\ne^{X + Y} = (e^{\\frac{1}{2}Y/k}e^{X/k}e^{\\frac{1}{2}Y/k})^k +\\bigO(k^{-2}). \n\\]\nGiven $\\Delta \\approx  U_1\\Lambda U_2^T $ as in Algorithm \\ref{nysQR} (the case for $\\Delta_s $ is likewise) for any $u\\in \\V$ we compute (writing $\\delta t:= \\tau/k$)\n\\be\n\\begin{split}\ne^{-\\tau A}u &= \\left(e^{-\\frac{1}{2}\\tau\\mu/k P_{Z}} e^{-\\tau/k \\Delta} e^{-\\frac{1}{2}\\tau\\mu/k P_{Z}}\\right)^k u+ \\bigO(k^{-2})\\\\\n\t           &=  \\left(e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}\\left(I + U_1(e^{-\\delta t \\Lambda}-I_K)U_2^T\\right) e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}\\right)^k u+E+ \\bigO(\\delta t^2)\\\\\n\t\t&= v_k + E+ \\bigO(\\delta t^2)\n\\end{split}\n\\ee\nwhere $E$ is a spectrum truncation error and $v_k$ is defined by $v_0 := u$, and $v_r$ for $r \\in\\{1,...,k\\}$ is defined iteratively by \n\\be\n\\label{SFscheme}\n\\begin{split}\nv_{r+1} &= e^{-\\mu\\delta t P_{Z}}v_r + e^{-\\frac{1}{2}\\mu\\delta t P_{Z}} U_1(e^{-\\delta t \\Lambda}-I_K)U_2^T e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}v_r\\\\\n%\\notag&=\\operatorname{exp}(-\\tau\\mu/k \\chi_{Z_d}) \\odot v_r + U\\left((\\operatorname{exp}(-\\tau/k \\operatorname{diag}(\\Lambda))-\\mathbf{1}_K)\\odot \\left(V^T \\left(\\operatorname{exp}(-\\tau \\mu/k \\chi_{Z_d})\\odot v_r\\right)\\right)\\right)\\\\\n&= a_1(\\delta t) \\odot v_r + a_3(\\delta t) \\odot \\left( U_1\\left( a_2(\\delta t) \\odot \\left(U_2^T\\left(a_3(\\delta t) \\odot v_r\\right) \\right)\\right) \\right)\\\\\n&=: S(\\delta t)v_r\n\\end{split}\n\\ee\nwhere $\\odot$ is the Hadamard (i.e. elementwise) product, $a_1(\\delta t):= \\operatorname{exp}(-\\mu\\delta t\\chi_{Z})$, $a_2(\\delta t) := \\operatorname{exp}(-\\delta t\\operatorname{diag}(\\Lambda))-\\mathbf{1}_K$, and $a_3(\\delta t):= \\operatorname{exp}(-\\frac{1}{2}\\mu\\delta t\\chi_{Z})$ is the elementwise square root of $a_1(\\delta t)$ (where $\\exp$ is applied elementwise, and $\\mathbf{1}_K$ is the vector of $K$ ones). In Fig. \\ref{LPFfig}, we verify on a simple image that this method has quadratic error (plus a spectrum truncation error) and outperforms the \\cite{MKB} Euler method. Furthermore\n%\n%[[Arieh idea]]\n%\n%We can improve upon the Lie product formula by an order of magnitude by using \n%\n%As for the Lie product formula, we compute\n%\\be\n%\\begin{split}\n%e^{-\\tau A}u &= \\left(e^{-\\tau\\mu/2k P_{Z}} e^{-\\tau/k \\Delta} e^{-\\tau\\mu/2k P_{Z}}\\right)^k u+ \\bigO(k^{-2})\\\\\n%\t           &\\approx  \\left(e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}\\left(I + U_1(e^{-\\delta t \\Lambda}-I_K)U_2^T\\right) e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}\\right)^k u+ \\bigO(\\delta t^2)\\\\\n%\t\t&= v_k + \\bigO(\\delta t^2)\n%\\end{split}\n%\\ee\n%where $v_k$ is defined by $v_0 := u$, and $v_r$ for $r \\in\\{1,...,k\\}$ is defined iteratively by \n%\\be\n%\\label{SFscheme}\n%\\begin{split}\n%v_{r+1} &= e^{-\\mu\\delta t P_{Z}}v_r + e^{-\\frac{1}{2}\\mu\\delta t P_{Z}} U_1(e^{-\\delta t \\Lambda}-I_K)U_2^T e^{-\\frac{1}{2}\\mu\\delta t P_{Z}}v_r\\\\\n%%\\notag&=\\operatorname{exp}(-\\tau\\mu/k \\chi_{Z_d}) \\odot v_r + U\\left((\\operatorname{exp}(-\\tau/k \\operatorname{diag}(\\Lambda))-\\mathbf{1}_K)\\odot \\left(V^T \\left(\\operatorname{exp}(-\\tau \\mu/k \\chi_{Z_d})\\odot v_r\\right)\\right)\\right)\\\\\n%&= a_1 \\odot v_r + a_3 \\odot \\left( U_1\\left( a_2 \\odot \\left(U_2^T\\left(a_3 \\odot v_r\\right) \\right)\\right) \\right)\n%\\end{split}\n%\\ee\n%where $a_1$ and $a_2$ are as before and $a_3:= \\operatorname{exp}(-\\frac{1}{2}\\mu\\delta t\\chi_{Z})$ is the elementwise square root of $a_1$.\n%\\begin{prop} \\label{prop_nystromcost}\n\\eqref{SFscheme} is as fast as \\eqref{Eulersoln2} (i.e. a step of the \\cite{MKB} Euler method). This is because by defining $\\tilde a_1 := \\mathbf{1}-\\mu\\delta t \\chi_Z$ and $\\tilde a_2 := (\\mathbf{1}_K +\\delta t \\operatorname{diag}(\\Lambda))^{-1}$ (applying the reciprocation elementwise), we can rewrite \\eqref{Eulersoln2} as \n\\[\nv_{r+1} = U_1 \\left( \\tilde a_2 \\odot \\left( U_2^T \\left(  \\tilde a_1 \\odot v_r + \\mu\\delta t f \\right) \\right)\\right)\n\\] and so both \\eqref{SFscheme} and \\eqref{Eulersoln2} involve two $\\bigO(NK)$ matrix multiplications and the vectors in \\eqref{SFscheme} and \\eqref{Eulersoln2} and are at most $N$-dimensional, hence the Hadamard products in \\eqref{SFscheme} and \\eqref{Eulersoln2} are all at most $\\bigO(N)$ and so are not rate-limiting.\n\nAt the cost of extra $\\bigO(NK)$ matrix multiplications, one can employ the method of Yoshida \\cite{Yoshida} to increase the order of the (non-spectrum-truncation) error by 2.\nIf we set $\\alpha_0 := -\\sqrt[3]{2}/(2 - \\sqrt[3]{2})$ and $\\alpha_1:= 1/(2 - \\sqrt[3]{2})$ then we can define the map \n\\[\nY(\\delta t) := S(\\alpha_1 \\delta t) \\circ S(\\alpha_0 \\delta t) \\circ S(\\alpha_1 \\delta t)\n\\]\nwhich gives $Y^k(\\delta t)u = e^{-\\tau A} u +\\bigO(\\delta t ^4)$ plus a spectrum truncation error.\\footnote{This method can be extended to give higher-order formulae of any even order, but consideration of those formulae is beyond the scope of this paper.} However, as can be seen in Fig. \\ref{LPFfig}(c,d), the spectrum truncation error can make negligible any gain from using the Yoshida method over the Strang formula.\n\nIt remains to compute an approximation for \n$\nb : = \\mu A^{-1}(I-e^{-\\tau A}) f. %= \\mu \\sum_{r=0}^\\infty (-1)^r \\frac{ \\tau^{r+1}}{(r+1)!} A^r f.\n$ \nIt is easy to show that $b$ can be rewritten as the integral\n\\[\n%\\label {bint}\nb = \\mu \\int_0^\\tau e^{-tA} f \\; dt\n\\]\nwhich we can approximate via a quadrature, e.g. applying respectively the trapezium, midpoint, or Simpson's rules we get \n\\be\\label{eq_quad}\nb = \\frac{1}{2}\\mu\\tau(I + e^{-\\tau A})f +\\bigO(\\tau^3) =\\mu \\tau e^{-\\frac{1}{2}\\tau A} f + \\bigO(\\tau^3) = \\frac{1}{6}\\mu\\tau(I + 4e^{-\\frac{1}{2}\\tau A} + e^{-\\tau A})f + \\bigO(\\tau^5) \n\\ee\nany of which we can approximate efficiently via the above methods. Furthermore, as we only need to compute $b$ once, we can take a large value, $k_b$, for $k$ in those methods. As is standard for quadrature methods, the accuracy can often be improved by subdividing the interval. For example, using Simpson's rule and subdividing into intervals of length $h:=\\tau/(2m)$ we get \n\\begin{align*}\n b &= \\frac{1}{3}\\mu h \\left(I+2\\sum_{j=1}^{m-1} e^{-2jhA} + 4\\sum_{j=1}^{m}e^{-(2j-1)hA} + e^{-\\tau A} \\right)f + \\bigO(\\tau h^4)\\\\\n\\intertext{which if $k_b = 2m$, i.e. the Simpson subdivision equals the Strang/Yoshida step number, can be approximated efficiently by}\nb& = \\frac{1}{3}\\mu h \\left(f+2\\sum_{j=1}^{m-1} v_{2j} + 4\\sum_{j=1}^{m} v_{2j-1} + v_{2m} \\right) + E_1 + E_2 + \\bigO(\\tau h^4)\n\\end{align*} where $v_r:=S^r(h) f$ with $E_1 = \\bigO(\\tau^2 h)$ or $v_r := Y^r(h) f$ with $E_1 = \\bigO(\\tau^2 h^3)$, and $E_2$ is the spectrum truncation error. Finally, we can also let \\textsc{Matlab} compute its preferred quadrature using the in-built \\texttt{integrate} function, using either the Strang formula or Yoshida method to compute the integrand. However, we found this to be very slow. \n\nAnother method to compute $b$ is to solve an ODE. We note that, by \\eqref{fdiffusesoln}, $b$ is the fidelity forced diffusion of $\\mathbf{0}$ at time $\\tau$, i.e.\n\t\\begin{align*}&\\frac{dv}{dt}(t) = -\\Delta v(t) -\\mu P_{Z}v(t) + \\mu f,  &v(0)=\\mathbf{0},\\\\\n\\intertext{has $v(\\tau) = b$. Hence we can approximate $b$ by solving}\n\t&\\frac{d\\hat v}{dt}(t) = -U_1\\Lambda (U_2^T \\hat v(t)) -\\mu \\chi_{Z} \\odot \\hat v(t) + \\mu f,  &\\hat v(0)=\\mathbf{0},\\end{align*}\n%which we can simplify by defining $\\hat w := V^T\\hat v$ and precomputing $Q:= \\mu V^TP_{Z_d}U$ and $g:=\\mu V^T f$ to give \n%\t\\begin{align*}&\\frac{d\\hat w}{dt} = -\\Lambda \\hat w - Q\\hat w + g,  &\\hat w(0)=\\mathbf{0}\\end{align*}\n%which has solution \n%\\[\n%\\hat w(\\tau) = (\\Lambda + Q)^{-1}\\left(I-e^{-\\tau (\\Lambda + Q)}\\right) g\n%\\] \n%which since these matrices are small we can directly compute. This gives approximation \n%\\be\n%\\hat b = U\\hat w(\\tau) =  U (\\Lambda + Q)^{-1}\\left(I-e^{-\\tau (\\Lambda + Q)}\\right) g \\approx b.\n%\\ee\n%Note that $\\Lambda + Q$ is invertible since \n%\\[\n%x^T(\\Lambda + Q)x = x^T\\Lambda x + \\mu x^TU_s^T D^{1/2}P_{Z_d} D^{-1/2}U_s x = x^T\\Lambda x + \\mu (U_s x)^T P_{Z_d} (U_s x) > 0 \n%\\]\n%and note that\n%\\[\n%\\begin{split}\n%\\hat b &=  U (\\Lambda + Q)^{-1}\\left(I-e^{-\\tau (\\Lambda + Q)}\\right) g\\\\\n%&= \\mu  U (\\Lambda + Q)^{-1}\\left(I-e^{-\\tau (\\Lambda + Q)}\\right) V^T f \\\\\n%&= \\mu  (\\Lambda V^T + \\mu V^TP_{Z_d})^{-1}\\left(I-e^{-\\tau (\\Lambda +  \\mu V^TP_{Z_d}U)}\\right) V^T f \\\\\n%&= \\mu  (U\\Lambda V^T + \\mu P_{Z_d})^{-1}U\\left(I-e^{-\\tau V^T(U\\Lambda V^T +  \\mu P_{Z_d})U}\\right) V^T f \\\\\n%&= \\mu  \\hat A^{-1}\\left(I-Ue^{-\\tau V^T\\hat A U}V^T \\right) f \n%\\end{split}\n%\\]\nvia the semi-implicit Euler method from \\cite{MKB}.\n%\\texttt{ode15s} (following the observation in \\cite{MKB} that this ODE is stiff) \n%to find $\\hat v(\\tau)\\approx b$. Since \nSince we only need to compute $b$ once we can choose a small time step, i.e. a time step of $\\tau/k_b$ for $k_b$ large, for this Euler method. One could also choose a higher-order ODE solver for this same reason, however as \\cite{MKB} notes this ODE is stiff, which we found causes standard solvers such as \\texttt{ode45} (i.e. Dormand--Prince-(4, 5) \\cite{DP}) to be inaccurate, and we ran into the issue of the \\textsc{Matlab} stiff solvers requiring matrices too large to fit in memory.   \n%\n%[[MORE ARIEH]]\n%\n%\\[\\int_0^t e^{-(t-\\tau)A} f \\; d\\tau \\approx \\frac{t}{2} [I + e^{-tA}] f,\n%\\]\n%the trapezoidal rule. If you want higher order, try\n%\n%\\[\\frac{t}{4} [I + 2\\exp(-tA/2) + \\exp(-tA)]\\]\n\nFinally, we can try to compute the formula for $b$ directly. By the Strang formula or Yoshida method, we can efficiently compute $g:=f - e^{-\\tau A}f$. It remains to compute $b = \\mu A^{-1}g$. Given our approximation $\\Delta \\approx  U_1\\Lambda U_2^T$, by the Woodbury identity \\cite{Woodbury}\n\\[\nA^{-1} = (\\Delta + \\mu P_Z)^{-1}  \\approx (I - U_1\\Sigma U_2^T + \\mu P_Z)^{-1} = Y^{-1} - Y^{-1} U_1\\left( -\\Sigma^{+} + U_2^T Y^{-1} U_1 \\right)^{-1} U_2^T Y^{-1}\n\\]\nwhere $Y := I+ \\mu P_Z$, superscript $+$ denotes the pseudoinverse, and recall that $\\Sigma = I_K-\\Lambda$. Then\n\\[\nb = \\mu y \\odot \\left( g - U_1 h \\right) \n\\]\nwhere $y:=(1+\\mu\\chi_Z)^{-1}$, reciprocation applied elementwise, and $h$ is given by solving\n\\[\n\\left( -\\Sigma^{+} + U_2^T (y \\odot U_1) \\right)h = U_2^T (y \\odot g)\n\\]\nwhere we define $y \\odot U_1$ as columnwise Hadamard multiplication, i.e. $(y \\odot U_1)_{ij} := y_i(U_1)_{ij}$. \nWe compare the accuracy of these approximations of $b$ in Table \\ref{btable}, and observe that no method is hands-down superior. Table \\ref{btable} also indicates that the likely reason for methods like Simpson's rule not performing as well as expected is that the spectrum truncation error is dominating. \n%\n%\\begin{figure}[ht]\n%\\begin{tabular}{ll}\n%Method              & Relative $\\ell^2$ error from true $b$ \\\\\n%Semi-implicit Euler & 0.4938                                \\\\\n%Woodbury formula    & 0.5714                                \\\\\n%Trapezium rule      & 0.1505                                \\\\\n%Midpoint rule       & 0.1286                                \\\\\n%Simpson's rule      & 0.1330                               \n%\\end{tabular}\n%\\caption{}\n%\\label{btable}\n%\\end{figure}\n\nGiven these ingredients, it is then straightforward to compute the SDIE scheme sequence via Algorithm~\\ref{SDalg}.\n\\begin{algorithm}[htp]\n \\caption{The SDIE scheme via a Strang formula method.\\label{SDalg}}\n%\\SetAlgoLined\n%\\DontPrintSemicolon\n%\\KwIn{ $\\mu$, $Z$, $f$, $U,\\Lambda,V$, $\\tau$, $\\varepsilon$, $u_0$, $k$, $K$, $\\delta$. }\n%\\KwOut{$u$.}\n%\\KwResult{Computes $u_\\infty$, the terminus of the SDIE scheme.  }\n%\\algblockdefx{Switch}[1]{\\textbf{switch} #1}{\\textbf{end switch}}\n\\algblock[SWITCH]{switch}{endswitch}\n\\algblockdefx[NAME]{START}{END}%\n[1]{\\textbf{switch} #1}{\\textbf{end switch}}\n\\begin{algorithmic}[1]\n\\Function{SDIE}{$\\mu$, $Z$, $f$, $U_1,\\Lambda,U_2$, $\\tau$, $\\varepsilon$, $u_0$, $k$, $k_b$, $K$, $\\delta$} \\Comment{Computes the terminus of the SDIE scheme.  }\n\\If{using the quadrature method}\n\\State $F_1: t \\mapsto e^{-tA} f$ \\Comment{Computed using Strang formula or Yoshida method,  with parameter $k_b$}\n%\\State $a_1' = \\operatorname{exp}(-\\frac{1}{2}\\tau\\mu/k \\chi_{Z})$ \n%\\State $a_2' = \\operatorname{exp}(-\\frac{1}{2}\\tau/k \\operatorname{diag}(\\Lambda))-\\mathbf{1}_K$ \n%\\State $a_3' = \\operatorname{sqrt}(a_1')$\n%\\State $g = f$\n%\\For{$r = 1$ to $k_b$}\n%\t\\State $g =a_1' \\odot g + a_3' \\odot \\left( U_1\\left( a_2' \\odot \\left(U_2^T\\left(a_3' \\odot g\\right) \\right)\\right) \\right)$ \\Comment{Strang formula iteration}\n%\\EndFor\n\\State $ b = \\mu \\:\\texttt{quadrature}(F_1,[0,\\tau]) $ \\Comment{Approximates $\\mu\\int_0^\\tau F_1(t) \\; dt$ by some quadrature method} \n\\ElsIf {using the ODE method}\n\\State $ F_2: x \\mapsto  \\left(-U_1\\Lambda (U_2^T x) -\\mu \\chi_{Z} \\odot x + \\mu f\\right)$ \n\\State $\\hat v = \\texttt{ode\\_solver}(F_2,[0,\\tau],\\mathbf{0})$ \\Comment{Solves $\\hat v'(t)=F_2(\\hat v)$ on $[0,\\tau]$ with $\\hat v(0) = \\mathbf{0}$} %via \\texttt{ode45}}\n\\State $ b = \\hat v(\\tau)$\n\\ElsIf {using the Woodbury identity method}\n\\State $g = f - e^{-\\tau A} f$  \\Comment{Computed using Strang formula or Yoshida method, with parameter $k_b$}\n\\State $ y = (1+ \\mu \\chi_Z)^{-1} $\n\\State $\\Sigma = I_K-\\Lambda$\n\\State $(-\\Sigma^+ + U_2^T (y \\odot U_1) )h = U_2^T(y \\odot g)$ \\Comment{Solving the linear system for $h$}\n\\State $b = \\mu y \\odot (g - U_1 h)$ \n\\EndIf\n\n\\State $a_1 = \\operatorname{exp}(-\\tau\\mu/k \\chi_{Z})$ \n\\State $a_2 = \\operatorname{exp}(-\\tau/k \\operatorname{diag}(\\Lambda))-\\mathbf{1}_K$ \n\\State $a_3 = \\operatorname{sqrt}(a_1)$\n\\State $ n=0$ \n\\While{$||u_n-u_{n-1}||_2^2/||u_n||_2^2\\geq\\delta$}\n\\State $v = u_n$ \n\\For{$r = 1$ to $k$}\n\t\\State $v =a_1 \\odot v + a_3 \\odot \\left( U_1\\left( a_2 \\odot \\left(U_2^T\\left(a_3 \\odot v\\right) \\right)\\right) \\right)$ \\Comment{Strang formula iteration}\n\\EndFor\n\\State $v = v + b$ \\Comment{Approximates $v = \\mathcal{S}_\\tau u_n$}\n\\For{$i \\in V$}\n\\If{$v_i < \\tau/2\\varepsilon$}\n   \\State $(u_{n+1})_i = 0$ \n\\ElsIf{$v_i \\geq 1 - \\tau/2\\varepsilon$}\n    \\State $(u_{n+1})_i = 1$ \n  \\Else\n   \\State $(u_{n+1})_i= \\frac{1}{2} + \\frac{v_i - 1/2}{1-\\tau/\\varepsilon}$ \n \\EndIf\n% \\START{$v_i$}\n%  \\State \\textbf{case} $<\\tau/2\\varepison$\\textbf{:}  $(u_{n+1})_i = $ %\\State \\textbf{case} $\\geq 1- \\tau/2\\varepison$\\textbf{:}  $(u_{n+1})_i=1$ \n%\\State \\textbf{default:}  $(u_{n+1})_i= \\frac{1}{2} + \\frac{v_i - 1/2}{1-\\tau/\\varepsilon}$ \n%\\END\n\\EndFor\n\\State $n = n +1$ \n \\EndWhile\n\\State \\textbf{return} $u_n$\n\\EndFunction\n%$b = D^{-1/2} b$\\;\n\\end{algorithmic}\n\\end{algorithm}\n\\subsubsection{Numerical assessment of methods}\nIn this section, we will build our graphs on the image in Fig. \\ref{toyimage}, which has sufficiently few pixels that we can compute the true values of $e^{-\\tau A} u$ (with $A$ here given by $\\Delta_s+\\mu P_Z$) and $b$ to high accuracy. \n\\begin{figure}[ht]\n\\centering\n         \\includegraphics[width=0.20\\textwidth]{LPFtestIMG}\n\\caption{The $40 \\times 40$ or $80\\times 80$ image that we build our graphs on, using feature vectors as described in Section \\ref{appsetup}. } % We will take this to have either 1600 or 6400 pixels.}\n\\label{toyimage}\n\\end{figure}\nFirst, in Fig. \\ref{LPFfig} we investigate the accuracy of the Strang formula and Yoshida method vs. the \\cite{MKB} Euler method. We take $|V|=1600$, $\\tau = 0.5$, $u$ a random vector given by \\textsc{Matlab}'s \\texttt{rand}(1600,1), $\\mu =1$, and $Z$ as the left two quadrants of the image. We consider two cases: one where $K= |V|$ (i.e. full-rank) and one where $K=\\sqrt{|V|}$. We observe that the Strang formula and Yoshida method are more accurate than the Euler method in both cases, and that the Yoshida method is more accurate than the Strang formula, but only barely in the rank-reduced case. Furthermore, the log-log gradients of the Strang formula error and the Yoshida method error (excluding the outliers for small $k$ values and the outliers caused by errors from reaching machine precision) in Fig. \\ref{LPFfig}(b) are respectively 2.000 and 3.997 (computed using \\texttt{polyfit}), confirming that these methods achieve their theoretical orders of error in the full-rank case.\n\\begin{figure}[ht]\n\\centering\n\\begin{subfigure}{0.48\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{LPFtestStrangfig2}\n\\caption{Plot of $\\ell^2$ errors vs. $1/k$.}\n\\end{subfigure}\n\\begin{subfigure}{0.48\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{LPFtestStrangfiglog2}\n\\caption{Log-log plot, i.e. plot of log $\\ell^2$ errors vs. $-\\log k$.}\n\\end{subfigure}\\\\\n\\vspace{0.8em}\n\\begin{subfigure}{0.48\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{LPFtestK2N2}\n\\caption{Plot of $\\ell^2$ errors vs. $1/k$ in the rank-reduced case.}\n\\end{subfigure}\n\\begin{subfigure}{0.48\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{LPFtestK2Nlog2}\n\\caption{Log-log plot of Strang formula error minus Yoshida formula error vs. $1/k$ in the rank-reduced case.}\n\\end{subfigure}\n\\caption{Comparison of the $\\ell^2$ error from approximating $e^{-\\tau A}u$ via the semi-implicit Euler method (blue), Strang formula (red), and Yoshida method (green) approximations for $e^{-\\tau A}u$ on the graph built on the image in Fig. \\ref{toyimage}. For (a) and (b), $K=|V|$. For (c) and (d), $K=\\sqrt{|V|}$. The gradient of the line in (d), excluding outliers for small $k$, is 2.000. In (c), the green and red lines are both plotted but cannot be distinguished by the eye.   }\n\\label{LPFfig} \n%\\todo[inline]{Jonas: not super happy with having this numerical experiment just in a caption. I would suggest to either put it as a paragraph on its own at the end of this section or in \\S 4.}\n\\end{figure}\n\nNext, in Table \\ref{btable} we compare the accuracy of the different methods for computing $b$. We take $\\mu=1$, $Z$ as the left two quadrants of the image, $f$ as equal to the image on $Z$, and $k_b=1000$ in the Strang formula/Yoshida method approximations for $ e^{-t A}f$ and in the \\cite{MKB} Euler scheme. We observe that the rank reduction plays a significant role in the errors incurred, and that no method is hands-down superior. In the ``two cows'' application (Example~\\ref{ex_twocows}), we have observed that (interestingly) the \\cite{MKB} Euler method yields the best segmentation. A topic for future research can be whether this is generally true for large matrices. \n\n\\begin{table}[ht]\n\\hspace{-5.5em}\n%\\centering\n% Please add the following required packages to your document preamble:\n% \\usepackage{multirow}\n\\begin{tabular}{|c|c|c|c|c|c|c|}\n\\hline\n\\multirow{2}{*}{\\textbf{Method}}                                                                 & \\multicolumn{3}{c|}{\\textbf{Relative $\\ell^2$ error for $\\tau = 0.5$}}                                                                                                                       & \\multicolumn{3}{c|}{\\textbf{Relative $\\ell^2$ error for $\\tau=4$}}                                                                                                                           \\\\ \\cline{2-7} \n                                                                                                 & \\begin{tabular}[c]{@{}c@{}}$|V|=1600$,\\\\ $K=1600$\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}$|V|=1600$,\\\\ $K=40$\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}$|V|=6400$,\\\\ $K=40$\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}$|V|=1600$,\\\\ $K=1600$\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}$|V|=1600$,\\\\ $K=40$\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}$|V|=6400$,\\\\ $K=40$\\end{tabular} \\\\ \\hline\nSemi-implicit Euler  \\cite{MKB}                                                                            & $1.434\\times 10^{-4}$                                                         & 0.4951                                                       & 0.4111                                                       & $2.882\\times 10^{-4}$                                                         & 0.2071                                                       & 0.1721                                                       \\\\ \\hline\nWoodbury identity                                                                                 & $2.292\\times 10^{-8}$                                         & 0.5751                                                       & 0.4607                                                       & $1.038\\times 10^{-7}$                                         & \\textbf{0.1973}                                                       & \\textbf{0.1537}                                                       \\\\ \\hline\nMidpoint rule \\eqref{eq_quad}                                                                   & 0.0279                                                         & \\textbf{0.1290}                                                       & \\textbf{0.1110}                                                       & 0.4279                                                         & 0.6083                                                       & 0.6113                                                       \\\\ \\hline\n\\begin{tabular}[c]{@{}c@{}}Simpson's rule ($m=500$) \\\\ via Strang formula\\end{tabular}      & $2.592\\times 10^{-9}$                                         & 0.1335                                                       & 0.1136                                                       & $5.845\\times 10^{-7}$                                         & 0.5124                                                       & 0.4827                                                       \\\\ \\hline\n\\begin{tabular}[c]{@{}c@{}}\\textsc{Matlab} \\texttt{integrate} \\\\ via Strang formula\\end{tabular} & n/a                                                            & 0.1335                                                       & 0.1136                                                       & n/a                                                            & 0.5124                                                       & 0.4827                                                       \\\\ \\hline\n\\begin{tabular}[c]{@{}c@{}}Simpson's rule ($m = 500$) \\\\ via Yoshida method\\end{tabular}    &$\\mathbf{8.381\\times 10^{-14}}$                                        & 0.1335                                                       & 0.1136                                                       & $\\mathbf{9.335\\times 10^{-12}}$                                        & 0.5124                                                       & 0.4827                                                       \\\\ \\hline\n\\begin{tabular}[c]{@{}c@{}}\\textsc{Matlab} \\texttt{integrate} \\\\ via Yoshida method\\end{tabular} & n/a                                                            & 0.1335                                                       & 0.1136                                                       & n/a                                                            & 0.5124                                                       & 0.4827                                                       \\\\ \\hline\n\\end{tabular}\n\\caption{Comparison of the relative $\\ell^2$ errors from the methods for approximating $b$ on the image from Fig. \\ref{toyimage}%for $\\tau\\in\\{0.5,4\\}$ and $|V|\\in\\{1600,6400\\}$\n. We did not compute \\texttt{integrate} for $K=1600$ as it ran too slowly. Bold entries indicate the smallest error in that column. }\n\\label{btable}\n\\end{table}\n\n%This has error \n%\\[\n%b -\\hat v(\\tau) = \\mu \\sum_{r=0}^\\infty (-1)^r \\frac{ \\tau^{r+1}}{(r+1)!} (A^r - (U\\Lambda V^T v +\\mu P_{Z_{d}})^r)  f + E\n%\\]\n%where $E$ is the error from the ODE solver. \n%From the function handle $\\omega_{ij}$, we compute the ACA \n%\\[\n%U_WV_W^T \\approx W.\n%\\]\n%These are used to approximate the degree sequence of the matrix:\n%\\[\n%d = U_W(V_W^T\\mathbf{1}) \\approx W\\mathbf{1}.\n%\\]\n%This lets us build the function handle for $A$:\n%\\[\n%A_{ij} \\approx d_i^{-r}(d_i\\delta_{ij} - \\omega_{ij}) + \\mu\\delta_{ij}1(i\\in Z_{data})\n%\\]\n%and from this we compute the symmetric positive semi-definite ACA\n%\\[\n%A \\approx \\hat A = U_A V_A^T.\n%\\] \n%We then follow the method of [Bebendorf, Kunis,2009] to compute the SVD of $\\hat A$. First, we compute the reduced QR factorisations:\n%\\begin{align*}\n%& U_A = Q_U R_U, &V_A = Q_V R_V,\n%\\end{align*}\n%and compute the SVD of the $K\\times K$ matrix \n%\\[\n%R_U R_V^T = \\hat U \\Sigma \\hat V^T.\n%\\]\n%This gives a reduced SVD for $\\hat A$\n%\\[\n%\\hat A =  (Q_U\\hat U)\\Sigma (Q_V\\hat V)^T =: U\\Sigma V^T.\n%\\]\n%Since $\\hat A$ is symmetric positive semi-definite, if $\\hat A$ is rank $K$ then $V^T U = I_K$.  It follows that \n%\\[ e^{-\\tau\\hat A} = I + U(e^{-\\tau\\Sigma}-I_K)V^T =: I + U E V^T \\]\n%Finally we compute $b \\approx A^{-1}(I -e^{-\\tau A})f$  by\n%\\[\n%b = \\tau f + U g(\\Sigma)V^Tf\n%\\]\n%where $g(\\Sigma)_{ij} := \\delta_{ij}(1-e^{-\\tau\\Sigma_{ii}}-\\tau\\Sigma_{ii})/\\Sigma_{ii}$ ($=0$ if $\\Sigma_{ii} = 0$). \n%\n%Hence \n%\\be\n%\\mathcal{S}_\\tau u \\approx e^{-\\tau\\hat A} u + b = u + U E V^Tu + b\n%%\\ee\n\\newpage\n\\section{Applications in image processing}\\label{applicationsec}\n\\subsection{Examples}\nWe consider three examples, all using images of cows from the Microsoft Research Cambridge Object Recognition Image Database\\footnote{Available at \\texttt{https://www.microsoft.com/en-us/research/project/image-understanding/} accessed 20 October 2020.}). Some of these images have been used before by \\cite{MKB,BF} to illustrate and test graph-based segmentation algorithms.\n\n\\begin{example}[Two cows]\\label{ex_twocows} We first introduce the \\emph{two cows} example familiar from \\cite{MKB,BF}. \nWe take the image of two cows in the top left of Fig.~\\ref{Fig_twocows} as the reference data $Z$ and the segmentation in the bottom left as the reference labels $f$, which separate the cows from the background. \nWe apply the SDIE scheme to segment the image of two cows shown in the top right of Fig.~\\ref{Fig_twocows}, aiming to separate the cows from the background, and compare to the ground truth in the bottom right.\nBoth images are RGB images of size $480 \\times 640$ pixels, i.e. the reference data and the image are tensors of size $480 \\times 640 \\times 3$.\n\\end{example}\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[scale=0.45]{data_test_overview.pdf}\n\\caption{Two cows: the reference data image, the reference $f$, the image to be segmented, and the ground truth segmentation associated to Example~\\ref{ex_twocows}. We drew both segmentations by hand.} \\label{Fig_twocows}\n\\end{figure}\nWe will use Example~\\ref{ex_twocows} to illustrate the application of the SDIE scheme. Moreover, we will run several numerical experiments on this example. Namely, we will:\n\\begin{itemize}\n\\item study the influence of the parameters $\\varepsilon$ and $\\tau$, comparing non-MBO SDIE ($\\tau<\\varepsilon$) and MBO SDIE ($\\tau = \\varepsilon$);\n\\item compare different normalisations of the graph Laplacian, i.e. the symmetric vs. random walk normalisation;\n\\item investigate the influence of the Nystr\\\"om-QR approximation of the graph Laplacian in terms of the rank $K$; and\n\\item quantify the inherent uncertainty in the computational strategy induced by the randomised Nystr\\\"om approximation.\n\\end{itemize}\n\n\\begin{example}[Greyscale] \\label{ex_twocows_gs}\nThis example is the greyscale version of Example~\\ref{ex_twocows}. Hence, we map the images in Fig.~\\ref{Fig_twocows} to greyscale using {\\rm\\texttt{rgb2gray}}. We show the greyscale images in Fig.~\\ref{Fig_twocows_gs}. We use the same segmentation of the reference data image as in Example~\\ref{ex_twocows}.\nThe greyscale images are matrices of size $480 \\times 640$.\n\\end{example}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[scale=0.65]{data_test_overview_gs.pdf}\n\n\\caption{Two cows greyscale: the reference data image and the image to be segmented associated to Example~\\ref{ex_twocows_gs}. Note that the reference $f$ and the ground truth segmentation are identical to those in Fig.~\\ref{Fig_twocows}.} \\label{Fig_twocows_gs}\n\\end{figure}\n\nThe greyscale image is much harder to segment than the RGB image, as there is no clear colour separation. With Example~\\ref{ex_twocows_gs}, we aim to illustrate the performance of the SDIE scheme in a harder segmentation task.\n\n\\begin{example}[Many cows] \\label{ex_manycows}\nIn this example, we have concatenated four images of cows that we aim to segment as a whole. We show the concatenated image in Fig.~\\ref{Fig_twocows_large}.\nAgain, we shall separate the cows from the background. As reference data, we use the reference data image and labels as in Example~\\ref{ex_twocows}. Hence, the reference data is a tensor of size $480 \\times 640 \\times 3$. The image consists of approximately $1.23$ megapixels. It is represented by a tensor of size $480 \\times 2560 \\times 3$.\n\\end{example}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=\\textwidth]{data_test_overview_big.pdf}\n\n\\caption{Many cows: the image to be segmented associated to Example~\\ref{ex_manycows}. Note that the reference data image and labels are identical to those in Fig.~\\ref{Fig_twocows} (left).} \\label{Fig_twocows_large}\n\\end{figure}\nWith Example~\\ref{ex_manycows}, we will illustrate the application of the SDIE scheme to large scale images, as well as the case where the image and reference data are of different sizes.\n\\begin{nb}\nIn each of these examples we took as reference data a separate reference data image. However, our algorithm does not require this, and one could take a subset of the pixels of a single image to be the reference data, and thereby investigate the impact of the relative size of the reference data on the segmentation, which is beyond the scope of this paper but is explored for the \\cite{MKB} MBO segmentation algorithm and related methods in \\cite[Fig. 4]{BayesianGraphs}.\n\\end{nb}\n\\subsection{Set-up}\\label{appsetup}\n\\paragraph{Algorithms}\nWe here use the Nystr\\\"om-QR method to compute the rank $K$ approximation to the Laplacian, and we use the \\cite{MKB} semi-implicit Euler method (with time step $\\tau/k_b$) to compute $b$ (as we found that in practice this worked best for the above examples).\n\\paragraph{Feature vectors}\nLet $\\mathcal{N}(i)$ denote the $3\\times 3$ neighbourhood of pixel $i\\in V$ in the image (with replication padding at borders performed via \\texttt{padarray}) and let $\\mathcal{K}$ be a $3\\times 3$ Gaussian kernel with standard deviation 1 (computed via \\texttt{fspecial}(\\texttt{`gaussian'},3,1)). Thus $x|_{\\mathcal{N}(i)}$ can be viewed as a triple of $3\\times 3$ matrices $x^J|_{\\mathcal{N}(i)}$ for $J\\in\\{R,G,B\\}$ (i.e. one in each of the R, G, and B channels). Then in each channel we define \\begin{align*}\n&z_i^R := 9\\mathcal{K}\\odot x^R|_{\\mathcal{N}(i)}, &z_i^G := 9\\mathcal{K}\\odot x^G|_{\\mathcal{N}(i)},& &z_i^B := 9\\mathcal{K}\\odot x^B|_{\\mathcal{N}(i)},\n\\end{align*}\nand thus define $z_i := (z_i^R,z_i^G,z_i^B)\\in\\mathbb{R}^{3\\times 3\\times 3}$, which we reshaped (using \\texttt{reshape}) so that $z\\in\\mathbb{R}^{|V|\\times 27}$. \n\\paragraph{Interpolation sets}\nFor the interpolation sets $X_1,X_2$ in Nystr\\\"om, we took $K/2$ vertices from the reference data image and $K/2$ vertices from the image to be segmented, chosen at random using \\texttt{randperm}. We experimented with choosing interpolation sets using ACA (see \\cite{BK}), but this showed no improvement over choosing random sets, and ran much slower. \n\\paragraph{Initial condition}\nWe took the initial condition, i.e. $u_0$, to equal the reference $f$ on the reference data vertices and to equal 0.49 on the vertices of the image to be segmented (where $f$ labels `cow' with 1 and `not cow' with 0). We used 0.49 rather than the more natural 0.5 because the latter led to much more of the background (e.g. the grass) getting labelled as `cow'. This choice can be viewed as incorporating the slight extra {a priori} information that the image to be segmented has more non-cow than cow.\n%\\paragraph{Parameters}\n%For Example \\ref{ex_twocows} we got best results with $\\tau=0.003$ (following \\cite{MKB}), $\\varepsilon=0.003$, $\\mu = 30$, $\\sigma = 35$, $k_b = 10$ (using the \\cite{MKB} Euler method to compute $b$), $k = 5$, $\\delta = 10^{-15}$, and $K \\in [10,250]$ (see Fig. \\ref{Fig_Error_timing} for accuracy as a function of $K$).   \n\\paragraph{Computational set-up}\nAll programming was done in \\textsc{Matlab}R2019a with relevant toolboxes the Computer Vision Toolbox Version 9.0, Image Processing Toolbox Version 10.4, and Signal Processing Toolbox Version 8.2.\nAll reported runtimes are of implementations executed serially on a machine with an Intel\\textsuperscript{\\textregistered}  Core\\textsuperscript{\\texttrademark} i7-9800X @ 3.80 GHz [16 cores] CPU and 32 GB RAM of memory.\n\n\\subsection{Two cows}\nWe begin with some examples of segmentations obtained from the SDIE scheme. Based on these, we illustrate the progression of the algorithm and discuss the segmentation output qualitatively. We will give a quantitative analysis in Section~\\ref{subsubse_error_timing_2cows}. Note that we give here merely \\emph{typical} realisations of the random output of the algorithm---the output is random due to the random choice of interpolation sets in the Nystr\\\"om approximation. We investigate the stochasticity of the algorithm in Section~\\ref{subsubse_uncertain}.\n\n\\begin{figure}[hpt]\n\\centering\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_groundtruth.pdf}\\vspace{-0.35cm}\n         \\caption{Reference data image, image to be segmented, and \\break image  masked with ground truth segmentation.}\n\\end{subfigure} \n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_taulleps.pdf}\\vspace{-0.35cm}\n\\caption{$\\tau = 0.001 \\ll 0.003 = \\varepsilon$. Relative segmentation \\break error: 1.6416\\%, elapsed time: 13.0 sec.}\n\\end{subfigure} \\\\\n \\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_tauleps.pdf}\\vspace{-0.35cm}\n\\caption{$\\tau = 0.0025 < 0.003 =\\varepsilon$. Relative segmentation \\break error: 1.9424\\%, elapsed time: 4.9 sec.}\n\\end{subfigure}\n \\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_MBOcase.pdf}\\vspace{-0.35cm}\n\\caption{$\\tau = \\varepsilon = 0.003$ (following \\cite{MKB}). Relative segmentation error: 1.5378\\%, elapsed time: 2.4 sec.}\n\\end{subfigure} \n%\\begin{subfigure}{0.49\\textwidth}\n%\\centering\n%         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_taugeps.pdf}\n%\\caption{$\\tau = 0.003 > 0.0029 = \\varepsilon$. Relative segmentation error: 87.2399\\%, elapsed time: 2.4 sec.}\n%\\end{subfigure}\n\\caption{MBO SDIE and non-MBO SDIE segmentations for the \\emph{two cows} segmentation task. In the top left figure, we show the reference data image, the image to be segmented, and the image masked with the segmentation we consider the ground truth, see also Fig.~\\ref{Fig_twocows}. The other figures (b)-(d) show the labels on the reference data, the segmentation returned by the respective algorithm, and the original images masked with the segmentation.}\n\\label{Fig_Results_MBO+SDIE} \n\\end{figure}\n\nWe consider three different cases: the MBO case $\\tau = \\varepsilon$ and two non-MBO cases, where $\\tau \\ll \\varepsilon$, and $\\tau < \\varepsilon$. We show the resulting reconstructions from these methods in Fig.~\\ref{Fig_Results_MBO+SDIE}. Moreover, we show the progression of the algorithms in Fig. \\ref{Fig_ProgressionMBO}. The parameters not given in the captions of Fig.~\\ref{Fig_Results_MBO+SDIE}  are $\\mu = 30$, $\\sigma = 35$, $k_b = 1$, $k = 1$, $\\delta = 10^{-10}$, and $K = 70$.    \n\n\\begin{nb} The regime $\\tau > \\varepsilon$ is not of much interest since, by \\cite[Remark 4.8]{Budd} \\emph{mutatis mutandis}, in this regime the SDIE scheme has non-unique solution for the update, of which one is just the MBO solution.\n\\end{nb}\n\nComparing the results in Fig.~\\ref{Fig_Results_MBO+SDIE}, we see roughly equivalent segmentations and segmentation errors. Indeed, the cows are generally nicely segmented in each of the cases. However, the segmentation also labels as `cow' a part of the wall in the background and small clumps of grass, while a small part of the left cow's snout is cut out. This may be because the reference data image does not contain these features and so the scheme is not able to handle them correctly. \n\nIn Fig.~\\ref{fig:usvsBFMKB} we compare the result of Fig.~\\ref{Fig_Results_MBO+SDIE}(d) (our best segmentation) with the results of the analogous experiments in \\cite{MKB,BF}. We observe  significant qualitative improvement. In particular, we achieve a much more complete identification of the left cow's snout, complete identification of the left cow's eyes and ear tag, and a slightly more complete identification of the right cow's hind.   \n\\begin{figure}[ht]\n    \\centering\n    \\begin{subfigure}[t]{0.32\\textwidth}\n    \\centering\n    \\includegraphics[width=\\textwidth]{BFcows2.png}\n    \\caption{Segmentation from \\cite[Fig. 4.6]{BF}}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.32\\textwidth}\n    \\centering\n    \\includegraphics[width=\\textwidth]{MKBcows2.png}\n    \\caption{Segmentation from \\cite[Fig. 2(f)]{MKB}}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.32\\textwidth}\n    \\centering\n    \\includegraphics[width=\\textwidth]{OURcows2.png}\n    \\caption{Segmentation from Fig.~\\ref{Fig_Results_MBO+SDIE}(d)}\n    \\end{subfigure}\n    \\caption{Comparison of our segmentation (using the set-up in Fig.~\\ref{Fig_Results_MBO+SDIE}(d)) with the analogous segmentations from the previous literature \\cite{MKB,BF}, both reproduced with permission from SIAM and the authors. Note that unfortunately in reproduction the colour balances and aspect ratios have become slightly inconsistent, but we can still make qualitative comparisons.  }\n    \\label{fig:usvsBFMKB}\n\\end{figure}\n\\begin{figure}[hpt]\n\\centering\n\\begin{subfigure}[t]{0.25\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth,height=4.8\\textwidth]{ProgressSDIE_taulleps.pdf}\n\\caption{$\\tau = 0.001 \\ll 0.003 = \\varepsilon$.}\n\\end{subfigure}\n\\hspace{0.1\\textwidth}\n \\begin{subfigure}[t]{0.25\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_tauleps.pdf}\n\\caption{$\\tau = 0.0025 < 0.003 =\\varepsilon$}\n\\end{subfigure}\n\\hspace{0.1\\textwidth}\n \\begin{subfigure}[t]{0.25\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_MBOcase.png}\n\\caption{$\\tau = \\varepsilon = 0.003$ (as in \\cite{MKB})}\n\\end{subfigure} \n%\\hspace{0.1\\textwidth}\n%\\begin{subfigure}[t]{0.15\\textwidth}\n%\\centering\n%         \\includegraphics[width=\\textwidth]{ProgressSDIE_taugeps.pdf}\n%\\caption{$\\tau = 0.003 > 0.0029 = \\varepsilon$}\n%\\end{subfigure}\n\\caption{Progression of MBO and non-MBO SDIE for the \\emph{two cows} example. In each subfigure: The first row shows the reference data, image, and ground truth, as in Fig.~\\ref{Fig_Results_MBO+SDIE}. The middle rows, showing the reshaped label vector $u_n$ and the image masked by the thresholded label, each represent one iteration of the considered algorithm, to be read from top to bottom. The last row gives the state returned by the scheme, i.e. the state satisfying the termination criterion, which correspond to the subfigures in Fig.~\\ref{Fig_Results_MBO+SDIE}. For layout reasons, we have squashed the figure in (a).}\n\\label{Fig_ProgressionMBO} \n\\end{figure}\n\nWe measure the computational cost of the SDIE scheme through the measured runtime of the respective algorithm. We note from Fig.~\\ref{Fig_Results_MBO+SDIE} that the MBO scheme ($\\tau = \\varepsilon$) outperforms the non-MBO schemes ($\\tau < \\varepsilon$); the SDIE relaxation of the MBO scheme merely slows down the convergence of the algorithm, without improving the segmentation. This can especially be seen in Fig.~\\ref{Fig_ProgressionMBO}, where the SDIE scheme needs many more steps to satisfy the termination criterion.\nAt least for this example, the non-MBO SDIE scheme is less efficient than the MBO scheme. Thus, in the following sections we focus on the MBO case. %and quantify its properties in the segmentation of the two cows image.\n\\subsubsection{Errors and timings} \\label{subsubse_error_timing_2cows}\nWe now quantify the influence, on the accuracy and computational cost of the segmentation, of the Nystr\\\"om rank $K$, the number of discretisation steps $k_b$ and $k$ in the Euler method and the Strang formula respectively, and the choice of normalisation of the graph Laplacian. \nTo this end, we segment the \\emph{two cows} image using the following parameters: $\\varepsilon = \\tau = 0.003$,  $\\mu = 30$, $\\sigma = 35$, and $\\delta = 10^{-10}$. We take $K \\in \\{10, 25, 70, 100, 250\\}$, $(k_b, k) \\in \\{(1,1), (10,5)\\}$, and use the random walk Laplacian $\\Delta$ and the symmetric normalised Laplacian $\\Delta_s$. \n\nWe plot runtimes and relative segmentation errors in Fig.~\\ref{Fig_Error_timing}. As our method has randomness from the Nystr\\\"om extension, we repeat every experiment 100 times and show means and standard deviations. We make several observations. Starting with the runtimes, we indeed see that these are roughly linear in $K$, verifying numerically the expected complexity. The runtime also increases when increasing $k_b$ and $k$. That is, increasing the accuracy of the Euler method and Strang formula does not lead to faster convergence, and also does not increase the accuracy of the overall segmentation. Finally, we see that the symmetric normalised Laplacian incurs consistently low relative segmentation error for small values of $K$. This property is of the utmost importance to scale up our algorithm for very large images. Interestingly, the segmentations using the symmetric normalised Laplacian seem to deteriorate for a large $K$. The random walk Laplacian has diametric properties in this regard: the segmentations are only reliably accurate when $K$ is reasonably large. \n\n\n\\begin{figure}[hpt]\n\\centering\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Error_Time_twocows_Eul1LPF1_symm0.pdf}\n\\caption{$k_b=1$, $k = 1$, random walk Laplacian.}\n\\end{subfigure}\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Error_Time_twocows_Eul10LPF5_symm0.pdf}\n\\caption{$k_b=10$, $k = 5$, random walk Laplacian.}\n\\end{subfigure}\\\\\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Error_Time_twocows_Eul1LPF1_symm1.pdf}\n\\caption{$k_b=1$, $k = 1$, symmetric normalised Laplacian.}\n\\end{subfigure}\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Error_Time_twocows_Eul10LPF5_symm1.pdf}\n\\caption{$k_b=10$, $k=5$, symmetric normalised Laplacian.}\n\\end{subfigure}\n\\caption{Error and timing of $100$ independent segmentations of the two cows image (Example~\\ref{ex_twocows}) with the MBO SDIE scheme. The solid lines represent the means averaged over 100 runs, the dotted lines show means $\\pm$ standard deviations.}\n\\label{Fig_Error_timing} \n\\end{figure}\n\n\n\n\\subsubsection{Uncertainty in the segmentation} \\label{subsubse_uncertain}\nDue to the randomised Nystr\\\"om approximation, our approximation of the SDIE scheme is inherently stochastic. \nTherefore, the segmentations that the algorithm returns are realisations of random variables. \nWe now briefly study these random variables, especially with regard to $K$. We show pointwise mean and standard deviations of the binary labels in each of the left two columns of the four subfigures of Fig.~\\ref{Fig_MonteCarlo}. In the remaining figures, we weight the original \\emph{two cows} image with these means (varying continuously between label 1 for `cow' and label 0 for `not cow') and standard deviations.  For these experiments we use the same parameter set-up as Section~\\ref{subsubse_error_timing_2cows}. \n\n\n\\begin{figure}[hpt]\n\\centering\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{MC_twocows_Eul1LPF1_symm0.pdf}\\vspace{-0.8cm}\n\\caption{$k_b=1$, $k = 1$, random walk Laplacian. }\n\\end{subfigure}\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{MC_twocows_Eul10LPF5_symm0.pdf}\\vspace{-0.8cm}\n\\caption{$k_b=10$, $k = 5$, random walk Laplacian.\n}\n\\end{subfigure}\\\\\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{MC_twocows_Eul1LPF1_symm1.pdf}\\vspace{-0.8cm}\n\\caption{$k_b=1$, $k = 1$, symmetric normalised Laplacian.}\n\\end{subfigure}\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{MC_twocows_Eul10LPF5_symm1.pdf}\\vspace{-0.8cm}\n\\caption{$k_b=10$, $k=5$, symmetric normalised Laplacian.}\n\\end{subfigure}\n\\caption{Mean, standard deviation, and images weighted by mean and standard deviation of $100$ independent segmentations of Example~\\ref{ex_twocows} with the MBO SDIE scheme, with set-up as in Section~\\ref{subsubse_error_timing_2cows}.}\n\\label{Fig_MonteCarlo} \n\\end{figure}\n\nWe make several observations. First, as $K$ increases we see less variation. This is what we expect, as when $K=|V|$ the method is deterministic so has no variation. Second, the type of normalisation of the Laplacian has an effect: the symmetric normalised Laplacian leads to less variation than the random walk Laplacian. Third, the parameters $k_b$ and $k$  appear to have no major effect within the range tested. Finally, looking at the figures with rather large $K$, we observe that the standard deviation of the labels is high in the areas of the figure in which there is indeed uncertainty in the segmentation, namely the boundaries of the cows and the parts of the wall with similar colour to the dark cow. Determining the exact position of the boundary of a cow on a pixel-by-pixel level is indeed also difficult for a human observer. Moreover, the SDIE scheme usually confuses the wall in the background for a cow. Hence, a large standard deviation here reflects that the estimate is uncertain. \n\nThis is of course not a rigorous Bayesian uncertainty quantification, as for instance is given in \\cite{BayesianGraphs,GraphUQ} for graph-based learning. However the use of stochastic algorithms for inference tasks, and the use of their output as a method of uncertainty quantification, has for instance been motivated by \\cite{SGDBayes}.\n\n\\subsection{Greyscale}\nWe now move on to Example~\\ref{ex_twocows_gs}, the \\emph{greyscale} problem. We will especially use this example to study the influence of the parameters $\\mu$ and $\\sigma$. The parameter $\\mu > 0$ determines the strength of the fidelity term in the ACE. From a statistical point of view, we can understand a choice of $\\mu$ as an assumption on the statistical precision (i.e. the inverse of the variance of the noise) of the reference~$f$ (see \\cite[Section 3.3]{GraphUQ} %and \\cite[Section 2.2]{Stuart2010} \nfor details). Thus, a small $\\mu$ should lead to a stronger regularisation coming from the Ginzburg--Landau functional, and a large $\\mu$ leads to more adherence to the reference. The parameter $\\sigma > 0$ is the `standard deviation' in the Gaussian kernel $\\Omega$ used to build the weight matrix $\\omega$. For our methods we must not choose too small a $\\sigma$, as otherwise the weight matrix becomes sparse (up to some precision), and so the Nystr\\\"om submatrix $\\omega_{XX}$ has a high probability of being ill-conditioned.\\footnote{However, in such a case this sparsity can be exploited using Raleigh\u2013Chebyshev \\cite{RC} methods as in \\cite{MKB}, or \\textsc{Matlab} sparse matrix algorithms as in \\cite{BF}. This lies beyond the scope of this paper.} If $\\sigma$ is too large then the graph structure no longer reflects the features of the image. %Larger $\\sigma$ will lead to high edge weights, even if the features are fairly different, which should smooth out the segmentation. Small $\\sigma$ should lead to a more erratic segmentation.\n\n\\begin{figure}[hpt]\n\\centering\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_GStruth.pdf}\n\\end{subfigure} \\\\\n\\begin{subfigure}{0.49\\textwidth}\n\\centering\n        \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_GS1_cropped.pdf} \n \\caption{$\\mu = 100, \\sigma = 50$, error = 5.7868 \\%, time = 6.9 sec.}\n\\end{subfigure}\n \\begin{subfigure}{0.49\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{ProgressSDIE_Result_GS2_cropped.pdf} \n\\caption{$\\mu = 150, \\sigma = 35$, error = 5.8245 \\%, time = 7.0 sec.}\n\\end{subfigure}\n\\caption{MBO SDIE segmentations for the \\emph{greyscale} segmentation task. In the centred top figure, we show the reference data image, the image to be segmented, and the image masked with the ground truth segmentation, cf. Fig.~\\ref{Fig_twocows}. The other figures show the reference $f$, the segmentation returned by the algorithm, and the original images masked with the segmentation.}\n\\label{Fig_Results_greysc} \n\\end{figure}\n\nIn the following, we set $\\varepsilon = \\tau = 0.00024$, $k_b = 10$, $k = 5$, and $\\delta = 10^{-10}$. To get reliable results we choose a rather large $K$, $K=200$, and therefore (by the discussion in Section \\ref{subsubse_uncertain}) we use the random walk Laplacian. We will qualitatively study single realisations of the inherently stochastic SDIE algorithm. We vary $\\mu \\in \\{50, 100, 150, 200\\}$ and $\\sigma \\in \\{20, 35, 50\\}$. We show the best results from these tests in  Fig.~\\ref{Fig_Results_greysc}. Moreover, we give a comprehensive overview of all tests and the progression of the SDIE scheme in Fig.~\\ref{Fig_Progression_GS}.\n\\begin{figure}[htp]\n    \\centering\n    \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu50_sig20.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 50, \\sigma = 20$, error = 12.7887 \\%, time = 7.0 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu100_sig20.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 100, \\sigma = 20$, error = 6.0492 \\%, time = 7.0 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu150_sig20.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 150, \\sigma = 20$, error = 5.9326 \\%, time = 7.1 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu200_sig20.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 200, \\sigma = 20$, error = 6.293 \\%, time = 13.3 sec.}\\vspace{0.25cm}\n    \\end{subfigure} \\\\\n        \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu50_sig35.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 50, \\sigma = 35$, error = 12.7969 \\%, time = 7.1 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu100_sig35.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 100, \\sigma = 35$, error = 5.9043 \\%, time = 7.2 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu150_sig35.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 150, \\sigma = 35$, error = 5.8245 \\%, time = 7.0 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu200_sig35.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 200, \\sigma = 35$, error = 6.1882 \\%, time = 7.1 sec.}\\vspace{0.25cm}\n    \\end{subfigure} \\\\\n        \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu50_sig50.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 50, \\sigma = 50$, error = 12.7995 \\%, time = 7.0 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu100_sig50.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 100, \\sigma = 50$, error = 5.7868 \\%, time = 6.9 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu150_sig50.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 150, \\sigma = 50$, error = 5.8861 \\%, time = 6.9 sec.}\\vspace{0.25cm}\n    \\end{subfigure}\n       \\begin{subfigure}{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Progression_GS_mu200_sig50.pdf}\\vspace{-0.25cm}\n    \\caption{$\\mu = 200, \\sigma = 50$, error = 6.291 \\%, time = 7.1 sec.}\\vspace{0.25cm}\n    \\end{subfigure} \n    \\caption{Progression of the MBO SDIE scheme for the \\emph{greyscale} segmentation task. In each subfigure: The first row shows the reference data, the image to be segmented, and the ground truth segmentation. The middle rows, showing the reshaped label vector $u_n$ and the image masked by the label, each represent one iteration of the considered algorithm, to be read from top to bottom. The last row gives the state returned by the scheme, i.e. the state satisfying the termination criterion.}\n    \\label{Fig_Progression_GS}\n\\end{figure}\nWe observe that this segmentation problem is indeed considerably harder than the \\emph{two cows} problem, as we anticipated after stating Example~\\ref{ex_twocows_gs}. The difference in shade between the left cow and the wall is less visible than in Example~\\ref{ex_twocows}, and the left cow's snout is less identifiable as part of the cow. Thus, the segmentation errors we incur are about 3 times larger than before. There is hardly any visible influence from changing $\\sigma$ in the given range. However, $\\mu$ has a significant impact on the result. Indeed,  for $\\mu=50$ the algorithm does not find any segmentation. For $\\mu \\geq 100$, we get more practical segmentations. Interestingly, for $\\mu = 150$ and $\\mu = 200$ we get almost all of the left cow, but misclassify most of the wall in the background; \nfor $\\mu = 100$, we miss a large part of the left cow, but classify more accurately the wall.\nThe interpretation of $\\mu$ as the statistical precision of the reference explains this effect well. For $\\mu = 100$, we assume that the reference is less precise, leading us (due to the smoothing effect of the Ginzburg--Landau regularisation) to classify accurately most of the wall. With $\\mu \\geq 150$, we assume that the reference is more precise, leading us to misclassify the wall (due to its similarity to the cows in the reference data image) but classify accurately more of the cows. At $\\mu = 200$, this effect even leads to a larger total segmentation error.\nThe runtimes are approximately equal across all choices of parameters, except for $\\mu = 200$ and $\\sigma = 20$ for which the runtime is much higher. \n\n\n\\subsection{Many cows}\n\n\\begin{figure}[ht]\n\\centering\n\\begin{subfigure}{0.99\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Bigcow_result_sameastwocows.pdf}\\vspace{-0.5cm}\n         \\caption{Segmentation with parameters $\\varepsilon = \\tau = 0.003, K = 70, k_b = 1, k = 1, \\mu = 30, \\sigma = 35$, and the symmetric normalised Laplacian. Elapsed time for segmentation: 9.1 sec.}\n\\end{subfigure} \\\\\n\\begin{subfigure}{0.99\\textwidth}\n\\centering\n        \\includegraphics[width=\\textwidth]{Bigcow_result_moresensible.pdf}\\vspace{-0.5cm}\n\\caption{Segmentation with parameters $\\varepsilon = \\tau = 0.00025, K = 100, k_b = 1, k = 1, \\mu = 500, \\sigma = 35$, and the symmetric normalised Laplacian. Elapsed time for segmentation: 14.0 sec.}\n\\end{subfigure}\\\\\n \\begin{subfigure}{0.99\\textwidth}\n\\centering\n         \\includegraphics[width=\\textwidth]{Bigcow_result_moresensible2.pdf}\\vspace{-0.5cm}\n\\caption{Segmentation with parameters $\\varepsilon = \\tau = 0.00025, K = 100, k_b = 10, k = 10, \\mu = 400, \\sigma = 35$, and the symmetric normalised Laplacian. Elapsed time for segmentation: 19.1 sec.}\n\\end{subfigure}\n\\caption{Segmentations of the MBO scheme for the \\emph{many cows} segmentation task. In each subfigure: the top row shows the reference data image and twice the image that is to be segmented, and the bottom row shows the reference $f$, the segmentation returned by the respective algorithm, and the original image masked with the segmentation.}\n\\label{Fig_Results_manycows} \n\\end{figure}\n\nWe finally study the \\emph{many cows} example, i.e. Example~\\ref{ex_manycows}. The main differences to the earlier examples are the larger size of the image that is to be segmented and the variety within it. We first comment on the size. The image is given by a $480 \\times 2560 \\times 3$ tensor, which is a manageable size. The graph Laplacian, however, is a dense matrix with $1.536 \\times 10^6$ rows and columns. A matrix of this size requires $17.6$ TB of memory to be constructed in \\textsc{Matlab}R2019a. This image is much more difficult to segment than the previous examples, in which the cows in the image to be segmented are very similar to the cows in the reference data. Here, we have concatenated images of cows that look very different, e.g. cows with a white blaze on their nose.\n\nAs the \\emph{two cows} image is part of the \\emph{many cows} image, we first test the algorithmic set-up that was successful at segmenting the former. We show the result (and remind the reader of the set-up) in Fig.~\\ref{Fig_Results_manycows}(a). The segmentation obtained in this experiment is rather mediocre---even the \\emph{two cows} part is only coarsely reconstructed.  We present two more attempts at segmenting the \\emph{many cows} image in Fig.~\\ref{Fig_Results_manycows}: we choose $\\varepsilon = \\tau = 0.00025$, a slightly larger Nystr\\\"om rank $K = 100$, and vary $(k_b, k, \\mu) \\in \\{(1,1,500), (10,10,400)\\}$. In both cases, we obtain a considerably better segmentation of the image. In the case where $\\mu = 500$, we see a good, but slightly noisy segmentation of the brown and black parts of the cows. In the case where $\\mu = 400$, we reduce the noise in the segmentation, but then also misclassify some parts of the cows. The blaze (and surrounding fur) is not recognised as `cow' in any of the segmentations, likely because the blaze is not represented in the reference data image.\nThe influence of the set-up on the runtimes is now much more pronounced. For the given segmentations, however, all the runtimes are at most a factor of eight larger than the smallest runtimes in the previous examples, despite the larger image size.\n\n%* Pictures of the segmentation, qualitative improvement \\cite{MKB}, run times, uncertainty in Nystr\\\"om vs. ACA\\\\\n%* Quantify speed improvement of QR Nystrom vs BF Nystrom vs QR ACA and maybe accuracy (on toy images) vs. SVD rank K approx of Laplacian [[DONE]]\\\\\n%* Quantify improvement of LPF vs Euler (on toy images) [[DONE]] \\\\\n%* Symmetric vs rw matrix\\\\\n%* Tests of different params? -- Label the other cows image and compare accuracy to ``ground truth\"  \\\\\n%* SDIE vs MBO (SDIE loses :( )\n\n\\section{Conclusion}\n\nExtending the set-up and results in \\cite{Budd}, we defined the continuous-in-time graph Allen--Cahn equation (ACE) with fidelity forcing as in \\cite{BF} and a semi-discrete implicit Euler (SDIE) time discretisation scheme for this equation. We proved well-posedness of the ACE and showed that solutions of the SDIE scheme converge to the solution of the ACE. Moreover, we proved that the graph Merriman--Bence--Osher (MBO) scheme with fidelity forcing \\cite{MKB} is a special case of an SDIE scheme.\n\nWe provided an algorithm to solve the SDIE scheme, which---besides the obvious extension from the MBO scheme to the SDIE scheme---differs in two key places from the existing algorithm for graph MBO with fidelity forcing: it implements the Nystr\\\"om extension via a QR decomposition and it replaces the Euler discretisation of the diffusion step with a computation based on the Strang formula for matrix exponentials. The former of these changes appears to have been a quite significant improvement: in experiments the Nystr\\\"om-QR method proved to be faster, more accurate, and more stable than the Nystr\\\"om method used in previous literature \\cite{MKB,BF}, and it is less conceptually troubling than that method, as it does not involve taking the square root of a non-positive-semi-definite matrix. \n\nWe applied this algorithm to a number of image segmentation examples concerning images of cows from the Microsoft Research Cambridge Object Recognition Image Database. We found that whilst the SDIE scheme yielded no improvement over the MBO scheme (and took longer to run in the non-MBO case) the other improvements that we made led to a substantial qualitative improvement over the segmentations of the corresponding examples in \\cite{MKB,BF}. We furthermore investigated empirically various properties of this numerical method and the role of different parameters. In particular:\n\\begin{itemize}\n    \\item We found that the symmetric normalised Laplacian incurred consistently low segmentation error when approximated to a low rank, whilst the random walk Laplacian was more reliably accurate at higher ranks (where `higher' is still less than 0.1\\% of the full rank). Thus for applications that require scalabity, and thus very low-rank approximations, we recommend using the symmetric normalised Laplacian.\n    \\item We investigated empirically the uncertainty inherited from the randomisation in the Nystr\\\"om extension. We found that the rank reduction and the normalisation of the graph Laplacian had the most influence on the uncertainty, and we furthermore observed that at higher ranks the segmentations had high variance at those pixels which are genuinely difficult to classify, e.g. the boundaries of the cows.\n    \\item We noted that the fidelity parameter $\\mu$ corresponds to ascribing a statistical precision to the reference data. We observed that when the reference data were not fully informative, as in Examples \\ref{ex_twocows_gs} and \\ref{ex_manycows}, it was important to tune this parameter to get an accurate segmentation.\n\\end{itemize}\n\nTo conclude, we give a number of directions we hope to explore in future work, in no particular order. \n\nWe seek to investigate the use of the very recent method of \\cite{BSV} combined with methods such as the HMT method \\cite{HMT} or the (even more recent) generalised Nystr\\\"om method \\cite{Yuji} to further increase the accuracy of the low-rank approximations to the graph Laplacian. Unfortunately, we became aware of these works too near to finalising this paper to use those methods here.\n\nWe will seek to extend both our theoretical and numerical framework to multi-class graph-based classification, as considered for example in \\cite{BayesianGraphs,GCP,Auction}. The groundwork for this extension was laid by the authors in  \\cite[Section 6]{volumeBudd}.\n\nThis work dovetails with currently ongoing work of the authors with Carola-Bibiane Sch\\\"onlieb and Simone Parisotto exploring graph-based joint reconstruction and segmentation with the SDIE scheme. In practice, we often do not observe images directly, but must reconstruct an image from what we observe. For example, when the image is noisy, blurred, has regions missing, or we observe only a transform of the image, such as the output of a CT or MRI scanner. `Joint reconstruction and segmentation' (see \\cite{jointrecon1,jointrecon2}) is the task of simultaneously reconstructing and segmenting an image, which can reduce computational time and improve the quality of both the reconstruction and the segmentation.\n\nWe will also seek to develop an SDIE classification algorithm that is scalable towards larger data sets containing not just one, but hundreds or thousands of reference data images. This can be attempted via data subsampling: rather than evolving the SDIE scheme with regard to the full reference data set, we use only a data subset that is randomly replaced by a different subset after some time interval has passed.  Data subsampling is the fundamental principle of various algorithms used in machine learning, such as stochastic gradient descent \\cite{RobbinsMonro}. A subsampling strategy that is applicable in continuous-in-time algorithms has recently been proposed and analysed by \\cite{Jonas}.\n\n\n\\appendix \n\\section{An analysis of the method from \\cite{MKB}} \n\\label{MKBapp} \nIn \\cite{MKB}, the authors approximated $\\mathcal{S}_\\tau u$ by a semi-implicit Euler method for fidelity forced diffusion. That is, since $\\mathcal{S}_\\tau u$ is defined to equal $v(\\tau)$ where $v$ is defined by\n\t\\[\\frac{dv}{dt} = -\\Delta v  -\\mu P_{Z}(v-f), \\qquad v(0) = u, \\] \nthe authors of \\cite{MKB} approximate trajectories of this ODE by a semi-implicit Euler method with time step $\\delta t>0$ (such that $\\tau/\\delta t\\in\\mathbb{N}$), i.e. $v_0:=u$ and\n\\[\n\\frac{v_{k+1}-v_k}{\\delta t} = -\\Delta v_{k+1} -\\mu P_{Z}(v_k-f)\n\\]\nwith solution \n\\be \\label{Eulersoln}\n\\begin{split}\nv_{k+1} &= \\left(I+\\delta t \\Delta\\right)^{-1}\\left(v_k - \\mu\\delta t  P_{Z}(v_k-f)\\right)\\\\\n&=\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)v_k+\\mu\\delta t \\left(I+\\delta t \\Delta\\right)^{-1} f\n\\end{split}\n\\ee\nand then \\eqref{Eulersoln} leads to the approximation $\\mathcal{S}_\\tau u\\approx v_{\\tau/\\delta t}$. \nTo compute \\eqref{Eulersoln}, they use the Nystr\\\"om decomposition to compute the leading eigenvectors and eigenvalues of $\\Delta$. \n\\begin{nb}\nIn fact, in \\cite{MKB} the authors use $\\Delta_s$ not $\\Delta$. It makes no difference to this analysis which Laplacian is used.\n%In particular, \\cite{MKB} first approximate $\\omega$ by a Nystr\\\" om decompiosition, which they use to approximate $D$. This then yields a Nystr\\\"om decomposition of $D^{-1/2}\\omega D^{-1/2}$, which they use the trick in [blah] to compute the eigenvalue decomposition $D^{-1/2}\\omega D^{-1/2}=\\hat U \\Lambda'\\hat U^T$. Then $\\Lambda = I-\\Lambda'$. \n\\end{nb}\nGiven $\\Delta\\approx U_1\\Lambda U_2^T$, an approximate SVD of low rank, the authors approximate \\eqref{Eulersoln} by \n\\be\n\\label{Eulersoln2}\n\\begin{split}\n\\hat v_{k+1} &= U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T(\\hat v_k -\\mu\\delta t P_{Z}(\\hat v_k-f))\\\\\n&=  U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T(I-\\mu\\delta t P_{Z})\\hat v_k + \\mu \\delta t  U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T f.\n\\end{split}\n\\ee\nTherefore, the final approximation for $\\mathcal{S}_\\tau u$ in \\cite{MKB} is computed by setting $\\hat v_0 = u$ and $\\mathcal{S}_\\tau u\\approx \\hat v_{\\tau/\\delta t}$.\n\\subsection{Analysis}\nBoth \\eqref{Eulersoln} and \\eqref{Eulersoln2} are of the form \n\\[\nv_{k+1} = \\mathcal{A}v_k + g.\n\\]\nBy induction, this has $k^\\text{th}$ term \n\\be\\label{kthterm}\nv_k = \\mathcal{A}^k v_0 + \\sum_{r=0}^{k-1} \\mathcal{A}^r g = \\mathcal{A}^k v_0 + (\\mathcal{A}-I)^{-1}(\\mathcal{A}^{k}-I) g. \n\\ee\nThus taking $k = \\tau/\\delta t$ and $v_0 = u$, we get successive approximations \n\\begin{align}\n\\notag &\\mathcal{S}_\\tau u \\\\\n\\label{approx1}&\\approx \\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^k u\\\\ \n\\notag &\\quad + \\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)-I\\right]^{-1} \\left(\\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^k - I\\right) \\mu\\delta t \\left(I+\\delta t \\Delta\\right)^{-1} f\\\\\n\\label{approx2}&\\approx \\left[  U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T(I-\\mu\\delta t P_{Z})\\right]^k u\\\\ \n\\notag &\\quad + \\left[U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T\\left(I - \\mu\\delta t  P_{Z}\\right)-I\\right]^{-1} \\left(\\left[U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^k - I\\right) \\mu\\delta t U_1(I_K + \\delta t \\Lambda)^{-1} U_2^Tf.\n\\end{align}\nTo see what these approximations are doing, note that \n\\[\nI + \\delta t X = e^{\\delta t X} +\\bigO(\\delta t^{2})\n\\]\nand note the Lie product formula \\cite[Theorem 2.11]{Hall}\n\\begin{align*}\n&e^{(X + Y)/k} = e^{X/k}e^{Y/k} +\\bigO(k^{-2}) &\\text{and therefore}& &e^{X + Y} = \\left(e^{X/k}e^{Y/k}\\right)^k +\\bigO(k^{-1}). \n\\end{align*}\nThen, since $k\\delta t = \\tau$,\n\\be \\label{LPFapprox}\n\\begin{split}\n\\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^k &= \\left[e^{-\\delta t\\Delta}e^{-\\mu\\delta t P_{Z}} +\\bigO(\\delta t^2)\\right]^k \\\\\n&= \\left[e^{-\\delta t\\Delta}e^{-\\mu\\delta t P_{Z}}\\right]^k +\\bigO(k\\delta t^2)\\\\\n&= \\left(e^{-\\tau(\\Delta +\\mu P_{Z})} + \\bigO(k\\delta t^2) \\right) +\\bigO(k\\delta t^2) \\\\&= e^{-\\tau A} + \\bigO(\\delta t)\n\\end{split}\n\\ee\nand the second term in \\eqref{approx1} becomes \n\\begin{align*}\n&\\left[I-\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^{-1} \\left(I-e^{-\\tau A} + \\bigO(\\delta t) \\right) \\mu\\delta t \\left(I+\\delta t \\Delta\\right)^{-1}\\\\\n&= \\mu \\left( \\Delta + \\mu P_{Z}\\right)^{-1}(I+\\delta t \\Delta) \\left(I-e^{-\\tau A} + \\bigO(\\delta t) \\right)\\left(I+\\delta t \\Delta\\right)^{-1} \\\\\n&=\\mu A^{-1}(I-e^{-\\tau A}) + E + \\bigO(\\delta t)\n\\end{align*}\nwhere (writing $[X,Y]:=XY - YX$ for the commutator of $X$ and $Y$)\n\\begin{align*}E&:=\\mu A^{-1}(I+\\delta t \\Delta) \\left [I-e^{-\\tau A},(I+\\delta t \\Delta)^{-1}\\right] \\\\\n&= -\\mu A^{-1}(I+\\delta t \\Delta) \\left [e^{-\\tau A},(I+\\delta t \\Delta)^{-1}\\right] \\\\\n&=\\mu A^{-1} \\left [e^{-\\tau A},(I+\\delta t \\Delta)\\right](I+\\delta t \\Delta)^{-1}\\\\\n&=\\mu\\delta t A^{-1} \\left [e^{-\\tau A},  \\Delta\\right](I+\\delta t \\Delta)^{-1} = \\bigO(\\delta t)\n\\end{align*}\n is the commutation error. Hence the overall error for $\\eqref{approx1}$ is $\\bigO(\\delta t)$. The error for \\eqref{approx2} is similar but also contains an extra error from the spectrum truncation. \n \nWe can also relate this Euler method to a modified quadrature rule. It is easy to see from \\eqref{fdiffusesoln} that \n\\[\nS_\\tau u = e^{-\\tau A} u + \\mu \\int_0^\\tau e^{-tA}f \\; dt.\n\\]\nWe understand the Euler approximation for the $e^{-\\tau A}u$ term by \\eqref{LPFapprox}. By \\eqref{kthterm}, we can write the Euler approximation for the integral term as \n\\begin{align}\n    \\label{quad1} \\mu \\int_0^\\tau e^{-tA}f \\; dt &\\approx \\mu\\delta t \\sum_{r=0}^{k-1} \\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^r\\left(I+\\delta t \\Delta\\right)^{-1} f \\\\\n    \\label{quad2} &\\approx \\mu\\delta t \\sum_{r=0}^{k-1} \\left[  U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T(I-\\mu\\delta t P_{Z})\\right]^rU_1(I_K + \\delta t \\Lambda)^{-1} U_2^Tf.\n\\end{align}\nWe note that, since $P_Z$ is idempotent (and assuming that $\\mu \\delta t <1 $), \n\\[(I-\\mu\\delta t P_Z)^{-1} = I + \\frac{\\mu\\delta t}{1-\\mu\\delta t}P_Z \\]\nand, since $P_Zf = f$, that\n$ (I + \\mu\\delta t/(1-\\mu\\delta t)P_Z)f = (1-\\mu\\delta t)^{-1}f$. Therefore, we can rewrite \\eqref{quad1} as \n\\begin{align*}\nb:=\\mu\\int_0^\\tau e^{-tA}f \\; dt &\\approx \\frac{\\mu\\delta t}{1-\\mu\\delta t} \\sum_{r=0}^{k-1} \\left[\\left(I+\\delta t \\Delta\\right)^{-1}\\left(I - \\mu\\delta t  P_{Z}\\right)\\right]^{r+1} f & \\\\\n&= \\frac{\\mu\\delta t}{1-\\mu\\delta t} \\sum_{r=1}^{k} \\left(e^{-r\\delta t A}f + \\bigO(r\\delta t^2)\\right) &\\text{by \\eqref{LPFapprox} and relabelling $r$}\\\\\n&= \\left(\\frac{\\mu\\delta t}{1-\\mu\\delta t} \\sum_{r=1}^{k} e^{-r\\delta t A}f \\right)+ \\bigO(\\tau^2\\delta t) &\n\\end{align*}\nrecalling that $k\\delta t = \\tau$. This can be seen to be a quadrature by the right-hand rule, multiplied by a factor of $(1-\\mu\\delta t)^{-1}$. Likewise, we can rewrite \\eqref{quad2} as \n\\[\n\\mu\\int_0^\\tau e^{-tA}f \\; dt \\approx \\frac{\\mu\\delta t}{1-\\mu\\delta t} \\sum_{r=1}^{k} \\left[ U_1(I_K + \\delta t \\Lambda)^{-1} U_2^T(I-\\mu\\delta t P_{Z})\\right]^{r} f\n\\]\nwhere going from \\eqref{quad1} to \\eqref{quad2} has incurred an extra error from the spectrum truncation alongside the quadrature and Lie product formula errors. \n\n\\subsection{Conclusions from analysis}\n\nThe key takeaway from these calculations (besides the verification that we have the usual $\\bigO(\\delta t)$ Euler error) concerns \\eqref{LPFapprox}. That equation shows that the Euler approximation for the $e^{-\\tau A}$ term is in fact an approximation of a Lie product formula approximation for $e^{-\\tau A}$. This motivates our method of cutting out the middleman and using a matrix exponential formula directly, and furthermore motivates our replacement of the linear error Lie product formula with the quadratic error Strang formula. \n\nWe have also shown how the Euler method approximation for $b$ can be written as a form of quadrature, motivating our investigation of other quadrature methods as potential improvements for computing $b$.  \n\n\n%\n%\\section{Jonas' alternative efficient discretisation scheme}\n%Let $W$ be the weight matrix and $A := \\mathrm{Id}_N-D^{-1/2}WD^{-1/2} + \\mu P_Z$. We need to solve an ODE of the form:\n%$$\n%\\dot{u}(t) = -Au(t) + b \\qquad \\qquad (\\text{s.t. initial condition})\n%$$\n%We aim to solve this ODE with a higher order ODE solver; say \\texttt{ode45}. This will require us to compute \\textit{many} matrix vector products $A \\cdot u$.\n%To this end, we aim to approximate $A$ by a matrix $\\tilde{A}$ of the following form:\n%$$\n%\\tilde{A} = \\mathrm{diag}(y) + UV,\n%$$\n%where $y$ is some vector and $U,V$ are rank $K \\ll N$. This would lead to $\\tilde{A}\\cdot u$  having a computational cost of $O(NK)$ (I guess).\n%\\paragraph{Sketch of an algorithm:}\n%\\begin{enumerate}\n%\\item Let $W' := W + \\mathrm{Id}_N$\n%\\item Compute $I := \\mathrm{ACA\\_SPSD}(W')$ and set $U':= W'(:,I)$, $V':= W'(I,I)^{-1}W'(I,:)$.\n%\\textit{\\underline{Comment:} Note that $U'V' - \\mathrm{Id}_N =: \\tilde{W}\\approx W$}\n%\\item Approximate the degrees $d$ using $W$; also obtain $D := \\mathrm{diag}(d)$.\n%\\item Obtain\n%\\begin{align*}\n%\\tilde{A} &:= \\mathrm{Id}_N-D^{-1/2}\\tilde{W}D^{-1/2} + \\mu P_Z \\\\\n%&= \\mathrm{Id}_N-(D^{-1/2}U'V'D^{-1/2} - D^{-1/2}\\mathrm{Id}_ND^{-1/2}) + \\mu P_Z \\\\\n%&= \\mathrm{Id}_N-\\underbrace{D^{-1/2}U'}_{=: U}\\underbrace{V'D^{-1/2}}_{=: V} + D + \\mu P_Z \\\\\n%&=  \\underbrace{\\mathrm{Id}_N + D + \\mu P_Z}_{=:\\mathrm{diag}(y)} - UV\n%\\end{align*}\n%where $y := \\mathbf{1} + d + \\mu p_z$, with $P_Z = \\mathrm{diag}(p_Z)$.\n%\n%\\end{enumerate}\n%\\paragraph{Remarks:}\n%\\begin{itemize}\n%\\item Using the algorithm above, one could also use the (asymmetric) random walk normalisation: $\\Delta = \\mathrm{Id}_N-D^{-1}W$. In this case, $U := D^{-1/2}U'$ and $V := V'$.\n%\\item To get $b$, we also need to solve an equation with $\\tilde{A}$. Due to the form of $\\tilde{A}$, one can use a Woodbury-type identity for fast matrix inversion.\n%\\item We use $W'$ instead of $W$, as $W'$ is SPSD -- $W$ isn't. Also, $W$ has zeros on the diagonal; thus, ACA\\_SPSD is not well-defined for $W$.\n%\\end{itemize}\n%%\n%\n%\\begin{algorithm}[h]\n%\\SetAlgoLined\n%%\\DontPrintSemicolon\n%\\KwIn{ $\\omega$ (as a function, never the full matrix), $Z, K$. }\n%\\KwOut{$U,\\Lambda $.}\n%\\KwResult{Computes $U$ and $\\Lambda$, with $\\Delta\\approx U\\Lambda U^T$ a rank $K$ approximate eigendecomoposition.  }\n%$ X = \\texttt{rand\\_subset}(Z,K) $ \\;\n%$\\omega_{{XX}}=\\omega({X},{X})$ \\;\n%$P=\\omega(:,{X})$ \\;\n%$d =P \\left(\\omega_{{XX}}^{-1} \\left(P^T\\mathbf{1}\\right)\\right) $ \\;\n%$ P = d^{-1/2} \\:.\\ast P $ \\tcp*{Exponentiation elementwise, product rowwise}\n%$ [Q,R] = \\texttt{qr}(P,0) $ \\tcp*{Computes thin QR decomoposition $P=QR$}\n%$ S = R\\omega_{{XX}}^{-1}R^T$ \\;\n%$ S = (S + S^T)/2 $ \\tcp*{Corrects symmetry-breaking computational errors}\n%$ [\\Phi,\\Sigma] = \\texttt{eig}(S)$  \\tcp*{Computes eigendecomoposition $S = \\Phi\\Sigma\\Phi^T$}\n%$ \\Lambda = I_K -\\Sigma$ \\;\n%$ U = Q\\Phi$ \\tcp*{Orthonormal by construction}\n% \\caption{[Bebendorf,Kunis,2009]-inspired Nystr\\\"om method for eigendecomoposition of $\\Delta$, the symmetric normalised graph Laplacian.}\n%\\end{algorithm}\n\n%%\n%\\begin{algorithm}[h]\n% \\caption{[Bebendorf,Kunis,2009]-inspired Nystr\\\"om method for approximate eigendecomposition (ED) of $A\\in\\mathbb{R}^{N\\times N}$, a symmetric matrix.}\n%\\begin{algorithmic}[1]\n%\\Function{Nystr\\\"omQR}{$ij\\mapsto A_{ij}, N, K$}\\Comment{Computes $U$ and $\\Lambda$, with $A \\approx U\\Lambda U^T$ a rank $K$ approximate ED  }\n%%\\SetAlgoLined\n%%\\DontPrintSemicolon\n%%\\KwIn{ $ij\\mapsto\\omega_{ij}$ , $Z, K$. }\n%%\\KwOut{$U,\\Lambda, V$.}\n%%\\KwResult{Computes $U,\\Lambda, V$, with $\\Delta\\approx U\\Lambda V^T$ a rank $K$ approximate SVD.  }\n%\\State $ X= \\texttt{random\\_subset}(N,K) $ \\Comment{A random subset of $\\{1,...,N\\}$ of size $K$, where $K\\ll N$}\n%\\State $A_{{XX}}=A({X},{X})$ \n%\\State $A_{N{X}}=A(:,{X})$ \\Comment{Nystr\\\"om extension is $A\\approx A_{NX}A_{XX}^{-1}A_{NX}^T$}\n%\\State $ [Q,R] = \\texttt{thin\\_qr}(A_{NX}) $\\Comment{Computes thin QR decomposition $A_{N{X}}=QR,Q\\in\\mathbb{R}^{N\\times K},R\\in\\mathbb{R}^{K\\times K}$}\n%\\State $ S = RA_{{XX}}^{-1}R^T$ \n%\\State $ S = (S + S^T)/2 $ \\Comment{Corrects symmetry-breaking computational errors}\n%\\State $ [\\Phi,\\Lambda] = \\texttt{eig}(S)$\\Comment{Computes eigendecomposition $S = \\Phi\\Lambda\\Phi^T$}\n%\\State $ U = Q\\Phi$ \\Comment{$U$ is orthonormal, since $Q$ is orthonormal and $\\Phi$ is orthogonal}\n%\\State \\textbf{return} $U,\\Lambda$\n%\\EndFunction \\Comment{Rate limiting are steps 5 and 9, which are $\\bigO(NK^2)$, followed by steps 6 and 8, which are $\\bigO(K^3)$} \n%\\end{algorithmic}\n%\\end{algorithm}\n\n\\section*{Acknowledgements}\n\n%\\ack\nWe thank Andrea Bertozzi, Arjuna Flenner, and Arieh Iserles for very helpful comments. This work dovetails with ongoing work of the authors joint with Carola-Bibiane Sch\u00f6nlieb and Simone Parisotto, whom we therefore also thank for many indirect contributions.\n\nThe work of the first and second authors was supported by the European Union's Horizon 2020 research and innovation program under Marie Sk\u0142odowska-Curie grant 777826. The work of the third author was supported by the EPSRC grant EP/S026045/1.\n\n\\begin{thebibliography}{99}\n\\vspace{-0.1cm}\n\n%\\bibitem{RS} [RS1992]\n\\bibitem{Budd} J. Budd and Y. van Gennip, \\emph{Graph Merriman--Bence--Osher as a SemiDiscrete Implicit Euler Scheme for Graph Allen--Cahn Flow}, {SIAM J. Math. Anal.} \\textbf{52} (2020), 4101\u20134139. Doi:10.1137/19M1277394.\n\n\n\\bibitem{MKB} E. Merkurjev, T. Kosti\u0107, and A. L. Bertozzi, \\emph{An MBO scheme on\ngraphs for segmentation and image processing}, {SIAM Journal on Imaging Sciences} \\textbf{6} (2013), 1903\\textendash 1930. Doi:10.1137/120886935.\n\n\\bibitem{Nys} E. J. Nystr\\\"om, \\emph{\\\"Uber die Praktische Aufl\\\"osung von Linearen\nIntegralgleichungen mit Anwendungen auf Randwertaufgaben\nder Potentialtheorie}, Commentationes Physico-Mathematicae \\textbf{4} (1928), 1--52.\n\\bibitem{FBCM} C. Fowlkes, S. Belongie, F. Chung, and J. Malik, \\emph{Spectral grouping using the Nystr\\\"om method},\n{IEEE Transactions on Pattern Analysis and Machine Intelligence} \\textbf{26} (2004), 1\u201312.\n\n\\bibitem{BF} A. L. Bertozzi and A. Flenner, \\emph{Diffuse interface models on graphs\nfor analysis of high dimensional data}, {Multiscale Modeling and Simulation}\n\\textbf{10} (2012), 1090\\textendash1118. Doi:10.1137/11083109X.\n\n\\bibitem{birdspot} L. Calatroni, Y. van Gennip, C.-B. Sch{\\\"o}nlieb,  H. M. Rowland, and A. Flenner, \\emph{Graph Clustering, Variational Image Segmentation Methods and Hough Transform Scale Detection for Object Measurement in Images}, {Journal of Mathematical Imaging and Vision} \\textbf{57} (2017), 269\\textendash 291. \n\\bibitem{BK} M. Bebendorf and S. Kunis, \\emph{Recompression techniques for adaptive cross approximation}, {J. Integral Equations Applications} \\textbf{21} (2009), 331--357. Doi:10.1216/JIE-2009-21-3-331.%\\texttt{https://projecteuclid.org/euclid.jiea/1248269700}\n\n\\bibitem{Strang} G. Strang, \\emph{On the construction and comparison of difference schemes}, {SIAM J. Numer. Anal.} \\textbf{5} (1968), 506\u2013517.\n%\\bibitem{OKMBO} Y. van Gennip, \\emph{An MBO Scheme for Minimizing the Graph Ohta\u2013Kawasaki Functional}, J Nonlinear Sci (2018). %https://doi.org/10.1007/s00332-018-9468-8\n%\\bibitem{Auction} M. Jacobs, E. Merkurjev, and S. Esedo\\=glu. \\emph{Auction dynamics: A volume\n%preserving MBO scheme}. Technical report, In preperation, 2017.\n%\n\\bibitem{MS} D. Mumford and J. Shah, \\emph{Optimal Approximation by\nPiecewise Smooth Functions and Associated Variational\nProblems}, {Communication in Pure and Applied Mathematics}\n\\textbf{42} (1989), 577\\textendash 685.\n\\bibitem{CV} T. Chan and L. Vese, \\emph{Active Contour Without Edges}, {IEEE Transactions on Image Processing} \\textbf{10} (2001), 266--277.\n\\bibitem{MM} L. Modica and S. Mortola, \\emph{Un esempio di $\\Gamma^{-}$-convergenza}, {Boll. Un. Mat. Ital. B} \\textbf{14} (1977),\n285\u2013299.\n\\bibitem{KS} R. V. Kohn and P. Sternberg, \\emph{Local minimisers and singular perturbations}, {Proc. Roy.\nSoc. Edinburgh Sect. A} \\textbf{111} (1989), 69--84.\n\\bibitem{vGB} Y. van Gennip and A. L. Bertozzi, \\emph{$\\Gamma$-convergence of graph Ginzburg\\textendash\nLandau functionals}, {Adv. Differential Equations} \\textbf{17} (2012), 1115\\textendash1180.\n\n\\bibitem{ET} S. Esedo\\=glu and Y. H. R. Tsai, \\emph{Threshold dynamics for the piecewise constant Mumford\\textendash Shah functional}, {Journal of Computational Physics} \\textbf{211} (2006), 367\\textendash384.\n\\bibitem{MBO92} J. Bence, B. Merriman, and S. Osher, \\emph{Diffusion generated motion by mean curvature},\nCAM Report, 92-18, Department of Mathematics, University of California,\nLos Angeles, 1992.\n\\bibitem{BE1991} J. F. Blowey and C. M. Elliott, \\emph{The Cahn-Hilliard gradient theory for phase separation with\nnon-smooth free energy, Part I: Mathematical Analysis}, {Eur. J. appl. Math} \\textbf{3} (1991), 233\\textendash279.\n\\bibitem{BE1992} J. F. Blowey and C. M. Elliott, \\emph{The Cahn-Hilliard gradient theory for phase separation with\nnon-smooth free energy, Part II: Numerical analysis}, {Eur. J. appl. Math} \\textbf{3} (1992), 147\\textendash179.\n\\bibitem{BE1993} J. F. Blowey and C. M. Elliott, \\emph{Curvature Dependent Phase Boundary Motion and Parabolic Double Obstacle Problems}, in \\emph{Degenerate Diffusions} (ed. W. M. Ni, L. A. Peletier, and J. L. Vazquez), The IMA Volumes in Mathematics and its Applications \\textbf{47}, Springer, New York, 1993, 19\\textendash60.\n\\bibitem{BKS2018} J. Bosch, S. Klamt, and M. Stoll, \\emph{Generalizing diffuse interface methods on graphs: non-smooth potentials and hypergraphs}, {SIAM J. appl. Math} \\textbf{78} (2018), 1350\\textendash1377.\n\\bibitem{volumeBudd} J. Budd and Y. van Gennip, {Mass-conserving diffusion-based dynamics on graphs}, arXiv e-prints, 2020: arXiv:2005.13072 [math.AP].\n\\bibitem{vGGOB}\nY. van Gennip, N. Guillen, B. Osting, and A. L. Bertozzi,\n\\emph{Mean Curvature, Threshold Dynamics, and Phase Field Theory on Finite Graphs}, {Milan Journal of Mathematics} \\textbf{82} (2014), 3\\textendash65.\n%\\bibitem{Hartman} %Hartman, P. (2002). \\emph{Ordinary differential equations: Second Edition}. Basel: Birkh\u00e4user.\n\\bibitem{Teschl} G. Teschl, \\emph{Ordinary differential equations and dynamical systems}, Graduate Studies in Mathematics \\textbf{140}, Providence, RI: American Mathematical Society, 2012.\n\n\\bibitem{VZ} M. Varma and A. Zisserman, \\emph{A statistical approach to texture classification\nfrom single images}, {Int. J. Comput. Vis.} \\textbf{62} (2005), 61\u201381.\n\\bibitem{Yarov} L. Yaroslavsky, \\emph{Digital Picture Processing: An Introduction}, Springer-Verlag, Berlin, 1985.\n\\bibitem{BCM} A. Buades, B. Coll, and J. M. Morel, \\emph{A review of image denoising algorithms, with a new one}, {Multiscale Modeling and Simulation} \\textbf{4} (2005), 490--530.\n\\bibitem{ZMP} L. Zelnik-Manor and P. Perona, \\emph{Self-tuning spectral clustering}, {Advances in Neural Information Processing Systems} \\textbf{17} (2004), 1601--1608.\n\\bibitem{GVL} G. H. Golub and C. F. Van Loan, \\emph{Matrix Computations}, Vol \\textbf{4}, Baltimore, Maryland: Johns Hopkins University Press, 2013.\n\\bibitem{BSV} K. Bergermann, M. Stoll, and T. Volkmer,  {Semi-supervised Learning for Multilayer Graphs Using Diffuse Interface Methods and Fast Matrix Vector Products}, arXiv e-prints, 2020: arXiv:2007.05239 [cs.LG].\n\\bibitem{HMT} N. Halko, P. G. Martinsson, and J. A. Tropp, \\emph{Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions}, {SIAM Rev.} \\textbf{53} (2011), 217--288.\n\\bibitem{EY} C. Eckart and G. Young, \\emph{The approximation of one matrix by another of lower rank}, {Psychometrika} \\textbf{1} (1936), 211\u2013218. \n\\bibitem{Hall} B.C. Hall, \\emph{Lie Groups, Lie Algebras, and Representations: An Elementary Introduction}, Vol \\textbf{2}, Graduate Texts in Mathematics \\textbf{222}, Springer, New York, 2015.\n\\bibitem{Yoshida} H. Yoshida, \\emph{Construction of higher order symplectic integrators}, {Phys. Lett. A} \\textbf{150} (1990), 262--268.\n\\bibitem{DP} J. R. Dormand and P. J. Prince, \\emph{A family of embedded Runge--Kutta formulae}, {J. Comp.\nAppl. Math.} \\textbf{6} (1980), 19\u201326.\n\\bibitem{Woodbury} M. A. Woodbury, \\emph{Inverting  modified  matrices}, Memorandum Report 42, Statistical Research Group, Princeton, NJ, 1950.\n\\bibitem{BayesianGraphs} Y. Qiao, C. Shi, C. Wang, H. Li, M. Haberland, X. Luo, A. M. Stuart, and A. L. Bertozzi, \\emph{Uncertainty quantification for semi-supervised multi-class classification in image processing and ego-motion analysis of body-worn videos}, {Electronic Imaging, Image Processing: Algorithms and Systems} \\textbf{XVII} (2019), 264-1-264-7.\n\\bibitem{GraphUQ} A. L. Bertozzi, X. Luo, A. M. Stuart, and K. Zygalakis,  \\emph{Uncertainty Quantification in Graph-Based Classification  of  High  Dimensional  Data}, {SIAM/ASA Journal on Uncertainty Quantification} \\textbf{6} (2018), 568\u2013595. Doi:10.1137/17M1134214.\n\\bibitem{SGDBayes} S. Mandt, M. D. Hoffman, and D. M. Blei, \\emph{Stochastic Gradient Descent as Approximate Bayesian Inference}, {Journal of Machine Learning Research} \\textbf{18} (2017), 1--35.\n%\\bibitem{Stuart2010} Stuart, A.M. (2010). Inverse Problems: A Bayesian perspective. \\emph{Acta Numer.} 19: 451--559.\n\\bibitem{RC} C. Anderson, \\emph{A Raleigh-Chebyshev procedure for finding the smallest eigenvalues and associated eigenvectors of large sparse Hermitian matrices}, {J. Comput. Phys.} \\textbf{229} (2010), 7477\u20137487.\n\\bibitem{Yuji} Y. Nakatsukasa, Fast and stable randomized low-rank matrix approximation, arXiv e-prints, 2020: arXiv:2009.11392 [math.NA].  \n\\bibitem{GCP} C. Garcia-Cardona, E. Merkurjev,  A. L. Bertozzi, A. Flenner, and A. G. Percus, \\emph{Multiclass data segmentation using diffuse interface methods on graphs}, {IEEE transactions on pattern analysis and machine intelligence} \\textbf{36} (2014), 1600\u20131613.\n\\bibitem{Auction} {M. Jacobs, E. Merkurjev, and S. Esedo\\=glu}, \\emph{Auction dynamics: A volume constrained MBO scheme}, {J. Comp. Phys.} \\textbf{354} (2018), 288--310.\n\\bibitem{jointrecon1} J. Adler, S. Lunz, O. Verdier, C.-B. Sch\\\"onlieb, and O. \\\"Oktem, \\emph{Task  adapted  reconstruction  for  inverse  problems}, arXiv  e-prints, 2018: arXiv:1809.00948 [cs.CV].\n\\bibitem{jointrecon2} V. Corona, M. Benning, M. J. Ehrhardt, L. F. Gladden, R. Mair, A. Reci, A. J. Sederman, S. Reichelt, and C.-B. Sch\\\"onlieb, \\emph{Enhancing  joint reconstruction  and  segmentation  with  non-convex  Bregman  iteration}, {Inverse Problems} \\textbf{35} (2019), 055001. Doi:10.1088/1361-6420/ab0b77.\n\\bibitem{RobbinsMonro} H. Robbins and S. Monro, \\emph{A Stochastic Approximation Method}, {Ann. Math. Statist.} \\textbf{22} (1951), 400--407. \n\\bibitem{Jonas} J. Latz, Analysis of Stochastic Gradient Descent in Continuous Time, arXiv e-prints, 2020: arXiv:2004.07177 [math.PR].\n\n%\\bibitem{Evans}L. C. Evans, \\emph{Convergence of an algorithm for mean curvature motion}, Indiana Univ. Math. J. 42 (1993), no. 2, 533\\textendash 557.\n%\\bibitem{BG} G. Barles and C. Georgelin, \\emph{A simple proof of convergence for an\n%approximation scheme for computing motions by mean curvature},\n%SIAM J. Numer. Anal. 32 (1995), no. 2, 484\\textendash500.\n%\\bibitem{SKY} D. Swartz and N. Kwan Yip, \\emph{Convergence of diffusion generated motion to motion\n%by mean curvature}, Communications in Partial Differential Equations 42 (2017), no. 10, 1598\\textendash 1643.\n%\\bibitem{LS} S. Luckhaus and T. Sturzenhecker, \\emph{Implicit time discretization for\n%the mean curvature flow equation}, Calc. Var. Partial Differential Equations 3 (1995), no. 2, 253\\textendash 271.\n%\\bibitem{AC}S. M. Allen and J. W. Cahn, \\emph{A microscopic theory for antiphase\n%boundary motion and its application to antiphase domain coarsening},\n%Acta Metallurgica 27 (1979), no. 6, 1085\\textendash 1095.\n%\\bibitem{BV}L. Bronsard and R. V. Kohn, \\emph{Motion by mean curvature as the singular limit of Ginzburg\\textendash Landau dynamics}, J. Differential Equations 90 (1991), no. 2, 211\\textendash 237.\n%\\bibitem{ESS} L. C. Evans, H. M. Soner, and P. E. Souganidis. \\emph{Phase transitions and generalized\n%motion by mean curvature}, Communications on Pure and Applied Mathematics 45 (1992), no. 9, 1097\\textendash 1123.\n%\\bi\n\n\\end{thebibliography}\n\n\n\n\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:02:23", "yymm": "2010", "arxiv_id": "2010.14556", "url": "https://arxiv.org/abs/2010.14556", "source": "arxiv"}}
{"text": "\\documentclass[11pt]{article}\r\n\\renewcommand{\\theequation}{\\arabic{section}.\\arabic{equation}}\r\n\\def\\be{\\begin{equation}}\r\n\\def\\ee{\\end{equation}}\r\n\\def\\ba{\\begin{eqnarray}}\r\n\\def\\ea{\\end{eqnarray}}\r\n\\def\\nn{\\nonumber}\r\n\\def\\lb{\\label}\r\n\\def\\bb{\\bibitem}\r\n\\def\\A{{\\cal A}}\r\n\\begin{document}\r\n\r\n\\begin{titlepage}\r\n\r\n\\date{27 0ctober 2020}\r\n\r\n\\title{\r\n\\begin{flushright}\\begin{small}    LAPTH-044/20\r\n\\end{small} \\end{flushright} \\vspace{1cm}\r\nThe gravimagnetic dipole}\r\n\r\n\\author{G\\'erard Cl\\'ement\\thanks{Email: gclement@lapth.cnrs.fr} \\\\ \\\\\r\n{\\small LAPTh, Universit\\'e Savoie Mont Blanc, CNRS,} \\\\ {\\small 9 chemin de Bellevue,\r\nBP 110, F-74941 Annecy-le-Vieux cedex, France}}\r\n\r\n\\maketitle\r\n\r\n\\begin{abstract}\r\nWe investigate a previously constructed stationary solution of the vacuum Einstein equations,\r\nwhich represents a system of two black holes with equal masses and opposite NUT charges,\r\nconnected by a Misner string with tension. For large separations, the inverse square law force\r\nmeasured by this tension is attractive or repulsive, according to the relative values of\r\nthe masses and NUT charges. For small separations, the force is always repulsive, so that the\r\nsystem cannot collapse to a single black hole. For given values of the black hole masses\r\nand NUT charges, there is a unique configuration corresponding to a balanced system. Whether\r\nbalanced or unbalanced, all double black hole and string configurations satisfy a generalized\r\nfirst law of black hole mechanics.\r\n\\end{abstract}\r\n\\end{titlepage}\r\n\\setcounter{page}{2}\r\n\r\n\\section{Introduction}\r\n\r\nA recurring question in general relativity is that of the existence of regular, stationary, asymptotically flat double black hole systems, as solutions either to the vacuum Einstein equations or to the Einstein-Maxwell equations. With the exception of linear Majumdar-Papapetrou \\cite{MP} superpositions of extreme Reissner-Nordstr\\\"om black holes, these generically can be balanced only if there is a line of conical singularities (cosmic string) connecting the two black holes. Recently we have investigated some systems of two extreme black holes carrying opposite gravimagnetic or NUT charges, and shown that the parameters can be fine tuned so that the Misner string between the two black holes is tensionless \\cite{dimagn,baldimagn}. Misner strings are usually considered to be unphysical, but we have shown that they are transparent to geodesic motion, and argued that they do not lead to observable violations of causality \\cite{GC15}.\r\n\r\nNon-extreme double black hole solutions of the Einstein-Maxwell equations have been discussed in \\cite{Emparan:2001bb}. The superposition of two Kerr-NUT solutions was analyzed in \\cite{Tomimatsu:1981bc}, where it was shown that balance could be achieved in the absence of both cosmic string and Misner string. It was not clear however whether the two constituent sources were regular black holes, or whether the solution was free from a ring singularity. A similar problem was later discussed in \\cite{letelier98a}.\r\n\r\nAfter the double Schwarzschild solution, where balance is clearly impossible, the simplest asymptotically flat stationary double black hole solution is the double Schwarzschild-NUT vacuum solution. Such a solution was constructed in \\cite{manko2009} as a non-linear superposition of two sources with equal masses and opposite NUT charges. The main purpose of the authors of \\cite{manko2009} was to show that their solution reduced to the Kerr black hole when the distance between the two sources was appropriately chosen. In this paper, we analyze in more detail this solution, show that it is free from a ring singularity in a large parameter domain, and determine the two-dimensional surface in the three-dimensional parameter domain such that the system is weakly balanced, in the sense that the Misner string connecting the two constituent black holes is tensionless.\r\n\r\nThe solution is recalled in the next section. The geometrical structure which it describes is identified in section 3, where the condition for the absence of a Kerr-like ring singularity is given, and the horizon characteristics are determined. The properties of the string connecting the two black holes are discussed in section 4. The horizon and string Komar masses and angular momenta are evaluated in section 5, and our conclusions are given in the final section.\r\n\r\n\\setcounter{equation}{0}\r\n\\section{The solution}\r\n\r\nThe non-linear superposition of two NUT solutions (of the vacuum Einstein equations)with equal masses $m$\r\nand opposite NUT charges $\\nu$, separated by a distance $2k$ ($k > \\ge m >0$), leads to the Ernst potential,\r\nconstructed by Sibgatullin's method \\cite{sibga84} in \\cite{manko2009} :\r\n \\be\r\n{\\cal E} = \\frac{A-B}{A+B},\r\n \\ee\r\nwith\r\n \\ba\r\nA &=& \\left[(m^2+\\nu^2)(k^2-m^2)(k^2-m^2-\\nu^2) - 2m^2k^2\\nu^2\\right](R_+-R_-)(r_+-r_-) \\nn\\\\\r\n&& - \\alpha_+\\alpha_-\\left[2(m^2+\\nu^2)(k^2-m^2)(R_+R_- + r_+r_-)\\right. \\nn\\\\\r\n&& \\left. + (2m^4 + (m^2+\\nu^2)(k^2-m^2))(R_++R_-)(r_++r_-)\\right] \\nn\\\\\r\n&& - 2imk\\nu d\\left[(\\alpha_+-\\alpha_-)(R_+r_+ - R_-r_-) - (\\alpha_++\\alpha_-)(R_+r_- - R_-r_+)\\right], \\\\\r\nB &=& 4d\\left\\{m\\alpha_+\\alpha_-\\left[(m^2-d)(R_++R_-) - (m^2+d)(r_++r_-)\\right]\\right. \\nn\\\\\r\n&& \\left. + ik\\nu\\left[\\alpha_-(m^2-d)(R_+-R_-) - \\alpha_+(m^2+d)(r_+-r_-)\\right]\\right\\},\r\n \\ea\r\nwhere\r\n \\be\r\nR_\\pm = \\sqrt{\\rho^2+(z\\pm\\alpha_+)^2}, \\quad r_\\pm = \\sqrt{\\rho^2+(z\\pm\\alpha_-)^2},\r\n \\ee\r\n$\\rho$ and $z$ being the Weyl coordinates, and\r\n \\be\\lb{dalpha}\r\n\\alpha_\\pm = \\sqrt{m^2+k^2-\\nu^2 \\pm 2d}, \\quad d = \\sqrt{m^2k^2 + \\nu^2(k^2-m^2)}.\r\n \\ee\r\n\r\nThe corresponding metric is\r\n \\be\r\nds^2 = - f(dt-\\omega d\\varphi)^2 + f^{-1}\\left[e^{2\\gamma}(d\\rho^2+dz^2) + \\rho^2d\\varphi^2\\right],\r\n \\ee\r\nwith\r\n \\be\\label{metfunct}\r\nf = \\frac{A\\bar{A} - B\\bar{B}}{(A+B)(\\bar{A}+\\bar{B})}, \\quad\r\ne^{2\\gamma} = \\frac{A\\bar{A} - B\\bar{B}}{64d^4\\alpha_+^2\\alpha_-^2R_+R_-r_+r_-}, \\quad\r\n\\omega = - \\frac{4{\\rm Im}[G(\\bar{A}+\\bar{B})]}{A\\bar{A} - B\\bar{B}},\r\n \\ee\r\n \\ba\r\nG &=& - d[d^2+m^2(m^2+2ik\\nu)]\\left[(\\alpha_+-\\alpha_-)(R_+r_+ - R_-r_-) - (\\alpha_++\\alpha_-)(R_+r_- - R_-r_+)\\right] \\nn\\\\\r\n&& + 2m^2d^2\\left[(\\alpha_++\\alpha_-)(R_+r_+ - R_-r_-) - (\\alpha_+-\\alpha_-)(R_+r_- - R_-r_+)\\right] \\nn\\\\\r\n&& - m\\alpha_+\\alpha_-(d^2+m^4)(R_++R_-)(r_++r_-) + m\\left[kd^2(k+4i\\nu) - (2k^2-m^2)(m^2+\\nu^2)^2\\right. \\nn\\\\\r\n&& \\left. + k^2\\nu^4\\right](R_+-R_-)(r_+-r_-) - 2m\\alpha_+\\alpha_-(m^2+\\nu^2)(k^2-m^2)(R_+R_- + r_+r_-) \\nn\\\\\r\n&& - 2dz\\left\\{\\alpha_-(m^2-d)\\left[m\\alpha_+(R_++R_-) + ik\\nu(R_+-R_-)\\right] \\right. \\nn\\\\\r\n&& \\left. - \\alpha_+(m^2+d)\\left[m\\alpha_-(r_++r_-) + ik\\nu(r_+-r_-)\\right]\\right\\} \\nn\\\\\r\n&& + 2d\\alpha_+\\alpha_-(2m^2+ik\\nu)\\left[m^2(R_++R_--r_+-r_-) - d(R_++R_-+r_++r_-)\\right] \\nn\\\\\r\n&& - 2md\\left[d^2-m^4-ik\\nu(2m^2+ik\\nu)\\right]\\left[\\alpha_-(R_+-R_-) - \\alpha_+(r_+-r_-)\\right] \\nn\\\\\r\n&& + 2md^2(m^2-k^2+\\nu^2-2ik\\nu)\\left[\\alpha_-(R_+-R_-) + \\alpha_+(r_+-r_-)\\right].\r\n \\ea\r\nThis metric is asymptotically flat, with total mass $M = 2m$ and total angular momentum $J = 2k\\nu$.\r\n\r\nThe Ernst potential and the metric can be reexpressed in terms of the three parameters $\\alpha_+$,\r\n$\\alpha_-$, and $m$. The definitions (\\ref{dalpha}) can be inverted to give\r\n \\be\r\nk^2-\\nu^2 = \\alpha_\\pm^2\\mp 2d - m^2, \\quad k^2\\nu^2 = (d\\pm m^2)^2 - m^2\\alpha_\\pm^2\r\n \\ee\r\nOther useful identities are\r\n \\ba\\label{ids}\r\n&& 4d = \\alpha_+^2 - \\alpha_-^2 = 4m^2\\sigma\\delta, \\quad (d \\pm m^2 \\pm m\\alpha_\\pm) = m^2(\\sigma+1)(\\delta\\pm 1), \\nn\\\\\r\n&& [(d-m^2)\\alpha_+ + (d+m^2)\\alpha_-] = 2m^3\\delta(\\sigma^2-1), \\nn\\\\\r\n&& [(d+m^2)\\alpha_+ + (d-m^2)\\alpha_- + 4md] = 2m^3\\delta(\\sigma+1)^2, \\nn\\\\\r\n&& k^2\\nu^2 = m^4(\\sigma^2-1)(\\delta^2-1),\r\n \\ea\r\nwhere\r\n \\be\r\n\\sigma \\equiv \\frac{\\alpha_++\\alpha_-}{2m}, \\quad \\delta \\equiv \\frac{\\alpha_+-\\alpha_-}{2m}.\r\n \\ee\r\n\r\nUsing these, the three functions $A$, $B$ and $G$ can be reexpressed in terms of $\\alpha_+$, $\\alpha_-$, and $m$ as:\r\n \\ba\r\nA &=& \\frac12\\left[(d-m^2)^2\\alpha_+^2 + (d+m^2)^2\\alpha_-^2\\right](R_+-R_-)(r_+-r_-) \\nn\\\\\r\n&& - \\alpha_+\\alpha_-\\left[2(d^2-m^4)(R_+R_- + r_+r_-) + (d^2+m^4)(R_++R_-)(r_++r_-)\\right] \\nn\\\\\r\n&& - 2imk\\nu d\\left[(\\alpha_+-\\alpha_-)(R_+r_+ - R_-r_-) - (\\alpha_++\\alpha_-)(R_+r_- - R_-r_+)\\right], \\nn\\\\\r\nB &=& - 4d\\left\\{(d-m^2)\\alpha_-\\left[m\\alpha_+(R_++R_-) + ik\\nu(R_+-R_-)\\right]\\right. \\nn\\\\\r\n&& \\left. + (d+m^2)\\alpha_+\\left[m\\alpha_-(r_++r_-) + ik\\nu(r_+-r-)\\right]\\right\\} \\nn\\\\\r\nG &=& d[- (d-m^2)^2\\alpha_+ + (d+m^2)^2\\alpha_- - 2ik\\nu m^2(\\alpha_+-\\alpha_-)](R_+r_+ - R_-r_-) \\nn\\\\\r\n&& + d[(d-m^2)^2\\alpha_+ + (d+m^2)^2\\alpha_- + 2ik\\nu m^2(\\alpha_++\\alpha_-)](R_+r_- - R_-r_+) \\nn\\\\\r\n&& - m(d^2+m^4)\\alpha_+\\alpha_-(R_++R_-)(r_++r_-) \\nn\\\\\r\n&& + \\frac{m}2\\left[(d-m^2)^2\\alpha_+^2 + (d+m^2)^2\\alpha_-^2 + 8ik\\nu d^2\\right](R_+-R_-)(r_+-r_-) \\nn\\\\\r\n&& - 2m(d^2-m^4)\\alpha_+\\alpha_-(R_+R_- + r_+r_-) \\\\\r\n&& - 2d(d-m^2)\\alpha_-\\left[(\\alpha_+ +2m-z)(m\\alpha_+ + ik\\nu)R_+ - (\\alpha_+ -2m+z)(m\\alpha_+ - ik\\nu)R_-\\right] \\nn\\\\\r\n&& - 2d(d+m^2)\\alpha_+\\left[(\\alpha_- +2m-z)(m\\alpha_- + ik\\nu)r_+ - (\\alpha_- -2m+z)(m\\alpha_- - ik\\nu)r_-\\right] .\\nn\r\n \\ea\r\n\r\n\\setcounter{equation}{0}\r\n\\section{Structure}\r\n\r\nFor $\\nu=0$, $d=km$ and $\\alpha_\\pm = k\\pm m$ are real, and the metric describes a system of two black holes\r\nconnected by a cosmic string of length $2(k-m)$. The two black holes coalesce when $k=m$ to form a single\r\nSchwarzschild black hole.\r\nThe situation is less simple when $\\nu\\neq0$, and depends on the domain of values of $k$. For $k$ large enough, $d$ and $\\alpha_\\pm$\r\nare again real and the system consists of two black holes connected by a spinning cosmic string (Misner string). On the $z$ axis,\r\nthese correspond to three rods, two symmetrical rods $\\alpha_-<z<\\alpha_+$ and $-\\alpha_+<z<-\\alpha_-$\r\ncorresponding to the two black hole horizons, and the central rod $-\\alpha_-<z<\\alpha_-$ corresponding\r\nto the Misner string. We have checked that on the axis outside the rods\r\n($|z|>\\alpha_+$), $G$, which is a polynomial of second order in $z$, vanishes identically, so that the axis condition $\\omega(0,z)=0$ is satisfied. Therefore the solution is asymptotically flat.\r\n\r\nIt was shown in \\cite{manko2009} that for $k=m$ the solution describes the Kerr black hole\r\n(a single rod) provided $|\\nu|<2m$ (and presumably the extreme black hole\r\nif $|\\nu|=2m$). In this case, $\\alpha_+$ is real and $\\alpha_-$ imaginary. Clearly, there will be an\r\nintermediate domain of values\r\n$k>m$ with $\\alpha_+$ real and $\\alpha_-$ imaginary, and it is not clear what will the solution describe\r\nin this case. We have found that, assuming $k>m$, $\\alpha_\\pm$ are real and non-zero provided\r\n \\be\\lb{k0}\r\nk > k_0(m,\\nu) = \\sqrt{m^2+2\\nu^2} + |\\nu|.\r\n \\ee\r\nWe will show in section 4 that the solution for $k = k_0(m,\\nu)$ ($\\alpha_-=0$) is actually singular for $\\nu\\neq0$.\r\nIt follows that when the separation $2k$ between the two NUTty black holes with fixed $m$ and $\\nu$ is decreased, a\r\nsingular configuration with $k = k_0(m,\\nu)$ is reached {\\em before} the Kerr configuration $k = m$.\r\nThe reality of the parameters $\\alpha_\\pm$ will be assumed in the following.\r\n\r\n\\subsection{Absence of ring singularity}\r\nUnder this condition, one can prove the absence of an equatorial ring singularity. The equatorial plane is $z=0$, so that $R_+=R_-=R$,\r\nand $r_+=r_-=r$, leading to\r\n \\ba\r\nA &=& - 2\\alpha_+\\alpha_-[(d^2-m^4)(R+r)^2 + 4m^4], \\nn\\\\\r\nB &=& -8dm\\alpha_+\\alpha_-[(d-m^2)R + (d+m^2)r].\r\n \\ea\r\nIt follows from\r\n \\be\r\nd^2-m^4=(m^2+\\nu^2)(k^2-m^2)\r\n \\ee\r\nthat $k>m$ implies $d>m^2$, so that $A<0$ and $B\\le0$, and therefore $A+B$ cannot vanish, proving that the\r\nequatorial ring singularity is absent. Conversely, for $\\rho\\to\\infty$,\r\n \\be\r\nA + B \\simeq -8\\alpha_+\\alpha_-d^2\\rho^2,\r\n \\ee\r\nwhile, for $\\rho=0$,\r\n \\be\r\nA + B = - 8m^6\\alpha_+\\alpha_-\\delta^2(\\sigma+1)^2(\\sigma^2-1)\r\n \\ee\r\nso that a necessary condition for the absence of a zero of $A+B$ is $\\sigma>1$, implying $\\delta>1$ in view of the last\r\nequation (\\ref{ids}), and so $d = m^2\\sigma\\delta > m^2$, equivalent to $k>m$.\r\n\r\n\r\n\\subsection{Horizons}\r\n\r\nOn the upper horizon ($\\rho=0$, $\\alpha_-<z<\\alpha_-+$),\r\n \\be\r\nR_\\pm = \\alpha_+ \\pm z, \\quad r_\\pm = z \\pm \\alpha_- ,\r\n \\ee\r\nleading to\r\n \\ba\r\nA_H &=& -8d\\alpha_-\\left\\{(d+m^2)[(d-m^2)\\alpha_+ + (d+m^2)z] + ik\\nu m(\\alpha_+^2-z^2)\\right\\}, \\\\\r\nB_H &=& -8d\\alpha_-\\left\\{m\\alpha_+[(d-m^2)\\alpha_+ + (d+m^2)z] + ik\\nu[(d+m^2)\\alpha_+ + (d-m^2)z] \\right\\}. \\nn\r\n \\ea\r\n\r\nWe know that $e^{2\\gamma}$ and $\\omega$ are constant over each rod (this should be checked).\r\nSo their values for a given rod can be obtained by evaluating the corresponding expressions (\\ref{metfunct})\r\nat the axis point $z=0$ (whether or not it belongs to the rod). For the horizon rod, noting $A_H(0,0) = A_0$, etc.,\r\nwe obtain:\r\n \\ba\r\nA_0 &=& -8d\\alpha_+\\alpha_-\\left[d^2-m^4 + ik\\nu m\\alpha_+\\right], \\nn\\\\\r\nB_0 &=& -8d\\alpha_+\\alpha_-\\left[m\\alpha_+(d-m^2) + ik\\nu (d+m^2)\\right],\\\\\r\nG_0 &=& -4d(d+m^2)\\alpha_+\\alpha_-\\left[(\\alpha_+-2m)(d+m\\alpha_++m^2) + ik\\nu(\\alpha_++2m)\\right], \\nn\r\n \\ea\r\nleading to the horizon characteristics\r\n \\be\r\ne^{2\\gamma_H} = - \\left(\\frac{k\\nu m}{d\\alpha_+}\\right)^2, \\quad \\Omega_H = \\omega_H^{-1} = \\frac{k\\nu m}{2(d+m^2)(d+m\\alpha_++m^2)}.\r\n \\ee\r\nThe surface gravity $\\kappa_H = \\sqrt{|e^{-2\\gamma_H}|}\\,|\\Omega_H|$ is\r\n \\be\r\n\\kappa_H = \\frac{d\\alpha_+}{2(d+m^2)(d+m\\alpha_++m^2)} = \\frac{\\sigma\\delta(\\sigma+\\delta)}\r\n{2m(1+\\sigma\\delta)(\\sigma+1)(\\delta+1)},\r\n \\ee\r\nfrom which one can derive the horizon area ${\\cal A}_H = 2\\pi L_H/\\kappa_H$ (where\r\n$L_H = \\alpha_+-\\alpha_- = 2m\\delta$ is the length of the horizon rod).\r\n\r\n\\setcounter{equation}{0}\r\n\\section{The string}\r\n\r\nThe two co-rotating black holes are connected by a finite length spinning cosmic string located on the segment ($\\rho=0$, $-\\alpha_-<z<\\alpha_-$),\r\nOn this string,\r\n \\be\r\nR_\\pm = \\alpha_+ \\pm z, \\quad r_\\pm = \\alpha_- \\pm z,\r\n \\ee\r\nleading to\r\n \\ba\r\nA_S &=& - 2\\alpha_+\\alpha_-[d^2(\\alpha_++\\alpha_-)^2 - m^4(\\alpha_+-\\alpha_-)^2], \\nn\\\\\r\n&& + 2[d(\\alpha_++\\alpha_-) - m^2(\\alpha_+-\\alpha_-)]^2z^2 - 32ik\\nu md^2z \\nn\\\\\r\nB_S &=& - 8dm\\alpha_+\\alpha_-[d(\\alpha_++\\alpha_-) - m^2(\\alpha_+-\\alpha_-)] \\nn\\\\\r\n&& - 8ik\\nu d[d(\\alpha_++\\alpha_-) + m^2(\\alpha_+-\\alpha_-)]z .\r\n \\ea\r\nEvaluating these at the string center $z=0$ (where they are real), together with ${\\rm Im}\\,G$,\r\n \\be\r\n{\\rm Im}\\,G_0 = -4k\\nu d\\alpha_+\\alpha_-[d(\\alpha_++\\alpha_-) - m^2(\\alpha_+-\\alpha_-)], \\nn\r\n \\ee\r\nwe obtain the string characteristics\r\n \\ba\r\ne^{2\\gamma_S} &=& \\left(\\frac{[d(\\alpha_++\\alpha_-) - m^2(\\alpha_+-\\alpha_-)]^2}{4d^2\\alpha_+\\alpha_-}\\right)^2\r\n\\;=\\; \\left(\\frac{(\\sigma^2 - 1)^2}{\\sigma^2(\\sigma^2-\\delta^2)}\\right)^2, \\\\\r\n\\omega_S &=& -8k\\nu d\\frac{d(\\alpha_++\\alpha_-+4m) + m^2(\\alpha_+-\\alpha_-)}{[d(\\alpha_++\\alpha_-) - m^2(\\alpha_+-\\alpha_-)]^2}\r\n\\;=\\; -\\frac{4k\\nu\\sigma}{m(\\sigma-1)^2}. \\nn\r\n \\ea\r\nFrom these we can derive the string area and surface gravity,\r\n \\be\r\n\\A_S = 4\\pi\\alpha_-|\\omega_S|e^{\\gamma_S} = \\frac{16\\pi k\\nu(\\sigma+1)^2}{\\sigma(\\sigma+\\delta)}, \\quad\r\n\\kappa_S = \\frac{4\\pi m(\\sigma-\\delta)}{\\A_S}.\r\n \\ee\r\n\r\nThese characteristics are simply related to the string tension per unit length, which is\r\n$(1-e^{-\\gamma_S})/4$, and the string spin, $-\\omega_S/4$.\r\nAs discussed in \\cite{taleful}, this spin measures the gravimagnetic flow along the Misner string connecting the two horizons carrying\r\nthe effective NUT charges $\\mp\\omega_S/4$ (generically different from the ``bare'' NUT charges $\\pm\\nu$). And the string tension\r\nmeasures the force \\cite{letelier98b} which is necessary to balance the gravitational forces between the two sources (black holes), attractive\r\nbetween the two equal masses and repulsive between the opposite NUT charges, a negative string tension ($e^{\\gamma_S}<1$) corresponding\r\nto a net attractive force, and a positive string tension ($e^{\\gamma_S}>1$) corresponding to a net repulsive force.\r\n\r\nFor a large separation between the two black holes ($k \\gg (m,\\,\\nu)$, $\\sigma\\gg1$), we find $\\sigma \\simeq k/m$, $\\delta \\simeq \\mu/m$\r\n($\\mu^2 = m^2 + \\nu^2$). The string length $2\\alpha_-$ is of the order of $2k$, while the string tension and spin go to\r\n \\be\r\n\\frac{1-e^{-\\gamma_S}}4 \\simeq - \\frac{m^2-\\nu^2}{(2k)^2}, \\qquad - \\frac{\\omega_S}4 \\simeq \\nu .\r\n \\ee\r\nIn this quasi-linear newtonian regime, the effective and bare NUT charges coincide, while the net force is simply the superposition of the inverse\r\nsquare law gravitational and gravimagnetic forces\r\n\r\nOn the other hand, when for fixed $m$ and $\\nu$ the parameter $k$ is progressively decreased to its lowest possible limit $k_0(m,\\nu)$,\r\ncorresponding to $\\alpha_-\\to0$ ($\\delta \\to \\sigma$), $e^{\\gamma_S}$ diverges while the string length goes to zero,\r\nsignalling a singularity at $\\rho=z=0$, unless $\\sigma$ simultaneously goes to $1$, i.e. $k$ goes to $m$, which\r\nfrom (\\ref{k0}) is possible only for $\\nu=0$. Otherwise, whatever the relative values of the mass and NUT parameters $m$ and $\\nu$, the\r\nregime becomes highly non-linear when the limit $k\\to k_0$ is approached, leading to an increasing repulsion which will prevent the two\r\nblack holes from coalescing, no matter what external force is exerted.\r\n\r\nIn the absence of an external force, the stationary double black hole system is balanced provided\r\nthe string parameters are constrained by $e^{\\gamma_S} = 1$, which is achieved by\r\n \\be\\lb{bal}\r\n\\delta^2 = 2 - \\frac1{\\sigma^2}.\r\n \\ee\r\nThe regular balanced configurations depend therefore only on two parameters, which can be chosen for instance as the total mass $M=2m$\r\nand the dimensionless parameter $\\sigma\\ge1$.\r\nRecalling that the total angular momentum is $J \\equiv Ma = 2k\\nu$, for these balanced configurations the ratio\r\n \\be\\lb{aoverM}\r\n\\frac{|a|}M = \\frac{k|\\nu|}{2m^2} = \\frac12\\left(\\sigma - \\sigma^{-1}\\right)\r\n \\ee\r\ncan take any real non-negative value. Using this relation and the relation\r\n \\be\r\nk^2 - \\nu^2 = m^2(\\sigma^2 + 1 - \\sigma^{-2}),\r\n \\ee\r\none derives the relation between the ratio $\\nu/m$ and the parameter $\\sigma$,\r\n \\be\r\n\\nu^4 + (\\sigma^2 + 1 - \\sigma^{-2})m^2\\nu^2 - (\\sigma - \\sigma^{-1})^2m^4 = 0.\r\n \\ee\r\nFor $\\sigma\\ge1$, $\\nu/m$ is bounded above by $1$. More precisely, when $\\sigma$ varies from $1$ to infinity,\r\n$\\nu/m$ varies from $0$ to $1$.\r\n\r\nFor fixed mass $M=2m$ and large $\\sigma$, one finds\r\n \\be\r\n\\nu \\simeq m\\sigma(1-2\\sigma^{-2}), \\qquad k \\simeq m\\sigma(1+\\sigma^{-2}).\r\n \\ee\r\nThe string rod length increases as\r\n$L_S \\simeq M\\sigma$, while the horizon rod lengths go to the finite value $L_H \\simeq M\\sqrt2$.\r\nThe horizon area and surface gravity go to finite limits, and the horizon angular velocity goes to zero,\r\n \\be\r\n\\A_H \\simeq 4\\pi\\,\\frac{1+\\sqrt2}{\\sqrt2}\\,M^2, \\quad \\kappa_H \\simeq \\frac1{1+\\sqrt2}\\,M^{-1},\r\n\\quad \\Omega_H \\simeq \\frac1{\\sqrt2(1+\\sqrt2)}\\,(M\\sigma)^{-1},\r\n \\ee\r\nin spite of the fact that the total angular momentum diverges as (\\ref{aoverM}). Of course, this\r\nlarge angular momentum is due to the gravimagnetic dipole moment $L_S \\simeq 2k\\nu$.\r\n\r\nIn the opposite limit $\\sigma\\to 1$, one can take $\\nu/m \\simeq 2a/M$ as independent dimensionless parameter, in terms of which\r\n \\be\r\n\\sigma \\simeq 1 + \\frac\\nu{2m} + \\frac{5\\nu^2}{8m^2}, \\qquad k \\simeq m + \\nu.\r\n \\ee\r\nThe horizon rod lengths are now $L_H \\simeq M$, while the string rod contracts to a length $L_S \\simeq 2a^2/M$. The values\r\nof the {\\em total} horizon area, surface gravity, and horizon angular velocity\r\n \\be\r\n2\\A_H \\simeq 16\\pi M^2, \\quad \\kappa_H \\simeq \\frac1{4M}, \\quad \\Omega_H \\simeq \\frac{a}{4M^2}\r\n \\ee\r\ncoincide in lowest order with those of a slowly rotating Kerr black hole with the same parameters\r\n$M$ and $a$.\r\n\r\n\\setcounter{equation}{0}\r\n\\section{Komar masses and angular momenta}\r\n\r\nNow we compute the horizon and string Komar masses and angular momenta. The Tomimatsu formulas \\cite{Tomimatsu:1983qc} for these are\r\n \\be\\lb{MnJn}\r\nM_n = \\frac{\\omega_n}4\\,[\\chi(z_{n+}) - \\chi(z_{n-})], \\quad J_n = \\frac{\\omega_n}2\\left(M_n - \\frac{z_{n+} - z_{n-}}2\\right),\r\n \\ee\r\nwhere $\\chi = - {\\rm Im}\\cal E$\\footnote{The Ernst potential used in \\cite{manko2009} and in the present paper\r\nis the complex conjugate of that used in our previous papers.}, and $z_{n\\pm}$ are the upper and lower ends of\r\nthe rod, $\\pm\\alpha_\\pm$ and $\\pm\\alpha_\\mp$ for the upper and lower horizon rods, and $\\alpha_-$ and $-\\alpha_-$\r\nfor the string rod. At these ends,\r\n \\ba\r\nA(\\pm\\alpha_+) &=& -16d^2(d+m^2)\\alpha_+\\alpha_-, \\nn\\\\\r\nB(\\pm\\alpha_+) &=& -16d^2\\alpha_+\\alpha_-(m\\alpha_+ \\pm ik\\nu), \\nn\\\\\r\nA(\\pm\\alpha_-) &=& -8d\\alpha_-\\left\\{(d+m^2)[(d-m^2)\\alpha_+ + (d+m^2)\\alpha_-] \\pm ik\\nu4md\\right\\}, \\nn\\\\\r\nB(\\pm\\alpha_-) &=& -8d\\alpha_- \\left\\{m\\alpha_+[(d-m^2)\\alpha_+ + (d+m^2)\\alpha_-] \\right.\\nn\\\\\r\n&& \\left. \\pm ik\\nu[(d+m^2)\\alpha_+ + (d-m^2)\\alpha_-]\\right\\}.\r\n \\ea\r\nUsing these and the identities (\\ref{ids}), we obtain,\r\n \\ba\r\n\\chi(\\pm\\alpha_+) &=& \\pm \\frac{k\\nu}{m^2(\\sigma+1)(\\delta+1)}, \\nn\\\\\r\n\\chi(\\pm\\alpha_-) &=& \\pm \\frac{k\\nu(\\sigma-1)}{m^2(\\sigma+1)^2(\\delta+1)},\r\n \\ea\r\nTogether with the rod angular velocities evaluated in the previous section, these lead to the horizon\r\nand string Komar masses and angular momenta\r\n \\ba\r\nM_{H_\\pm} &=& m\\,\\frac{\\sigma\\delta+1}{\\sigma+1}, \\quad J_{H_\\pm} = - k\\nu\\,\\frac{\\sigma\\delta+1}{\\sigma^2-1}, \\nn\\\\\r\nM_S &=& - 2m\\,\\frac{\\sigma(\\delta-1)}{\\sigma+1}, \\quad J_S = 2k\\nu\\,\\frac{\\sigma(\\sigma+\\delta)}{\\sigma^2-1}.\r\n \\ea\r\nIt is easy to check that these add up to the total mass and angular momentum,\r\n \\be\r\n2M_H + M_S = 2m, \\quad 2J_H + J_S = 2k\\nu.\r\n \\ee\r\n\r\nFor a large separation between the two black holes ($k \\gg (m,\\,\\nu)$, $\\sigma\\gg1$),\r\nthe Komar angular momentum is mainly carried by the string,\r\nwhile the Komar masses of the two horizons and of the string are of the same order but opposite signs,\r\n$M_{H_\\pm} \\simeq M\\delta/2$ and $M_S \\simeq -M(\\delta-1)$ (with $\\delta \\simeq \\sqrt2$ for a balanced configuration).\r\nConversely, when the configuration is balanced and $\\nu\\to0$, the Komar mass is mainly carried by the black holes,\r\nthe respective horizon and string Komar angular momenta being of the order of $M^2$ but nearly compensating each other.\r\n\r\nBy construction, each rod satisfies its own Smarr relation (this is a simple consequence of the Tomimatsu formulas\r\n(\\ref{MnJn})), so that the global Smarr relation \\cite{smarrnut}\r\n \\be\r\nM = 2\\left(2\\Omega_{H}J_{H} + \\frac{\\kappa_{H}}{4\\pi} \\A_{H}\\right)  +\r\n2\\Omega_{S}J_{S} + \\frac{\\kappa_{S}}{4\\pi} \\A_{S}\r\n \\ee\r\nis trivially satisfied. Careful accounting shows that the global first law of mechanics for this system of\r\ntwo black holes connected by a Misner string \\cite{talefirst}\r\n \\be\r\ndM = 2\\left(\\Omega_{H}\\,dJ_{H} + \\frac{\\kappa_{H}}{8\\pi}\\,d\\A_{H}\\right)  +\r\n\\Omega_{S}\\,dJ_{S} + \\frac{\\kappa_{S}}{8\\pi}\\,d\\A_{S}\r\n \\ee\r\nholds for independent variations of the two dimensionless parameters $\\sigma$ and $\\delta$ (it is trivially\r\nsatisfied for variations of the scale $m$), whether the system is balanced or unbalanced. It should be stressed\r\nthat, contrary to the Smarr relations, the first law is not satisfied independently by the various interacting\r\ncomponents -- horizons and string -- but only by the composite system.\r\n\r\n\\setcounter{equation}{0}\r\n\\section{Discussion}\r\n\r\nWe have discussed the properties of an exact asymptotically flat stationary solution to vacuum gravity, describing a system of two black holes with equal masses and opposite NUT charges, connected by a Misner string with tension. The solution is free from a ring singularity.  For large separations, the force measured by the string tension is attractive or repulsive, depending on the relative values of the masses and NUT charges. For small separations, the force is always repulsive, so that the\r\nsystem cannot collapse to a single black hole. For given values of the black hole masses and NUT charges, the distance between the two black holes (the string length) can always be adjusted so that the string tension vanishes and the system is balanced. The existence of a Misner string, on which the (usually enforced) axis condition $\\omega(0,z) = 0$ is relaxed, is necessary for this balance to be possible.\r\n\r\nThis condition being relaxed, the usual black hole uniqueness theorems no longer apply. The observable charges of the dihole solution (total mass and angular momentum) take the same values as those of the Kerr solution, while the overall topology and geometry are different. For small black hole separations (short dipoles), the angular-momentum-to-mass ratio is small, and the global horizon characteristics (horizon\r\nangular velocity, temperature and entropy) are roughly the same as those of a slowly rotating Kerr black hole with the same parameters $M$ and $a=J/M$. On the other hand, for large black hole separations (long dipoles), the ratio $|a|/M$ becomes arbitrarily large, corresponding to regular overspinning configurations.\r\n\r\nFinally, we have evaluated the horizon and string Komar masses and angular momenta and other mechanical observables, and checked that the dipole system satisfies a generalized first law of black hole mechanics, to which all the Killing horizons -- the two black hole horizons and the Misner string -- contribute equally.\r\n\r\n\\section*{Acknowledgments}\r\nI warmly thank Dmitry Gal'tsov for a critical reading of the manuscript and useful suggestions.\r\n\r\n\\begin{thebibliography}{9}\r\n\r\n\\bibitem{MP} A. Papapetrou, Proc. Roy. Irish Acad. A \\textbf{51} (1947) 191;\r\nS.D. Majumdar, Phys. Rev. \\textbf{72} (1947) 390.\r\n\r\n\\bb{dimagn} G. Cl\\'ement, Phys. Rev. D {\\bf 98} (2018) 104003 [arXiv:1807.01379].\r\n\r\n\\bb{baldimagn} G. Cl\\'ement, Phys. Lett. B {\\bf 795} (2019) 587\r\n[arXiv:1906.06951].\r\n\r\n\\bibitem{GC15}\r\nG.~Cl\\'ement, D.~Gal'tsov and M.~Guenouche, Phys. Lett. B {\\bf 750} (2015)\r\n591 [arXiv:1508.07622]; Phys. Rev. D {\\bf 93} (2016) 024048\r\n[arXiv:1509.07854].\r\n\r\n\\bibitem{Emparan:2001bb} R.~Emparan and E.~Teo,\r\n%``Macroscopic and microscopic description of black diholes,''\r\nNucl.\\ Phys.\\ B {\\bf 610} (2001) 190 [arXiv:hep-th/0104206].\r\n\r\n\\bibitem{Tomimatsu:1981bc}\r\n  A.~Tomimatsu and M.~Kihara,\r\n  %``Conditions for Regularity on the Symmetry Axis in a Superposition of Two Kerr Nut Solutions,''\r\n  Prog.\\ Theor.\\ Phys.\\  {\\bf 67} (1982) 1406.\r\n\r\n\\bb{letelier98a} P.S. Letelier and S.R. de Oliveira, Phys. Lett. {\\bf A 238} (1998) 101.\r\n\r\n\\bb{manko2009} V.S. Manko, E.D. Rodchenko, E. Ruiz and M.B. Sadovnikova,\r\nMoscow Univ. Phys. Bull. {\\bf 64} (2009) 359 [arXiv:0901.3168].\r\n\r\n\\bb{sibga84} N.R. Sibgatullin: Oscillations and Waves in Strong Gravitational\r\nand Electromagnetic Fields (Nauka, Moscow, 1984;\r\nEnglish translation: Springer-Verlag, Berlin, 1991).\r\n\r\n\\bb{taleful} G. Cl\\'ement and D. Gal'tsov,\r\n%``Stationary double black hole without naked ring singularity'',\r\nClass. Quantum Grav. {\\bf 35} (2018) 214002 [arXiv:1806.11193].\r\n\r\n\\bb{letelier98b} P.S. Letelier and S.R. de Oliveira, Class. Quantum Grav. {\\bf 15} (1998) 421 [arXiv:gr-qc/9710122].\r\n\r\n\\bibitem{Tomimatsu:1983qc} A.~Tomimatsu,\r\n  %``On Gravitational Mass and Angular Momentum of Two Black Holes in Equilibrium,''\r\nProg.\\ Theor.\\ Phys.\\ {\\bf 70} (1983) 385.\r\n\r\n\\bb{smarrnut} G. Cl\\'ement and D. Gal'tsov,\r\n%``On the Smarr formulas for electrovac spacetimes with line singularities'',\r\nPhys. Lett. B {\\bf 802} (2020) 135270 [arXiv:1908.10617].\r\n\r\n\\bb{talefirst} G. Cl\\'ement and D. Gal'tsov, in preparation.\r\n\r\n\\end{thebibliography}\r\n\r\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:35", "yymm": "2010", "arxiv_id": "2010.14473", "url": "https://arxiv.org/abs/2010.14473", "source": "arxiv"}}
{"text": "%\\documentclass[a4paper]{styles/svproc}\n%\\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  \n\\documentclass[journal]{IEEEtran} \n%\\IEEEoverridecommandlockouts   \n\\usepackage{url}\n\\usepackage{amsmath}\n\\usepackage{siunitx}\n\\usepackage{amssymb}\n\\usepackage{hyperref}\n\\usepackage{float}\n\n\\usepackage[numbers]{natbib}\n\\usepackage{listings}\n\\usepackage{algorithm}\n\\usepackage{algpseudocode}\n\n\\usepackage{makecell}\n\\usepackage{tabulary}\n\\usepackage{rotating}\n\\usepackage{booktabs}\n\n\\usepackage[export]{adjustbox}\n\\usepackage{graphicx}\n\\usepackage{xspace}\n\\usepackage{subcaption}\n\\usepackage{wrapfig}\n\n\\usepackage{tikz}\n\\usetikzlibrary{patterns}\n\\usetikzlibrary{calc}\n\n\\newcommand{\\X}{X}\n\\newcommand{\\fiber}{F}\n\n\\newcommand{\\R}{\\mathbb{R}}\n\\def\\Xk{\\X_{k}}\n\\def\\Xf{\\X_\\textnormal{F}}\n\\def\\XK{\\X_{K}}\n\\def\\Xkk{\\X_{k-1}}\n\\def\\fiberk{\\fiber_{k}}\n\\def\\fiberK{\\fiber_{K}}\n\n\\def\\ManhattanAbbrv{MH\\xspace}\n\\def\\PriorityQueue{\\ensuremath{\\mathbf{X}}}\n\n\\def\\lift{\\textsc{Lift}}\n\n\\def\\h{h}\n\\def\\hstar{h^{*}}\n\n\\def\\x{x}\n\\def\\xi{\\x_I}\n\\def\\xik{\\x^k_I}\n\\def\\xg{\\x_G}\n\\def\\xgk{\\x^k_G}\n\\def\\Xg{\\X_G}\n\\def\\Xgk{\\X^k_G}\n\\def\\dx{\\dot{\\x}}\n\\def\\xk{\\x_k}\n\\def\\xj{\\x_j}\n\n\n\\def\\G{\\ensuremath{\\mathbf{G}}}\n\\def\\Gk{\\ensuremath{\\G_k}}\n\\def\\Gkk{\\ensuremath{\\G_{k-1}}}\n\\def\\path{\\ensuremath{\\mathbf{p}}}\n\\def\\tpath{\\tilde{\\path}}\n\n\\algnewcommand\\True{\\textbf{true}\\xspace}\n\\algnewcommand\\False{\\textbf{false}\\xspace}\n\\makeatletter\n\\newcommand{\\toprulealg}{\\hrule height.8pt depth0pt \\kern2pt} % Caption top horizontal rule+skip\n\\newcommand{\\midrulealg}{\\kern2pt\\hrule\\kern2pt} % Caption bottom (or mid) horizontal rule+skip\n\\newcommand{\\bottomrulealg}{\\kern2pt\\hrule\\relax}% Algorithm bottom rule\n\\newcommand{\\algcaption}[2][]{%\n  \\refstepcounter{algorithm}%\n  %\\toprulealg\n  \\textbf{{\\raggedright\\fname@algorithm~\\thealgorithm}}\\ #2\\par % Caption\n  \\midrulealg\n}\n\\makeatother\n\n\n%\\setcounter{algorithm}{1}\n\n\\def\\basePath{p}\n\\def\\xb{\\x_{\\text{base}}}\n\\def\\FF{FF}\n\\def\\notFF{\\overline{\\FF}}\n\\def\\xf{\\x_{\\text{fiber}}}\n\\def\\xm{x_{\\text{mid}}}\n\n\\def\\pifk{\\pi_{\\fiber_k}}\n\\def\\pif{\\pi_{\\fiber}}\n\n\\def\\maxSample{\\ensuremath{S_{\\text{max}}}}\n\\def\\maxDepth{\\ensuremath{D_{\\text{max}}}}\n\\def\\maxBranch{\\ensuremath{B_{\\text{max}}}}\n\\def\\deltaBase{\\ensuremath{\\delta_{\\Xkk}}}\n\\def\\deltaBundle{\\ensuremath{\\delta_{\\Xk}}}\n\\def\\deltaFiber{\\ensuremath{\\delta_{\\fiberk}}}\n\n\n\\def\\location{\\ensuremath{\\text{location}}}\n\\def\\depth{\\ensuremath{\\text{depth}}}\n\\def\\restriction{\\ensuremath{\\text{r}}}\n\\def\\pathsection{\\ensuremath{\\text{s}}}\n\\def\\head{\\ensuremath{\\text{h}}}\n\\algnewcommand{\\algorithmicbreak}{\\textbf{break}}\n\\algnewcommand{\\BREAK}{\\algorithmicbreak}\n\\algnewcommand{\\algorithmicor}{\\textbf{ or }}\n\\algnewcommand{\\OR}{\\algorithmicor}\n\\algnewcommand{\\algorithmicand}{\\textbf{ and }}\n\\algnewcommand{\\AND}{\\algorithmicand}\n\n\\def\\wrigglePattern{\\textsc{WrigglePattern}\\xspace}\n\\def\\tunnelPattern{\\textsc{TunnelPattern}\\xspace}\n\\def\\triplestepPattern{\\textsc{TripleStepPattern}\\xspace}\n\\def\\L1Pattern{\\textsc{ManhattanPattern}\\xspace}\n\n\\def\\xend{\\x_\\text{End}}\n\\def\\xhead{\\x_{\\head}}\n\\def\\xfiberhead{\\x_{\\fiber_{\\head}}}\n\\def\\lend{l_\\text{End}}\n \n\\title{\\Huge Section Patterns: Efficiently Solving Narrow Passage Problems using Multilevel Motion Planning}\n\n\\begin{document}\n\n\\author{Andreas Orthey$^{1}$ and Marc Toussaint$^{1,2}$\n\\thanks{$^{1}$Max Planck Institute for Intelligent Systems, Stuttgart, Germany {\\tt\\small {aorthey}@is.mpg.de}}\n\\thanks{$^{2}$Technical University of Berlin, Germany}\n\\thanks{\\copyright 2020 IEEE.  Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.}\n}\n\n\\maketitle \n\n\n\\begin{abstract}\n\nSampling-based planning methods often become inefficient due to narrow passages. Narrow passages induce a higher runtime, because the chance to\n  sample them becomes vanishingly small. In recent work, we showed that narrow\n  passages can be approached by relaxing the problem using admissible lower-dimensional\n  projections of the state space. Those relaxations often increase the volume of narrow passages under\n  projection. Solving the relaxed problem is often efficient and produces an\n  admissible heuristic we can exploit. However, given a base path, i.e. a solution to a relaxed problem, there\n  are currently no tailored methods to efficiently exploit the base path. To efficiently exploit the base path and thereby its admissible heuristic, we develop section patterns, which are solution strategies to efficiently\n  exploit base paths in particular around narrow passages. To coordinate section patterns, we develop the pattern dance algorithm, which efficiently coordinates section patterns to reactively traverse narrow passages. We combine the pattern dance algorithm with previously developed multilevel planning algorithms and benchmark them on\n  challenging planning problems like the Bugtrap, the double L-shape, an\n  egress problem and on four pregrasp scenarios for a 37 degrees of freedom shadow hand mounted on a\n  KUKA LWR robot. Our results confirm that\n  section patterns are useful to efficiently solve high-dimensional\n  narrow passage motion planning problems. \n\n\\end{abstract}\n \n\\section{Introduction}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{images/pullfigure/pullfigure.pdf}\n    \\caption{Efficient exploitation of admissible heuristics (stemming from solution to relaxed problem) using the triple step pattern. The triple step pattern is one of four section patterns we advocate to efficiently exploit admissible heuristics near narrow passages.}\n    \\label{fig:pullfigure}\n\\end{figure}\n\nSampling-based motion planning algorithms are a successful paradigm to automate robotic\ntasks \\cite{lavalle_2006}. However, sampling-based algorithms do not perform well when the state space of the robot contains narrow passages \\cite{Mainprice2020, Szkandera2020, Hsu2003, Saha2005}, which are low-measure regions which have to be\ntraversed to reach a goal. Narrow passages are often occurring in tasks which are\nparticularly important in robotic applications, like grasping, peg-in-hole, egress/ingress or long-horizon planning problems \\cite{Fu2019, Hartmann2020}.\n\nIn previous work, we and other research teams have shown that we can often efficiently solve high-dimensional\nplanning problems by using admissible\nlower-dimensional projections of the state space, a topic we refer to as\nmultilevel motion planning \\cite{Ferbach1997, Bayazit2005, Orthey2020IJRR, Reid2020, Vidal2019}. When\nusing a multilevel motion planning framework, we can often use solutions to\nsimplified planning stages as admissible heuristics for the original problem\n\\cite{Pearl1984, Aine2016}. To efficiently exploit those admissible heuristics, we can use biased sampling methods \\cite{Orthey2020IJRR, Reid2019}, which we can combine with classical planning algorithms like the rapidly-exploring random tree algorithm\n\\cite{Orthey2019}, the probabilistic roadmap planner \\cite{Orthey2018}, its\noptimal star versions \\cite{Orthey2020IJRR} or the fast marching trees planner\n\\cite{Reid2019}. However, while showing promising runtimes, those algorithms are prone to get trapped when run on problems involving narrow passages.\n\nIn this work, we address narrow passages in multilevel motion planning problems\nby developing section patterns. Section patterns are methods to explicitly address problematic situations which occur when we like to exploit solutions to relaxed problems. \n\nWe introduce four section patterns. First, we introduce the Manhattan pattern, which we use to compute solution paths which actuate the minimal amount of joints to reach a goal region, which is advantageous for high dimensional systems \\cite{Cortes2008, Orthey2020IJRR}. \nSecond, we introduce the Wriggle pattern, which we use to make small random walk steps to traverse a narrow passage. Third, we introduce the Tunnel pattern, which we use to steer around small infeasible regions. Fourth, we introduce the Triple step pattern, which we use to backtrack in case the algorithm gets stuck. \nIn Fig.~\\ref{fig:pullfigure} the Triple step pattern is showcased for a $37$-degrees of freedom (dof) robotic hand. We execute the pattern when a collision occurs (1). We first backstep (2), then sidestep (3) and finally we make a forward step (4) to reach a goal position. The details of this and of the other pattern will be detailed later in this paper.\n\nTo coordinate the execution of the four section patterns, we develop a novel algorithm we call \\emph{pattern dance}. The pattern dance algorithm starts with an Manhattan pattern until a collision occurs. The algorithm then switches to an iteration of the wriggling pattern followed by the tunneling pattern. If those patterns fail, we switch to the triple step pattern. Once a pattern is successful, we recursively call the pattern dance algorithm until we either reach a certain depth or we reach the goal region. We embed the pattern dance algorithm into four multilevel planner \\cite{Orthey2020IJRR}, namely the quotient space RRT (QRRT) \\cite{Orthey2019}, the quotient space roadmap planner (QMP) \\cite{Orthey2018} and its optimal versions QRRT* and QMP* \\cite{Orthey2020IJRR}.\n\nOur contributions are as follows.\n\\begin{enumerate}\n    \\item We develop section patterns to efficiently exploit base space\n      paths (solutions to relaxed problems).\n    \\item To coordinate sections patterns, we develop the pattern dance algorithm\n    \\item We combine the pattern dance algorithm with four multilevel planner (QRRT, QRRT*, QMP, QMP*) and comparison against $36$ planners from the open motion planning library (OMPL) and a previous sidestepping\n      algorithm \\cite{Orthey2020IJRR} on $7$ challenging scenarios.\n\\end{enumerate}\n \\section{Related Work}\n\nLet us review the literature by focusing on two topics. First, we focus on generating admissible heuristics \\cite{Edelkamp2011} for motion planning problems involving continuous domains \\cite{lavalle_2006}. We discuss sources of admissible heuristics like constraint relaxations, lazy search, informed trees and past experience. Second, given an admissible heuristic, we review methods to efficiently exploit the heuristic either using path section approaches, local minima avoidance or narrow passage handling. \n\n\\subsection{Generating Admissible Heuristics}\n%Might be relevant: \\cite{Bhardwaj2019}\n\nMotion planning \\cite{lavalle_2006} is a well studied topic which has been successfully applied to a wide range of problem domains \\cite{Moll2015}. One of the most promising paradigms to solve motion planning problems are (optimal) sampling-based planner \\cite{Karaman2011, Salzman2016, Salzman2019, Bekris2020, Gammell2020Survey}.  However, those planner might become inefficient in state spaces which are too high-dimensional \\cite{Orthey2020IJRR}, contain intricate constraints \\cite{Jaillet2012} or narrow passages \\cite{Lee2012}. We can, however, often solve such problems efficiently, if we use admissible heuristics \\cite{Aine2016}. \n\n%%% Heuristics from relaxed problem\nWe believe there are three large sources of admissible heuristics. First, we can compute admissible heuristics as solutions to relaxed problems \\cite{Pearl1984}. Early instances of this idea to motion planning can be found in the constraint relaxation frameworks by \\citeauthor{Ferbach1997} \\cite{Ferbach1997}, \\citeauthor{Sekhavat1998} \\cite{Sekhavat1998} and \\citeauthor{Bayazit2005} \\cite{Bayazit2005}. Newer instances of this idea are putting the focus on different aspects like the specific type of projection \\cite{Sucan2011, Gochev2012} or the type of lower-dimensional space \\cite{Orthey2018, Brandao2020}. We refer to all those frameworks under the collective term multilevel motion planning \\cite{Orthey2020IJRR}. We can apply multilevel frameworks both to holonomic \\cite{Reid2019, Reid2020} and nonholonomic planning problems \\cite{Vidal2019, Orthey2020IJRR}. To create multilevel abstraction, we can often remove links from a robot \\cite{Bayazit2005, Zhang2009}, shrink links \\cite{Baginski1996, Saha2005} or approximate a robot by simpler geometries, either exact \\cite{Orthey2018, Grey2017} or approximate \\cite{Brock2001, Rickert2014, tonneau_2018}.\nWhile most methods use prespecified levels of abstraction, we can also use workspace information to compute abstractions on the fly \\cite{Yoshida2005, Luna2020}, adaptively switch between abstractions \\cite{Styler2017} or learn useful abstractions for specific instances \\cite{Brandao2020}. Our approach is similar, in that we also use a multilevel motion planning framework \\cite{Orthey2020IJRR}. However, our work is complementary, in that we focus specifically on computing path sections in the presence of narrow passages in the state space.\n\n% from lazy search and informed sets\nA second source of admissible heuristics are lazy search \\cite{Bohlin2000, Haghtalab2017} and informed sets \\cite{Gammell2014, Joshi2020}. Instead of using relaxations, we can compute lazy paths (paths not checked for collisions), either forward from the start \\cite{Hauser2014} or backwards from the goal \\cite{Strub2020Adaptively}, to create an efficient heuristic which we can exploit using dedicated algorithms \\cite{Gammell2020}. Once a solution exists, we can also exploit informed sets, sets which exclude all states with provable higher cost-to-go \\cite{Gammell2014, Gammell2020}. Those methods are particularly important, since edge evaluations is one of the bottlenecks in motion planning \\cite{Kleinbort2020}. It makes therefore sense to develop heuristics which evaluate edges as late as possible \\cite{Mandalika2019, Hou2020}.\n\n%% Pattern databases\nThird, inspired by pattern database approaches in discrete search \\cite{Culberson1998, Edelkamp2012, Hu2019}, we can also construct admissible heuristics by using past experience. We can achieve this by either precomputing motion primitives, like steering functions or controllers like linear quadratic regulators \\cite{Sakcak2019Auto, Sakcak2019}. Or, we can store previous solution paths directly and use them as heuristics in new environments \\cite{Driess2020, Qureshi2020}. Our work is complementary in that we assume a heuristic given and we focus on exploiting this heuristic as efficiently as possible. \n%% Discrete vs Continuous \n%% A* like (Discrete search inspired)\n%% Guide Paths\n%% Biased Sampling\n%% Local Minima Avoidance\n%% Narrow Passage Detection\n\n\\subsection{Exploiting Admissible Heuristic}\n\n%% discrete vs continuous domains\nGiven an admissible heuristic, we can optimally exploit it by discretizing the state space \\cite{Ferguson2005} and by using the A* algorithm \\cite{Hart1968, Pearl1984, Aine2016}. However, discretizing the state space usually does not scale well to higher dimensional state spaces \\cite{Bungartz2004, Persson2014, Giles2015} and performance would be sensitive to the resolution used \\cite{Du2020}. To avoid discretization, we found three categories of works which use continuous methods to exploit admissible heuristics.\n\n%% Biased Sampling\nFirst, we can use biased sampling methods. A straightforward way would be to represent the heuristic value of a state by the radius of a hypersphere around the state \\cite{Littlefield2018}. We could then exploit this hypersphere using dynamic domain sampling \\cite{Yershova2009}. Using such a scheme, we would expand states with higher heuristic values more often. Depending on the exact type of heuristic function used, we would obtain sampling distributions which would increase the probability to sample states which are near to restricted workspace geometries \\cite{VanDenBerg2005, Yang2005}, to state space obstacles \\cite{Amato1998} or to narrow passage \\cite{Hsu2003}. Those sampling distributions could also be learned over time to improve sampling \\cite{Luo2019, Ichter2018}. Our approach is similar in that we also use sampling-based methods. We differ, however, in that we concentrate on designing efficient patterns complementary to biased sampling methods.\n\n%% Guide Paths\nGiven a solution to a relaxed problem, we can often use this solution as a guide path heuristic \\cite{Zhang2009, tonneau_2018} to quickly find a solution in the original state space. Using the parlance of fiber bundles, we refer to this approach as the path section approach \\cite{Orthey2020IJRR}. To implement a path section approach, we can often use restriction sampling \\cite{Palmieri2016, Orthey2018}. Restriction sampling is often used in high-dimensional contact planning cases \\cite{bretl_2006, tonneau_2018}, where uniform sampling would most likely fail to find solutions in a reasonable time \\cite{Grey2017}. Apart from biasing sampling, we can also explicitly search over the set of states which project onto the guide path (the path restriction) \\cite{Zhang2009}. One particular method is the sidestepping path section approach \\cite{Orthey2020IJRR}, where we propagate states while following the path restriction. Once collisions occur, we execute local sidesteps to move around the obstacle. However, as we show in Sec.~\\ref{sec:sectionpatterns}, sidesteps are often not beneficial for narrow passages. While we also use a path section approach, we differ by developing dedicated patterns to more efficiently traverse narrow passages.\n\n%% Local minima\n%escape-> and never return (tabu search), deflate heuristic (Du2019)\n%avoid->Learn \n\n%escape local minima: Pohl 1973\nPath section approaches and other heuristic search methods often fail because they reach local minima. We define a local minimum as a region in state space where the heuristic is not or only weakly correlated with the true cost-to-go \\cite{Vats2017}. To address local minima, we can choose one of two approaches. First, we could preemptively avoid local minima. If the environment is static, we can learn minima regions and use this information to update the heuristic function \\cite{Vats2017}. Second, we could try to escape local minima. There exist several methods to escape local minima like deflating the heuristic value of states close to obstacles \\cite{Du2019} or increasing the search resolution to prevent evaluation of closeby states \\cite{Du2020}. A related idea is to utilize Tabu search \\cite{Glover1998} to prevent sampling\nin previously visited regions. \n\n%% Narrow Passages\nIt is important to make the distinction between local minima which trap the planner and regions which might look like local minima but which a planner can actually traverse. We call such regions narrow passages \\cite{Salzman2013}. To verify the existence of narrow passages in low-dimensional state spaces, we can use exact infeasibility proofs \\cite{Schweikard1998, Basch2001}, for example using geometrical shapes like alpha complices \\cite{Mccarthy2012} or cell decomposition methods \\cite{Zhang2008}. Because many state spaces have a local product structure, we can often use configuration space slices \\cite{Lozano1987, Sintov2020} to efficiently test for infeasibility \\cite{Varava2020}. If the problem is feasible, we could then use the geometrical shapes to enumerate narrow passages \\cite{Manak2019}. To exploit narrow passages, we could bias sampling to the most constricted areas \\cite{Yang2005, Szkandera2020}. We differ to those approaches by not explicitly modeling narrow passages or local minima, but we instead develop reactive measures to escape minima and to traverse narrow passages. We thereby avoid spending time on irrelevant narrow passages. \n \\section{Background\\label{sec:background}}\n\n\\begin{figure}\n    \\centering\n\\resizebox{0.8\\linewidth}{!}{\n\n\\begin{tikzpicture}\n\\def\\height{2}\n\\def\\radius{1.25}\n\\def\\heightEllipse{0.5}\n\\def\\distBase{1.8}\n\\def\\pathLength{1.5}\n\\def\\vertexStart{-0.5*\\pathLength}\n\\def\\pathStretch{2*3.1415/\\pathLength}\n\n\\def\\xposFiber{-2.5*\\radius}\n\\def\\xposPath{0*\\radius}\n%\\def\\xposGraph{2.2*\\radius}\n\n\\tikzset{\n    classical/.style={thin,double,->,shorten >=4pt,shorten <=4pt,>=stealth}\n}\n\\newcommand\\drawCylinder[1]{\n\\draw (#1,\\height) ellipse ({\\radius} and \\heightEllipse);\n\\draw (#1-\\radius,0) -- (#1-\\radius,\\height);\n\\draw (#1+\\radius,0) -- (#1+\\radius,\\height);\n\\draw (#1-\\radius,0) arc (180:360:{\\radius} and \\heightEllipse);\n\\draw [dashed] (#1-\\radius,0) arc (180:360:{\\radius} and -\\heightEllipse);\n\\draw (#1,-\\distBase) ellipse ({\\radius} and \\heightEllipse);\n\\draw[classical] (#1,0-\\heightEllipse) -- (#1,-\\distBase+\\heightEllipse);\n}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%Draw Path\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\newcommand\\ppath[1]{\n0.13*sin(180*(\\pathStretch*(#1-\\pathStart))/3.14)\n}\n\\newcommand\\drawPath[1]{\n\\def\\pathStart{#1+\\vertexStart}\n\\draw plot [smooth,samples=10,domain=\\pathStart:{\\pathStart+\\pathLength}](\\x,{\\ppath{\\x} - \\distBase});\n\\fill [gray, pattern=vertical lines, opacity=0.8]\nplot [smooth,samples=10,domain=\\pathStart:{\\pathStart+\\pathLength}](\\x,{\\ppath{\\x}}) -- \nplot [smooth,samples=10,domain={\\pathStart+\\pathLength}:\\pathStart](\\x,{\\ppath{\\x} + \\height});\n\n\\foreach \\y in {0,0.5,...,\\height}\n\\draw plot [smooth,samples=10,domain=\\pathStart:{\\pathStart+\\pathLength}](\\x,{\\ppath{\\x} + \\y});\n\n\\draw (\\pathStart,0) -- (\\pathStart, \\height);\n\\draw (\\pathStart+\\pathLength,0) -- (\\pathStart+\\pathLength, \\height);\n}\n\n\\newcommand\\drawFiber[1]{\n\\def\\pointPosX{#1+0.5*\\radius}\n\\draw[line width=0.3mm,black](\\pointPosX,0) -- (\\pointPosX, \\height);\n\\node[draw,fill,circle,inner sep=0pt,minimum size=0.3mm] at (\\pointPosX, 0-\\distBase){};\n\\draw node[left] at (\\pointPosX, 0-\\distBase) {$x_B$};\n\\draw node[left] at (\\pointPosX, 0.5*\\height) {$\\pi^{-1}(x_B)$};\n}\n\n\\newcommand\\drawGraphCC[2]{\n\\draw \n(#1+\\vertexStart+1.2*\\pathLength,#2 - 0.1*\\heightEllipse)\n-- (#1+\\vertexStart+0.9*\\pathLength,#2 + 0.3*\\heightEllipse)\n-- (#1+\\vertexStart+0.6*\\pathLength,#2 + 0.5*\\heightEllipse)\n-- (#1+\\vertexStart+0.4*\\pathLength,#2 - 0.5*\\heightEllipse)\n-- (#1+\\vertexStart+0.75*\\pathLength,#2 - 0.4*\\heightEllipse)\n-- (#1+\\vertexStart+0.9*\\pathLength,#2 + 0.3*\\heightEllipse);\n}\n\n\n\\tikzset{\n  vertex/.style = {shape=circle,inner sep=0,outer sep=0},\n  edge/.style = {->,-Latex},\n}\n\\node[vertex] (a) at (+\\vertexStart+1.2*\\pathLength, - 0.1*\\heightEllipse) {};\n\\node[vertex] (b) at (+\\vertexStart+0.9*\\pathLength, + 0.3*\\heightEllipse) {};\n\\node[vertex] (c) at (+\\vertexStart+0.6*\\pathLength, + 0.5*\\heightEllipse) {};\n\\node[vertex] (d) at (+\\vertexStart+0.4*\\pathLength, - 0.5*\\heightEllipse) {};\n\\node[vertex] (e) at (+\\vertexStart+0.75*\\pathLength, - 0.4*\\heightEllipse) {};\n\\node[vertex] (f) at (+\\vertexStart+0.9*\\pathLength, + 0.3*\\heightEllipse) {};\n\n\\node[vertex] (g) at (+\\vertexStart-0.2*\\pathLength, -0.2*\\heightEllipse) {};\n\\node[vertex] (h) at (+\\vertexStart+0.2*\\pathLength, + 0.1*\\heightEllipse) {};\n\\node[vertex] (i) at (+\\vertexStart+0.05*\\pathLength, + 0.5*\\heightEllipse) {};\n\n\\def\\edgeList{a/b, b/c, c/d, d/e, e/b, g/h, h/i, i/g}\n\n\\newcommand\\drawGraph[2]{\n\\foreach \\source/\\target in \\edgeList\n    \\draw ($(\\source)+(#1,#2)$) -- \n    ($(\\target)+(#1,#2)$);\n}\n\\newcommand\\drawGraphRestriction[3]{\n\\foreach \\source/\\target in \\edgeList\n    \\fill [gray, draw, pattern=vertical lines, opacity=0.8]\n    ($(\\source)+(#1,#2)$) -- \n    ($(\\target)+(#1,#2)$) --\n    ($(\\target)+(#1,#2)+(0,#3)$) --\n    ($(\\source)+(#1,#2)+(0,#3)$) --\n    ($(\\source)+(#1,#2)$);\n}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\drawCylinder{\\xposFiber}\n\\drawFiber{\\xposFiber}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\drawCylinder{\\xposPath}\n\\drawPath{\\xposPath}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%\\drawGraph{\\xposGraph}{-\\distBase}\n%\\foreach \\y in {0,0.5,...,\\height}\n%   \\drawGraph{\\xposGraph}{\\y};\n%\\drawCylinder{\\xposGraph}\n%\\drawGraphRestriction{\\xposGraph}{0}{\\height};\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\end{tikzpicture}\n}\n    \\caption{Bundle restrictions on fiber bundle $\\R^3 \\rightarrow \\R^2$. Left: Point restriction (Fiber). Right: Path restriction over base path. Taken from \\cite{Orthey2020IJRR}.\\label{fig:fiberbundle}}\n\\end{figure} \nLet us describe the necessary background to follow the exposition of our algorithm in Sec.~\\ref{sec:algorithm} and Sec.~\\ref{sec:sectionpatterns}. We start by explaining multilevel motion planning, i.e.~planning with sequences of relaxed subproblems. While several formulations exist, we believe the framework of fiber bundles \\cite{Orthey2020IJRR} to be a good way to concisely model multilevel abstractions and describe our algorithms. We then describe the concepts of lift, path restriction and path section which are particularly important. \nFinally, we describe the notion of admissible heuristics, which is one of the fundamental concepts to exploit solutions to relaxed problems. \n\n\\subsection{Optimal Motion Planning}\n\nLet $\\X$ be the state space of the robot. To each state space we associate a constraint function $\\phi: \\X \\rightarrow \\{0,1\\}$ which evaluates to $0$ if a state is constraint-free and to $1$ otherwise. We use the constraint function to define the free state space $\\Xf = \\{ x \\in \\X \\mid \\phi(x) = 0\\}$. Together with an initial configuration $\\xi \\in \\Xf$ and a goal configuration $\\xg \\in \\Xf$, we define an optimal motion planning problem \\cite{Karaman2011, Salzman2019, Bekris2020} as the tuple $(\\Xf, \\xi, \\xg, c)$, whereby our task is to develop an algorithm which computes a path from $\\xi$ to $\\xg$ while staying in $\\Xf$ and minimizing the cost functional $c$. In this work, we use a minimal-length cost functional, but other costs are also possible like minimal energy or maximum clearance.\n\n%If we are given a cost function $c$ on paths \\marc{why do you mention this? Will you introduce a cost?} in $\\Xf$, we can formulate the optimal motion planning problem \\cite{Karaman2011, Salzman2019, Bekris2020}, where we want to compute an optimal path with respect to the cost function $c$.\n\n\\subsection{Multilevel Motion Planning}\n\nSince high-dimensional motion planning problems are often too computationally expensive to solve, we use a sequence of relaxed problems which we refer to as multilevel abstractions\n\\cite{Orthey2020IJRR}. Given a state space $\\X$, let us denote a multilevel abstraction as the tuple $\\{\\X_1, \\cdots, \\X_K\\}$ with $\\X_K = \\X$. To each state space $\\X_k$, we associate a constraint function $\\phi_k$ and a projection $\\pi_k$ from $\\X_k$ to $\\X_{k-1}$. We say that the projection $\\pi_k$ is admissible (w.r.t. the constraint functions), if $\\phi_{k-1}(\\pi_k(x)) \\leq \\phi_k(x)$ for any $x$ in $\\X_k$. With admissibility, we basically guarantee that solutions are preserved under projections \\cite{Orthey2019}. If we would allow inadmissible projections, we would potentially sacrifice solutions and thereby sacrifice (probabilistic) completeness. \n\n\\subsection{Fiber Bundle Formulation}\n\nWhen working with multilevel abstraction, we quickly stumble upon situations where we lack the appropriate vocabulary to describe solution strategies. As a remedy, we describe multilevel abstractions using the framework of fiber bundles \\cite{steenrod_1951, husemoller_1966, lee_2003}. A fiber bundle is a tuple $(\\X_k, \\X_{k-1}, \\fiber_k, \\pi_k, \\pifk$, consisting of a total space $\\X_k$, a base space $\\X_{k-1}$, a fiber space $\\fiber_k$, a projection mapping $\\pi_k$ from total to base space and a fiber projection mapping $\\pifk$ from total to fiber space. We assume the projection mapping $\\pi_k$ to be admissible. With a fiber bundle, we model product spaces which locally decompose as $\\X_k = \\X_{k-1} \\times \\fiber_k$. The total space $\\X_k$ is a union of fiber spaces which are parameterized by the base space $\\X_{k-1}$. We show a prototypical fiber bundle in Fig.~\\ref{fig:fiberbundle} (left). If the level $k$ is unimportant for the task as hand, we often refer to a fiber bundle as the tuple $(\\X, B, \\fiber, \\pi, \\pif)$ with $\\X$ being the total, $B$ the base, $\\fiber$ the fiber space and $\\pi$, $\\pif$ the base and fiber projection, respectively. For more details and motivation, we refer to our prior work \\cite{Orthey2020IJRR}. For the purpose of this paper, we focus on the three concepts of lift, path restriction and path section, which we explain next.\n\n\\subsection{Lift}\n\nLet $(\\X, B, \\fiber, \\pi, \\pif)$ be a fiber bundle and let $b \\in B$ be a base space element. We often like to project the element $b$ back to the total space $\\X$. We call this operation a lift \\cite{Roewekaemper2013, Orthey2020IJRR}. We define a lift as a mapping $\\lift: B \\rightarrow \\X$. To uniquely select an element in $\\X$, we will overload this function as a mapping $\\lift: B \\times F \\rightarrow \\X$ by providing a fiber space element $f$ in $\\fiber$. If $\\X$ is a product space, we define the lift as $\\lift(b,f)=(b,f)$ \\cite{Orthey2020IJRR}.\n\n\\subsection{Path Restrictions}\n\nLet $p: I \\rightarrow B$ with $I = [0,1]$ be a path on the base space (a base path). Given a base path, one of the most central sets which we use in this work are path restrictions. A path restriction is the set $r(p) = \\{ x \\in \\X \\mid \\pi(x) \\in p[I]\\}$, whereby $p[I] = \\{ p(t): t \\in I \\}$ is the image of the base path in $B$ and $\\pi$ is the projection from $\\X$ to $B$. We visualize this situation in Fig.~\\ref{fig:fiberbundle} (right), where we show the image of a base path on the disk-shaped base space and its associated path restriction on the total space.\n\n\\subsection{Path Sections}\n\nGiven a path restriction, we are often interested in finding paths which are lying inside the path restriction. We call them path sections \\cite{steenrod_1951}. A (smooth) path section w.r.t. a base path $p$ is a mapping $s$ from base space to total space such that $\\pi(s(u))=u$ for any $u$ in the image of $p$ \\cite{lee_2003}. This means, for each base path element, we select a unique state from the path restriction. \n\n\\subsection{Admissible Heuristics}\n\nOur motivation to introduce path restrictions and path sections comes from the role they play in exploiting admissible heuristics. Given a goal state $\\xg$, an admissible heuristic $\\h(x)$ for a state $x$ in $\\X$ is a lower-bound on the true cost-to-go (or value) function $\\hstar(x)$, which we define as the cost of the optimal path from $x$ to $x_G$ through $\\Xf$. Formally, we write this condition as $h(x) \\leq \\hstar(x)$  \\cite{Pearl1984, Aine2016, Orthey2019}. \n\nGiven an admissible heuristic, we can try to reach the goal $\\xg$ by using locally optimal decisions \\cite{Hart1968}. If we are at a state $x$, we can make an optimal decision by doing a two-step approach. First, we compute the $f$-value of all its neighbors, which is the sum of its heuristic value and its cost-to-come from the start state. We then expand the state (node) with the lowest $f$-value, because, under the admissible heuristic, it is our best guess to efficiently reach the goal \\cite{Pearl1984}.\n\nHowever, in a continuous domain, we cannot straightforwardly compute all neighboring states. Instead, we imagine computing a small $\\epsilon$-neighborhood around the state. To compute heuristic values, we project the complete neighborhood down onto the base space. To reach the goal, our best guess is to make a step into the direction of the current minimal-cost base path. The states which we would expand in that way are exactly the states on the path restriction. By searching a path section over this path restriction, we efficiently exploit the admissible heuristic given by the base path. \\section{Section Patterns\\label{sec:sectionpatterns}}\n\nIn this section, we formulate the problem of finding sections over path restrictions. To find sections, we develop four\nsection patterns to efficiently traverse narrow passages and escape local minima. A local minimum is defined as a region where the true cost is only weakly correlated with the true cost-to-go \\cite{Vats2017}. We eventually integrate the section patterns into the pattern dance algorithms we present in Sec.~\\ref{sec:algorithm}.\n\n\\subsection{Problem Formulation}\n\nLet $\\X$ be a state space with initial state $\\xi \\in \\X$ and goal state $\\xg \\in \\X$. Further, let $(\\X, B, \\fiber, \\pi)$ be a fiber bundle on $\\X$ (possibly in a sequence of fiber bundles) and let $p: I \\to B$ be a base path on $B$ starting at $\\pi(\\xi)$ and ending at $\\pi(\\xg)$. Given the base path $p$ and its path restriction $r(p) \\subseteq \\X$, our goal is to develop an algorithm to find a feasible path section, i.e. a path lying in the intersection of the path restriction $r(p)$ and the free state space $\\Xf$ connecting $\\xi$ to $\\xg$.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/restriction/restriction.pdf}\n    \\caption{Path restriction over base path $p$ with head pointer $h$, initial state $x_I$, goal state $x_G$, projection $\\pi$. See text for clarification.\\label{fig:pathrestriction}}\n\\end{figure} \n\\subsection{Head Pointer on Path Restriction}\n\nFor better exposition of our algorithm, we will introduce the terminology of a head pointer on a path restriction. We define a head pointer $h$ as the tuple $h=(x, l, r)$ consisting of a path restriction $r(p) \\subseteq \\X$ over a base path $p$ in $B$, a current state $x$ in $r(p)$ and a location $l \\in [0,1]$ defining the position along the base path. We think of the head pointer as  a ruler which we try move forward along the path restriction towards the goal state. We visualize this situation in Fig.~\\ref{fig:pathrestriction}. In pseudocode, we refer to the current state as $\\textsc{State}(h)$ and its location as $\\textsc{Location}(h)$. \n\nThe role of the section patterns is to propagate the head pointer forward along the path restriction. With propagating the head pointer we refer to the action of increasing the location of the head along the base path. All section patterns implement different strategies to accomplish this while keeping the current state inside of the free space $\\Xf$. \n\n\\subsection{Manhattan Pattern}\n\nOur first section pattern to propagate the head pointer $h$ is the Manhattan (\\ManhattanAbbrv) pattern. With the \\ManhattanAbbrv pattern, we interpolate a path between the head state and the goal state along the path restriction. To interpolate, we first interpolate along the base path while keeping the fiber element fixed. Once we reach the end of the base path, we interpolate along the fiber space to the goal state. This method is motivated by our desire to actuate the smallest number of joints at the same time, which is advantageous for high-dimensional systems \\cite{Cortes2008}. \n\n\n\n\\begin{algorithm}[t]\n\\algcaption{ManhattanPattern($\\head$)}\n\\begin{algorithmic}[1]\n\\State $x_h \\gets \\Call{State}{\\head}$\n\\State $x_{F} \\gets \\Call{ProjectFiber}{x_h}$\n\\Comment{$\\pif(x_h)$}\n\\State $l \\gets \\Call{Location}{\\head}$\n\\State $s \\gets \\emptyset$\n\\While{$l < \\Call{Length}{p}$}\n    \\State $x_B \\gets \\Call{BasePathAt}{p,l}$ \\Comment{State $p(l)$ on base path}\n    \\State $x \\gets \\Call{Lift}{x_B, x_{F}}$\n    \\State $s \\gets s \\cup \\{x\\}$\n    \\State $l \\gets l + \\deltaBase$\n\\EndWhile\n\\State $s \\gets s \\cup \\{x_G\\}$\n\\State $\\head \\gets \\Call{CheckMotion}{s}$\\Comment{Return Last Valid}\n\\State \\Return $\\Call{HasReachedGoal}{\\head}$\n\\end{algorithmic}\\label{alg:L1pattern}\n\\end{algorithm}\n\n \nWe detail the \\ManhattanAbbrv pattern in Alg.~\\ref{alg:L1pattern}. We take as input a head pointer $h$ over a path restriction $r$ with base path $p$. We first project the head state onto the fiber (Line 1-2) by using the fiber projection $\\pif$. We then take the location of the head pointer along the base path (Line 3) and step along the base path in increments of $\\deltaBase$ (Line 5-10) and add the states to the path $s$ (Line 4). This is done by computing the next base state (Line 6), lifting the base state into the total space (Line 7) and adding it to the path (Line 8). Once we reached the end of the base path, we add the goal state to the section (Line 11). The resulting path $s$ is schematically shown in Fig.~\\ref{fig:pathrestriction}. Finally, we evaluate the path by moving along until a constraint violation occurs or we reached the goal state (Line 12). The function $\\textsc{CheckMotion}$ returns the last valid state which we use to update the head $h$. We then return true if the head has reached the goal and false otherwise.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.55\\linewidth]{images/narrowpassage/03D_cylinder_env.png}\n    \\includegraphics[width=0.4\\linewidth]{images/narrowpassage/03D_cylinder_statespace.png}\n    \\caption{The geometry of state spaces near narrow passages.}\n    \\label{fig:geometrynarrowpassage}\n\\end{figure}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.48\\linewidth]{images/narrowpassage/03D_cylinder_section.pdf}\n    \\includegraphics[width=0.48\\linewidth]{images/narrowpassage/03D_cylinder_section_offset.pdf}\n    \\caption{Path restrictions near narrow passages.}\n    \\label{fig:pathrestrictionsnarrowpassages}\n\\end{figure}\n\n\\subsection{Interlude: The Geometry near Narrow Passages}\n\nThe next three section patterns are tailor-made solutions to either traverse a narrow passage or to escape a local minimum. To motivate those patterns, we first study the geometry of state spaces near narrow passages. We use a simple toy example of a rigid rectangular body moving in the 2D plane. The state space of this rigid body is the special euclidean group $SE(2)$, consisting of position and orientation. We assume that the body is located near to a narrow passages as shown in Fig.~\\ref{fig:geometrynarrowpassage} (left). We will further assume that our task is to move the rigid body through the narrow passage, from a start state (green) to a goal state (red). We will represent a state as $(x_0,x_1,x_2) \\in SE(2)$, with $x_0, x_1$  being vertical and horizontal displacement and $x_2$ the orientation. We visualize a subset of the state space in Fig.~\\ref{fig:geometrynarrowpassage} (right), whereby points in collision are colored from dark red (low $x_1$ value, close to start) to bright blue (high $x_1$ value, close to goal). \n\nTo generate path restrictions, we first use a relaxation of the problem onto circular disks (Fig.~\\ref{fig:geometrynarrowpassage}). This creates a fiber bundle $SE(2) \\rightarrow \\R^2$ with base space $\\R^2$ and total space $SE(2)$ \\cite{Orthey2018}. Let us assume a base path $p: I \\rightarrow \\R^2$ be given. This path induces a two-dimensional path restriction in $SE(2)$, two of which we visualize in Fig.~\\ref{fig:pathrestrictionsnarrowpassages}. The left Figure shows a path restriction for a base path going straight through the passage, as shown in Fig.~\\ref{fig:geometrynarrowpassage}. The right Figure shows a path restriction for a base path which goes slanted through the passage. Both are also slices through the state space geometry shown in Fig.~\\ref{fig:geometrynarrowpassage} (right). From Fig.~\\ref{fig:pathrestrictionsnarrowpassages}, we observe that there are at least three failure cases. Either, we reach a local minimum, we collide with constraints near local minima or narrow passages, or we get stuck in front of a small but infeasible region. For each case, we develop a dedicated section pattern to either advance or backtrack.\n\n\\subsection{Triple Step Pattern}\n\\begin{figure}[t]\n    \\centering\n    \\begin{subfigure}[t]{\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/triplestep/03D_cylinder_section.pdf}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/triplestep/T1.png}\n    \\caption{At $p_1$ (after collision).}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/triplestep/T2.png}\n    \\caption{At $p_2$ (after backstep).}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/triplestep/T3.png}\n    \\caption{At $p_3$ (after sidestep).}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/triplestep/T4.png}\n    \\caption{At $p_4$ (after forward step).}\n    \\end{subfigure}\n\n\\caption{Triple step pattern. See text for clarification. \\label{fig:sectionpattern:triplestep}}\n\\end{figure} \\begin{algorithm}[t]\n\\algcaption{TripleStepPattern($\\head, x$)}\n\\begin{algorithmic}[1]\n\\State $x_H \\gets \\Call{State}{\\head}$\n\\State $l \\gets \\Call{Location}{\\head}$\n\\State $x_{F_1} \\gets \\Call{ProjectFiber}{\\head}$\n\\State $x_{F_2} \\gets \\Call{ProjectFiber}{x}$\n\\State $x_{F_m} \\gets \\Call{Steer}{x_{F_1},x_{F_2}, 0.5}$\\Comment{Midpoint}\n\\While{$l > \\deltaBase$}\n    \\State $l \\gets l - \\deltaBase$\n    \\State $x_B \\gets \\Call{BasePathAt}{p,l}$\n    \\State $\\xm \\gets \\Call{Lift}{x_B, x_{F_m}}$\n    \\If{$\\Call{IsValid}{\\xm}$}\n        \\State $x_1 \\gets \\Call{Lift}{x_B, x_{F_1}}$\n        \\State $x_2 \\gets \\Call{Lift}{x_B, x_{F_2}}$\n        \\If{$\\Call{CheckMotion}{x_1,x_2}$}\n            \\If{$\\Call{CheckMotion}{x_H, x_1}$}\n                \\If{$\\Call{CheckMotion}{x_2, x}$}\n                    \\State $\\G_k \\gets \\G_k \\cup \\{x_H, x_1\\}$\n                    \\State $\\G_k \\gets \\G_k \\cup \\{x_1, x_2\\}$\n                    \\State $\\G_k \\gets \\G_k \\cup \\{x_2, x\\}$\n                    \\State $\\Call{UpdateHead}{h, x}$\n                    \\State \\Return \\True\n                \\EndIf\n            \\EndIf\n            \\State \\BREAK \\Comment{End While Loop}\n        \\EndIf\n    \\EndIf\n\\EndWhile\n\\State \\Return \\False\n\\end{algorithmic}\\label{alg:triplesteppattern}\n\\end{algorithm}\n \nTo escape a local minimum, we develop the triple step pattern. With the triple step pattern, we connect two states on the path restriction using a triple backtracking step. For the rectangular rigid body in the plane, we visualize this situation in Fig.~\\ref{fig:sectionpattern:triplestep}. We use the triple step pattern to connect states $p_1$ and $p_4$. To do that, we move backwards along the path restriction from $p_1$ to $p_2$ and from $p_4$ to $p_3$, respectively. We stop until we can connect $p_2$ and $p_3$ by a straight line. In that case we execute a backstep from $p_1$ to $p_2$, a sidestep (along the fiber) from $p_2$ to $p_3$ and a forward step from $p_3$ to $p_4$. \n\nWe show the pseudocode for the triple step pattern in Alg.~\\ref{alg:triplesteppattern}. Our goal is to connect the head state to the given state $x$. We first compute a midpoint on the fiber space (Line 5) (to minimize the number of \\textsc{CheckMotion} calls \\cite{Mandalika2019}). We then move backwards along the base path while we are greater than the parameter $\\deltaBase$ (Line 6-7). For each location, we interpolate a base state (Line 8), lift the state using the fiber midpoint (Line 9) and check if this state is valid. If it is valid, we compute intermediate states $x_1$ and $x_2$ (Line 11, 12) and check if the motion between them is feasible (Line 13). If that is true, we additionally check if the backward and forward steps are feasible (Line 14, 15). If that is true, we add those edges to the graph (Line 16-18) and update the head to our new state $x$ (Line 19). In that case we return true (Line 20). If we fail to find such a triple step, we terminate once we reach the beginning of the base path location and return false (Line 27). \n\n\\subsection{Wriggle Pattern}\n\nIf we reach a local minimum, the triple step pattern is a way to backtrack to a narrow passage. However, we often might execute the triple step pattern prematurely, because we bumped into constraints near or in a narrow passage. To circumvent those situations, we use the wriggle pattern. With the wriggle pattern, we make small random steps forward along the path restriction and accept a step if it is valid. \n\nThe pseudocode we depict in Alg.~\\ref{alg:wrigglepattern}. We start by making one $\\deltaBase$ step forward from the head (Line 1). Until we have not reached the end (Line 3), we get the base state at location $l$ (Line 4), and get the fiber element of the head state (Line 6). We then sample for $\\maxSample$ rounds (Line 8) by sampling a fiber state in the $\\deltaFiber$ proximity of the head fiber state (Line 9). We then lift the base and fiber state (Line 10) and check if the state is valid (Line 11). If the state is valid, we check if the motion from the head to the new state is feasible (Line 12-17). We terminate if we could not expand the state (Line 21-23) or reach the end. We then return true if we made at least one step (Line 25).\n\n\n\\def\\counterSampler{\\ensuremath{\\text{ctr}}}\n\\def\\stepsTaken{\\ensuremath{\\text{steps}}}\n\n\\begin{algorithm}[t]\n\\algcaption{WrigglePattern($\\head$)}\n\\begin{algorithmic}[1]\n\\State $l \\gets \\Call{Location}{\\head} + \\deltaBase$\n\\State $\\stepsTaken \\gets 0$\n\\While{$l < \\Call{Length}{p}$}\n    \\State $x_B \\gets \\Call{BasePathAt}{p,l}$\n    \\State $x_{\\head} \\gets \\Call{State}{\\head}$\n    \\State $x_{\\fiber_{\\head}} \\gets \\Call{ProjectFiber}{x_{\\head}}$\n    \\State $\\counterSampler \\gets 0$\n    \\While{$\\counterSampler < \\maxSample$}\n        \\State $x_F \\gets \\Call{SampleUniformNear}{x_{\\fiber_{\\head}}, \\deltaFiber}$\n        \\State $x \\gets \\Call{Lift}{x_B, x_{F}}$\n        \\If{$\\Call{IsValid}{x}$}\n            \\If{$\\Call{CheckMotion}{x_H, x}$}\n                \\State $\\G_k \\gets \\G_k \\cup \\{x_H, x\\}$\n                \\State $\\Call{UpdateHead}{\\head, x}$\n                \\State $\\stepsTaken \\gets \\stepsTaken + 1$\n                \\State \\BREAK\n            \\EndIf\n        \\EndIf\n        \\State $\\counterSampler \\gets \\counterSampler + 1$\n    \\EndWhile\n    \\If{$\\counterSampler \\geq \\maxSample$}\n        \\State \\BREAK\n    \\EndIf\n\\EndWhile\n\\State \\Return $\\stepsTaken > 0$\n\\end{algorithmic}\\label{alg:wrigglepattern}\n\\end{algorithm}\n \n\\subsection{Tunnel Pattern}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/sectionpatterns/tunnel/narrow_passage_cylinder_offset.pdf}\n    \\caption{Tunnel Pattern. See text for clarification. \\label{fig:tunnelpattern}}\n\\end{figure} \\begin{algorithm}[!ht]\n\\algcaption{TunnelPattern($\\head$)}\n\\begin{algorithmic}[1]\n%%find valid state\n\\State $(\\xend, \\lend) \\gets \\Call{TunnelEnd}(\\head)$\n\\State $\\xhead \\gets \\Call{State}{\\head}$\n\\State $\\xfiberhead \\gets \\Call{ProjectFiber}{\\xhead}$\n\n%%tunnel to valid state\n\\def\\dbest{d_{\\text{best}}}\n\\State $\\dbest \\gets \\Call{Distance}{\\xhead, \\xend}$\n\\State $l \\gets \\Call{Location}{\\head}$\n\\While{$l \\leq \\lend$}\n    \\If{$\\Call{CheckMotion}{\\xhead, \\xend}$}\n        \\State $\\G_k \\gets \\G_k \\cup \\{\\xhead, \\xend\\}$\n        \\State $\\Call{UpdateHead}{\\head, \\xend}$\n        \\State \\Return \\True\n    \\EndIf\n    \\State $l \\gets l + \\deltaBase$\n    \\State $x_B \\gets \\Call{BasePathAt}{p,l}$\n    \\State $\\epsilon \\gets \\Call{SmoothParameter}{0,10\\deltaBase,\\maxSample}$\n    \\State $\\counterSampler \\gets 0$\n    \\While{$\\counterSampler < \\maxSample$}\n        \\State $x_B \\gets \\Call{SampleUniformNear}{x_B, \\epsilon(\\counterSampler)}$\n        \\State $x_\\fiber \\gets \\Call{SampleUniformNear}{\\xfiberhead, \\deltaFiber}$\n        \\State $x \\gets \\Call{Lift}{x_B, x_\\fiber}$\n        \\If{$\\Call{IsValid}{x}$}\n            \\State $d \\gets \\Call{Distance}{x, \\xend}$\n            \\If{$d < \\dbest \\AND \n            \\Call{CheckMotion}{\\xhead, x}$}\n                \\State $\\G_k \\gets \\G_k \\cup \\{\\xhead, x\\}$\n                \\State $\\xhead \\gets x$\n                \\State \\BREAK\n            \\EndIf\n        \\EndIf\n        \\State $\\counterSampler \\gets \\counterSampler + 1$\n    \\EndWhile\n    \\If{$\\counterSampler \\geq \\maxSample$}\n    \\State \\Return \\False\n    \\EndIf\n\\EndWhile\n\\State \\Return \\False\n\\end{algorithmic}\\label{alg:tunnelpattern}\n\\end{algorithm}\n\n\n\n\n\n \nWhile the wriggle pattern locally explores the neighborhood \\emph{inside} the path restriction, we often encounter situations where we find it advantageous to momentarily step \\emph{outside} the path restriction to overcome an infeasible region. From the perspective of the path restriction, we \"tunnel\" through the infeasible region, which we therefore refer to as the tunnel pattern. With the tunnel pattern, we assume to be located at a local minimum $p_1$ as shown in Fig.~\\ref{fig:tunnelpattern}. To resolve this situation, we try to find the next valid state $p_2$ while keeping the fiber element constant. We then try to connect $p_1$ to $p_2$ by sampling valid states in a smoothly increasing neighborhood of the base space and a constant neighborhood in fiber space. While $p_2$ is not reached, we accept new states if they decrease the distance to $p_2$.\n\nWe show the pseudocode in Alg.~\\ref{alg:tunnelpattern}. We first search for a tunnel ending state $\\xend$ at base path location $\\lend$ (Line 1). To find the tunnel ending, we step forward along the base path without changing the fiber until we find a valid state. We then try to connect the head state $\\xhead$ to the tunnel ending state $\\xend$. We use a while loop to move along the relevant base path segment from the head location $l$ to the tunnel end location $\\lend$ (Line 6). We first check if we can connect the head state to the tunnel end state (Line 7). If true, we add a new edge into the graph (Line 8), set the head to the tunnel ending state (Line 9) and return true (Line 10). Otherwise, we step forward along the base path with step size $\\deltaBase$ (Line 12) and query the base state at $l$ (Line 13). Instead of using the base state exactly, we use a smoothly increasing neighborhood parameter $\\epsilon$. The value of $\\epsilon$ depends on the counter $\\textsc{\\counterSampler}$ and smoothly interpolates between $0$ and $10 \\deltaBase$ using an Hermite polynomial \\cite{De1987} (Line 14). We then attempt to make a step towards the tunnel ending for a maximum of $\\maxSample$ attempts (Line 16). We do this by sampling a base space element (Line 17) and a fiber element (Line 18). We then lift the state (Line 19) and check for validity (Line 20). If the new state is valid, its distance is closer to the tunnel ending and we can connect it to the head state (Line 22), we add a new edge to the graph (Line 23), set the head state to the new state (Line 24) and continue forward (Line 25). If we fail to find a better sample for $\\maxSample$ attempts, we return false (Line 30-32). We also return false if we reach the base path location $\\lend$ without having a valid connection (Line 34). \\section{Pattern Dance Algorithm\\label{sec:algorithm}}\n\nTo combine and coordinate section patterns, we develop the \\emph{pattern dance} algorithm. The pattern dance algorithm is a recursive algorithm which takes as input a path restriction over a base path,\na start and a goal configuration, and either returns a feasible path section or\nterminates after a certain depth has been reached. We use the pattern dance algorithm in combination\nwith the multilevel planner QMP, QMP*, QRRT and QRRT* \\cite{Orthey2020IJRR} to quickly determine if a given base path has a feasible section. The resulting algorithms inherit all properties from PRM \\cite{Kavraki1996}, PRM* \\cite{Karaman2011}, RRT \\cite{Kuffner2000} and RRT* \\cite{Karaman2011}, respectively, i.e. they are probabilistically complete, meaning the probability of finding a feasible path if one exists converges to one if time goes to infinity. The star versions are asymptotically optimal, meaning they will eventually converge to an optimal solution if time goes to infinity \\cite{Karaman2011, Orthey2020IJRR}.\n\n\\subsection{Pattern Dance as Part of Multilevel Planner}\n\n\n\\begin{algorithm}[t]\n\\algcaption{MultilevelPlanner($\\xi, \\xg, \\X_1,\\cdots,\\X_K$)}\n\\begin{algorithmic}[1]\n  \\State Let $\\PriorityQueue$ be a \\Call{priority\\ queue}{}\\label{alg:bundleplanner:priorityqueue}\n  \\For{$k=1$ to $K$}\n    \\def\\Xbest{\\X_{\\text{select}}}\n    \\def\\Xcur{\\X_{k}}\n    \\State $\\Call{FindSection}{\\Xcur}$\\label{alg:bundleplanner:section}\n    \\State $\\PriorityQueue.\\Call{push}{\\Xcur}$\\label{alg:bundleplanner:pushk}\n    \\While{$\\neg\\Call{ptc}{\\Xcur}$}\\label{alg:bundleplanner:while}\n      \\State $\\Xbest = \\PriorityQueue.\\Call{pop}{}$\\label{alg:bundleplanner:popselect}\n      \\State $\\Call{Grow}{\\Xbest}$\n      \\label{alg:bundleplanner:growselect}\n      \\State $\\PriorityQueue.\\Call{push}{\\Xbest}$\\label{alg:bundleplanner:pushselect}\n    \\EndWhile\n  \\EndFor\n\\end{algorithmic}\\label{alg:bundleplanner}\n\\end{algorithm}\n\n\\begin{algorithm}[t]\n\\algcaption{FindSection($\\Xk$)}\n\\begin{algorithmic}[1]\n    \\If{\\Call{Exists}{$\\Xkk $}}\\label{alg:section:exist}\n    \\State $\\basePath \\gets \\Call{BasePath}{\\G_{k-1}}$\n    \\State $\\restriction \\gets \\Call{Restriction}{\\basePath}$\n    \\State $\\head \\gets \\Call{HeadPointer}{x_I, \\location=0, \\restriction}$\n    \\State $\\Call{PatternDance}{\\head}$\n    \\EndIf\n\\end{algorithmic}\\label{alg:findsection}\n\\end{algorithm}\n \nBefore describing the pattern dance algorithm, we describe how it is embedded in the larger context of multilevel planner. A multilevel planner \\cite{Orthey2020IJRR} computes a feasible path for a multilevel motion planning problem. We describe such an algorithm in Alg.~\\ref{alg:bundleplanner}. We initialize the algorithm with an initial state $\\xi$, a goal state $\\xg$ and a sequence of bundle spaces $\\X_1, \\ldots, \\X_K$. To search for a feasible path, we first initialize a priority queue (Line 1), then we iteratively explore the bundle spaces (Line 2) by first testing for a path section (Line 3) and pushing the $k$-th bundle space into the priority queue (Line 4). We then loop while a planner terminate condition (PTC) of the $k$-th space is not fulfilled. A PTC can be a timelimit, an iteration limit or a desired cost. We then pop the space with the lowest importance from the queue (Line 6), which depends on the algorithm itself \\cite{Orthey2020IJRR}. We then execute one grow iteration for the selected bundle space (Line 7) and push the space back to the queue thereby updating its importance (Line 8). All multilevel planner share this high-level structure. Multilevel planner differ by how the \\textsc{Grow} function is implemented. \n\nWe previously developed four multilevel planner. First, the quotient-space roadmap planner (QMP), in which we implement \\textsc{Grow} as a probabilistic roadmap (PRM) step \\cite{Kavraki1996}. Second, the quotient-space rapidly-exploring random tree (QRRT), in which we implement \\textsc{Grow} as an RRT step \\cite{Kuffner2000}. Finally, we use the two asymptotically optimal versions QRRT* and QMP*, in which we implement a step of RRT* \nand PRM* \\cite{Karaman2011}, respectively. The algorithms also differ in how we order the bundle spaces inside the priority queue, how we compute the distance metric and how we implement sampling inside the grow function, as we detail in our previous publication \\cite{Orthey2020IJRR}.\n\nWe embed the pattern dance algorithm in the multilevel planner as a particular implementation of the \\textsc{FindSection} method. We show this in detail in Alg.~\\ref{alg:findsection}. First, we check if there exists a base space (Line 1). We then compute a base path $p$ from the underlying graph or tree on the base space (Line 2). We then build a path restriction $r$ from $p$ (Line 3) and create a head on the path restriction (Line 4). We then call the pattern dance algorithm with the head as input. \n\n\\subsection{Pattern Dance Implementation}\n\n\\def\\algName{PatternDance}\n\n\\begin{algorithm}[t]\n\\algcaption{\\algName($\\head, \\depth=0$)}\n\\begin{algorithmic}[1]\n    \\If{$\\Call{ManhattanPattern}{\\head}$}\n        \\State \\Return \\True\n    \\EndIf\n    \\If{$\\depth \\geq \\maxDepth$}\n    \\State \\Return \\False\n    \\EndIf\n    \\If{\\Call{WrigglePattern}{\\head} \\OR \\Call{TunnelPattern}{\\head}}\n    \\State \\Return \\Call{\\algName}{\\head, \\depth+1}\n    \\EndIf\n    \\State $l \\gets \\Call{Location}{\\head}+\\deltaBase$\n    \\State $x_B \\gets \\Call{BasePathAt}{p,l}$\n    \\For{$j \\in [1, \\maxBranch]$}\n       \\State $x_F \\gets \\Call{SampleFiber}{x_B}$\n       \\State $x \\gets \\Call{Lift}{x_B, x_F}$\n       \\State $x_H \\gets \\Call{State}{\\head}$\n       \\If{$\\Call{IsValid}{x} \\AND\n       \\neg \\Call{CheckMotion}{x_H, x}$}\n       \\If{$\\Call{TripleStepPattern}{\\head, x}$}\n           \\State \\Return \\Call{\\algName}{\\head, \\depth+1}\n       \\EndIf\n       \\EndIf\n    \\EndFor\n\\end{algorithmic}\\label{alg:patterndance}\n\\end{algorithm}\n \nWe depict the pseudocode of the pattern dance algorithm in Alg.~\\ref{alg:patterndance}. The input is a head over the path restriction and a recursion depth (initially set to zero). We first execute the \\textsc{ManhattanPattern} (Line 1). If the pattern succeeds, we successfully return (Line 2). Otherwise, we check if we reached the maximum recursion depth (Line 4) and return with failure (Line 5). \n\nIf the depth is below the maximum depth, we continue by executing first the \\wrigglePattern and the \\tunnelPattern (Line 7). If one is successful, we recursively call the pattern dance algorithm and we increase the recursion depth (Line 8). If none is successful, we are likely in a local minimum from which we like to escape using the \\triplestepPattern. To execute the triple step pattern, we first interpolate a single step forward along the base path (Line 10, 11). We then attempt to find a valid fiber space element for a maximum of $\\maxSample$ attempts (Line 12). This is done by first sampling a fiber state over the given base state (Line 13). We then lift the state to the path restriction (Line 14) to obtain a state $x$. If this state is valid and we \\emph{cannot} reach it from the head state (Line 16), we execute the triple step pattern with target $x$ (Line 17). If we successfully executed the pattern, we call the pattern dance algorithm again recursively. Note that the small forward step of $\\deltaBase$ (Line 10) is an essential component of our algorithm. If we would sample directly over the head base state, we often would sample symmetrical local minima (as an example, see state $p^{\\prime}_1$ in Fig.~\\ref{fig:sectionpattern:triplestep}). we found this to be particularly important for higher dimensional state spaces, where we often encounter infinitely many symmetrical local minima (consider the set of horizontal rotations of the cylinder before entering the opening in the Bugtrap scenario in Sec.~\\ref{sec:evaluations}).  \n\nTo implement the section patterns and the pattern dance algorithm, we use the open motion planning library (OMPL) \\cite{Sucan2012}. The algorithms are freely available and part of our multilevel motion planning extension of OMPL \\cite{Orthey2020IJRR}. All code can be downloaded over github\\footnote{\\url{https://github.com/aorthey/MotionExplorer/} and \\url{https://github.com/aorthey/ompl/}.}.\nAll parameters used in the algorithms are shown in Table~\\ref{tab:parameters}, including the values we use for the evaluations.\n\n\\begin{table}[t]\n\\centering\n\\begin{tabular}{ccc}\n\\toprule\nParameter & Description & Values used\\\\\n\\midrule\n\\maxDepth & Maximum depth of pattern dance & $3$\\\\\n\\maxBranch & Maximum branching of pattern dance & $500$\\\\\n\\maxSample & Maximum sampling attempts & $100$\\\\\n\\deltaBase & Step size on base space & $0.01 \\mu_{\\Xkk}$\\\\\n\\deltaFiber & Step size on fiber space & $0.01 \\mu_{\\fiberk}$\\\\\n\\bottomrule \n\\end{tabular}\n\\caption{Parameters used in algorithm. The variable $\\mu_{\\X}$ refers to the maximum extend of the state space $\\X$.\\label{tab:parameters}}\n\\end{table}  \\section{Evaluations\\label{sec:evaluations}}\n\n\\begin{figure*}[ht]\n    \\centering\n    \\begin{subfigure}[t]{0.3\\linewidth}\n    \\centering\n    \\includegraphics[width=0.9\\linewidth]{images/evaluations/06D_Bugtrap.png}\n    \\caption{06D Bugtrap\\label{fig:scenarios:bugtrap}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.3\\linewidth}\n    \\centering\n    \\includegraphics[width=0.9\\linewidth]{images/evaluations/06D_DoubleL.png}\n    \\caption{06D Double Lshape\\label{fig:scenarios:doubleLshape}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.3\\linewidth}\n    \\centering\n    \\includegraphics[width=0.9\\linewidth]{images/evaluations/10D_ChainEgress.png}\n    \\caption{10D Chain Egress\\label{fig:scenarios:chainegress}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.25\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/evaluations/37D_overhand.png}\n    \\caption{37D ShadowHand Ball\\label{fig:scenarios:overhand}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.25\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/evaluations/37D_underhand.png}\n    \\caption{37D ShadowHand Metal\\label{fig:scenarios:underhand}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/evaluations/37D_singlefinger.png}\n    \\caption{37D ShadowHand Mug\\label{fig:scenarios:mug}} \n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.24\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/evaluations/37D_doublefinger.png}\n    \\caption{37D ShadowHand Scissor\\label{fig:scenarios:scissor}} \n    \\end{subfigure}\n\\caption{Scenarios for evaluations. The task is to move the robot from the start state (green) to the goal state (red). Top Row (left to right): Bugtrap (6-dof), Double L Shape (6-dof) (goal configuration not shown) and Chain Egress (10-dof). Bottom Row: Overhand, Underhand, Single-Finger and Double-Finger Pregrasp (each 37-dof) (start configurations not shown).\\label{fig:scenarios}}\n\\end{figure*} \\begin{figure}[ht]\n    \\centering\n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/37D_level3.png}\n    \\caption{Shadow Hand Level 3 $\\R^{37}$.\\label{fig:simplifications:hand3}}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/37D_level2.png}\n    \\caption{Shadow Hand Level 2 $\\R^{18}$.\\label{fig:simplifications:hand2}}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/37D_level1.png}\n    \\caption{Shadow Hand Level 1 $\\R^{13}$.\\label{fig:simplifications:hand1}}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/06D_Bugtrap_level2.png}\n    \\caption{Bugtrap Level 2 $SE(3)$.\\label{fig:simplifications:bugtrap2}}\n    \\end{subfigure}    \n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/06D_DL_level2.png}\n    \\caption{Double Lshape Level 2 $SE(3)$.\\label{fig:simplifications:dls2}}\n    \\end{subfigure}    \n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/10D_level2.png}\n    \\caption{Articulated Chain Level 2 $SE(3) \\times \\R^6$.\\label{fig:simplifications:chain2}}\n    \\end{subfigure}    \n%%%%%\n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/06D_Bugtrap_level1.png}\n    \\caption{Bugtrap Level 1 $\\R^3$.\\label{fig:simplifications:bugtrap1}}\n    \\end{subfigure}       \n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/06D_DL_level1.png}\n    \\caption{Double Lshape Level 1 $\\R^3$.\\label{fig:simplifications:dls1}}\n    \\end{subfigure}    \n    \\begin{subfigure}[t]{0.32\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/multilevel/10D_level1.png}\n    \\caption{Articulated Chain Level 1 $\\R^3$.\\label{fig:simplifications:chain1}}\n    \\end{subfigure}\n\\caption{Multilevel abstraction using simplified models.\\label{fig:simplifications}}\n\\end{figure} \\colorlet{Mycolor1}{gray!80}\n\\newcommand{\\markedcell}[1]{\\textit{\\textcolor{Mycolor1}{#1}}}\n\\newcommand{\\thispaper}{{(\\textbf{ours})}}\n\\begin{table}[!t]\n\\centering\n\\renewcommand{\\cellrotangle}{90}\n\\renewcommand\\theadfont{\\bfseries}\n\\settowidth{\\rotheadsize}{\\theadfont 37D ShadowHand Scissor}\n\\newcolumntype{Y}{>{\\raggedleft\\arraybackslash}X}\n\\footnotesize\\centering\n\\renewcommand{\\arraystretch}{1.2}\n\\setlength\\tabcolsep{3pt}\n\\begin{tabulary}{\\linewidth}{@{}LLCCCCCCC@{}}\n\\toprule\n\\multicolumn{2}{>{\\centering}p{2.6cm}}{Runtime in seconds (10 run average)} & \\rothead{06D Bugtrap} & \\rothead{06D Double Lshape} & \\rothead{10D Chain Egress} & \\rothead{37D ShadowHand Ball} & \\rothead{37D ShadowHand Metal} & \\rothead{37D ShadowHand Mug} & \\rothead{37D ShadowHand Scissor} \\\\ \n\\midrule\n1 & \\mbox{QRRT \\thispaper} &  4.45  &  1.86  &  \\textbf{0.55}  &  2.01  &  35.63  &  19.80  &  60.00  \\\\\n2 & \\mbox{QRRT* \\thispaper} &  24.87  &  2.00  &  0.56  &  25.35  &  43.95  &  60.00  &  60.00  \\\\ \n3 & \\mbox{QMP \\thispaper} &  \\textbf{0.51}  &  \\textbf{1.27}  &  1.91  &  0.86  &  18.98  &  \\textbf{1.20}  &  \\textbf{14.52}  \\\\ \n4 & \\mbox{QMP* \\thispaper} &  0.90  &  1.63  &  7.29  &  \\textbf{0.86}  &  \\textbf{1.94}  &  1.63  &  37.27  \\\\ \n\\midrule\n5 & \\mbox{RRT} &  60.00  &  60.00  &  49.77  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n  6 & \\mbox{RRTConnect} &  60.00  &  60.00  &  60.00  &  \\markedcell{1.70}  &\n  \\markedcell{8.16}  &  57.38  &  60.00  \\\\ \n7 & \\mbox{RRT\\#} &  60.00  &  60.00  &  45.43  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n8 & \\mbox{RRT*} &  60.00  &  60.00  &  51.74  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n9 & \\mbox{RRTXstatic} &  60.00  &  60.00  &  50.49  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n10 & \\mbox{LazyRRT} &  60.00  &  60.00  &  55.56  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n  11 & \\mbox{TRRT} &  60.00  &  60.00  &  \\markedcell{0.81}  &  42.08  &  60.00  &  60.00  &  60.00  \\\\ \n  12 & \\mbox{BiTRRT} &  11.54  &  54.30  &  \\markedcell{4.57}  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n13 & \\mbox{LBTRRT} &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n  14 & \\mbox{RLRT} &  60.00  &  60.00  &  51.39  &  \\markedcell{3.68}  &  28.47  &  60.00  &  60.00  \\\\ \n  15 & \\mbox{BiRLRT} &  60.00  &  57.40  &  60.00  &  \\markedcell{1.52}  &  25.60  &  60.00  &  60.00  \\\\ \n16 & \\mbox{pRRT} &  60.00  &  60.00  &  49.41  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n17 & \\mbox{FMT} &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n18 & \\mbox{BFMT} &  60.00  &  50.34  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n19 & \\mbox{PRM} &  60.00  &  56.47  &  60.00  &  37.25  &  52.72  &  60.00  &  60.00  \\\\ \n20 & \\mbox{PRM*} &  60.00  &  57.80  &  60.00  &  34.24  &  50.04  &  60.00  &  60.00  \\\\ \n21 & \\mbox{LazyPRM} &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n22 & \\mbox{LazyPRM*} &  60.00  &  60.00  &  60.00  &  54.06  &  60.00  &  60.00  &  60.00  \\\\ \n23 & \\mbox{SPARS} &  60.00  &  59.73  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n24 & \\mbox{SPARStwo} &  60.00  &  54.69  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n25 & \\mbox{SST} &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n26 & \\mbox{EST} &  60.00  &  60.00  &  50.46  &  24.96  &  45.64  &  60.00  &  60.00  \\\\ \n27 & \\mbox{BiEST} &  60.00  &  60.00  &  59.85  &  29.79  &  33.36  &  60.00  &  60.00  \\\\ \n28 & \\mbox{InformedRRT*} &  60.00  &  60.00  &  -  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n29 & \\mbox{SORRT*} &  60.00  &  60.00  &  -  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n30 & \\mbox{kBIT*} &  60.00  &  60.00  &  -  &  34.17  &  46.44  &  60.00  &  60.00  \\\\ \n31 & \\mbox{kABIT*} &  60.00  &  60.00  &  -  &  50.28  &  44.56  &  60.00  &  60.00  \\\\ \n32 & \\mbox{AIT*} &  60.00  &  60.00  &  -  &  55.35  &  60.00  &  60.00  &  60.00  \\\\ \n33 & \\mbox{STRIDE} &  60.00  &  60.00  &  -  &  29.58  &  48.98  &  60.00  &  60.00  \\\\ \n34 & \\mbox{ProjEST} &  60.00  &  60.00  &  -  &  47.77  &  60.00  &  60.00  &  60.00  \\\\ \n  35 & \\mbox{PDST} &  60.00  &  60.00  &  -  &  \\markedcell{3.25}  &  54.42  &  60.00  &  60.00  \\\\ \n  36 & \\mbox{KPIECE1} &  60.00  &  60.00  &  -  &  \\markedcell{6.27}  &  32.48  &  60.00  &  60.00  \\\\ \n37 & \\mbox{BKPIECE1} &  60.00  &  60.00  &  -  &  52.35  &  60.00  &  60.00  &  60.00  \\\\ \n38 & \\mbox{LBKPIECE1} &  60.00  &  49.79  &  -  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n39 & \\mbox{SBL} &  60.00  &  50.30  &  -  &  60.00  &  60.00  &  60.00  &  60.00  \\\\ \n40 & \\mbox{CForest} &  60.00  &  60.00  &  -  &  60.00  &  60.00  &  60.00  &  60.00  \\\\\n\\bottomrule\n\\end{tabulary}\n\\caption{Runtime (s) of motion planner on the scenarios from Fig. \\ref{fig:scenarios}, each         averaged\n  over $10$ runs with cut-off time limit of $60$s. An entry $-$ means that\n  planner does not support the particular state space.\\label{table:eval1}}\n\\end{table}\n\n\\begin{table}[!t]\n\\centering\n\\renewcommand{\\cellrotangle}{90}\n\\renewcommand\\theadfont{\\bfseries}\n\\settowidth{\\rotheadsize}{\\theadfont 37D ShadowHand Scissor}\n\\newcolumntype{Y}{>{\\raggedleft\\arraybackslash}X}\n\\footnotesize\\centering\n\\renewcommand{\\arraystretch}{1.2}\n\\setlength\\tabcolsep{3pt}\n\\begin{tabulary}{\\linewidth}{@{}LLCCCCCCC@{}}\n\\toprule\n\\multicolumn{2}{>{\\centering}p{2.8cm}}{Runtime in seconds (10 run average)} & \\rothead{06D Bugtrap} & \\rothead{06D Double Lshape} & \\rothead{10D Chain Egress} & \\rothead{37D ShadowHand Ball} & \\rothead{37D ShadowHand Metal} & \\rothead{37D ShadowHand Mug} & \\rothead{37D ShadowHand Scissor} \\\\ \n\\midrule\n1 & \\mbox{QMP \\thispaper} &  \\textbf{0.51}  &  \\textbf{1.27}  &  \\textbf{1.91}  &  \\textbf{0.86}  &  \\textbf{18.98}  &  \\textbf{1.20}  &  \\textbf{14.52}  \\\\ \n2 & \\mbox{QMP (SideStepping)} &  60.00  &  26.08  &  60.00  &  1.07  &  55.37  &  6\\footnotemark  &  60.00  \\\\ \n\\midrule\n3 & \\mbox{QMP* \\thispaper} &  \\textbf{0.90}  &  \\textbf{1.63}  &  \\textbf{7.29}  &  \\textbf{0.86}  &  \\textbf{1.94}  &  \\textbf{1.63}  &  \\textbf{37.27}  \\\\ \n4 & \\mbox{QMP* (SideStepping)} &  60.00  &  30.11  &  60.00  &  1.76  &  60.00  &  12\\footnotemark[\\value{footnote}]  &  60.00  \\\\ \n\\midrule\n5 & \\mbox{QRRT \\thispaper} &  \\textbf{4.45}  &  \\textbf{1.86}  &  \\textbf{0.55}  &  \\textbf{2.01}  &  \\textbf{35.63}  &  \\textbf{19.80}  &  60.00  \\\\ \n6 & \\mbox{QRRT (SideStepping)} &  60.00  &  27.72  &  9.14  &  18.65  &  60.00  &  44\\footnotemark[\\value{footnote}]  &  60.00  \\\\ \n\\midrule\n7 & \\mbox{QRRT* \\thispaper} &  \\textbf{24.87}  &  \\textbf{2.00}  &  \\textbf{0.56}  &  \\textbf{25.35}  &  \\textbf{43.95}  &  60.00  &  60.00  \\\\ \n8 & \\mbox{QRRT* (SideStepping)} &  60.00  &  60.00  &  16.42  &  42.33  &  54.05  &  \\textbf{48}\\footnotemark[\\value{footnote}]  &  60.00  \\\\ \n\\bottomrule\n\\end{tabulary}\n\\caption{Comparison of multilevel planners with sidestepping \\cite{Orthey2020IJRR} versus multilevel planner with our pattern dance algorithm.\\label{table:eval2}}\n\\end{table}\n\n\\footnotetext{Taken from \\cite{Orthey2020IJRR}.}\n \nTo evaluate our pattern dance algorithm, we\nintegrate it as an elementary check into the multilevel planner QRRT, QRRT*, QMP and QMP*. We then conduct two comparisons. First, we compare our planner to $36$\navailable planning algorithms in the Open motion planning library (OMPL)\n\\cite{Moll2015} on $7$ challenging environments as shown in Fig.~\\ref{fig:scenarios}. For each algorithm, we will use the abbreviated name. For a full list of algorithms with full names and associated publication, see \\cite{Orthey2020IJRR} and the OMPL documentation \\cite{Sucan2012}. Second, we compare the multilevel planner with the pattern dance algorithm to an older version of the same multilevel planner, where we use a recursive\nsidestepping algorithm to quickly find sections \\cite{Orthey2020IJRR}. \n\n\\subsection{Evaluation Metric}\n\nTo evaluate, we use a 8GB RAM 4-core 2.5GHz laptop running Ubuntu 16.04. For each\nexperiment, we use a minimum length cost (for planner which support cost functions) and we let each planner run $10$ times with a\ncut-off time limit of $60$ seconds. We then report on the average runtime over\nthose $10$ runs. We show the results in Table \\ref{table:eval1}. \n\nConcerning the results, there are two notes of caution. First, we let each OMPL planner run out-of-the-box without any parameter tuning. Further tuning of parameters could potentially improve results significantly. Second, due to the high number of planner and scenarios, we let each planner run only $10$ times and take the average. However, averaging over $10$ runs might exhibit more variance and thereby create more outlier.\n\n\\subsection{06-dof Bugtrap}\n\nFor the first evaluation, we use the Bugtrap scenario \\cite{Lee2012} (Fig.~\\ref{fig:scenarios:bugtrap}). The lowest runtime we found in the literature is $22.17$s for a version of the Selective-Retraction-RRT \\cite{Lee2012, Zhang2008}. However, this runtime is not directly comparable due to different hardware, implementation, parameters and operating systems. To relax the problem, we use an inscribed sphere at the center of the cylindrical bug as shown in Fig.~\\ref{fig:simplifications:bugtrap1} and Fig.~\\ref{fig:simplifications:bugtrap2}. \n\nWe show the results of our evaluation in Fig.~\\ref{table:eval1}. The best performing planner is QMP (3th planner in table) with $0.51$s followed by QMP* (4) with $0.90$s and QRRT (1) with $4.45$s. We also see good performance of the BiTRRT (13) planner \\cite{Jaillet2010} with $11.54$s. We note that the QRRT* (2) algorithm requires $24.87$s, which we believe to be caused by the additional burden of rewiring the tree \\cite{Salzman2016, Orthey2020IJRR}.\n\n\\subsection{06-dof Double L shape}\n\nIn the next evaluation, we like to show that the section patterns are not specific to the cylindrical geometry, but are more widely applicable to other rigid bodies. As demonstration, we use the double L-shape scenario \\cite{VanDenBerg2005}, where two L-shape bodies are connected to each other as shown in Fig.~\\ref{fig:scenarios:doubleLshape}. The task is to move through a vertical wall with a small quadratic hole. We use a two-level relaxation by using an inscribed sphere as shown in Fig.~\\ref{fig:simplifications:dls1} and Fig.~\\ref{fig:simplifications:dls2}. To make our method more robust against base paths too close to obstacles, we increase the size of the sphere slightly to increase clearance from obstacles. \n\nOur evaluation shows that QMP performs best with $1.27$s followed by QMP* ($1.63$s), QRRT ($1.86$s) and QRRT* ($2.00$s). The next best planner from OMPL is LBKPIECE1 (38) with $49.79$s. \n\n\\subsection{10-dof Chain Egress}\n\nIn the third evaluation, we like to increase the complexity by considering an articulated chain ($10$-dof) as shown in Fig.~\\ref{fig:scenarios:chainegress}. The task is to remove the chain from a pipe, a typical egress scenario. Note that for such systems, we can find analytical feasible path sections if we assume the base path of the head to be curvature constrained \\cite{Orthey2018RAS}. \nHowever, we will not make such assumption in this paper. \n\nTo relax the problem, we use an inscribed sphere in the head of the chain as shown in Fig.~\\ref{fig:simplifications:chain1} and Fig.~\\ref{fig:simplifications:chain2}. As in the case of the double L-shape, we slightly increase the size of the sphere to make our method more robust against base paths too close to obstacles. \n\nIn our evaluations, we show that QRRT performs best with $0.55$s followed by QRRT* ($0.56$s). The next best planners are TRRT (11) ($0.81$s), QMP ($1.91$), BiTRRT (12) ($4.57$s) and QMP* with $7.29$s. Note that there are $12$ OMPL planner which cannot address this problem, because they do not support compound state spaces or do not have dedicated projection functions for such spaces.\n\n\\subsection{37-dof Pre-Grasp}\n\nFor the next evaluations, we compute (pre-)grasping paths for a ShadowHand mounted on a KUKA LWR robot. The tasks are to compute an overhand grasp on a ball (Fig.~\\ref{fig:scenarios:overhand}), an underhand grasp on a metal piece \n(Fig.~\\ref{fig:scenarios:underhand}), a single-finger precision grasp on a mug (Fig.~\\ref{fig:scenarios:mug}) and a double-finger precision grasp on a scissor (Fig.~\\ref{fig:scenarios:scissor}). The starting state for all scenarios is an upright position of the arm with hand being open, as shown in Fig.~\\ref{fig:simplifications:hand3}. To relax the problem, we use a three-level abstraction by first removing three fingers (Fig.~\\ref{fig:simplifications:hand2}) and subsequently removing the thumb (Fig.~\\ref{fig:simplifications:hand1}) of the hand. \n\nOur evaluations show the following results. First, for the Ball scenario, we see that QMP and QMP* perform best with $0.86$s. The next best planner is the OMPL planner BiRLRT (15) \\cite{Luna2020} with $1.52$s, QRRT with $2.01$s and RRTConnect (6) with $1.70$s. We note that also the planner PDST (35) \\cite{Ladd2004}, RLRT (14) \\cite{Luna2020} and KPIECE1 (36) \\cite{Sucan2011} perform competively with $3.25$s, $3.68$s and $6.27$s, respectively. The planner QRRT* does not perform well on this problem instance with $25.35$s, due to similar problems as on the Bugtrap scenario. Second, for the underhand grasp on the metal piece, we see that QMP* performs best with $1.94$s followed by RRTConnect (6) with $8.16$s and QMP with $18.98$s. We will address the discrepancy between QMP and QMP* further in Sec.~\\ref{sec:limitations}. Third, for the single-finger precision grasp on the mug, we observe that QMP performs best with $1.20$s followed by QMP* with $1.63$s. While QRRT performs significantly worse ($19.80$s), QRRT* was not able to solve this problem ($60.00$s). Fourth, for the double-finger precision grasp on the scissor, we observe that QMP performs best with $14.52$s followed by QMP* with $37.27$s. No other planner is able to solve this problem. We will further discuss the high runtime of both QMP and QMP* in detail in Sec.~\\ref{sec:limitations}. \\section{Limitations and Discussion\\label{sec:limitations}}\n\nWhile our evaluations support the usage of section patterns for narrow passage planning problems, we also like to point out two limitations of our approach. To each limitation, we will discuss possible ways to eventually address and resolve the limitation. \n\n\\begin{figure}[ht]\n    \\centering\n    \\begin{subfigure}[t]{0.46\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/limitations/multimodal1.png}\n    \\end{subfigure}\n    \\begin{subfigure}[t]{0.46\\linewidth}\n    \\centering\n    \\includegraphics[width=\\linewidth]{images/limitations/multimodal2.png}\n    \\end{subfigure}\n\\caption{Limitations of Section Pattern Approach. Base path does not admit a feasible path section. See text for clarification. \\label{fig:limitations}}\n\\end{figure}\n\n\n\n\\begin{table}[!t]\n\\centering\n\\renewcommand{\\cellrotangle}{90}\n\\renewcommand\\theadfont{\\bfseries}\n\\newcolumntype{Y}{>{\\raggedleft\\arraybackslash}X}\n\\footnotesize\\centering\n\\renewcommand{\\arraystretch}{1.2}\n\\setlength\\tabcolsep{3pt}\n\\begin{tabulary}{\\linewidth}{@{}LCCCCCCCCCC@{}}\n\\toprule\n Run & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\\\ \n\\midrule\n\\multicolumn{11}{c}{37D ShadowHand Metal Scenario}\\\\ \n\\midrule\n QMP & 1.53 & 1.11 & 1.20 & 0.99 & 1.06 & 60.00 & 60.00 & 2.93 & 1.02 & 60.00 \\\\ \n QMP* & 0.98 & 1.15 & 0.93 & 1.23 & 2.73 & 1.13 & 1.03 & 7.61 & 0.98 & 1.65\\\\\n\\midrule\n \\multicolumn{11}{c}{37D ShadowHand Scissor Scenario}\\\\\n\\midrule\n QMP & 1.45 & 1.50 & 2.14 & 2.17 & 60.00 & 60.00 & 2.44 & 7.49 & 1.51 & 6.51 \\\\ \n QMP* & 60.00 & 60.00 & 2.22 & 60.00 & 6.27 & 60.00 & 60.00 & 60.00 & 1.92 & 2.30 \\\\ \n\\bottomrule\n\\end{tabulary}\n\\caption{Runtime (s) for QMP and QMP* on each run. Average runtimes are $18.98$s/$1.94$s (QMP/QMP*) for the Metal scenarios and $14.52$s/$37.27$s for the Scissor scenario.\\label{table:limitations}}\n\\end{table}\n\n \n\\subsection{Increased runtime on Metal and Scissor Scenario}\n\nThe first limitation is the increased runtime of our planner on the 37D ShadowHand Scissor and the Metal scenario. We distinguish between two subproblems. First, we observe that QRRT and QRRT* have a runtime of $60$s on the Scissor scenario. Both scenarios, however, are ingress scenarios, where the planner needs to find a narrow passage on the base space to enter the goal region, which is challenging for RRT-like algorithms \\cite{Kuffner2000} and could be addressed using a bidirectional version of QRRT.\n\nSecond, we observe that QMP and QMP* require $14.52$s and $37.27$s to solve the Scissor scenario and that QMP requires $18.98$s to solve the Metal scenario. To explain this rather large increase in runtime, we have a closer look at the individual runtimes, which we show in Table~\\ref{table:limitations}. We can observe that both planner exhibit one of two outputs. Either, they quickly return a solution (usually less than $3$s, always less than $10$s) or they fail and time out at $60$s (three/two times for QMP, zero/six times for QMP*). To us, this indicates that both algorithms might be sensitive to the base space path. If the base path is not smooth enough, has kinks in it, or is too close to obstacles, then we might not be able to solve it with the pattern dance algorithm. We could address this problem in the future by either additional smoothing of the base space path \\cite{Vidal2019}, by introducing conservative heuristics \\cite{Chatterjee2019} or by switching to a different relaxed model \\cite{Styler2017}.\n\n\\subsection{Base path does not admit a feasible section}\n\nWhile all multilevel planner are probabilistically complete, we often need the pattern dance algorithm to efficiently solve a problem. However, we might encounter scenarios, where the base path does not admit a feasible path section. Such a situation is shown in Fig.~\\ref{fig:limitations}. The scenario depicts an X-shape robot, which has to traverse a shape-sorter box with different openings, which we relax by inscribing a sphere (right). Planning for the spherical robot might produce a base path going through the wrong hole. Such a base path does not admit a feasible path section, meaning there are no paths along the path restriction of the base path to traverse towards the goal. While multilevel planner are probabilistically complete and would eventually resolve the situation, we would not be able to do it efficiently using our pattern dance algorithm. To address such situations, we could either compute several base paths \\cite{Orthey2020WAFR, Ha2019, Vonasek2019, Osa2020, bhattacharya_2018, pokorny_2016_ijrr} or we could automatically choose an alternative relaxation using either a meta-heuristic \\cite{Brandao2020} or a brute-force search \\cite{Orthey2019}. \\section{Conclusion}\n\nWe developed the pattern dance algorithm, which takes as input a base space path\nand efficiently exploits its path restriction using the section\npatterns Manhattan, wriggle, tunnel and triple step. We showed in evaluations,\nthat our pattern dance algorithm successfully coordinates section patterns and outperforms a similar sidestepping algorithm \\cite{Orthey2020IJRR}. We then showed that multilevel motion planning algorithms using our pattern dance algorithm outperform classical planner from the OMPL library on challenging narrow passage\nscenarios including the Bugtrap, chain egress and precision grasping. With some\nexceptions, we often observed runtime improvement by one to two order of\nmagnitudes.\n\nWhile we demonstrated to efficiently solve narrow passage problems, we also\npointed out two limitations. First, we observe an increased runtime in some planning instances. We could address this problem by either further deforming the base path \\cite{Zhang2009}, by improved neighborhood modeling \\cite{lacevic_2020} or by learning of the section patterns themselves \\cite{Ichter2018}. Second, we cannot find handle cases where the base path does not admit path sections. We could address this problem by\ncomputing multiple base paths \\cite{Orthey2020WAFR, Osa2020, Vonasek2019} or using more informed graph restriction sampling methods \\cite{Orthey2019}.\n\nDespite limitations, we believe to have contributed a novel solution method\nwhich we can use to efficiently find sections over base path restrictions. We believe our method to be a promising tool to further probe, understand and efficiently exploit high-dimensional state spaces. \n\\bibliographystyle{IEEEtranSN}\n\n{\\footnotesize\n\\bibliography{IEEEabrv, bib/general, bib/discretesearch}\n}\n\n% biography section\n% \n% If you have an EPS/PDF photo (graphicx package needed) extra braces are\n% needed around the contents of the optional argument to biography to prevent\n% the LaTeX parser from getting confused when it sees the complicated\n% \\includegraphics command within an optional argument. (You could create\n% your own custom macro containing the \\includegraphics command to make things\n% simpler here.)\n%\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}\n% or if you just want to reserve a space for a photo:\n\n%\\begin{IEEEbiography}{Michael Shell}\n%Biography text here.\n%\\end{IEEEbiography}\n\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:00:26", "yymm": "2010", "arxiv_id": "2010.14524", "url": "https://arxiv.org/abs/2010.14524", "source": "arxiv"}}
{"text": "\\documentclass[10pt,reqno]{amsart}\n\\usepackage{amsmath,amssymb,latexsym,esint,cite,mathrsfs,dsfont}\n\\usepackage{verbatim,cite,relsize,color,soul}\n\\usepackage[latin1]{inputenc}\n\\usepackage{microtype}\n\\usepackage{color,enumitem,graphicx}\n\\usepackage[colorlinks=true,urlcolor=blue, citecolor=red,linkcolor=blue,\nlinktocpage,pdfpagelabels, bookmarksnumbered,bookmarksopen]{hyperref}\n\\usepackage[hyperpageref]{backref}\n\\usepackage[english]{babel}\n\\usepackage{tikz}\n\\usepackage[font=small,skip=5pt]{caption}\n\\setlength{\\belowcaptionskip}{-10pt}\n\\usepackage{enumitem}\n%\\usepackage[notref,notcite]{showkeys}\n\n\\usepackage{amsrefs}\n\\renewcommand{\\eprint}[1]{\\href{#1}{#1}} %link for papers\n\n\\usepackage{geometry}\n\\geometry{\n\ta4paper,\n\ttotal={160mm,247mm},\n\tleft=30mm, right=30mm,\n\ttop=30mm, bottom=30mm,\n\theightrounded,\n}\n\n\\numberwithin{equation}{section}\n\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{open}[theorem]{Open Problem}\n\\newtheorem{claim}[theorem]{Claim}\n%\\newtheorem*{theorem*}[theorem]{Conjecture}\n\\newtheorem*{theorem*}{Conjecture}\n\n\n\\newtheoremstyle{remarkstyle}\n{}{}{}{ }{\\bfseries}{.}{ }{\\thmname{#1}\\thmnumber{ #2}\\thmnote{ (#3)}}\n\\theoremstyle{remarkstyle}\n\\newtheorem{remark}{Remark}[section]\n\\newtheorem{definition}{Definition}[section]\n\n\\newcommand{\\N}{\\mathbb N}\n\\newcommand{\\Z}{\\mathbb Z}\n\\newcommand{\\Q}{\\mathbb Q}\n\\newcommand{\\R}{\\mathbb R}\n\\newcommand{\\C}{\\mathbb C}\n\\newcommand{\\Ac}{\\mathcal A}\n\\newcommand{\\Bc}{\\mathcal B}\n\\newcommand{\\Rc}{\\mathcal R}\n\\newcommand{\\Fc}{\\mathcal F}\n\\newcommand{\\Sc}{\\mathcal S}\n\\newcommand{\\Gc}{\\mathcal G}\n\\newcommand{\\Vc}{\\mathcal V}\n\\newcommand{\\Cc}{\\mathcal C}\n\\newcommand{\\Oc}{\\mathcal O}\n\\newcommand{\\Sb}{\\mathbb S}\n\\newcommand{\\Hc}{\\mathds H}\n\\newcommand{\\Sh}{\\mathscr{S}}\n\\newcommand{\\Lc}{\\mathcal L}\n\\newcommand{\\Mcal}{\\mathcal M}\n\\newcommand{\\vareps}{\\varepsilon}\n\\DeclareMathOperator*{\\loc}{loc}\n\\DeclareMathOperator*{\\rad}{rad}\n\\DeclareMathOperator*{\\opt}{opt}\n\\DeclareMathOperator*{\\GN}{GN}\n\\DeclareMathOperator*{\\Sob}{Sob}\n\\DeclareMathOperator*{\\dip}{dip}\n\\DeclareMathOperator*{\\SE}{SE}\n\\DeclareMathOperator*{\\dist}{dist}\n\\DeclareMathOperator*{\\supp}{supp}\n\\DeclareMathOperator*{\\sr}{sr}\n\\DeclareMathOperator*{\\ur}{ur}\n\\DeclareMathOperator*{\\rea}{Re}\n\\DeclareMathOperator*{\\ima}{Im}\n\\DeclareMathOperator*{\\gamc}{{\\gamma_c}}\n\\DeclareMathOperator*{\\sigc}{{\\sigma_c}}\n\\DeclareMathOperator*{\\csb}{{c}}\n\\DeclareMathOperator*{\\cb}{{\\boldsymbol{c}}}\n\\DeclareMathOperator*{\\nls}{{DNLS}}\n\\newcommand{\\scal}[1]{\\left\\langle #1 \\right\\rangle}\n\\newcommand{\\wihat}[1]{\\widehat{#1}}\n\n\n\n%Title----------------------------\n\\title[Blow-up for System NLS]\n{Blow-up results for systems of nonlinear Schr\\\"odinger equations with quadratic interaction}\n\n%Author-----------------------------\n\\author[V. D. Dinh]{Van Duong Dinh}\n\\address[V. D. Dinh]{Laboratoire Paul Painlev\\'e UMR 8524, Universit\\'e de Lille CNRS, 59655 Villeneuve d'Ascq Cedex, France\nand \nDepartment of Mathematics, HCMC University of Pedagogy, 280 An Duong Vuong, Ho Chi Minh, Vietnam}\n\\email{contact@duongdinh.com}\n\n\\author[L. Forcella]{Luigi Forcella}\n\\address[L. Forcella]{Department of Mathematics, Heriot-Watt University and The Maxwell Institute for the Mathematical Sciences, Edinburgh, EH14 4AS, United Kingdom}\n\\email{l.forcella@hw.ac.uk}\n\n\\subjclass[2010]{35B44; 35Q55}\n\\keywords{Nonlinear Schr\\\"odinger systems, Quadratic-type interactions, Blow-up, Grow-up}\n\n\\thanks{This work was supported in part by the Labex CEMPI (ANR-11-LABX-0007-01).}\n\n\\begin{document}\n\t\n\t\\begin{abstract}\n\t\tWe establish blow-up results for systems of NLS equations with quadratic interaction in anisotropic spaces. We precisely show finite time blow-up or grow-up for cylindrical symmetric solutions. With our construction, we moreover prove some polynomial lower bounds on the kinetic energy of global solutions in the mass-critical case, which in turn implies grow-up along any diverging time sequence. Our analysis extends to general NLS systems with quadratic interactions, and it also provides improvements of known results in the radial case. \n\t\\end{abstract}\n\t\n\t\\maketitle\n\t\n\t\\section{Introduction}\n\t\\label{S1}\n\t\\setcounter{equation}{0}\n\t\nIn this paper, we investigate  the existence of blowing-up solutions for the Cauchy problem for the following system of nonlinear Schr\\\"odinger equations with quadratic interaction\n\t\\begin{align} \\label{QNLS}\n\t\\left\\{\n\t\\renewcommand*{\\arraystretch}{1.2}\n\t\\begin{array}{rcl}\n\ti\\partial_t u + \\frac{1}{2m}\\Delta u &=& \\lambda v \\overline{u}, \\\\\n\ti \\partial_t v + \\frac{1}{2M} \\Delta v &=& \\mu u^2, \n\t\\end{array}\n\t\\right.\t\n\t\\end{align}\n\twhere the wave functions $u,v: \\R \\times \\R^d \\rightarrow \\C$ are complex scalar functions, the parameters $m, M$ are two real positive quantities, and $\\lambda, \\mu \\in \\C$ are two complex coupling constants.  \n\nMulti-components systems of non-linear Schr\\\"odinger equations with quadratic-type interactions appear in the processes of waves propagation in quadratic media. They model, for example, the Raman amplification phenomena in a plasma, or they are used to describe other phenomena in nonlinear optics. We refer the readers to \\cite{CCO, CdMS, Kiv, KS} for more insights on these kind of physical models.\n\nIn the case of the so-called mass-resonance condition, namely provided that the condition\n \t\\begin{align} \\label{mass-reso}\n\tM=2m\n\t\\end{align} \nis satisfied, the system \\eqref{QNLS} can be viewed, see \\cite{HOT}, as a non-relativistic limit of the following system of nonlinear Klein-Gordon equations\n\t\\[\n\t\\left\\{\n\t\\renewcommand*{\\arraystretch}{1.2}\n\t\\begin{array}{rcl}\n\t\\frac{1}{2c^2 m} \\partial^2_t u -\\frac{1}{2m} \\Delta u + \\frac{mc^2}{2} u &=& -\\lambda v \\overline{u}, \\\\\n\t\\frac{1}{2c^2 M} \\partial^2_t v -\\frac{1}{2M} \\Delta v +\\frac{Mc^2}{2} v &=& - \\mu u^2, \\\\\n\t\\end{array}\n\t\\right.\t\n\t\\]\nas the speed of light $c$ tends to infinity. \\\\\n\n\tTo the best of our knowledge, the first mathematical study of the system \\eqref{QNLS} is due to Hayashi, Ozawa, and Tanaka \\cite{HOT}, where, among other things, they established the local well-posedness of the system \\eqref{QNLS}, and they proved that, in order to ensure the conservation law of the total charge, namely the sum (up to some constant) of the $L^2$ norm of $u$ and $v,$ it is natural to consider the condition \n\t\\begin{align} \\label{cond-lambda-mu}\n\t\\exists\\, c \\in \\R \\backslash \\{0\\} \\ \\hbox{ such that } \\ \\lambda = c \\overline{\\mu}.\n\t\\end{align}\n\t\n\\noindent\tMoreover, if we assume that $\\lambda, \\mu$ satisfy \\eqref{cond-lambda-mu} for some $c>0$ and $\\lambda, \\mu \\ne 0,$ by the change of variable\n\t\\[\n\t\\tilde{u}(t,x) = \\sqrt{\\frac{c}{2}} |\\mu| u \\left(t, \\sqrt{\\frac{1}{2m}} x\\right), \\quad \\tilde{v}(t,x) = -\\frac{\\lambda}{2} v \\left(t,\\sqrt{\\frac{1}{2m}} x\\right), \n\t\\]\n\tthe system \\eqref{QNLS} can be written (by dropping the tildes) as\n\t \\begin{align} \\label{SNLS}\n\t \\left\\{\n\t \\begin{array}{rcl}\n\t i\\partial_t u + \\Delta u &=& - 2 v \\overline{u}, \\\\\n\t i \\partial_t v + \\kappa \\Delta v &=& - u^2,\n\t \\end{array}\n\t \\right.\t\n\t \\end{align}\n\t where $\\kappa =\\frac{m}{M}$ is the mass ratio. Note that $\\kappa=\\frac{1}{2}$ in the mass-resonance case \\eqref{mass-reso}. The system \\eqref{SNLS} satisfies the conservation of mass and energy defined respectively by\n\t \\begin{align*} \n\t  M(u(t),v(t)) &= \\|u(t)\\|^2_{L^2} + 2 \\|v(t)\\|^2_{L^2}, \\\\\n\t E(u(t),v(t)) &= \\frac{1}{2} \\|\\nabla u(t)\\|^2_{L^2} + \\kappa \\|\\nabla v(t)\\|^2_{L^2} -  \\rea \\int v(t) \\overline{u}^2(t) dx.\n\t \\end{align*}\n\tFor the purpose of our paper, we define the \\emph{kinetic} energy \n\t \\begin{equation}\\label{defi-K}\n\t T(f,g) := \\|\\nabla f\\|^2_{L^2} + \\kappa \\|\\nabla g\\|^2_{L^2},\n\t \\end{equation}\n\t and the \\emph{potential} energy by\n\t \\begin{equation}\\label{defi-N}\n\t P(f,g) := \\rea \\int g \\overline{f}^2 dx,\n\t \\end{equation}\nhence we rewrite the total energy as\n\\[\nE(u(t),v(t))= \\frac12 T(u(t),v(t))- P(u(t),v(t)).\n\\] \n\n\\noindent We also introduce the following functional defined in terms of $T$ and $P:$\n\\begin{align} \\label{defi-G}\n\tG(f,g):= T(f,g) - \\frac{d}{2} P(f,g).\n\t\\end{align}\nEven if the we will use $G$ evaluated at time-dependent solutions, it is worth mentioning that $G$ is the Pohozaev functional which is strictly related to the time-independent elliptic equations \\eqref{ground-1} and \\eqref{ground-2} below.\n\nAnother crucial property of \\eqref{SNLS} is that \\eqref{SNLS} is invariant under the scaling\n\t \t\\begin{align} \\label{scaling}\n\t \tu_\\lambda(t,x):= \\lambda^2 u(\\lambda^2 t, \\lambda x), \\quad v_\\lambda(t,x):= \\lambda^2 v(\\lambda^2 t, \\lambda x), \\quad \\lambda>0.\n\t \t\\end{align}\nA direct computation gives\n\t \t\\begin{align*}\n\t \t\\|u_\\lambda(0)\\|_{\\dot{H}^\\gamma} = \\lambda^{\\gamma-\\frac{d}{2} +2} \\|u_0\\|_{\\dot{H}^\\gamma}, \\quad \\|v_\\lambda(0)\\|_{\\dot{H}^\\gamma} = \\lambda^{\\gamma-\\frac{d}{2} +2} \\|v_0\\|_{\\dot{H}^\\gamma}.\n\t \t\\end{align*}\n\t \tThis shows that \\eqref{scaling} leaves the $\\dot{H}^{\\gamc}$-norm of initial data invariant, where\n\t \t\\[\n\t \t\\gamc:= \\frac{d}{2}-2.\n\t \t\\]\n\t \tAccording to the conservation laws of mass and energy, \\eqref{SNLS} is called mass-critical, mass and energy intercritical (or intercritical for short), and energy-critical if $d=4$, $d=5$, and $d=6$, respectively.\\\\\n\nIn the present paper, we restrict our attention to the dimensions $d=4,5,6,$ and we are interested in showing the formation of singularities in finite or infinite time for solutions to the initial value problem associated to \\eqref{SNLS}, for initial data \n\\[\n\\left.(u,v)\\right|_{t=0}=(u_0,v_0)\\in H^1(\\R^d)\\times H^1(\\R^d).\n\\] \nAs well-known, the existence of blowing-up solutions to the Schr\\\"odinger-type equations is closely related to the notion of standing wave or static (in the energy-critical case) solutions. Therefore, before stating our main results, we recall some basic facts about the existence of ground states for \\eqref{SNLS}.\\\\\n\nFirst of all, we recall that by standing waves solutions we mean solutions to \\eqref{SNLS} of the form \n\\[\n\t(u(t,x),v(t,x)) = (e^{it} \\phi(x), e^{2it} \\psi(x)),\n\t\\]\n\twhere $\\phi, \\psi$ are real-valued functions satisfying\n\t\\begin{align} \\label{ground-1}\n\t\\left\\{\n\t\\begin{array}{ccl}\n\t- \\Delta \\phi + \\phi &=&  2 \\phi \\psi, \\\\\n\t- \\kappa \\Delta \\psi + 2\\psi&=& \\phi^2.\n\t\\end{array}\n\t\\right.\t\n\t\\end{align}\n\nIn \\cite{HOT}, Hayashi, Ozawa, and Tanaka showed the existence of ground states related to \\eqref{ground-1}, i.e. non-trivial solutions to \\eqref{ground-1} that minimizes the action functional\n\t\\[\n\tS(f,g):= E(f,g) +\\frac{1}{2} M(f,g)\n\t\\]\n\tover all non-trivial solutions to \\eqref{ground-1}. It is worth mentioning that this existence result holds whenever $d\\leq5,$ and not only for $d=4,5.$ When $d=6$, i.e. the energy-critical case, \\eqref{SNLS} admits a static solution of the form\n\t\\[\n\t(u(t,x),v(t,x)) = (\\phi(x), \\psi(x)),\n\t\\]\n\twhere $\\phi,\\psi$ are real-valued functions satisfying\n\t\\begin{align} \\label{ground-2}\n\t\\left\\{\n\t\\begin{array}{ccl}\n\t- \\Delta \\phi  &=&  2 \\phi \\psi, \\\\\n\t- \\kappa \\Delta \\psi &=& \\phi^2.\n\t\\end{array}\n\t\\right.\t\n\t\\end{align}\n\tThe existence of ground states related to \\eqref{ground-2} was shown in \\cite{HOT} (see also \\cite[Section 3]{NP-blow}). Here by a ground state related to \\eqref{ground-2}, we mean a non-trivial solution to \\eqref{ground-2} that minimizes the energy functional over all non-trivial solutions of \\eqref{ground-2}. \n\n\n\t\\section{Main results}\\label{S-Main} \n\t \\label{S2}\n\t \\setcounter{equation}{0}\n\t After we have introduced the notion of ground state, we are ready to state our first result  about the blow-up of solutions in the mass and energy intercritical case in anisotropic spaces. To this aim, we introduce some notation. Denote\n\t \\begin{align} \\label{Sigma-d}\n\t \t\t\\Sigma_d:= \\left\\{ f \\in H^1 (\\R^d) \\ : f(y,x_d) = f(|y|,x_d), ~ x_d f \\in L^2(\\R^d)\\right\\},\n\t \t\t\\end{align}\nwhere $x=(y,x_d), y=(x_1, \\dots, x_{d-1}) \\in \\R^{d-1}$, and $x_d \\in \\R$. Here $\\Sigma_d$ stands for the space of cylindrical symmetric functions with finite variance in the last direction. We also introduce the following blow-up conditions:\n\\begin{align} \\label{cond-blow}\\tag{BC$_{5d}$}\n\tE(u_0,v_0) M(u_0,v_0) < E(\\phi,\\psi) M(\\phi,\\psi) \\quad \\& \\quad T(u_0,v_0) M(u_0,v_0) > T(\\phi,\\psi) M(\\phi,\\psi).\n\t\\end{align}\nAs for the usual Schr\\\"odinger equation, the conditions expressed in \\eqref{cond-blow} are the counterpart of  the conditions\n\\begin{align} \\label{cond-gwp}\\tag{SC$_{5d}$}\n\tE(u_0,v_0) M(u_0,v_0) < E(\\phi,\\psi) M(\\phi,\\psi) \\quad \\& \\quad T(u_0,v_0) M(u_0,v_0) < T(\\phi,\\psi) M(\\phi,\\psi),\n\t\\end{align} \nin the dichotomy leading to global well-posedness \\& scattering (\\eqref{cond-gwp}) or blow-up (\\eqref{cond-blow}). In the energy critical case, the previous conditions in \\eqref{cond-blow} will be replaced by analogous inequalities, see \\eqref{cond-blow-6d} below. Since in this paper we are concerned only with the blow-up dynamics of solutions to \\eqref{SNLS}, we will not use the modified conditions for the scattering theory.\n\\begin{remark}\nWe incorporate, in the statements of our main theorems below, also some known results in the radial setting. The scope is twofold: we highlight the main differences with respect to the existing literature on blowing/growing-up solutions to \\eqref{SNLS} in the radial setting, and we give a complete picture of the formation of singularity results for the model \\eqref{SNLS}. \n\\end{remark}\n\n%In what follows, $T^*>0$ stands for the maximal (forward in time) time of existence of the solution, and blow-up in finite time classically means  that $T^*<\\infty.$ {\\color{red}SHOULD WE SAY ANYTHING ABOUT NEGATIVE TIMES?}\n\n\\subsection{Intercritical case} \nOur first result concerns a finite time blow-up for \\eqref{SNLS} in the intercritical case $d=5$.\n\t \\begin{theorem} \\label{theo-blow-5d}\n\t \tLet $d=5$, $\\kappa >0$, and $(\\phi,\\psi)$ be a ground state related to \\eqref{ground-1}. Let $(u_0,v_0) \\in H^1 \\times H^1$ satisfy either $E(u_0,v_0)<0$ or if $E(u_0,v_0)\\geq 0$, we assume that \\eqref{cond-blow} holds. Assume in addition that one of the following conditions holds:\n\t\\begin{itemize}[leftmargin=6mm]\n\t \t\t\\item[(a)] $(u_0,v_0)$ is radially symmetric;\n\t \t\t\\item[(b)] $(u_0,v_0) \\in \\Sigma_5 \\times \\Sigma_5.$\n\t\\end{itemize}\n\t \tThen the corresponding solution to \\eqref{SNLS} blows-up in finite time.\n\t \\end{theorem}\n\t \nOur main achievement in Theorem \\ref{theo-blow-5d} is the second point on cylindrical symmetric solutions. The blow-up result for non-negative energy radial data is due to Inui, Kishimoto, and Nishimura, who recently proved in \\cite{IKN-NA} that, under the condition \\emph{(a)}, the conclusion of the Theorem holds true, provided that \n\\begin{equation} \\label{cond-IKN-5d}\nE(u_0,v_0) M(u_0,v_0)< E(\\phi,\\psi) M(\\phi,\\psi) \\quad\\& \\quad G(u_0,v_0) <0.\n\\end{equation}\nBy a variational characterization, we show in Lemma \\ref{lem-equi-5d} that \\eqref{cond-blow} and \\eqref{cond-IKN-5d} are indeed equivalent. Therefore, our result is new for data in $\\Sigma_5\\times \\Sigma_5$ and is interchangeable with the one in \\cite{IKN-NA} in the radial setting.\nThe blow-up result for negative energy radial data was shown by Yoshida \\cite{Yoshida}.\n\nDespite our approach relies on the classical virial identities, we need to precisely construct suitable cylindrical cut-off functions enabling us to get  enough decay (by means of some Sobolev embedding for partially radial functions) to close our estimates. With respect to the classical NLS equation, we will use an ODE argument instead of a concavity argument to prove our results, by only using the first derivative in time of suitable localized quantity, see Section \\ref{S3}. We refer the reader to the early work of Martel \\cite{Mar} in the context of the NLS equation in anisotropic spaces, and the more recent papers \\cite{BF20, Inui1, Inui2}. \\\\\n\nFor sake of completeness, we report now  known blow-up  and long time dynamics  results for  \\eqref{SNLS} in the intercritical case.\\\\\n\nIf $\\kappa =\\frac{1}{2}$, Hayashi, Ozawa, and Tanaka in \\cite{HOT} showed a blow-up result with negative energy and finite variance data, i.e. initial data belonging to $\\Sigma\\times\\Sigma:=(H^1\\times H^1)\\cap (L^2(|x|^2\\, dx) \\times (L^2(|x|^2\\, dx))$. Hamano, see \\cite{Hamano}, proved the scattering below the mass energy ground state. More precisely, he proved that if $(u_0, v_0) \\in H^1 \\times H^1$ satisfies \\eqref{cond-gwp}  then the corresponding solution to \\eqref{SNLS} exists globally in time and scatters in $H^1\\times H^1$ in both directions, i.e. there exist $(u_\\pm, v_\\pm) \\in H^1\\times H^1$ such that\n\\[\n\\|(u(t),v(t)) - (e^{it\\Delta} u_\\pm, e^{i\\kappa t\\Delta} v_\\pm)\\|_{H^1\\times H^1} \\rightarrow 0\n\\]\nas $t\\rightarrow \\pm \\infty$. Here $e^{itc\\Delta}$ denotes the classical Schr\\\"odinger free propagator. In addition, if $(u_0,v_0) \\in H^1 \\times H^1$ satisfies \\eqref{cond-blow}, then the corresponding solution to \\eqref{SNLS} either blows-up in finite time or there exists $|t_n|\\rightarrow \\infty$ such that $\\|(u(t_n),v(t_n))\\|_{H^1\\times H^1} \\rightarrow \\infty$ as $n\\rightarrow \\infty$. Furthermore, if $(u_0,v_0) \\in \\Sigma \\times \\Sigma$ or $(u_0,v_0)$ is radial, then the solution blows-up in finite time. The first author, see \\cite{Dinh-insta}, established the strong instability by blow-up for ground state standing waves of \\eqref{SNLS}.\n\t \nIf $\\kappa \\ne \\frac{1}{2}$, Hamano, Inui, and Nishimura \\cite{HIN} established the scattering for radial data below the mass-energy threshold. The proof is based on the concentration/compactness and rigidity scheme in the spirit of Kenig and Merle \\cite{KM}. Wang and Yang \\cite{WY}  extended the result of \\cite{HIN} to the non-radial case provided that $\\kappa$ belongs to a small neighbourhood  of $\\frac{1}{2}$. Their proof made use of a recent method of Dodson and Murphy \\cite{DM-MRL} using the interaction Morawetz inequality. Noguera and Pastor \\cite{NP-DPDE} proved that if $(u_0, v_0) \\in H^1 \\times H^1$ satisfies \\eqref{cond-gwp}, then the corresponding solution to \\eqref{SNLS} exists globally in time. \n\t \n\\begin{remark}\nFrom a pure mathematical perspective, distinguishing  the cases $\\kappa=\\frac12$ and $0<\\kappa\\neq\\frac12$ plays a role in the virial identities related to \\eqref{SNLS}. Under the mass-resonance condition, namely $\\kappa=\\frac12,$ some terms in the virial identities disappear, and the study of the dynamics of solutions is easier due to these cancellations. This is no more the case in the non-mass-resonance setting, i.e. when $\\kappa\\neq\\frac12.$  We refer the reader to \\cite[Introduction]{NP-blow} for an exhaustive list of references in which the effects of the mass and non-mass resonance conditions on the dynamics of solutions to systems similar to \\eqref{SNLS} were studied.\n\\end{remark}\n\n%{\\color{red} \n%\\begin{remark}\n%Due to the lack of cancellation properties in the virial identities in the non-mass-resonance case, we point out that we do not have an analogous result as in \\cite{HOT} for solutions in $\\Sigma\\times\\Sigma$ when  $\\kappa\\neq\\frac12$. \n% AS USUAL, I'D AVOID THIS KIND OF SENTENCES, TO REDUCE BAD COMMENTS IN THE REFEREE REPORTS\n%  \\end{remark} \n%}\n\t \n\\subsection{Energy-critical case}\nOur next Theorem deals with a blow-up result in the energy-critical case $d=6.$\n\t \n\t \\begin{theorem} \\label{theo-blow-6d}\n\t \tLet $d=6$, $\\kappa >0$, and $(\\phi,\\psi)$ be a ground state related to \\eqref{ground-2}. Let $(u_0,v_0) \\in H^1 \\times H^1$ satisfy either $E(u_0,v_0)<0$ or if $E(u_0,v_0)\\geq 0$, we assume that\n\t \t\\begin{align}\\tag{BC$_{6d}$}\\label{cond-blow-6d}\n\t \tE(u_0,v_0) < E(\\phi,\\psi), \\quad T(u_0,v_0)> T(\\phi,\\psi).\n\t \t\\end{align} \n\t \tAssume in addition that one of the following conditions holds:\n\t \t\\begin{itemize}[leftmargin=6mm]\n\t \t\t\\item[(1)] $(u_0,v_0)$ is radially symmetric;\n\t \t\t\\item[(2)] $(u_0,v_0) \\in \\Sigma_6 \\times \\Sigma_6$.\n\t \t\\end{itemize}\n\t \tThen the corresponding solution to \\eqref{SNLS} blows-up in finite time.\n\t \\end{theorem}\nAs in the intercritical case, our main contribution is in the anisotropic framework. \nIndeed, the finite time blow-up with negative energy radial data was established in \\cite{Yoshida}, while for non-negative energy radial data, the blow-up result was shown in \\cite{IKN-NA} for data satisfying\n\t \t\t\\begin{align} \\label{cond-IKN-6d}\n\t \t\tE(u_0,v_0) < E(\\phi,\\psi), \\quad G(u_0,v_0) <0.\n\t \t\t\\end{align} \nSince we will prove in Lemma \\ref{lem-equi-6d} that \\eqref{cond-blow-6d} is equivalent to \\eqref{cond-IKN-6d}, our result is indistinguishable from the one in \\cite{IKN-NA}.\n\n\\begin{remark}\nIf $\\kappa =\\frac{1}{2}$,  the blow-up result with negative energy and finite variance data was shown in Hayashi, Ozawa, and Tanaka, see \\cite{HOT}. \n\\end{remark}\n\t \t\n\\subsection{Mass-critical case}\n\nIn the mass-critical case, we have the following blow-up or grow-up results for \\eqref{SNLS}.\n\t \n\t \\begin{theorem} \\label{theo-blow-grow-4d}\n\t \tLet $d=4$ and $0<\\kappa \\ne \\frac{1}{2}$. Let $(u_0,v_0) \\in H^1 \\times H^1$ be radially symmetric satisfying $E(u_0,v_0)<0$. Then the corresponding solution to \\eqref{SNLS} either blows-up forward in finite time, i.e. $T^*<\\infty$, or it blows-up in infinite time in the sense that $T^*=\\infty$ and \n\t \t\\begin{equation}\\label{grow-4d}\n\t \tT(u(t),v(t)) \\geq C t^2\n\t \t\\end{equation}\n\t \tfor all $t\\geq t_0$, where $C>0$ and $t_0 \\gg 1$ depend only on $\\kappa, M(u_0,v_0)$, and $E(u_0,v_0)$. A similar statement holds for negative times.\n\t \\end{theorem}\nUnder the assumption of Theorem \\ref{theo-blow-grow-4d}, the blow-up or grow-up result along one time sequence was proved in \\cite[Theorem 1.2]{IKN-NA}. More precisely, if $T^*=\\infty$, then there exists a time sequence $t_n\\rightarrow \\infty$ such that $\\|(u(t_n),v(t_n))\\|_{H^1\\times H^1}\\rightarrow \\infty$ as $n\\rightarrow \\infty$. \n\nBy performing a more careful analysis, our argument yields to a stronger result with respect to the one in \\cite{IKN-NA}. Indeed, we are able to show a growth rate for the kinetic energy of the form \\eqref{grow-4d} which in turn implies the grow-up result along an arbitrary diverging sequence of times.\nWe would like to mention that this grow-up result along any diverging time sequence, is also an interesting open problem related to the usual mass-supercritical focusing cubic 3D NLS, see the weak conjecture of Holmer and Roudenko in \\cite{HR-CPDE}.\n\t \n\\begin{remark} In the case $\\kappa=\\frac{1}{2}$ and for radial data with negative energy, the finite time blow-up was shown by the first author in \\cite{Dinh-NA}. For the long time dynamics in the mass-critical case we refer to \\cite{IKN-mass}.\n\\end{remark}\n\t \nWe  give now the following blow-up or grow-up result for anisotropic solutions to \\eqref{SNLS}.\n\t \n\\begin{theorem} \\label{theo-blow-grow-Sigma-4d}\n\t \tLet $d=4$ and $0<\\kappa \\ne \\frac{1}{2}$. Let $(u_0,v_0) \\in \\Sigma_4 \\times \\Sigma_4$ satisfy $E(u_0,v_0)<0$. Then the corresponding solution to \\eqref{SNLS} either blows-up forward in finite time, i.e. $T^*<\\infty$, or $T^*=\\infty$ and there exists a time sequence $t_n\\rightarrow \\infty$ such that $\\|(u(t_n),v(t_n))\\|_{H^1 \\times H^1} \\rightarrow \\infty$ as $n\\rightarrow \\infty$. If we assume $\\kappa =\\frac{1}{2}$, then either $T^*<\\infty$ or $T^*=\\infty$ and there exists a time sequence $t_n\\rightarrow \\infty$ such that $\\|\\partial_4u(t_n)\\|_{L^2} \\rightarrow \\infty$ as $n\\rightarrow \\infty$. A similar statement holds for negative times.\n\\end{theorem}\n\n\\subsection{Extensions to a general system of NLS with quadratic interactions}\nWe conclude this section by listing some extensions of the previous Theorems for general NLS systems with quadratic interactions.\n\nIn dimension $d=5$ and $d=6,$ namely in the mass-supercritical and the energy-critical case, respectively, the results above can be extended -- provided that some structural hypothesis are satisfied -- to the following initial value problem for general system of NLS with quadratic interactions:\n\\begin{align} \\label{GQNLS}\n\t\\left\\{\n\t\\renewcommand*{\\arraystretch}{1.2}\n\t\\begin{array}{rcl}\n\tia_j\\partial_t u_j+ b_j\\Delta u_j -c_ju_j &=&-f_j(u_1,\\dots, u_N), \\quad j\\in\\{1,\\dots, N\\},\\\\\n\t\\left.(u_1,\\dots, u_N)\\right|_{t=0} &=& (u_{0,1},\\dots,u_{0,N}) \\in H^1(\\R^d) \\times \\dots \\times H^1(\\R^d), \n\t\\end{array}\n\t\\right.\t\n\t\\end{align}\nwhere $u_j:\\R^d\\to\\C$, the parameters $a_j,b_j,c_j$ are real coefficients satisfying $a_j>0, b_j>0$ and $c_j\\geq0$, and the functions $f_j$ grow quadratically for all $j =1,\\dots, N$. More precisely, under the assumptions (H1)--(H8) in \\cite{NP-blow}, Theorems \\ref{theo-blow-5d} and \\ref{theo-blow-6d} can be stated for \\eqref{GQNLS} as well, with the necessary modifications. In particular, the set of conditions (H1)--(H8) in \\cite{NP-blow} (see also \\cite{NP-CCM}) ensure that \\eqref{GQNLS} is local well-posed, there exist ground states (along with stability and instability properties), and the mass and the energy are conserved. Here the mass is defined by\n\\[\n\\mathcal M(\\vec u(t)):=\\sum_{j=1}^{N}\\frac{a_j s_j}{2}\\|u_j(t)\\|_{L^2}^2,\n\\]\nwhere the real parameters $s_j>0$ satisfy \n\\[\n\\ima \\sum_{j=1}^{N}s_jf_j(\\boldsymbol{z})\\bar z_j=0, \\quad \\forall \\boldsymbol{z}=(z_1,\\dots, z_N)\\in\\C^N,\n\\] \nand $\\vec u$ is  the compact notation for $(u_1,\\dots, u_N)$. The energy is instead defined by \n\\[\n\\mathcal E(\\vec u(t)):= \\frac{1}{2}\\sum_{j=1}^{N} b_j\\|\\nabla u_j(t)\\|_{L^2}^2 +\\frac{1}{2}\\sum_{j=1}^{N}c_j \\|u_j(t)\\|_{L^2}^2- \\rea \\int F(\\vec u(t)) dx,\n\\]\nwhere $F:\\C^N\\to\\C$ is such that $f_j=\\partial_{\\bar z_j}F+\\overline{\\partial_{z_j}F}$ for any $j\\in\\{1,\\dots, N\\}.$\\\\\n\nIn $d=5$, we denote by $\\vec\\phi=(\\phi_1,\\dots, \\phi_N)$ the ground state related to the system of elliptic equations\n\\begin{align} \\label{ell-equ-vec}\n-b_j\\Delta \\phi_j+\\left(\\frac{a_js_j}{2}\\omega+c_j \\right)\\phi_j=f_j(\\vec \\phi), \\quad j\\in\\{1,\\dots, N\\},\\quad \\omega\\in\\R,\n\\end{align}\ni.e. $\\vec{\\phi}$ is a non-trivial real-valued solution of \\eqref{ell-equ-vec} that minimizes the action functional\n\\[\n\\mathcal{S}(\\vec{\\phi}) = \\frac{1}{2} \\mathcal{T}(\\vec{\\phi}) + \\mathcal{Q}(\\vec{\\phi}) - \\mathcal{P}(\\vec{\\phi})\n\\]\nover all non-trivial real-valued solutions to \\eqref{ell-equ-vec}, where\n\\[\n\\mathcal T(\\vec g):=\\sum_{j=1}^Nb_j\\|\\nabla g_j\\|_{L^2}^2, \\quad \\mathcal Q(\\vec g):=\\sum_{j=1}^N\\left(\\frac{a_js_j}{2}\\omega+c_j\\right)\\|g_j\\|_{L^2}^2, \\quad \\mathcal P (\\vec g) := \\rea \\int F(\\vec g) dx.\n\\]\nUnder the assumptions (H1)--(H8) in \\cite{NP-blow} , ground states related to \\eqref{ell-equ-vec} do exist if \n\\begin{align} \\label{cond-c}\n\\frac{a_js_j}{2}\\omega+c_j >0, \\quad \\forall j \\in \\{1, \\dots, N\\}. \n\\end{align}\nIf we denote by $\\mathbb G(\\omega, \\cb)$ the set of ground states related to \\eqref{ell-equ-vec}, where $\\cb=(c_1, \\dots, c_N)$, then $\\mathbb G(\\omega, \\cb) \\ne \\emptyset$ provided that \\eqref{cond-c} is satisfied. In particular, $\\mathbb G (1,\\boldsymbol{0}) \\ne \\emptyset$. Moreover, the following Gagliardo-Nirenberg inequality\n\\begin{align} \\label{GN-ineq-vec}\nP(\\vec g) \\leq C_{\\opt} \\left[ \\mathcal Q(\\vec g) \\right]^{\\frac{6-d}{4}} \\left[ \\mathcal T (\\vec g) \\right]^{\\frac{d}{4}}\n\\end{align}\nis achieved by a ground state $\\vec \\phi \\in \\mathbb G (\\omega, \\cb)$. We refer the reader to \\cite[Section 4]{NP-CCM} for more details on ground states related to \\eqref{ell-equ-vec}.\n\n\\noindent By adapting the arguments presented in this paper, we can prove the result in Theorem \\ref{theo-blow-5d} provided that we replace \\eqref{cond-blow} with \n\\begin{equation}\\tag{BC$^\\prime_{5d}$}\n\\mathcal M(\\vec u_0) \\mathcal E(\\vec u_0)<\\mathcal M(\\vec \\phi)\\mathcal E_0(\\vec \\phi) \\quad \\& \\quad \\mathcal M(\\vec u_0)\\mathcal T(\\vec u_0)>\\mathcal M(\\vec \\phi)\\mathcal T(\\vec \\phi),\n\\end{equation}\nwhere $\\vec \\phi \\in \\mathbb G(1,\\boldsymbol{0})$ and \n\\[\n\\mathcal E_0(\\vec g):= \\frac{1}{2} \\mathcal T(\\vec g)- \\mathcal P(\\vec g).\n\\]\n\\\\\n\nSimilarly, in $d=6,$ we can prove the result in Theorem \\ref{theo-blow-6d} provided that we replace \\eqref{cond-blow-6d} with \n\\begin{equation}\\tag{BC$^\\prime_{6d}$}\n\\mathcal E(\\vec u_0)<\\mathcal E_0(\\vec\\varphi) \\quad \\& \\quad \\mathcal T(\\vec u_0)>\\mathcal T(\\vec \\varphi),\n\\end{equation}\nwhere $\\vec\\varphi=(\\varphi_1,\\dots, \\varphi_N)$ is the ground state related to\n\\begin{align} \\label{ell-equ-vec-6d}\n-b_j\\Delta \\varphi_j=f_j(\\vec\\varphi), \\quad j\\in\\{1,\\dots, N\\}.\n\\end{align}\nHere $\\vec \\varphi$ is a ground state related to \\eqref{ell-equ-vec-6d} if it is a non-trivial real valued solution to \\eqref{ell-equ-vec-6d} that minimizes the functional $\\mathcal E_0$ over all non-trivial real-valued solutions of \\eqref{ell-equ-vec-6d}. Note that blow-up results similar to Theorems \\ref{theo-blow-5d} and \\ref{theo-blow-6d} for radial solutions to \\eqref{GQNLS} were established in \\cite{NP-blow}. Thus our extensions are for anisotropic solutions. % \\eqref{GQNLS}.\n\n\\noindent As pointed-out in \\cite{NP-blow}, the non-mass-resonance condition $0<\\kappa\\neq\\frac12$ for \\eqref{SNLS} in Theorems \\ref{theo-blow-5d} and  \\ref{theo-blow-6d}, corresponds  to the following analog mass-resonance condition for \\eqref{GQNLS} \n\\begin{align} \\label{cond-non-mass-reso-GQNLS}\n\\ima  \\sum_{j=1}^N\\frac{a_j}{2b_j}f_j(\\boldsymbol{z})\\bar z_j  \\ne 0, \\quad \\forall \\boldsymbol{z}=(z_1,\\dots,z_N)\\in\\C^N.\n\\end{align}\n\nIn the mass-critical case $d=4$, we have the following blow-up results for \\eqref{GQNLS}. \n\n\\begin{theorem} \\label{theo-blow-grow-4d-GQNLS}\n\tLet $d=4$ and assume that \\eqref{cond-non-mass-reso-GQNLS} holds. Let $\\vec u_0=(u_{0,1}, \\dots, u_{0,N}) \\in H^1 \\times \\dots \\times H^1$ be radially symmetric satisfying $\\mathcal E(\\vec u_0) <0$. Then the corresponding solution to \\eqref{GQNLS} either blows-up forward in finite time, i.e. $T^*<\\infty$, or it blows-up in infinite time in the sense that $T^*=\\infty$ and\n\t\\[\n\t\\mathcal T (\\vec u(t)) \\geq Ct^2\n\t\\]\n\tfor all $t\\geq t_0$, where $C>0$ and $t_0\\gg 1$ depend only on $M(\\vec u_0)$, and $\\mathcal E(\\vec u_0)$. Moreover, if we assume\n\t\\begin{align} \\label{cond-mass-reso-GQNLS}\n\t\\ima  \\sum_{j=1}^N\\frac{a_j}{2b_j}f_j(\\boldsymbol{z})\\bar z_j  = 0, \\quad \\forall \\boldsymbol{z}=(z_1,\\dots,z_N)\\in\\C^N\n\t\\end{align} \n\tinstead of \\eqref{cond-non-mass-reso-GQNLS}, then the corresponding solution to \\eqref{GQNLS} blows-up in finite time.\n\\end{theorem}\nThe proof of this result follows from a similar argument as that for Theorem \\ref{theo-blow-grow-4d} using a refined localized virial estimates (see Lemma \\ref{lem-viri-est-rad-4d-GQNLS}). Our result is new even under the mass-resonance condition \\eqref{cond-mass-reso-GQNLS}. Note that the finite time blow-up for \\eqref{GQNLS} in the mass-critical case $d=4$ was proved in \\cite[Theorem 5.11]{NP-CCM} only for finite variance solutions.\n\n\\begin{theorem} \\label{theo-blow-grow-4d-Sigma-SQNLS}\n\tLet $d=4$ and assume that \\eqref{cond-non-mass-reso-GQNLS} holds. Let $\\vec u_0 = (u_{0,1}, \\dots, u_{0,N}) \\in \\Sigma_4 \\times \\dots \\times \\Sigma_4$ satisfy $\\mathcal E(\\vec u_0)<0$. Then the corresponding solution to \\eqref{GQNLS} either blows-up forward in finite time, i.e. $T^*<\\infty$, or $T^*=\\infty$ and there exists a time sequence $t_n \\rightarrow \\infty$ such that $\\|(u_1(t_n), \\dots, u_N(t_n))\\|_{H^1 \\times \\dots \\times H^1} \\rightarrow \\infty$ as $n\\rightarrow \\infty$. If we assume \\eqref{cond-mass-reso-GQNLS} instead of \\eqref{cond-non-mass-reso-GQNLS}, then either $T^* <\\infty$ or $T^*=\\infty$  and  $\\|(\\partial_4 u_1(t_n), \\dots, \\partial_4 u_N(t_n))\\|_{L^2\\times \\dots \\times L^2} \\rightarrow \\infty$ for some diverging time sequence $t_n\\rightarrow \\infty.$ \n\\end{theorem}\n\n Similarly to Theorem \\ref{theo-blow-grow-Sigma-4d}, the proof of Theorem \\ref{theo-blow-grow-4d-Sigma-SQNLS} is based on refined localized virial estimates for anisotropic solutions to \\eqref{GQNLS} (see Lemma \\ref{lem-viri-est-cyli-4d-GQNLS}). Therefore, we will omit the details of the proof.\\\\\n\nThe paper is organized as follows. In Section \\ref{S3}, we recall some useful properties of ground states related to \\eqref{ground-1} and \\eqref{ground-2}. We also prove some variational estimates associated to blow-up conditions given in Theorems \\ref{theo-blow-5d} and \\ref{theo-blow-6d}. Section \\ref{S4} is devoted to various localized virial estimates for radial and anisotropic solutions to \\eqref{SNLS}. The proofs of our main results are  given in Section \\ref{S5}. Finally, we prove in Appendix \\ref{S6} some localized virial estimates for the general system  \\eqref{GQNLS} of NLS with quadratic interactions.\n\n\n \t\\section{Variational analysis}\n \t\\label{S3}\n \t\\setcounter{equation}{0}\nIn this section, we report some useful properties of ground states related to \\eqref{ground-1} and \\eqref{ground-2}.  Then we use them to get some a-priori uniform-in-time estimates for the Pohozaev functional evaluated at the solutions to the corresponding time-dependent equations. \n\t\\subsection{Variational inequalities}\n\tWe first recall the following Gagliardo-Nirenberg type inequalities due to \\cite{HOT} (see also \\cite{NP-DPDE}): for $1\\leq d\\leq 5$,\n\t\\begin{align} \\label{GN-ineq}\n\tP(f,g) \\leq C_{\\GN} [M(f,g)]^{\\frac{6-d}{4}} [T(f,g)]^{\\frac{d}{4}}, \\quad (f,g) \\in H^1 \\times H^1.\n\t\\end{align}\n\tThe optimal constant in \\eqref{GN-ineq} is attained by any ground state $(\\phi,\\psi)$ related to \\eqref{ground-1}, i.e.\n\t\\[\n\tC_{\\GN} =\\frac{P(\\phi,\\psi)}{[M(\\phi,\\psi)]^{\\frac{6-d}{4}} [T(\\phi,\\psi)]^{\\frac{d}{4}}}.\n\t\\]\n\tThis result was first shown by Hayashi, Ozawa, and Tanaka \\cite[Theorem 5.1]{HOT} (for $d=4$), and recently by Noguera and Pastor \\cite[Corollary 2.10]{NP-DPDE} (for $1\\leq d\\leq 5$). We also have the following Pohozaev's identity:\n\t\\begin{align} \\label{poho-iden}\n\tM(\\phi,\\psi) = \\frac{6-d}{d} T(\\phi,\\psi) = \\frac{6-d}{2} P(\\phi,\\psi).\n\t\\end{align}\n\tIt follows that\n\t\\[\n\tC_{\\GN} = \\frac{2}{d [M(\\phi,\\psi)]^{\\frac{6-d}{4}} [T(\\phi,\\psi)]^{\\frac{d-4}{4}}}.\n\t\\]\n\tWhen $d=4$, we have\n\t\\begin{align} \\label{opti-cons-4d}\n\tC_{\\GN} = \\frac{1}{2} [M(\\phi,\\psi)]^{-\\frac{1}{2}}.\n\t\\end{align}\n\tAlthough the uniqueness (up to symmetries) of ground states related to \\eqref{ground-1} is not known yet, \\eqref{opti-cons-4d} shows that the mass of ground states does not depend on the choice of a ground state $(\\phi,\\psi)$. \\\\\n\t\n\tIn the case $d=5$, we have\n\t\\begin{align} \\label{opti-cons-5d}\n\tC_{\\GN} = \\frac{2}{5} [M(\\phi,\\psi) T(\\phi,\\psi)]^{-\\frac{1}{4}}\n\t\\end{align}\n\tand\n\t\\begin{align} \\label{E-M-5d}\n\tE(\\phi,\\psi) = \\frac{1}{10}  T(\\phi,\\psi) = \\frac{1}{4} P(\\phi,\\psi).\n\t\\end{align}\n\tIn particular, the quantities\n\t\\begin{align} \\label{inva-quan-5d}\n\tE(\\phi,\\psi) M(\\phi,\\psi), \\quad T(\\phi,\\psi) M(\\phi,\\psi), \\quad P(\\phi,\\psi) M(\\phi,\\psi)\n\t\\end{align}\n\tdo not depend on the choice of a ground state $(\\phi,\\psi)$.\\\\\n\t\n\tWhen $d=6$, we have the following Sobolev type inequality:\n\t\\begin{align} \\label{Sobo-ineq}\n\tP(f,g) \\leq C_{\\Sob} [T(f,g)]^{\\frac{3}{2}}, \\quad (f,g) \\in \\dot{H}^1 \\times \\dot{H}^1.\n\t\\end{align}\n\tIt was shown in \\cite[Theorem 3.3]{NP-blow} that the sharp constant in \\eqref{Sobo-ineq} is achieved by a ground state $(\\phi,\\psi)$ related to \\eqref{ground-2}, i.e.\n\t\\[\n\tC_{\\Sob} = \\frac{P(\\phi,\\psi)}{ [T(\\phi,\\psi)]^{\\frac{3}{2}}}.\n\t\\]\n\tUsing the following identity\n\t\\[\n\tT(\\phi,\\psi) = 3 P(\\phi,\\psi),\n\t\\]\n\twe see that\n\t\\begin{align} \\label{shap-cons-6d}\n\tC_{\\Sob} = \\frac{1}{3} [T(\\phi,\\psi)]^{-\\frac{1}{2}}\n\t\\end{align}\n\tand\n\t\\begin{align} \\label{E-K-6d}\n\tE(\\phi,\\psi) = \\frac{1}{6} T(\\phi,\\psi).\n\t\\end{align}\n\tThis shows in particular that $E(\\phi,\\psi)$ and $T(\\phi,\\psi)$ do not depend on the choice of a ground state $(\\phi,\\psi)$.\n\t\n\t\\subsection{Variational estimates}\n\tIn this section, we characterize the blow-up region defined in \\eqref{cond-blow} (see \\eqref{cond-blow-6d} for the energy critical case) in terms of the sign of the Pohozaev functional $G$ defined in \\eqref{defi-G}. For similar analysis in the context of the classical NLS equation, we refer to our previous works \\cite{BF19, DFH}.\n\t\n\t\\begin{lemma} \\label{lem-equi-5d}\n\tLet $d=5$, $\\kappa>0$, and $(\\phi,\\psi)$ is a ground state related \\eqref{ground-1}. Denote\n\t\\begin{align} \\label{A}\n\t\\Ac:= \\left\\{ (f,g) \\in H^1\\times H^1 \\Big|\n\t\\begin{array}{rcl}\n\tE(f,g) M(f,g) &<& E(\\phi,\\psi) M(\\phi,\\psi) \\\\\n\tT(f,g) M(f,g) &>& T(\\phi,\\psi) M(\\phi,\\psi)\n\t\\end{array}\n\t\\right\\}\n\t\\end{align}\n\tand\n\t\\begin{align} \\label{tilde-A}\n\t\\tilde{\\Ac}:= \\left\\{ \n\t(f,g) \\in H^1\\times H^1 \\Big| \n\t\\begin{array}{rcl}\n\tE(f,g) M(f,g) &<& E(\\phi,\\psi) M(\\phi,\\psi) \\\\\n\tG(f,g) &<& 0\n\t\\end{array}\n\t\\right\\}.\n\t\\end{align}\n\tThen $\\Ac \\equiv \\tilde{\\Ac}$.\t\n\t\\end{lemma}\n\t\n\t\\begin{proof}\n\t\tLet $(f,g) \\in \\Ac$. We will show that $G(f,g) <0$, hence $(f,g) \\in \\tilde{\\Ac}$. We have\n\t\t\\begin{align*}\n\t\tG(f,g) M(f,g) &= \\left(\\frac{5}{2} E(f,g) - \\frac{1}{4} T(f,g) \\right) M(f,g) \\\\\n\t\t&<\\frac{5}{2} E(\\phi,\\psi) M(\\phi,\\psi) - \\frac{1}{4} T(\\phi,\\psi) M(\\phi,\\psi),\n\t\t\\end{align*}\n\t\thence $G(f,g)<0$ by using \\eqref{E-M-5d}.\\\\\n\t\t\n\\noindent \t\tNow let $(f,g) \\in \\tilde{\\Ac}$. We will show that $T(f,g) M(f,g) > T(\\phi,\\psi) M(\\phi,\\psi)$, so $(f,g) \\in \\Ac$. Indeed, as $G(f,g) <0$, we use  \\eqref{GN-ineq} to have\n\t\t\\begin{align*}\n\t\tT(f,g) <\\frac{5}{2} P(f,g) \\leq \\frac{5}{2} C_{\\GN} [M(f,g)]^{\\frac{1}{4}} [T(f,g)]^{\\frac{5}{4}}.\n\t\t\\end{align*}\n\t\tIn particular, we have\n\t\t\\[\n\t\t\\left(T(f,g) M(f,g)\\right)^{\\frac{1}{4}} >\\frac{2}{5} C_{\\GN}^{-1} \n\t\t\\]\n\t\twhich, by \\eqref{opti-cons-5d}, implies that\n\t\t\\[\n\t\tT(f,g) M(f,g) > T(\\phi,\\psi) M(\\phi,\\psi).\n\t\t\\]\n\t\tThe proof is complete.\n\t\\end{proof}\n\t\n\t\\begin{lemma} \\label{lem-uppe-boun-5d}\n\t\tLet $d=5$, $\\kappa >0$, and $(\\phi,\\psi)$ is a ground state related to \\eqref{ground-1}. Let $(u_0,v_0) \\in H^1 \\times H^1$ satisfy either $E(u_0,v_0)<0$ or if $E(u_0,v_0)\\geq 0$, we assume that \\eqref{cond-blow} holds. Let $(u,v)$ be the corresponding solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Then there exist positive constants $\\vareps$ and $c$ such that\n\t\t\\begin{align} \\label{uppe-boun-5d}\n\t\tG(u(t),v(t)) + \\vareps T(u(t),v(t)) \\leq -c \n\t\t\\end{align}\n\t\tfor all $t\\in [0,T^*)$.\n\t\\end{lemma}\n\t%{\\color{red} $\\vareps=0 \\implies G\\leq-c$?}\n\t\\begin{proof}\n\t\tIn the case $E(u_0,v_0)<0$, the conservation of energy yields\n\t\t\\[\n\t\tG(u(t),v(t)) = \\frac{5}{2} E(u(t),v(t)) -\\frac{1}{4} T(u(t),v(t)) = \\frac{5}{2} E(u_0,v_0) - \\frac{1}{4} T(u(t),v(t)).\n\t\t\\]\n\t\tThis shows \\eqref{uppe-boun-5d} with $\\vareps = \\frac{1}{4}$ and $c= -\\frac{5}{2} E(u_0,v_0)>0$.\\\\\n\t\t\n\\noindent \tLet us now focus on the case $E(u_0,v_0)\\geq 0$ for which \\eqref{cond-blow} is assumed. By \\eqref{GN-ineq}, we have for all $t\\in [0,T^*)$,\n\t\t\\begin{equation}\\label{eq:F}\n\t\t\\begin{aligned}\n\t\tE(u(t),v(t)) M(u(t),v(t)) &= \\frac{1}{2} T(u(t),v(t)) M(u(t),v(t)) - P(u(t),v(t)) M(u(t),v(t)) \\\\\n\t\t&\\geq \\frac{1}{2} T(u(t),v(t)) M(u(t),v(t)) - C_{\\GN} \\left(T(u(t),v(t)) M(u(t),v(t)) \\right)^{\\frac{5}{4}} \\\\\n\t\t&=: F\\left( T(u(t),v(t)) M(u(t),v(t))\\right),\n\t\t\\end{aligned}\n\t\t\\end{equation}\n\t\twhere\n\t\t\\[\n\t\tF(\\lambda):= \\frac{1}{2} \\lambda - C_{\\GN} \\lambda^{\\frac{5}{4}}.\n\t\t\\]\n\t\tUsing \\eqref{opti-cons-5d} and \\eqref{E-M-5d}, we see that\n\t\t\\begin{align*}\n\t\tF\\left( T(\\phi,\\psi) M(\\phi,\\psi) \\right) &= \\frac{1}{2} T(\\phi,\\psi) M(\\phi,\\psi) - C_{\\GN} \\left(T(\\phi,\\psi) M(\\phi,\\psi) \\right)^{\\frac{5}{4}} \\\\\n\t\t&=\\frac{1}{10} T(\\phi,\\psi) M(\\phi,\\psi) = E(\\phi,\\psi) M(\\phi,\\psi).\n\t\t\\end{align*}\n\t\tThanks to the first condition in \\eqref{cond-blow} and the conservation laws of mass and energy, we can continue the estimate \\eqref{eq:F} as\n\t\t\\begin{equation*}\n\t\t\\begin{aligned}\n\t\tF\\left( T(u(t),v(t)) M(u(t),v(t))\\right)& \\leq E(u_0,v_0) M(u_0,v_0) \\\\\n\t\t&< E(\\phi,\\psi)M(\\phi,\\psi)  = F \\left( T(\\phi,\\psi) M(\\phi,\\psi) \\right), \\quad \\forall\\,t\\in [0,T^*).\n\t\t\\end{aligned}\n\t\t\\end{equation*}\n\t\tBy the continuity argument and the second condition in \\eqref{cond-blow}, we infer that \n\t\t\\begin{align} \\label{est-solu-5d}\n\t\tT(u(t),v(t)) M(u(t),v(t)) > T(\\phi,\\psi) M(\\phi,\\psi)\n\t\t\\end{align}\n\t\tfor all $t\\in [0,T^*)$. Next we use the first condition in \\eqref{cond-blow} to pick $\\rho:= \\rho(u_0,v_0, \\phi,\\psi)>0$ so that\n\t\t\\begin{align} \\label{defi-rho-5d}\n\t\tE(u_0,v_0) M(u_0,v_0) \\leq (1-\\rho) E(\\phi,\\psi) M(\\phi,\\psi).\n\t\t\\end{align}\n\t\tIt follows that\n\t\t\\[\n\t\tF\\left( T(u(t),v(t)) M(u(t),v(t)) \\right) \\leq (1-\\rho) E(\\phi,\\psi) M(\\phi, \\psi).\n\t\t\\]\n\t\tUsing the fact that\n\t\t\\[\n\t\tE(\\phi,\\psi) M(\\phi,\\psi) = \\frac{1}{10} T(\\phi,\\psi) M(\\phi,\\psi) = \\frac{1}{4}C_{\\GN} \\left( T(\\phi,\\psi) M(\\phi,\\psi)\\right)^{\\frac{5}{4}},\n\t\t\\]\n\t\twe infer that\n\t\t\\begin{align} \\label{est-rho-5d}\n\t\t5 \\frac{T(u(t), v(t)) M(u(t),v(t))}{T(\\phi,\\psi) M(\\phi,\\psi)} - 4 \\left(\\frac{T(u(t), v(t)) M(u(t),v(t))}{T(\\phi,\\psi) M(\\phi,\\psi)} \\right)^{\\frac{5}{4}} \\leq 1-\\rho\n\t\t\\end{align}\n\t\tfor all $t\\in [0,T^*)$. We consider $g(\\lambda):= 5 \\lambda -4 \\lambda^{\\frac{5}{4}}$ for $\\lambda>1$. Note that the condition $\\lambda>1$ is due to \\eqref{est-solu-5d}. We see that $g(1)=0$ and $g$ is strictly decreasing on $(1,\\infty)$. It follows from \\eqref{est-rho-5d} that there exists $\\nu:= \\nu(\\rho)>0$ such that $\\lambda>1+\\nu$. In particular, we have\n\t\t\\begin{align} \\label{refi-est-solu-5d}\n\t\tT(u(t),v(t)) M(u(t),v(t)) \\geq (1+\\nu) T(\\phi,\\psi) M(\\phi,\\psi)\n\t\t\\end{align}\n\t\tfor all $t\\in [0,T^*)$. Now let $\\vareps>0$ to be chosen later. By the conservation of mass and energy, \\eqref{E-M-5d}, \\eqref{defi-rho-5d}, and \\eqref{refi-est-solu-5d}, we have for all $t\\in [0,T^*)$,\n\t\t\\begin{align*}\n\t\t\\Big( G(u(t),v(t)) &+ \\vareps T(u(t),v(t)) \\Big) M(u(t),v(t)) \\\\\n\t\t&= \\frac{5}{2} E(u(t),v(t)) M(u(t),v(t)) - \\left(\\frac{1}{4}-\\vareps\\right) T(u(t),v(t)) M(u(t),v(t)) \\\\\n\t\t&=\\frac{5}{2} E(u_0,v_0) M(u_0,v_0) -  \\left(\\frac{1}{4}-\\vareps\\right) T(u(t),v(t)) M(u(t),v(t)) \\\\\n\t\t&\\leq \\frac{5}{2}(1-\\rho) E(\\phi,\\psi) M(\\phi,\\psi) - \\left(\\frac{1}{4}-\\vareps\\right) (1+\\nu) T(\\phi,\\psi) M(\\phi,\\psi) \\\\\n\t\t&= \\left( -\\frac{1}{4}(\\rho+\\nu) +\\vareps (1+\\nu)\\right) T(\\phi,\\psi) M(\\phi,\\psi).\n\t\t\\end{align*} \n\t\tBy taking $0<\\vareps <\\frac{\\rho+\\nu}{4(1+\\nu)}$  and using the conservation of mass, we have \\eqref{uppe-boun-5d} with \n\t\t\\[\n\t\tc= \\left(\\frac{1}{4}(\\rho+\\nu) - \\vareps(1+\\nu)\\right) T(\\phi,\\psi) \\frac{M(\\phi,\\psi)}{M(u_0,v_0)}>0.\n\t\t\\]\n\t\tThe proof is complete.\n\t\\end{proof}\n\n\t\\begin{lemma} \\label{lem-equi-6d}\n\t\tLet $d=6$, $\\kappa>0$, and $(\\phi,\\psi)$ is a ground state related \\eqref{ground-2}. Denote\n\t\t\\begin{align} \\label{B}\n\t\t\\Bc:= \\left\\{ (f,g) \\in H^1\\times H^1 \\Big| \n\t\t\\begin{array}{rcl}\n\t\tE(f,g)  &<& E(\\phi,\\psi) \\\\\n\t\tT(f,g) &>& T(\\phi,\\psi)\n\t\t\\end{array}\n\t\t\\right\\}\n\t\t\\end{align}\n\t\tand\n\t\t\\begin{align} \\label{tilde-B}\n\t\t\\tilde{\\Bc}:= \\left\\{ \n\t\t(f,g) \\in H^1\\times H^1 \\Big| \n\t\t\\begin{array}{rcl}\n\t\tE(f,g) &<& E(\\phi,\\psi) \\\\\n\t\tG(f,g) &<& 0\n\t\t\\end{array}\n\t\t\\right\\}.\n\t\t\\end{align}\n\t\tThen $\\Bc \\equiv \\tilde{\\Bc}$.\t\n\t\\end{lemma}\n\t\n\t\\begin{proof}\n\t\tLet $(f,g) \\in \\Bc$. We will show that $G(f,g) <0$. Indeed, by \\eqref{E-K-6d}, we have\n\t\t\\[\n\t\tG(f,g)= 3 E(f,g) - T(f,g) < 3E(\\phi,\\psi) - \\frac{1}{2}T(\\phi,\\psi) =0.\n\t\t\\]\n\t\t\n\t\\noindent \tLet us consider now $(f,g) \\in \\tilde{\\Bc}$. As $G(f,g) <0$, we have from \\eqref{Sobo-ineq} that\n\t\t\\[\n\t\tT(f,g) < 3 P(f,g) \\leq 3 C_{\\Sob} [T(f,g)]^{\\frac{3}{2}} \n\t\t\\]\n\t\tor equivalently $[T(f,g)]^{\\frac{1}{2}} > \\frac{1}{3} C_{\\Sob}^{-1}$. This shows that $T(f,g)> T(\\phi,\\psi)$ thanks to \\eqref{shap-cons-6d}.\n\t\\end{proof}\n\n\t\\begin{lemma} \\label{lem-uppe-boun-6d}\n\t\tLet $d=6$, $\\kappa>0$, and $(\\phi,\\psi)$ is a ground state related \\eqref{ground-2}. Let $(u_0,v_0) \\in H^1 \\times H^1$ satisfy either $E(u_0,v_0)<0$ or if $E(u_0,v_0)\\geq 0$, we assume that \\eqref{cond-blow-6d} holds. Let $(u,v)$ be the corresponding solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Then there exist positive constants $\\vareps$ and $c$ such that\n\t\t\\begin{align} \\label{uppe-boun-6d}\n\t\tG(u(t),v(t)) + \\vareps T(u(t),v(t)) \\leq -c \n\t\t\\end{align}\n\t\tfor all $t\\in [0,T^*)$.\n\t\\end{lemma}\n\t\n\t\\begin{proof}\n\t\tThe proof is similar to that of Lemma \\ref{lem-uppe-boun-5d} using \\eqref{shap-cons-6d} and \\eqref{E-K-6d}. We thus omit the details.\n\t\\end{proof}\n\n\t\\section{Localized virial estimates}\n\t\\label{S4}\n\t\\setcounter{equation}{0}\n\tIn this section we prove the preliminary and fundamental estimates we need for the proof of our main Theorems. We start with the following virial identity (see e.g. \\cite[(4.34)]{WY}).\n\t\\begin{lemma} \\label{lem-viri}\n\t\tLet $d\\geq 1$ and $\\kappa>0$. Let $\\varphi: \\R^d \\rightarrow \\R$ be a sufficiently smooth and decaying function. Let $(u,v)$ be a $H^1$-solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Define\n\t \t\\begin{align} \\label{defi-M-varphi}\n\t \tM_\\varphi(t):= 2\\ima \\int \\nabla \\varphi(x) \\cdot \\left( \\nabla u(t,x) \\overline{u}(t,x) + \\nabla v(t,x) \\overline{v}(t,x)\\right) dx.\n\t \t\\end{align}\n\t \tThen we have for all $t\\in [0,T^*)$,\n\t \t\\begin{align*}\n\t \t\\frac{d}{dt} M_\\varphi(t) &= - \\int \\Delta^2 \\varphi(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2 \\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=}}+ 4\\sum_{j,k=1}^d \\rea \\int \\partial^2_{jk} \\varphi(x) \\left( \\partial_j u(t,x) \\partial_k \\overline{u}(t,x) + \\kappa \\partial_j v(t,x) \\partial_k \\overline{v}(t,x) \\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta \\varphi(x)  v(t,x) \\overline{u}^2(t,x) dx.\n\t \t\\end{align*}\n\t \\end{lemma}\n\t \n\t \\noindent The above identity can be checked by formal computations. The rigorous proof can be done by performing a standard approximation trick (see e.g. \\cite[Section 6.5]{Cazenave}).\n\t \n\t \\begin{remark} From now on we denote $r=|x|.$ \\label{rem-viri} ~\n\t \t\\begin{itemize}[leftmargin=6mm]\n\t \t\t\\item[(1)] If $\\varphi(x) = |x|^2$, then\n\t \t\t\\[\n\t \t\t\\frac{d}{dt} M_{|x|^2}(t) = 8 G(u(t),v(t)),\n\t \t\t\\]\n\t \t\twhere $G$ is as in \\eqref{defi-G}.\n\t \t\t\\item[(2)] If $\\varphi$ is radially symmetric, then using the fact that\n\t \t\t\\[\n\t \t\t\\partial_j = \\frac{x_j}{r} \\partial_r, \\quad \\partial^2_{jk} = \\left( \\frac{\\delta_{jk}}{r} - \\frac{x_jx_k}{r^3} \\right) \\partial_r + \\frac{x_j x_k}{r^2} \\partial^2_r,\n\t \t\t\\]\n\t \t\twe have\n\t \t\t\\begin{align*}\n\t \t\t\\sum_{j,k=1}^d \\rea &\\int \\partial^2_{jk} \\varphi(x) \\partial_j u (t,x) \\partial_k \\overline{u}(t,x) dx \\\\\n\t \t\t&= \\int \\frac{\\varphi'(r)}{r} |\\nabla u(t,x)|^2 dx + \\int \\left(\\frac{\\varphi''(r)}{r^2}-\\frac{\\varphi'(r)}{r^3}\\right) |x \\cdot \\nabla u(t,x)|^2 dx, \n\t \t\t\\end{align*}\n\t \t\twhere $r=|x|$. In particular, we have\n\t \t\t\\begin{align*}\n\t \t\t\\frac{d}{dt} M_\\varphi(t) &= -\\int \\Delta^2 \\varphi(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2 \\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 4\\int \\frac{\\varphi'(r)}{r} \\left(|\\nabla u(t,x)|^2 + \\kappa |\\nabla v(t,x)|^2 \\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 4 \\int \\left(\\frac{\\varphi''(r)}{r^2} - \\frac{\\varphi'(r)}{r^3} \\right) \\left(|x\\cdot \\nabla u(t,x)|^2 + \\kappa |x\\cdot \\nabla u(t,x)|^2 \\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta \\varphi(x) v(t,x) \\overline{u}^2(t,x) dx.\n\t \t\t\\end{align*}\n\t \t\t\\item[(3)] If $\\varphi$ is radial and $(u,v)$ is also radial, then \n\t \t\t\\begin{align*}\n\t \t\t\\frac{d}{dt} M_\\varphi(t) &= -\\int \\Delta^2 \\varphi(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 4 \\int \\varphi''(r) \\left(|\\nabla u(t,x)|^2 + \\kappa |\\nabla v(t,x)|^2\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta \\varphi(x) v(t,x) \\overline{u}^2(t,x) dx.\n\t \t\t\\end{align*}\n\t \t\t\\item[(4)] Let $d\\geq 3$ and denote $x=(y,x_d)$ with $y=(x_1, \\dots, x_{d-1}) \\in \\R^{d-1}$ and $x_d \\in \\R$. Let $\\psi: \\R^{d-1} \\rightarrow \\R$ be a sufficiently smooth and decaying function. Set $\\varphi(x) = \\psi(y) + x_d^2$. We have\n\t \t\t\\begin{align*}\n\t \t\t\\frac{d}{dt}M_\\varphi(t) &= -\\int \\Delta^2_y \\psi(y) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 4\\sum_{j,k=1}^{d-1} \\rea \\int \\partial^2_{jk} \\psi(y) \\left(\\partial_j u(t,x) \\partial_k \\overline{u}(t,x) + \\kappa \\partial_j v(t,x) \\partial_k \\overline{v}(t,x)\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta_y \\psi(y) v(t,x) \\overline{u}^2(t,x)dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 8 \\left(\\|\\partial_d u(t)\\|^2_{L^2} + \\kappa \\|\\partial_d v(t)\\|^2_{L^2}\\right) - 4 P(u(t),v(t)).\n\t \t\t\\end{align*}\n\t \t\tMoreover, if $(u(t),v(t)) \\in \\Sigma_d \\times \\Sigma_d$ for all $t\\in [0,T^*)$, then we have\n\t \t\t\\begin{align*}\n\t \t\t\\frac{d}{dt} M_\\varphi(t) &= -\\int \\Delta^2_y \\psi(y) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 4\\int \\psi''(\\rho) \\left(|\\nabla_y u(t,x)|^2 + \\kappa |\\nabla_y v(t,x)|^2\\right) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta_y \\psi(y)v(t,x) \\overline{u}^2(t,x) dx \\\\\n\t \t\t&\\mathrel{\\phantom{=}} + 8 \\left(\\|\\partial_d u(t)\\|^2_{L^2} + \\kappa \\|\\partial_d v(t)\\|^2_{L^2}\\right) - 4 P(u(t),v(t)),\n\t \t\t\\end{align*}\n\t \t\twhere $\\rho = |y|$.\n\t \t\\end{itemize}\n\t \\end{remark}\n\t \n\t Let $\\chi: [0,\\infty) \\rightarrow [0,\\infty)$ be a sufficiently smooth function satisfying\n\t \\begin{align} \\label{defi-chi}\n\t \\chi(s):= \\left\\{\n\t \\begin{array}{ccl}\n\t s^2 &\\text{if}& 0\\leq s \\leq 1, \\\\\n\t \\text{const.} &\\text{if}& s\\geq 2, \n\t \\end{array}\n\t \\right.\n\t \\quad \\chi''(s) \\leq 2, \\quad \\forall s \\geq 0.\n\t \\end{align}\n\t Given $R>1$, we define, by rescaling, the radial function $\\varphi_R: \\R^d \\rightarrow \\R$ by\n\t \\begin{align} \\label{defi-varphi-R}\n\t \\varphi_R(x) = \\varphi_R(r) := R^2 \\chi(r/R).\n\t \\end{align}\n\t \n\t \\begin{lemma} [Radial localized virial estimate I] \\label{lem-loca-viri-est-rad-1}\n\t \tLet $d=5,6$, and $\\kappa >0$. Let $(u,v)$ be a radial $H^1$-solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R} and denote $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. Then we have for all $t\\in [0,T^*)$,\n\t \t\\begin{align} \\label{loca-viri-est-rad-1}\n\t \t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq 8 G(u(t),v(t))  + C R^{-\\frac{d-1}{2}} \\|\\nabla u(t)\\|^2_{L^2} + o_R(1)\n\t \t\\end{align}\n\t \tfor some constant $C>0$ depending only on $d, \\kappa$, and $M(u_0,v_0)$, where $o_R(1) \\rightarrow 0$ as $R\\rightarrow \\infty$.\n\t \\end{lemma}\n\t \n\t \\begin{proof}\n\t \tThe proof of this result is essentially given in \\cite{IKN-NA}. For the reader's convenience, we provide some details. By Item (3) of Remark \\ref{rem-viri}, we have for all $t\\in [0,T^*)$,\n\t \t\\begin{align*}\n\t \t\\frac{d}{dt} M_{\\varphi_R}(t) &= -\\int \\Delta^2 \\varphi_R(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2 \\right) dx + 4\\int \\varphi''_R(r) \\left( |\\nabla u(t,x)|^2 + \\kappa |\\nabla v(t,x)|^2 \\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=  -\\int \\Delta^2 \\varphi_R(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2 \\right) dx }} - 2\\rea \\int \\Delta \\varphi_R v(t,x) \\overline{u}^2 (t,x) dx.\n\t \t\\end{align*}\n\t \tWe rewrite\n\t \t\\begin{align*}\n\t \t\\frac{d}{dt} M_{\\varphi_R}(t) &= 8 G(u(t),v(t)) -  8 T(u(t),v(t)) +4d P(u(t),v(t)) \\\\\n\t \t&\\mathrel{\\phantom{=8 G(u(t),v(t)) }} - \\int \\Delta^2\\varphi_R(x) \\left( |u(t,x)|^2 + \\kappa |v(t,x)|^2 \\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=8 G(u(t),v(t)) }}+ 4\\int \\varphi''_R(r) \\left( |\\nabla u(t,x)|^2 + \\kappa |\\nabla v(t,x)|^2 \\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=8 G(u(t),v(t)) }} - 2\\rea \\int \\Delta \\varphi_R(x) v(t,x) \\overline{u}^2(t,x) dx \\\\\n\t \t&=8 G(u(t),v(t)) - 4 \\int (2-\\varphi''_R(r)) \\left( |\\nabla u(t,x)|^2 + \\kappa |\\nabla v(t,x)|^2\\right) dx \\\\\n\t \t&\\mathrel{\\phantom{=}} - \\int \\Delta^2 \\varphi_R(x) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2\\right) dx + 2 \\rea \\int (2d-\\Delta \\varphi_R(x)) v(t,x) \\overline{u}^2(t,x) dx.\n\t \t\\end{align*}\n\t \tAs $\\|\\Delta^2 \\varphi_R\\|_{L^\\infty} \\lesssim R^{-2}$, the conservation of mass implies that\n\t \t\\[\n\t \t\\left| \\int \\Delta^2 \\varphi_R(x) \\left(|u(t,x)|^2 +\\kappa |v(t,x)|^2\\right) dx \\right| \\lesssim R^{-2}\n\t \t\\]\n\t \twhich together with $\\varphi''_R (r) \\leq 2$ for all $r\\geq0$, $\\|\\Delta \\varphi_R\\|_{L^\\infty} \\lesssim 1$, and $\\varphi_R(x) = |x|^2$ on $|x| \\leq R$ yield\n\t \t\\[\n\t \t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq 8 G(u(t),v(t)) + CR^{-2} + C\\int_{|x|\\geq R} |v(t,x) \\overline{u}^2(t,x)| dx.\n\t \t\\]\n\t \tTo estimate the last term, we recall the following radial Sobolev embedding, see  \\cite{CO}: let $d\\geq 2$ and $f$ be a radial function, then  \n\t \t\\begin{align} \\label{rad-sobo}\n\t \t\\sup_{x \\ne 0} |x|^{\\frac{d-1}{2}} |f(x)| \\leq C(d) \\|\\nabla f\\|^{\\frac{1}{2}}_{L^2} \\|f\\|^{\\frac{1}{2}}_{L^2}.\n\t \t\\end{align}\n\t \tThanks to \\eqref{rad-sobo} and the conservation of mass, we estimate\n\t \t\\begin{align*}\n\t \t\\int_{|x|\\geq R} |v(t,x) \\overline{u}^2(t,x)| dx &\\leq \\sup_{|x|\\geq R} |u(t,x)| \\|u(t)\\|_{L^2} \\|v(t)\\|_{L^2} \\\\\n\t \t&\\lesssim R^{-\\frac{d-1}{2}} \\sup_{|x|\\geq R} |x|^{\\frac{d-1}{2}} |u(t,x)| \\\\\n\t \t&\\lesssim R^{-\\frac{d-1}{2}} \\|\\nabla u(t)\\|^{\\frac{1}{2}} \\|u(t)\\|^{\\frac{1}{2}}_{L^2} \\\\\n\t \t&\\lesssim R^{-\\frac{d-1}{2}} \\|\\nabla u(t)\\|^{\\frac{1}{2}} \\\\\n\t \t&\\lesssim R^{-\\frac{d-1}{2}} \\left( \\|\\nabla u(t)\\|^2_{L^2}+1\\right).\n\t \t\\end{align*}\n\t \tIt follows that\n\t \t\\[\n\t \t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq 8 G(u(t),v(t)) + CR^{-2} + CR^{-\\frac{d-1}{2}} + CR^{-\\frac{d-1}{2}} \\|\\nabla u(t)\\|^2_{L^2}.\n\t \t\\]\n\t \tThe proof is complete.\n\t \\end{proof}\n\t \n\t In the mass-critical case, we have the following refined localized virial estimate.\n\t \n\t \\begin{lemma} [Radial localized virial estimate II] \\label{lem-loca-viri-est-rad-2} \n\t \tLet $d=4$ and $\\kappa >0$. Let $(u,v)$ be a radial $H^1$-solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R} and denote $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. Then we have for all $t\\in [0,T^*)$,\n\t \t\\begin{align} \\label{loca-viri-est-rad-2}\n\t \t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u(t),v(t)) -4 \\int \\left(\\theta_{1,R}(r)- CR^{-\\frac{3}{2}} (\\theta_{2,R}(x))^2\\right) |\\nabla u(t,x)|^2 dx  + o_R(1)\n\t \t\\end{align}\n\t \tfor some constant $C>0$ depending only on $\\kappa$ and $M(u_0,v_0)$, where\n\t \t\\begin{align} \\label{defi-theta-12-R}\n\t \t\\theta_{1,R}(r) := 2-\\varphi''_R(r), \\quad \\theta_{2,R}(x) = 8-\\Delta \\varphi_R(x).\n\t \t\\end{align}\n\t \\end{lemma}\n \t\n \t\\begin{proof}\n \t\tWe first note that $G(u(t),v(t))=2 E(u(t),v(t))$ if $d=4$. Arguing as in the proof of Lemma \\ref{lem-loca-viri-est-rad-1}, we have\n \t\t\\begin{align*}\n \t\t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq 16E(u(t),v(t)) - 4 \\int \\theta_{1,R}(r) |\\nabla u(t,x)|^2 dx + 2 \\rea \\int \\theta_{2,R}(x) v(t,x) \\overline{u}^2(t,x) dx + CR^{-2}.\n \t\t\\end{align*}\n \t\tWe estimate\n \t\t\\begin{align*}\n \t\t\\left| \\rea \\int \\theta_{2,R}(x) v(t,x) \\overline{u}^2(t,x) dx \\right| &\\leq \\sup_{|x|\\geq R} |\\theta_{2,R}(x) u(t,x)| \\|v(t)\\|_{L^2} \\|u(t)\\|_{L^2} \\\\\n \t\t&\\lesssim R^{-\\frac{3}{2}} \\|\\nabla (\\theta_{2,R} u(t))\\|_{L^2}^{\\frac{1}{2}} \\|\\theta_{2,R} u(t)\\|^{\\frac{1}{2}}_{L^2} \\|v(t)\\|_{L^2} \\|u(t)\\|_{L^2} \\\\\n \t\t&\\lesssim R^{-\\frac{3}{2}} \\|\\nabla (\\theta_{2,R} u(t))\\|^{\\frac{1}{2}}_{L^2},\n \t\t\\end{align*}\n \t\twhere we have used the conservation of mass in the last estimate. Note that $\\theta_{2,R}(x)=0$ for $|x|\\leq R$. As $\\|\\nabla \\theta_{2,R}\\|_{L^\\infty} \\lesssim 1$, the conservation of mass implies that\n \t\t\\[\n \t\t\\|\\nabla(\\theta_{2,R} u(t))\\|_{L^2} \\lesssim \\|\\nabla \\theta_{2,R}\\|_{L^\\infty} \\|u(t)\\|_{L^2} + \\|\\theta_{2,R} \\nabla u(t)\\|_{L^2} \\lesssim \\|\\theta_{2,R} \\nabla u(t)\\|_{L^2} + 1.\n \t\t\\]\n \t\tIt follows that\n \t\t\\begin{align*}\n \t\t\\left| \\rea \\int \\theta_{2,R}(x) v(t,x) \\overline{u}^2(t,x) dx \\right| & \\lesssim R^{-\\frac{3}{2}} \\left(\\|\\theta_{2,R} \\nabla u(t)\\|_{L^2} + 1 \\right)^{\\frac{1}{2}} \\\\\n \t\t&\\lesssim R^{-\\frac{3}{2}} \\left( \\|\\theta_{2,R} \\nabla u(t)\\|^2_{L^2} +1\\right).\n \t\t\\end{align*}\n \t\tTherefore, we obtain\n \t\t\\[\n \t\t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq 16 E(u(t),v(t)) - 4 \\int \\left(\\theta_{1,R}(r) - CR^{-\\frac{3}{2}} (\\theta_{2,R}(x))^2\\right) |\\nabla u(t,x)|^2 dx + CR^{-2} +CR^{-\\frac{3}{2}}.\n \t\t\\]\n \t\tThe proof is complete.\n \t\\end{proof}\n \t\n \tNext we derive localized virial estimates for cylindrically symmetric solutions. To this end, we introduce\n \t\\begin{align} \\label{defi-psi-R}\n \t\\psi_R(y)= \\psi_R(\\rho) := R^2 \\chi(\\rho/R), \\quad \\rho =|y|\n \t\\end{align}\n \tand set\n \t\\begin{align} \\label{defi-varphi-R-psi}\n \t\\varphi_R(x):= \\psi_R(y) + x_d^2.\n \t\\end{align}\n \t\n \t\\begin{lemma}[Cylindrical localized virial estimate I] \\label{lem-loca-viri-est-cyli-1}\n \t\tLet $d=5,6$, and $\\kappa>0$. Let $(u,v)$ be a $\\Sigma_d$-solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R-psi} and denote $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. Then we have for all $t\\in [0,T^*)$,\n \t\t\\begin{align} \\label{loca-viri-est-cyli-1}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq 8 G(u(t),v(t)) + CR^{-\\frac{d-2}{2}} \\|\\nabla u(t)\\|^2_{L^2} + o_R(1)\n \t\t\\end{align}\n \t\tfor some constant $C>0$ depending only on $d,\\kappa$, and $M(u_0,v_0)$.\n \t\\end{lemma}\n \t\n \t\\begin{proof}\n \t\tBy Item (4) of Remark \\ref{rem-viri}, we have for all $t\\in [0,T^*)$,\n \t\t\\begin{align*}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) &=  -\\int \\Delta^2_y \\psi_R(y) \\left(|u(t,x)|^2 + \\kappa |v(t,x)|^2\\right) dx \\\\\n \t\t&\\mathrel{\\phantom{=}} + 4\\int \\psi''_R(\\rho) \\left(|\\nabla_y u(t,x)|^2 + \\kappa |\\nabla_y v(t,x)|^2\\right) dx \\\\\n \t\t&\\mathrel{\\phantom{=}} - 2 \\rea \\int \\Delta_y \\psi_R(y)v(t,x) \\overline{u}^2(t,x) dx \\\\\n \t\t&\\mathrel{\\phantom{=}} + 8 \\left(\\|\\partial_d u(t)\\|^2_{L^2} + \\kappa \\|\\partial_d v(t)\\|^2_{L^2}\\right) - 4 P(u(t),v(t)).\n \t\t\\end{align*}\n \t\tIt follows that\n \t\t\\begin{align*}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 8 G(u(t),v(t)) +CR^{-2} - 4 \\int (2-\\psi''_R(\\rho)) \\left( |\\nabla_y u(t,x)|^2 + \\kappa |\\nabla_y v(t,x)|^2\\right) dx \\\\\n \t\t&\\mathrel{\\phantom{\\leq 8 G(u(t),v(t)) +CR^{-2}}} +2 \\rea \\int (2(d-1)-\\Delta_y\\psi_R(y)) v(t,x) \\overline{u}^2(t,x) dx.\n \t\t\\end{align*}\n \t\tAs $\\psi''_R(\\rho) \\leq 2$ and $\\|\\Delta_y \\psi_R\\|_{L^\\infty_x} \\lesssim 1$, we have\n \t\t\\begin{align} \\label{est-cyli}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq 8 G(u(t),v(t)) + CR^{-2} + C \\int_{|y|\\geq R} |v(t,x) \\overline{u}^2(t,x)| dx.\n \t\t\\end{align}\n \t\tBy the conservation of mass, we have\n \t\t\\begin{align}\n \t\t\\int_{|y|\\geq R} |v(t,x) \\overline{u}^2(t,x)|dx &\\leq \\left( \\int_{|y|\\geq R} |u(t,x)|^4 dx\\right)^{1/2} \\left( \\int_{|y|\\geq R} |v(t,x)|^2 dx\\right)^{1/2} \\nonumber \\\\\n \t\t&\\lesssim \\left( \\int_{|y|\\geq R} |u(t,x)|^4 dx\\right)^{1/2}. \\label{est-cyli-0}\n \t\t\\end{align}\n \t\tNext we estimate\n \t\t\\begin{align*}\n \t\t\\int_{|y|\\geq R} |u(t,x)|^4 dx &\\leq \\int_{\\R} \\|u(t,x_d)\\|^2_{L^2_y} \\|u(t,x_d)\\|^2_{L^\\infty_y(|y|\\geq R)} dx_d \\\\\n \t\t&\\leq \\sup_{x_d \\in \\R} \\|u(t,x_d)\\|^2_{L^2_y} \\left(\\int_{\\R} \\|u(t,x_d)\\|^2_{L^\\infty_y(|y|\\geq R)} dx_d \\right).\n \t\t\\end{align*}\n \t\tSet $g(x_d):= \\|u(t,x_d)\\|^2_{L^2_y}$, we have\n \t\t\\begin{align*}\n \t\tg(x_d) = \\int_{-\\infty}^{x_d} \\partial_s g(s) ds &= 2 \\int_{-\\infty}^{x_d} \\rea \\int_{\\R^{d-1}} \\overline{u}(t,y,s) \\partial_s u(t,y,s) dy  ds \\\\\n \t\t&\\leq 2 \\|u(t)\\|_{L^2_x} \\|\\partial_d u(t)\\|_{L^2_x}\n \t\t\\end{align*}\n \t\twhich, by the conservation of mass, implies that\n \t\t\\begin{align} \\label{est-cyli-1}\n \t\t\\sup_{x_d \\in \\R} \\|u(t,x_d)\\|^2_{L^2_y} \\lesssim \\|\\partial_d u(t)\\|_{L^2_x}.\n \t\t\\end{align}\n \t\tWe next use the radial Sobolev embedding \\eqref{rad-sobo} to have\n \t\t\\begin{align}\n \t\t\\int_{\\R} \\|u(t,x_d)\\|^2_{L^\\infty_y(|y|\\geq R)} dx_d &\\lesssim R^{-d+2}  \\int_{\\R} \\|\\nabla_y u(t,x_d)\\|_{L^2_y} \\|u(t,x_d)\\|_{L^2_y} dx_d \\nonumber \\\\\n \t\t&\\lesssim R^{-d+2} \\left( \\int_{\\R} \\|\\nabla_y u(t,x_d)\\|^2_{L^2_y} dx_d\\right)^{1/2} \\left( \\int_{\\R} \\|u(t,x_d)\\|^2_{L^2_y} dx_d\\right)^{1/2} \\nonumber \\\\\n \t\t&\\lesssim R^{-d+2} \\|\\nabla_y u(t)\\|_{L^2_x} \\|u(t)\\|_{L^2_x} \\nonumber \\\\\n \t\t&\\lesssim R^{-d+2} \\|\\nabla_y u(t)\\|_{L^2_x}. \\label{est-cyli-2}\n \t\t\\end{align}\n \t\tCollecting \\eqref{est-cyli-0}, \\eqref{est-cyli-1}, and \\eqref{est-cyli-2}, we get\n \t\t\\begin{align*}\n \t\t\\int_{|y|\\geq R} |v(t,x) \\overline{u}^2(t,x)| dx &\\lesssim R^{-\\frac{d-2}{2}} \\|\\nabla_y u(t)\\|^{1/2}_{L^2_x} \\|\\partial_d u(t)\\|^{1/2}_{L^2_x} \\\\\n \t\t&\\lesssim R^{-\\frac{d-2}{2}} \\left(\\|\\nabla_y u(t)\\|_{L^2_x} + \\|\\partial_d u(t)\\|_{L^2_x}\\right) \\\\\n \t\t&\\lesssim R^{-\\frac{d-2}{2}} \\left( \\|\\nabla u(t)\\|^2_{L^2_x} + 1 \\right).\n \t\t\\end{align*}\n \t\tThis together with \\eqref{est-cyli} prove \\eqref{loca-viri-est-cyli-1}. The proof is complete.\n \t\\end{proof}\n \t\n \tWe also have the following refined localized virial estimate which will be used in the mass-critical problem.\n \t\\begin{lemma}[Cylindrical localized virial estimate II] \\label{lem-loca-viri-est-cyli-2}\n \t\tLet $d=4$ and $\\kappa>0$. Let $(u,v)$ be a $\\Sigma_4$-solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R-psi} and denote $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. Then we have for all $t\\in [0,T^*)$,\n \t\t\\begin{align} \\label{loca-viri-est-cyli-2}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u(t),v(t)) -4 \\int \\left(\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2\\right) |\\nabla_y u(t,x)|^2 dx \\nonumber \\\\\n \t\t&\\mathrel{\\phantom{\\leq 16 E(u(t),v(t)) }} + CR^{-1} \\|\\partial_4 u(t)\\|^2_{L^2} + o_R(1)\n \t\t\\end{align}\n \t\tfor some constant $C>0$ depending only on $\\kappa$ and $M(u_0,v_0)$, where\n \t\t\\begin{align} \\label{defi-vartheta-12-R}\n \t\t\\vartheta_{1,R}(\\rho):= 2-\\psi''_R(\\rho), \\quad \\vartheta_{2,R}(y):= 6-\\Delta_y \\psi_R(y).\n \t\t\\end{align}\n \t\\end{lemma}\n \t\n \t\\begin{proof}\n \t\tEstimating as in the proof of Lemma \\ref{lem-loca-viri-est-cyli-1}, we have\n \t\t\\begin{align*}\n \t\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u(t),v(t)) + CR^{-2} - 4 \\int \\vartheta_{1,R}(\\rho) \\left( |\\nabla_y u(t,x)|^2 + \\kappa |\\nabla_y v(t,x)|^2\\right) dx \\\\\n \t\t&\\mathrel{\\phantom{\\leq 16 E(u(t),v(t)) + CR^{-2}}} +2 \\rea \\int \\vartheta_{2,R}(y) v(t,x) \\overline{u}^2(t,x) dx.\n \t\t\\end{align*}\n \t\tBy the conservation of mass, we see that\n \t\t\\begin{align*}\n \t\t\\left| \\rea \\int \\vartheta_{2,R}(y) v(t,x) \\overline{u}^2(t,x) dx \\right| &\\leq \\left( \\int (\\vartheta_{2,R}(y))^2 |u(t,x)|^4 dx \\right)^{1/2} \\left(\\int |v(t,x)|^2 dx\\right)^{1/2} \\\\\n \t\t&\\lesssim \\left( \\int  (\\vartheta_{2,R}(y))^2 |u(t,x)|^4 dx \\right)^{1/2}.\n \t\t\\end{align*}\n \t\tBy the H\\\"older's inequality, we have\n \t\t\\begin{align*}\n \t\t\\int  (\\vartheta_{2,R}(y))^2 |u(t,x)|^4 dx  &\\leq \\int_{\\R} \\|u(t,x_4)\\|^2_{L^2_y} \\|\\vartheta_{2,R} u(t,x_4)\\|^2_{L^\\infty_y} dx_4 \\\\\n \t\t&\\leq \\sup_{x_4 \\in \\R} \\|u(t,x_4)\\|^2_{L^2_y} \\left( \\int_{\\R} |\\vartheta_{2,R} u(t,x_4)\\|^2_{L^\\infty_y} dx_4\\right).\n \t\t\\end{align*}\n \t\tThe first term is treated in \\eqref{est-cyli-1}. For the second term, as $\\vartheta_{2,R}(y) =0$ for $|y|\\leq R$, we use the radial Sobolev embedding \\eqref{rad-sobo} to have\n \t\t\\begin{align*}\n \t\t\\int_{\\R} \\|\\vartheta_{2,R} u(t,x_4)\\|^2_{L^\\infty_y} dx_4 &\\lesssim R^{-2} \\int_{\\R} \\|\\nabla_y (\\vartheta_{2,R} u(t,x_4))\\|_{L^2_y} \\|\\vartheta_{2,R} u(t,x_4)\\|_{L^2_y} dx_4 \\\\\n \t\t&\\lesssim R^{-2} \\left( \\int_{\\R} \\|\\nabla_y (\\vartheta_{2,R} u(t,x_4))\\|^2_{L^2_y} dx_4 \\right)^{1/2} \\left( \\int_{\\R} \\|\\vartheta_{2,R} u(t,x_4)\\|^2_{L^2_y} dx_4\\right)^{1/2} \\\\\n \t\t&\\lesssim R^{-2} \\|\\nabla_y (\\vartheta_{2,R} u(t))\\|_{L^2_x} \\|\\vartheta_{2,R} u(t)\\|_{L^2_x} \\\\\n \t\t&\\lesssim R^{-2} \\|\\nabla_y(\\vartheta_{2,R} u(t))\\|_{L^2_x}.\n \t\t\\end{align*}\n \t\tIt follows that\n \t\t\\begin{align*}\n \t\t\\left|\\rea \\int \\vartheta_{2,R}(y) v(t,x) \\overline{u}^2(t,x) dx \\right| &\\lesssim R^{-1} \\|\\nabla_y(\\vartheta_{2,R} u(t))\\|_{L^2_x}^{1/2} \\|\\partial_4 u(t)\\|_{L^2_x}^{1/2} \\\\\n \t\t&\\lesssim R^{-1} \\left( \\|\\nabla_y(\\vartheta_{2,R} u(t))\\|_{L^2_x} + \\|\\partial_4 u(t)\\|_{L^2_x}\\right) \\\\\n \t\t&\\lesssim R^{-1} \\left( \\|\\nabla_y(\\vartheta_{2,R} u(t))\\|^2_{L^2_x} + \\|\\partial_4 u(t)\\|^2_{L^2_x}  +1 \\right) \\\\\n \t\t&\\lesssim R^{-1} \\left( \\|\\vartheta_{2,R} \\nabla_y u(t)\\|^2_{L^2_x} +  \\|\\partial_4 u(t)\\|^2_{L^2_x} +1 \\right),\n \t\t\\end{align*}\n \t\twhere we have used the conservation of mass and $\\|\\nabla \\vartheta_{2,R}\\|_{L^\\infty_x}\\lesssim 1$ to get the last estimate. Collecting the above estimates, we prove \\eqref{loca-viri-est-cyli-2}.\n \t\\end{proof}\n \t\n \t\n \t\\section{Proof of the main results}\n\t\\label{S5}\n\t\\setcounter{equation}{0}\n\tWe are now able to prove the main results stated in Section \\ref{S-Main}.\n\t\n\t\\subsection{The intercritical case} The proof of Theorem \\ref{theo-blow-5d} is done by performing an ODE argument, by using the a-priori estimates we proved in the previous Section.\\\\\n\t \n\t\\noindent {\\it Proof of Theorem \\ref{theo-blow-5d}.}\n\tWe only consider the case of $\\Sigma_5$-data. The one for radial solution is given in \\cite{IKN-NA}.  Let $(u_0,v_0) \\in \\Sigma_5 \\times \\Sigma_5$ satisfy either $E(u_0,v_0)<0$ or if $E(u_0,v_0) \\geq 0$, we assume that \\eqref{cond-blow} holds. We will show that $T^*<\\infty$. Assume by contradiction that $T^*=\\infty$. By Lemma \\ref{lem-uppe-boun-5d}, there exist positive constants $\\vareps$ and $c$ such that\n\t\\begin{align} \\label{uppe-boun-5d-app}\n\tG(u(t),u(t)) + \\vareps T(u(t),v(t)) \\leq -c\n\t\\end{align}\n\tfor all $t\\in [0,\\infty)$. On the other hand, by Lemma \\ref{lem-loca-viri-est-cyli-1}, we have for all $t\\in [0,\\infty)$,\n\t\\begin{align} \\label{est-viri-cyli-app}\n\t\\frac{d}{dt} M_{\\varphi_R}(t)\\leq 8G(u(t),v(t)) + CR^{-\\frac{3}{2}} \\|\\nabla u(t)\\|^2_{L^2} + o_R(1),\n\t\\end{align}\n\twhere $\\varphi_R$ is as in \\eqref{defi-varphi-R} and $M_{\\varphi_R}(t)$ is as in \\eqref{defi-M-varphi}. It follows from \\eqref{uppe-boun-5d-app} and \\eqref{est-viri-cyli-app} that for all $t\\in [0,\\infty)$,\n\t\\begin{align*}\n\t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq -8c - 8\\vareps T(u(t),v(t)) +CR^{-\\frac{3}{2}} \\|\\nabla u(t)\\|^2_{L^2} + o_R(1).\n\t\\end{align*}\n\tBy choosing $R>1$ sufficiently large, we get\n\t\\begin{align} \\label{est-M-varphi-R-app-1}\n\t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq -4c -4\\vareps T(u(t),v(t))\n\t\\end{align}\n\tfor all $t\\in [0,\\infty)$. Integrating the above inequality, we see that $M_{\\varphi_R}(t) <0$ for all $t\\geq t_0$  with some $t_0>0$ sufficiently large. We infer from \\eqref{est-M-varphi-R-app-1} that\n\t\\begin{align} \\label{est-M-varphi-R-app-2}\n\tM_{\\varphi_R}(t) \\leq -4\\vareps \\int_{t_0}^t T(u(s),v(s)) ds\n\t\\end{align}\n\tfor all $t\\geq t_0$. On the other hand, by the H\\\"older's inequality and the conservation of mass, we have\n\t\\begin{align}\n\t|M_{\\varphi_R}(t)| &\\leq C \\|\\nabla \\varphi_R\\|_{L^\\infty} \\left( \\|\\nabla u(t)\\|_{L^2} \\|u(t)\\|_{L^2} + \\|\\nabla v(t)\\|_{L^2} \\|v(t)\\|_{L^2} \\right) \\nonumber \\\\\n\t&\\leq C(\\varphi_R, \\kappa, M(u_0,v_0)) \\sqrt{T(u(t),v(t))}. \\label{est-M-varphi-R-app-3}\n\t\\end{align}\n\tFrom \\eqref{est-M-varphi-R-app-2} and \\eqref{est-M-varphi-R-app-3}, we get\n\t\\begin{align} \\label{est-M-varphi-R-app-4}\n\tM_{\\varphi_R}(t) \\leq -A \\int_{t_0}^t |M_{\\varphi_R}(s)|^2 ds\n\t\\end{align}\n\tfor all $t\\geq t_0$, where $A=A(\\vareps, \\varphi_R, \\kappa, M(u_0,v_0))>0$. Set \n\t\\begin{align} \\label{est-M-varphi-R-app-5}\n\tz(t):= \\int_{t_0}^t |M_{\\varphi_R}(s)|^2 ds, \\quad t\\geq t_0.\n\t\\end{align}\n\tWe see that $z(t)$ is  non-decreasing and non-negative. Moreover, \n\t\\[\n\tz'(t) = |M_{\\varphi_R}(t)|^2 \\geq A^2 z^2(t), \\quad \\forall t\\geq t_0.\n\t\\]\n\tFor $t_1>t_0$, we integrate \\eqref{est-M-varphi-R-app-5} over $[t_1,t]$ to obtain\n\t\\[\n\tz(t) \\geq \\frac{z(t_1)}{1-A^2z(t_1)(t-t_1)}, \\quad \\forall t\\geq t_1.\n\t\\]\n\tThis shows that $z(t) \\rightarrow +\\infty$ as $t \\nearrow t^*$, where\n\t\\[\n\tt^*:= t_1 + \\frac{1}{A^2 z(t_1)} >t_1.\n\t\\]\n\tIn particular, we have\n\t\\[\n\tM_{\\varphi_R}(t) \\leq -Az(t) \\rightarrow -\\infty\n\t\\]\n\tas $t\\nearrow t^*$. Thus the solution cannot exist for all time $t\\geq 0$. Therefore it must blow-up in finite time.\n\t\\hfill $\\Box$\n\t\t\n\t\\subsection{The energy-critical case} The proof is done by an ODE argument as well, similarly to the intercritical case. \\\\\n\t\n\t\\noindent {\\it Proof of Theorem \\ref{theo-blow-6d}.} The proof is similar to that of Theorem \\ref{theo-blow-5d} using \\eqref{uppe-boun-6d} and \\eqref{loca-viri-est-cyli-1}. Thus we omit the details.\n\t\\hfill $\\Box$\n\t\n\t\n\t\\subsection{The mass-critical case} In this subsection, we give the proofs of the blow-up/grow-up results given in Theorems \\ref{theo-blow-grow-4d} and \\ref{theo-blow-grow-Sigma-4d}. \\\\\n\t\n\t\\noindent {\\it Proof of Theorem \\ref{theo-blow-grow-4d}.}\n\tLet $(u_0,v_0) \\in H^1\\times H^1$ be radially symmetric satisfying $E(u_0,v_0)<0$. Let $(u,v)$ be the corresponding solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. If $T^*<\\infty$, then we are done. Suppose that $T^*=\\infty$. We will show that there exists a constant $C>0$ depending only on $\\kappa, M(u_0,v_0)$, and $E(u_0,v_0)$ such that \n\t\\[ \n\tT(u(t),v(t)) \\geq Ct^2\n\t\\]\n\tfor all $t\\geq t_0$, where $t_0\\gg 1$, namely that \\eqref{grow-4d} holds true. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R} and $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. By Lemma \\ref{lem-loca-viri-est-rad-2} and the conservation of energy, we have for all $t\\in [0,\\infty)$,\n\t\\[\n\t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq 16E(u_0,v_0) - 4 \\int \\left( \\theta_{1,R}(r) - CR^{-\\frac{3}{2}} \\left(\\theta_{2,R}(x)\\right)^2\\right) |\\nabla u(t,x)|^2 dx + o_R(1),\n\t\\]\n\twhere $\\theta_{1,R}$ and $\\theta_{2,R}$ are as in \\eqref{defi-theta-12-R}. \\\\\n\t\n\\noindent\tIf we can show that \n\t\\begin{equation} \\label{prop-theta-12-R}\n\t\\theta_{1,R}(r) - CR^{-\\frac{3}{2}} \\left(\\theta_{2,R}(x)\\right)^2 \\geq 0, \\quad \\forall r=|x|\\geq0,\n\t\\end{equation}\n\tthen, by taking $R>1$ large enough, we get\n\t\\[\n\t\\frac{d}{dt} M_{\\varphi_R}(t) \\leq 8E(u_0,v_0) <0\n\t\\]\n\tfor all $t\\in [0,\\infty)$. Integrating the above estimate, we have\n\t\\[\n\tM_{\\varphi_R}(t) \\leq M_{\\varphi_R}(0) + 8E(u_0,v_0) t\n\t\\]\n\twhich implies\n\t\\[\n\tM_{\\varphi_R}(t) \\leq 4E(u_0,v_0) t<0\n\t\\]\n\tfor all $t\\geq t_0$, where $t_0:= \\frac{|M_{\\varphi_R}(0)|}{-4E(u_0,v_0)}$. By \\eqref{est-M-varphi-R-app-3}, we have\n\t\\[\n\t- 4E(u_0,v_0) t \\leq -M_{\\varphi_R}(t) = |M_{\\varphi_R}(t)| \\leq C(\\varphi_R, \\kappa, M(u_0,v_0)) \\sqrt{T(u(t),v(t))}\n\t\\]\n\tfor all $t\\geq t_0$. This shows \\eqref{grow-4d}.\\\\\n\t\n\tIt remains to find a suitable cut-off function $\\chi$ (as defined in \\eqref{defi-chi}) so that \\eqref{prop-theta-12-R} holds. For the choice of such a function, we are inspired by \\cite{OT-JDE}. Let \n\t\\[\n\t\\zeta(s):= \\left\\{\n\t\\begin{array}{c l c}\n\t2s & \\text{if}& 0\\leq s \\leq 1, \\\\\n\t2[s-(s-1)^3] &\\text{if}& 1<s\\leq 1+1/\\sqrt{3}, \\\\\n\t\\zeta'(s) <0 &\\text{if}& 1+ 1/\\sqrt{3} <s < 2, \\\\\n\t0 &\\text{if}& s \\geq 2,\n\t\\end{array}\n\t\\right.\n\t\\]\n\tand \n\t\\begin{align} \\label{defi-chi-app}\n\t\\chi(r):= \\int_{0}^{r}\\zeta(s)ds.\n\t\\end{align}\n\tIt is easy to see that $\\chi$ satisfies \\eqref{defi-chi}. Define $\\varphi_R$ as in \\eqref{defi-varphi-R}. We will show that \\eqref{prop-theta-12-R} is satisfied for this choice of $\\varphi_R$. Indeed, we have $\\theta_{1,R}(r) = 2-\\varphi''_R(r)$ and \n\t\\[\n\t\\theta_{2,R}(x) = 8-\\Delta \\varphi_R(x) = 2- \\varphi''_R(r) + 3 \\left(2-\\frac{\\varphi'_R(r)}{r}\\right),\n\t\\]\n\twhere the latter follows from the fact that\n\t\\[\n\t\\Delta \\varphi_R(x) = \\varphi''_R(r) +\\frac{3}{r}\\varphi'_R(r).\n\t\\]\n\tWe infer, from the definition of $\\varphi_R,$ that\n\t\\[\n\t\\varphi'_R(r) = R\\chi'(r/R) = R \\zeta(r/R), \\quad \\varphi''_R(r) = \\chi''(r/R) = \\zeta'(r/R).\n\t\\]\n\t\\begin{itemize}[leftmargin=6mm]\n\t\t\\item For $0 \\leq r =|x|\\leq R$, we have $\\theta_{1,R}(r) = \\theta_{2,R}(x) =0$.\n\t\t\\item For $R < r = |x| \\leq (1+1/\\sqrt{3}) R$, we have\n\t\t\\[\n\t\t\\theta_{1,R}(r) = 6(r/R-1)^2\n\t\t\\]\n\t\tand \n\t\t\\[\n\t\t\\theta_{2,R}(x) = 2(r/R-1)^2 \\left(3+2 \\frac{r/R-1}{r/R}\\right) < 2\\left(3+\\frac{2}{\\sqrt{3}}\\right)(r/R-1)^2.\n\t\t\\]\n\t\tBy choosing $R>1$ sufficiently large, we see that \\eqref{prop-theta-12-R} is fulfilled. \n\t\t\\item When $r> (1+1/\\sqrt{3})R$, we see that $\\zeta'(r/R) \\leq 0$, so $\\theta_{1,R}(r) = 2-\\varphi''_R(r) \\geq 2$. We also have $\\theta_{2,R}(r) \\leq C$ for some constant $C>0$. Thus by choosing $R>1$ sufficiently large, we have \\eqref{prop-theta-12-R}. \n\t\\end{itemize}\n\tThe proof is complete by glueing together \\eqref{grow-4d} and \\eqref{prop-theta-12-R}.\n\t\\hfill $\\Box$\\\\\n\t\n\tWe can now proceed with the proof of the cylindrical case. \\\\\n\t\n\t\\noindent {\\it Proof of Theorem \\ref{theo-blow-grow-Sigma-4d}.}\n\tLet $(u_0,v_0) \\in \\Sigma_4 \\times \\Sigma_4$ satisfy $E(u_0,v_0)<0$. Let $(u,v)$ be the corresponding solution to \\eqref{SNLS} defined on the maximal forward time interval $[0,T^*)$. \n\t\n\t\n\t\\noindent First we consider the non-mass-resonance case, i.e. $0<\\kappa \\ne \\frac{1}{2}$. If $T^*<\\infty$, then we are done. Suppose that $T^*=\\infty$. We will show that there exists a time sequence $t_n \\rightarrow \\infty$ such that $\\|(u(t_n),v(t_n))\\|_{H^1 \\times H^1} \\rightarrow \\infty$ as $n\\rightarrow \\infty$. Assume by contradiction that it is not true, that is, \n\t\\begin{align} \\label{contra}\n\t\\sup_{t\\in[0,\\infty)} \\|(u(t),v(t))\\|_{H^1 \\times H^1} \\leq C <\\infty.\n\t\\end{align}\n\tLet $\\varphi_R$ be as in \\eqref{defi-varphi-R-psi} and $M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi}. By Lemma \\ref{lem-loca-viri-est-cyli-2} and the conservation of energy, we have for all $t\\in [0,\\infty)$,\n\t\\begin{align}\n\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u_0,v_0) -4 \\int \\left(\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2\\right) |\\nabla_y u(t,x)|^2 dx \\nonumber \\\\\n\t&\\mathrel{\\phantom{\\leq 16 E(u_0,v_0) }} + CR^{-1} \\|\\partial_4 u(t)\\|^2_{L^2} + o_R(1) \\label{est-cyli-4d-app}\n\t\\end{align}\n\tfor some constant $C>0$ depending only on $\\kappa$ and $M(u_0,v_0)$, where $\\vartheta_{1,R}$ and $\\vartheta_{2,R}$ are as in \\eqref{defi-vartheta-12-R}. This, together with \\eqref{contra}, gives \n\t\\begin{align*}\n\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u_0,v_0) -4 \\int \\left(\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2\\right) |\\nabla_y u(t,x)|^2 dx \\\\\n\t&\\mathrel{\\phantom{\\leq 16 E(u_0,v_0) }} + CR^{-1} + o_R(1).\n\t\\end{align*}\n\tfor all $t\\in [0,\\infty).$\n\t\\\\\n\t\n\t\\noindent Provided that we prove  \n\t\\begin{align} \\label{prop-vartheta-12-R}\n\t\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2 \\geq 0, \\quad \\forall \\rho=|y| \\geq 0,\n\t\\end{align}\n\tthen we can choose $R>1$ large enough so that for all $t\\in [0,\\infty)$,\n\t\\[\n\t\\frac{d}{dt}M_{\\varphi_R}(t) \\leq 4E(u_0,v_0).\n\t\\]\n\tArguing as in the proof of Theorem \\ref{theo-blow-grow-4d}, we have\n\t\\[\n\t-4E(u_0,v_0) t \\leq C(\\varphi_R, \\kappa, M(u_0,v_0)) \\sqrt{T(u(t),v(t))}\n\t\\]\n\tfor all $t\\geq t_0$, where $t_0 \\gg 1$. In particular, we have\n\t\\[\n\tT(u(t),v(t)) \\geq C(\\varphi_R, \\kappa, M(u_0,v_0),E(u_0,v_0)) t^2\n\t\\]\n\tfor all $t\\geq t_0$ which contradicts \\eqref{contra} for $t$ sufficiently large. \\\\\n\t\n\tNext we consider the mass-resonance case, i.e. $\\kappa=\\frac{1}{2}$. If $T^*<\\infty$, then we are done. Suppose that $T^*=\\infty$. We will show that there exists a time sequence $t_n \\rightarrow \\infty$ such that $\\|\\partial_4 u(t_n)\\|_{L^2}\\rightarrow \\infty$ as $n\\rightarrow \\infty$. Assume by contradiction that it does not hold, i.e. \n\t\\begin{align*}\n\t\\sup_{t\\in [0,\\infty)} \\|\\partial_4 u(t)\\|_{L^2} \\leq C<\\infty. \n\t\\end{align*}\n\tThanks to \\eqref{est-cyli-4d-app}, we have for all $t\\in [0,\\infty)$,\n\t\\begin{align*}\n\t\\frac{d}{dt} M_{\\varphi_R}(t) &\\leq 16 E(u_0,v_0) -4 \\int \\left(\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2\\right) |\\nabla_y u(t,x)|^2 dx \\\\\n\t&\\mathrel{\\phantom{\\leq 16 E(u_0,v_0) }} + CR^{-1} + o_R(1).\n\t\\end{align*}\n\tProvided that \\eqref{prop-vartheta-12-R} holds true, we can choose $R>1$ sufficiently large to get for all $t\\in [0,\\infty)$,\n\t\\[\n\t\\frac{d}{dt} M_{\\varphi_R} (t) \\leq 4 E(u_0,v_0).\n\t\\]\n\tAs $\\kappa=\\frac{1}{2}$, we see that\n\t\\[\n\t\\frac{d}{dt} V_{\\varphi_R}(t) = M_{\\varphi_R}(t),\n\t\\]\n\twhere\n\t\\[\n\tV_{\\varphi_R}(t) := \\int \\varphi_R (x) \\left(|u(t,x)|^2 +2|v(t,x)|^2 \\right) dx.\n\t\\]\n\tIt follows that, for all $t\\in [0,\\infty)$,\n\t\\[\n\t\\frac{d^2}{dt^2} V_{\\varphi_R}(t) \\leq 4 E(u_0,v_0) <0.\n\t\\]\n\tIntegrating the above inequality, there exists $t_0>0$ sufficiently large so that $V_{\\varphi_R}(t_0)<0$ which is impossible. \\\\\n\t\n\tFinally, let us choose a suitable cut-off function $\\varphi_R$ so that \\eqref{prop-vartheta-12-R} is fulfilled. Let $\\chi$ as in \\eqref{defi-chi-app}. It is easy to see that $\\chi$ satisfies \\eqref{defi-chi}. Define\n\t\\[\n\t\\psi_R(y):= \\psi_R(\\rho) = R^2 \\chi(\\rho/R), \\quad \\rho=|y|\n\t\\]\n\tand let $\\varphi_R$ be as in \\eqref{defi-varphi-R-psi}, namely $\\varphi_R(x)=\\psi_R(y)+x_4^2$. We will show that \\eqref{prop-vartheta-12-R} is satisfied for this choice of $\\psi_R$. Indeed, we have $\\vartheta_{1,R}(\\rho) = 2-\\psi''_R(\\rho)$ and\n\t\\[\n\t\\vartheta_{2,R}(y) = 6-\\Delta_y \\psi_R(y) = 2- \\psi''_R(\\rho) + 2 \\left(2-\\frac{\\psi'_R(\\rho)}{\\rho}\\right)\n\t\\]\n\tas $\\Delta_y \\psi_R(y) = \\psi''_R(\\rho) +\\frac{2}{\\rho}\\psi'_R(\\rho)$.\tBy the definition of $\\psi_R$, we have\n\t\\[\n\t\\psi'_R(\\rho) = R\\chi'(\\rho/R) = R \\zeta(\\rho/R), \\quad \\psi''_R(\\rho) = \\chi''(\\rho/R) = \\zeta'(\\rho/R).\n\t\\]\n\t\\begin{itemize}[leftmargin=6mm]\n\t\t\\item For $0 \\leq \\rho =|y|\\leq R$, we have $\\vartheta_{1,R}(\\rho) = \\vartheta_{2,R}(y) =0$.\n\t\t\\item For $R < \\rho = |y| \\leq (1+1/\\sqrt{3}) R$, we have\n\t\t\\[\n\t\t\\vartheta_{1,R}(\\rho) = 6(\\rho/R-1)^2\n\t\t\\]\n\t\tand \n\t\t\\[\n\t\t\\vartheta_{2,R}(y) = 2(\\rho/R-1)^2 \\left(3+2 \\frac{\\rho/R-1}{\\rho/R}\\right) < 2\\left(3+\\frac{2}{\\sqrt{3}}\\right)(\\rho/R-1)^2.\n\t\t\\]\n\t\tBy choosing $R>1$ sufficiently large, we see that \\eqref{prop-vartheta-12-R} holds. \n\t\t\\item When $\\rho> (1+1/\\sqrt{3})R$, we see that $\\zeta'(\\rho/R) \\leq 0$, so $\\vartheta_{1,R}(\\rho) = 2-\\psi''_R(\\rho) \\geq 2$. We also have $\\vartheta_{2,R}(\\rho) \\leq C$ for some constant $C>0$. Thus by choosing $R>1$ sufficiently large, we get \\eqref{prop-vartheta-12-R}. \n\t\\end{itemize}\n\tThe proof is complete.\n\t\\hfill $\\Box$\n\t\n\t\n%\\section*{Acknowledgement}\n%This work was supported in part by the Labex CEMPI (ANR-11-LABX-0007-01). V. D. D. would like to express his deep gratitude to his wife - Uyen Cong for her encouragement and support. %The authors would like to thank the reviewers for their helpful comments and suggestions. \n\n%\\section*{Author's contributions}\n%All authors contributed equally to this work. \n\n%\\section*{Data availability} \n%Data sharing is not applicable to this article as no new data were created or analyzed in this study.\n\n\\appendix\n\t\n\\section{Localized virial estimates for the 4D general quadratic system}\n\\label{S6}\n\\setcounter{equation}{0}\nIn this appendix, we provide some localized virial estimates related to a generalized system of NLS with quadratic interactions \\eqref{GQNLS} in the mass-critical case $d=4$.\n\n\\begin{lemma} \\label{lem-viri-est-rad-4d-GQNLS}\n\tLet $d=4$ and $\\vec u$ be a radial $H^1$-solution to \\eqref{GQNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R} and denote\n\t\\begin{align} \\label{defi-M-varphi-GQNLS}\n\t\\mathcal M_{\\varphi_R}(t):= 2 \\ima \\sum_{j=1}^N a_j \\int \\nabla \\varphi_R(x) \\cdot \\nabla u_j(t,x) \\overline{u}_j(t,x) dx.\n\t\\end{align}\n\tThen we have for all $t\\in [0,T^*)$,\n\t\\begin{equation*}\n\t\\frac{d}{dt} \\mathcal M_{\\varphi_R}(t) \\leq 16 \\mathcal E (\\vec u(t)) - 4 \\int \\left( \\theta_{1,R}(r) - CR^{-\\frac{3}{2}} \\left(\\theta_{2,R}(x)\\right)^2 \\right) \\left( \\sum_{j=1}^N a_j |\\nabla_j(t,x)|^2\\right) dx + o_R(1)\n\t\\end{equation*}\n\tfor some constant $C>0$ depending only on $\\kappa$, $\\boldsymbol{a}=(a_1,\\dots, a_N)$, and $M(u_0,v_0)$, where $\\theta_{1,R}$ and $\\theta_{2,R}$ are as in \\eqref{defi-theta-12-R}.\n\\end{lemma}\n\n\\begin{proof}\n\tArguing as in the proof of \\cite[Theorem 4.1]{NP-blow}, we have for all $t\\in [0,T^*)$,\n\t\\begin{align*}\n\t\\frac{d}{dt} \\Mcal_{\\varphi_R}(t) &= 16 \\mathcal E(\\vec u(t)) - 4 \\int (2-\\varphi''_R) \\left(\\sum_{j=1}^N a_j |\\nabla u_j(t)|^2 \\right) dx \\\\\n\t&\\mathrel{\\phantom{=}}- \\int \\Delta^2 \\varphi_R \\left( \\sum_{j=1}^N a_j |u_j(t)|^2\\right) dx + 2 \\rea \\int (8-\\Delta \\varphi_R) F(\\vec u(t)) dx.\n\t\\end{align*}\n\tBy the conservation of mass, we have\n\t\\[\n\t\\left|\\int \\Delta^2 \\varphi_R \\left( \\sum_{j=1}^N a_j |u_j(t)|^2\\right) dx\\right| \\lesssim R^{-2}.\n\t\\]\n\tThus we get\n\t\\begin{equation} \\label{est-1}\n\t\\frac{d}{dt} \\Mcal_{\\varphi_R}(t) \\leq 16 \\mathcal E(\\vec u(t)) - 4\\int \\theta_{1,R} \\left(\\sum_{j=1}^N a_j |\\nabla u_j(t)|^2 \\right) dx + 2\\rea \\int \\theta_{2,R} F(\\vec u(t))dx + CR^{-2},\n\t\\end{equation}\n\twhere $\\theta_{1,R}$ and $\\theta_{2,R}$ are as in \\eqref{defi-theta-12-R}. By the assumption (H6) in \\cite{NP-blow}, the radial Sobolev embedding and the conservation of mass, we estimate\n\t\\begin{equation*}\n\t\\begin{aligned}\n\t\\left|\\rea \\int \\theta_{2,R} F(\\vec u(t))dx \\right| &\\leq \\int \\theta_{2,R} |F(\\vec u(t))| dx \\\\\n\t&\\leq \\int \\theta_{2,R} \\left( \\sum_{j=1}^N |u_j(t)|^3\\right) dx \\\\\n\t&\\leq \\sum_{j=1}^N \\sup_{|x|\\geq R} |\\theta_{2,R}(x) u_j(t,x)| \\|u_j(t)\\|_{L^2}^2 \\\\\n\t&\\lesssim  R^{-\\frac{3}{2}} \\sum_{j=1}^N \\|\\nabla(\\theta_{2,R} u_j(t))\\|^{\\frac{1}{2}}_{L^2} \\|\\theta_{2,R} u_j(t)\\|^{\\frac{1}{2}}_{L^2} \\|u_j(t)\\|^2_{L^2}\\\\\n\t&\\lesssim R^{-\\frac{3}{2}} \\sum_{j=1}^N  \\|\\nabla(\\theta_{2,R} u_j(t))\\|^{\\frac{1}{2}}_{L^2}.\n\t\\end{aligned}\n\t\\end{equation*}\n\tThanks to the conservation of mass and the fact that $\\|\\nabla \\theta_{2,R}\\|_{L^\\infty} \\lesssim 1$, we have\n\t\\[\n\t\\|\\nabla (\\theta_{2,R} u_j(t))\\|_{L^2} \\lesssim \\|\\theta_{2,R} \\nabla_j u(t)\\|_{L^2} +1\n\t\\]\n\twhich implies that\n\t\\begin{equation} \\label{est-2}\n\t\\begin{aligned}\n\t\\left|\\rea \\int \\theta_{2,R} F(\\vec u(t))dx \\right| &\\lesssim R^{-\\frac{3}{2}} \\sum_{j=1}^N \\left( \\|\\theta_{2,R} \\nabla u_j(t)\\|^2_{L^2} +1 \\right)  \\\\\n\t&\\lesssim R^{-\\frac{3}{2}} \\int \\left(\\theta_{2,R} \\right)^2 \\left( \\sum_{j=1}^N a_j |\\nabla u_j(t)|^2\\right) dx + R^{-\\frac{3}{2}}.\n\t\\end{aligned}\n\t\\end{equation}\n\tCollecting \\eqref{est-1} and \\eqref{est-2}, we finish the proof.\n\\end{proof}\n\n\\begin{lemma} \\label{lem-viri-est-cyli-4d-GQNLS}\n\tLet $d=4$ and $\\vec u$ be a $\\Sigma_4$-solution to \\eqref{GQNLS} defined on the maximal forward time interval $[0,T^*)$. Let $\\varphi_R$ be as in \\eqref{defi-varphi-R-psi} and denote $\\mathcal M_{\\varphi_R}(t)$ as in \\eqref{defi-M-varphi-GQNLS}. Then we have for all $t\\in [0,T^*)$,\n\t\\begin{equation*}\n\t\\begin{aligned} \n\t\\frac{d}{dt} \\mathcal M_{\\varphi_R}(t) &\\leq 16 \\mathcal E(\\vec u(t)) -4 \\int \\left(\\vartheta_{1,R}(\\rho) - CR^{-1} (\\vartheta_{2,R}(y))^2\\right) \\left(\\sum_{j=1}^N a_j |\\nabla_y u_j(t,x)|^2\\right) dx  \\\\\n\t&\\mathrel{\\phantom{\\leq 16 \\mathcal E(\\vec u(t)) }} + CR^{-1} \\sum_{j=1}^N\\|\\partial_4 u_j(t)\\|^2_{L^2} + o_R(1)\n\t\\end{aligned}\n\t\\end{equation*}\n\tfor some constant $C>0$ depending only on $\\kappa$, $\\boldsymbol{a}=(a_1,\\dots,a_N)$, and $M(u_0,v_0)$, where $\\vartheta_{1,R}$ and $\\vartheta_{2,R}$ are as in \\eqref{defi-vartheta-12-R}.\n\\end{lemma}\n\n\\begin{proof}\n\tUsing localized virial identities similar to Item (4) of Remark \\ref{rem-viri} (see also Lemma \\ref{lem-loca-viri-est-cyli-2}), we have for all $t\\in [0,T^*)$,\n\t\\begin{equation*}\n\t\\begin{aligned}\n\t\\frac{d}{dt} \\mathcal M_{\\varphi_R}(t) &= 16 \\mathcal E(\\vec u(t)) + CR^{-2} - 4 \\int \\vartheta_{1,R}(\\rho) \\left(\\sum_{j=1}^N a_j |\\nabla_y u_j(t,x)|^2\\right) dx \\\\\n\t&\\mathrel{\\phantom{= 16 \\mathcal E(\\vec u(t)) + CR^{-2} }} + 2\\rea \\int \\vartheta_{2,R}(y) F(\\vec u(t,x)) dx,\n\t\\end{aligned}\n\t\\end{equation*}\n\twhere $\\vartheta_{1,R}$ and $\\vartheta_{2,R}$ are as in \\eqref{defi-vartheta-12-R}. We estimate\n\t\\begin{equation*}\n\t\\begin{aligned}\n\t\\left| \\rea \\int \\vartheta_{2,R}(y) F(\\vec u(t,x)) dx\\right| &\\leq \\int \\vartheta_{2,R}(y) |F(\\vec u(t,x))| dx \\\\\n\t&\\leq \\int \\vartheta_{2,R}(y) \\left(\\sum_{j=1}^N |u_j(t,x)|^3 \\right) dx \\\\\n\t&\\leq \\sum_{j=1}^N \\left( \\int \\left(\\vartheta_{2,R}(y)\\right)^2 |u_j(t,x)|^4 dx\\right)^{1/2} \\|u_j(t)\\|_{L^2_x} \\\\\n\t&\\lesssim \\sum_{j=1}^N \\left( \\int \\left(\\vartheta_{2,R}(y)\\right)^2 |u_j(t,x)|^4 dx\\right)^{1/2}.\n\t\\end{aligned}\n\t\\end{equation*}\n\tEstimating as in Lemmas \\ref{lem-loca-viri-est-cyli-1} and \\ref{lem-loca-viri-est-cyli-2}, we have\n\t\\begin{align*}\n\t\\left(\\int \\left(\\vartheta_{2,R}(y)\\right)^2 |u_j(t,x)|^4 dx \\right)^{1/2} &\\lesssim R^{-1} \\|\\nabla_y(\\vartheta_{2,R} u_j(t))\\|^{1/2}_{L^2_x} \\|\\partial_4 u_j(t)\\|^{1/2}_{L^2_x}\\\\\n\t&\\lesssim R^{-1} \\left( \\|\\nabla_y(\\vartheta_{2,R} u_j(t)\\|_{L^2_x} + \\|\\partial_4 u_j(t)\\|_{L^2_x}\\right) \\\\\n\t&\\lesssim R^{-1} \\left(\\|\\nabla_y(\\vartheta_{2,R} u_j(t))\\|^2_{L^2_x} + \\|\\partial_4 u_j(t)\\|^2_{L^2_x} +1 \\right) \\\\\n\t&\\lesssim R^{-1} \\left(\\|\\vartheta_{2,R} \\nabla_y u_j(t)\\|^2_{L^2_x} + \\|\\partial_4 u_j(t)\\|^2_{L^2_x} +1 \\right).\t\n\t\\end{align*}\n\tThe proof is complete by collecting the above estimates.\n\\end{proof}\n\n\n%\\appendix\n%\\section*{Appendix}\n\t\n\\begin{bibdiv}\n\\begin{biblist}\n\t\t\t\n\\bib{BF19}{article}{\nauthor={Bellazzini, J.},\nauthor={Forcella, L.},\ntitle={Asymptotic dynamic for dipolar quantum gases below the ground state energy threshold},\njournal={J. Funct. Anal.},\nvolume={277},\ndate={2019},\nnumber={6},\npages={1958--1998},\nissn={0022-1236},\n%review={\\MR{3985521}},\n%doi={10.1016/j.jfa.2019.04.005},\n}\n\n\\bib{BF20}{article}{\nauthor={Bellazzini, {J.}},\nauthor={Forcella, {L.}},\ntitle={Dynamical collapse of cylindrical symmetric dipolar Bose-Einstein Condensates},\njournal={preprint},\neprint={https://arxiv.org/abs/2005.02894}, \n}\n\n\\bib{Cazenave}{book}{\nauthor={Cazenave, T.},\ntitle={Semilinear Schr\\\"{o}dinger equations},\nseries={Courant Lecture Notes in Mathematics},\nvolume={10},\npublisher={New York University, Courant Institute of Mathematical Sciences, New York; American Mathematical Society, Providence, RI},\ndate={2003},\npages={xiv+323},\nisbn={0-8218-3399-5},\n%review={\\MR{2002047}},\n%doi={10.1090/cln/010},\n}\n\n\\bib{CO}{article}{\nauthor={Cho, Y.},\nauthor={Ozawa, T.},\ntitle={Sobolev inequalities with symmetry},\njournal={Commun. Contemp. Math.},\nvolume={11},\ndate={2009},\nnumber={3},\npages={355--365},\nissn={0219-1997},\n%review={\\MR{2538202}},\n%doi={10.1142/S0219199\n}\n\t\t\n\\bib{CCO}{article}{\nauthor={Colin, M.},\nauthor={Colin, Th.},\nauthor={Ohta, M.},\ntitle={Stability of solitary waves for a system of nonlinear Schr\\\"{o}dinger\nequations with three wave interaction},\nlanguage={English, with English and French summaries},\njournal={Ann. Inst. H. Poincar\\'{e} Anal. Non Lin\\'{e}aire},\nvolume={26},\ndate={2009},\nnumber={6},\npages={2211--2226},\nissn={0294-1449},\n%review={\\MR{2569892}},\n%doi={10.1016/j.anihpc.2009.01.011},\n}\n\n\\bib{CdMS}{article}{\nauthor={Colin, M.},\nauthor={Di Menza, L.},\nauthor={Saut, J. C.},\ntitle={Solitons in quadratic media},\njournal={Nonlinearity},\nvolume={29},\ndate={2016},\nnumber={3},\npages={1000--1035},\nissn={0951-7715},\n%review={\\MR{3465991}},\n%doi={10.1088/0951-7715/29/3/1000},\n}\n\n\\bib{Dinh-NA}{article}{\nauthor={Dinh, V. D.},\t\ntitle={Existence, stability of standing waves and the characterization of finite time blow-up solutions for a system NLS with quadratic interaction},\njournal={Nonlinear Anal.},\nvolume={190},\t\ndate={2020},\npages={111589, 39},\nissn={0362-546X},\n%review={\\MR{3991960}},\n%doi={10.1016/j.na.2019.111589},\n}\n\n\\bib{Dinh-insta}{article}{\n\tauthor={Dinh, {V. D.}},\n\ttitle={Strong Instability of Standing Waves for a System NLS with\n\t\tQuadratic Interaction},\n\tjournal={Acta Math. Sci. Ser. B (Engl. Ed.)},\n\tvolume={40},\n\tdate={2020},\n\tnumber={2},\n\tpages={515--528},\n\tissn={0252-9602},\n\t%review={\\MR{4085313}},\n\t%doi={10.1007/s10473-020-0214-6},\n}\n\n\\bib{DFH}{article}{\nauthor={Dinh, V. D.},\nauthor={Forcella, L.},\nauthor={Hajaiej, H.},\ntitle={Mass-Energy threshold dynamics for dipolar Quantum Gases},\njournal={preprint},\neprint={https://arxiv.org/abs/2009.05933},\n}\n\n\\bib{DM-MRL}{article}{\nauthor={Dodson, B.},\nauthor={Murphy, J.},\ntitle={A new proof of scattering below the ground state for the non-radial focusing NLS},\njournal={Math. Res. Lett.},\nvolume={25},\ndate={2018},\nnumber={6},\npages={1805--1825},\nissn={1073-2780},\n%review={\\MR{3934845}},\n%doi={10.4310/MRL.2018.v25.n6.a5},\n}\n\t\t\t\n%\\bib{DWZ}{article}{\n%author={Du, D.},\n%author={Wu, Y.},\n%author={Zhang, K.},\n%title={On blow-up criterion for the nonlinear Schr\\\"{o}dinger equation},\n%journal={Discrete Contin. Dyn. Syst.},\n%volume={36},\n%date={2016},\n%number={7},\n%pages={3639--3650},\n%issn={1078-0947},\n%review={\\MR{3485846}},\n%doi={10.3934/dcds.2016.36.3639},\n%}\n\t\t\t\n%\\bib{Glassey}{article}{\n%\tauthor={Glassey, R. T.},\n%\ttitle={On the blowing up of solutions to the Cauchy problem for nonlinear\n%\t\tSchr\\\"{o}dinger equations},\n%\tjournal={J. Math. Phys.},\n%\tvolume={18},\n%\tdate={1977},\n%\tnumber={9},\n%\tpages={1794--1797},\n%\tissn={0022-2488},\n%review={\\MR{460850}},\n%doi={10.1063/1.523491},\n%}\n\t\t\n\\bib{Hamano}{article}{\nauthor={Hamano, M.},\ntitle={Global dynamics below the ground state for the quadratic Sch\\\"odinger system in 5d},\njournal={preprint},\neprint={https://arxiv.org/abs/1805.12245},\n}\n\t\t\t\n\\bib{HIN}{article}{\nauthor={Hamano, M.},\nauthor={Inui, T.},\nauthor={Nishimura, K.},\ntitle={Scattering for the quadratic nonlinear Schr\\\"odinger system in $\\mathbb R^5$ without mass-resonance condition},\njournal={preprint},\neprint={https://arxiv.org/abs/1903.05880},\n}\n\t\t\n\\bib{HOT}{article}{\nauthor={Hayashi, N.},\nauthor={Ozawa, T.},\nauthor={Tanaka, K.},\ntitle={On a system of nonlinear Schr\\\"{o}dinger equations with quadratic interaction},\njournal={Ann. Inst. H. Poincar\\'{e} Anal. Non Lin\\'{e}aire},\nvolume={30},\ndate={2013},\nnumber={4},\npages={661--690},\nissn={0294-1449},\n%review={\\MR{3082479}},\n%doi={10.1016/j.anihpc.2012.10.007},\n}\n\n\\bib{HR-CPDE}{article}{\nauthor={Holmer, J.},\nauthor={Roudenko, S.},\ntitle={Divergence of infinite-variance nonradial solutions to the 3D NLS\nequation},\njournal={Comm. Partial Differential Equations},\nvolume={35},\ndate={2010},\nnumber={5},\npages={878--905},\nissn={0360-5302},\n%review={\\MR{2753623}},\n%doi={10.1080/03605301003646713},\n}\t\n\n\\bib{Inui1}{article}{\nauthor={Inui, T.},\ntitle={Global dynamics of solutions with group invariance for the\nnonlinear Schr\\\"{o}dinger equation},\njournal={Commun. Pure Appl. Anal.},\nvolume={16},\ndate={2017},\nnumber={2},\npages={557--590},\nissn={1534-0392},\n%review={\\MR{3602576}},\n%doi={10.3934/cpaa.2017028},\n}\n\t\t\n\\bib{Inui2}{article}{\nauthor={Inui, {T.}},\ntitle={Remarks on the global dynamics for solutions with an infinite group invariance to the nonlinear Schr\\\"{o}dinger equation},\nconference={\ntitle={Harmonic analysis and nonlinear partial differential equations},},\nbook={series={RIMS K\\^{o}ky\\^{u}roku Bessatsu, B70},\npublisher={Res. Inst. Math. Sci. (RIMS), Kyoto},},\ndate={2018},\npages={1--32},\n%review={\\MR{3888580}},\n}\n\n\\bib{IKN-mass}{article}{\nauthor={Inui, T.},\nauthor={Kishimoto, N.},\nauthor={Nishimura, K.},\ntitle={Scattering for a mass critical NLS system below the ground state with and without mass-resonance condition},\njournal={Discrete Contin. Dyn. Syst.},\nvolume={39},\ndate={2019},\nnumber={11},\npages={6299--6353},\nissn={1078-0947},\n}\n\n\\bib{IKN-NA}{article}{\nauthor={Inui, {T.}},\nauthor={Kishimoto, {N.}},\nauthor={Nishimura, {K.}},\ntitle={Blow-up of the radially symmetric solutions for the quadratic nonlinear Schr\\\"{o}dinger system without mass-resonance},\njournal={Nonlinear Anal.},\nvolume={198},\ndate={2020},\npages={111895, 10},\nissn={0362-546X},\n%review={\\MR{4090442}},\n%doi={10.1016/j.na.2020.111895},\n}\n\t\t\t\t\t\t\t\n\\bib{KM}{article}{\nauthor={Kenig, C. E.},\nauthor={Merle, F.},\ntitle={Global well-posedness, scattering and blow-up for the energy-critical, focusing, nonlinear Schr\\\"odinger equation in the radial case},\njournal={Invent. Math.},\nvolume={166},\ndate={2006},\nnumber={3},\npages={645--675},\nissn={0020-9910},\n%review={\\MR{2257393}},\n%doi={10.1007/s00222-006-0011-4},\n}\n\n\\bib{Kiv}{article}{\nauthor={Kivshar, Y. S.}, \nauthor={Sukhorukova, A. A.}, \nauthor={Ostrovskayaa, E. A.}, \nauthor={Alexandera, T. J.}, \nauthor={Bang, O.}, \nauthor={Saltiel, S. M.}, \nauthor={Clausen, C. B.}, \nauthor={Christiansen, P. L.},\ntitle={Multi-component optical solitary waves},\njournal={Physica A: Statistical Mechanics and its Applications},\nvolume={288},\nnumber={1--4},\nyear={2000},\npages={152--173},\n}\n\n\\bib{KS}{article}{\nauthor={Koynov, K.},\nauthor={Saltiel, S.},\ntitle={Nonlinear phase shift via multistep $\\chi^{(2)}$ cascading},\njournal={Optics Communications},\nvolume={152},\nnumber={1},\npages={96--100},\nyear={1998},\n}\n\n\\bib{Mar}{article}{\nauthor={Martel, Y.},\ntitle={Blow-up for the nonlinear Schr\\\"{o}dinger equation in nonisotropic spaces},\njournal={Nonlinear Anal.},\nvolume={28},\ndate={1997},\nnumber={12},\npages={1903--1908},\nissn={0362-546X},\n%review={\\MR{1436360}},\n%doi={10.1016/S0362-546X(96)00036-3},\n}\n\n\\bib{NP-CCM}{article}{\nauthor={Noguera, N.},\nauthor={Pastor, {A.}},\ntitle = {A system of Schr\\\"odinger equations with general quadratic-type nonlinearities},\njournal = {Communications in Contemporary Mathematics (in press)},\n%volume = {0},\n%number = {0},\n%pages = {2050023},\nyear = {2020},\neprint = {https:doi.org/10.1142/S0219199720500236},\n}\n\n\\bib{NP-blow}{article}{\nauthor={Noguera, N.},\nauthor={Pastor, A.},\ntitle={Blow-up solutions for a system of Schr\\\"odinger equations with general quadratic type nonlinearities in dimensions five and six},\njournal={preprint},\neprint={https://arxiv.org/abs/2003.11103},\n}\n\t\t\t\n\\bib{NP-DPDE}{article}{\nauthor={Noguera , N.},\nauthor={Pastor, A.},\ntitle={On the dynamics of a quadratic Schr\\\"odinger system in dimension $n =5$},\njournal={Dynamics of Partial Differential Equations}\nyear={2020},\nvolume={17},\nnumber={1},\npages={1-17},\n%doi={10.4310/DPDE.2020.v17.n1.a1},\n}\n\t\t\t\n\\bib{OT-JDE}{article}{\nauthor={Ogawa , T.},\nauthor={Tsutsumi, Y.},\ntitle={Blow-up of $H^1$ solution for the nonlinear Schr\\\"{o}dinger equation},\njournal={J. Differential Equations},\nvolume={92},\ndate={1991},\nnumber={2},\npages={317--330},\nissn={0022-0396},\n%review={\\MR{1120908}},\n%doi={10.1016/0022-0396(91)90052-B},\n}\n\t\t\t\n%\\bib{OT-PAMS}{article}{\n%author={Ogawa, T.},\n%author={Tsutsumi, Y.},\n%title={Blow-up of $H^1$ solutions for the one-dimensional nonlinear Schr\\\"{o}dinger equation with critical power nonlinearity},\n%journal={Proc. Amer. Math. Soc.},\n%volume={111},\n%date={1991},\n%number={2},\n%pages={487--496},\n%issn={0002-9939},\n%review={\\MR{1045145}},\n%doi={10.2307/2048340},\n%}\n\t\t\t\n%\\bib{Strauss}{article}{\n%author={Strauss, W. A.},\n%title={Existence of solitary waves in higher dimensions},\n%journal={Comm. Math. Phys.},\n%volume={55},\n%date={1977},\n%number={2},\n%pages={149--162},\n%issn={0010-3616},\n%review={\\MR{454365}},\n%}\n\t\t\t\n\\bib{WY}{article}{\nauthor={Wang, H.},\nauthor={Yang, Q.},\ntitle={Scattering for the 5D quadratic NLS system without mass-resonance},\njournal={J. Math. Phys.},\nvolume={60},\ndate={2019},\nnumber={12},\npages={121508, 23},\nissn={0022-2488},\n%review={\\MR{4043361}},\n%doi={10.1063/1.5119293},\n}\n\t\t\t\n\\bib{Yoshida}{article}{\nauthor={Yoshida, N.},\ntitle={Master Thesis},\njournal={Osaka University},\nyear={2013},\n}\n\t\t\n\\end{biblist}\n\\end{bibdiv}\n\t\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:04:28", "yymm": "2010", "arxiv_id": "2010.14595", "url": "https://arxiv.org/abs/2010.14595", "source": "arxiv"}}
{"text": "% ------------------------------------------------------------------------------------------%\n\n\\documentclass[\n3p,\n%review,\n]{elsarticle}\n\n\\usepackage{pgfplots}\n\t\\pgfplotsset{compat=1.12}\n\\usepackage{tikz}\n \t\\usetikzlibrary{decorations.markings}\n \t\\usetikzlibrary{calc}\n\\usepackage{amsmath,amsthm,amssymb}\n\\usepackage{hyperref}\n\t\\hypersetup{pdfauthor=author}\n\\usepackage[capitalize]{cleveref}\n\t\\crefname{equation}{}{}\n\t\\crefformat{section}{\\textsection#2#1#3}\n\t\\crefformat{appendix}{\\textsection#2#1#3}\n\n\\theoremstyle{plain}\n\t\\newtheorem{mtheorem}{Theorem}\n\t\\renewcommand\\themtheorem{\\Alph{mtheorem}}\n\t\\newtheorem{theorem}{Theorem}[section]\n\t\\newtheorem{lemma}[theorem]{Lemma}\n\t\\newtheorem{proposition}[theorem]{Proposition}\n\t\\newtheorem{corollary}[theorem]{Corollary}\n\n\\theoremstyle{definition}\n\t\\newtheorem{definition}[theorem]{Definition}\n\t\\newtheorem{assumption}[theorem]{Assumption}\n\t\\newtheorem{remark}[theorem]{Remark}\n\t\\newtheorem{example}[theorem]{Example}\n\t\\newtheorem*{notation}{Notation}\n\t\\newenvironment{eg}{\\begin{footnotesize} \\begin{example}}{\\end{example}\\end{footnotesize}}\n\n\\newcommand{\\N}{\\mathbb{N}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\C}{\\mathbb{C}}\n\\newcommand{\\T}{\\mathbb{T}}\n\n\\newcommand{\\rL}{\\mathrm{L}}\n\\newcommand{\\rR}{\\mathrm{R}}\n\n\\newcommand{\\cA}{\\mathcal{A}}\n\\newcommand{\\cF}{\\mathcal{F}}\n\\newcommand{\\cB}{\\mathcal{B}}\n\\newcommand{\\cK}{\\mathcal{K}}\n\\newcommand{\\cH}{\\mathcal{H}}\n\n\\newcommand{\\sgn}{\\mathrm{sgn}\\,}\n\\newcommand{\\spa}{\\mathrm{span}\\,}\n\\newcommand{\\inner}[1]{\\left \\langle #1 \\right \\rangle}\n\\newcommand{\\wn}{\\mathrm{wn}}\n\\renewcommand{\\Re}{\\mathrm{Re}\\,}\n\\renewcommand{\\Im}{\\mathrm{Im}\\,}\n\\newcommand{\\ind}{\\mathrm{ind}\\,}\n\\newcommand{\\dis}{\\sigma_{\\mathrm{dis}}}\n\\newcommand{\\ess}{\\sigma_{\\mathrm{ess}}}\n\\newcommand{\\Arg}{\\mathrm{Arg}\\,}\n\n\\newcommand{\\textbi}[1]{\\textit{\\textbf{#1}}}\n\n% -----------------------------------------------------------------------------------------%\n\n%\\renewcommand{\\baselinestretch}{2} %Delete this later\n\\begin{document}\n\n\\begin{frontmatter}\n\n\\title{\nA Constructive Approach to Topological Invariants for One-dimensional Strictly Local Operators\n}\n\n\n\\author[Shinshu]{Yohei Tanaka\\corref{corresponding}}\n\\ead{20hs602a@shinshu-u.ac.jp}\n\n\\cortext[corresponding]{Corresponding author}\n\n\\address[Shinshu]{Division of Mathematics and Physics, Faculty of Engineering, Shinshu University, Wakasato, Nagano 380-8553, Japan}\n\n\\begin{abstract}\nIn this paper we shall focus on one-dimensional strictly local operators, the notion of which naturally arises in the context of discrete-time quantum walks on the one-dimensional integer lattice $\\Z.$ In particular, we give an elementary constructive approach to the following two topological invariants associated with such operators: Fredholm index and essential spectrum. As a direct application, we shall explicitly compute and fully classify these topological invariants for a well-known quantum walk model.\n\\end{abstract}\n\n\\begin{keyword}\nStrictly local operators \\sep Fredholm index \\sep Essential spectrum \\sep Toeplitz operators \\sep Quantum walks\n\\end{keyword}\n\\end{frontmatter}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n% New Section                                                                                                  %\n% ------------------------------------------------------------------------------------------------------------ %\n\\section{Introduction}\n\nThe underlying Hilbert space of this manuscript is $\\ell^2(\\Z, \\C^n)$ of square-summable $\\C^n$-valued sequences indexed by the set $\\Z$ of all integers. With the obvious orthogonal decomposition $\\ell^2(\\Z, \\C^n) = \\bigoplus_{j=1}^n \\ell^2(\\Z, \\C)$ in mind, we shall consider the following \\textit{finite} sum of operators;\n\\begin{equation}\n\\label{equation2: characterisation of strict locality}\nA\n=\n\\sum^k_{y=-k}\n\\begin{pmatrix}\na_{11}(y, \\cdot) L^{y} & \\dots & a_{1n}(y, \\cdot) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\na_{n1}(y, \\cdot) L^{y} & \\dots & a_{nn}(y, \\cdot) L^{y} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y, \\cdot) L^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y, \\cdot) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y, \\cdot) L^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y, \\cdot) L^{y} \\\\\n\\end{pmatrix},\n\\end{equation}\nwhere $L$ denotes the bilateral left-shift operator on $\\ell^2(\\Z, \\C)$ (see Equation \\cref{definition: bileteral shift} for definition) and where each $a_{ij}(y, \\cdot) = (a_{ij}(y, x))_{x \\in \\Z}$ is an arbitrary bounded $\\C$-valued sequence viewed as a multiplication operator on $\\ell^2(\\Z, \\C) = \\bigoplus_{x \\in \\Z} \\C.$ An operator the form \\cref{equation2: characterisation of strict locality} is known as a (one-dimensional) \\textbi{strictly local operator} \\cite[\\textsection 1.2]{Cedzich-Geib-Stahl-Velazquez-Werner-Werner-2018}. Such an operator naturally arises, for example, in the context of $n$-state quantum walks defined on the integer lattice $\\Z,$ where we regard $\\ell^2(\\Z, \\C^n)$ as the state Hilbert space of the walker. The purpose of this paper is to prove the following general theorem;\n\n\\begin{mtheorem}\n\\label{theorem: two-phase case}\nLet $A$ be a strictly local operator of the form \\cref{equation2: characterisation of strict locality} with the property that the following two-sided limits exist:\n\\begin{equation}\n\\label{equation: two-phase assumptions}\n\\tag{A1}\na_{ij}(y, \\pm \\infty) := \\lim_{x \\to \\pm \\infty} a_{ij}(y,x) \\in \\C, \\qquad i,j = 1, \\dots, n ,\\ -k \\leq y \\leq k.\n\\end{equation}\nLet\n\\begin{align}\n% ---------------------- %\n\\label{equation: definition of Apm}\n\\tag{A2}\nA(\\pm \\infty)\n&:=\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y, \\pm \\infty) L^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y, \\pm \\infty) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y, \\pm \\infty) L^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y, \\pm \\infty) L^{y} \\\\\n\\end{pmatrix}, \\\\\n% ---------------------- %\n\\label{equation: definition of hatA}\n\\tag{A3}\n\\hat{A}(z,\\pm \\infty)\n&:=\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y, \\pm \\infty) z^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y, \\pm \\infty) z^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y, \\pm \\infty) z^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y, \\pm \\infty) z^{y} \\\\\n\\end{pmatrix}, \\qquad z \\in \\T.\n\\end{align}\nThen the following assertions hold true:\n\\begin{enumerate}[(i)]\n\\item We have that $A$ is Fredholm if and only if $\\T \\ni z \\longmapsto \\det \\hat{A}(z,\\star) \\in \\C$ is nowhere vanishing on $\\T$ for each $\\star = \\pm \\infty.$ In this case, the Fredholm index of $A$ is given by\n\\begin{equation}\n\\label{equation: bulk-edge correspondence}\n\\tag{A4}\n\\ind(A) = \\wn \\left(\\det \\hat{A}(\\cdot,+\\infty) \\right) - \\wn \\left(\\det \\hat{A}(\\cdot, -\\infty) \\right),\n\\end{equation}\nwhere $\\wn \\left(\\det \\hat{A}(\\cdot, \\star) \\right)$ denotes the winding number of the function $\\T \\ni z \\longmapsto \\det \\hat{A}(z,\\star) \\in \\C$ with respect to the origin.\n\n\\item The essential spectrum of $A$ is given by\n\\begin{align}\n\\label{equation1: essential spectrum of two-phase operator}\n\\tag{A5}\n&\\ess(A) = \\ess(A(+ \\infty)) \\cup \\ess(A(- \\infty)), \\\\\n\\label{equation2: essential spectrum of two-phase operator}\n\\tag{A6}\n&\\ess(A(\\star)) = \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{A}(z,\\star)\\right), \\qquad \\star = \\pm \\infty.\n\\end{align}\n\\end{enumerate}\n\\end{mtheorem}\n\nNote that the Fredholm index and essential spectrum can be viewed as topological invariants in the sense that these are stable under compact perturbations as is well-known. \\cref{theorem: two-phase case} allows us to explicitly compute these topological invariants for strictly local operators, both of which depend only on the asymptotic values \\cref{equation: two-phase assumptions}. As we shall see in this article, \\cref{theorem: two-phase case}(i) can be viewed as an abstract version of the one-dimensional bulk-boundary correspondence (see, for example, \\cite[Corollary 4.3]{Cedzich-Geib-Grunbaum-Stahl-Velazquez-Werner-Werner-2018}). In the setting of discrete-time quantum walks, a standard approach to \\cref{theorem: two-phase case}(ii) involves the use of the discrete Fourier transform \\cref{equation: definition of hatA} and Weyl's criterion for the essential spectrum; see, for example, \\cite[Lemma 3.3]{Fuda-Funakawa-Suzuki-2017}, where the essential spectrum of the self-adjoint discriminant operator is determined via a certain spectral mapping theorem for quantum walks \\cite{Segawa-Suzuki-2016,Segawa-Suzuki-2019}. Weyl's criterion is capable of dealing with a wide range of perturbations that are not necessarily compact (see, for example, \\cite{Sasaki-Suzuki-2017}), but its usage is obviously restricted to normal operators, unlike \\cref{theorem: two-phase case}(ii).\n\n\nThis paper is organised as follows. Proof of \\cref{theorem: two-phase case} is given in \\cref{section: analysis of strictly local operators}. In particular, our proof of the index formula \\cref{equation: bulk-edge correspondence} is entirely motivated by \\cite{Matsuzawa-2020}, where the special case $n=1$ of the index formula is established by making use of the notion of Toeplitz operators with $\\C$-valued symbols. We show that \\cref{theorem: two-phase case}(ii) can be proved without relying on Weyl's criterion, if we allow Toeplitz operators to have $\\C^{n \\times n}$-valued symbols. The paper concludes with \\cref{section: examples}, where we explicitly compute and fully classify the \\textbi{Witten index} of a certain quantum walk model on $\\ell^2(\\Z,\\C^2)$ with the aid of \\cref{theorem: two-phase case}(i). This is the one-dimensional split-step quantum walk model considered in \\cite{Fuda-Funakawa-Suzuki-2017,Fuda-Funakawa-Suzuki-2018,Fuda-Funakawa-Suzuki-2019,Suzuki-Tanaka-2019,Matsuzawa-2020} with a modification that all parameters of the model depend freely on $\\Z.$ It is shown that this seemingly minor modification leads to the new index formula taking values from $\\{-2,-1,0,+1,+2\\},$ where the indices $\\pm 2$ do not appear in the existing literature \\cite{Suzuki-Tanaka-2019,Matsuzawa-2020}. This result turns out to be significant improvement, since the Witten index gives a lower bound for the number of \\textit{topologically protected bound states} in the sense of \\cref{section: topologically protected bound states}. As a direct application of \\cref{theorem: two-phase case}(ii), we shall also compute the essential spectrum of the associated time-evolution operator.\n\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\section*{Acknowledgements}\n\nThe author would like to thank the members of the Shinshu Mathematical Physics Group for extremely useful comments and discussions. In particular, his sincerely thanks goes to K.~Wada for pointing out that \\cite[Theorem 8]{Suzuki-Tanaka-2019} can be generalised to \\cref{lemma: wada decomposition}. He would also like to thank M.~Seki and K.~Asahara for carefully checking the manuscript. This research was supported by the Ministry of Education, Science, Sports and Culture, Grant-in-Aid for JSPS Fellows, 20J22684, 2020. This work was also partially supported by the Research Institute for Mathematical Sciences, an International Joint Usage/Research Center located in Kyoto University.\n\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n% New Section                                                                                                  %\n% ------------------------------------------------------------------------------------------------------------ %\n\\section{Analysis of Strictly Local Operators}\n\\label{section: analysis of strictly local operators}\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Notation and terminology}\nBy operators we shall always mean everywhere-defined bounded linear operators between Banach spaces throughout this paper. An operator $A$ on a Hilbert space $\\cH$ is said to be \\textbi{Fredholm}, if $\\ker A, \\ker A^*$ are finite-dimensional and if $A$ has a closed range. Given such $A,$ we define the \\textbi{Fredholm index} of $A$ by $\\ind(A) := \\dim \\ker A - \\dim \\ker A^*.$ It is well-known that the Fredholm index is invariant under compact perturbations. That is, given an operator $A$ on $\\cH$ and a compact operator $K$ on $\\cH,$ we have that $A$ is Fredholm if and only if so is $A + K,$ and in this case $\\ind(A) = \\ind(A + K).$ The (Fredholm) \\textbi{essential spectrum} of an operator $A$ on $\\cH$ is defined as the set $\\ess(A)$ of all $\\lambda \\in \\C,$ such that $A - \\lambda$ fails to be Fredholm. Note that  $\\ess(A)$ is also stable under compact perturbations.\n\nThe Hilbert space of all square-summable $\\C$-valued sequences $\\Psi = (\\Psi(x))_{x \\in \\Z}$ is denoted by the shorthand $\\ell^2(\\Z) := \\ell^2(\\Z,\\C).$ We have a natural orthogonal decomposition $\\ell^2(\\Z) = \\ell^2_\\rL(\\Z) \\oplus \\ell^2_\\rR(\\Z),$ where\n\\[\n\\ell^2_{\\rL}(\\Z) := \\{\\Psi \\in \\ell^2(\\Z) \\mid \\Psi(x) = 0 \\,\\, \\forall x \\geq 0 \\}, \\qquad\n\\ell^2_\\rR(\\Z) := \\{\\Psi \\in \\ell^2(\\Z) \\mid \\Psi(x) = 0 \\,\\, \\forall x < 0\\}.\n\\]\nThe orthogonal projections of $\\ell^2(\\Z)$ onto the above subspaces shall be denoted by $P_{\\rL}$ and $P_{\\rR} = 1 - P_{\\rL}$ respectively. For each $\\sharp  \\in \\{\\rL,\\rR\\},$ the orthogonal projection $P_{\\sharp}$ can be written as $P_{\\sharp} = \\iota_{\\sharp} \\iota_{\\sharp}^*,$ where $\\iota_{\\sharp} : \\ell^2_{\\sharp}(\\Z) \\hookrightarrow \\ell^2(\\Z)$ is the inclusion mapping. The left-shift operator $L$ on $\\ell^2(\\Z)$ is defined by\n\\begin{equation}\n\\label{definition: bileteral shift}\nL \\Psi := \\Psi(\\cdot + 1), \\qquad \\Psi \\in \\ell^2(\\Z).\n\\end{equation}\n\nLet $n \\in \\N$ be fixed throughout the current section. Any operator $A$ on $\\ell^2(\\Z, \\C^n) := \\bigoplus_{j=1}^n \\ell^2(\\Z)$ admits the following unique block-operator matrix representation;\n\\begin{equation}\n\\label{equation: standard representation of A}\nA =\n\\begin{pmatrix}\nA_{11} & \\dots & A_{1n} \\\\\n\\vdots & \\ddots& \\vdots \\\\\nA_{n1} & \\dots & A_{nn} \\\\\n\\end{pmatrix}_{\\bigoplus_{j=1}^n \\ell^2(\\Z)},\n\\end{equation}\nwhere each $A_{ij}$ is an operator on $\\ell^2(\\Z).$ We shall agree to use the shorthand $A = (A_{ij})$ to mean that \\cref{equation: standard representation of A} holds true. With this representation of $A$ in mind, for each $\\sharp  = \\rL, \\rR,$ we define the following operator on $\\ell^2_{\\sharp}(\\Z, \\C^n) := \\bigoplus_{j=1}^n \\ell^2_{\\sharp}(\\Z);$\n\\begin{equation}\n\\label{equation: matrix repesentation of contraction}\nA_{\\sharp} :=\n\\begin{pmatrix}\n\\iota_{\\sharp}^* A_{11}\\iota_{\\sharp} & \\dots & \\iota_{\\sharp}^* A_{1n}\\iota_{\\sharp} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\iota_{\\sharp}^* A_{n1}\\iota_{\\sharp} & \\dots & \\iota_{\\sharp}^* A_{nn}\\iota_{\\sharp} \\\\\n\\end{pmatrix}_{\\bigoplus_{j=1}^n \\ell_\\sharp^2(\\Z)}.\n\\end{equation}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Strictly local operators}\n\n\\begin{lemma}\n\\label{lemma: characterisation of strict locality}\nLet $(\\delta_x)_{x \\in \\Z}$ be the standard complete orthonormal basis for $\\ell^2(\\Z),$ and let $A$ be an operator on $\\ell^2(\\Z, \\C^n)$ with the block-operator matrix representation \\cref{equation: standard representation of A}. Then the following are equivalent:\n\\begin{enumerate}[(i)]\n\\item For each $i,j \\in \\{1, \\dots, n\\},$ the operator $A_{ij}$ is a finite sum of the form $A_{ij} = \\sum^k_{y=-k} a_{ij}(y, \\cdot)L^y$ for some $\\C$-valued sequences $a_{ij}(y, \\cdot) = (a_{ij}(y, x))_{x \\in \\Z},$ where $-k \\leq y \\leq k,$ viewed as multiplication operators on $\\ell^2(\\Z) = \\bigoplus_{x \\in \\Z} \\C.$\n\n\\item There exists a large enough positive integer $k,$ such that for each $x \\in \\Z$ and for each $i,j \\in \\{1, \\dots, n\\},$ the vector $A_{ij} \\delta_x \\in \\ell^2(\\Z)$ belongs to the linear span of the finite set $\\{ \\delta_{x-y} \\mid -k \\leq y \\leq k \\}.$\n\\end{enumerate}\n\\end{lemma}\nFollowing \\cite[\\textsection 1.2]{Cedzich-Geib-Stahl-Velazquez-Werner-Werner-2018}, any operator $A$ satisfying the above equivalent conditions shall be referred to as a \\textbi{strictly local operator} from here on. It follows from (i) that such $A$ admits a block-matrix representation of the form \\cref{equation2: characterisation of strict locality}.\n\\begin{proof}\nIt is obvious that (i) implies (ii), since $L^y \\delta_x  = \\delta_{x - y}$ for each $x,y \\in \\Z.$ This equality shall be repeatedly used throughout the current section. To prove the converse, let (ii) hold true, and let $i,j$ be both fixed. For each $x \\in \\Z,$ there exist finitely many scalars $a'_{ij}(y, x) \\in \\C,$ where $-k \\leq y \\leq k,$ such that\n\\begin{equation}\n\\label{equation3: characterisation of strict locality}\nA_{ij} \\delta_x = \\sum_{y=-k}^k a'_{ij}(y, x) \\delta_{x-y}.\n\\end{equation}\nNote that $a'_{ij}(y, \\cdot) = (a'_{ij}(y, x))_{x \\in \\Z}$ is a bounded sequence for $-k \\leq y \\leq k;$\n\\[\n|a'_{ij}(y, x)| = |\\inner{\\delta_{x - y}, A_{ij}\\delta_{x}}_{\\ell^2(\\Z)}| \\leq \\|A_{ij}\\| \\|\\delta_{x-y}\\|_{\\ell^2(\\Z)}  \\|\\delta_{x}\\|_{\\ell^2(\\Z)} \\leq \\|A_{ij}\\|, \\qquad x \\in \\Z.\n\\]\nLet $a_{ij}(y,x) := a'_{ij}(y, x + y)$ for each $x, y.$ Then we obtain the following equality for each $x \\in \\Z;$\n\\[\n\\sum^k_{y=-k} a_{ij}(y, \\cdot) L^{y} \\delta_x\n= \\sum^k_{y=-k} a_{ij}(y, \\cdot) \\delta_{x-y}\n= \\sum^k_{y=-k} a_{ij}(y, x-y) \\delta_{x-y}\n= \\sum^k_{y=-k} a'_{ij}(y, x) \\delta_{x-y}\n= A_{ij} \\delta_x,\n\\]\nwhere the last equality follows from \\cref{equation3: characterisation of strict locality}. That is, (i) holds true.\n\\end{proof}\n\n\n\\begin{corollary}\n\\label{corollary: properties of strictly local operators}\nIf $A$ is a strictly local operator on $\\ell^2(\\Z, \\C^n),$ then the difference $A - A_{\\rL} \\oplus A_{\\rR}$ is finite-rank. Moreover, the following assertions hold true:\n\\begin{enumerate}[(i)]\n\\item The operator $A$ is Fredholm if and only if $A_\\rL, A_{\\rR}$ are both Fredholm. In this case, we have\n\\begin{equation}\n\\label{equation: fredholm index of strictly local operators}\n\\ind(A) = \\ind(A_{\\rL}) + \\ind(A_{\\rR}).\n\\end{equation}\n\\item The essential spectrum of $A$ is given by\n\\begin{equation}\n\\label{equation: essential spectrum of strictly local operators}\n\\ess(A) = \\ess(A_{\\rL}) \\cup \\ess(A_{\\rR}).\n\\end{equation}\n\\end{enumerate}\n\\end{corollary}\n\\begin{proof}\nNote that $P := \\bigoplus_{j=1}^n P_{\\rR}$ is the orthogonal projection onto $\\ell_{\\rR}^2(\\Z, \\C^n) = \\bigoplus_{j=1}^n \\ell_{\\rR}^2(\\Z).$ We have\n\\[\nA -  A_{\\rL} \\oplus A_{\\rR}\n= PA(1 - P) + (1-P)AP\n= PA - PAP + AP - PAP\n= P[P,A] + [A,P]P,\n\\]\nwhere $[X,Y] := XY - YX$ denotes the commutator of two operators $X,Y.$ It remains to show that $[A,P]$ is finite-rank, where we may assume without loss of generality that $A$ is of the form \\cref{equation2: characterisation of strict locality}. Since $P = \\bigoplus_{j=1}^n P_{\\rR}$ is a diagonal block-operator matrix, we obtain\n\\[\n[A,P] =\n\\begin{pmatrix}\n\\left[\\sum^k_{y=-k} a_{11}(y, \\cdot) L^{y}, P_{\\rR}\\right]& \\dots & \\left[\\sum^k_{y=-k} a_{1n}(y, \\cdot) L^{y}, P_{\\rR} \\right] \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\left[\\sum^k_{y=-k} a_{n1}(y, \\cdot) L^{y}, P_{\\rR}\\right] & \\dots & \\left[\\sum^k_{y=-k} a_{nn}(y, \\cdot) L^{y}, P_{\\rR}\\right] \\\\\n\\end{pmatrix}.\n\\]\nSince $[-, P_{\\rR}]$ is linear with respect to the first variable, each $(i,j)$-entry of the above block-operator matrix is given by $\\sum^k_{y=-k}  a_{ij}(y, \\cdot) \\left[ L^{y}, P_{\\rR} \\right],$ where the commutator $\\left[ L^{y}, P_{\\rR} \\right]$ is finite-rank for $-k \\leq y \\leq k.$ It follows that $A - A_{\\rL} \\oplus A_{\\rR}$ is finite-rank, and so the remaining assertions immediately follow.\n\\end{proof}\n\n\nNote that a strictly local operator of the form \\cref{equation2: characterisation of strict locality} has the simplest formula, if each sequence $a_{ij}(y,\\cdot)$ is constant. Such an operator admits the following characterisation;\n\n\\begin{lemma}\n\\label{lemma: characterisation of uniformity}\nLet $A$ be an operator on $\\ell^2(\\Z)$ with the block-operator matrix representation \\cref{equation: standard representation of A}. Then the following are equivalent:\n\\begin{enumerate}[(i)]\n\\item For each $i,j \\in \\{1, \\dots, n\\},$ the operator $A_{ij}$ is a finite sum of the form $A_{ij} = \\sum^k_{y=-k} a_{ij}(y) L^y$ for some complex numbers $a_{ij}(y),$ where $-k \\leq y \\leq k.$ \n\n\\item The operator $A$ is strictly local and $[A_{ij}, L^x] = 0$ for each $x \\in \\Z$ and each $i,j \\in \\{1, \\dots, n\\}.$\n\\end{enumerate}\n\\end{lemma}\nThe operator $A$ is said to be \\textbi{uniform}, if it satisfies the above equivalent conditions. It follows from (i) that such $A$ admits a block-matrix representation of the following form;\n\\begin{equation}\n\\label{equation: characterisation of uniformity}\nA\n=\n\\sum^k_{y=-k}\n\\begin{pmatrix}\na_{11}(y) L^{y} & \\dots & a_{1n}(y) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\na_{n1}(y) L^{y} & \\dots & a_{nn}(y) L^{y} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y) L^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y) L^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y) L^{y} \\\\\n\\end{pmatrix}.\n\\end{equation}\n\n\n\\begin{proof}\nIt is obvious that (i) implies (ii). To prove the converse, let $A = (A_{ij})$ be strictly local, and let $[A_{ij}, L^x] = 0$ for each $x \\in \\Z$ and for each $i,j \\in \\{1, \\dots, n\\}.$ It follows from \\cref{lemma: characterisation of strict locality}(i) that for each $i,j \\in \\{1, \\dots, n\\}$ we have $A_{ij} = \\sum^k_{y=-k} a_{ij}(y,\\cdot) L^y.$ It remains to show that the sequence $a_{ij}(y, \\cdot) = (a_{ij}(y, x))_{x \\in \\Z}$ is constant for a fixed pair $i,j \\in \\{1, \\dots, n\\}.$ Since $A_{ij}\\delta_x = \\sum^k_{y=-k} a_{ij}(y,x-y) \\delta_{x-y}$ for each $x \\in \\Z,$ we get\n\\[\nA_{ij}\\delta_x\n= A_{ij} L^{-x} \\delta_0\n= L^{-x} A_{ij}  \\delta_0\n= L^{-x} \\left(\\sum^k_{y=-k} a_{ij}(y,-y) \\delta_{-y} \\right)\n= \\sum^k_{y=-k} a_{ij}(y,-y) \\delta_{x-y}.\n\\]\nIt follows that $a_{ij}(y,x-y) = a_{ij}(y,-y)$ for each $x \\in \\Z$ and for each $y \\in \\{-k, \\dots, k\\}.$ The claim follows.\n\\end{proof}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Uniform operators}\n\nThe following result is one of the main theorems of the current section;\n\\begin{theorem}\n\\label{theorem: uniform operators}\nLet $A$ be a uniform operator on $\\cH = \\ell^2(\\Z, \\C^n)$ of the form \\cref{equation: characterisation of uniformity}, and let\n\\begin{equation}\n\\label{equation: definition of f}\n\\hat{A}(z) :=\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y) z^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y) z^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y) z^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y) z^{y} \\\\\n\\end{pmatrix}, \\qquad z \\in \\T.\n\\end{equation}\nThen the following assertions hold true:\n\\begin{enumerate}[(i)]\n\\item The operator $A$ is Fredholm if and only if $A_\\rL, A_{\\rR}$ are both Fredholm if and only if $\\T \\ni z \\longmapsto \\det \\hat{A}(z) \\in \\C$ is nowhere vanishing on $\\T.$ In this case, we have $\\ind A = \\ind A_\\rR + \\ind A_\\rL = 0,$ and\n\\[\n\\ind A_{\\rR} = \\wn \\left(\\det \\hat{A} \\right).\n\\]\n\n\\item The essential spectrum of $A$ is given by\n\\begin{equation}\n\\label{equation: essential spectra of toeplitz operators}\n\\ess(A) = \\ess(A_{\\rL}) = \\ess(A_{\\rR})\n= \\bigcup_{z \\in \\T}\n\\sigma (\\hat{A}(z)).\n\\end{equation}\n\\end{enumerate}\n\\end{theorem}\n\nA proof of \\cref{theorem: uniform operators} shall be given at the end of the current subsection. Let us first recall the notion of Toeplitz operators. Let $L^2(\\T)$ be the Hilbert space of square-summable functions on the unit-circle $\\T,$ where $\\T$ is endowed with the normalised arc-length measure. It is well-known that $L^2(\\T)$ admits the standard complete orthonormal basis $(e_x)_{x \\in \\Z},$ where each $e_x$ is defined by $\\T \\ni z \\longmapsto z^x \\in \\C.$ The \\textbi{Hardy-Hilbert space} $\\mathrm{H}^2$ is the closure of the linear span of the set $\\{e_x \\mid x \\geq 0\\}.$ Let $\\iota : \\mathrm{H}^2 \\hookrightarrow L^2(\\T)$ be the inclusion mapping, and let $f \\in \\C(\\T).$  Then the \\textbi{Toeplitz operator} $T_f$ with symbol $f$ is defined by\n\\begin{equation}\n\\label{equation: definition of toeplitz operator}\nT_f := \\iota^* M_f \\iota,\n\\end{equation}\nwhere $M_f : L^2(\\T) \\to L^2(\\T)$ is the multiplication operator by $f.$ More generally, let us consider the Banach space $C(\\T, \\C^{n \\times n})$ of continuous matrix-valued functions on $\\T.$ Given a function $F \\in C(\\T, \\C^{n \\times n})$ of the form $F(z) = (f_{ij}(z))$ for each $z \\in \\T,$ the Toeplitz operator with symbol $F$ is defined by\n\\begin{equation}\n\\label{equation: definition of toeplitz operator with matrix-valued symbol}\nT_F :=\n\\begin{pmatrix}\nT_{f_{11}} & \\dots & T_{f_{1n}} \\\\\n\\vdots & \\ddots & \\vdots\\\\\nT_{f_{n1}} & \\dots & T_{f_{nn}}\n\\end{pmatrix}_{\\bigoplus_{j=1}^n \\mathrm{H}^2}.\n\\end{equation}\nThe following result is standard;\n\n%\\label{equation: definition of fij}\n%f_{ij}(z) &=  \\sum^k_{y=-k} a_{ij}(y) z^{y}, \\qquad z \\in \\T, \\\\\n\n\\begin{theorem}\n\\label{theorem: Gohberg-Krein}\nLet $F \\in C(\\T, \\C^{n \\times n})$ be a matrix-valued function of the form $F(\\cdot) = (f_{ij}(\\cdot)),$ and let $T_F$ be the corresponding Toeplitz operator given by \\cref{equation: definition of toeplitz operator with matrix-valued symbol}. Then the following assertions hold true:\n\\begin{enumerate}[(i)]\n\\item The Toeplitz operator $T_F$ is Fredholm if and only if $\\T \\ni z \\longmapsto \\det F(z) \\in \\C$ is nowhere vanishing on $\\T.$ In this case,\n\\begin{equation}\n\\label{equation: fredholm index of matrix toeplitz operator}\n\\ind T_F = - \\wn(\\det F).\n\\end{equation}\n\n\\item The essential spectrum of $T_F$ is given by\n\\begin{equation}\n\\label{equation: essential spectrum of matrix toeplitz operator}\n\\ess(T_F) = \\bigcup_{z \\in \\T} \\sigma(F(z)).\n\\end{equation}\n\\end{enumerate}\n\\end{theorem}\n\\begin{proof}\nNote that (i) is the celebrated theorem of Gohberg-Krein (see, for example, \\cite[Theorem 3.3]{Murphy-2006}). It remains to prove (ii). Let $\\cB_n(\\mathrm{H}^2) := \\cB \\left(\\bigoplus_{j=1}^n \\mathrm{H}^2\\right)$ be the $C^*$-algebra of operators on $\\bigoplus_{j=1}^n \\mathrm{H}^2,$ and let $\\cK_n(\\mathrm{H}^2) := \\cK \\left(\\bigoplus_{j=1}^n \\mathrm{H}^2\\right)$ be the ideal of compact operators on $\\bigoplus_{j=1}^n \\mathrm{H}^2.$ Let $\\cA_n(\\mathrm{H}^2)$ be the closed $*$-subalgebra of $\\cB_n(\\mathrm{H}^2)$ generated by $\\{T_F \\mid F \\in  C(\\T, \\C^{n \\times n})\\}.$ It is a well-known result that the following mapping is $*$-isomorphic (see, for example, \\cite[\\textsection 1]{Douglas-1973});\n\\[\nC(\\T, \\C^{n \\times n}) \\ni F \\longmapsto [T_F] \\in \\cA_n(\\mathrm{H}^2) / \\cK_n(\\mathrm{H}^2).\n\\]\nThat is, for each $F \\in C(\\T, \\C^{n \\times n})$ we have that $F$ is invertible in $C(\\T, \\C^{n \\times n})$ if and only if $[T_F]$ is invertible in the Calkyin algebra $\\cB_n(\\mathrm{H}^2) / \\cK_n(\\mathrm{H}^2).$ The equality \\cref{equation: essential spectrum of matrix toeplitz operator} follows.\n\\end{proof}\n\nLet us consider two unitary operators $\\cF_{\\rL} :  \\mathrm{H}^2 \\to \\ell^2_{\\rL}(\\Z)$ and $\\cF_{\\rR} : \\mathrm{H}^2 \\to \\ell^2_{\\rR}(\\Z)$ defined respectively by\n\\[\n\\cF_{\\rL} e_x := \\delta_{-x-1}, \\qquad \\cF_{\\rR}e_x  := \\delta_x, \\qquad x \\geq 0,\n\\]\nwhere $(\\delta_x)_{x \\in \\Z}, (e_x)_{x \\in \\Z}$ are the standard bases of $\\ell^2(\\Z), \\mathrm{H}^2$ respectively.\n\n\\begin{lemma}\n\\label{lemma: fourier transform of compression is toeplitz operator}\nLet $A$ be a uniform operator on $\\cH = \\ell^2(\\Z, \\C^n)$ of the form \\cref{equation: characterisation of uniformity}, and let $\\hat{A}$ be given by \\cref{equation: definition of f}. Then\n\\begin{equation}\n\\label{equation: essential spectra of uniform operators}\n\\left(\\bigoplus_{j=1}^n \\cF^*_{\\sharp} \\right) A_{\\sharp} \\left(\\bigoplus_{j=1}^n \\cF_{\\sharp} \\right)\n=\n\\begin{cases}\nT_{\\hat{A}}, & \\sharp = \\rL, \\\\\nT_{\\hat{A}(-^{*})}, & \\sharp = \\rR,\n\\end{cases}\n\\end{equation}\nwhere $\\hat{A}(-^{*})$ denote the matrix-valued function $\\T \\ni z \\longmapsto \\hat{A}(z^{*}) \\in \\C^{n \\times n}.$\n\\end{lemma}\n\\begin{proof}\nNote first that the inverses of $\\cF_{\\rL}, \\cF_{\\rR}$ are given respectively by $\\cF_{\\rL}^{-1} \\delta_x = \\cF_{\\rL}^{*} \\delta_x = e_{-x-1}$ for each $x < 0$ and $\\cF_{\\rR}^{-1} \\delta_x = \\cF_{\\rR}^{*} \\delta_x = e_x$ for each $x \\geq 0.$ Let us first prove the following non-trivial equalities:\n\\begin{equation}\n\\label{equaton: fourier transform of compression}\nT_{e_y} = \\cF_{\\rL}^{*}\\iota_{\\rL}^* L^{y} \\iota_{\\rL} \\cF_{\\rL} =  \\cF_{\\rR}^{*}\\iota_{\\rR}^* L^{-y} \\iota_{\\rR} \\cF_{\\rR} , \\qquad y \\in \\Z.\n\\end{equation}\nNote that for each $y \\geq 0$ each $x \\geq 0$ we have\n\\begin{align*}\n&T_{e_y} e_x\n= \\iota^* M_{e_y} \\iota e_x\n= \\iota^* M_{e_y} e_x\n= \\iota^* e_{x+y}\n= e_{x+y}, \\\\\n% ---------------------- %\n&\\cF_{\\rL}^{*} \\iota_{\\rL}^* L^{y} \\iota_{\\rL} \\cF_{\\rL} e_x\n=\\cF_{\\rL}^{*} \\iota_{\\rL}^* L^{y} \\iota_{\\rL} \\delta_{-x-1}\n=\\cF_{\\rL}^{*}\\iota_{\\rL}^* \\delta_{-x-y-1}\n= e_{x+y}, \\\\\n% ---------------------- %\n&\\cF_{\\rR}^{*} \\iota_{\\rR}^* L^{-y} \\iota_{\\rR} \\cF_{\\rR} e_x\n= \\cF_{\\rR}^{*} \\iota_{\\rR}^* L^{-y} \\iota_{\\rR} \\delta_x\n= \\cF_{\\rR}^{*} \\iota_{\\rR}^* \\delta_{x+y}\n= e_{x+y}.\n\\end{align*}\nThat is, we have shown that \\cref{equaton: fourier transform of compression} holds true for any $y \\geq 0.$ On the other hand, if $y < 0,$ then $-y > 0,$ and so\n\\[\nT_{e_y} = (T_{e_{-y}})^*\n= (\\cF_{\\rL}^{*} \\iota_{\\rL}^* L^{-y} \\iota_{\\rL} \\cF_{\\rL})^*\n=\n(\\cF_{\\rR}^{*} \\iota_{\\rR}^* L^{y} \\iota_{\\rR} \\cF_{\\rR})^* , \\qquad y < 0.\n\\]\nThat is, \\cref{equaton: fourier transform of compression} holds true for any $y \\in \\Z.$ Let\n\\[\nf_{ij}(z) \n:=  \\sum^k_{y=-k} a_{ij}(y) z^{y}\n=  \\sum^k_{y=-k} a_{ij}(y) e_{y}(z), \\qquad z \\in \\T.\n\\]\nThen the block-operator matrix representation of $A$ is given by\n\\[\nA =\n\\begin{pmatrix}\n\\sum^k_{y=-k} a_{11}(y) L^{y} & \\dots & \\sum^k_{y=-k} a_{1n}(y) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} a_{n1}(y) L^{y} & \\dots & \\sum^k_{y=-k} a_{nn}(y) L^{y} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nf_{11}(L) & \\dots & f_{1n}(L) \\\\\n\\vdots & \\ddots &  \\vdots\\\\\nf_{n1}(L) & \\dots & f_{nn}(L)\n\\end{pmatrix}.\n\\]\nWith the representation \\cref{equation: matrix repesentation of contraction} in mind, we obtain\n\\[\n\\left(\\bigoplus_{j=1}^n \\cF_{\\sharp}^* \\right) A_{\\sharp} \\left(\\bigoplus_{j=1}^n \\cF_{\\sharp} \\right)\n =\n\\begin{pmatrix}\n\\cF_{\\sharp}^* \\iota^*_{\\sharp}  f_{11}(L) \\iota_{\\sharp} \\cF_{\\sharp} & \\dots &  \\cF_{\\sharp}^* \\iota^*_{\\sharp}  f_{1n}(L)\\iota_{\\sharp}\\cF_{\\sharp}  \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\cF_{\\sharp}^* \\iota^*_{\\sharp} f_{n1}(L) \\iota_{\\sharp} \\cF_{\\sharp}& \\dots &  \\cF_{\\sharp}^* \\iota^*_{\\sharp} f_{nn}(L)\\iota_{\\sharp} \\cF_{\\sharp}\n\\end{pmatrix}_{\\bigoplus_{j=1}^n \\mathrm{H}^2}, \\qquad \\sharp =\\rL, \\rR,\n\\]\nwhere \\cref{equaton: fourier transform of compression} gives the following equalities for each $i,j \\in \\{1, \\dots, n\\}:$\n\\[\n\\cF_{\\sharp}^* \\iota^*_{\\sharp} f_{ij}(L) \\iota_{\\sharp} \\cF_{\\sharp}\n= \\sum^k_{y=-k} a_{ij}(y) (\\cF_{\\sharp}^* \\iota_{\\sharp}^*  L^{y} \\iota_{\\sharp} \\cF_{\\sharp})\n=\n\\begin{cases}\n\\sum^k_{y=-k} a_{ij}(y) T_{e_y} = T_{f_{ij}}, & \\sharp = \\rL, \\\\\n\\sum^k_{y=-k} a_{ij}(y) T_{e_y}^* = T_{f_{ij}(-^{*})}, &\\sharp = \\rR.\n\\end{cases}\n\\]\nIt follows that \\cref{equation: essential spectra of uniform operators} holds true, since the Toeplitz operator $T_{\\hat{A}}$ is given by \\cref{equation: definition of toeplitz operator with matrix-valued symbol} with $F := \\hat{A}.$\n\\end{proof}\n\n\n\\begin{proof}[Proof of \\cref{theorem: uniform operators}]\nLet $A$ be a uniform operator on $\\cH = \\ell^2(\\Z, \\C^n)$ of the form \\cref{equation: characterisation of uniformity}, and let $\\hat{A}$ be given by \\cref{equation: definition of f}. It follows from \\cref{equation: essential spectra of uniform operators} that $A_\\rL \\cong T_{\\hat{A}}$ and $A_\\rR \\cong T_{\\hat{A}(-^*)},$ where $\\cong$ denotes unitary equivalence. The Fredholmness and essential spectra are invariant under unitary transforms. \n\n(i) It follows from \\cref{corollary: properties of strictly local operators} (i) that the operator $A$ is Fredholm if and only if $A_\\rL \\cong T_{\\hat{A}}, A_{\\rR} \\cong T_{\\hat{A}(-^*)}$ are both Fredholm, and in this case we have $\\ind A = \\ind T_{\\hat{A}} + \\ind T_{\\hat{A}(-^*)}.$ On the other hand, it follows from \\cref{theorem: Gohberg-Krein}(i) that $A_\\rL \\cong T_{\\hat{A}}$ is Fredholm if and only if $A_{\\rR} \\cong T_{\\hat{A}(-^*)}$ is Fredholm if and only if $\\det \\hat{A}$ is nowhere vanishing. In this case, we have $\\ind A_\\rL = -\\wn \\left(\\det \\hat{A}\\right)$ and $\\ind A_\\rR = -  \\wn \\left(\\det \\hat{A}(-^*)\\right).$ Therefore,\n\\[\n\\ind A\n= \\ind A_\\rL + \\ind A_\\rR\n= -\\wn \\left(\\det \\hat{A}\\right) -  \\wn \\left(\\det \\hat{A}(-^*)\\right)\n= -\\wn \\left(\\det \\hat{A}\\right) + \\wn \\left(\\det \\hat{A} \\right) \n= 0.\n\\]\n\n\n(ii) It follows from \\cref{corollary: properties of strictly local operators} (ii) that $\\ess(A) = \\ess(A_{\\rL}) \\cup \\ess(A_{\\rR}),$ where $A_\\rL \\cong T_{\\hat{A}}, A_{\\rR} \\cong T_{\\hat{A}(-^*)}.$ It follows from \\cref{theorem: Gohberg-Krein}(ii) that\n\\[\n\\ess(A_\\rL) = \\ess(T_{\\hat{A}}) = \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{A}(z)\\right) = \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{A}(z^*) \\right) = \\ess\\left(T_{\\hat{A}(-^*)}\\right) = \\ess(A_\\rR),\n\\]\nwhere the third equality follows from the fact that the ranges of $\\hat{A}, \\hat{A}(-^*)$ are identical.\n\\end{proof}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Proof of Theorem A}\n\nWe are now in a position to prove \\cref{theorem: two-phase case} with the aid of the following lemma;\n\n\\begin{lemma}\n\\label{lemma: theorem A}\nUnder the assumption of \\cref{theorem: two-phase case}, the difference $A_{\\rL} \\oplus A_{\\rR} - A(-\\infty)_{\\rL} \\oplus A(+\\infty)_{\\rR}$ is compact.\n\\end{lemma}\nIt follows that $A_{\\rL} - A(-\\infty)_{\\rL}, A_{\\rR} - A(+\\infty)_{\\rR}$ are both compact.\n\\begin{proof}\nLet $P_{+\\infty} := \\bigoplus_{j=1}^n P_{\\rR},$ and let $P_{-\\infty} := \\bigoplus_{j=1}^n P_{\\rL}.$ We have\n\\begin{align*}\nA_{\\rL} \\oplus A_{\\rR} - A(-\\infty)_{\\rL} \\oplus A(+\\infty)_{\\rR}\n&= A_{\\rL} \\oplus 0 + 0 \\oplus A_{\\rR} - (A(-\\infty)_{\\rL} \\oplus 0 + 0 \\oplus A(+\\infty)_{\\rR}) \\\\\n&= P_{-\\infty}AP_{-\\infty} +  P_{+\\infty}AP_{+\\infty} - (P_{-\\infty} A(-\\infty) P_{-\\infty} +  P_{+\\infty}A(+\\infty)P_{+\\infty}) \\\\\n&=P_{-\\infty}(A - A(-\\infty))P_{-\\infty} +  P_{+\\infty}(A - A(+\\infty))P_{+\\infty}.\n\\end{align*}\nIt remains to show that $B(\\star) := P_{\\star}(A -  A(\\star))P_{\\star}$ is compact for each $\\star = \\pm \\infty.$ We have\n\\[\nB(\\star) =\nP_{\\star}\n\\begin{pmatrix}\n\\sum^k_{y=-k} (a_{11}(y, \\cdot) - a_{11}(y, \\star)) L^{y} & \\dots & \\sum^k_{y=-k} (a_{1n}(y, \\cdot) - a_{1n}(y, \\star)) L^{y} \\\\\n\\vdots & \\ddots& \\vdots \\\\\n\\sum^k_{y=-k} (a_{n1}(y, \\cdot) - a_{n1}(y, \\star)) L^{y} & \\dots & \\sum^k_{y=-k} (a_{nn}(y, \\cdot) - a_{nn}(y, \\star)) L^{y} \\\\\n\\end{pmatrix}\nP_{\\star}.\n\\]\nIf $B(\\star) = (B_{ij}(\\star))$ is the block-operator matrix representation of $B,$ then\n\\begin{equation}\n\\label{equation: definition of Bij}\nB_{ij}(\\star) =\n\\begin{cases}\n\\sum^k_{y=-k} P_{\\rR}(a_{ij}(y, \\cdot) - a_{ij}(y, +\\infty)) L^{y} P_{\\rR}, & \\star = +\\infty, \\\\\n\\sum^k_{y=-k} P_{\\rL}(a_{ij}(y, \\cdot) - a_{ij}(y, -\\infty)) L^{y} P_{\\rL}, & \\star = -\\infty.\n\\end{cases}\n\\end{equation}\nNote that the projection $P_{\\rR}$ on $\\ell^2(\\Z) = \\bigoplus_{x \\in \\Z} \\C$ is a multiplication operator of the form $P_{\\rR} = \\bigoplus_{x \\in \\Z} \\delta_{\\rR}(x),$ where $\\delta_{\\rR}(x) := 1$ for each $x \\geq 0$ and $\\delta_{\\rR}(x) := 0$ for each $x < 0.$ That is, for each $y \\in \\{-k, \\dots, k\\},$\n\\begin{align*}\n&P_{\\rR}(a_{ij}(y, \\cdot) - a_{ij}(y, +\\infty)) = \\bigoplus_{x \\in \\Z} \\delta_{\\rR}(x)(a_{ij}(y, x) - a_{ij}(y, +\\infty)), \\\\\n&\\lim_{x \\to \\pm \\infty}  \\delta_{\\rR}(x)(a_{ij}(y, x) - a_{ij}(y, +\\infty)) = 0.\n\\end{align*}\nIt follows that $P_{\\rR}(a_{ij}(y, \\cdot) - a_{ij}(y, +\\infty))$ is compact for each $i,j,y,$ and so $B_{ij}(+\\infty)$ given by \\cref{equation: definition of Bij} is compact. Hence, $B(+\\infty) = (B_{ij}(+\\infty))$ is compact. An analogous argument can be used to show that $B(-\\infty) = (B_{ij}(-\\infty))$ is compact. The claim follows.\n\\end{proof}\n\n\n\\begin{proof}[Proof of \\cref{theorem: two-phase case}]\nUnder the assumption of \\cref{theorem: two-phase case}, it follows from \\cref{corollary: properties of strictly local operators} and \\cref{lemma: theorem A} that $A - A(-\\infty)_{\\rL} \\oplus A(+\\infty)_{\\rR}$ is compact, where $A(-\\infty), A(+\\infty)$ are uniform operators.\n\n(i) We shall make use of \\cref{theorem: uniform operators} (i). We have that $A$ is Fredholm if and only if $A(-\\infty)_{\\rL}, A(+\\infty)_{\\rR}$ are Fredholm if and only if $\\hat{A}(\\cdot, \\star)$ is nowhere vanishing on $\\T$ for each $\\star = \\pm \\infty.$ In this case, we have\n\\begin{align*}\n\\ind A\n= \\ind A(-\\infty)_{\\rL} + \\ind A(+\\infty)_{\\rR} \n= -\\wn\\left(\\hat{A}(\\cdot,-\\infty)\\right) + \\wn\\left(\\hat{A}(\\cdot,+\\infty) \\right).\n\\end{align*}\n\n(ii) We shall make use of \\cref{theorem: uniform operators} (ii). We have\n\\[\n\\ess(A)\n= \\ess(A(-\\infty)_{\\rL}) \\cup \\ess(A(+\\infty)_{\\rR})\n= \\ess(A(-\\infty)) \\cup \\ess(A(+\\infty)),\n\\]\nwhere each $\\ess(A(\\pm \\infty))$ is given by the formula \\cref{equation2: essential spectrum of two-phase operator}.\n\\end{proof}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n% New Section                                                                                                  %\n% ------------------------------------------------------------------------------------------------------------ %\n\\section{Applications of Theorem A}\n\\label{section: examples}\n\nQuantum walk theory is a quantum-mechanical counterpart of the classical random walk theory, and it constitutes a vast multidisciplinary branch of modern Science. Certain primitive forms of this ubiquitous notion can be found, for example, in \\cite{Gudder-1988,Aharonov-Davidovich-Zagury-1993,Meyer-1996,Ambainis-Bach-Nayak-Vishwanath-Watrous-2001}. Mathematically rigorous studies of discrete-time quantum walks include: scattering-theoretic analysis \\cite{Suzuki-2016,Richard-Suzuki-Tiedra-2017,Richard-Suzuki-Tiedra-2018,Morioka-2019,Wada-2020}, non-linear analysis \\cite{Maeda-Sasaki-Segawa-Suzuki-Suzuki-2018a,Maeda-Sasaki-Segawa-Suzuki-Suzuki-2018b,Maeda-Sasaki-Segawa-Suzuki-Suzuki-2019}, \nlocalisation and weak-limit theorems \\cite{Konno-2002,Inui-Konishi-Konno-2004,Segawa-2011,Cantero-Grunbaum-Moral-Velazquez-2012,Suzuki-2016,Fuda-Funakawa-Suzuki-2018,Fuda-Funakawa-Suzuki-2019}, classification theorems \\cite{Ohno-2016,Ohno-2017,Cedzich-Geib-Grunbaum-Stahl-Velazquez-Werner-Werner-2018}, discrete analogues of the time-operator \\cite{Sambou-Tiedra-2019,Funakawa-Matsuzawa-Sasaki-Suzuki-Teranishi-2020}, and index theorems \\cite{Cedzich-Geib-Stahl-Velazquez-Werner-Werner-2018,Suzuki-Tanaka-2019,Matsuzawa-2020}.\n\n\nIn this section we shall give a new index theorem in align with the setting of \\cite{Cedzich-Geib-Grunbaum-Stahl-Velazquez-Werner-Werner-2018,Cedzich-Geib-Stahl-Velazquez-Werner-Werner-2018,Suzuki-Tanaka-2019,Matsuzawa-2020} as a direct application of \\cref{theorem: two-phase case}(i). More precisely, we consider a concrete quantum walk model defined on the underlying Hilbert space $\\ell^2(\\Z, \\C^2),$ which unifies all of the following models: the one-dimensional quantum walk considered in \\cite{Ambainis-Bach-Nayak-Vishwanath-Watrous-2001,Konno-2002,Suzuki-2016}, Kitagawa's split-step quantum walk \\cite{Kitagawa-Rudner-Berg-Demler-2010,Kitagawa-Broome-Fedrizzi-Rudner-Berg-Kassal-Aspuru-Demler-White-2012,Kitagawa_2012}, another split-step quantum walk in  \\cite{Fuda-Funakawa-Suzuki-2017,Fuda-Funakawa-Suzuki-2018,Fuda-Funakawa-Suzuki-2019,Suzuki-Tanaka-2019,Matsuzawa-2020}. We compute the following two associated topological invariants: (i) a certain well-defined Fredholm index known as the \\textbi{Witten index}, and (ii) the essential spectrum of the evolution operator. The complete classification of these invariants can be found in \\cref{theorem: split-step}(i),(ii) respectively. The precise statement of \\cref{theorem: split-step}, including the definition of the model, appears in \\cref{section: statement of the main theorem}. Proofs of \\cref{theorem: split-step}(i),(ii) will be given in \\cref{section: fredholm index},\\cref{section: essential spectrum} respectively. This paper concludes with several remarks in \\cref{section: concluding remarks}.\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Statement of the main theorem (Theorem B)}\n\\label{section: statement of the main theorem}\n\nWhat follows is a brief overview of \\cite[\\textsection 2]{Suzuki-2019} and \\cite[\\textsection 2.1]{Suzuki-Tanaka-2019}. An operator $\\varGamma$ defined on an abstract Hilbert space $\\cH$ is called an \\textbi{involution}, if $\\varGamma^2 = 1,$ where $1$ denotes the identity operator on $\\cH.$ Note first that any unitary involution is self-adjoint (in fact, if an operator possess any two of the properties ``self-adjoint'', ``unitary'', ``involutory'', then it automatically has the third). The two operators $-1,1$ are referred to as \\textbi{trivial unitary involutions}. We have $\\cH = \\ker(\\varGamma - 1) \\oplus \\ker(\\varGamma + 1)$ for any unitary involution $\\varGamma.$ The model we shall consider in this section is based on the following simple finite-dimensional example;\n\n\\begin{eg}\n\\label{example: unitary involution}\nIf $X$ denotes a $2 \\times 2$ matrix viewed as an operator on $\\C^2,$ then $X$ is a non-trivial unitary involution if and only if there exist $\\alpha \\in \\R$ and $\\beta \\in \\C$ satisfying the following equalities:\n\\begin{equation}\n\\label{equation: unitary involutory matric}\nX =\n\\begin{pmatrix}\n\\alpha & \\beta \\\\\n\\beta^* & -\\alpha\n\\end{pmatrix}, \\qquad \\alpha^2 + |\\beta|^2 = 1.\n\\end{equation}\nNote that the spectrum of such a matrix $X$ is $\\{1,-1\\},$ and so the following diagonalisation is possible;\n\\begin{equation}\n\\label{equation: diagonalisation of unitary involutory matrix}\n\\eta^*\n\\begin{pmatrix}\n\\alpha & \\beta \\\\\n\\beta^* & -\\alpha\n\\end{pmatrix}\n\\eta\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}, \\qquad\n\\eta :=\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{-i\\Theta}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha_+ & -\\alpha_- \\\\\n\\alpha_-   & \\alpha_+\n\\end{pmatrix},\n\\end{equation}\nwhere $\\Theta$ is any real number satisfying $\\beta = e^{i \\Theta} |\\beta|$ and $\\alpha_\\pm := \\sqrt{1 \\pm \\alpha}.$ Note that $\\eta$ is unitary.\n\\end{eg}\n\nA \\textbi{chiral pair} on $\\cH$ is any pair $(\\varGamma, \\varGamma')$ of two unitary involutions $\\varGamma, \\varGamma'$ on $\\cH.$ Given such a pair $(\\varGamma, \\varGamma'),$ the operator $U := \\varGamma \\varGamma'$ is called the \\textbi{evolution operator} of $(\\varGamma, \\varGamma').$ Let $R, Q$ be the real and imaginary parts of $U$ respectively:\n\\[\nR := \\Re U = \\frac{U + U^*}{2} = \\frac{\\{ \\varGamma, \\varGamma' \\}}{2}, \\qquad\nQ := \\Im U = \\frac{U - U^*}{2i} = \\frac{[ \\varGamma, \\varGamma']}{2i},\n\\]\nwhere $\\{X,Y\\} := XY + YX$ and $[X,Y] := XY - YX.$ Note that the evolution operator $U$ satisfies the following \\textbi{chiral symmetry conditions} with respect to $\\varGamma, \\varGamma'$ respectively:\n\\begin{align}\n\\label{equation: chiral symmetry}\nU^* = \\varGamma' \\varGamma = \\varGamma^2 \\varGamma' \\varGamma = \\varGamma (\\varGamma \\varGamma')\\varGamma = \\varGamma U \\varGamma, \\qquad\nU^* = \\varGamma' \\varGamma = \\varGamma' \\varGamma (\\varGamma')^2 = \\varGamma' (\\varGamma \\varGamma') \\varGamma' = \\varGamma' U \\varGamma'.\n\\end{align}\nThe above equality immediately implies the commutation relations $[\\varGamma, R] = [\\varGamma', R] = 0$ and anti-commutation relations $\\{\\varGamma, Q\\} = \\{\\varGamma', Q\\} = 0,$ and so $R, Q, U$ admit the following block-operator matrix representations with respect to $\\cH = \\ker(\\varGamma - 1) \\oplus \\ker(\\varGamma + 1)  = \\ker(\\varGamma' - 1) \\oplus \\ker(\\varGamma' + 1):$\n\\begin{align}\n% ------------------------- %\n\\label{equation: representation of R}\nR &=\n\\begin{pmatrix}\nR_1 & 0 \\\\\n0 & R_2\n\\end{pmatrix}_{\\ker(\\varGamma - 1) \\oplus \\ker(\\varGamma + 1)}\n=\n\\begin{pmatrix}\nR'_1 & 0 \\\\\n0 & R'_2\n\\end{pmatrix}_{\\ker(\\varGamma' - 1) \\oplus \\ker(\\varGamma' + 1)}, \\\\\n% ------------------------- %\n\\label{equation: representation of Q}\nQ &=\n\\begin{pmatrix}\n0 & Q_0^* \\\\\nQ_0 & 0\n\\end{pmatrix}_{\\ker(\\varGamma - 1) \\oplus \\ker(\\varGamma + 1)}\n=\n\\begin{pmatrix}\n0 & (Q'_0)^* \\\\\nQ'_0 & 0\n\\end{pmatrix}_{\\ker(\\varGamma' - 1) \\oplus \\ker(\\varGamma' + 1)}, \\\\\n% ------------------------- %\n\\label{equation: representation of U}\nU &=\n\\begin{pmatrix}\nR_1 & iQ_0^* \\\\\niQ_0 & R_2\n\\end{pmatrix}_{\\ker(\\varGamma - 1) \\oplus \\ker(\\varGamma + 1)}\n=\n\\begin{pmatrix}\nR'_1 & i(Q'_0)^* \\\\\niQ'_0 & R'_2\n\\end{pmatrix}_{\\ker(\\varGamma' - 1) \\oplus \\ker(\\varGamma' + 1)},\n\\end{align}\nwhere $R_j, R'_j$ are self-adjoint for each $j=1,2.$ The chiral pair $(\\varGamma, \\varGamma')$ is said to be \\textbi{Fredholm}, if the operator $Q$ is Fredholm (or, equivalently, $Q_0, Q'_0$ are Fredholm). In this case, we define the \\textbi{Witten indices} of the pairs $(\\varGamma, \\varGamma')', (\\varGamma, \\varGamma)$ by the following formulas respectively:\n\\[\n\\ind(\\varGamma, \\varGamma') := \\ind Q_0, \\qquad \\ind(\\varGamma', \\varGamma) := \\ind Q'_0,\n\\]\nwhere $\\ind Q_0, \\ind Q'_0$ denote the Fredholm indices of $Q_0, Q'_0$ respectively. The Witten indices introduced above are \\textbi{unitarily invariant} in the following precise sense (see \\cite[Theorem 3]{Suzuki-Tanaka-2019} for details); for any unitary operator $\\epsilon$ on $\\cH,$ we have that $(\\varGamma, \\varGamma')$ is Fredholm if and only if so is $(\\epsilon^* \\varGamma \\epsilon, \\epsilon^* \\varGamma' \\epsilon),$ and that in this case\n\\begin{equation}\n\\label{equation: unitary invariance of the witten index}\n\\ind(\\varGamma, \\varGamma') = \\ind(\\epsilon^* \\varGamma \\epsilon, \\epsilon^* \\varGamma' \\epsilon), \\qquad\n\\ind(\\varGamma', \\varGamma) = \\ind(\\epsilon^* \\varGamma' \\epsilon, \\epsilon^* \\varGamma \\epsilon).\n\\end{equation}\n\n\n\nWith \\cref{example: unitary involution} in mind, we are now in a position to state the main theorem of the current section;\n\n\\begin{mtheorem}\n\\label{theorem: split-step}\nLet $\\varGamma,\\varGamma'$ be two unitary involutions defined respectively as the following block-operator matrices with respect to $\\ell^2(\\Z, \\C^2) = \\ell^2(\\Z) \\oplus \\ell^2(\\Z):$\n\\begin{align}\n% ----------------- %\n\\label{equation: definition of shift operator}\n\\tag{B1}\n\\varGamma &:=\n\\begin{pmatrix}\n1 & 0\\\\\n0  &  L^*\n\\end{pmatrix}\n\\begin{pmatrix}\np   & q \\\\\nq^* & -p\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0\\\\\n0  &  L\n\\end{pmatrix}\n=\n\\begin{pmatrix}\np & q L \\\\\n L^*q^*  & -p(\\cdot - 1)\n\\end{pmatrix}, \\\\\n% ----------------- %\n\\label{equation: definition of coin operator}\n\\tag{B2}\n\\varGamma' &:=\n\\begin{pmatrix}\na & b^* \\\\\nb & -a\n\\end{pmatrix},\n\\end{align}\nwhere we assume that two convergent $\\R$-valued sequences $p = (p(x))_{x \\in \\Z}, a = (a(x))_{x \\in \\Z}$ and two convergent $\\C$-valued sequences $q = (q(x))_{x \\in \\Z}, b = (b(x))_{x \\in \\Z}$ satisfy the following:\n\\begin{align}\n% ----------------- %\n\\label{equation: p and q}\n\\tag{B3}\n&p(x)^2 + |q(x)|^2 = 1, & &x \\in \\Z, \\\\\n% ----------------- %\n\\label{equation: alpha and beta}\n\\tag{B4}\n&a(x)^2 + |b(x)|^2 = 1, & &x \\in \\Z,  \\\\\n% ----------------- %\n\\label{equation: limits of real sequences}\n\\tag{B5}\n&p(\\pm \\infty) := \\lim_{x \\to \\pm \\infty} p(x) \\in \\R, && a(\\pm \\infty) := \\lim_{x \\to \\pm \\infty} a(x) \\in \\R, \\\\\n% ----------------- %\n\\label{equation: limits of complex sequences}\n\\tag{B6}\n&q(\\pm \\infty) := \\lim_{x \\to \\pm \\infty} q(x) \\in \\C,& &b(\\pm \\infty) := \\lim_{x \\to \\pm \\infty} b(x) \\in \\C, \\\\\n% ----------------- %\n\\label{equation: limits of theta}\n\\tag{B7}\n&\\theta(\\pm \\infty) :=\n\\begin{cases}\n\\arg q(\\pm \\infty), & q(\\pm \\infty) \\neq 0, \\\\\n0,             & q(\\pm \\infty) = 0,\n\\end{cases} &\n&\n\\phi(\\pm \\infty) :=\n\\begin{cases}\n\\arg b(\\pm \\infty), & b(\\pm \\infty) \\neq 0, \\\\\n0,                 & b(\\pm \\infty) = 0,\n\\end{cases}\n\\end{align}\nwhere $\\arg w$ of a non-zero complex number $w$ is uniquely defined by $w = e^{i \\arg w}$ and $\\arg w \\in [0,2\\pi).$ Then the following two assertions hold true:\n\\begin{enumerate}[(i)]\n\\item The chiral pair $(\\varGamma,\\varGamma' )$ is Fredholm if and only if $|p(\\star)| \\neq |a(\\star)|$ for each $\\star = \\pm \\infty.$ In this case, we have\n\\begin{align}\n% --------------------------- %\n\\label{equation1: Witten index formula}\n\\tag{B8}\n&\\ind (\\varGamma,\\varGamma') =\n\\begin{cases}\n0, &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| < |a(+\\infty)|, \\\\\n+\\sgn p(+\\infty), &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| > |a(+\\infty)|, \\\\\n-  \\sgn p(-\\infty), &  |p(-\\infty)| > |a(-\\infty)| \\mbox{ and } |p(+\\infty)| < |a(+\\infty)|, \\\\\n+\\sgn p(+\\infty) - \\sgn p(-\\infty), &  |p(-\\infty)| >  |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| > |a(+\\infty)|,\n\\end{cases} \\\\\n% --------------------------- %\n\\label{equation2: Witten index formula}\n\\tag{B9}\n&\\ind (\\varGamma',\\varGamma) =\n\\begin{cases}\n-\\sgn a(+\\infty) + \\sgn a(-\\infty), &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| < |a(+\\infty)|, \\\\\n+ \\sgn a(-\\infty), &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| > |a(+\\infty)|, \\\\\n- \\sgn a(+\\infty), &  |p(-\\infty)| > |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| < |a(+\\infty)|, \\\\\n0, &  |p(-\\infty)| >  |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| > |a(+\\infty)|,\n\\end{cases}\n% --------------------------- %\n\\end{align}\nwhere the sign function $\\sgn : \\R \\to \\{-1,1\\}$ is defined by\n\\begin{equation}\n\\tag{B10}\n\\label{equation: definition of sign function}\n\\sgn x :=\n\\begin{cases}\n\\frac{x}{|x|}, & x \\neq 0, \\\\\n1, & x = 0.\n\\end{cases}\n\\end{equation}\n\n\\item The essential spectrum of the evolution operator $U := \\varGamma \\varGamma'$ is given by\n\\begin{align}\n% ----------------------------------- %\n\\label{equation: essential spectrum of U}\n\\tag{B11}\n\\ess(U) &= \\bigcup_{\\star = \\pm \\infty} \\left\\{z \\in \\T \\mid \\sgn(p(\\star) a(\\star)) \\cdot \\Re z \\in I(\\star) \\right\\},  \\\\\n% ----------------------------------- %\n\\label{equation: definition of Istar}\n\\tag{B12}\nI(\\star) &:= [|p(\\star) a(\\star)| - |q(\\star) b(\\star)|, |p(\\star) a(\\star)| + |q(\\star) b(\\star)|], \\qquad \\star = \\pm \\infty.\n\\end{align}\nMoreover, $\\ess(U)$ does not contain both $-1,+1$ if and only if $|p(\\star)| \\neq |a(\\star)|$ for each $\\star = \\pm \\infty.$\n\\end{enumerate}\n\\end{mtheorem}\n\nThe chiral pair $(\\varGamma,\\varGamma')$ in \\cref{theorem: split-step} is a one-dimensional split-step quantum walk model considered in \\cite{Fuda-Funakawa-Suzuki-2017,Fuda-Funakawa-Suzuki-2018,Fuda-Funakawa-Suzuki-2019,Suzuki-Tanaka-2019,Matsuzawa-2020} with a modification that the two parameters $p, q$ depend freely on $\\Z.$ Note that this seemingly minor modification leads to the new Witten index formula \\cref{equation1: Witten index formula} taking values from $\\{-2,-1,0,+1,+2\\},$ where the indices $\\pm 2$ never appear in the existing formula (see \\cite[(A2)]{Suzuki-Tanaka-2019} or \\cite[Theorem 1.1]{Matsuzawa-2020} for details), since $p, q$ are kept constant in the five papers mentioned above. The index formula \\cref{equation2: Witten index formula} is new to the best of the author's knowledge. As we shall see in \\cref{section: topologically protected bound states}, the two index formulas \\crefrange{equation1: Witten index formula}{equation2: Witten index formula} naturally provide a lower bound for $\\dim \\ker(U \\mp 1).$\n\n\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Proof of Theorem B (i)}\n\\label{section: fredholm index}\n\nWhat follows is a generalisation of \\cite[\\textsection 3]{Suzuki-Tanaka-2019}. With the notation introduced in \\cref{theorem: split-step}, on one hand, the imaginary part $Q$ admits two off-diagonal matrix representations as in \\cref{equation: representation of Q}, where $\\ind(\\varGamma,\\varGamma') = \\ind Q_0$ and $\\ind(\\varGamma',\\varGamma) = \\ind Q'_0$ by definition. On the other hand, an easy computation shows that the same operator $Q$ does \\textit{not} admit an off-diagonal representation with respect to the orthogonal decomposition $\\ell^2(\\Z,\\C^2) = \\ell^2(\\Z) \\oplus \\ell^2(\\Z).$ The unitary invariance property \\cref{equation: unitary invariance of the witten index} motivates us to construct explicit unitary operators $\\epsilon, \\gamma : \\ell^2(\\Z) \\to \\ell^2(\\Z),$ such that $\\epsilon^* Q \\epsilon, \\gamma^* Q \\gamma$ become off-diagonal with respect to this decomposition. \n\n\\begin{lemma}\n\\label{lemma: wada decomposition}\nLet $(\\varGamma,\\varGamma')$ be the chiral pair in \\cref{theorem: split-step}, and let $U := \\varGamma \\varGamma'$ be the associated evolution operator. Let $R, Q$ be the real and imaginary parts of $U$ respectively. For each $x \\in \\Z,$ let $\\theta(x), \\phi(x)$ be any real numbers satisfying $q(x) = |q(x)|e^{i \\theta(x)}$ and $b(x) = |b(x)|e^{i \\phi(x)}.$ Let $p_\\pm := \\sqrt{1 \\pm p},$ and let $a_\\pm := \\sqrt{1 \\pm a}.$ Let\n\\begin{equation}\n\\label{equation: wada transform}\n\\epsilon :=\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n1 & 0 \\\\\n0  &  L^*e^{-i \\theta}\n\\end{pmatrix}\n\\begin{pmatrix}\np_+  & -p_- \\\\\np_-  & p_+\n\\end{pmatrix}, \\qquad\n\\gamma :=\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\phi}\n\\end{pmatrix}\n\\begin{pmatrix}\na_+ & -a_- \\\\\na_-   & a_+\n\\end{pmatrix}.\n\\end{equation}\nThen the unitary operators $\\epsilon, \\gamma$ give the following decompositions with respect to $\\ell^2(\\Z,\\C^2) = \\ell^2(\\Z) \\oplus \\ell^2(\\Z):$\n\\begin{align}\n% ------------- %\n\\label{equation1: wada decomposition}\n&\\epsilon^* \\varGamma \\epsilon\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix},\n% ------------- %\n&&\\epsilon^* U \\epsilon\n=\n\\begin{pmatrix}\nR_{\\epsilon_1} & iQ_{\\epsilon_0}^* \\\\\niQ_{\\epsilon_0} & R_{\\epsilon_2}\n\\end{pmatrix},\n% ------------- %\n&&\\epsilon^* R \\epsilon\n=\n\\begin{pmatrix}\nR_{\\epsilon_1} & 0 \\\\\n0 & R_{\\epsilon_2}\n\\end{pmatrix},\n% ------------- %\n&&\\epsilon^* Q \\epsilon\n=\n\\begin{pmatrix}\n0 & Q_{\\epsilon_0}^* \\\\\nQ_{\\epsilon_0} & 0\n\\end{pmatrix}, \\\\\n% ------------- %\n\\label{equation2: wada decomposition}\n&\\gamma^* \\varGamma' \\gamma\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix},\n% ------------- %\n&&\\gamma^* U \\gamma\n=\n\\begin{pmatrix}\nR_{\\gamma_1} & iQ_{\\gamma_0}^* \\\\\niQ_{\\gamma_0} & R_{\\gamma_2}\n\\end{pmatrix},\n% ------------- %\n&&\\gamma^* R \\gamma\n=\n\\begin{pmatrix}\nR_{\\gamma_1} & 0 \\\\\n0 & R_{\\gamma_2}\n\\end{pmatrix},\n% ------------- %\n&&\\gamma^* Q \\gamma\n=\n\\begin{pmatrix}\n0 & Q_{\\gamma_0}^* \\\\\nQ_{\\gamma_0} & 0\n\\end{pmatrix},\n% ------------- %\n\\end{align}\nwhere the six operators $Q_{\\epsilon_0},Q_{\\gamma_0},R_{\\epsilon_1},R_{\\gamma_1},R_{\\epsilon_2},R_{\\gamma_2}$ are defined respectively by the following formulas:\n\\begin{align}\n% ------------- %\n\\label{equation: definition of Qepsilon}\n-2i Q_{\\epsilon_0} &:= p_+  e^{i \\theta}L b p_+ - p_- b^*  L^* e^{-i \\theta}p_-  - |q|(a + a(\\cdot + 1)), \\\\\n% ------------- %\n\\label{equation: definition of Qgamma}\n2i Q_{\\gamma_0} &:=  a_+ e^{-i\\phi}L^* q^* a_+ - a_- q L e^{i\\phi} a_- - |b|(p + p(\\cdot - 1)), \\\\\n% ------------- %\n\\label{equation1: definition of Repsilon}\n2R_{\\epsilon_1} &:= p_-  e^{i \\theta}L b p_+ + p_+ b^*  L^* e^{-i \\theta} p_-  + p_+^2 a - p_-^2 a(\\cdot + 1), \\\\\n% ------------- %\n\\label{equation1: definition of Rgamma}\n2R_{\\gamma_1} &:= a_- e^{-i\\phi}L^* q^* a_+ + a_+ q L e^{i\\phi} a_- + a_+^2p - a_-^2p(\\cdot - 1), \\\\\n% ------------- %\n\\label{equation2: definition of Repsilon}\n2R_{\\epsilon_2} &:= p_+  e^{i \\theta}L b p_- + p_- b^*  L^* e^{-i \\theta} p_+  - p_-^2a + p_+^2 a(\\cdot + 1), \\\\\n% ------------- %\n\\label{equation2: definition of Rgamma}\n2R_{\\gamma_2} &:= a_+ e^{-i\\phi}L^* q^* a_- + a_- q L e^{i\\phi} a_+ - a_-^2p + a_+^2p(\\cdot - 1).\n% ------------- %\n\\end{align}\nMoreover, the chiral pair $(\\varGamma,\\varGamma')$ is Fredholm if and only if $Q_{\\epsilon_0},Q_{\\gamma_0}$ are Fredholm. In this case, \n\\begin{equation}\n\\label{equation: first index formula}\n\\ind(\\varGamma,\\varGamma') = \\ind Q_{\\epsilon_0}, \\qquad \\ind(\\varGamma',\\varGamma) = \\ind Q_{\\gamma_0}.\n\\end{equation}\n\\end{lemma}\n\\begin{proof}\nIt follows from \\cref{equation: diagonalisation of unitary involutory matrix} that we have the following diagonalisation:\n\\begin{align}\n\\epsilon_0^*\n\\begin{pmatrix}\np & q \\\\\nq^* & -p\n\\end{pmatrix}\n\\epsilon_0\n&=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix},\n&\n\\epsilon_0 &:=\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{-i\\theta}\n\\end{pmatrix}\n\\begin{pmatrix}\np_+ & -p_- \\\\\np_-   & p_+\n\\end{pmatrix}, \\\\\n% ----------------- %\n\\gamma^*\n\\begin{pmatrix}\na & b^* \\\\\nb & -a\n\\end{pmatrix}\n\\gamma\n&=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix},\n&\n\\gamma &:=\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\phi}\n\\end{pmatrix}\n\\begin{pmatrix}\na_+ & -a_- \\\\\na_-   & a_+\n\\end{pmatrix}.\n\\end{align}\nThe operator $\\epsilon$ given by the first equality in \\cref{equation: wada transform} can be written as the product $\\epsilon = (1 \\oplus L^*) \\epsilon_0$ of two unitary operators $1 \\oplus L^*$ and $\\epsilon_0.$ With the first equality in \\cref{equation: definition of shift operator}, we obtain\n\\[\n\\epsilon^* \\varGamma \\epsilon\n=\n\\epsilon_0^*\n\\begin{pmatrix}\n1 & 0 \\\\\n0  &  L\n\\end{pmatrix}\n\\left(\n\\begin{pmatrix}\n1 & 0 \\\\\n0  &  L^*\n\\end{pmatrix}\n\\begin{pmatrix}\np   & q \\\\\nq^* & -p\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0 \\\\\n0  &  L\n\\end{pmatrix}\n\\right)\n\\begin{pmatrix}\n1 & 0 \\\\\n0  &  L^*\n\\end{pmatrix}\n\\epsilon_0 \\\\\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}.\n\\]\nGiven an operator $X$ on $\\ell^2(\\Z,\\C^2),$ we introduce the shorthand $X_\\epsilon := \\epsilon^* X \\epsilon$ and $X_\\eta := \\eta^* X \\eta.$ With this convention in mind, we have the commutation relations $[\\varGamma_\\epsilon, R_\\epsilon] = [\\varGamma'_\\gamma, R_\\gamma] = 0$ and anti-commutation relations $\\{\\varGamma_\\epsilon, Q_\\epsilon\\} = \\{\\varGamma'_\\gamma, Q_\\gamma\\} = 0,$ where $\\varGamma_\\epsilon = \\varGamma'_\\gamma = 1 \\oplus -1$ with respect to $\\ell^2(\\Z,\\C^2) = \\ell^2(\\Z) \\oplus \\ell^2(\\Z).$ It follows that we have the following representations:\n\\begin{align}\n% ------------- %\n\\label{equation: epsilon representation}\nR_\\epsilon\n&=\n\\begin{pmatrix}\nR'_{\\epsilon_1} & 0 \\\\\n0 & R'_{\\epsilon_2}\n\\end{pmatrix},\n% ------------- %\n&\nQ_\\epsilon\n&=\n\\begin{pmatrix}\n0 & (Q'_{\\epsilon_0})^* \\\\\nQ'_{\\epsilon_0} & 0\n\\end{pmatrix},\n% ------------- %\n&\nU_\\epsilon\n&= R_\\epsilon + iQ_\\epsilon =\n\\begin{pmatrix}\nR'_{\\epsilon_1} & i(Q'_{\\epsilon_0})^* \\\\\niQ'_{\\epsilon_0} & R'_{\\epsilon_2}\n\\end{pmatrix}, \\\\\n% ------------- %\n\\label{equation: gamma representation}\nR_\\gamma\n&=\n\\begin{pmatrix}\nR'_{\\gamma_1} & 0 \\\\\n0 & R'_{\\gamma_2}\n\\end{pmatrix},\n% ------------- %\n&\nQ_\\gamma\n&=\n\\begin{pmatrix}\n0 & (Q'_{\\gamma_0})^* \\\\\nQ'_{\\gamma_0} & 0\n\\end{pmatrix},\n&\nU_\\gamma\n&= R_\\gamma + iQ_\\gamma =\n\\begin{pmatrix}\nR'_{\\gamma_1} & i(Q'_{\\gamma_0})^* \\\\\niQ'_{\\gamma_0} & R'_{\\gamma_2}\n\\end{pmatrix}.\n% ------------- %\n\\end{align}\nIt remains to show that the six operators introduced above coincide with the ones defined by the formulas \\crefrange{equation: definition of Qepsilon}{equation2: definition of Rgamma}. Note that\n\\begin{align}\n% ---------------------------- %\n\\label{equation1: Cepsilon}\n2 \\varGamma'_\\epsilon\n&=\n2\\varGamma_\\epsilon U_\\epsilon\n=\n2\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}\n\\begin{pmatrix}\nR'_{\\epsilon_1} & i(Q'_{\\epsilon_0})^* \\\\\niQ'_{\\epsilon_0}   & R'_{\\epsilon_2}  \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2R'_{\\epsilon_1}     & 2i(Q'_{\\epsilon_0})^* \\\\\n-2iQ'_{\\epsilon_0}   & -2R'_{\\epsilon_2}  \\\\\n\\end{pmatrix},\\\\\n% ---------------------------- %\n\\label{equation1: Sgamma}\n2\\varGamma_\\gamma\n&=\n2 U_\\gamma \\varGamma'_\\gamma\n=\n2\n\\begin{pmatrix}\nR'_{\\gamma_1}    & i(Q'_{\\gamma_0})^* \\\\\niQ'_{\\gamma_0}   & R'_{\\gamma_2}  \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2R'_{\\gamma_1}    & -2i(Q'_{\\gamma_0})^* \\\\\n2iQ'_{\\gamma_0}   & -2R'_{\\gamma_2}  \\\\\n\\end{pmatrix}.\n\\end{align}\nIt remains to compute $2\\varGamma'_\\epsilon, 2\\varGamma_\\gamma$;\n\\begin{align*}\n% ------------- %\n2\\epsilon^*\n\\begin{pmatrix}\n0 & b^* \\\\\nb & 0 \\\\\n\\end{pmatrix}\n\\epsilon\n&=\n\\begin{pmatrix}\np_-  e^{i \\theta}L b p_+ + p_+ b^*  L^*e^{-i \\theta} p_-    & -p_-  e^{i \\theta}L b p_- + p_+ b^*  L^* e^{-i \\theta} p_+   \\\\\np_+  e^{i \\theta}L b p_+ - p_- b^*  L^*e^{-i \\theta} p_-  &\n-p_+  e^{i \\theta}L b p_- - p_- b^*  L^*e^{-i \\theta} p_+\n\\end{pmatrix}, \\\\\n% ------------- %\n2\\epsilon^*\n\\begin{pmatrix}\na & 0 \\\\\n0 & -a \\\\\n\\end{pmatrix}\n\\epsilon\n&=\n\\begin{pmatrix}\np_+^2 a - p_-^2 a(\\cdot + 1) & -|q|(a + a(\\cdot + 1)) \\\\\n-|q|(a + a(\\cdot + 1))  & p_-^2 a - p_+^2a(\\cdot + 1)\n\\end{pmatrix}, \\\\\n% ------------- %\n2\\gamma^*\n\\begin{pmatrix}\n0 & q L \\\\\nL^*q^*  & 0\n\\end{pmatrix}\n\\gamma\n&=\n\\begin{pmatrix}\na_- e^{-i\\phi}L^* q^* a_+ + a_+ q L e^{i\\phi} a_- & -a_- e^{-i\\phi}L^* q^* a_- + a_+ q L e^{i\\phi} a_+ \\\\\na_+ e^{-i\\phi}L^* q^* a_+ - a_- q L e^{i\\phi} a_-  & -a_+ e^{-i\\phi}L^* q^* a_- - a_- q L e^{i\\phi} a_+\n\\end{pmatrix}, \\\\\n% ------------- %\n2\\gamma^*\n\\begin{pmatrix}\np & 0 \\\\\n0  & -p(\\cdot - 1)\n\\end{pmatrix}\n\\gamma\n&=\n\\begin{pmatrix}\na_+^2p - a_-^2p(\\cdot - 1) & -|b|(p + p(\\cdot - 1)) \\\\\n-|b|(p + p(\\cdot - 1))  & a_-^2p - a_+^2p(\\cdot - 1)\n\\end{pmatrix}.\n\\end{align*}\nIt follows from the above equalities that\n\\begin{align}\n% --------------- %\n\\label{equation2: Cepsilon}\n2\\varGamma'_\\epsilon &=\n2\\epsilon^*\n\\begin{pmatrix}\n0 & b^* \\\\\nb & 0 \\\\\n\\end{pmatrix}\n\\epsilon\n+\n2\\epsilon^*\n\\begin{pmatrix}\na & 0 \\\\\n0 & -a \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2R_{\\epsilon_1} & 2i Q_{\\epsilon_0}^* \\\\\n-2i Q_{\\epsilon_0} & -2R_{\\epsilon_2}\n\\end{pmatrix}, \\\\\n% --------------- %\n\\label{equation2: Sgamma}\n2\\varGamma_\\gamma &=\n2\\gamma^*\n\\begin{pmatrix}\n0 & q L \\\\\nL^*q^*  & 0\n\\end{pmatrix}\n\\gamma\n+\n2\\gamma^*\n\\begin{pmatrix}\np & 0 \\\\\n0  & -p(\\cdot - 1)\n\\end{pmatrix}\n\\gamma\n=\n\\begin{pmatrix}\n2R_{\\gamma_1} & -2i Q_{\\gamma_0}^* \\\\\n2i Q_{\\gamma_0} & -2R_{\\gamma_2}\n\\end{pmatrix}.\n\\end{align}\nBy comparing \\crefrange{equation1: Cepsilon}{equation1: Sgamma} with \\crefrange{equation2: Cepsilon}{equation2: Sgamma}, we see that \\crefrange{equation1: wada decomposition}{equation2: wada decomposition} hold true.\n\nNote that $\\ell^2(\\Z,\\C^2) = \\ell^2(\\Z) \\oplus \\ell^2(\\Z)$ can be identified with the orthogonal sum $\\ell^2(\\Z) \\oplus \\{0\\} \\oplus \\{0\\} \\oplus \\ell^2(\\Z)$ through the following unitary transform;\n\\[\n\\ell^2(\\Z,\\C^2) \\ni (\\Psi_1, \\Psi_2) \\longmapsto (\\Psi_1, 0,0,\\Psi_2) \\in \\ell^2(\\Z) \\oplus \\{0\\} \\oplus \\{0\\} \\oplus \\ell^2(\\Z).\n\\]\nIt is then easy to see that the operator $Q_\\epsilon$ admits the following block-operator matrix representations:\n\\begin{equation}\n\\label{equation1: representation of Qepsilon}\nQ_\\epsilon\n=\n\\begin{pmatrix}\n0 & Q_{\\epsilon_0}^* \\\\\nQ_{\\epsilon_0} & 0\n\\end{pmatrix}_{\\ell^2(\\Z) \\oplus \\ell^2(\\Z)}\n=\n\\begin{pmatrix}\n0 & 0 & 0 & Q_{\\epsilon_0}^* \\\\\n0 & 0 & \\textbf{0} & 0 \\\\\n0 & \\textbf{0} & 0 & 0 \\\\\nQ_{\\epsilon_0} & 0 & 0 & 0\n\\end{pmatrix}_{\\ell^2(\\Z) \\oplus \\{0\\} \\oplus \\{0\\} \\oplus \\ell^2(\\Z)},\n\\end{equation}\nwhere $\\textbf{0}$ denotes the zero operator of the form $\\textbf{0} : \\{0\\} \\to \\{0\\},$ and where $\\ell^2(\\Z) \\oplus \\{0\\} = \\ker(\\varGamma_\\epsilon - 1)$ and $\\{0\\} \\oplus \\ell^2(\\Z) = \\ker(\\varGamma_\\epsilon + 1).$ On the other hand, the same operator $Q_\\epsilon$ is the imaginary part of $U_\\epsilon = \\varGamma_\\epsilon \\varGamma'_\\epsilon,$ and so it admits the following off-diagonal block-operator matrix representation according to \\cref{equation: representation of Q};\n\\begin{equation}\n\\label{equation2: representation of Qepsilon}\nQ_\\epsilon =\n\\begin{pmatrix}\n0 & (Q''_{0})^* \\\\\nQ''_{0} & 0\n\\end{pmatrix}_{\\ker(\\varGamma_\\epsilon - 1) \\oplus \\ker(\\varGamma_\\epsilon + 1)}\n=\n\\begin{pmatrix}\n0 & (Q''_{0})^* \\\\\nQ''_{0} & 0\n\\end{pmatrix}_{(\\ell^2(\\Z) \\oplus \\{0\\}) \\oplus (\\{0\\} \\oplus \\ell^2(\\Z))}.\n\\end{equation}\nIt follows from \\crefrange{equation1: representation of Qepsilon}{equation2: representation of Qepsilon} that $Q''_{0}$ is an off-diagonal block-operator matrix of the form;\n\\[\nQ''_{0} =\n\\begin{pmatrix}\n0  & \\textbf{0} \\\\\nQ_{\\epsilon_0} & 0\n\\end{pmatrix}.\n\\]\nSince $\\textbf{0} : \\{0\\} \\to \\{0\\}$ is a Fredholm operator of zero index, we have that $Q''_{0}$ is Fredholm if and only if $Q_{\\epsilon_0}$ is Fredholm. In this case, we have $\\ind Q''_{0} = \\ind Q_{\\epsilon_0} + \\ind(\\textbf{0}) = \\ind Q_{\\epsilon_0} + 0 = \\ind Q_{\\epsilon_0}.$ The first equality in \\cref{equation: first index formula} follows from the unitary invariance of the Witten index \\cref{equation: unitary invariance of the witten index}. An analogous argument can be used to show that the second equality in \\cref{equation: first index formula} also holds true.\n\\end{proof}\n\\begin{remark}\nThe above derivation of \\cref{equation: first index formula} only requires the sequences $p,q,a,b$ to be bounded, and so the existence of the two-sided limits \\crefrange{equation: limits of real sequences}{equation: limits of complex sequences} turn out to be redundant. Note, however, that from here on we shall impose \\crefrange{equation: limits of real sequences}{equation: limits of complex sequences} to prove the index formulas \\crefrange{equation1: Witten index formula}{equation2: Witten index formula}.\n\\end{remark}\n\nWith \\cref{lemma: wada decomposition} in mind, it remains to compute the Fredholm indices of the following operators:\n\\begin{align}\n\\label{equation2: definition of Qepsilon}\n-2i Q_{\\epsilon_0} &= p_+  p_+(\\cdot + 1) b(\\cdot + 1) e^{i \\theta}L  - p_-p_-(\\cdot - 1) b^*  e^{-i \\theta(\\cdot - 1)}L^*   - |q|(a + a(\\cdot + 1)), \\\\\n\\label{equation2: definition of Qgamma}\n2i Q_{\\gamma_0}   &= a_+ a_+(\\cdot - 1)q(\\cdot - 1)^* e^{-i\\phi}L^* - a_- a_-(\\cdot + 1) q e^{i\\phi(\\cdot + 1)}  L     - |b|(p + p(\\cdot - 1)),\n\\end{align}\nwhere $\\theta, \\phi$ can be any $\\R$-valued sequences satisfying $q(x) = |q(x)|e^{i \\theta(x)}$ and $b(x) = |b(x)|e^{i \\phi(x)}$ for each $x \\in \\Z.$ Note that \\cref{theorem: two-phase case}(i) is not immediately applicable to the above strictly local operators, since it is not necessarily true that $\\theta$ and $\\phi$ are convergent. More precisely, for each $\\star = \\pm \\infty,$ if $q(\\star) \\neq 0,$ then we can explicitly construct $\\theta$ in such a way that $\\theta(\\star) = \\lim_{x \\to \\star} \\theta(x)$ holds true. On the other hand, if $q(\\star) =  0,$ then the same conclusion cannot be drawn in general, because there are some pathological examples. Note that the same remark applies to $\\phi.$ The purpose of the current section is to overcome this hindrance, which does not appear under the setting of \\cite{Suzuki-Tanaka-2019,Matsuzawa-2020}, where $p,q$ are held constant.\n\n\\begin{lemma}\n\\label{lemma: phase problem}\nThe following assertions hold true:\n\\begin{enumerate}[(i)]\n\\item There exist two $\\R$-valued sequences $\\theta_+ = (\\theta_+(x))_{x \\in \\Z}, \\theta_- = (\\theta_-(x))_{x \\in \\Z},$ such that\n\\begin{equation}\n\\label{equation: modified Qepsilon}\n\\begin{aligned}\ne^{-i \\theta_+} (-2i Q_{\\epsilon_0}) e^{i \\theta_-}\n&= p_+ p_+(\\cdot + 1) b(\\cdot + 1) e^{i(\\theta - \\theta_+ + \\theta_-(\\cdot + 1))} L  \\\\\n&- p_- p_-(\\cdot - 1) b^* e^{-i (\\theta(\\cdot - 1) - \\theta_-(\\cdot - 1) + \\theta_+ )} L^* \\\\\n&- |q|(a + a(\\cdot + 1))e^{i(\\theta_- - \\theta_+)},\n\\end{aligned}\n\\end{equation}\nwhere the three coefficients of the above strictly local operator have the following limits for each $\\star = \\pm \\infty:$\n\\begin{align}\n% -------------------- %\n\\label{equation1: new phase}\n&\\lim_{x \\to \\star} \\left( p_+(x) p_+(x + 1) b(x + 1)  e^{i (\\theta(x) - \\theta_+(x) + \\theta_-(x + 1))} \\right) =\n(p(\\star) + 1) b(\\star)e^{i \\theta(\\star)}, \\\\\n% -------------------- %\n\\label{equation2: new phase}\n&\\lim_{x \\to \\star} \\left(- p_-(x) p_-(x - 1) b(x)^* e^{-i (\\theta(x - 1) - \\theta_-(x - 1)  + \\theta_+(x))}\\right) =\n(p(\\star) - 1) b(\\star)^* e^{-i \\theta(\\star)}, \\\\\n% -------------------- %\n\\label{equation3: new phase}\n&\\lim_{x \\to \\star}\n\\left(-|q(x)|(a(x) + a(x + 1))e^{i (\\theta_-(x) - \\theta_+(x))}\\right)\n= -2|q(\\star)|a(\\star).\n\\end{align}\n\n\\item There exist two $\\R$-valued sequences $\\phi_+ = (\\phi_+(x))_{x \\in \\Z}, \\phi_- = (\\phi_-(x))_{x \\in \\Z},$ such that\n\\begin{equation}\n\\label{equation: modified Qgamma}\n\\begin{aligned}\ne^{i \\phi_+} (2i Q_{\\gamma_0}) e^{-i \\phi_-}\n&= a_+ a_+(\\cdot - 1) q(\\cdot - 1)^* e^{-i(\\phi - \\phi_+ + \\phi_-(\\cdot - 1))} L^*  \\\\\n&- a_- a_-(\\cdot + 1) q e^{i (\\phi(\\cdot + 1) - \\phi_-(\\cdot + 1) + \\phi_+ )} L \\\\\n&- |b|(p + p(\\cdot - 1))e^{i(\\phi_+ - \\phi_-)},\n\\end{aligned}\n\\end{equation}\nwhere the three coefficients of the above strictly local operator have the following limits for each $\\star = \\pm \\infty:$\n\\begin{align}\n% -------------------- %\n\\label{equation4: new phase}\n&\\lim_{x \\to \\star} \\left( a_+(x) a_+(x - 1) q(x - 1)^* e^{-i(\\phi(x) - \\phi_+(x) + \\phi_-(x - 1))} \\right) =\n(a(\\star) + 1) q(\\star)^*e^{-i \\phi(\\star)}, \\\\\n% -------------------- %\n\\label{equation5: new phase}\n&\\lim_{x \\to \\star} \\left(- a_-(x) a_-(x + 1) q(x) e^{i (\\phi(x + 1) - \\phi_-(x + 1) + \\phi_+(x) )}\\right) =\n(a(\\star) - 1) q(\\star) e^{i \\phi(\\star)}, \\\\\n% -------------------- %\n\\label{equation6: new phase}\n&\\lim_{x \\to \\star}\n\\left(- |b(x)|(p(x) + p(x - 1))e^{i(\\phi_+(x) - \\phi_-(x))}\\right)\n= -2|b(\\star)|p(\\star).\n\\end{align}\n\\end{enumerate}\n\\end{lemma}\n\\begin{proof}\nFor each $x \\in \\Z$ we let\n\\[\n\\star(x) :=\n\\begin{cases}\n+\\infty, & x \\geq 0, \\\\\n-\\infty, & x < 0,\n\\end{cases} \\qquad\n\\theta_{\\pm}(x) :=\n\\begin{cases}\n\\theta(x), & p(\\star(x)) =    \\pm 1, \\\\\n0,         & p(\\star(x)) \\neq \\pm1, \\\\\n\\end{cases} \\qquad\n\\phi_{\\pm}(x) :=\n\\begin{cases}\n\\phi(x),   & a(\\star(x)) =    \\pm 1, \\\\\n0,         & a(\\star(x)) \\neq \\pm 1.\n\\end{cases} \n\\]\nNote that \\cref{equation: modified Qepsilon} follows from \\cref{equation2: definition of Qepsilon}, and \\cref{equation: modified Qgamma} follows from \\cref{equation2: definition of Qgamma}. For each $x \\in \\Z$ we let\n\\[\n\\Lambda_1(x) := \\theta(x) - \\theta_+(x) + \\theta_-(x + 1), \\quad\n\\Lambda_2(x) := \\theta(x - 1) - \\theta_-(x - 1)  + \\theta_+(x), \\quad\n\\Lambda_3(x) := \\theta_-(x)  - \\theta_+(x).\n\\]\n\n(i)  It suffices to prove the following equalities:\n\\begin{align}\n% -------------------- %\n\\label{equation7: new phase}\n&\\lim_{x \\to \\star} \\left(p_+(x) p_+(x + 1) e^{i \\Lambda_1(x)} \\right) =\n(p(\\star) + 1) e^{i \\theta(\\star)}, \\\\\n% -------------------- %\n\\label{equation8: new phase}\n&\\lim_{x \\to \\star} \\left(p_-(x) p_-(x - 1) e^{-i\\Lambda_2(x)}\\right) =\n-(p(\\star) - 1) e^{-i \\theta(\\star)}, \\\\\n% -------------------- %\n\\label{equation9: new phase}\n&\\lim_{x \\to \\star}\n\\left(|q(x)|e^{i \\Lambda_3(x)}\\right) = |q(\\star)|.\n\\end{align}\nLet $\\star = \\pm \\infty$ and $|x| > 1$ be fixed. If $|p(\\star)| < 1,$ then $\\theta_+(x) = \\theta_-(x) = 0.$ In this case, \\crefrange{equation4: new phase}{equation6: new phase} follow from the fact that as $x \\to \\star$ we have $\\Lambda_j(x) \\to \\theta(\\star)$ for each $j = 1,2,$ and $\\Lambda_3(x) \\to 0.$ On the other hand, if $|p(\\star)| = 1,$ then $q(\\star) = 0,$ and so \\cref{equation9: new phase} becomes trivial. We need to check the following two cases separately: $p(\\star) = -1$ and $p(\\star) = +1.$ If $p(\\star) = -1,$ then \\cref{equation7: new phase} holds trivially, and \\cref{equation8: new phase} follows from $\\theta_-(x - 1) = \\theta(x - 1)$ and $\\theta_+(x) = 0  = \\theta(\\star),$ where the last equality follows from \\cref{equation: limits of theta}.  Similarly, if $p(\\star) = +1,$ then \\cref{equation8: new phase} holds trivially, and \\cref{equation7: new phase} follows from $\\theta_+(x) = \\theta(x)$ and $\\theta_-(x+1) = 0  = \\theta(\\star).$\n\n(ii) The claim follows from the following analogous equalities:\n\\begin{align*}\n% -------------------- %\n&\\lim_{x \\to \\star} \\left( a_+(x) a_+(x - 1) e^{-i(\\phi(x) - \\phi_+(x) + \\phi_-(x - 1))} \\right) =\n(a(\\star) + 1) e^{-i \\phi(\\star)}, \\\\\n% -------------------- %\n&\\lim_{x \\to \\star} \\left( a_-(x) a_-(x + 1) e^{i (\\phi(x + 1) - \\phi_-(x + 1) + \\phi_+(x) )}\\right) =\n-(a(\\star) - 1)e^{i \\phi(\\star)}, \\\\\n% -------------------- %\n&\\lim_{x \\to \\star}\n\\left(|b(x)|e^{i(\\phi_+(x) - \\phi_-(x))}\\right)\n= |b(\\star)|.\n\\end{align*}\nWe omit the proof.\n\\end{proof}\n\nSince the Fredholm index is invariant under multiplication by invertible operators, we have\n\\[\n\\ind(e^{-i \\theta_+} Q_{\\epsilon_0} e^{i \\theta_-}) = \\ind Q_{\\epsilon_0} = \\ind(\\varGamma,\\varGamma'), \\qquad\n\\ind(e^{i \\phi_+} Q_{\\gamma_0} e^{-i \\phi_-}) = \\ind Q_{\\gamma_0} = \\ind(\\varGamma',\\varGamma).\n\\]\nWe are now in a position to apply \\cref{theorem: two-phase case}(i) to the strictly local operators $A_\\epsilon := e^{-i \\theta_+} Q_{\\epsilon_0} e^{i \\theta_-}$ and $A_\\gamma := e^{i \\phi_+} Q_{\\gamma_0} e^{-i \\phi_-}.$ Since the two-sided limits of the coefficients of $-2iA_\\epsilon$ and $2iA_\\gamma$ are given respectively by \\crefrange{equation1: new phase}{equation3: new phase} and \\crefrange{equation4: new phase}{equation6: new phase}, we introduce the following two functions for each $\\star = \\pm \\infty$ according to \\cref{equation: definition of hatA}:\n\\begin{align}\n% -------------------- %\n\\label{equation1: definition of fepsilon}\n-2if_\\epsilon(z,\\star) &:=\n(p(\\star) + 1) b(\\star) e^{i \\theta(\\star)} z + (p(\\star) - 1) b(\\star)^* e^{-i \\theta(\\star)} z^*  -2|q(\\star)|a(\\star), \\qquad z \\in \\T, \\\\\n% -------------------- %\n\\label{equation2: definition of fgamma}\n2if_\\gamma(z,\\star) &:=\n(a(\\star) + 1) q(\\star)^* e^{-i \\phi(\\star)} z^* + (a(\\star) - 1) q(\\star) e^{i \\phi(\\star)} z   -2|b(\\star)|p(\\star), \\qquad z \\in \\T.\n\\end{align}\nIt follows from \\cref{theorem: two-phase case}(i) that $A _\\epsilon$ is Fredholm (resp. $A _\\epsilon$ is Fredholm) if and only if for each $\\star = \\pm \\infty$ the function $f_\\epsilon(\\cdot,\\star)$ is nowhere vanishing (resp. $f_\\gamma(\\cdot,\\star)$ is nowhere vanishing). Moreover,\nin this case,\n\\begin{align}\n\\label{equation1: witten index expressed as the difference of winding numbers}\n\\ind(\\varGamma,\\varGamma') &= \\wn(f_\\epsilon(\\cdot, + \\infty)) - \\wn(f_\\epsilon(\\cdot, - \\infty)), \\\\\n\\label{equation2: witten index expressed as the difference of winding numbers}\n\\ind(\\varGamma',\\varGamma) &= \\wn(f_\\gamma(\\cdot, + \\infty)) - \\wn(f_\\gamma(\\cdot, - \\infty)).\n\\end{align}\nIt remains to compute the winding numbers of $f_\\epsilon(\\cdot, \\star), f_\\gamma(\\cdot, \\star)$ by making use of the following elementary fact;\n\n\\begin{lemma}\n\\label{lemma: matsuzawa function is an ellipse}\nFor each $j=1,2,$ let $(\\alpha_j, \\beta_j, \\Theta_j) \\in \\R \\times \\C \\times [0,2\\pi)$ be a fixed triple satisfying $\\alpha_j^2 + |\\beta_j|^2 = 1$ and $\\beta_j = |\\beta_j|e^{i \\Theta_j}.$ Let $f : \\T \\to \\C$ be the trigonometric polynomial defined by\n\\begin{equation}\n\\label{equation2: definition of matsuzawa function}\n2 f(z) :=\n(\\alpha_1 + 1) \\beta_2 e^{i \\Theta_1} z + (\\alpha_1 - 1) \\beta_2^* e^{-i \\Theta_1} z^*  -2|\\beta_1|\\alpha_2,\n\\qquad z \\in \\T.\n\\end{equation}\nThen the function $\\T \\ni z \\longmapsto f(z) \\in \\C$ is nowhere vanishing if and only if $|\\alpha_1| \\neq |\\alpha_2|.$ In this case, we have\n\\begin{equation}\n\\label{equation1: winding number of matsuzawa function}\n\\wn(f) =\n\\begin{cases}\n\\sgn \\alpha_1, & |\\alpha_1| > |\\alpha_2|, \\\\\n0,             & |\\alpha_1| < |\\alpha_2|,\n\\end{cases}\n\\end{equation}\nwhere the sign function $\\sgn$ is defined by \\cref{equation: definition of sign function}.\n\\end{lemma}\nAs we shall see below, if $\\alpha_1\\beta_2 \\neq 0,$ then the image of the function $f$ turns out to be an ellipse. In this case, the curve $[0,2\\pi] \\ni t \\longmapsto f(e^{it}) \\in \\C$ makes precise one revolution around the fixed point $-|\\beta_1|\\alpha_2$ on the real axis, and so we have $\\wn(f) \\in \\{-1,0,+1\\}.$\n\\begin{proof}\nLet us first prove that $f$ is nowhere vanishing if and only if $|\\alpha_1 \\beta_2| \\neq |\\beta_1 \\alpha_2|.$ In this case,\n\\begin{equation}\n\\label{equation2: winding number of matsuzawa function}\n\\wn(f) =\n\\begin{cases}\n\\sgn \\alpha_1, & |\\alpha_1 \\beta_2| >  |\\beta_1 \\alpha_2|, \\\\\n0,             & |\\alpha_1 \\beta_2| <  |\\beta_1 \\alpha_2|.\n\\end{cases}\n\\end{equation}\nLet us consider the following function on $\\R;$\n\\[\n2F(s) := (|\\alpha_1 \\beta_2| + |\\beta_2|) e^{is} + (|\\alpha_1 \\beta_2| - |\\beta_2|)e^{-i s}\n= 2 |\\alpha_1 \\beta_2| \\cos s + i 2|\\beta_2| \\sin s, \\qquad s \\in \\R.\n\\]\nOn one hand, if $\\alpha_1 \\beta_2 = 0,$ then the image of $F$ is a vertical line segment passing through the origin $0 + i0.$ On the other hand, if $\\alpha_1 \\beta_2 \\neq 0,$ then the image of $F$ is an ellipse centred at the origin. For each $t \\in [0,2\\pi]$\n\\begin{align*}\n2f(e^{i t}) + 2|\\beta_1|\\alpha_2\n&= (\\alpha_1 + 1) \\beta_2 e^{i \\Theta_1} e^{i t} + (\\alpha_1 - 1) \\beta_2^* e^{-i \\Theta_1} e^{-i t} \\\\\n&= (\\sgn \\alpha_1|\\alpha_1| + 1) |\\beta_2| e^{i(\\Theta_1 + \\Theta_2 + t)} + (\\sgn \\alpha_1|\\alpha_1| - 1) |\\beta_2| e^{-i(\\Theta_1 + \\Theta_2 + t)}  \\\\\n&= \\sgn \\alpha_1 \\cdot 2F(\\sgn \\alpha_1(\\Theta_1 + \\Theta_2 + t)).\n\\end{align*}\nIf $\\alpha_1 \\beta_2 = 0,$ then the image of the function $[0,2\\pi] \\ni t \\longmapsto f(e^{i t}) \\in \\C$ coincides with that of the vertical line segment $[-1,1] \\ni t \\longmapsto -|\\beta_1|\\alpha_2 + i t|\\beta_2| \\in \\C$ passing through $-|\\beta_1|\\alpha_2.$ That is, $f$ does not go through the origin if and only if $\\beta_1\\alpha_2 \\neq 0 = \\alpha_1 \\beta_2,$ and in this case $\\wn(f) = 0.$ This is a special case of \\cref{equation2: winding number of matsuzawa function}. If $\\alpha_1 \\beta_2 \\neq 0,$ then the image of the curve $[0,2\\pi] \\ni t \\longmapsto f(e^{i t}) \\in \\C$ is the following ellipse with $\\sgn \\alpha_1$ being its winding number with respect to the center $-|\\beta_1|\\alpha_2$ on the real axis;\n\\[\n\\begin{tikzpicture}\n\\begin{axis}[axis y line=none,ticks=none,xmin=-8, xmax=8, ymin=-2, ymax=2, legend pos = north west, axis lines=center, xlabel=$\\Re$, xlabel style={anchor = west}, width = 0.9\\textwidth, height = 0.5\\textwidth]\n\t\\addplot [domain=-2*pi:2*pi,samples=50, smooth]({3*cos(deg(x))},{sin(deg(x))});\n\t\\addplot [mark=none,forget plot, dashed] coordinates {(3, -1.5) (3, 1.5)};\n\t\\addplot [mark=none,forget plot, dashed] coordinates {(-3, -1.5) (-3, 1.5)};\n\t\\addplot [mark=none,forget plot, dashed] coordinates {(0, -1.5) (0, 1.5)};\n\t\\draw [fill, black!20!blue] (-3,0) circle (1.5 pt) node [anchor = north east] {$-|\\beta_1|\\alpha_2 - |\\alpha_1 \\beta_2|$};\n\t\\draw [fill, black!20!red] (3,0) circle (1.5 pt) node [anchor = north west] {$-|\\beta_1|\\alpha_2 + |\\alpha_1 \\beta_2|$};\n\t\\draw [fill] (0,0) circle (1.5 pt) node [anchor = north west] {$-|\\beta_1|\\alpha_2$};\n\\end{axis}\n\\end{tikzpicture}\n\\]\n\nIf $|\\alpha_1 \\beta_2| >  |\\beta_1 \\alpha_2|,$ then the origin is inside the interior of the ellipse, and so $\\wn(f) = \\sgn \\alpha_1.$ If $|\\alpha_1 \\beta_2| <  |\\beta_1 \\alpha_2|,$ then the origin is inside the exterior of the ellipse, and so $\\wn(f) = 0.$ Clearly, the ellipse $f$ goes through the origin if and only if $|\\alpha_1 \\beta_2| =  |\\beta_1 \\alpha_2|.$\n\nIt remains to check that \\cref{equation1: winding number of matsuzawa function} coincides with \\cref{equation2: winding number of matsuzawa function}. If the notation $\\lessgtr$ simultaneously denotes $>, =, <,$ then\n$|\\alpha_1 \\beta_2| \\lessgtr  |\\beta_1 \\alpha_2|$ if and only if  $|\\alpha_1|^2 |\\beta_2|^2 \\lessgtr  |\\beta_1|^2 |\\alpha_2|^2$ if and only if $|\\alpha_1|^2 \\lessgtr |\\alpha_2|^2$ if and only if $|\\alpha_1| \\lessgtr |\\alpha_2|.$ The claim follows.\n\\end{proof}\n\n\n\\begin{proof}[Proof of \\cref{theorem: split-step}(i)]\n(1) Let $\\alpha_1 := p(\\star), \\beta_1:= q(\\star), \\alpha_2:= a(\\star), \\beta_2:= b(\\star), \\Theta := \\theta(\\star).$ Then \\cref{equation2: definition of matsuzawa function} becomes\n\\[\n2f(z) =\n(p(\\star) + 1) b(\\star) e^{i \\theta(\\star)} z + (p(\\star) - 1)  b(\\star)^* e^{-i \\theta(\\star)} z^*  -2|q(\\star)|a(\\star) = -2if_\\epsilon(z,\\star), \\qquad z \\in \\T.\n\\]\nThat is, $f = -if_\\epsilon(\\cdot,\\star),$ where the constant $-i$ does not play a significant role in this proof. It follows from \\cref{lemma: matsuzawa function is an ellipse} that $f_\\epsilon(\\cdot,\\star)$ is nowhere vanishing if and only if $|p(\\star)| \\neq |a(\\star)|.$ In this case, we have\n\\begin{equation}\n\\label{equation: winding number of fepsilon}\n\\wn(f_\\epsilon(\\cdot,\\star)) = \\wn(f) =\n\\begin{cases}\n\\sgn p(\\star), & |p(\\star)| > |a(\\star)|, \\\\\n0,             & |p(\\star)| < |a(\\star)|.\n\\end{cases}\n\\end{equation}\nThe index formula \\cref{equation1: Witten index formula} is now an immediate consequence of \\cref{equation1: witten index expressed as the difference of winding numbers} and \\cref{equation: winding number of fepsilon}.\n\n(2) Let $\\alpha_1 := a(\\star), \\beta_1:= b(\\star), \\alpha_2:= p(\\star), \\beta_2:= q(\\star), \\Theta := \\phi(\\star).$ Then \\cref{equation2: definition of matsuzawa function} becomes\n\\[\n2f(z) =\n(a(\\star) + 1) q(\\star) e^{i \\phi(\\star)} z + ( a(\\star) - 1) q(\\star)^* e^{-i \\phi(\\star)} z^*  -2| b(\\star)|p(\\star) =\n(2if_\\gamma(z,\\star))^*,\n\\qquad z \\in \\T.\n\\]\nThat is, $f^* = -if_\\epsilon(\\cdot,\\star).$ It follows from \\cref{lemma: matsuzawa function is an ellipse} that $f_\\gamma(\\cdot,\\star)$ is nowhere vanishing if and only if $|a(\\star)| \\neq |p(\\star)|.$ In this case, we have\n\\begin{equation}\n\\label{equation: winding number of fgamma}\n\\wn(f_\\gamma(\\cdot,\\star)) = \\wn(f^*) = -\\wn(f) =\n\\begin{cases}\n-\\sgn a(\\star), & |a(\\star)| > |p(\\star)|, \\\\\n0,             & |a(\\star)| < |p(\\star)|,\n\\end{cases}\n\\end{equation}\nwhere the last equality follows from $\\wn(f^*) = -\\wn(f).$ The index formula \\cref{equation2: Witten index formula} is now an immediate consequence of \\cref{equation2: witten index expressed as the difference of winding numbers} and \\cref{equation: winding number of fgamma}.\n\\end{proof}\n\n\\cref{theorem: split-step}(i) can also be proved by a purely analytic method without relying on \\cref{lemma: matsuzawa function is an ellipse}\n(see, for example, \\cite[\\textsection 4]{Matsuzawa-2020}).\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Proof of Theorem B (ii)}\n\\label{section: essential spectrum}\n\n\n\n\\begin{proof}[Proof of \\cref{theorem: split-step} (ii)]\nIt follows from a direct computation that $U = \\varGamma \\varGamma'$ is a strictly local operator of the following form;\n\\begin{align*}\nU =\n\\begin{pmatrix}\np & q L \\\\\nL^{-1} q^*  & -p(\\cdot - 1)\n\\end{pmatrix}\n\\begin{pmatrix}\na & b^* \\\\\nb & -a\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nq Lb + pa &  - q  La + pb^*  \\\\\nL^{-1}q^*a - p(\\cdot - 1) b     &  L^{-1}q^* b^* +  p(\\cdot - 1) a\n\\end{pmatrix}.\n\\end{align*}\nFor each $\\star = \\pm \\infty$ and each $z \\in \\T,$ we introduce the following matrix according to \\cref{equation: definition of hatA};\n\\[\n\\hat{U}(z, \\star)\n:=\n\\begin{pmatrix}\nq(\\star) b(\\star)z + p(\\star) a(\\star)&  -(q(\\star) a(\\star) z - p(\\star) b(\\star)^*)  \\\\\nq(\\star)^* a(\\star) z^{-1} - p(\\star) b(\\star)  & q(\\star)^* b(\\star)^* z^{-1}  + p(\\star) a(\\star)\n\\end{pmatrix}\n=:\n\\begin{pmatrix}\nX(z,\\star) & -Y(z,\\star)^* \\\\\nY(z,\\star) & X(z,\\star)^*\n\\end{pmatrix}.\n\\]\nIt follows from \\cref{theorem: two-phase case}(ii) that the essential spectrum of the evolution operator $U$ is given by\n\\begin{equation}\n\\label{equation: definition of sigma pm}\n\\ess(U) = \\sigma(+\\infty) \\cup \\sigma(-\\infty), \\qquad \\sigma(\\pm \\infty) := \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{U}(z, \\pm \\infty)\\right) =\n\\bigcup_{t \\in [0,2\\pi]} \\sigma \\left(\\hat{U}(e^{it}, \\pm \\infty)\\right).\n\\end{equation}\nIt remains to compute $\\sigma(\\star)$ for each $\\star = \\pm \\infty.$ Recall that we have $q(\\star) = |q(\\star)| e^{i\\theta(\\star)}$ and $b(\\star) = |b(\\star)|e^{i\\phi(\\star)}$ by \\cref{equation: limits of theta}. For each $t \\in [0,2\\pi]$ we have\n\\begin{align*}\nX(e^{it},\\star) &= q(\\star) b(\\star) e^{it} + p(\\star) a(\\star) = |q(\\star) b(\\star)| e^{i(t+\\theta(\\star) + \\phi(\\star))} + p(\\star) a(\\star), \\\\\nY(e^{it},\\star) &= q(\\star) a(\\star) e^{it} - p(\\star) b(\\star)^* = |q(\\star)| a(\\star) e^{i(t+\\theta(\\star))} - p(\\star) |b(\\star)|e^{-i\\phi(\\star)}.\n\\end{align*}\nWe get the following characteristic equation for each $t \\in [0,2\\pi];$\n\\begin{align*}\n\\det\\left(\\hat{U}(e^{it}, \\star) - \\lambda\\right)\n&= \\lambda^2 - (X(e^{it},\\star) + X(e^{it},\\star)^*)\\lambda + X(e^{it},\\star)X(e^{it},\\star)^* + Y(e^{it},\\star)Y(e^{it},\\star)^* = 0.\n\\end{align*}\nwhere $X(e^{it},\\star)X(e^{it},\\star)^* + Y(e^{it},\\star)Y(e^{it},\\star)^* = 1$ for each $t \\in [0,2\\pi]$ by a direct computation. The above characteristic equation becomes the following quadratic equation:\n\\[\n\\lambda^2 - 2 \\left(p(\\star)a(\\star)  + |q(\\star)  b(\\star)| \\cos(t + \\theta(\\star) + \\phi(\\star))\\right) \\lambda + 1 = 0, \\qquad t \\in [0,2\\pi].\n\\]\nThus, if we let $\\tau(t, \\star) := p(\\star) a(\\star) + |q(\\star) b(\\star)| \\cos(t + \\theta(\\star) + \\phi(\\star))$ for each $t \\in [0,2\\pi],$ then the above equation has the following two solutions:\n\\[\n\\lambda_\\pm(t, \\star) := \\tau(t, \\star)  \\pm \\sqrt{\\tau(t, \\star)^2 - 1},\n\\]\nwhere $\\{\\tau(t,\\star)\\}_{t \\in [0,2\\pi]} = [p(\\star)a(\\star) - |q(\\star) b(\\star)|, p(\\star)a(\\star) + |q(\\star) b(\\star)|] \\subseteq [-1,1],$ since\n\\[\n\\sup_{t \\in [0,2\\pi]}\n|\\tau(t,\\star)|\n\\leq |p(\\star)a(\\star)| + |q(\\star) b(\\star)|\n\\leq \\frac{|p(\\star)|^2 + |a(\\star)|^2}{2} + \\frac{|q(\\star)|^2 + |b(\\star)|^2}{2} = 1.\n\\]\nIt follows that\n\\[\n\\sigma(\\star)\n= \\bigcup_{t \\in [0,2\\pi]}\\sigma \\left(\\hat{U}(e^{it}, \\star) \\right) = \\{\\lambda_\\pm(t, \\star)\\}_{t \\in [0,2\\pi]} =  \\left\\{x \\pm i\\sqrt{1 - x^2}\\right\\}_{ x \\in [p(\\star)a(\\star) - |q(\\star) b(\\star)|, p(\\star)a(\\star) + |q(\\star) b(\\star)|]}.\n\\]\nNote that $\\pm 1 \\in \\sigma(\\star)$ if and only if $p(\\star)a(\\star) \\pm |q(\\star) b(\\star)| = \\pm 1.$\nIt can be shown that the last equations are equivalent to $(p(\\star) \\mp a(\\star))^2 = 0,$ and so it follows from \\cref{equation: definition of sigma pm} that $\\ess(U)$ does not contain both $-1,+1$ if and only if $|p(\\star)| \\neq |a(\\star)|$ for each $\\star = \\pm \\infty.$ Finally, the formula \\cref{equation: essential spectrum of U} follows from the fact that $x \\in [p(\\star)a(\\star) - |q(\\star) b(\\star)|, p(\\star)a(\\star) + |q(\\star) b(\\star)|]$ if and only if $\\sgn(p(\\star)a(\\star))x \\in I(\\star)$ for each $x \\in [-1,1].$\n\\end{proof}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsection{Several concluding remarks}\n\\label{section: concluding remarks}\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsubsection{The essential spectrum of the imaginary part}\n\n\\begin{lemma}\n\\label{lemma: characterisation of unitary chiral pair}\nLet $\\cH$ be an abstract Hilbert space, and let $(\\varGamma, \\varGamma')$ be a chiral pair on $\\cH.$ Let $U := \\varGamma \\varGamma'$ be the associated evolution operator, and let $R,Q$ be the real and imaginary parts of $U$ respectively. Then\n\\begin{align}\n% ------------------------ %\n\\label{equation: spectral mapping theorem for essential of R}\n\\ess(R) = \\left\\{\\frac{z + z^*}{2} \\mid z \\in \\ess(U)\\right\\}, \\\\\n% ------------------------ %\n\\label{equation: spectral mapping theorem for essential of Q}\n\\ess(Q) = \\left\\{\\frac{z - z^*}{2i} \\mid z \\in \\ess(U)\\right\\},\n\\end{align}\n\\end{lemma}\n\\begin{proof}\nLet $\\cB(\\cH) \\ni A \\longmapsto [A] \\in \\cB(\\cH)/\\cK(\\cH)$ be the natural surjection onto the Calkin algebra $\\cB(\\cH)/\\cK(\\cH).$ If $p : \\T \\to \\C$ is a trigonometric polynomial of the form $p(z) = \\sum_{y=-k}^k a(y) z^y$ for each $z \\in \\T,$ then\n\\begin{equation}\n\\ess(p(U))\n= \\sigma \\left(\\left[\\sum_{y=-k}^k a(y) U^y\\right] \\right)\n= \\sigma \\left(\\sum_{y=-k}^k a(y) \\left[U\\right]^y \\right)\n= \\sigma \\left( p([U]) \\right)\n= p(\\sigma \\left( [U] \\right))\n= p( \\ess(U)),\n\\end{equation}\nwhere the second last equality follows from the spectral mapping theorem. If we let $p(z) := (z + z^*)/2$ (resp. $p(z) := (z - z^*)/(2i)$) for each $z \\in \\T,$ then $p(U) = R$ (resp. $p(U) = Q$). The claim follows.\n\\end{proof}\n\nIt follows from \\cref{equation: spectral mapping theorem for essential of Q} that the following characterisations holds true:\n\\begin{equation}\n\\label{equation: characterisation of Fredholmness}\n\\mbox{The chiral pair } (\\varGamma,\\varGamma') \\mbox{ is Fredholm if and only if } 0 \\notin \\ess(Q) \\mbox{ if and only if } -1,+1 \\notin \\ess(U).\n\\end{equation}\nNote that \\cref{equation: characterisation of Fredholmness} explains why we have the same characterisation $|p(\\star)| \\neq |a(\\star)|$ for each $\\star = \\pm \\infty$ in \\cref{theorem: split-step}(i) and \\cref{theorem: split-step}(ii).\n\n\\begin{theorem}\nIf $(\\varGamma,\\varGamma' )$ is the chiral pair in \\cref{theorem: split-step} and if $Q$ is the imaginary part of the evolution operator $U := \\varGamma \\varGamma' ,$ then the following formula holds true;\n\\begin{equation}\n\\label{equation: formula for the essential spectrum of Q}\n\\ess(Q)\n= \\bigcup_{\\star = \\pm \\infty} \\left\\{\\pm |f_\\epsilon(z,\\star)|\\right\\}_{z \\in \\T}\n= \\bigcup_{\\star = \\pm \\infty} \\left\\{\\pm |f_\\gamma(z,\\star)|\\right\\}_{z \\in \\T},\n\\end{equation}\nwhere $f_\\epsilon(z,\\star)$ and $f_\\gamma(z,\\star)$ are given respectively by \\cref{equation1: definition of fepsilon} and \\cref{equation2: definition of fgamma}.\n\\end{theorem}\n\\begin{proof}\nIt follows from \\cref{lemma: wada decomposition} that the block-operator matrix representation of $Q_\\epsilon := \\epsilon^* Q \\epsilon$ is given explicitly by the last equality in \\cref{equation1: wada decomposition}. Let $\\theta_+, \\theta_-$ be as in \\cref{lemma: phase problem}, and let us consider the following unitary transform of $Q_\\epsilon;$\n\\[\nA :=\n\\begin{pmatrix}\ne^{-i \\theta_-} & 0 \\\\\n0 & e^{-i \\theta_+}\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & Q_{\\epsilon_0}^* \\\\\nQ_{\\epsilon_0} & 0\n\\end{pmatrix}\n\\begin{pmatrix}\ne^{i \\theta_-} & 0 \\\\\n0 & e^{i \\theta_+}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 & e^{-i \\theta_-} Q_{\\epsilon_0}^* e^{i \\theta_+} \\\\\ne^{-i \\theta_+} Q_{\\epsilon_0} e^{i \\theta_-} & 0\n\\end{pmatrix}.\n\\]\nWe are in a position to apply \\cref{theorem: two-phase case}(ii) to the above strictly local operator. We introduce the following matrix-valued function according to \\cref{equation: definition of hatA};\n\\[\n\\hat{A}(\\cdot, \\star) :=\n\\begin{pmatrix}\n0 & f_\\epsilon(\\cdot,\\star)^* \\\\\nf_\\epsilon(\\cdot,\\star) & 0\n\\end{pmatrix}, \\qquad \\star = \\pm \\infty,\n\\]\nwhere $\\sigma \\left(\\hat{A}(z, \\star) \\right) = \\{\\pm |f_\\epsilon(z,\\star)|\\}$ for each $z \\in \\T$ and each $\\star = \\pm \\infty.$ It follows from \\cref{theorem: two-phase case}(ii) that\n\\[\n\\ess(A)\n= \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{A}(\\cdot, -\\infty)\\right)  \\cup \\bigcup_{z \\in \\T} \\sigma \\left(\\hat{A}(\\cdot, +\\infty)\\right)\n= \\bigcup_{z \\in \\T} \\{\\pm |f_\\epsilon(z,-\\infty)|\\} \\cup \\bigcup_{z \\in \\T} \\{\\pm |f_\\epsilon(z,+\\infty)|\\}.\n\\]\nSince the essential spectrum is invariant under unitary transforms, we have $\\ess(Q) = \\ess(Q_\\epsilon) = \\ess(A).$ It follows that the first equality in \\cref{equation: formula for the essential spectrum of Q} holds true. The second equality follows similarly.\n\\end{proof}\n\n\n% ------------------------------------------------------------------------------------------------------------ %\n\\subsubsection{Topologically protected bound states}\n\\label{section: topologically protected bound states}\n\nWhat follows is the subject of another paper in preparation. Let $(\\varGamma, \\varGamma')$ be a chiral pair defined on an abstract Hilbert space $\\cH,$ and let $R, Q$ be the real and imaginary parts of the evolution operator $U := \\varGamma \\varGamma'$ respectively. With the block-operator matrix representations \\crefrange{equation: representation of R}{equation: representation of U} in mind, we define the following two indices:\n\\begin{equation}\n\\label{equation: definition of the GW indices}\n\\ind_\\pm (\\varGamma, \\varGamma') := \\dim \\ker(R_1 \\mp 1) -  \\dim \\ker(R_2 \\mp 1).\n\\end{equation}\nThe operator $U = R + iQ$ is unitary, and so $[R,Q] = 0$ and $R^2 + Q^2 = 1.$ It immediately follows from the second equality that the two indices $\\ind_\\pm (\\varGamma, \\varGamma')$ given by \\cref{equation: definition of the GW indices} are well-defined, if the chiral pair $(\\varGamma, \\varGamma')$ is Fredholm. In this case, it is not difficult to prove:\n\\begin{align}\n% -------------------------- %\n\\label{equation: GW indices expressed as the sum and difference of Witten indices}\n\\ind_\\pm (\\varGamma, \\varGamma') &= \\frac{\\ind(\\varGamma, \\varGamma') \\pm \\ind(\\varGamma', \\varGamma)}{2}, \\\\\n% -------------------------- %\n\\label{equation: topologically protected bound states}\n|\\ind_\\pm (\\varGamma, \\varGamma')| &\\leq \\dim \\ker(U \\mp 1),\n\\end{align}\nwhere non-zero vectors in $\\ker(U \\mp 1)$ may be referred to as \\textbi{topologically protected bound states} as in Physics literature (see, for example, \\cite{Kitagawa-Rudner-Berg-Demler-2010,Kitagawa-Broome-Fedrizzi-Rudner-Berg-Kassal-Aspuru-Demler-White-2012}). The three indices $\\ind(\\varGamma,\\varGamma'), \\ind_\\pm(\\varGamma,\\varGamma')$ coincide with the \\textbi{symmetry indices} $\\textrm{si}(U), \\textrm{si}_\\pm(U)$ discussed in \\cite{Cedzich-Geib-Grunbaum-Stahl-Velazquez-Werner-Werner-2018,Cedzich-Geib-Stahl-Velazquez-Werner-Werner-2018}.\n\n\nIf $(\\varGamma,\\varGamma' )$ is the chiral pair in \\cref{theorem: split-step}, then it follows from \\cref{theorem: split-step}(i) and \\cref{equation: GW indices expressed as the sum and difference of Witten indices} that $\\ind_\\pm (\\varGamma,\\varGamma' )$ are given explicitly by the following formulas:\n\\begin{equation}\n\\label{equation: GW index for ssqw}\n2 \\cdot \\ind_\\pm (\\varGamma,\\varGamma' ) =\n\\begin{cases}\n\\mp \\sgn a(+\\infty) \\pm \\sgn a(-\\infty),                &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and } |p(+\\infty)| < |a(+\\infty)|, \\\\\n+\\sgn p(+\\infty) \\pm \\sgn a(-\\infty), &  |p(-\\infty)| < |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| > |a(+\\infty)|, \\\\\n-  \\sgn p(-\\infty) \\mp \\sgn a(+\\infty), &  |p(-\\infty)| > |a(-\\infty)| \\mbox{ and }  |p(+\\infty)| < |a(+\\infty)|, \\\\\n+\\sgn p(+\\infty) - \\sgn p(-\\infty), &  |p(-\\infty)| >  |a(-\\infty)| \\mbox{ and } |p(+\\infty)| > |a(+\\infty)|,\n\\end{cases}\n\\end{equation}\nwhere we assume $|p(\\star)| \\neq |a(\\star)|$ for each $\\star = \\pm \\infty.$ With \\cref{equation: topologically protected bound states} in mind, the formula \\cref{equation: GW index for ssqw} can be used to give a lower bound for the number of topologically protected bound states associated with this explicit one-dimensional quantum walk model. This estimate is robust in the sense that the lower bounds $|\\ind_\\pm (\\varGamma,\\varGamma' )|$ depend only on the four asymptotic values $p(\\pm \\infty), a(\\pm \\infty).$\n\nNote that an estimate of this kind can also be obtained via the \\textbi{spectral mapping for discrete-time quantum walks} discussed in \\cite{Segawa-Suzuki-2016,Segawa-Suzuki-2019}. Indeed, \\cite[Theorem 3.1(iii)]{Suzuki-2019} states that if $U := \\varGamma \\varGamma'$ denotes the evolution operator of an abstract chiral pair $(\\varGamma, \\varGamma'),$ where $\\varGamma'$ is expressed as $\\varGamma' = 2d^*d - 1$ for some fixed co-isometry (i.e. $dd^* = 1$), then the following equalities hold true:\n\\[\n\\dim \\ker(U \\mp 1) = m_\\pm + M_\\pm,\n\\]\nwhere $m_\\pm := \\dim \\ker(d \\varGamma d^* \\mp 1)$ and $M_\\pm := \\dim \\ker(\\varGamma \\mp 1) \\cap \\ker d.$ For example, as in \\cite[Remark 6.2]{Fuda-Funakawa-Suzuki-2018}, if $U = \\varGamma \\varGamma' $ is the evolution operator associated with the chiral pair $(\\varGamma,\\varGamma' ),$ defined in \\cref{theorem: split-step}, with $p, q$ being held constant, then one can solve some first-order difference equations to show that there exists a well-defined constant $k > 0,$ such that the condition $|q| < k$ ensures $\\dim \\ker(U \\mp 1) = 1.$\n\n\n\\bibliographystyle{alpha}\n\\bibliography{Bibliography}\n\n\\end{document}\n\n\n\\begin{enumerate}\n\\item \\textbf{Non-linear quantum walks}: .\n\\item \\textbf{One-dimensional quantum walk}:\n\\item \\textbf{Essential spectrum}: \\cite{Sasaki-Suzuki-2017} deals with Graph Laplacian\n\\item \\textbf{Scattering}: ,\n\\item \\textbf{SMT}: more detailed study of SMT\n%\\item \\textbf{SSQW}: The purpose of \\cite{Suzuki-Tanaka-2019} is to compute the Witten index for an explicit one-dimensional split-step quantum walk \\cite{Fuda-Funakawa-Suzuki-2019,Fuda-Funakawa-Suzuki-2018,Fuda-Funakawa-Suzuki-2017}, where \\cite{Fuda-Funakawa-Suzuki-2019} deals with a weak limit theorem for a split-step qw and \\cite{Fuda-Funakawa-Suzuki-2018} makes use of the difference equation method. \\cite{Fuda-Funakawa-Suzuki-2017} makes use of the SMT.\n\\item \\textbf{Continuous limits}:\\cite{Maeda-Suzuki-2019}.\n\\item \\textbf{M}: .\n\\end{enumerate}", "meta": {"timestamp": "2020-10-28T00:31:21", "yymm": "2010", "arxiv_id": "2010.14466", "url": "https://arxiv.org/abs/2010.14466", "source": "arxiv"}}
{"text": "\\documentclass[12pt]{article}\n\n\\usepackage{amsmath,amsfonts,amssymb,amsthm}\n\\usepackage{fullpage}\n\\usepackage[colorlinks]{hyperref} \n\\usepackage{enumitem} \n\\usepackage{graphicx,tikz}\n\\usepackage{mathtools}\n\n\\urlstyle{same}\n        \t\t\n\\renewcommand{\\qedsymbol}{$\\blacksquare$}\n\\newcommand*{\\QED}{\\hfill\\ensuremath{\\blacksquare}}\n\\DeclarePairedDelimiter\\floor{\\lfloor}{\\rfloor}\n\\DeclarePairedDelimiter\\ceil{\\lceil}{\\rceil}\n\\DeclareMathOperator{\\ex}{ex}\n\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{conjecture}[theorem]{Conjecture}\n\\newtheorem{fact}[theorem]{Fact}\n\\newtheorem{observation}[theorem]{Observation}\n\\theoremstyle{definition}\n\\newtheorem*{definition}{Definition}\n\\theoremstyle{remark}\n\\newtheorem*{remark}{Remark}\n\n\\newcommand{\\ds}{\\displaystyle}\n\\newcommand{\\field}{\\mathbb{F}}\n\\newcommand{\\integers}{\\mathbb{Z}}\n\\newcommand{\\reals}{\\mathbb{R}}\n\\newcommand{\\E}{\\mathbb{E}}\n\\newcommand{\\tcr}{\\textcolor{red}}\n\\newcommand{\\rK}{\\text{rainbow-}K}\n\\newcommand{\\rH}{\\text{rainbow-}H}\n\\newcommand{\\rC}{\\text{rainbow-}C}\n\\newcommand{\\rF}{\\text{rainbow-}F}\n\n\\hypersetup{\n  colorlinks,\n  citecolor=blue,\n  urlcolor=blue}\n  \n\n\\title{Generalized Rainbow Tur\\'an  Numbers of Odd Cycles}\n\n\\author{\n  J\\'ozsef Balogh \\footnote{Department of Mathematics, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA, and Moscow Institute of Physics and Technology, Russian Federation. E-mail: \\texttt{jobal@illinois.edu}. Research supported by NSF RTG Grant DMS-1937241, NSF Grant DMS-1764123, Arnold O. Beckman Research Award (UIUC Campus Research Board RB 18132), the Langan Scholar Fund (UIUC), and the Simons Fellowship.}\n \\and Michelle Delcourt \\footnote {Department of Mathematics,  Ryerson  University,   Toronto,  Ontario  M5B  2K3, Canada. E-mail: \\texttt{mdelcourt@ryerson.ca}.  Research supported by NSERC under Discovery Grant No.2019-04269 and an AMS-Simons Travel Grant.}\n \\and Emily Heath \\footnote {Department of Mathematics, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA, Email: \\texttt{eheath3@illinois.edu}. Research supported by NSF RTG Grant DMS-1937241.}\n \\and Lina Li \\footnote {Department of Combinatorics and Optimization, University of Waterloo, Waterloo, Ontario N2L 3G1, Canada, Email: \\texttt{lina.li@uwaterloo.ca}.}\n  }\n\n\n\\begin{document}\n\\maketitle\n\n\\begin{abstract}\nGiven graphs $F$ and $H$, the \\emph{generalized rainbow Tur\\'an number} $\\ex(n,F,\\rH)$ is the maximum number of copies of $F$ in an $n$-vertex graph with a proper edge-coloring that contains no rainbow copy of $H$. B.~Janzer~\\cite{J1} determined the order of magnitude of $\\ex(n,C_s,\\rC_t)$ for all $s\\geq 4$ and $t\\geq 3$, and a recent result of O.~Janzer~\\cite{J2} implied that $\\ex(n,C_3,\\rC_{2k})=O(n^{1+1/k})$. \nWe prove the corresponding upper bound for the remaining cases, showing that  $\\ex(n,C_3,\\rC_{2k+1})=O(n^{1+1/k})$. This matches the known lower bound for $k$ even and is conjectured to be tight for $k$ odd.\n\\end{abstract}\n\n\n\\section{Introduction}\n\nThe \\emph{Tur\\'an number} of a graph $H$ is the maximum number of edges in an $H$-free graph on $n$ vertices, denoted $\\ex(n,H)$. \nThis has been generalized in many different ways. For example, the \\emph{rainbow Tur\\'an number} $\\ex^*(n,H)$, introduced in \\cite{KMSV}, is the maximum number of edges in a graph on $n$ vertices which can be properly edge-colored with no rainbow copy of $H$. \n% define rainbow?\nAnother natural variation is the \\emph{generalized Tur\\'an number} $\\ex(n,F,H)$,  which is the maximum number of copies of a graph $F$ in an $n$-vertex graph that contains no copy of $H$, and was introduced systematically by Alon and Shikhelman~\\cite{AS}.\nBoth of these problems have been extensively studied, see for example~\\cite{J2,KMSV} and \\cite{AS,GGMV,GS, GL}.\n\nGerbner, M\\'esz\\'aros, Methuku and Palmer~\\cite{GMMP}\nconsidered the following generalized problem which unites the two concepts above.\nGiven two graphs $F$ and $H$, the \\emph{generalized rainbow Tur\\'an number}, denoted by $\\ex(n,F,\\rH)$, is the maximum number of copies of $F$ in an $n$-vertex graph which can be properly edge-colored to avoid a rainbow copy of $H$. Note that trivially $\\ex(n,F,\\rH)\\geq \\ex(n,F,H)$. The question for $F = H$ has been studied for paths, trees, cycles and cliques, see~\\cite{GMMP,GJ,J1}.\n\nRecently, B.~Janzer~\\cite{J1} determined the order of magnitude of $\\ex(n,C_s,\\rC_t)$ for all cases except for $s=3$. \nIn the case $s=3$, he gave the following bounds.\n\\begin{theorem}[Janzer~\\cite{J1}]\\label{thm Janzer}\nIf $k \\geq 2$ is odd then $\\ex(n, C_3,\\rC_{2k}) = \\Omega(n^{1+1/k})$, and if $k$ is even then $\\ex(n, C_3,\\rC_{2k+1}) = \\Omega(n^{1+1/k})$. Furthermore, for every integer $k \\geq 2$, we have\n\\[\\ex(n, C_3,\\rC_{2k}) = O(\\ex^*(n, C_{2k})),\\]\nand\n\\[\\ex(n, C_3,\\rC_{2k}) \\geq \\ex(n, C_3, C_{2k}) = \\Omega(\\ex(n, \\{C_4, C_6,\\dots, C_{2k}\\})),\\]\n\\[\\ex(n, C_3,\\rC_{2k+1}) \\geq \\ex(n, C_3, C_{2k+1}) = \\Omega(\\ex(n, \\{C_4, C_6,\\dots, C_{2k}\\})).\\]\n\\end{theorem}  \nVery recently, O.~Janzer~\\cite{J2},  settling a conjecture of Keevash, Mubayi, Sudakov and Verstra\\\"{e}te~\\cite{KMSV}, proved that $\\ex^*(n, C_{2k})=\\Theta(n^{1 +1/k})$. Together with Theorem~\\ref{thm Janzer}, this leads to \n\\[\n\\ex(n, C_3,\\rC_{2k}) = O(n^{1 +1/k}),\n\\]\nwhich is tight for $k$ odd.\n\nWe study the remaining open cases for cycles, proving an upper bound on $\\ex(n,C_3,C_{2k+1})$ which matches the lower bound given by B.~Janzer~\\cite{J1} for $k$ even and which is expected to be sharp for $k$ odd as well. \n\n\\begin{theorem}\\label{thm longer cycles} \nFor $k\\geq 3$, we have \\[\\ex(n,C_3,\\rC_{2k+1})=O\\left(n^{1+1/k}\\right).\\]\n\\end{theorem}\n\nOur proof uses two main tools. First, we take a random partition of the vertices (as in Alon and Shikhelman~\\cite{AS}) which allows us to extend a rainbow copy of $C_{2k}$ to a longer cycle $C_{2k+1}$. Second, we adapt the arguments in O.~Janzer~\\cite{J2} which bound the number of rainbow, injective homomorphisms from even cycles into a properly edge-colored graph. Note that the results in~\\cite{J2} cannot be used as a black box for our proof; instead, we prove versions of the key lemmas for our new setting.\n\nIn Section~\\ref{sec C5}, we give a different short proof of the upper bound on $\\ex(n,C_3,\\rC_5)$ which gives an explicit constant. In Section~\\ref{sec tools}, we give the lemmas which will be needed to prove our main theorem. Finally, in Section~\\ref{sec longer cycles}, we prove Theorem~\\ref{thm longer cycles}. Throughout the paper, we use $P_k$ to denote the path with $k$ edges.\n\n\n\\section{No rainbow $C_5$}\\label{sec C5}\n\n\\begin{proof}\nLet $G$ be an $n$-vertex graph with a proper edge-coloring $c$ containing no rainbow copy of $C_5$. First, we will show that $G$ contains at most $\\frac{32}{3}|E(G)|$ triangles. \n\nFix a vertex $v\\in V(G)$ and let $d$ denote the degree of $v$. Fix a set $S\\subset N(v)$ containing half of the neighbors of $v$ in $G$. There are $\\binom{d}{\\lfloor d/2\\rfloor}$ ways to do this. Throw out any edge in $G[S]$ whose color appears on an edge incident with $v$ and $S$. \nLet $E'$ denote the set of remaining edges in $G[S]$. Now $E'$ must be rainbow $P_3$-free, otherwise we can find a rainbow copy of $C_5$ in $G$. \nJohnston, Palmer, and Sarkar~\\cite{JPS} showed that for $\\ell\\geq 1$,  \\begin{equation}\\label{lem:norainbowpath} \n\\frac{\\ell-1}{2}n\\sim\\ex(n,P_{\\ell})\\leq\\ex^*(n,P_{\\ell})\\leq\\left\\lceil\\frac{3\\ell-2}{2}\\right\\rceil n.\n\\end{equation}\nTherefore, we have $|E'|\\leq 2d$.  Thus, the number of triangles containing $v$ which are formed in this way, that is, the number of pairs of such a set $S$ and an edge from $E'$ of a different color, is at most $2d\\binom{d}{\\lfloor d/2\\rfloor}$.\n\nOn the other hand, we could instead first choose an edge $e$ in the neighborhood of $v$ to form our triangle, which can be done in $|E(G[N(v)])|$ ways, and then select an additional $\\lfloor d/2\\rfloor-2$ vertices from $N(v)$ to form the rest of $S$. However, we do not want the color of $e$ to appear on an edge incident to $v$. Since the edge coloring is proper, this only requires us to throw out at most one vertex from $N(v)$ since at most one edge incident to $v$ can have the same color as $e$. Thus, we can pick the remaining vertices of $S$ in at least $\\binom{d-3}{\\lfloor d/2\\rfloor-2}$ ways. Therefore, we have \n\\[|E(G[N(v)])|\\cdot \\binom{d-3}{\\lfloor d/2\\rfloor-2} \\leq 2d\\binom{d}{\\lfloor d/2\\rfloor}.\\]\nThus, $|E(G[N(v)])|\\leq 16d$, so the number of triangles in $G$ is at most \\[\\frac{1}{3}\\sum_{v\\in V(G)}|E(G[N(v)])|\\leq \\frac{16}{3}\\sum_{v\\in V(G)}d(v)=\\frac{32}{3}|E(G)|.\\]\n\nNext, we will give an upper bound on the number of edges in $G$. Assume towards a contradiction that $|E(G)|\\geq 8n^{3/2}$. We may assume that every edge in $G$ is in a triangle, otherwise we could delete the edge without decreasing the number of triangles. \n\nDelete all vertices of degree less than $4\\sqrt{n}$ in $G$.  Note that not all vertices are deleted, since otherwise $|E(G)|<4n^{3/2}$. Denote by $G'$ the remaining induced subgraph with minimum degree $\\delta(G')\\geq 4\\sqrt{n}$, and let $n'=|V(G')|$. Fix an arbitrary vertex $v\\in V(G')$.\n\nA \\textit{cherry} is a path of length 2. We will form an auxiliary graph $F$ with vertex set $V(F)=N_{G'}(v)$ which contains an edge $uw$ if and only if there are at least seven cherries of the form $uxw$ in $G'$. We will show that $F$ must contain a vertex of degree at least 3 and use this vertex to find a rainbow copy of $C_5$ in $G$.\n\nLet $S\\subseteq N_{G'}(v)$ be a set of $\\sqrt{n}$ vertices. We will count the cherries in $G'$ with endpoints in $S$. \nSince each vertex $x$ in $V(G')$ is in exactly $\\binom{d_S(x)}{2} \\footnote{$d_S(x)=|N_G(x)\\cap S|$.}$ cherries of this form, we can count the desired cherries as follows:\n\\begin{align*}\n    \\sum_{x\\in V(G')} \\binom{d_S(x)}{2} & \\geq n'\\binom{\\frac{1}{n'}\\sum d_S(x)}{2}\n     = n'\\binom{\\frac{1}{n'}\\sum_{s\\in S} d_{G'}(s)}{2}\n     \\geq n'\\binom{\\frac{1}{n'}\\cdot\\delta(G') |S|}{2}\\\\\n    &  \\geq \\frac{(\\delta(G')|S|)^2}{4n'}\n    \\geq \\frac{16n |S|^2}{4n'}\n     > 7\\binom{|S|}{2},\n\\end{align*}\nwhere we use $\\delta(G')\\geq 4\\sqrt{n}$.\nThus, there must be some pair of vertices in $S$ which are the endpoints of at least seven cherries in $G'$, and hence, these vertices are adjacent in $F$.  Since $S$ was an arbitrary set of $\\sqrt{n}$ vertices in $N_{G'}(v)=V(F)$, we have shown that  $\\alpha(F)\\leq \\sqrt{n}$. This gives $\\Delta(F)\\geq |F|/\\sqrt{n}\\geq 4\\sqrt{n}/\\sqrt{n}\\geq 3$, so there is a vertex $u$ in $F$ of degree at least 3. Let $x,y,z$ be neighbors of $u$ in $F$. By assumption, the edge $uv$ is in at least one triangle in $G$, so there is a vertex $w\\in V(G)$, possibly in $\\{x,y,z\\}$, which forms a triangle with $uv$. We will consider two cases for $w$.\n\n\n\\begin{figure}\n\\centering\n\\begin{tikzpicture}[scale=.8]\n\t\t\\filldraw[very thick, color=black,fill=white] (-6,0) ellipse (0.8 and 2);\n\t\t\\draw[very thick, black,->] (-4.2,0.4) -- (-3.2,0.4);\n\t\t\\filldraw[very thick, color=black,fill=white] (0.6,0) ellipse (2.35 and 2);\n\t\t\\filldraw[very thick, color=black,fill=white] (0.15,0) ellipse (0.7 and 1.8);\n\t    \\filldraw[very thick, color=black,fill=white] (7.6,0) ellipse (2.35 and 2);\n\t    \\filldraw[very thick, color=black,fill=white] (7.2,0) ellipse (0.7 and 1.8);\t\n\t\t% labels\n\t\t\\node[below] at (0.6,-2.4) {Case 1};\n\t\t\\node[below] at (7.6,-2.4) {Case 2};\n\t\t\\node[above] at (-6,2.1) {$F$};\n\t\t\\node[above] at (0.6,2.1) {$G'$};\n\t\t\\node[above] at (1.65,0.55) {$N_{G'}(v)$};\n\t\t\\node[above] at (7.6,2.1) {$G'$};\n\t\t\\node[above] at (8.65,0.55) {$N_{G'}(v)$};\n        % vertex labels\n        \\node at (-6.3,-1.4) {$u$};\n        \\node at (-6.4,-.4) {$z$};\n        \\node at (-6.4,.4) {$y$};\n        \\node at (-6.3,1.4) {$x$};\n        \\node at (-1.5,0) {$v$};\n        \\node at (-2.1,-2) {$w$};\n        \\node at (.3,-1.4) {$u$};\n        \\node at (.4,-.2) {$z$};\n        \\node at (.4,.5) {$y$};\n        \\node at (.3,1.4) {$x$};\n        \\node at (5.5,0) {$v$};\n        \\node at (7.2,-1.5) {$u$};\n        \\node at (7.4,-.4) {$z$};\n        \\node at (7.4,.4) {$y$};\n        \\node at (7.3,1.4) {$x$};\n        % edges\n\t\t\\draw[very thick, black, dashed] (-6,-1.2) -- (-6, -.4);\n\t\t\\draw[very thick, black ,dashed] (-6,-1.2) to [out=15,in=-15] (-6, .4);\n\t\t\\draw[very thick, black, dashed] (-6,-1.2) to [out=25,in=-25]  (-6, 1.2);\n\t\t\\draw[very thick, blue] (-1.4,-.4) -- (-1.8,-1.8); % vw\n\t\t\\draw[very thick, black] (-1.4,-.4) -- (0, -1.2);  \n\t\t\\draw[very thick, orange] (-1.4,-.4) -- (0, -.4); % zv\n\t\t\\draw[very thick, black] (-1.4,-.4) -- (0, .4);\n\t\t\\draw[very thick, black] (-1.4,-.4) -- (0, 1.2);\n\t\t\\draw[very thick, red] (-1.8,-1.8) -- (0,-1.2);  % wu\n\t\t\\draw[very thick, green!70!blue] (0,-1.2) -- (2,-.8); % ug\n\t\t\\draw[very thick, magenta!60!blue] (0,-.4) -- (2,-.8); % gz\n\t\t\\draw[very thick, black] (5.6,-.4) -- (7, -1.2);\n\t\t\\draw[very thick, blue] (5.6,-.4) -- (7, -.4); % vz\n\t\t\\draw[very thick, black] (5.6,-.4) -- (7, .4);\n\t\t\\draw[very thick, orange] (5.6,-.4) -- (7, 1.2); % xv\n\t\t\\draw[very thick, red] (7,-1.2) -- (7,-.4); % zu\n\t\t\\draw[very thick, green!70!blue] (7,-1.2) -- (8.9,-.5); % ug\n\t\t\\draw[very thick, magenta!60!blue] (7,1.2) -- (8.9,-.5); % gx\n\t\t% colors\n        \\node at (-1.85,-1.15) {1}; %vw\n        \\node at (-1.2,-1.9) {2}; %wu\n        \\node at (1.3,.-1.3) {5}; %ug\n        \\node at (1.3,-.35) {4}; %gz\n        \\node at (-.2,-.1) {3};\t%zv\t\n        \\node at (6.8,-.1) {1}; %vz\n        \\node at (7.2,-.8) {2}; %zu\n        \\node at (8.3,.-1.1) {5}; %ug\n        \\node at (8.6,0.2) {4}; %gx\n        \\node at (6.1,.6) {3};\t%xv\t\n        % vertices\n\t\t\\draw[fill=black] (-6,-1.2) circle (3pt); %u\n\t\t\\draw[fill=black] (-6,-.4) circle (3pt); %z\n\t\t\\draw[fill=black] (-6,.4) circle (3pt); %y\n\t\t\\draw[fill=black] (-6,1.2) circle (3pt); %x\n        \\draw[fill=black] (-1.4,-.4) circle (3pt); %v\n        \\draw[fill=black] (-1.8,-1.8) circle (3pt); %w\n        \\draw[fill=black] (0,-1.2) circle (3pt); %u\n        \\draw[fill=black] (0,-.4) circle (3pt); %z \n        \\draw[fill=black] (0,.4) circle (3pt); %y\n        \\draw[fill=black] (0,1.2) circle (3pt); %x\n        \\draw[fill=black] (2,-.8) circle (3pt); \n        \\draw[fill=black] (5.6,-.4) circle (3pt); %v\n        \\draw[fill=black] (7,-1.2) circle (3pt); %u\n        \\draw[fill=black] (7,-.4) circle (3pt); %z\n        \\draw[fill=black] (7,.4) circle (3pt); %y\n        \\draw[fill=black] (7,1.2) circle (3pt); %x\n        \\draw[fill=black] (8.9,-.5) circle (3pt);\n    \\end{tikzpicture}\n\\caption{If there is a vertex of degree at least 3 in $F$, then $G$ contains a rainbow copy of $C_5$. Edges in $F$ are dashed while edges in $G$ are solid.}\n\\label{figureC5}\n\\end{figure}\n\n\nFirst, assume $w\\notin\\{x,y,z\\}$. Let $c(vw)=1$ and $c(uw)=2$. Then since $c$ is a proper coloring, at most one edge of $\\{vx, vy, vz\\}$ can be colored with 2, and none of them is colored with 1. Assume $c(vz)=3$. Then since $uz$ is an edge in $F$, there must be at least seven cherries in $G'$ with endpoints $u$ and $z$, meaning that we can find a cherry with two new colors, say 4 and 5, which does not contain $v$ or $w$. Thus, there is a rainbow $C_5$ in $G$, a contradiction.\n\nNext, without loss of generality, assume $w=z$. In this case, $uz$ is also an edge in $G$, not just in $F$. Let $c(vz)=1$ and $c(uz)=2$. Then at least one of $vx$ and $vy$ is colored with a new color, say $c(vx)=3$. Since $ux$ is an edge in $F$, there are at least seven cherries in $G'$ with endpoints $u$ and $x$, and hence, at least one with new colors 4 and 5 which avoids $v$ and $z$. As before, this gives a rainbow $C_5$ in $G$, so we reach a contradiction. Therefore, $G$ must contain at most $8n^{3/2}$ edges, and hence, at most $\\frac{256}{3}n^{3/2}$ triangles, as desired.\n\\end{proof}\n\n\n\n\\section{No rainbow $C_{2k+1}$}\n\\subsection{Homomorphic copies of $C_{2k}$ in proper colorings}\\label{sec tools}\n\nIn this section, we give the lemmas which will be used to prove Theorem~\\ref{thm longer cycles} in Section~\\ref{sec longer cycles}. \nWe start by introducing some notation. \nLet $\\hom(H,G)$ denote the number of graph homomorphisms $V(H)\\rightarrow V(G)$. We use the convention $C_2=P_1$, so note that $\\hom(C_2, G)=2|E(G)|$. For vertices $x,y\\in V(G)$,   $\\hom_x(P_{\\ell},G)$ denotes the number of walks of length $\\ell$ in $F$ starting at $x$, and $\\hom_{x,y}(P_{\\ell},G)$ denotes the number of walks of length $\\ell$ in $G$ between $x$ and $y$. \n\nFor every $\\ell\\geq 2$, a \\emph{homomorphic copy} of $C_{2\\ell}$ is a tuple $(x_1, \\ldots, x_{2\\ell})\\in V(G)^{2\\ell}$ such that $x_1x_2, x_2x_3, \\dots, x_{2\\ell}x_1\\in E(G)$. A homomorphic copy is \\emph{injective} if $x_i\\neq x_j$ for every $i\\neq j$.\nGiven a graph $G$ with a proper edge-coloring $c$, we say that a list edge-coloring $L$ of $G$ is \\emph{$c$-proper} if for every $e\\in E(G)$, $|L(e)|=3$ and $c(e)\\in L(e)$.\nA homomorphic copy $(x_1, \\ldots, x_{2\\ell})$ of $C_{2\\ell}$ is \\emph{rainbow} if $c(x_ix_{i+1})\\neq c(x_jx_{j+1})$ for every $i\\neq j$.  We require stronger conditions in our proof: given a $c$-proper list edge-coloring $L$ of $G$, a homomorphic copy of $C_{2\\ell}$ is \\emph{extendable} if for some $i$, $c(x_jx_{j+1})\\notin L(x_ix_{i+1})$ for every $j\\neq i$, and a homomorphic copy of $C_{2\\ell}$ is \\emph{$(L, c)$-colorful} if $c(x_ix_{i+1})\\notin L(x_jx_{j+1})$ for all $i\\neq j$. \n\n\\begin{lemma}\\label{lem:norabow}\nLet $G$ be a properly edge-colored graph with coloring $c$, and $L$ be a $c$-proper list edge-coloring of $G$.\nFor every integer $\\ell\\geq 2$, the number of homomorphic copies of $C_{2\\ell}$ which are not $(L, c)$-colorful is at most\n\\[\n64\\ell(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G))^{1/2}.\n\\]\n\\end{lemma}\n\n\nWe remark that the proof of Lemma~\\ref{lem:norabow} is quite similar to that of Lemma~2.1 in~\\cite{J2}, with several key modifications.\nMore specifically, we count the homomorphic copies $x_1x_2\\ldots x_{2\\ell}x_1$ of $C_{2\\ell}$ such that $c(x_1x_2) \\in L(x_i x_{i+1})$ (rather than simply $c(x_1x_2)=c(x_ix_{i+1})$ in~\\cite{J2}) for some $2\\leq i\\leq \\ell+1$. By the symmetry of even cycles, there are at most\n$2\\cdot 2\\ell$ ways (rather that $2\\ell$ in~\\cite{J2}) to alter the position of $x_1x_2$, so we can bound the total number of homomorphic copies $x_1x_2\\ldots x_{2\\ell}x_1$ of $C_{2\\ell}$ with $c(x_jx_{j+1})\\in L(x_ix_{i+1})$ for some $i\\neq j$.\nMoreover, later in our argument, given $x_2,\\ldots, x_{\\ell+1}$, there are at most $3 \\ell$ proper choices for $x_1$ (rather than $\\ell$ in~\\cite{J2}), as we are comparing $c(x_1)$ with all the colors in the lists $L(x_2), \\ldots, L(x_{\\ell+1})$.\nWe include the details of the proof for self-completeness.\n\n\\begin{proof}[Proof of Lemma~\\ref{lem:norabow}]\nBy symmetry, it suffices to prove that the number of $(x_1, \\ldots, x_{2\\ell})\\in V(G)^{2\\ell}$ with $x_1x_2, x_2x_3, \\dots, x_{2\\ell}x_1\\in E(G)$ such that $c(x_1x_2\n)\\in L(x_ix_{i+1})$ for some $2\\leq i \\leq \\ell+1$ is at most \\[\n16(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G))^{1/2}.\n\\]\n\nFor a positive integer $s$, let $\\alpha_s$ be the number of walks of length $\\ell-1$ in $G$ whose endpoints $y$ and $z$ have\n\\[\n2^{s-1}\\leq \\hom_{y, z}(P_{\\ell-1}, G) <2^s,\n\\]\nand let $\\beta_s$ be the number of walks of length $\\ell$ in $G$ whose endpoints $y$ and $z$ have\n\\[\n2^{s-1}\\leq \\hom_{y, z}(P_{\\ell}, G) <2^s.\n\\]\nClearly, we have\n\\begin{equation}\\label{lem:norabow:def1}\n\\sum_{s\\geq 1}2^{s-1}\\alpha_s\\leq \\hom(C_{2\\ell-2}, G)    \n\\end{equation}\nand \n\\begin{equation}\\label{lem:norabow:def2}\n\\sum_{s\\geq 1}2^{s-1}\\beta_s\\leq \\hom(C_{2\\ell}, G).\n\\end{equation}\n\n\nFor positive integers $s$ and $t$, write $\\gamma_{s, t}$ for the number of homomorphic copies $(x_1, \\ldots, x_{2\\ell})$ of $C_{2\\ell}$ such that $c(x_1x_2\n)\\in L(x_ix_{i+1})$ for some $2\\leq i \\leq \\ell+1$,\n\\begin{equation}\\label{lem:norabow:cond}\n2^{s-1}\\leq \\hom_{x_1, x_{\\ell+2}}(P_{\\ell-1}, G) <2^s\n\\quad \\text{and} \\quad\n2^{t-1}\\leq \\hom_{x_2, x_{\\ell+2}}(P_{\\ell}, G) <2^t.\n\\end{equation}\nFirst observe that \n\\begin{equation}\\label{lem:norabow:bou1}\n\\gamma_{s, t}\\leq \\alpha_s\\cdot \\Delta(G)\\cdot 2^t.\n\\end{equation} \nIndeed, there are at most $\\alpha_s$ ways to choose $(x_{\\ell+2}, x_{\\ell+3},\\ldots, x_{2\\ell}, x_1)$. Given such a choice, there are at most $\\Delta(G)$ choices for $x_2$, and then by (\\ref{lem:norabow:cond}) there are at most $2^t$ choices for $(x_3,\\ldots, x_{\\ell+1})$. \nOn the other hand, we have \n\\begin{equation}\\label{lem:norabow:bou2}\n\\gamma_{s, t}\\leq \\beta_t\\cdot (3\\ell)\\cdot 2^s. \n\\end{equation}\nIndeed, there are at most $\\beta_t$ ways to choose $(x_2, \\ldots, x_{\\ell+2})$. Given such a choice, there are at most $3\\ell$ choices for $x_1$, since $c(x_1x_2)\\in L(x_ix_{i+1})$ for some $2\\leq i \\leq \\ell+1$, and $c$ is a proper coloring of $G$.\nThen by (\\ref{lem:norabow:cond}) there are at most $2^s$ ways to choose $(x_{\\ell+3}, \\ldots, x_{2\\ell})$.  \n\nLet $q$ be the integer for which \n\\begin{equation}\\label{lem:norabow:bou3}\n\\left(\\frac{\\ell\\cdot\\hom(C_{2\\ell}, G)}{\\Delta(G)\\hom(C_{2\\ell-2}, G)}\\right)^{1/2} \\leq 2^q < 2\\left(\\frac{\\ell\\cdot\\hom(C_{2\\ell}, G)}{\\Delta(G)\\hom(C_{2\\ell-2}, G)}\\right)^{1/2}.\n\\end{equation}\nFirst by (\\ref{lem:norabow:bou1}), (\\ref{lem:norabow:def1}), and (\\ref{lem:norabow:bou3}), we obtain that\n\\[\\begin{split}\n\\sum_{s, t, s> t-q}\\gamma_{s, t}\n&\\leq \\Delta(G)\\sum_{t\\geq 1}\\sum_{s\\geq t-q+1} 2^t\\alpha_s =\\Delta(G)\\sum_{s\\geq1}\\alpha_s\\sum_{t=1}^{s+q-1}2^t\n\\leq \\Delta(G)2^{q+1}\\sum_{s\\geq 1}2^{s-1}\\alpha_s\\\\ \n& \\leq \\Delta(G)2^{q+1}\\hom(C_{2\\ell-2}, G)\n\\leq 4\\left(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G)\\right)^{1/2}.\n\\end{split}\n\\]\nSimilarly, by (\\ref{lem:norabow:bou2}), (\\ref{lem:norabow:def2}), and (\\ref{lem:norabow:bou3}), we have\n\\[\n\\begin{split}\n\\sum_{s, t, s\\leq t-q}\\gamma_{s, t} \n&\\leq 3\\ell\\sum_{s, t, s\\leq t-q}2^s\\beta_t\n= 3\\ell\\sum_{t\\geq 1}\\beta_t\\sum_{s=1}^{t-q}2^s\n\\leq 3\\ell\\cdot 2^{-q+2}\\sum_{t\\geq 1}2^{t-1}\\beta_t \\\\\n& \\leq 3\\ell\\cdot 2^{-q+2}\\hom(C_{2\\ell}, G)\n\\leq 12\\left(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G)\\right)^{1/2}.\n\\end{split}\n\\]\nFinally, the total number of homomorphic copies $(x_1, \\ldots, x_{2\\ell})$ of $C_{2\\ell}$ with $c(x_1x_2\n)\\in L(x_ix_{i+1})$ for some $2\\leq i \\leq \\ell+1$ is \n\\[\n\\sum_{s, t\\geq 1} \\gamma_{s, t} \\leq 16\\left(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G)\\right)^{1/2}.\n\\]\n\\end{proof}\n\n\n\\begin{corollary}\nLet $G$ be a properly edge-colored graph on $n$ vertices with a coloring $c$, and $L$ be a $c$-proper list edge-coloring of $G$.\nLet $k\\geq 2$ be an integer. If $G$ satisfies \n\\[\n\\hom(C_{2k},G)\\geq 2^{12k}k^{3k}n\\Delta(G)^k,\n\\]\nthen $G$ contains an $(L, c)$-colorful cycle of length at most $2k$. \n\\end{corollary}\n\\begin{proof}\nLet $\\ell$ be the smallest positive integer satisfying\n\\[\n\\hom(C_{2\\ell},G)\\geq 2^{12\\ell} k^{3\\ell}n\\Delta(G)^{\\ell}.\n\\]\nThis is well-defined, and $2\\leq \\ell \\leq k$ by the condition of the lemma, and $\\hom(C_2, G) = 2e(G)\\leq n\\Delta(G)$.\nNote that \n\\[\n\\hom(C_{2\\ell-2},G) < 2^{12(\\ell-1)} k^{3(\\ell-1)}n\\Delta(G)^{\\ell-1}\n\\leq \\frac{\\hom(C_{2\\ell},G)}{2^{12}k^3\\Delta(G)}\n\\leq \\frac{\\hom(C_{2\\ell},G)}{2^{12}\\ell^3\\Delta(G)}.\n\\]\nBy Lemma~\\ref{lem:norabow}, the number of homomorphic copies of $C_{2\\ell}$ which are not $(L, c)$-colorful is at most\n\\[\n64\\ell(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G))^{1/2}\n< \\hom(C_{2\\ell},G).\n\\]\nHence, there is at least one homomorphic copy of $C_{2\\ell}$ in $G$ which is $(L, c)$-colorful. In particular, this homomorphic copy of $C_{2\\ell}$ is a circuit, i.e. no edge is repeated. This implies the existence of an $(L, c)$-colorful cycle of length at most $2k$.\n\\end{proof}\n\nWe will also use the following two lemmas from~\\cite{J2}.\n\\begin{lemma}\\label{lem:injcopies}\nLet $\\ell\\geq 2$ be a positive integer and let $G$ be a graph. Then the number of homomorphic, but not injective copies of $C_{2\\ell}$ in $G$ is at most\n\\[\n16\\ell(\\ell\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G)^{1/2}.\n\\]\n\\end{lemma}\n\n\\begin{lemma}\\label{lem:bipmindeg}\nLet $H$ be a bipartite graph with parts $Y$ and $Z$. Let $f:Y\\rightarrow \\reals$ be a function and let $g(z)=\\sum_{y\\in N_H(z)}f(y)$ for every $y\\in Z$. Suppose that $H$ does not contain a non-empty subgraph with minimum degree at least $d$. Then \n\\[\n\\sum_{y\\in Y} f(y)^2\\geq\\frac{1}{4d\\Delta(H)}\\sum_{z\\in Z}g(z)^2.\n\\]\n\\end{lemma}\n\nNext, we will adapt the argument in the proof of Lemma~2.6 from~\\cite{J2} to find an extendable rainbow $C_{2k}$.\n\n\n\\begin{lemma}\\label{lem:C2k}\nLet $k$ be a fixed positive integer. Let $G$ be a properly edge-colored graph on $n$ vertices with coloring $c$, and $L$ be a $c$-proper list edge-coloring of $G$. Suppose that for some $2\\leq\\ell\\leq k$ we have \\[\\hom(C_{2\\ell},G)\\geq c_k\\Delta(G)\\hom(C_{2\\ell-2},G),\\] where $c_k=2^{16}(25k^7)$. Then $G$ contains an extendable rainbow $C_{2k}$.\n\\end{lemma}\n\n\\begin{proof}\nWe will call a pair $(x_1,x_{\\ell+1})$ of vertices \\emph{nice} if the number of $(L,c)$-colorful, injective homomorphic copies of $C_{2\\ell}$ of the form $x_1x_2\\ldots x_{2\\ell}$ is greater than \\[\\left(1-\\frac{1}{\\binom{4k}{2}}\\right)(\\hom_{x_1,x_{\\ell+1}}(P_{\\ell},G))^2.\\] \nNote that the total number of homomorphic copies of $C_{2\\ell}$ of the form $x_1x_2\\ldots x_{2\\ell}x_1$ is $\\hom_{x_1,x_{\\ell+1}}(P_{\\ell},G)^2$. So, if we randomly choose $4k$ walks of length $\\ell$ between $x_1$ and $x_{\\ell+1}$ (with replacement), then with positive probability, the concatenation of any two forms an injective and $(L,c)$-colorful homomorphic copy of $C_{2\\ell}$. Thus, for a nice pair $(x_1, x_{\\ell+1})$, we can select such a set of at least $4k$ pairwise internally vertex-disjoint paths between $x_1$ and $x_{\\ell+1}$ where for each edge $e$ in these paths, its color $c(e)$ does not appear in any of the lists in these paths except for $L(e)$.\n\nBy Lemmas~\\ref{lem:norabow} and~\\ref{lem:injcopies}, the number of non-injective or non-$(L,c)$-colorful homomorphic copies of $C_{2\\ell}$ in $G$ is at most \n\\[\n80\\ell^{3/2}\\left(\\Delta(G)\\hom(C_{2\\ell-2}, G)\\hom(C_{2\\ell}, G)\\right)^{1/2}\\leq \\frac{80\\ell^{3/2}}{c_k^{1/2}}\\hom(C_{2\\ell},G).\n\\]\nThus, considering non-nice pairs $(x_1,x_{\\ell+1})$, we have \n\\[\n\\sum_{(x_1,x_{\\ell+1}) \\text{ not nice}} \\frac{1}{\\binom{4k}{2}}\\hom_{x_1,x_{\\ell+1}}(P_{\\ell},G)^2 \\leq \\frac{80\\ell^{3/2}}{c_k^{1/2}}\\hom(C_{2\\ell},G).\n\\]\nSince $\\sum_{x_1,x_{\\ell+1}\\in V(G)}\\hom_{x_1,x_{\\ell+1}}(P_{\\ell},G)^2=\\hom(C_{2\\ell},G)$, this gives\n\\[\n\\begin{array}{ll}\\ds\\sum_{(x_1,x_{\\ell+1}) \\text{ nice}} \\hom_{x_1,x_{\\ell+1}}(P_{\\ell},G)^2 &\\geq\\ds \\left(1-\\binom{4k}{2}\\frac{80\\ell^{3/2}}{c_k^{1/2}}\\right)\\hom(C_{2\\ell},G)\\\\ & >\\frac{1}{2}\\hom(C_{2\\ell},G)\\geq\\frac{c_k}{2}\\Delta(G)\\hom(C_{2\\ell-2},G).\\end{array}\n\\]\nTherefore, there is some $x\\in V(G)$ such that\n\\begin{equation}\\label{lem:C2k:hom}\n\\sum_{z\\in V(G):(x,z) \\text{ is nice}}\\hom_{x,z}(P_{\\ell},G)^2>\\frac{c_k}{2}\\Delta(G)\\hom_x(C_{2\\ell-2},G),\n\\end{equation}\nwhere $\\hom_x(C_{2\\ell-2},G)$ is the number of homomorphic copies $x_1x_2\\ldots x_{2\\ell-2}x_1$ of $C_{2\\ell-2}$ with $x_1=x$. Let $Z=\\{z\\in G:(x,z)\\text{ is nice}\\}$ and $Y=V(G)$. Consider the bipartite graph $H$ with parts $Y$ and $Z$, viewed as disjoint sets despite their overlap as subsets of $V(G)$, and edges $yz\\in E(H)$ if and only if $yz\\in E(G)$. \n\nWe will show that $H$ contains a subgraph of minimum degree at least $4k$. Assume towards a contradiction that $H$ has no such subgraph, and let $f(y)=\\hom_{x,y}(P_{\\ell-1},G)$ for each $y\\in Y=V(G)$ and $g(z)=\\sum_{y\\in N_H(z)}f(y)$ for each $z\\in Z$. Then applying Lemma~\\ref{lem:bipmindeg} with $d=4k$, we get \n\\[\n\\sum_{y\\in Y}f(y)^2\\geq\\frac{1}{16k\\Delta(H)}\\sum_{z\\in Z}g(z)^2\\geq\\frac{1}{16k\\Delta(G)}\\sum_{z\\in Z}g(z)^2.\n\\]\nBut $g(z)=\\sum_{y\\in N_G(z)}\\hom_{x,y}(P_{\\ell-1},G)=\\hom_{x,z}(P_{\\ell},G)$, so by (\\ref{lem:C2k:hom}), \n\\[\n\\sum_{y\\in Y}f(y)^2\\geq\\frac{1}{16k\\Delta(G)}\\sum_{z\\in Z}\\hom_{x,z}(P_{\\ell},G)^2>\\frac{c_k}{32k}\\hom_x(C_{2\\ell-2},G),\n\\]\na contradiction since $\\sum_{y\\in Y}f(y)^2=\\hom_x(C_{2\\ell-2},G)$.\nTherefore, $H$ contains a subgraph $H'$ of minimum degree at least $4k$. \n\nNow we can construct an extendable, rainbow, and injective homomorphic copy of $C_{2\\ell}$. Fix a vertex $z_1\\in Z\\cap V(H')$ with minimum degree at least $4k$.\nSince $(x,z_1)$ is a nice pair, we can pick a rainbow path $P$ of length $\\ell$ from $x_1=x$ to $z_1$, say $x_1x_2\\ldots x_\\ell z_1$.  Then we can greedily find a rainbow path $Q$ of length $2k-2\\ell$ in $H'$, and so in $G$, which starts at $z_1$ and avoids the vertices and colors on $P$ and the colors in $L(x_1x_2)$. Let $z_2\\in Z$ be the other endpoint of $Q$, and note that $z_2\\in Z\\cap V(H')$. Then since $(x,z_2)$ is a nice pair, there are at least $4k$ pairwise internally vertex-disjoint paths of length $\\ell$ between $x$ and $z_2$ such that each color appears at most once on these paths. Therefore, we can find a path $P'$ of length $\\ell$ which avoids the $2k-\\ell-1$ vertices and $2k-\\ell+2$ colors on $P$, $Q$, and $L(x_1x_2)$, so that the concatenation of $P,$ $Q$, and $P'$ is an extendable rainbow cycle of length $2k$.\n\\end{proof}\n\nThe following corollary follows from Lemma~\\ref{lem:C2k} and the proof of Corollary~2.7 in~\\cite{J2}.\n\n\\begin{corollary}\\label{cor:rbC2k}\nLet $k$ be a fixed integer. Let $G$ be a properly edge-colored graph on $n$ vertices with coloring $c$, and $L$ be a $c$-proper list edge-coloring of $G$. Suppose we have \\[\\hom(C_{2j},G)=\\omega(n\\Delta(G)^j)\\]  for some $2\\leq j\\leq k$. Then for sufficiently large $n$, $G$ contains an extendable rainbow $C_{2k}$.\n\\end{corollary}\n\n\\subsection{Proof of Theorem~\\ref{thm longer cycles}}\\label{sec longer cycles}\nSimilarly as in~\\cite{J2}, we will use the following lemma to pass to a subgraph  which is nearly regular. We say a graph is \\emph{$K$-almost regular} if $\\Delta(G)\\leq K\\delta(G)$. \n \n\\begin{lemma}[Jiang-Seiver~\\cite{JS}]\\label{lem:regsubgr} Let $\\varepsilon,c$ be positive reals, where $\\varepsilon<1$ and $c\\geq 1$. Let $n$ be a positive integer that is sufficiently large as a function of $\\varepsilon$. Let $G$ be a graph on $n$ vertices with $e(G)\\geq cn^{1+\\varepsilon}$. Then $G$ contains a $K$-almost regular subgraph $G'$ on $m\\geq n^{\\frac{\\varepsilon-\\varepsilon^2}{2+2\\varepsilon}}$ vertices such that $e(G')\\geq \\frac{2c}{5}m^{1+\\varepsilon}$ and $K=20\\cdot2^{\\frac{1}{\\varepsilon^2}+1}$.\n\\end{lemma}\n\n \n\n\\begin{proof}[Proof of Theorem~\\ref{thm longer cycles}]\nLet $G$ be an $n$-vertex graph with a proper edge-coloring $c$ containing no rainbow copy of $C_{2k+1}$. We may assume each edge in $G$ is in at least one triangle. \n\nSimilarly as in Section~\\ref{sec C5}, we begin by giving a bound on the number of triangles in $G$ in terms of the number of edges in $G$. Fix a vertex $v\\in V(G)$ and let $d$ denote the degree of $v$. Pick a set $S\\subset N(v)$ containing half of the neighborhood of $v$, and throw out any edge in $G[S]$ which is colored using some color which appears on an edge from $v$ to $S$.\n\nThen $G[S]$ must be rainbow $P_{2k-1}$-free, so (\\ref{lem:norainbowpath}) gives $|E(G[S])|\\leq \\frac{3k-2}{2}d$. By counting the triangles containing $v$ and two adjacent vertices in $S$ in two ways, we get \\[|E(G[N(v)])|\\cdot \\binom{d-3}{d/2-2} \\leq \\frac{3k-2}{2}d\\binom{d}{d/2}.\\]\nThus, $|E(G[N(v)])|\\leq (12k-8)d$, and the number of triangles in $G$  is \\[\\frac{1}{3}\\sum_{v\\in V(G)}|E(G[N(v)])|\\leq \\frac{12k-8}{3}\\sum_{v\\in V(G)}d(v)=\\frac{24k-16}{3}|E(G)|.\\] \nWe will show that $|E(G)|=O(n^{1+\\frac{1}{k}})$. \n\nAssume towards a contradiction that $G$ has more edges. First, we will partition the vertex set of $G$ so that we can extend a copy of $C_{2k}$ in one part by replacing an edge with a path of length two through a vertex in the other part, giving a copy of $C_{2k+1}$. \n\nRandomly select a partition of $V(G)$ into parts $R$ of size $\\lfloor\\frac{n}{2}\\rfloor$ and $B$ of size $\\lceil\\frac{n}{2}\\rceil$, and color the vertices in these parts red and blue, respectively. Now for each edge $xy\\in E(G[B])$, fix a vertex $z$ which forms a triangle with $xy$ in $G$ (if there are multiple choices, choose one arbitrarily). Then keep $xy$ if $z\\in R$ and delete $xy$ if $z\\in B$. Since the expected number of edges left in $E(G[B])$ is at least $|E(G)|/8$, we can select a partition $(R,B)$ so that $|E(G)|/8$ edges remain in $E(G[B])$.\n\nNow we would like to find a rainbow $C_{2k}$ in $G[B]$ which we can extend to a rainbow $C_{2k+1}$ in $G$. In order to do so, we will define a $c$-proper list edge-coloring on $G[B]$ by setting $L(xy)=\\{c(xy),c(xz),c(yz)\\}$ for each $xy\\in E(G[B])$, where $z\\in R$ is the vertex fixed above which forms a triangle with $xy$. \n\nBy Lemma~\\ref{lem:regsubgr} applied to $G[B]$, it suffices to prove that for any fixed $K$, if $G'$ is a properly edge-colored $K$-almost regular graph on $m$ vertices with minimum degree $\\delta=\\omega(m^{1/k})$, then for $m$ sufficiently large, $G'$ contains an extendable rainbow $C_{2k}$. \n\nSince $C_{2k}$ satisfies Sidorenko's conjecture, we know \n\\[\n\\hom(C_{2k},G')\\geq \\frac{\\hom(K_2,G')^{2k}}{m^{2k}}\\geq\\delta^{2k}\\geq\\frac{\\delta^k}{mK^k}m\\Delta(G')^k.\n\\]\nThus, $\\hom(C_{2k},G')=\\omega(m\\Delta(G')^k)$, so Corollary~\\ref{cor:rbC2k} implies that $G'$ contains an extendable rainbow $C_{2k}$.\n\nSince this cycle contains only vertices in $B$, we can replace its extendable edge $xy$ by the pair of edges $xz$ and $zy$ to create a copy of $C_{2k+1}$, where $z\\in R$ is the fixed vertex forming a triangle with $xy$ in $G$. By construction, no other edges on the cycle share a color with either new edge, so we have found a rainbow $C_{2k+1}$.  But this is a contradiction, since $G$ contains no rainbow copies of $C_{2k+1}$. Thus, $|E(G)|=O(n^{1+\\frac{1}{k}})$, which implies that the number of triangles in $G$ is $O(n^{1+\\frac{1}{k}})$, as desired.\n\\end{proof}\n\n\n\n\\begin{thebibliography}{}\n    \\bibitem{AS} N. Alon and C. Shikhelman, Many $T$ copies in $H$-free graphs, \\emph{J. Comb. Theory. Ser. B} \\textbf{121}, 146--172, 2016.\n\t\\bibitem{GGMV} D. Gerbner, E. Gy\\H{o}ri, A. Methuku, and M. Vizer. Generalized Tur\\'an problems for even cycles, \\emph{arXiv:1712.07079}.\n\t\\bibitem{GMMP} D. Gerbner, T. M\\'esz\\'aros, A. Methuku, and C. Palmer, Generalized rainbow Tur\\'an problems, \\emph{arXiv:1911.06642}.\n\t\\bibitem{GJ} W. T. Gowers and B. Janzer, Generalizations of the Ruzsa-Szemer\\'edi and rainbow Tur\\'an problems for cliques, \\emph{arXiv:2003.02754}.\n\t\\bibitem{GS} L. Gishboliner and A. Shapira, A generalized Tur\\'an problem and its applications, \\emph{Proceedings of STOC 2018 Theory Fest: 50th Annual ACM Symposium on the Theory of Computing} June 25-29, 2018 in Los Angeles, CA, pp. 760--772.\n\t\\bibitem{GL} E. Gy\\H{o}ri and H. Li, The maximum number of triangles in $C_{2k+1}$-free graphs, \\emph{Comb. Probab. Comput.} \\textbf{21}, 187--191, 2012.\n    \\bibitem{J1} B. Janzer, The generalised rainbow Tur\\'an problem for cycles, \\emph{arXiv:2005.08073}.\n    \\bibitem{J2} O. Janzer, Rainbow Tur\\'an number of even cycles, repeated patterns and blow-ups of cycles, \\emph{arxiv:2006.01062}.\n    \\bibitem{JPS} D. Johnston, C. Palmer and A. Sarkar, Rainbow Tur\\'an Problems for Paths and Forests of Stars, \\emph{Electron. J. Comb.} \\textbf{24}(1), 1--34, 2017.\n    \\bibitem{JS} T. Jiang and R. Seiver, Tur\\'an numbers of subdivided graphs, \\emph{SIAM J. Discrete Math.}, 26:1238\u20131255, 2012.\n\t\\bibitem{KMSV} P. Keevash, D. Mubayi, B. Sudakov, and J. Verstra\\\"ete, Rainbow Tur\\'an problems, \\emph{Comb. Probab. Comput.} \\textbf{16}(1), 109--126, 2007.\n\\end{thebibliography}\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:05:12", "yymm": "2010", "arxiv_id": "2010.14609", "url": "https://arxiv.org/abs/2010.14609", "source": "arxiv"}}
{"text": "\\documentclass[11pt]{article}\n\n\\clearpage{}%%\\usepackage[final]{neurips_2020}\n\\usepackage{fullpage}\n\n\\usepackage[utf8]{inputenc} % allow utf-8 input\n\\usepackage[T1]{fontenc}    % use 8-bit T1 fonts\n\n\\usepackage{amsmath,amsthm,amssymb,amsfonts}\n\n%% Bibliography\n\\usepackage[round]{natbib}\n\n%% Plots and figures\n\\usepackage{pgfplots}\n\\pgfplotsset{compat=1.15}\n\n\\usepackage{tikz}\n\\usepackage{graphicx}\n\\usepackage{caption}\n\n%% Algorithms\n\\usepackage{algorithm}\n\\usepackage{algorithmic}\n\n%% hyperlinks\n\\PassOptionsToPackage{linktocpage}{hyperref}\n\\usepackage{xr-hyper}\n\\usepackage[hyperindex,breaklinks]{hyperref}    \n%\\usepackage{url}\n\n%% Misc\n\\usepackage{mathtools}\n\\usepackage{booktabs}\n\\usepackage{microtype}\n\n%% Fractions\n\\usepackage{xfrac}\n\\usepackage{nicefrac}    \n\n%%\\usepackage{times}\n\n%% Misc fonts (e.g., \\one)\n\\usepackage{dsfont}\n\\usepackage[T1]{fontenc}\n\\usepackage{lmodern}\n\n\\usepackage{authblk} %Author affiliations\n\\clearpage{}\n\\clearpage{}%% Theorems, lemmas, claims etc\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{claim}[theorem]{Claim}\n\\newtheorem{fact}[theorem]{Fact}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{definition}{Definition}[section]\n\\newtheorem{example}[definition]{Example}\n\\newtheorem{assumption}[definition]{Assumption}\n\\newtheorem{remark}[definition]{Remark}\n\n%% Rounding up and down\n\\DeclarePairedDelimiter\\ceil{\\lceil}{\\rceil}\n\\DeclarePairedDelimiter\\floor{\\lfloor}{\\rfloor}\n\n%% Probability notation\n\\def\\expect#1{\\mathbb{E}\\left[#1\\right]}\n\\def\\prob#1{\\mathbb{P}\\left[#1\\right]}\n\\def\\pr{\\mathbb{P}}\n\\def\\abs#1{\\left\\lvert#1\\right\\rvert}\n\\def\\var#1{\\mathrm{Var}\\left[#1\\right]}\n\\newcommand{\\Pois}{\\mathrm{Pois}}\n\\newcommand{\\Exp}{\\mathrm{Exp}}\n\n\\def\\rbr#1{\\left(#1\\right)}   %round bracket\n\\def\\sbr#1{\\left[#1\\right]}   %square bracket\n\\def\\cbr#1{\\left\\{#1\\right\\}}  %curly bracket\n\n\\def\\norm#1{\\lVert#1\\rVert}\n\\newcommand{\\N}{\\mathbb{N}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\matr}[1]{\\mathbf{#1}}\n\\newcommand{\\real}{\\mathbb{R}}\n\\newcommand{\\ind}{\\mathds{1}}\n\\newcommand{\\de}{\\mathrm{d}}\n\n\\newcommand{\\opt}{\\mathrm{OPT}}\n\\newcommand{\\cost}{\\mathrm{cost}}\n\\newcommand{\\cluster}{P}\n\\newcommand{\\total}{\\mathbf{X}}\n\\newcommand{\\Y}{\\mathbf{Y}}\n\\newcommand{\\centerset}{C}\n\\newcommand{\\uncover}{U}\n\\newcommand{\\cover}{H}\n\\newcommand{\\misses}{W}\n\\newcommand{\\potential}{\\Psi}\n\\newcommand{\\dimension}{d}\n\\newcommand{\\pointset}{\\mathbf{X}}\n\\newcommand{\\extracenters}{\\Delta}\n\\newcommand{\\statespace}{S}\n\\newcommand{\\calE}{\\mathcal{E}}\n\\newcommand{\\calD}{\\mathcal{D}}\n\\newcommand{\\MM}{\\partial \\calM}\n\n\\newcommand{\\ip}[1]{\\left\\langle #1 \\right\\rangle}\n\n\\newcommand{\\one}{\\mathds{1}}\n\\newcommand{\\kpp}{\\text{$\\parallel_{\\Pois}$}}\n\\newcommand{\\kpois}{\\text{$++_{\\text{ER}}$}}\n\\newcommand{\\kmpp}{$k$-\\text{means++}}\n\\newcommand{\\kmpa}{$k$-\\text{means$\\parallel$}}\n\\newcommand{\\kmeans}{$k$-\\text{means}}\n\\newcommand{\\calP}{{\\cal{P}}}\n\\newcommand{\\calM}{{\\cal{M}}}\n\\newcommand{\\calH}{{\\cal{H}}}\n\\newcommand{\\E}{\\mathbb{E}}\n\\newcommand{\\OPT}{\\operatorname{OPT}}\n\\newcommand{\\HH}{\\widetilde{H}}\n\\newcommand{\\UU}{\\widetilde{U}}\n\n\\newcommand{\\yrcite}[1]{\\citeyearpar{#1}}\n\\renewcommand{\\cite}[1]{\\citep{#1}}\n\n\\ifdefined\\nohyperref\\else\\ifdefined\\hypersetup\n  \\definecolor{mydarkblue}{rgb}{0,0.08,0.45}\n  \\hypersetup{ %\n    colorlinks=true,\n    linkcolor=mydarkblue,\n    citecolor=mydarkblue,\n    filecolor=mydarkblue,\n    urlcolor=mydarkblue,\n    pdfview=FitH}\n\\fi\\fi\n\n\\renewcommand\\footnotemark{}%removes * in the title\n\\clearpage{}\n\\clearpage{}\\newcommand{\\todo}[1]{{\\color{red}$\\ll$#1 $\\gg$}}\n\\newcommand{\\anote}[1]{\\todo{Aravind: #1}}\n\\newcommand{\\lnote}[1]{\\todo{Liren: #1}}\n\\newcommand{\\knote}[1]{\\todo{Kostya: #1}}\n\\clearpage{}\n\n\\title{Improved Guarantees for $k$-means++ and $k$-means++ Parallel\\footnote{The conference version of this paper will appear in the proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS 2020). Author order is alphabetical.}}\n\n\\author{Konstantin Makarychev}\n\\author{Aravind Reddy}\n\\author{Liren Shan}\n\\affil{Department of Computer Science\n    \\\\Northwestern University\n    \\\\Evanston, IL, USA}\n\n\\begin{document}\n\\date{}\n\\maketitle\n\n\\begin{abstract}\nIn this paper, we study $k$-means++ and $k$-means$\\parallel$,  the two most popular algorithms for the classic $k$-means clustering problem. We provide novel analyses and show improved approximation and bi-criteria approximation guarantees for $k$-means++ and $k$-means$\\parallel$. Our results give a better theoretical justification for why these algorithms  perform extremely well in practice. We also propose a new variant of $k$-means$\\parallel$ algorithm (Exponential Race $k$-means++) that has the same approximation guarantees as $k$-means++.\n\\end{abstract} \\section{Introduction}\n\n$k$-means clustering is one of the most commonly encountered unsupervised learning problems. Given a set of $n$ data points in Euclidean space, our goal is to partition them into $k$ clusters (each characterized by a center), such that the sum of squares of distances of data points to their nearest centers is minimized.\nThe most popular heuristic for solving this problem is Lloyd's algorithm \\cite{lloyd}, often referred to simply as ``the $k$-means algorithm\".\n\nLloyd's algorithm uses iterative improvements to find a locally optimal $k$-means clustering.  The performance of Lloyd's algorithm crucially depends on the quality of the initial clustering, which is defined by the initial set of centers, called a \\emph{seed}. \\citet*{arthur2007k} and \\citet*{ostrovsky2006effectiveness} developed an elegant randomized seeding algorithm, known as the $k$-means++ algorithm. It works by choosing the first center uniformly at random from the data set and then choosing the subsequent $k-1$ centers by randomly sampling a single point in each round with the sampling probability of every point proportional to its current cost. That is, the probability of choosing any data point $x$ is proportional to the squared distance to its closest already chosen center. This squared distance is often denoted by $D^2(x)$. \\citet*{arthur2007k} proved that the expected cost of the initial clustering obtained by $k$-means++ is at most $8\\rbr{\\ln k + 2}$ times the cost of the optimal clustering i.e., $k$-means++ gives an $8\\rbr{\\ln k + 2}$-approximation for the $k$-means problem. They also provided a family of $k$-means instances for which the approximation factor of $k$-means++ is $2\\ln k$ and thus showed that\ntheir analysis of $k$-means++ is almost tight.\n\nDue to its speed, simplicity, and good empirical performance, $k$-means++ is the most widely used algorithm for $k$-means clustering. It is employed by such machine learning libraries as Apache Spark MLlib, Google BigQuery, IBM SPSS, Intel DAAL, and Microsoft ML.NET. In addition to $k$-means++, these libraries implement a scalable variant of $k$-means++ called $k$-means$\\parallel$ (read ``$k$-means parallel'') designed by \\citet*{bahmani2012scalable}. Somewhat surprisingly, $k$-means$\\parallel$ not only works better in parallel than $k$-means++ but also slightly outperforms $k$-means++ in practice in the single machine setting (see~\\citet{bahmani2012scalable} and Figure~\\ref{fig:experiment} below).\nHowever, theoretical guarantees for $k$-means$\\parallel$ are substantially weaker than for $k$-means++.\n\nThe $k$-means$\\parallel$ algorithm makes $T$ passes over the data set (usually $T = 5$). In every round, it independently draws approximately $\\ell = \\Theta(k)$ random centers according to the $D^2$ distribution. After each round it recomputes the distances to the closest chosen centers and updates $D^2(x)$ for all $x$ in the data set. Thus, after $T$ rounds, $k$-means$\\parallel$ chooses approximately $T\\ell$ centers. It then selects $k$ centers among $T\\ell$ centers using $k$-means++.\n\n\\medskip\n\n\\noindent\\textbf{Our contributions. } In this paper, we improve the theoretical guarantees for $k$-means++, $k$-means$\\parallel$, and Bi-Criteria $k$-means++ (which we define below).\n\nFirst, we show that the expected cost of the solution output by $k$-means++ is at most $5(\\ln k +2)$ times the optimal solution's cost. This improves upon the bound of $8(\\ln k +2)$ shown by \\citet*{arthur2007k} and directly improves the approximation factors for several algorithms which use $k$-means++ as a subroutine like Local Search k-means++ \\citep*{lattanzi2019better}. To obtain this result, we give a refined analysis of the expected cost of \\emph{covered clusters} (see Lemma 3.2 in \\citet*{arthur2007k} and Lemma~\\ref{lem:5OPT} in this paper). We also show that our new bound on the expected cost of \\emph{covered clusters} is tight (see Lemma~\\ref{thm:5-approx-tight}).\n\nThen, we address the question of why the observed performance of $k$-means$\\parallel$ is better than the performance of $k$-means++. There are two possible explanations for this fact. (1) This may be the case because $k$-means$\\parallel$ picks $k$ centers in two stages. At the first stage, it samples $\\ell T \\geq k$ centers. At the second stage, it prunes centers and chooses $k$ centers among $\\ell T$ centers using $k$-means++.  (2) This may also be the case because $k$-means$\\parallel$ updates the distribution function  $D^2(x)$ once in every round. That is, it recomputes $D^2(x)$ once for every $\\ell$ chosen centers, while $k$-means++ recomputes $D^2(x)$ every time it chooses a center. In this paper, we empirically demonstrate that the first explanation is correct.\nFirst, we noticed that $k$-means$\\parallel$ for $\\ell\\cdot T = k$ is almost identical with $k$-means++ (see Appendix~\\ref{sec:experiments}).\nSecond, we compare $k$-means$\\parallel$ with another algorithm which we call Bi-Criteria $k$-means++ with Pruning. This algorithm also works in two stages: At the Bi-Criteria $k$-means++ stage, it chooses $k+\\Delta$ centers in the data set using $k$-means++. Then, at the Pruning stage, it picks $k$ centers among the $k+\\Delta$ centers selected at the first stage again using $k$-means++. Our experiments on the standard data sets BioTest from KDD-Cup 2004 \\cite{kddcup2004} and COVTYPE from the UCI ML repository \\cite{Dua:2019} show that the performance of $k$-means$\\parallel$ and Bi-Criteria $k$-means++ with Pruning are essentially identical (see Figures~\\ref{fig:experiment} and Appendix~\\ref{sec:experiments}).\n\n\\begin{figure}\n    \\begin{minipage}[h]{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {(a) BioTest},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n        %\\caption{BioTest}\n        %\\label{fig:BioTest}\n    \\end{minipage}\n    \\quad\n    \\begin{minipage}[h]{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {(b) COVTYPE},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/covtype10-50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/covtype10-50.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/covtype10-50.csv};\\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n        %\\caption{COVTYPE}\n        %\\label{fig:CovType}\n    \\end{minipage}\n    \\caption{Performance of $k$-means++, $k$-means$\\parallel$, and Bi-Criteria  $k$-means++ with pruning on the BioTest and COVTYPE datasets. For $k=10,15,\\cdots, 50$, we ran these algorithms for 50 iterations and took their average. We normalized the clustering costs by dividing them by $\\cost_{1000}(\\pointset)$.}\n    \\label{fig:experiment}\n\\end{figure}\n\nThese results lead to another interesting question: How good are $k$-means++ and $k$-means$\\parallel$ algorithms that sample $k+\\Delta$ instead of $k$ centers? The idea of oversampling using $k$-means++ was studied earlier in the literature under the name of \\emph{bi-criteria approximation}. ~\\citet*{aggarwal2009adaptive} showed that with constant probability, sampling $k + \\Delta$ centers by $k$-means++ provides a constant-factor approximation if $\\Delta \\geq \\beta k$ for some constant $\\beta > 0$. \\citet{wei2016constant} improved on this result by showing an expected approximation ratio of $8(1+1.618 k/\\extracenters)$. Note that for bi-criteria algorithms we compare the expected cost of the clustering with $k+\\Delta$ centers they produce and the cost of the optimal clustering with exactly $k$ centers.\n\n\nIn this paper, we show that the expected bi-criteria approximation ratio for $k$-means++ with $\\Delta$ additional centers is at most the minimum of two bounds:\n$$\\text{(A) } 5\\rbr{2 + \\frac{1}{2e} + \\ln{\\frac{2k}{\\extracenters}}} \\text{ for } 1\\leq \\Delta \\leq 2k;\\text{ and (B) }5\\rbr{1+ \\frac{k}{e\\rbr{\\extracenters-1}}} \\text{ for }\\Delta \\geq 1$$\nBoth bounds are better than the bound by~\\citet{wei2016constant}. The improvement is especially noticeable for small values of $\\Delta$. More specifically, when the number of additional centers is $\\Delta = k/ \\log k$, our approximation guarantee is $O(\\log\\log k)$ while  \\citet{wei2016constant} gives an $O(\\log k)$ approximation.\n\nWe believe that our results for small values of $\\Delta$ provide an additional explanation for why $k$-means++ works so well in practice. Consider a data scientist who wants to cluster a data set $\\pointset$ with $k^*$ \\emph{true clusters} (i.e. $k^*$ latent groups). Since she does not know the actual value of $k^*$, she uses the \\emph{elbow method} \\cite{boehmke2019hands} or some other heuristic to find $k$. Our results indicate that if she chooses slightly more number of clusters (for instance, $1.05 k^*$), then she will get a constant bi-criteria approximation to the optimal clustering.\n\nWe also note that our bounds on the approximation factor smoothly transition from the regular ($\\Delta = 0$) to bi-criteria ($\\Delta > 0$) regime. We complement our analysis with an almost matching lower bound of $\\Theta(\\log (k/\\Delta))$ on the approximation factor of $k$-means for $\\Delta \\leq k$ (see Appendix~\\ref{sec:lb}).\n\nWe then analyze Bi-Criteria $k$-means$\\parallel$ algorithm, the variant of $k$-means$\\parallel$ that does not prune centers at the second stage. In their original paper, \\citet*{bahmani2012scalable} showed that the expected cost of the solution for $k$-means$\\parallel$ with $T$ rounds and oversampling parameter $\\ell$ is at most:\n$$\\frac{16}{1 - \\alpha} \\opt_k(\\pointset) + \\Big(\\frac{1+\\alpha}{2}\\Big)^T \\opt_1(\\pointset),$$\nwhere $\\alpha = \\exp\\rbr{-\\rbr{1-e^{-\\ell/(2k)}}} $;\n$\\opt_k(\\pointset)$ is the cost of the optimal $k$-means clustering of $\\pointset$; $\\opt_1(\\pointset)$ is the cost of the optimal clustering of $X$ with 1 center (see Section~\\ref{sec:prelim} for details). We note that $\\opt_1(\\pointset) \\gg \\opt_k(\\pointset)$. For $\\ell = k$, this result gives a bound of $\\approx 49\\, \\opt_k(\\pointset) + 0.83^T\\opt_1(\\pointset)$.\n\\citet*{bachem2017distributed} improved the approximation guarantee for $\\ell \\geq k$ to $$26 \\opt_k(\\pointset) + 2\\Big(\\frac{k}{e\\ell}\\Big)^T\\opt_1(\\pointset).$$\nIn this work, we improve this bound for $\\ell \\geq k$ and also obtain a better bound for $\\ell < k$. For $\\ell \\geq k$, we show that the cost of $k$-means$\\parallel$\nwithout pruning is at most\n$$8 \\opt_k(\\pointset) + 2\\Big(\\frac{k}{e\\ell}\\Big)^T\\opt_1(\\pointset).$$\nFor $\\ell < k$, we give a bound of\n$$\n\\frac{5}{1-e^{-\\frac{\\ell}{k}}}\\;\\opt_k(\\pointset)+\n2\\rbr{e^{-\\frac{\\ell}{k}}}^T \\opt_1(\\pointset)$$\n\nFinally, we give a new parallel variant of the $k$-means++ algorithm, which we call \\emph{Exponential Race $k$-means++} ($k$-means$\\kpois$). This algorithm is similar to $k$-means$\\parallel$.\nIn each round, it also selects $\\ell$ candidate centers in parallel (some of which may be dropped later) making one pass over the data set. However, after $T$ rounds, it returns exactly $k$ centers. The probability distribution of these centers is identical to the distribution of centers output by $k$-means++. The expected number of rounds is bounded as follows:\n$$O\\bigg(\\frac{k}{\\ell}+ \\log\\frac{\\OPT_1(\\pointset)}{\\OPT_k(\\pointset)}\\bigg).$$\nThis algorithm offers a unifying view on $k$-means++ and $k$-means$\\parallel$.\nWe describe it in Section~\\ref{sec:pois-kmeans-pp}.\n\n\\medskip\n\n\\noindent\\textbf{Other related work.} \\citet*{dasgupta2008hardness} and \\citet*{aloise2009np} showed that $k$-means problem is NP-hard. \\citet*{awasthi2015hardness} proved that it is also NP-hard to approximate $k$-means objective within a factor of $(1+\\varepsilon)$ for some constant $\\varepsilon>0$ (see also \\citet*{LSW17}). We also mention that $k$-means was studied not only for Euclidean spaces but also for arbitrary metric spaces.\n\nThere are several known \\emph{constant} factor approximation algorithms for the $k$-means problem. \\citet*{kanungo2004local} gave a $9+\\varepsilon$ approximation local search algorithm. \\citet*{ahmadian2019better} proposed a primal-dual algorithm with an approximation factor of $6.357$. This is the best known approximation for $k$-means. \\citet*{makarychev2016bi} gave constant-factor bi-criteria approximation algorithms based on linear programming and local search. Note that although these algorithms run in polynomial time, they do not scale well to massive data sets. \\citet*{lattanzi2019better} provided a constant factor approximation by combining the local search idea with the $k$-means++ algorithm. \\citet*{choo2020k} further improved upon this result by reducing the number of local search steps needed from $O(k\\log\\log k)$ to $O(k)$.\n\nIndependently and concurrently to our work, \\citet*{rozhovn2020simple} gave an interesting analysis for $k$-means$\\parallel$ by viewing it as a \\textit{balls into bins} problem and showed that $O(\\log n / \\log \\log n)$ rounds suffice to give a constant approximation with high probability. \n\\medskip\n\n\\noindent\\textbf{Acknowledgments.}\nWe would like to thank all the reviewers for their helpful comments. Konstantin Makarychev, Aravind Reddy, and Liren Shan were supported in part by NSF grants CCF-1955351 and HDR TRIPODS CCF-1934931. Aravind Reddy was also supported in part by NSF CCF-1637585.\n \\section{Preliminaries}\\label{sec:prelim}\nGiven a set of points $\\pointset = \\cbr{x_1,x_2,\\cdots, x_n} \\subseteq \\real^\\dimension$ and an integer $k \\geq 1$, the $k$-means clustering problem is to find a set $\\centerset$ of $k$ centers in $\\real^\\dimension$ to minimize\n$$\n    \\cost(\\pointset,C) \\coloneqq \\sum_{x \\in \\pointset} \\min_{c\\in \\centerset} \\norm{x-c}^2.\n$$\nFor any integer $i \\geq 1$, let us define $ \\opt_i(\\pointset) \\coloneqq \\min_{\\abs{\\centerset} = i} \\cost\\rbr{\\pointset, \\centerset}.$ Thus, $\\opt_k(\\pointset)$ refers to the cost of the optimal solution for the $k$-means problem. Let $\\centerset^*$ denote a set of optimal centers. We use $\\cbr{\\cluster_i}_{i=1}^k$ to denote the clusters induced by the center set $\\centerset^*$.\n\nFor any $\\Y \\subseteq \\pointset$, the cost of $\\Y$ with center set $C$, denoted by $\\cost\\rbr{\\mathbf{Y},\\centerset} = \\sum_{x \\in \\mathbf{Y}} \\min_{c\\in \\centerset} \\norm{x-c}^2$. The optimal cost for subset $\\Y$ with $i$ centers is $\\opt_i(\\Y)$.\nLet $\\mu =\\sum_{x \\in \\Y} x / \\abs{\\Y}$ be the \\textit{centroid} of the cluster $\\Y$.  Then, we have the following closed form expression for the optimal cost of $\\Y$ with one center (see Appendix~\\ref{sec:prelim_details} for proof),\n\\begin{align}\\label{eq:opt-1-closed-form}\n    \\opt_1(\\Y) = \\sum_{x\\in \\Y} \\norm{x-\\mu}^2 = \\frac{\\sum_{(x,y)\\in\\Y\\times\\Y} \\norm{x-y}^2}{2\\abs{\\Y}}.\n\\end{align}\n\n\\textbf{$k$-means++ seeding:}\nThe $k$-means++ algorithm samples the first center uniformly at random from the given points and then samples $k-1$ centers sequentially from the given points with probability of each point being sampled proportional to its cost i.e. $\\cost(x,C)/ \\cost(\\pointset,C)$.\n\n\\begin{algorithm}\n   \\caption{$k$-means++ seeding}\n   \\label{alg:kmeans++}\n\\begin{algorithmic}[1]\n   \\STATE Sample a point $c$ uniformly at random from $\\pointset$ and set $\\centerset_1 = \\cbr{c}$.\n   \\FOR{$t=2$ {\\bfseries to} $k$}\n   \\STATE Sample $x \\in \\pointset$ w.p. $\\cost(x,C_t)/\\cost(\\pointset,C_t)$.\n   \\STATE $\\centerset_t = \\centerset_{t-1} \\cup \\{x\\}$.\n   \\ENDFOR\n   \\STATE \\textbf{Return} $C_k$\n\\end{algorithmic}\n\\end{algorithm}\n\n\\textbf{$k$-means$\\parallel$ and $k$-means$\\kpp$ seeding:}\nIn the $k$-means$\\parallel$ algorithm, the first center is chosen uniformly at random from $\\pointset$. But after that, at each round, the algorithm samples each point independently with probability $\\min\\cbr{\\ell\\cdot\\cost(x,C)/\\cost(\\pointset,C),1}$ where $\\ell$ is the \\textit{oversampling parameter} chosen by the user and it usually lies between $0.1k$ and $10k$. The algorithm runs for $T$ rounds (where $T$ is also a parameter chosen by the user) and samples around $\\ell T$ points, which is usually strictly larger than $k$. This oversampled set is then weighted using the original data set $\\pointset$ and a weighted version of $k$-means++ is run on this set to get the final $k$-centers. We only focus on the stage in which we get the oversampled set because the guarantees for the second stage come directly from $k$-means++.\n\nFor the sake of analysis, we also consider a different implementation of $k$-means$\\parallel$, which we call $k$-means\\kpp\\; (Algorithm~\\ref{alg:kmeanpp_pd}). This algorithm differs from $k$-means$\\parallel$ in that each point is sampled independently with probability $1-\\exp(-\\ell\\cdot\\cost(x,C)/\\cost(\\pointset,C))$ rather than $\\min\\{\\ell\\cdot\\cost(x,C)/\\cost(\\pointset,C),1\\}$. In practice, there is essentially no difference between $k$-means$\\parallel$ and $k$-means$\\kpp$, since $\\ell\\cdot\\cost(x,C)/\\cost(\\pointset,C)$ is a very small number for all $x$ and thus the sampling probabilities for $k$-means$\\parallel$ and $k$-means$\\kpp$ are almost equal.\n\n\\begin{minipage}{0.45\\textwidth}\n\\begin{algorithm}[H]\n\\caption{$k$-means$\\parallel$ seeding}\n\\label{alg:kmeanpp}\n\\begin{algorithmic}[1]\n\\STATE Sample a point $c$ uniformly from $\\total$ and set $\\centerset_1 = \\cbr{c}$\n\\FOR{$t=1$ {\\bfseries to} $T$}\n\\STATE Sample each point $x$ into $\\centerset^\\prime$ independently w.p. $\\min\\{1,\\lambda_{t}(x)\\}$ where \\\\$\\lambda_{t}(x) = \\ell\\cdot\\cost(x,C_t)/ \\cost(\\total,C_t)$\n\\STATE Let $\\centerset_{t+1} = \\centerset_{t} \\cup \\centerset^\\prime$.\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\\end{minipage}\n\\quad\n\\begin{minipage}{0.45\\textwidth}\n\\begin{algorithm}[H]\n\\caption{$k$-means$\\kpp$ seeding}\n\\label{alg:kmeanpp_pd}\n\\begin{algorithmic}[1]\n\\STATE Sample a point $c$ uniformly from $\\total$ and set $\\centerset_1 = \\cbr{c}$\n\\FOR{$t=1$ {\\bfseries to} $T$}\n\n\\STATE Sample each point $x$ into $\\centerset^\\prime$ independently w.p. $1-e^{-\\lambda_{t}(x)}$ where \\\\$\\lambda_{t}(x) = \\ell\\cdot\\cost(x,C_t)/ \\cost(\\total,C_t)$\n\\STATE Let $\\centerset_{t+1} = \\centerset_{t} \\cup \\centerset^\\prime$.\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\\end{minipage}\n\nIn the rest of the paper, we focus only on the \\emph{seeding} step of $k$-means++, $k$-means$\\parallel$, and $k$-means$\\kpp$ and ignore Lloyd's iterations as the approximation guarantees for these algorithms come entirely from the seeding step.\n\n \\section{General framework}\\label{sec:framework}\nIn this section, we describe a general framework we use to analyze $k$-means++ and $k$-means\\kpp. Consider $k$-means++ or $k$-means$\\kpp$ algorithm.\nLet $C_t$ be the set of centers chosen by this algorithm after step $t$. For the sake of analysis, we assume that $C_t$ is an ordered set or list of centers, and the order of centers in $C_t$ is the same as the order in which our algorithm chooses these centers.\nWe explain how to order centers in\n$k$-means$\\kpp$ algorithm in Section~\\ref{sec:po-kmeans-parallel}.\nWe denote by $T$ the stopping time of the algorithm.\nObserve that after step $t$ of the algorithm, the probabilities of choosing a new center in $k$-means++ or a batch of new centers in $k$-means$\\kpp$ are defined by the current costs of points in $\\pointset$ which, in turn, are completely determined by the current set of centers $\\centerset_t$. Thus, the states of the algorithm form a Markov chain.\n\nIn our analysis, we fix the optimal clustering $\\calP = \\{\\cluster_1,\\dots, \\cluster_k\\}$ (if this clustering is not unique, we pick an arbitrary optimal clustering). The optimal cost of each cluster $\\cluster_i$ is $\\opt_1(\\cluster_i)$ and the optimal cost of the entire clustering is\n$\\opt_k(\\pointset)=\\sum_{i=1}^k \\opt_1(\\cluster_i)$.\n\nFollowing the notation in \\citet*{arthur2007k}, we say that a cluster $\\cluster_i$ is \\emph{hit} or \\emph{covered} by a set of centers $C$ if $C\\cap P_i \\neq \\varnothing$; otherwise, we say that $P_i$ is \\emph{not hit} or \\emph{uncovered}. We split the cost of each cluster $P_i$ into two\ncomponents which we call the covered and uncovered costs of $P_i$. For a given set of centers $\\centerset$,\n\\begin{align*}\n    \\text{The covered or hit cost of } P_i,\\qquad H(P_i,C) &\\coloneqq\n\\begin{cases}\n  \\cost(P_i,C), & \\mbox{if $P_i$ is covered by $C$ } \\\\\n  0, & \\mbox{otherwise}.\n\\end{cases}\n\\\\\\text{The uncovered cost of } P_i,\\qquad U(P_i,C) &\\coloneqq\n\\begin{cases}\n  0, & \\mbox{if $P_i$ is covered by $C$ } \\\\\n  \\cost(P_i,C), & \\mbox{otherwise}.\n\\end{cases}\n\\end{align*}\n\\iffalse\n%The covered or hit cost $H(P_i,\\centerset)$ of $P_i$ for a given set of centers $C$ equals\n$$H(P_i,C) =\n\\begin{cases}\n  \\cost(P_i,C), & \\mbox{if $P_i$ is covered by $C$ } \\\\\n  0, & \\mbox{otherwise}.\n\\end{cases}$$\nThe uncovered cost $U(P_i,C)$ equals\n$$U(P_i,C) =\n\\begin{cases}\n  0, & \\mbox{if $P_i$ is covered by $C$ } \\\\\n  \\cost(P_i,C), & \\mbox{otherwise}.\n\\end{cases}$$\n\\fi\nLet $H(\\pointset,\\centerset) = \\sum_{i=1}^k H(\\cluster_i,\\centerset)$ and $U(\\pointset,\\centerset) = \\sum_{i=1}^k U(\\cluster_i,\\centerset)$. Then,\n$$\\cost(\\pointset,C) = H(\\pointset,C) + U(\\pointset,C).$$\nFor the sake of brevity, we define $\\cost_t(\\Y) \\coloneqq \\cost(\\Y,C_t)$ for any $\\Y \\subseteq \\pointset$, $H_t(P_i) \\coloneqq H(P_i,C_t)$, and $U_t(P_i) \\coloneqq U(P_i,C_t)$.\nIn Section~\\ref{sec:5OPT}, we show that for any $t$, we have $\\E[H_t(\\pointset)]\\leq 5\\opt_k(\\pointset)$,\nwhich is an improvement over the bound of $8\\opt_k(\\pointset)$ given by \\citet*{arthur2007k}.\nThen, in Sections~\\ref{sec:po-bi-criteria} and \\ref{sec:po-kmeans-parallel}, we analyze the expected uncovered cost $U(\\pointset,C_T)$ for $k$-means++ and $k$-means$\\parallel$ algorithms.\n\nConsider a center $c$ in $\\centerset$. We say that $c$ is a \\textit{miss} if another center $c'$ covers the same cluster in $\\calP$ as $c$, and $c'$ appears before $c$ in the ordered set $C$.\nWe denote the number of misses in $C$ by $M(C)$ and the the number of clusters in $\\calP$ not covered by centers in $C$ by $K(C)$.\n\nObserve that the stochastic processes $U_t(P_i)$ with discrete time $t$ are non-increasing since the algorithm never removes centers from the set $C_t$ and therefore the distance from any point $x$ to $C_t$ never increases. Similarly, the processes $H_t(P_i)$ are non-increasing after the step $t_i$ when $P_i$ is covered first time.\nIn this paper, we sometimes use a proxy $\\HH_t(P_i)$ for $H_t(P_i)$, which we define as follows.\nIf $P_i$ is covered by $C_t$, then $\\HH_t(P_i) = H_{t_i}(P_i)$, where $t_i\\leq t$ is the first time when $P_i$ is covered by $C_t$.\nIf $P_i$ is not covered by $C_t$, then $\\HH_t(P_i)=5\\opt_1(P_i)$. It is easy to see that $H_{t}(P_i) \\leq \\HH_{t'}(P_i)$ for all\n$t\\leq t'$.\nIn Section~\\ref{sec:5OPT}, we also show that $\\HH_t(P_i)$ is a supermartingale i.e., $\\E [\\HH_{t'}(P_i) \\mid C_{t}] \\leq \\HH_{t}(P_i)$ for all $t\\leq t'$.\n \\section{Bound on the cost of covered clusters}\\label{sec:5OPT}\nIn this section, we improve the bound by \\citet*{arthur2007k} on the expected cost of a covered cluster in $k$-means++. Our bound also works for $k$-means$\\kpp$ algorithm. Pick an arbitrary cluster $P_i$ in the optimal solution $\\calP= \\cbr{P_1,\\dots, P_k}$ and consider an arbitrary state\n$C_t = \\cbr{c_1,\\dots,c_N}$ of the $k$-means++ or $k$-means$\\parallel_{\\Pois}$ algorithm. Let $D_{t+1}$ be the set of new centers the algorithm adds to $C_t$\nat step $t$ (for $k$-means++, $D_{t+1}$ contains only one center). Suppose now that centers in $D_{t+1}$ cover $P_i$ i.e. $D_{t+1}\\cap P_i\\neq \\varnothing$.\nWe show that the expected cost of cluster $P_i$ after step $(t+1)$ conditioned on the event $\\{D_{t+1}\\cap P_i\\neq \\varnothing\\}$ and the current state of the algorithm $C_t$ is upper bounded by $5\\opt_1(P_i)$ i.e.\n\\begin{equation}\\label{eq:5OPT}\n\\E\\sbr{\\cost(\\cluster_i, C_{t+1}) \\mid C_t, \\{D_{t+1} \\cap \\cluster_i\\neq \\varnothing\\}} \\leq 5 \\opt_1(P_i).\n\\end{equation}\n\nWe now prove the main lemma.\n\\begin{lemma}\\label{lem:5OPT}\nConsider an arbitrary set of centers $C=\\{c_1,\\dots, c_N\\} \\subseteq \\R^\\dimension$ and an arbitrary set $P\\subseteq \\pointset$. Pick a random point $c$ in $P$ with probability $\\Pr(c = x) = \\cost(x, C)/\\cost(P,C)$. Let $C' = C\\cup \\{c\\}$. Then, $ \\E_c\\sbr{\\cost(P,C')} \\leq 5 \\opt_1(P)$.\n\\end{lemma}\n\n\\noindent\\textbf{Remarks:} Lemma 3.2 in the paper by \\citet*{arthur2007k} gives\na bound of $8 \\opt_1(P)$. We also show in Appendix~\\ref{sec:lb} that our bound is tight (see Lemma~\\ref{thm:5-approx-tight}).\n\n\\begin{proof}\nThe cost of any point $y$ after picking\ncenter $c$ equals the squared distance from $y$ to the set of\ncenters $C' = C \\cup \\{c\\}$, which in turn equals\n$\\min\\{\\cost(y,C), \\|y-c\\|^2\\}$. Thus, if a point\n$x\\in P$ is chosen as a center, then the\ncost of point $y$ equals $\\min\\{\\cost(y,C), \\norm{x-y}^2\\}$.\nSince $\\Pr(c=x) = \\cost(x,C)/\\cost(P,C)$, we have\n\\begin{align*}\n\\E_c\\sbr{\\cost(P,C')} = \\sum_{\\substack{x \\in P\\\\y\\in P}} \\frac{\\cost(x,C)}{\\cost(P,C)}\\cdot \\min\\{\\cost(y,C), \\|x-y\\|^2\\}. \n\\end{align*}\nWe write the right hand side in a symmetric form\nwith respect to $x$ and $y$. To this end,\nwe define function $f$ as follows:\n\\begin{align*}\nf(x,y) = \\cost(x,C) \\cdot \\min\\cbr{\\norm{x-y}^2, \\cost(y,C)} + \\cost(y,C) \\cdot \\min\\cbr{\\norm{x-y}^2, \\cost(x,C)}.\n\\end{align*}\nNote that $f(x,y) = f(y,x)$. Then,\n$$\\E_c\\sbr{\\cost(P,C')} =\n\\frac{1}{2\\cost(P,C)} \\sum_{(x, y)\\in \\cluster\\times \\cluster} f(x,y).\n$$\n\nWe now give an upper bound on $f(x,y)$ and then use\nthis bound to finish the proof of Lemma~\\ref{lem:5OPT}.\n\n\\begin{lemma}\\label{lem:fxy}\nFor any $x,y \\in \\cluster$, we have $f(x,y) \\leq 5 \\min\\cbr{\\cost(x,C),\\cost(y,C)} \\norm{x-y}^2$.\n\\end{lemma}\n\\begin{proof}\nSince $f(x,y)$ is a symmetric function with respect to $x$ and $y$, we may assume without loss of generality that $\\cost(x,C) \\leq \\cost(y,C)$. Then, we need to show that $f(x,y) \\leq 5 \\cost(x,C) \\norm{x-y}^2$.\nConsider three cases.\n\n\\medskip\n\n\\noindent\\textbf{Case 1:} If $\\cost(x,C) \\leq \\cost(y,C) \\leq \\norm{x-y}^2$, then\n\\begin{align*}\n    f(x,y) = 2\\cost(x,C) \\cost(y,C) \\leq 2\\cost(x,C) \\norm{x-y}^2.\n\\end{align*}\n\n\\medskip\n\n\\noindent\\textbf{Case 2:} If $\\cost(x,C) \\leq \\norm{x-y}^2 \\leq \\cost(y,C)$, then\n\\begin{align*}\n    f(x,y) = \\cost(x,C) \\norm{x-y}^2 + \\cost(y,C) \\cost(x,C).\n\\end{align*}\nBy the triangle inequality, we have\n$$\\cost(y,C) \\leq \\rbr{\\sqrt{\\cost(x,C)} + \\norm{x-y}}^2 \\leq 4 \\norm{x-y}^2.$$\nThus, $f(x,y) \\leq 5 \\cost(x,C) \\norm{x-y}^2$.\n\n\\medskip\n\n\\noindent\\textbf{Case 3:} If $\\norm{x-y}^2 \\leq \\cost(x,C) \\leq \\cost(y,C)$, then\n$$f(x,y) = \\rbr{\\cost(x,C) + \\cost(y,C)} \\norm{x-y}^2.$$\nBy the triangle inequality,\n$$\\cost(y,C) \\leq \\rbr{\\sqrt{\\cost(x,C)}+ \\norm{x-y}}^2 \\leq 4 \\cost(x,C).$$\nThus, we have\n$f(x,y) \\leq 5 \\cost(x,C) \\norm{x-y}^2$.\n\nIn all cases, the desired inequality holds. This concludes the proof of Lemma~\\ref{lem:fxy}.\n\\end{proof}\n\n\\medskip\n\nWe use Lemma~\\ref{lem:fxy} to bound the expected cost of $P$.\nLet $\\phi^*$ be a vector in $\\real^{P}$ with $\\phi^*_x = \\cost(x,C)$ for any $x \\in \\cluster$. Then,\n$\nf(x,y) \\leq 5 \\min\\cbr{\\phi^*_x,\\phi^*_y} \\norm{x-y}^2$.\nSince $\\cost(P,C) = \\sum_{z\\in P} \\phi^*_z$, we have\n$$\n\\E_c\\sbr{\\cost(P,C')} \\leq\n\\underbrace{\n    \\frac{5\\sum_{(x, y)\\in \\cluster\\times \\cluster} \\min\\cbr{\\phi^*_x,\\phi^*_y} \\norm{x-y}^2}{2\\sum_{z\\in P}\\phi^*_z}\n}_{5F(\\phi^*)}.\n$$\nFor arbitrary vector $\\phi \\in \\real_{\\geq 0}^{P}$, define the\nfollowing function:\n\\begin{equation}\\label{eq:def:F}\nF(\\phi) = \\frac{\\sum_{(x,y) \\in \\cluster\\times \\cluster}  \\min\\cbr{\\phi_x,\\phi_y} \\norm{x-y}^2}{2\\sum_{z\\in P} \\phi_z}. \n\\end{equation}\nWe have $\\E_c\\sbr{\\cost(P,C')} \\leq 5F(\\phi^*)$. Thus,\nto finish the proof of Lemma~\\ref{lem:5OPT}, it suffices to show that\n$F(\\phi)\\leq \\opt_1(P)$ for every $\\phi \\geq 0$ and particularly for\n$\\phi=\\phi^*$. By Lemma~\\ref{lem:5OPT:integral} (which we state and prove below), function\n$F(\\phi)$ is maximized when $\\phi\\in \\{0,1\\}^P$. Let $\\phi^{**}$\nbe a maximizer of $F(\\phi)$ in $\\{0,1\\}^P$\nand\n$P'=\\{x\\in P: \\phi^{**}_x = 1\\}$. Observe that\n\\begin{align*}\n    F(\\phi^{**}) =  \n\\frac{\\sum_{(x,y) \\in \\cluster'\\times \\cluster'}\n\\norm{x-y}^2}{2|P'|}\n= \\opt_1(P').\n\\end{align*}\nHere we used the closed form expression\n(\\ref{eq:opt-1-closed-form}) for\nthe optimal cost of cluster $P'$. Since $P'\\subset P$, we\nhave $\\opt_1(P')\\leq \\opt_1(P)$. Thus,\n$F(\\phi^*)\\leq F(\\phi^{**})\\leq \\opt_1(P)$.\n\\end{proof}\n\n\\begin{lemma}\\label{lem:5OPT:integral}\nThere exists a maximizer $\\phi^{**}$ of $F(\\phi)$ in the region $\\{\\phi \\geq 0\\}$\nsuch that $\\phi\\in \\{0,1\\}^P$.\n\\end{lemma}\n\\begin{proof}\nLet $m=|P|$ be the size of the cluster $P$ and\n$\\Pi$ be the set of all bisections or permutations $\\pi: \\{1,\\dots, m\\}\\to P$. Partition the set $\\{\\phi \\geq 0\\}$ into $m!$ regions (``cones over order polytopes''):\n$$\\{\\phi: \\phi \\geq 0\\}=\\cup_{\\pi \\in \\Pi} O_{\\pi},$$\nwhere $O_{\\pi} = \\{\\phi : 0 \\leq \\phi_{\\pi(1)} \\leq \\phi_{\\pi(2)}\\leq \\cdots \\leq \\phi_{\\pi(m)}\\}$.\nWe show that for every $\\pi \\in \\Pi$, there exists a maximizer $\\phi^{**}$ of $F(\\phi)$ in the\nregion $O_{\\pi}$, such that $\\phi^{**}\\in \\{0,1\\}^P$. Therefore, there exists a global\nmaximizer $\\phi^{**}$ that belongs $\\{0,1\\}^P$\n\nFix a $\\pi\\in \\Pi$. Denote by $V$ the hyperplane $\\{\\phi: \\sum_{x\\in P} \\phi_x = 1\\}$. Observe that\n$F$ is a scale invariant function i.e., $F(\\phi)= F(\\lambda \\phi)$ for every $\\lambda > 0$. Thus,\nfor every $\\phi \\in O_{\\pi}$, there exists\na $\\phi' \\in O_\\pi \\cap V$\n(namely,  $\\phi' = \\phi / (\\sum_{x\\in P} \\phi_x)$) such that $F(\\phi') = F(\\phi)$.\nHence, $\\max\\{F(\\phi): \\phi \\in O_{\\pi}\\} = \\max\\{F(\\phi): \\phi \\in O_{\\pi}\\cap V\\}$.\nNote that for $\\phi\\in V$, the denominator of~(\\ref{eq:def:F}) equals 2, and\nfor $\\phi\\in O_{\\pi}$, the numerator of~(\\ref{eq:def:F}) is a linear function of $\\phi$.\nTherefore, $F(\\phi)$ is a linear function in the convex set $O_{\\pi}\\cap V$. Consequently,\none of the maximizers of $F$ must be an extreme point of $O_{\\pi}\\cap V$.\n\nThe polytope $O_{\\pi}\\cap V$ is defined by $m$ inequalities and one equality. Thus, for every\nextreme point $\\phi$ of this polytope, all inequalities $\\phi_{\\pi(i)}\\leq \\phi_{\\pi(i+1)}$\nbut one must be tight. In other words, for some $j< m$, we have\n\\begin{equation}\\label{eq:all-but-one-equal}\n0 = \\phi_{\\pi(1)} =  \\cdots = \\phi_{\\pi(j)} < \\phi_{\\pi(j+1)} = \\cdots = \\phi_{\\pi(m)}. \n\\end{equation}\nTherefore, there exists a maximizer $\\phi$ of $F(\\phi)$ in $O_{\\pi} \\cap V$ satisfying\n(\\ref{eq:all-but-one-equal}) for some\n$j$. After rescaling $\\phi$ -- multiplying\nall coordinates of $\\phi$ by $(m-j)$ -- we obtain a vector $\\phi^{**}$ whose first $j$ coordinates\n$\\phi^{**}_{\\pi(1)}, \\dots, \\phi^{**}_{\\pi(j)}$ are zeroes and the last $m-j$ coordinates\n$\\phi^{**}_{\\pi(j+1)}, \\dots, \\phi^{**}_{\\pi(m)}$ are ones. Thus,\n$\\phi^{**}\\in\\{0,1\\}^P$. Since $F$ is rescaling invariant,\n$F(\\phi^{**}) = F(\\phi)$. This concludes the proof.\n\\end{proof}\n\n\nReplacing the bound in Lemma 3.2 from the analysis of \\citet{arthur2007k} by our bound from Lemma~\\ref{lem:5OPT} gives the following result (see also Lemma~\\ref{thm:log-bound}).\n\\begin{theorem}\nThe approximation factor of $k$-means++ is at most $5(\\ln k + 2)$.\n\\end{theorem}\n\nWe now state an important corollary of\nLemma~\\ref{lem:5OPT}.\n\\begin{corollary}~\\label{cor:5opt-martingale}\nFor every $P\\in\\calP$, the process $\\HH_{t}(P)$ for $k$-means++ is a supermartingale i.e.,\n$$\\expect{\\HH_{t+1}(\\pointset) \\mid C_t} \\leq \\HH_{t}(\\pointset).$$\n\\end{corollary}\n\\begin{proof}\nThe value of $\\HH_{t}(\\pointset)$ changes only\nif  at step $t$, we cover a yet uncovered cluster $P$. In this case, the value of $\\HH_{t+1}(P)$ changes by the new cost of $P$ minus $5\\opt(P)$. By Lemma~\\ref{lem:5OPT} this quantity is non-positive in expectation. %To apply Lemma~\\ref{lem:5OPT} to $k$-means\\kpp, we use the approach from Section~\\ref{sec:one-at-time}.\n\\end{proof}\n\nSince the process $\\HH_{t}(P)$ is a supermartingale, we have $\\E[\\HH_{t}(P)] \\leq \\HH_{0}(P) = 5\\opt_1(P)$.\nHence, $\\E[H_{t}(P)] \\leq \\E[\\HH_{t}(P)] = 5\\opt_1(P)$. Thus,\n$\\E[H_{t}(X)] \\leq 5\\opt_k(\\pointset)$.\nSince $\\cost_t(\\pointset) = H_t(\\pointset) +\nU_t(\\pointset)$ and we have a bound on the expectation of the covered cost, $H_t(\\pointset)$, in the remaining sections, we shall only analyze the uncovered cost $U_t(\\pointset)$.\n \\section{\\texorpdfstring{Bi-criteria approximation of $k$-means++}{Bi-criteria approximation of  k-means++}}\\label{sec:po-bi-criteria}\n\nIn this section, we give a bi-criteria approximation guarantee for $k$-means++.\n\n\\begin{theorem}\\label{thm:kmeanspp-main}\nLet $\\cost_{k+\\extracenters}\\rbr{\\total}$ be the cost of the clustering with $k+\\extracenters$ centers sampled by the $k$-means++ algorithm. Then,\nfor $\\extracenters \\geq 1$, the expected cost\n$\\expect{\\cost_{k+\\extracenters}(\\pointset)}$ is upper bounded by (below $(a)^+$ denotes $\\max(a,0)$).\n$$\\min\\Big\\{\n2 + \\frac{1}{2e} + \\Big(\\ln{\\frac{2k}{\\extracenters}}\\Big)^+,\n1+ \\frac{k}{e\\rbr{\\extracenters-1}}\n\\Big\\}\\, 5 \\opt_k(\\pointset).$$\n\\end{theorem}\n\nNote that the above approximation guarantee is  the minimum of two bounds: (1)\n$2 + \\frac{1}{2e} + \\ln{\\frac{2k}{\\extracenters}}$\nfor $1\\leq \\Delta \\leq 2k$; and (2) $1+ \\frac{k}{e\\rbr{\\extracenters-1}}$\nfor $\\Delta \\geq 1$. The second bound is stronger than the first bound when $\\extracenters/k \\gtrapprox 0.085$.\n\n\\subsection{Proof overview of Theorem~\\ref{thm:kmeanspp-main}}\nWe now present a high level overview of the proof and then give a formal proof. Our proof consists of three steps.\n\nFirst, we prove bound (2) on the expected cost of the clustering returned by $k$-means++ after $k+\\Delta$ rounds. We argue that the expected cost of the covered clusters is bounded by $5\\opt_k(\\pointset)$ (see Section~\\ref{sec:framework}) and thus it is sufficient to bound the expected cost of uncovered clusters. Consider an optimal cluster $P\\in \\calP$. We need to estimate the probability that it is not covered after $k + \\Delta$ rounds. We upper bound this probability by the probability that the algorithm does not cover $P$ before it makes $\\Delta$ misses (note: after $k+\\Delta$ rounds $k$-means++ must make at least  $\\Delta$ misses).\n\nIn this overview, we make the following simplifying assumptions (which turn out to be satisfied in the worst case for bi-criteria $k$-means++): Suppose that the uncovered cost of cluster $P$ does not decrease before it is covered and equals $U(P)$ and, moreover, the total cost of all covered clusters almost does not change and equals $H(\\pointset)$ (this may be the case if one large cluster contributes most of the covered cost, and that cluster is covered at the first step of $k$-means++). Under these assumptions, the probability that $k$-means++ chooses $\\Delta$ centers in the already covered clusters and does not choose a single center in $P$ equals $(H(\\pointset)/(U(P)+H(\\pointset)))^\\Delta$. If $k$-means++ does not choose a center in $P$, the \\emph{uncovered} cost of cluster $P$ is $U(P)$; otherwise, the \\emph{uncovered} cost of cluster $P$ is $0$. Thus, the expected~\\emph{uncovered cost} of $P$ is $(H(\\pointset)/(U(P)+H(\\pointset)))^\\Delta U(P)$. It is  easy to show that $(H(\\pointset)/(U(P)+H(\\pointset)))^\\Delta U(P) \\leq H(\\pointset)/(e (\\Delta - 1))$. Thus, the expected \\emph{uncovered cost} of all clusters is at most\n$$\\frac{k}{(e (\\Delta - 1))} \\E[H(\\pointset)]\\leq \\frac{k}{(e (\\Delta - 1))} 5\\opt_k(\\pointset).$$\n\nThen,  we use ideas from \\citet*{arthur2007k},~\\citet{dasgupta-notes} to prove the following statement: Let us count the cost of uncovered clusters only when the number of misses after $k$ rounds of $k$-means++ is greater than $\\Delta/2$. Then the expected cost of uncovered clusters is at most $O(\\log (k/\\Delta))\\cdot \\opt_k(\\pointset)$. That is, $\\E[H(U_k(\\pointset)\\cdot \\mathbf{1}\\{M(C_k)\\geq \\Delta/2\\}]\\leq O(\\log (k/\\Delta))\\cdot \\opt_k(\\pointset)$.\n\nFinally, we combine the previous two steps to get bound (1). We argue that if the number of misses after $k$ rounds of $k$-means++ is less than $\\Delta/2$, then\nalmost all clusters are covered. Hence, we can apply bound (2) to $k'\\leq \\Delta/2$ uncovered clusters and $\\Delta$ remaining rounds of $k$-means++ and get a $5(1+1/(2e))$ approximation. If the number of misses is greater than $\\Delta/2$, then the result from the previous step yields an $O(\\log (k/\\Delta))$ approximation.\n \\subsection{\\texorpdfstring{Analysis of $k$-means++}{Analysis of k-means++}}\\label{sec:apx-bi-criteria-kmeans}\n\nIn this section, we analyze the bi-criteria $k$-means++ algorithm and prove Theorem~\\ref{thm:kmeanspp-main}. To this end, we establish the first and second bounds from Theorem~\\ref{thm:kmeanspp-main} on the expected cost of the clustering after $k+\\Delta$ rounds of $k$-means. We will start with the second bound.\n\n\\subsubsection{\\texorpdfstring{Bi-criteria bound for large $\\Delta$}{Bi-criteria bound for large Delta}}\n\n\\begin{lemma}\\label{lem:e_bound}\nThe following bi-criteria bound holds\n$$\n    \\expect{\\cost_{k+\\extracenters}\\rbr{\\total}} \\leq 5\\rbr{1+ \\frac{k}{e\\rbr{\\extracenters-1}}} \\opt_k(\\pointset).\n$$\n\\end{lemma}\n\nConsider the discrete time Markov chain $C_t$\nassociated with $k$-means++ algorithm\n(see Section~\\ref{sec:framework}). Let $\\cluster\\in \\calP$ be an arbitrary cluster in the optimal solution. Partition all states of the Markov chain into\n$k+\\Delta$ disjoint groups $\\calM_0,\\calM_1,\\cdots, \\calM_{k+\\Delta-1}$ and $\\calH$. Each set $\\calM_i$ contains all states $C$ with $i$\nmisses that do not cover $P$:\n$\\calM_i = \\cbr{C: M(C) = i, \\cluster\\cap C = \\varnothing}.$\nThe set $\\calH$ contains all states $C$ that cover $P$:\n$\\calH = \\cbr{C: \\cluster \\cap C \\neq \\varnothing}$.\n\nWe now define a new Markov chain $X_t$. To this end, we first expand the set of states $\\{C\\}$.\nFor every state $C$ of the process $C_t$, we create two additional ``virtual'' states $C^a$ and $C^b$. Then, we let $X_{2t} = C_t$ for every even step $2t$,  and\n$$\nX_{2t+1}=\n\\begin{cases}\nC_t^a, & \\mbox{if } C_{t+1}\\in \\calM_i \\\\\nC_t^b, & \\mbox{if } C_{t+1}\\in \\calM_{i+1} \\cup \\calH.\n\\end{cases} $$\nfor every odd step $2t+1$. We stop $X_t$ when $C_t$ stops or when $C_t$ hits the set $\\calH$ (i.e., $C_t\\in \\calH$).\nLoosely speaking,  $X_t$ follows Markov chain $C_t$ but makes additional intermediate stops. When $C_t$ moves from one state in $\\calM_i$ to another state in $\\calM_i$, $X_{2t+1}$ stops in $C_t^a$; and when  $C_t$ moves from a state in $\\calM_i$ to a state in $\\calM_{i+1}$ or $\\calH$, $X_{2t+1}$ stops in $C_t^b$.\n\n\nWrite transition probabilities for $X_t$:\n\\begin{align*}\n    \\prob{X_{2t+1} = C^a \\mid X_{2t} =  C} = \\frac{U(\\pointset,C)- U(\\cluster,C)}{\\cost(\\pointset,C)}, \\\\\n    \\prob{X_{2t+1} = C^b \\mid  X_{2t} =  C} = \\frac{U(\\cluster,C) + H(\\pointset,C)}{\\cost(\\pointset,C)},\n\\end{align*}\nand for all $C \\in  \\calM_{i}$ and $C'= C\\cup\\{x\\}\\in \\calM_{i}$,\n$$\n\\prob{X_{2t+2} = C' \\mid X_{2t+1} = C^a} = \\frac{\\cost(x,C)}{U(\\pointset,C)- U(\\cluster,C)},\n$$\nfor all $C \\in \\calM_i$ and $C'= C\\cup\\{x\\} \\in \\calM_{i+1} \\cup \\calH$,\n$$\n\\prob{X_{2t+2} = C' \\mid  X_{2t+1} = C^b} = \\frac{\\cost(x,C)}{U(\\cluster,C) + H(\\pointset,C)}.\n$$\nAbove, $U(\\pointset,C)- U(\\cluster,C)$ is the\ncost of points in all uncovered clusters except for $P$. If we pick a center from these clusters, we will necessarily cover a new cluster, and therefore $X_{2t+2}$ will stay in $\\calM_i$. Similarly,\n$U(\\cluster,C) + H(\\pointset,C)$ is the cost of all covered clusters plus the cost of $P$. If we pick a center from these clusters, then $X_{2t+2}$ will move to $\\calM_{i+1}$ or\n$\\calH$.\n\nDefine another Markov chain $\\cbr{Y_t}$. The\ntransition probabilities of $\\cbr{Y_t}$\nare the same as the transition probabilities\nof $X_t$ except $Y$ never visits states in\n$\\calH$ and therefore for $C\\in \\calM_i$ and\n$C'=C\\cup\\{x\\}\\in\\calM_{i+1}$, we have\n$$\n\\prob{Y_{2t+2} = C' \\mid Y_{2t+1} = C^b} = \\frac{\\cost(x,C)}{H(\\pointset,C)}. \n$$\n\nWe now prove a lemma that relates probabilities of visiting states by $X_t$ and $Y_t$.\n\\begin{lemma}~\\label{lem:coupling}\nFor every $t\\leq k+\\Delta$ and states $C' \\in \\calM_i$, $C''\\in \\calM_\\extracenters$, we have\n$$\n\\frac{\\prob{C'' \\in \\cbr{X_j} \\mid X_{2t} = C'}}{\\prob{C'' \\in \\cbr{Y_j} \\mid Y_{2t} = C'}} \\leq \\rbr{\\frac{\\HH(\\pointset,C'')}{\\HH(\\pointset,C'')+U(\\cluster,C'')}}^{\\Delta - i}\n$$\nwhere $\\{C'' \\in \\cbr{X_j}\\}$ and $\\{C'' \\in \\cbr{Y_j}\\}$ denote the events $X$ visits\n$C''$ and $Y$ visits $C''$, respectively.\n\\end{lemma}\n\n\\begin{proof}\nConsider the unique path $p$ from $C'$ to $C''$\nin the state space of $X$ (note that the transition graphs for $X$ and $Y$ are directed trees).\nThe probability of transitioning from $C'$ to\n$C''$ for $X$ and $Y$ equals the product of\nrespective transition probabilities for every\nedge on the path. Recall that transitions probabilities for $X$ and $Y$ are the same for all states but $C^b$, where $C\\in \\cup_j\\calM_j$.\nThe number of such states on the path $p$ is\nequal to the number transitions from $\\calM_j$\nto $\\calM_{j+1}$, since $X$ and $Y$ can get\nfrom $\\calM_j$ to $\\calM_{j+1}$ only through\na state $C^b$ on the boundary of\n$\\calM_j$ and $\\calM_{j+1}$. The number of\ntransitions from $\\calM_j$ to $\\calM_{j+1}$\nequals $\\Delta - i$. For each state $C^b$ on the\npath, the ratio of transition probabilities\nfrom $C^b$ to the next state $C \\cup \\{x\\}$ for Markov chains\n$X$ and $Y$ equals\n$$\n \\frac{H(\\pointset,C)}{U(\\cluster,C) + H(\\pointset,C)}\\leq\n \\frac{\\HH(\\pointset,C'')}{U(\\cluster,C'') + \\HH(\\pointset,C'')},\n$$\nhere we used that (a) $U(P,C)\\geq U(P,C'')$ since\n$U_t(P)$ is a non-increasing process; and (b)\n$H(P,C)\\leq \\HH(P,C'')$ since\n$H_t(P)\\leq \\HH_{t'}(P)$\nif $t \\leq t'$ (see Section~\\ref{sec:framework}).\n\\end{proof}\nWe now prove an analog of Corollary~\\ref{cor:5opt-martingale} for\n$\\HH(\\pointset,Y_j)$.\n\\begin{lemma}~\\label{lem:supermartingale}\n$\\HH(\\pointset,Y_t)$ is a supermartingale.\n\\end{lemma}\n\\begin{proof}\nIf $Y_j = C$, then $Y_{j+1}$ can only be in $\\cbr{C^a,C^b}$. Since $\\HH(\\pointset,C^a) = \\HH(\\pointset,C^b) = \\HH(\\pointset,C)$, we have $\\expect{\\HH(\\pointset,Y_{j+1}) \\mid  Y_j = C} = \\HH(\\pointset,Y_j)$.\n\nIf $Y_j = C^a$, then $Y_{j+1} = C'$ where the new center $c$ should be in uncovered clusters with respect to $C_t$.\n$$\n    \\expect{H(\\cluster',Y_{j+1}) \\mid Y_j = C^a, c\\in \\cluster'} \\leq 5\\opt_1(\\cluster'),\n$$\nwhich implies\n$$\n    \\expect{\\HH(\\cluster',Y_{j+1}) \\mid Y_j = C^a, c \\in \\cluster'} \\leq \\HH(\\cluster',Y_j).\n$$\nTherefore, we have\n$$\n    \\expect{\\HH(\\pointset,Y_{j+1}) \\mid Y_j= C^a} \\leq \\HH(\\pointset,Y_j).\n$$\nIf $Y_j = C^b$, then for any possible state $C'$ of $Y_{j+1}$,  the new center should be in covered clusters with respect to $C$. By definition, we must have\n$\\HH(\\pointset,C') = \\HH(\\pointset,C) = \\HH(\\pointset,C^b)$. Thus, it holds that $\\expect{\\HH(\\pointset,Y_{j+1}) \\mid Y_j = C^b} = \\HH(\\pointset,Y_j)$.\n\nCombining all these cases, we get $\\cbr{\\HH(\\pointset,Y_j)}$ is a supermartingale.\n\\end{proof}\n\n\nWe now use Lemma~\\ref{lem:coupling} and Lemma~\\ref{lem:supermartingale} to bound the expected uncovered cost of $P$ after\n$k+\\extracenters$ rounds of $k$-means++.\n\n\\begin{lemma}~\\label{lem:e_bound-one-cluster}\nFor any cluster $P\\in \\calP$ and $t\\leq k+\\Delta$, we have\n$$\n\\expect{U_{k+\\extracenters}(\\cluster) \\mid C_t} \\leq \\frac{\\HH_t(\\pointset)}{e(\\extracenters-M(C_t)-1)}.\n$$\n\\end{lemma}\n\\begin{proof}\nSince $k$-means++ samples $k+\\extracenters$ centers and the total number of clusters in the optimal solution $\\calP$ is $k$, $k$-means++ must make $\\Delta$ misses. Hence, the process $\\cbr{X_t}$ which follows $k$-means++\nmust either visit a state in $\\calM_{\\geq \\extracenters}$\nor stop in $\\calH$ (recall that we stop process $X_t$ if it reaches $\\calH$).\n\nIf $\\cbr{X_t}$ stops in group $\\calH$, then the cluster $P$ is covered which means that $U_{k+\\extracenters}(\\cluster) = 0$.\nLet $\\partial \\calM_{\\Delta}$ be the frontier of\n$\\calM_{\\Delta}$ i.e., the states that $X_t$\nvisits first when it reaches $\\calM_\\Delta$\n(recall that the transition graph of $X_t$ is\na tree). The expected cost\n$\\expect{U_{k+\\extracenters}(\\cluster) \\mid C_t}$ is upper bounded by the expected uncovered cost of $P$ at time when $C_t$ reaches $\\MM_{\\Delta}$.\nThus,\n$$\n    \\expect{U_{k+\\extracenters}(\\cluster) \\mid C_t} \\leq \\sum_{C \\in \\MM_\\extracenters} \\prob{C \\in \\cbr{X_j} \\mid C_t} U(\\cluster,C).\n$$\nObserve that by Lemma~\\ref{lem:coupling},  for any $C \\in \\MM_{\\Delta}$, we have\n\\begin{align*}\n\\prob{C \\in \\cbr{X_j} \\mid C_t} U(P,C)\n\\leq \\prob{C \\in \\cbr{Y_j} \\mid C_t} \\rbr{\\frac{\\HH(\\pointset,C)}{\\HH(\\pointset,C)+U(\\cluster,C)}}^{\\extracenters'} U(P,C).\n\\end{align*}\n\nLet $f(x) = x(1/(1+x))^{\\extracenters'}$. Then, $f(x)$ is maximized at $x = 1/(\\extracenters'-1)$ and the maximum value $f(1/(\\extracenters'-1)) = 1/(e(\\extracenters'-1))$. Therefore, for every $C \\in \\MM_\\extracenters$, we have\n\\begin{align*}\n    \\pr[C \\in \\cbr{X_j} \\mid C_t] U(P,C) &\\leq \\prob{C \\in \\cbr{Y_j} \\mid C_t} f\\rbr{\\frac{U(\\cluster,C)}{\\HH(\\pointset,C)}} \\HH(\\pointset,C) \\\\\n    &\\leq \\prob{C \\in \\cbr{Y_j} \\mid C_t} \\frac{\\HH(\\pointset,C)}{e(\\extracenters'-1)}.\n\\end{align*}\nLet $\\tau = \\min\\cbr{j: Y_j \\in \\MM_\\extracenters}$ be the stopping time when $Y_j$ first visits $\\MM_\\extracenters$. We get\n\\begin{align*}\n    \\sum_{C \\in \\MM_\\extracenters} \\prob{C \\in \\cbr{Y_j} \\mid C_t} \\HH(\\pointset,C) = \\expect{\\HH(\\pointset,Y_\\tau) \\mid C_t}.\n\\end{align*}\nBy Lemma~\\ref{lem:supermartingale},  $\\HH(\\pointset,Y_j)$ is a supermartingale. Thus,\nby the optional stopping theorem,\n$$\n    \\expect{\\HH(\\pointset,Y_\\tau) \\mid C_t} \\leq \\HH(\\pointset,C_t).\n$$\nTherefore, we have\n\\begin{align*}\n    \\expect{U_{k+\\extracenters}(\\cluster) \\mid C_t} \\leq \\frac{\\HH_t(\\pointset)}{e(\\extracenters-M(C_t)-1)},\n\\end{align*}\nThis concludes the proof.\n\\end{proof}\nWe now add up bounds from  Lemma~\\ref{lem:e_bound-one-cluster} with\n$t= 0$\nfor all clusters $P\\in \\calP$ and obtain\nLemma~\\ref{lem:e_bound}.\n\n\n \\subsection{\\texorpdfstring{Bi-criteria bound for small $\\Delta$}{Bi-criteria bound for small Delta}}\nIn this section, we give another bi-criteria\napproximation guarantee for $k$-means++.\n\n\\begin{lemma}\\label{thm:log-bound}\nLet $\\cost_{k+\\extracenters}(\\pointset)$ be the cost of the the clustering resulting from sampling $k+\\Delta$ centers according to the $k$-means++ algorithm (for $\\Delta \\in \\{1,\\dots, 2k\\}$). Then,\n$$\n    \\expect{\\cost_{k+\\extracenters}(X)} \\leq 5\n    \\rbr{2 + \\frac{1}{2e} + \\ln{\\frac{2k}{\\extracenters}}}\n    \\opt_{k}(X).\n$$\n\\end{lemma}\n\\begin{proof}\nConsider  $k$-means++ clustering algorithm and the corresponding random process $C_t$.\nFix a $\\kappa\\in\\{1,\\dots,k\\}$.\nLet $\\tau$ be the first iteration\\footnote{Recall, that $K(C_t)$ is a non-increasing stochastic\nprocess with $K(C_0) = k$.} (stopping time) when $K(C_\\tau) \\leq \\kappa$ if $K(C_k) \\leq \\kappa$;\nand $\\tau = k$, otherwise.\nWe refer the reader to Section~\\ref{sec:framework} for\ndefinitions of $M(C_t)$, $U_t(X)=U(X,C_t)$,\nand $K(C_t)$.\n\nWe separately analyze the cost of uncovered clusters after the first $\\tau$ steps and the last $k'-\\tau$ steps, where $k'=k+\\Delta$ is the total number of centers chosen by $k$-means++.\n\nThe first step of our proof follows the analysis of $k$-means++ by~\\citet{dasgupta-notes}, and by \\citet*{arthur2007k}. Define a potential function $\\Psi$ (see~\\citealt{dasgupta-notes}):\n$$\n    \\potential_t \\coloneqq \\cfrac{M(C_t) U(X, C_t)}{K(C_t)}.\n$$\nIf $K(C_t)= 0$, then\n$M(C_t)$ and $U(X,C_t)$ must be $0$\nand we let $\\Psi_t =0$\n\nWe use the following result by~\\citet{dasgupta-notes} to estimate\n$\\E[\\Psi_{\\tau}(X)]$ in Lemma~\\ref{lem:many-misses}.\n\\begin{lemma}[\\citet{dasgupta-notes}]\\label{lem:potential}\nFor any $0\\leq t \\leq k$, we have\n$$\n\\expect{\\potential_{t+1} - \\potential_{t}\\mid C_t}\\leq\n\\frac{H(X, C_t)}{K(C_t)}.\n$$\n\\end{lemma}\n\n\\begin{lemma}\\label{lem:many-misses}  Then,\nthe following bound holds:\n$$\\E[\\Psi_{\\tau}(X)]\n\\leq 5\\rbr{1+\\ln \\rbr{\\frac{k}{\\kappa+1}} } \\opt_k(X).$$\n\\end{lemma}\n\\begin{proof}\nNote that $\\potential_{1} = 0$ as\n$M(C_1)= 0$. Thus,\n$$\n\\E[\\potential_{\\tau}]\n\\leq \\sum_{t=1}^{\\tau-1}\n\\E \\big[\\potential_{t+1} -  \\potential_{t}\\big]\\leq\n\\E\\Big[\\sum_{t=1}^{\\tau-1}\\frac{H(X, C_t)}{K(C_t)}\\Big].\n$$\nUsing the inequality $H(X, C_t)\\leq\n\\HH_k(X)$ (see Section~\\ref{sec:framework}), we get:\n$$\n\\E[\\potential_{\\tau}]\n\\leq\n\\E\\Big[\\sum_{t=1}^{\\tau-1}\\frac{\\HH_k(X)}{K(C_t)}\\Big]\n\\leq \\E\\Big[\\HH_k(X)\\cdot\n\\sum_{t=1}^{\\tau-1}\\frac{1}{K(C_t)}\\Big].\n$$\nObserve that $K(C_1),\\dots, K(C_{\\tau-1})$ is\na non-increasing sequence in which two consecutive\nterms are either equal or $K(C_{i+1}) = K(C_i) - 1$.\nMoreover, $K(C_1) =k$ and $K(C_{\\tau - 1}) > \\kappa$. Therefore,\nby Lemma~\\ref{lem:harmonic:series} (see below),\nfor every realization $C_0,C_1,\\dots, C_{\\tau}$,\nwe have:\n$$\\sum_{t=1}^{\\tau -1}\\frac{1}{K(C_t)}\\leq 1 + \\log \\nicefrac{k}{(\\kappa + 1)}.$$\nThus,\n$$\n\\E[\\potential_{\\tau}] \\leq\n(1 + \\log \\nicefrac{k}{(\\kappa + 1)}) \\E[\\HH_k(X)]\n\\leq\n5(1 + \\log \\nicefrac{k}{(\\kappa + 1)})\\;\\opt_k(X). $$\nThis concludes the proof.\n\\end{proof}\n\nLet $\\kappa = \\floor{(\\Delta - 1)/2}$.\nBy Lemma~\\ref{lem:many-misses}, we have\n$$\\E\\Big[\\cfrac{M(C_{\\tau}) U_{\\tau}(X)}{K(C_{\\tau})}\\Big] \\leq 5\\rbr{1+\\ln \\frac{2k}{\\Delta}} \\opt_k(X).$$\nSince $U_{t}(X)$ is a non-increasing\nstochastic process, we have $\\E[U_{k+\\Delta}(X)]\\leq \\E[U_{\\tau}(X)]$. Thus,\n$$\\E\\Big[\\cfrac{M(C_{\\tau})}{K(C_{\\tau})}\\cdot\nU_{k+\\Delta}(X)\\Big] \\leq 5\\rbr{1+\\ln \\frac{2k}{\\Delta}} \\opt_k(X).$$\nOur goal is to bound $\\E[U_{k'}(X)]$.\nWrite,\n\\begin{align*}\n\\E[U_{k'}(X)] =\n\\E\\Big[\\cfrac{M(C_{\\tau})}{K(C_{\\tau})}\\cdot\nU_{k'}(X)\\Big]+\n\\E\\Big[\\cfrac{K(C_\\tau) - M(C_{\\tau})}{K(C_{\\tau})}\\cdot\nU_{k'}(X)\\Big].\n\\end{align*}\nThe first term on the right hand side is upper bounded by $5\\big(1+\\ln \\frac{2k}{\\Delta}\\big) \\opt_k(X)$. We now estimate the second term,\nwhich we denote by $(*)$.\n\nNote that\n$K(C_t) - M(C_{t}) = k - t$,\nsince the number of uncovered clusters after\n$t$ steps of $k$-means++ equals\nthe number of misses plus the number of steps remaining. Particularly, if $\\tau = k$,\nwe have $K(C_\\tau) - M(C_{\\tau}) =\nK(C_k) - M(C_k) = 0$. Consequently, if $\\tau = k$, then the second term $(*)$ equals 0.\nThus, we only need to consider the case, when $\\tau < k$. Note that in this case $K(C_{\\tau}) = \\kappa$. By\nLemma~\\ref{lem:e_bound} (applied to all uncovered\nclusters), we have\n$$\n\\E[U_{k'}(X) \\mid C_{\\tau},\\tau]\n\\leq \\frac{K(C_{\\tau})}{e(\\Delta' - 1)}\\HH_{\\tau}(X),\n$$\nwhere $\\Delta' = \\Delta - M(C_{\\tau})$.\n\nThus,\n\\begin{align*}\n\\E\\Big[\\cfrac{K(C_\\tau) - M(C_{\\tau})}{K(C_{\\tau})}\\cdot\nU_{k'}(X) \\mid C_{\\tau},\\tau \\Big]\n\\leq\n\\cfrac{K(C_\\tau) - M(C_{\\tau})}{K(C_{\\tau})}\\cdot\n\\frac{K(C_{\\tau})}{e(\\Delta' - 1)}\n\\cdot \\HH_{\\tau}(X) = (**).\n\\end{align*}\nPlugging in $K(C_{\\tau})=\\kappa$ and\nthe expression for $\\Delta'$ (see above), and using that $\\kappa\\leq (\\Delta - 1)/2$,\nwe get\n$$\n(**)=\\cfrac{\\kappa - M(C_{\\tau})}{e\n(\\Delta - M(C_{\\tau}) - 1)}.\n\\cdot \\HH_{\\tau}(X)\\leq \\frac{1}{2e}\\HH_{\\tau}(X).\n$$\nFinally, taking the expectation over all $C_{\\tau}$, we obtain the bound\n$$\n\\E\\Big[\\cfrac{K(C_\\tau) - M(C_{\\tau})}{K(C_{\\tau})}\\cdot\nU_{k'}(X)\\Big]\n\\leq \\frac{5\\opt_1(X)}{2e}.\n$$\nThus, $\\E[U_{k'}(X)] \\leq 5(1 + \\nicefrac{1}{2e} + \\ln \\nicefrac{2k}{\\Delta})\\opt_k(X)$.\nTherefore,\n$$\n\\E[\\cost_{k'}(X)] = \\E[H_{k'}(X)] + U_{k'}(X) \\leq 5 \\big(2 + \\frac{1}{2e} + \\ln \\frac{2k}{\\Delta}\\big)\\;\\opt_k(X).\n$$\n\\end{proof}\n\nWe now prove Lemma~\\ref{lem:harmonic:series}.\n\\begin{lemma}~\\label{lem:harmonic:series}\nFor any $t \\leq k$ integers $a_1 \\geq a_2 \\geq \\cdots \\geq a_t$ such that $a_1 = k$, $a_t > \\kappa$ and $a_i -a_{i+1} \\in \\cbr{0,1}$ for all $1\\leq i < t$, the following inequality holds\n$$\n    \\sum_{i=1}^t \\frac{1}{a_i} \\leq 1+ \\log\\rbr{\\frac{k}{\\kappa+1}}.\n$$\n\\end{lemma}\n\n\\begin{proof}\nIt is easy to see that the sum is maximized when $t=k$, and the sequence\n$a_1,\\dots,a_k$ is as follows:\n$$\n\\underbrace{\\frac{1}{k},\\frac{1}{k-1},\n\\dots, \\frac{1}{\\kappa+2}}_{(k-(\\kappa+1)) \\text{ terms}},\n\\underbrace{\\frac{1}{\\kappa+1},\\dots, \\frac{1}{\\kappa+1}}_{(\\kappa + 1) \\text{ terms}}.\n$$\nThe sum of the first $(k-(\\kappa+1))$ terms is upper bounded by\n$$\\int_{1/(\\kappa + 1)}^{1/k}\\frac{1}{x}\\;dx = \\ln \\frac{k}{\\kappa + 1}.$$\nThe sum of the last $(\\kappa + 1)$\nterms is 1.\n\\end{proof}\n \\section{\\texorpdfstring{Analysis of $k$-means$\\parallel$}{Analysis of k-means Parallel}}\\label{sec:po-kmeans-parallel}\n\nIn this section, we give a sketch of analysis for the $k$-means$\\parallel$ algorithm.\nSpecifically, we show upper bounds on the expected cost of the solution after $T$ rounds.\n\n\\begin{theorem}~\\label{thm:kpp_main}\nThe expected cost of the clustering returned by $k$-means$\\parallel$ algorithm after $T$ rounds are upper bounded as follows:\n\\begin{align*}\n    \\text{for $\\ell < k$, }\\qquad \\expect{\\cost_{T+1}(\\total)} &\\leq \\rbr{e^{-\\frac{\\ell}{k}}}^T \\expect{\\cost_1(\\total)} + \\frac{5\\opt_k(\\pointset)}{1-e^{-\\frac{\\ell}{k}}};\n    \\\\\\text{for $\\ell \\geq k$, }\\qquad \\expect{\\cost_{T+1}(\\total)} &\\leq \\rbr{\\frac{k}{e\\ell}}^T \\expect{\\cost_1(\\total)} + \\frac{5\\opt_k(\\pointset)}{1-\\nicefrac{k}{e\\ell}}.\n\\end{align*}\n\\end{theorem}\n\n\\noindent\\textbf{Remark:} For the second bound ($\\ell \\geq k$), the additive term $5\\opt_k(\\pointset)/(1-k/(e\\ell)) \\leq 8 \\opt_k(\\pointset)$.\n\nThe probability that a point is sampled by $k$-means$\\parallel$ is strictly greater than the probability that it is sampled by $k$-means$\\kpp$ since $1-e^{-\\lambda} < \\lambda$ for all $\\lambda > 0$. Thus, for every round, we can couple $k$-means$\\kpp$ and $k$-means$\\parallel$ so that each point sampled by $k$-means$\\kpp$ is also sampled by $k$-means$\\parallel$. Thus, the expected cost returned by $k$-means$\\parallel$ is at most the expected cost returned by $k$-means$\\kpp$. In the following analysis, we show an upper bound for the expected cost of the solution returned by $k$-means$\\kpp$.\n\nAs a thought experiment, consider a modified $k$-means$\\kpp$ algorithm. This algorithm is given the set $\\pointset$, parameter $k$, and additionally\nthe optimal solution $\\calP=\\{P_1,\\dots, P_k\\}$. Although this modified algorithm is useless in practice as we do not know the optimal solution in advance, it will be helpful for our analysis.\n\nIn every round $t$, the modified algorithm first draws independent Poisson random variables $Z_t(P_i)\\sim\\Pois(\\lambda_t(P_i))$ for every cluster $i \\in \\{1,\\dots,k\\}$ with rate $\\lambda_t(P_i) = \\sum_{x\\in P_i} \\lambda_t(x)$. Then, for each $i\\in\\{1,\\dots, k\\}$, it samples $Z_t(P_i)$ points $x\\in P_i$ with repetitions from $P_i$, picking every point $x$ with probability $\\lambda_t(x)/\\lambda_t(P_i)$ and adds them to the set of centers $C_t$. We assume that points in every set $C_t$ are ordered in the same way as they were chosen by this algorithm.\n\nWe claim that the distribution of the output sets $C_T$ of this algorithm is exactly the same as in the original $k$-means$\\kpp$ algorithm. Therefore, we can analyze the modified algorithm instead of $k$-means$\\kpp$, using the framework described in\nSections~\\ref{sec:framework}.\n\n\\begin{lemma}~\\label{lem:kmpp}\nThe sets $C_t$ in the original and modified $k$-means$\\kpp$ algorithms are identically distributed.\n\\end{lemma}\n\\begin{proof}  Consider $|P_i|$ independent Poisson point processes $N_x(a)$ with rates $\\lambda_t(x)$, where $x\\in P_i$ (here, we use variable $a$ for time). Suppose we add a center $x$ at step $t$ of the algorithm if $N_x(t)\\geq 1$. On the one hand, the probability that we choose $x$ is equal to $1-e^{-\\lambda_t(x)}$ which is exactly the probability that $k$-means\\kpp\\; picks $x$ as a center at step $t$. On the other hand, the sum  $N_{P_i}= \\sum_{x\\in P_i} N_x$ is a Poisson point process with rate $\\lambda_t(P_i)$. Thus, the total number of jumps in the interval $[0,1]$ of processes $N_x$ with $x\\in P_i$ is distributed as $Z_t(P_i)$. Moreover, the probability that $N_x$ jumps at time $a$ conditioned on the event that $N_{P_i}$ jumps at time $a$ is $\\lambda_t(x)/\\lambda_t(P_i)$. Thus, for every jump of $N_{P_i}$, we choose one random center $x$ with probability $\\lambda_t(x)/\\lambda_t(P_i)$.\n\\end{proof}\n\n\\begin{lemma}~\\label{lem:parallel_1}\nFor $k$-means$\\parallel$  algorithm with parameter $\\ell$, the\nfollowing  bounds hold:\n\\begin{align*}\n    \\text{for $\\ell < k$, }\\qquad  \\expect{\\cost_{t+1}(\\total) } &\\leq e^{-\\frac{\\ell}{k}} \\cdot \\expect{\\cost_t(\\total)} + 5\\opt_k(\\pointset);\n    \\\\\\text{for $\\ell \\geq k$, }\\qquad \\expect{\\cost_{t+1}(\\total) } &\\leq \\rbr{\\frac{k}{e\\ell}} \\cdot \\expect{\\cost_t(\\total)} + 5\\opt_k(\\pointset).\n\\end{align*}\n\\end{lemma}\n\n\\begin{proof}\n\nSince the expected cost returned by $k$-means$\\parallel$ is at most the expected cost returned by $k$-means$\\kpp$, we analyze the expected cost of the clustering after one step of $k$-means\\kpp.\n\nIf the algorithm covers cluster $P_i$ at round $t$, then at the next round, its uncovered cost equals $0$. The number of centers chosen in $P_i$ is determined by the Poisson random variable $Z_{t+1}(P_i)$. Hence, $P_i$ is uncovered at round $t+1$ only if $Z_{t+1}(P_i)=0$. Since $U_t(\\cluster_i)$ is non-increasing in $t$ and $U_t(\\cluster_i) \\leq \\cost_t(\\cluster_i)$, we have\n\\begin{align*}\n    \\expect{U_{t+1}(P_i) \\mid \\centerset_t} \\leq  \\prob{Z_{t+1}(\\cluster_i) = 0} U_t(\\cluster_i) \\leq \\exp\\rbr{- \\frac{\\ell\\, \\cost_t(\\cluster_i)}{\\cost_t(\\total)}} \\cost_t(\\cluster_i).\n\\end{align*}\nDefine two function: $f(x) = e^{-x}\\cdot x$; and $g(x) = f(x)$ for $x \\in [0,1]$ and\n$g(x) =e^{-1}$ for $x \\in [1,\\infty)$. Then,\n\\[ \\expect{U_{t+1}(\\pointset) \\mid \\centerset_t} \\leq \\rbr{\\frac{1}{k}\\sum_{i=1}^k f\\rbr{\\frac{\\ell \\cost_t(\\cluster_i)}{\\cost_t(\\pointset)}}} \\frac{k\\cost_t(\\pointset)}{\\ell}. \\]\nSince $g(x)\\leq f(x)$, and $g(x)$ is concave for $x\\geq 0$, we have\n\\begin{align*}\n    \\expect{U_{t+1}(\\pointset) \\mid \\centerset_t}\n    \\leq \\rbr{\\frac{1}{k} \\sum_{i=1}^k g\\rbr{\\frac{\\ell\\; \\cost_t(\\cluster_i)}{\\cost_t(\\pointset)}}} \\frac{k\\cost_t(\\pointset)}{\\ell} \\leq g\\rbr{\\frac{\\ell}{k}} \\frac{k \\cost_t(\\pointset)}{\\ell}.\n\\end{align*}\nHere, we use that $\\sum_i \\cost_t(P_i) = \\cost_t(\\pointset)$.\n\nTherefore, for $ \\ell \\leq k$, we have\n$$\n    \\expect{U_{t+1}(\\pointset) \\mid \\centerset_t} \\leq \\rbr{e^{-\\frac{\\ell}{k}}} \\cost_t(\\pointset);\n$$\nand for $\\ell \\geq k$, we have\n$$\n    \\expect{U_{t+1}(\\pointset) \\mid \\centerset_t} \\leq \\rbr{\\frac{k}{e\\ell}} \\cost_t(\\pointset).\n$$\n\nSimilar to Corollary~\\ref{cor:5opt-martingale}, the process $\\HH_t(P)$ for $k$-means$\\kpp$ is also a supermartingale, which implies $\\expect{H_{t+1}(\\pointset) } \\leq 5\\opt_k(\\pointset)$.\nThis concludes the proof.\n\\end{proof}\n\n\\begin{proof}[Proof of Theorem~\\ref{thm:kpp_main}]\nApplying the bound from Lemma~\\ref{lem:parallel_1} for $t$ times, we get the following results. For $\\ell \\leq k$,\n$$\n    \\expect{\\cost_{t+1}(\\total)} \\leq \\rbr{e^{-\\frac{\\ell}{k}}}^t \\expect{\\cost_1(\\total)} + 5 \\opt_k(\\pointset) \\eta_t,\n$$\nwhere\n$\n    \\eta_t = \\sum_{j=1}^{t} \\rbr{e^{-\\frac{\\ell}{k}}}^{j-1} < \\frac{1}{1-e^{-\\frac{\\ell}{k}}}.\n$ For $\\ell \\geq k$,\n$$\n    \\expect{\\cost_{t+1}(\\total)} \\leq \\rbr{\\frac{k}{e\\ell}}^t \\expect{\\cost_1(\\total)} + 5 \\opt_k(\\pointset) \\eta_t,\n$$\nwhere\n$\n    \\eta_t = \\sum_{j=1}^{t} \\rbr{\\frac{k}{e\\ell}}^{j-1} \\leq \\frac{1}{1-\\frac{k}{e\\ell}}.\n$\n\\end{proof}\n\n\\begin{corollary}~\\label{cor:kpp_9opt}\nConsider a data set $\\pointset$ with more than $k$ distinct points. Let\n$$T = \\ln\\E\\bigg[\\frac{\\cost_1(\\total)}\n{\\opt_k(\\pointset))}\\bigg]$$\nand $\\ell > k$. Then, after $T$ rounds of $k$-means$\\parallel$, the expected cost of clustering $\\expect{\\cost_T(\\total)}$ is at most $9\\opt_k(\\pointset)$.\n\\end{corollary} \\section{\\texorpdfstring{Exponential Race $k$-means++ and Reservoir Sampling}{Exponential Race k-means++ and Reservoir Sampling}}\\label{sec:pois-kmeans-pp}\n\nIn this section, we show how to implement $k$-means++\nalgorithm in parallel using $R$ passes over the data set. This implementation, which we refer to as $k$-means$\\kpois$ (exponential race $k$-means++), is very similar to $k$-means$\\parallel$, but has stronger theoretical guarantees. Like $k$-means$\\parallel$, in every round,\n$k$-means$\\kpois$ tentatively selects $\\ell$ centers, in expectation. However, in the same round, it removes some of the just selected centers (without making another pass over the data set). Consequently, by the end of each iteration, the algorithm keeps at most $k$ centers.\n\nWe can run $k$-means$\\kpois$ till it samples exactly\n$k$ centers; in which case, the distribution of\n$k$ sampled centers is identical to the distribution of the regular $k$-means++, and the expected number of rounds or\npasses over the data set $R$ is upper bounded by\n$$O\\bigg(\\frac{k}{\\ell}+ \\log\\frac{\\OPT_1(\\pointset)}{\\OPT_k(\\pointset)}\\bigg).$$\nWe note that $R$ is never greater than $k$. We can also run this algorithm for at most $R^*$ rounds. Then, the expected cost of the clustering is at most\n$$\n5 (\\ln k + 2) \\OPT_k(\\pointset) +\n5R^*\\bigg(\\frac{4k}{e\\ell R^*}\\bigg)^{R^*}\\cdot \\OPT_1(\\pointset).\n$$\n\n\\subsection{Algorithm}\nIn this section, we give a high level description of our $k$-means$\\kpois$ algorithm. In Section~\\ref{sec:lazy}, we show how to efficiently implement $k$-means$\\kpois$ using lazy updates and explain why our algorithm makes $R$ passes over the data set.\n\nThe algorithm simulates $n$ continuous-time stochastic processes. Each stochastic process is associated with one of the points in the data set. We denote the process corresponding to $x\\in \\pointset$ by $P_t(x)$. Stochastic process $P_t(x)$ is a Poisson process with variable arrival rate $\\lambda_t(x)$.\n\nThe algorithm  chooses the first center $c_1$ uniformly at random in $\\pointset$ and sets the arrival rate of each process $P_t(x)$ to be $\\lambda_t(x)=\\cost(x,\\{c_1\\})$. Then, it waits till one of the Poisson processes $P_t(x)$ jumps. When process $P_t(x)$ jumps, the algorithm adds the point $x\\in\\pointset$ (corresponding to that process) to the set of centers $C_t$ and updates the arrival rates of all processes to be\n$$\\lambda_t(y)=\\cost(y,C_t)$$\nfor all $y\\in \\pointset$. Note that if $y$ is a center, then the arrival rate  $\\lambda_t(y)$ is $0$.\n\nThe algorithm also maintains a round counter $R$. In the lazy version of this algorithm (which we describe in the next section), the algorithm makes a pass over the data set and samples a new batch of centers every time this counter is incremented. Additionally, at the end of each round, the algorithm checks if it chose at least one center in that round, and in the unlikely event that it did not, it selects one center with probability proportional to the costs of the points.\n\nInitially, the algorithm sets $R=0$, $t_0 = 0$, and $t_1 =\\ell/\\cost(\\pointset,\\{c_1\\})$. Then, at each time point $t_i$ ($i \\geq 1$), we increment $R$ and compute\n$$t_{i+1}= t_i + \\ell / \\cost(\\pointset,C_{t_i}),$$\nwhere $C_{t_i}$ is the set of all centers selected before time $t_i$. We refer to the time frame\n$[t_{i-1},t_{i}]$ for $i\\geq 1$ as the $i$-th round. The algorithm stops when one of the following conditions holds true (1)~the number of sampled centers is $k$; or (2) the round counter $R$ equals the prespecified threshold\n$R^*$, which may be finite or infinite.\n\nBefore analyzing this algorithm, we mention that every Poisson process $P_t$ with a variable arrival rate $\\lambda_t$ can be coupled with a Poisson process $Q_s$ with rate $1$. To this end, we substitute the variable\n$$s(t) = \\int_0^t \\lambda_{\\tau}d\\tau,$$\nand let\n$$P_t \\equiv Q_{s(t)}.$$\nObserve that the expected number of arrivals for process $Q_s$ in the infinitesimal interval\n$[s,s+ds]$ is $ds = \\lambda_{t}dt$ which is exactly the same as for process $P_t$.\n\nIt is convenient to think about the variables $s$ as ``current position'', $t$ as ``current time'', and $\\lambda_{t}$ as ``current speed'' of $s$. To generate process $P_t(x)$, we can first generate Poisson process $Q_s(x)$ with arrival rate $1$ and then move the position $s_t(x)$ with speed $\\lambda_t(x)$. The process $P_t(x) = Q_{s_t(x)}(x)$ is a Poisson process with variable arrival rate $\\lambda_t(x)$.\n\n\\medskip\n\n\\begin{theorem}\\label{thm:main-poisson-kpp}\nI. If the number of rounds is not bounded (i.e., $R^*=\\infty$), then the distribution of centers returned by $k$-means$\\kpois$ is identical to the distribution of centers returned by $k$-means++.\n\nII. Moreover, the expected number of rounds $R$ is upper bounded by\n$$(1+o_k(1))\\cdot\\bigg(\\ceil{\\frac{k}{\\ell}} + \\log\\frac{2\\OPT_1(\\pointset)}{\\OPT_k(\\pointset)} \\bigg),$$\nand never exceeds $k$.\n\nIII. If the threshold $R^*$ is given ($R^*<\\infty$), then the cost of the solution after $R^*$ rounds is upper bounded by\n$$\n5 (\\ln k + 2) \\OPT_k(\\pointset) + 2 R^{*}\n\\bigg(\\frac{4k}{e\\ell R^*}\\bigg)^{R^*}\\cdot \\OPT_1(\\pointset).\n$$\n\\end{theorem}\n\\begin{proof}[Proof of Part I]\nFor the sake of analysis, we assume that after the algorithm outputs solution $C$, it does not terminate, but instead continues to simulate Poisson processes $P_t(x)$.\nIt also continues to update the set $C_t$ (but, of course, not the solution) and the arrival rates $\\lambda_t(x)$ till the set $C_t$ contains $k$ centers. Once $|C_t|=k$, the algorithm stops updating the set of centers $C_t$ and arrival rates but still simulates\ncontinuous-time processes $P_t(x)$. Clearly, this additional phase of the algorithm does not affect the solution since it starts after the solution is already returned to the user.\n\nWe prove by induction on $i$ that the first $i$ centers $c_1,\\dots,c_i$ have exactly the same joint distribution as in $k$-means++. Indeed, the first center $c_1$ is drawn uniformly at random from the data set $\\pointset$ as in $k$-means++. Suppose centers $c_1,\\dots,c_i$ are already selected. Then, we choose the next center $c_{i+1}$ at the time of the next jump of one of the Poisson processes $P_t(x)$.\nObserve that the conditional probability that a particular process $P_t(x)$ jumps given that one of the processes $P_t(y)$ ($y\\in \\pointset$) jumps is proportional to $\\lambda_t(x)$, which in turn equals the current $\\cost(x,C_t)$ of point $x$. Hence, the distribution of center $c_{i+1}$ is the same as in $k$-means++. This completes the proof of item I.\n\\end{proof}\n\\begin{proof}[Proof of Part II]\nWe now show items II and III. Define process\n$$P_t(\\pointset)=\\sum_{x\\in \\pointset} P_t(x).$$\nIts rate $\\lambda_t(\\pointset)$ equals $\\sum_{x\\in \\pointset} \\lambda_t(x)$. We couple this process\nwith a Poisson $Q_s(\\pointset)$ with arrival rate $1$ as discussed above. We want to estimate the number of centers chosen by the algorithm in the first $R'$ rounds. To this end, we count the number of jumps of the Poisson process $P_t(\\pointset)$ (recall that we add a new center to $C_t$ whenever $P_t(\\pointset)$ jumps unless $|C_t|$ already contains $k$ centers). The number of jumps equals $P_{t_{R'}}$ which, in turn, equals $Q_{s_{R'}}$ where $s_{R'}(\\pointset)$ is the position of $s(\\pointset)$\nat time $t_{R'}$:\n$$\ns_{R'}(\\pointset) = \\int_{0}^{t_{R'}} \\lambda_{\\tau}(\\pointset)\\; d\\tau =\n\\sum_{i=0}^{R'-1}\\int_{t_i}^{t_{i+1}}\n\\lambda_{\\tau}(\\pointset) \\;d\\tau \\geq\n\\sum_{i=0}^{R'-1} (t_{i+1}-t_i)\\cdot \\lambda_{t_{i+1}}(\\pointset).\n$$\nHere, we used that $\\lambda_{t}(\\pointset)$ is non-increasing, and thus,\n$\\lambda_{t_{i+1}}(\\pointset)\\leq \\lambda_{\\tau}(\\pointset)$ for all $\\tau \\in [t_i,t_{i+1}]$. We now recall that $(t_{i+1}-t_i)= \\ell / \\cost(\\pointset, C_{t_i})$ and\n$\\lambda_{t_{i+1}}(\\pointset) = \\cost(\\pointset, C_{t_{i+1}})$. Hence,\n$$\ns_{R'}(\\pointset) \\geq \\ell \\sum_{i=0}^{R'-1} \\frac{\\cost(\\pointset, C_{t_{i+1}})}{\\cost(\\pointset, C_{t_{i}})}.\n$$\nBy the inequality of arithmetic and geometric means, we have\n\\begin{align}\n\\label{eq:sR}\ns_{R'}(\\pointset) &\\geq \\ell \\cdot R' \\Bigg(\\prod_{i=0}^{R'-1} \\frac{\\cost(\\pointset, C_{t_{i+1}})}{\\cost(\\pointset, C_{t_{i}})}\\Bigg)^{\\nicefrac{1}{R'}} =\n\\ell \\cdot R' \\Bigg(\\frac{\\cost(\\pointset, C_{t_{R'}})}{\\cost(\\pointset, C_{t_{0}})}\\Bigg)^{\\nicefrac{1}{R'}}\n\\\\\n\\nonumber\n&=\n\\ell \\cdot R' \\Bigg(\\frac{\\cost(\\pointset, C_{t_{R'}})}{\\cost(\\pointset, \\{c_1\\})}\\Bigg)^{\\nicefrac{1}{R'}}.\n\\end{align}\n\nWe now use this equation to prove items II and III. For item II, we\nlet random variable $R'$ to be\n$$R'= 2e\\ceil{k/\\ell} +\n\\log \\frac{\\cost(\\pointset, \\{c_1\\})}{\\OPT_k(\\pointset)}.$$\nNote that $R'$ depends on the first center $c_1$ (which is chosen in the very beginning of the algorithm) but not on the\nPoisson processes $P_t(x)$. Since, $C_t$ always contains at most $k$ centers, we have $\\cost(x, C_{t_{R'}})\\geq \\OPT_k(\\pointset)$, and consequently\n$$s_{R'}(\\pointset) \\geq\n\\ell \\cdot R' \\Bigg(\\frac{\\OPT_k(\\pointset)}{\\cost(\\pointset, \\{c_1\\})}\\Bigg)^{\\nicefrac{1}{R'}}>\n\\ell \\cdot 2e\\ceil{k/\\ell} \\cdot \\nicefrac{1}{e}\n\\geq 2k.$$\nThe expected number of jumps of the Poisson process $Q_{s}(\\pointset)$ in the interval $[0,s_{R'}(\\pointset)]$ equals $Q_{s_R(\\pointset)}(\\pointset)$. Observe that\n$$Q_{s_R(\\pointset)}(\\pointset)\\geq Q_{2k}(\\pointset)$$\nand $Q_{2k}(\\pointset)$ is a Poisson random variable with\nparameter $2k$. By the Chernoff bound%\n\\footnote{We use the bound $\\Pr\\{P \\leq k\\}\\leq e^{-\\lambda}\\big(e\\lambda/k\\big)^k$, where $P$ is a Poisson random variable with parameter $\\lambda$ and $k< \\lambda$. See e.g., Theorem 5.4.2 in~\\citet{MU-Book}.},\nit makes fewer than $k$ jumps with exponentially small probability in $k$; namely, with probability at most $(e/2)^{-k}$. Thus, with probability at least $1 - (e/2)^{-k}$, the algorithm selects $k$ centers in the first $R'$ rounds. Moreover, if it does not happen in the first $R^*$ rounds, then it selects $k$ centers by the end of the second $R'$ rounds again with  probability at least $1 - (e/2)^{-k}$ and so on. Hence, the expected number of rounds till it selects $k$ centers is $(1+o_k(1))R'$. Finally, observe that the expectation of $\\cost(\\pointset, \\{c_1\\})$ over the choice of the first center equals $2\\OPT_k(\\pointset)$. Since $\\log(\\cdot)$ is a convex function, we have\n$$\\E[R']\\leq 2e\\ceil{k/\\ell} +\n\\log \\frac{2\\OPT_1(\\pointset)}{\\OPT_k(\\pointset)}.$$\nTherefore, we showed that the expected number of rounds is upper bounded by\nthe right hand side of the expression above times a multiplicative factor\nof $(1+o_k(1))$. A slightly more careful analysis gives a bound of\n$$(1+o_k(1))\\Bigg(e\\ceil{k/\\ell} +\n\\log \\frac{2\\OPT_1(\\pointset)}{\\OPT_k(\\pointset)}\\Bigg).$$\nThis concludes the proof of item II.\n\\end{proof}\n\\begin{proof}[Proof of Part III]\nWe now prove item III. Denote $T = t_{R^*}$.\nConsider the event\n$$\n\\mathcal{E} = \\big\\{\\text{algorithm samples $k$ centers in the first $R^*$ rounds}\\big\\}.\n$$\nLet $\\bar{\\calE}$ be the complimentary events to $\\calE$.\nThen,\n$$\n\\E\\big[\\cost(\\pointset, C_T)\\big]\n=\n\\E\\big[\\cost(\\pointset, C_T) \\cdot \\one(\\calE)\\big] +\n\\E\\big[\\cost(\\pointset, C_T) \\cdot \\one(\\bar{\\calE})\\big].\n$$\nWe now separately upper bound each of the terms on the right hand side. It is easy to upper bound the first term:\n$$\\E[\\cost(\\pointset, C_{T}) \\cdot \\one(\\calE)]\\leq 5(\\ln k +2)\\cdot \\OPT_k(\\pointset),$$\nbecause the distribution of centers returned by\n$k$-means$\\kpois$ is identical to the distribution of centers\nreturned by $k$-means++. We now bound the second term.\nDenote by $\\calD_{\\rho}$ the event\n$$\n\\calD_{\\rho} = \\bigg\\{\\cost(\\pointset, C_T)\\geq \\Big(\\frac{\\rho k}{\\ell R^*}\\Big)^{R^*} \\cost(\\pointset, \\{c_1\\})\\bigg\\}.\n$$\n\nWe prove the following claim.\n\\begin{claim}\\label{cl:prob-more-rho}\nThe following inequality holds for every real number $\\rho\\in[1,\\ell R^*/k]$ and any choice of the first center $c_1$:\n$$\\Pr\\big(\\bar\\calE \\text{ and } \\calD_{\\rho}\\mid c_1\\big)\n\\leq e^{-(\\rho -1) k}\\rho^{k-1}.$$\n\\end{claim}\n\\begin{proof}\nWe use inequality (\\ref{eq:sR}) with\n$R'= R^*$:\n$$s_{R^*}(\\pointset) \\geq \\ell \\cdot R^* \\Bigg(\\frac{\\cost(\\pointset, C_T)}{\\cost(\\pointset, \\{c_1\\})}\\Bigg)^{\\nicefrac{1}{R^*}}.$$\nIt implies that $s_{R^*}(\\pointset)\\geq \\rho k$ if event $\\calD_{\\rho}$ occurs. On the other hand if $\\bar \\calE$ occurs, then the number of centers chosen by the end of round $R^*$ is less than $k$ and,\nconsequently, the number of jumps of $P_t({\\pointset})$ in the interval $[0,T]$ is less than $k$:\n$$P_T({\\pointset}) \\equiv Q_{s_{R^*}(\\pointset)}(\\pointset) < k.$$\nHence, we can bound $\\Pr(\\bar \\calE \\text { and } \\calD_{\\rho}\\mid c_1)$ as follows:\n\\begin{multline*}\n\\Pr(\\bar \\calE \\text { and } \\calD_{\\rho}) \\leq\n\\Pr\\big(\\calD_{\\rho} \\text{ and } Q_{s_{R^*}}(\\pointset)<\nk\\mid c_1\\big) \\leq\n\\\\ \\leq\n\\Pr\\big(\\calD_{\\rho} \\text{ and } Q_{\\rho k}(\\pointset)< k\n\\mid c_1 \\big)\n\\leq\n\\Pr\\big(Q_{\\rho k}(\\pointset)< k \\mid c_1\\big).\n\\end{multline*}\nRandom variable $Q_{\\rho k}(\\pointset)$ has the Poisson distribution with parameter $\\rho k$ and is independent of $c_1$. By the Chernoff bound, the probability that $Q_{\\rho k}(\\pointset)\\leq k-1$ is at most (as in Part II of the proof):\n$$\\Pr\\big\\{Q_{\\rho k}(\\pointset)\\leq k-1\\big\\}\\leq\ne^{-\\rho k}\\Big(\\frac{e \\rho k}{k-1}\\Big)^{k-1} =\ne^{-(\\rho -1) k-1}\\rho^{k-1}\\cdot \n\\underbrace{\\bigg(\\frac{k}{k-1}\\bigg)^{k-1}}_{\\leq e}\n\\leq e^{-(\\rho -1) k}\\rho^{k-1}.\n$$\nThis completes the proof of Claim~\\ref{cl:prob-more-rho}.\n\\end{proof}\n\nLet\n$$Z=\\bigg(\\frac{\\ell R^*}{k}\\bigg)^{R^*}\\cdot \\frac{\\cost(\\pointset, C_T)}{\\cost(\\pointset,\\{c_1\\} )}.$$\nThen, by Claim~\\ref{cl:prob-more-rho},\n\\begin{equation}\\label{eq:prob-DZ}\n\\Pr\\big(\\bar\\calE \\text{ and } Z\\geq \\rho^{R^*} \\mid c_1\\big)\\leq\ne^{-(\\rho-1)k}\\rho^{k-1}. \n\\end{equation}\nWrite,\n$$\\E\\big[\\one(\\bar \\calE) \\cdot Z \\mid c_1\\big] =\n\\int_{0}^{\\infty} \\Pr\\big(\\one(\\bar \\calE) \\text{ and } Z\\geq r \\mid c_1\\big) dr\n\\leq 1 + \\int_{1}^{\\infty} \\Pr\\big(\\one(\\bar \\calE) \\text{ and } Z\\geq r \\mid c_1\\big)\\,dr.\n$$\nWe now substitute $r=\\rho^{R^*}$ and then use~(\\ref{eq:prob-DZ}):\n\\begin{align*}\n\\E\\big[Z \\cdot \\one(\\bar \\calE) \\mid c_1\\big] &\\leq 1 +\nR^*\\int_{1}^{\\infty} \\Pr\\big(\\bar\\calE \\text{ and } Z\\geq \\rho^{R^*} \\mid c_1\\big)\n\\cdot \\rho^{R^*-1}\nd\\rho\\\\\n&\\leq 1 + R^* \\int_{1}^{\\infty}\ne^{-(\\rho-1)k}\\rho^{k + R^* -2} d\\rho.\n\\end{align*}\n\nWe note that $R^*< k$, since our algorithm chooses at least one center in each round. Thus, by Lemma~\\ref{lem:rho-integral} (which we prove below), the integral on the right hand side is upper bounded by\n$\\nicefrac{eR^*}{2} \\cdot (\\nicefrac{4}{e})^{R^*}$.\nHence,\n$$\\E\\big[Z \\cdot \\one(\\bar \\calE) \\mid c_1\\big]\\leq 1+\nR^* \\cdot \\bigg(\\frac{4}{e}\\bigg)^{R^*-2}.\n$$\nMultiplying both sides of the inequality by $(\\nicefrac{k}{\\ell R^*})^{R^*}\\cdot\n{\\cost(\\pointset,\\{c_1\\})}$ and taking the expectation over $c_1$, we get the desired inequality:\n\\begin{align*}\n\\E\\big[\\cost(\\pointset, C_T) \\cdot \\one(\\bar{\\calE})\\big] &\\leq\n\\bigg(1 + R^*\\; \\bigg(\\frac{4}{e}\\bigg)^{R^*}\\bigg)\n\\Big(\\frac{k}{\\ell R^*}\\Big)^{R^*}\n\\E_{c_1}\\big[\\cost(\\pointset,\\{c_1\\}\\big]\\\\\n&=\\bigg(1 + R^* \\; \\Big(\\frac{4}{e}\\Big)^{R^*-2}\\bigg)\n\\Big(\\frac{k}{\\ell R^*}\\Big)^{R^*}\n\\cdot 2\\OPT_1(\\pointset)\n\\\\\n&<2R^* \\; \\bigg(\\frac{4k}{e\\ell R^*}\\bigg)^{R^*}\\OPT_1(\\pointset).\n\\end{align*}\n\nThis finishes the proof of Theorem~\\ref{thm:main-poisson-kpp}.\n\\end{proof}\n\n\\begin{lemma}\\label{lem:rho-integral}\nFor $R^*< k$, we have\n$$\\int_{1}^{\\infty}\ne^{-(\\rho-1)k}\\rho^{k + R^* -2} d\\rho\\leq\n\\frac{e}{2}\\bigg(\\frac{4}{e}\\bigg)^{R^*}.$$\n\\end{lemma}\n\\begin{proof}\nSince $e^{-(\\rho-1)}\\rho\\leq 1$ for all $\\rho \\geq 1$, we have\n$e^{-(\\rho-1)k}\\rho^{k} \\leq e^{-(\\rho-1)R^*}\\rho^{R^*}$ for any $R^* < k$.\nThus, we have\n\\begin{align*}\n\\int_{1}^{\\infty}\ne^{-(\\rho-1)k}\\rho^{k + R^* -2} d\\rho &\\leq\n\\int_{1}^{\\infty}\ne^{-(\\rho-1)R^*}\\rho^{2R^* -3} d\\rho\n= e^{R^*}\\int_{1}^{\\infty}\ne^{-\\rho R^*}\\rho^{2R^* - 3} d\\rho\\\\\n&= e^{R^*}\\int_{1}^{\\infty}\n(e^{-\\rho}\\rho^{2})^{R^*} \\rho^{-3} d\\rho.\n\\end{align*}\nObserve that $e^{-\\rho}\\rho^2 \\leq 4/e^2$ for any $\\rho \\geq 1$. Hence,\n$$(e^{-\\rho}\\rho^{2})^{R^*}\n=\n(e^{-\\rho}\\rho^{2})^{R^*-1}\\cdot e^{-\\rho}\\rho^{2}\n\\leq (4/e^2)^{R^*-1}e^{-\\rho}\\rho^{2}.$$\nThus,\n$$\\int_{1}^{\\infty}\ne^{-(\\rho-1)k}\\rho^{k + R^* -2} d\\rho \\leq\n\\frac{4^{R^*-1}\\cdot e^{R^*}}{e^{2(R^*-1)}}\\cdot\n\\int_1^{\\infty}\\frac{e^{-\\rho}}{\\rho} \\; d\\rho =\n\\frac{4^{R^*-1}}{e^{R^*-2}}\n\\cdot \\frac{1}{4} = \\bigg(\\frac{4}{e}\\bigg)^{R^*-2}.\n$$\n\\end{proof}\n\n\\subsection{\\texorpdfstring{Lazy implementation of $k$-means$\\kpois$}{Lazy implementation of Exponential Race k-means++}}\\label{sec:lazy}\n\nWe now describe how we can efficiently implement\nthe $k$-means$\\kpois$ algorithm using a lazy reservoir sampling.  We remind the reader that the time of the first jump of a Poisson process with parameter $\\lambda$ is distributed as the exponential distribution with parameter $\\lambda$. Imagine for a moment, that the arrival rates of our Poisson processes were constant. Then, in order to select the first $k$ jumps, we would generate independent exponential random variables with parameters $\\lambda(x)$ for all $x$ and choose $k$ smallest values among them. This algorithm is known as the reservoir sampling(see~\\citet{ReservoirSampling}). To adapt this algorithm to our needs, we need to update the arrival rates of the exponential random variables. Loosely speaking, we do so by generating exponential random variables with rate $1$ for Poisson processes $Q_s(x)$ which are described above and then updating the speeds $\\lambda_t(x)$ of variables $s_t(x)$. We now formally describe the algorithm.\n\nIn the beginning of every round $i$, we recompute costs of all points in the data set. Then, we draw an independent exponential random variable $\\mathcal{S}_x$ with rate $1$ for every point $x$, and let $S_t(x)=\\mathcal{S}_x$ . We set\n$$\\tau_t(x)=\\frac{S_t(x)}{\\lambda_t(x)}.$$\nThink of $S_t(x)$ as the distance $s_t(x)$ needs to travel till process $Q_s(x)$ jumps; $\\lambda_t(x)$ is the speed of point~$s_t(x)$; and $\\tau_t(x)$ is the time left till $Q_s(x)=P_t(x)$\njumps if the speed $\\lambda_t$ does not change. Among all points $x\\in X$, we select a tentative set of centers $Z$ for this round. The set $Z$ contains all points $x$\nwith $t_{i-1} + \\tau_t(x)\\leq t_{i}$. This is the set of all points for which their Poisson processes would jump in the current round if their arrival rates remained the same till the end of the round. Since the arrival rates can only decrease in our algorithm, we  know for sure that for points $x$ outside of $Z$, the corresponding processes $P_t(x)$ will not jump in this round. Thus, we can safely ignore those points during the current round.\n\nWe also note that in the unlikely event that the initial set $Z$ is empty, we choose $x$ with the smallest time $\\tau_t(x)$ and add it to the set of centers $C_t$. (This is equivalent to choosing a point with probability proportional to $\\cost(x,C_t)$ by the memorylessness property of the exponential distribution).\n\nThe steps we described above -- updating costs $\\cost(x,C_t)$, drawing exponential random variables $\\mathcal{S}_x$, and selecting points in the set $Z$ -- can be performed in parallel using one pass over the data set. In the rest of the current round, our algorithm deals only with the set $Z$ whose size in expectation is at most $\\ell$ (see below).\n\nWhile the set $Z$ is not empty we do the following. We choose $x\\in Z$ with the smallest value of $\\tau_t(x)$. This $x$ corresponds to the process that jumps first.\nThen, we perform the following updates: We add $x$ to the set of centers $C_t$. We set the ``current time'' $t$ to $t = t' + \\tau_{t'}(x)$, where $t'$ is the time of the previous update. If $x$ is the first center selected in the current round, then we let $t'$ to be the time when the round started (i.e., $t_{i-1}$). We recompute the arrival rates (speeds) $\\lambda_t(x)$ for each $x$ in $Z$. Finally, we update the values of all $\\tau_t(x)$ for $x\\in Z$ using the formula\n$$\\tau_t(x) =\n\\frac{S_t(x)-\\lambda_{t'}(x)\\cdot(t-t')}{\\lambda_t(x)},$$\nhere $\\lambda_{t'}(x)\\cdot(t-t')$ is the distance variable $s_t(x)$ moved from the position where it was at time~$t'$; $S_t(x)-\\lambda_{t'}(x)\\cdot(t-t')$ is the remaining distance $s_t(x)$ needs to travel till the process $Q_t(x)$ jumps; and $\\tau_t(x)$ is the remaining\ntime till $P_t(x)$ jumps if we do not update its arrival rate. After we update $\\tau_t(x)$, we prune the set $Z$. Specifically, we remove from set $Z$ all points $x$ with\n$t+\\tau_t(x) > t_{i}$. As before, we know for sure that if $x$ is removed from $Z$, then the corresponding  processes $P_t(x)$ will not jump in the current round.\n\nThis algorithm simulates the process we described in the previous section. The key observation is that Poisson processes $P_t(x)$ we associate with points $x$ removed from $Z$ cannot jump\nin this round and thus can be safely removed from our consideration. We now show that the expected size of the set $Z$ is at most $\\ell$. In the next section, we analyze the running time of this algorithm.\n\n\\medskip\n\nThen we show that the expected size of the set $Z$ in the beginning of each round $i+1$ is at most $\\ell$. Since every point $x$ belongs to $Z$ with probability\n$$\\Pr\\{x\\in Z\\} =\n\\Pr\\bigg\\{\\ \\frac{\\mathcal{S}_x}{\\cost(x,C_{t_i})}\n\\leq \\frac{\\ell}{\\cost(\\pointset, C_{t_i})} \\bigg\\} =\n\\Pr\\bigg\\{\\ \\mathcal{S}_x\n\\leq \\ell \\cdot \\frac{\\cost(x,C_{t_i})}{\\cost(\\pointset, C_{t_i})}\\bigg\\}.$$\nThe right hand side is the probability that the Poisson  process $Q_s(x)$ with rate 1 jumps in the interval\nof length $\\ell \\cdot \\cost(x,C_{t_i})/\\cost(\\pointset, C_{t_i})$ which is upper bounded by the expected number of jumps of $Q_s(x)$ in this interval. The expected number of jumps exactly equals $\\ell \\cdot \\cost(x,C_{t_i})/\\cost(\\pointset, C_{t_i})$. Thus, the expected size of $Z$ is upper bounded as\n$$\\E|Z| = \\sum_{z\\in \\pointset}\n\\Pr\\{z\\in Z\\} \\leq \\sum_{z \\in \\pointset} \\ell \\cdot \\frac{\\cost(z,C_{t_i})}{\\cost(\\pointset, C_{t_i})} = \\ell.$$\n\\subsection{Run time analysis}\nAccording to our analysis above, the number of new centers chosen at each round of $k$-means$\\kpois$ is at most the size of set $Z$, which is $O(\\ell)$ with high probability. In the beginning of every round, we need to update costs of all data points, which requires $O(n\\ell d)$ time. In each round, we also need to maintain the rates of all points in set $Z$, which needs $O(\\ell^2 d)$ time. Thus, the total running time for $k$-means$\\kpois$ with $R$ rounds is $O(Rn\\ell d)$. We note that before running our algorithm, we can reduce the dimension $d$ of the space to $O(\\log k)$ using the Johnson\u2013Lindenstrauss transform (see~\\citet{JLpaper}). This will increase the approximation factor by a factor of $(1+\\varepsilon)$ but make the algorithm considerably faster (see~\\citet{MMR19},\n\\citet{becchetti2019oblivious}, and \\citet{boutsidis2010random}).\n \n\\bibliographystyle{abbrvnat}\n\\bibliography{references}\n\n%%new page to make room for plots\n\\newpage\n\n\\appendix\n\\section*{\\centering{Appendix}}\n\nIn this appendix, we present our experiments, give proofs omitted in the main part of the paper, and provide complimentary lower bounds.\n\n\\section{Experiments}\\label{sec:experiments}\nIn this section, we present plots that show that the performance of $k$-means$\\parallel$\nand ``$k$-means++ with oversampling and pruning'' algorithms are very similar in practice.\nBelow, we compare the following algorithms on the datasets BioTest from KDD Cup 2004 \\cite{kddcup2004} and COVTYPE from the UCI ML repository \\cite{Dua:2019}:\n\\begin{itemize}\n  \\item Regular $k$-means++. The performance of this algorithm is shown with a solid black line on the plots below.\n  \\item $k$-means$\\parallel$ without pruning. This algorithm samples $k$ centers using $k$-means$\\parallel$ with $T = 5$ rounds and $\\ell = k/T$.\n  \\item $k$-means$\\parallel$. This algorithm first samples $5k$ centers using $k$-means$\\parallel$ and then subsamples $k$ centers using $k$-means++.\n  The performance of this algorithm is shown with a dashed blue line on the plots below.\n  \\item $k$-means++ with oversampling and pruning. This algorithm first samples $5k$ centers using $k$-means++ and then subsamples $k$ centers using $k$-means++. The performance of this algorithm is shown with a thin red line on the plots below.\n\\end{itemize}\n\nFor each $k=5,10,\\cdots, 200$, we ran these algorithms for 50 iterations and took their average. We normalized all costs by dividing them by the cost of $k$-means++ with $k=1000$ centers.\n\n%For each $k=5,10,\\cdots, 200$, we ran these algorithms 50 times each. We then averaged the cost over 50 runs and also computed the minimum cost over 50 runs. We normalized all costs by dividing them by the cost of $k$-means++ with $k=1000$ centers.\n\n\\begin{figure}[h]\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {BioTest},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/bio-test-results.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/bio-test-results.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/bio-test-results.csv}; \\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n        %\\caption{BioTest}\n        %\\label{fig:BioTest}\n    \\end{minipage}\n    \\quad\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {BioTest},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/bio-test10-50.csv}; \\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n        %\\caption{BioTest}\n        %\\label{fig:BioTest}\n    \\end{minipage}\n\\end{figure}\n\n\\begin{figure}\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {COVTYPE},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/covtype.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/covtype.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/covtype.csv};\\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n        %\\caption{COVTYPE}\n        %\\label{fig:CovType}\n    \\end{minipage}\n    \\quad\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {COVTYPE},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/covtype10-50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot[red,domain=1:2, line width = 0.5pt]  table[x=centers,y=avgBicriteria,col sep=comma] {plotdata/covtype10-50.csv}; \\addlegendentry{BiCriteria $k$-means++ w/Pruning}\n        \\addplot [blue, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallel,col sep=comma] {plotdata/covtype10-50.csv};\\addlegendentry{$k$-means$\\parallel$}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n    \\end{minipage}\n\\end{figure}\n\n%%%%%%%%%%%%%%%%%%%%%\n\n\\begin{figure}\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {BioTest},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/biotest_results_kpar_kpp.csv}; \\addlegendentry{$k$-means++}\n        \\addplot [red, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallelForK,col sep=comma] {plotdata/biotest_results_kpar_kpp.csv};\\addlegendentry{$k$-means$\\parallel$ without Pruning}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n    \\end{minipage}\n    \\quad\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {BioTest},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/biotest_results_kpar_kpp_50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot [red, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallelForK,col sep=comma] {plotdata/biotest_results_kpar_kpp_50.csv};\\addlegendentry{$k$-means$\\parallel$ without Prunning}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n    \\end{minipage}\n\\end{figure}\n\n\\begin{figure}\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {COVTYPE},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/covtype_kpar_kpp.csv}; \\addlegendentry{$k$-means++}\n        \\addplot [red, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallelForK,col sep=comma] {plotdata/covtype_kpar_kpp.csv};\\addlegendentry{$k$-means$\\parallel$ without Prunning}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n    \\end{minipage}\n    \\quad\n    \\begin{minipage}{0.45\\linewidth}\n        \\begin{tikzpicture}[scale=0.7]\n        \\begin{axis}[\n        title= {COVTYPE},\n        xlabel={\\#centers},\n        ylabel={cost},\n        grid = major]\n        \\addplot[black,domain=1:2, line width = 1pt]  table[x=centers,y=avgKMeansPP,col sep=comma] {plotdata/covtype_kpar_kpp_50.csv}; \\addlegendentry{$k$-means++}\n        \\addplot [red, domain=1:2, dashed, line width = 1pt] table[x=centers,y=avgKMeansParallelForK,col sep=comma] {plotdata/covtype_kpar_kpp_50.csv};\\addlegendentry{$k$-means$\\parallel$ without Pruning}\n        \\end{axis}\n        \\end{tikzpicture}\n        \\captionsetup{justification=centering}\n    \\end{minipage}\n\\end{figure} \n%%new page to make room for plots\n\\newpage\n\n\\section{Details for Preliminaries}\\label{sec:prelim_details}\nFor any set of points $\\Y \\subset \\R^d$, let $\\mu = \\sum_{x \\in \\Y} x/\\abs{\\Y}$ be the \\textit{centroid} of the cluster $\\Y$. Then, the optimal cost of $\\Y$ with one center,\n\\begin{align*}\n    \\opt_1(\\Y) = \\sum_{x\\in \\Y} \\norm{x-\\mu}^2 = \\frac{\\sum_{(x,y)\\in\\Y\\times\\Y} \\norm{x-y}^2}{2\\abs{\\Y}}.\n\\end{align*}\nThis is a well known formula which is often used for analyzing of $k$-means algorithms. For completeness, we give a proof below.\n\\begin{proof}\nConsider any point $z \\in \\R^d$, then we have:\n\\begin{align*}\n    \\cost(\\Y,\\{z\\}) &= \\sum_{x\\in \\Y} \\norm{x-z}^2 =  \\sum_{x\\in \\Y} \\norm{(x-\\mu) + (\\mu - z)}^2\\\\\n    &= \\sum_{x\\in \\Y} \\rbr{\\norm{x-\\mu}^2 + \\norm{\\mu-z}^2 + 2\\ip{x-\\mu, \\mu-z}}\n    \\\\&= \\sum_{x\\in \\Y} \\norm{x-\\mu}^2 + \\abs{\\Y} \\cdot \\norm{\\mu-z}^2 + 2 \\ip{\\sum_{x\\in \\Y} (x-\\mu), \\mu-z}\n    \\\\&= \\sum_{x\\in \\Y} \\norm{x-\\mu}^2 + \\abs{\\Y} \\cdot \\norm{\\mu-z}^2.\n\\end{align*}\nThus, the optimal choice of $z$ to minimize $\\cost(\\Y,\\{z\\})$ is $\\mu$ and $\\opt_1(\\Y) = \\sum_{x\\in \\Y} \\norm{x-\\mu}^2$.\n\n\\begin{align*}\n    \\sum_{x\\in \\Y} \\norm{x-\\mu}^2 &= \\sum_{x\\in \\Y} \\ip{x-\\mu, x-\\mu}\n    = \\sum_{x\\in \\Y} \\ip{x, x-\\mu}\n    \\\\&= \\sum_{x\\in \\Y} \\ip{x, x - \\sum_{y \\in \\Y} \\frac{y}{\\abs{\\Y}}} =\\frac{1}{\\abs{\\Y}} \\sum_{(x,y)\\in\\Y\\times\\Y} \\ip{x, x - y}\n    \\\\&= \\frac{1}{2\\abs{\\Y}} \\rbr{\\sum_{(x,y)\\in\\Y\\times\\Y} \\ip{x, x - y} + \\sum_{(x,y)\\in\\Y\\times\\Y} \\ip{y, y - x}}\n    \\\\&= \\frac{\\sum_{(x,y)\\in\\Y\\times\\Y} \\norm{x-y}^2}{2\\abs{\\Y}}.\n\\end{align*}\n\\end{proof}\n\n\n\n\n\n\n\n \\section{Lower bounds}\\label{sec:lb}\n\\subsection{Lower bound on the cost of covered clusters}\nWe show the following lower bound on the expected cost of a covered cluster in $k$-means++. Therefore, the $5$-approximation in Lemma~\\ref{lem:5OPT} is tight.\n\\begin{theorem}\\label{thm:5-approx-tight}\nFor any $\\varepsilon > 0$, there exists an instance of $k$-means such that for a set $\\cluster \\in \\pointset$ and a set of centers $C \\in \\real^\\dimension$, if a new center $c$ is sampled from $\\cluster$ with probability $\\Pr(c = x) = \\cost(x, C)/\\cost(P,C)$, then\n$$\n\\E_c\\sbr{\\cost(P,C\\cup\\cbr{c})} \\geq (5-\\varepsilon) \\opt_1(P).\n$$\n\\end{theorem}\n\n\\begin{proof}\nConsider the following one dimensional example, where $\\cluster$ contains $t$ points at $0$ and one point at $1$, and the closest center already chosen in $C$ to $\\cluster$ is at $-1$.\n\n\\begin{figure}[ht]\n\\centering\n\\begin{tikzpicture}\n    \\draw (-1,0) -- (1,0);\n    \\fill[black] (-1,0) circle (0.5 mm) node[below] {$-1$};\n    \\fill[black] (0,0) circle (0.5 mm) node[below] {$0$} node[above] {$t$};\n    \\fill[black] (1,0) circle (0.5 mm) node[below] {$1$} node[above] {$1$};\n  \\end{tikzpicture}\n\\end{figure}\n\nThe new center $c$ will be chosen at $0$ with probability $\\frac{t}{t+4}$, and at $1$ with probability $\\frac{4}{t+4}$. Then, the expected cost of $\\cluster$ is\n$$\n\\E_c\\sbr{\\cost(P,C\\cup\\cbr{c})} = 1\\cdot\\frac{t}{t+4} + t\\cdot\\frac{4}{t+4} = \\frac{5t}{t + 4};\n$$\nand the optimal cost of $\\cluster$ is $\\opt_1(\\cluster) \\leq 1$. Thus, by choosing $t \\geq 4(5-\\varepsilon)/\\varepsilon$, we have\n$$\n\\E_c\\sbr{\\cost(P,C\\cup\\cbr{c})} \\geq (5-\\varepsilon) \\opt_1(P).\n$$\n\\end{proof}\n\n\\subsection{Lower bound on the bi-criteria approximation}\n\nIn this section, we show that the bi-criteria approximation\nbound of $O(\\ln \\frac{k}{\\extracenters})$ is tight up to constant factor. Our proof follows the approach by~\\citet{brunsch2013bad}. We show the following theorem.\n\n\\begin{theorem}~\\label{thm:lowerbound_bi}\nFor every $k>1$ and $\\extracenters \\leq k$, there exists an instance $\\pointset$ of $k$-means such that the bi-criteria $k$-means++ algorithm with $k+\\extracenters$ centers returns a solution of cost greater than\n$$\\frac{1}{8}\\log \\frac{k}{\\extracenters} \\cdot \\opt_k(\\pointset)$$ with probability at least\n$1 - e^{-\\sqrt{k}/2}$.\n\\end{theorem}\n\n\\textbf{Remark:} This implies that the expected cost of bi-criteria $k$-means with $k+\\Delta$ centers is at least $$\\frac{1-e^{-\\sqrt{k}/2}}{8}\\cdot \\log \\frac{k}{\\extracenters} \\cdot \\opt_k(\\pointset).$$\n\n\\begin{proof}\nFor every $k$ and $\\extracenters \\geq \\sqrt{k}$, we consider the following instance. The first cluster is a scaled version of the standard simplex with $N \\gg k$ vertices centered at the origin, which is called the heavy cluster. The length of the edges in this simplex is $1/\\sqrt{N-1}$. Each of the remaining $k-1$ clusters contains a single point on $k-1$ axes, which are called light clusters. These clusters are located at distance $\\sqrt{\\alpha}$ from the center of the heavy cluster and $\\sqrt{2\\alpha}$ from each other, where $\\alpha = \\frac{\\ln(k/\\extracenters)}{4\\extracenters}$.\n\nFor the sake of analysis, let us run $k$-means++ till we cover all  clusters. At the first step, the $k$-means++ algorithm almost certainly selects a\ncenter from the heavy cluster since $N \\gg k$. Then, at each step, the algorithm can select a center either from one of uncovered light clusters or from the\nheavy cluster. In the former case, we say that the algorithm hits a light cluster,\nand in the latter case we say that the algorithm misses a light cluster. Below,\nwe show that with high probability the algorithm makes at least $2\\extracenters$ misses\nbefore it covers all but $\\Delta$ light clusters.\n\n\\begin{lemma}~\\label{lem:lb_miss}\nLet $\\extracenters\\geq \\sqrt{k}$. By the time the $k$-means++ algorithm covers all but $\\extracenters$ light clusters, it makes greater than $2\\extracenters$ misses with probability at least $1-e^{-\\sqrt{k}/2}$.\n\\end{lemma}\n\\begin{proof}[Proof sketch]\nLet $\\varepsilon = 1/\\sqrt{N}$. Observe that $k$-means++ almost certainly covers all clusters in $\\varepsilon N$ steps (since $N\\gg k$). So in the rest of this proof sketch, we assume that the\nnumber chosen centers is at most $\\varepsilon N$ and, consequently, at least $(1-\\varepsilon)N$ points in the heavy cluster are not selected as centers. Hence, the cost of the heavy cluster is at least $1-\\varepsilon$.\n\nConsider a step of the algorithm when exactly $u$ light clusters remain uncovered. At this\nstep, the total cost of all light clusters is $\\alpha u$ (we assume for simplicity that distance between the light clusters and the closest chosen center in the heavy cluster is the same as the distance to the origin). The cost of the heavy cluster is at least $1-\\varepsilon$. The probability that the algorithm chooses a center from the heavy cluster and thus misses a light cluster is at least $(1-\\varepsilon)/(1+\\alpha u)$.\n\nDefine random variables $\\cbr{X_u}$ as follows. Let $X_u = 1$ if the algorithm misses a\ncluster at least once when the number of uncovered light clusters is $u$; and let\n$X_u = 0$, otherwise. Then, $\\cbr{X_u}$ are independent Bernoulli random variables.\nFor each $u$, we have $\\prob{X_u = 1} \\geq (1-\\varepsilon)/(1+\\alpha u)$.\n\nObserve that the total number of misses is lower bounded by $\\sum_{u = \\extracenters}^{k-1} X_u$. Then, we have\n\\begin{align*}\n\\E\\sbr{\\sum_{u=\\extracenters}^{k-1} X_u } &\\geq (1-\\varepsilon)\\sum_{u = \\extracenters}^{k-1} \\frac{1}{1+\\alpha u} \\geq (1-\\varepsilon)\\int_{\\extracenters}^k \\frac{\\de u}{1+\\alpha u} \\\\\n&= (1-\\varepsilon)\\alpha^{-1}\\ln {\\frac{1+\\alpha k}{1+\\alpha\\extracenters}}  \\\\\n&\\geq (1-\\varepsilon)\\alpha^{-1} \\ln \\frac{k}{\\extracenters} = 4(1-\\varepsilon)\\extracenters.\n\\end{align*}\nLet $\\mu = \\E\\sbr{\\sum_{u=\\extracenters}^{k-1} X_u } \\geq 4(1-\\varepsilon)\\extracenters$. By the Chernoff bound for Bernoulli random variables, we have\n$$\n\\prob{\\sum_{u = \\extracenters}^k X_u \\leq 2\\extracenters } \\leq e^{-\\mu} \\rbr{\\frac{e\\mu}{2\\extracenters}}^{2\\extracenters}.\n$$\nSince $f(x) = e^{-x}(\\frac{ex}{2\\extracenters})^{2\\extracenters}$ is a monotone decreasing function for $x \\geq 2\\extracenters$, we have\n$$\n\\prob{\\sum_{u = \\extracenters}^k X_u \\leq 2\\extracenters }  \\leq e^{-(2-4\\varepsilon)\\extracenters}\\cdot 2^{2\\extracenters} \\leq e^{-\\extracenters/2}.\n$$\nHence, with probability as least $1-e^{-\\sqrt{k}/2}$, the number of misses is greater than $2\\extracenters$.\n\\end{proof}\n\nFor every $k$ and $\\extracenters \\geq \\sqrt{k}$, consider the instance we constructed. By Lemma~\\ref{lem:lb_miss}, the algorithm chooses more than $k+\\extracenters$ centers to cover all but $\\extracenters$ light clusters with probability at least $1-e^{-\\sqrt{k}/2}$. Thus, at the time when the algorithm chose $k+\\extracenters$ centers, the number of uncovered light clusters was greater than $\\extracenters$. Hence, in the clustering with $k+\\extracenters$ centers sampled by $k$-means++, the total cost is at least  $\\frac{1}{4}\\ln\\rbr{k/\\extracenters}$,\nwhile the cost of the optimal solution with $k$ clusters is $1$. For every $k$ and $\\extracenters < \\sqrt{k}$, the total cost is at least $\\frac{1}{4}\\ln(k/\\extracenters')$ with $\\extracenters' = \\sqrt{k}$ extra centers, which concludes the proof.\n\\end{proof} \\end{document}", "meta": {"timestamp": "2020-10-28T00:31:54", "yymm": "2010", "arxiv_id": "2010.14487", "url": "https://arxiv.org/abs/2010.14487", "source": "arxiv"}}
{"text": "\\documentclass[11pt]{amsart}\n\\usepackage[margin=10pt,font=small,labelfont=normalfont]{caption}\n\\usepackage{subcaption}\n\n\\usepackage{mathtools}\n\n\n\\usepackage{hyperref}\n\n\n\n\n\\usepackage[demo]{graphicx}\n\n\\usepackage{xcolor}\n\n\\usepackage[margin=1.1in]{geometry} % set the margins to 1.5in on all sides\n%\\usepackage{forest}\n\n\\usepackage{graphics,graphicx}\n\\usepackage{pstricks,pst-node,pst-tree}\n\n\\usepackage{xcolor}\n%\\usepackage{tikz-cd}\n\n\\theoremstyle{plain}\n\n\n\n\n\n\\usepackage{amsfonts}\n\\usepackage{amssymb}\n\\usepackage{amsthm}\n\\usepackage{amsmath}\n\\usepackage{enumerate}\n\\usepackage{hyperref}\n\\hypersetup{\n    colorlinks=false,\n    pdfborder={0 0 0},\n}\n\\usepackage{amsrefs}\n\\usepackage{graphicx}\n\\usepackage{verbatim}\n\\usepackage{amscd}\n\\usepackage{mathtools}\n\n\\usepackage{arydshln}\n\n\n%\\tikzset{\n  %pt/.style={insert path={node[scale=1]{.}}},\n  %dnup/.style={insert path={ [pt] .. controls +(0,1) and +(0,-1) .. +(#1,2) [pt]}},\n  %dndn/.style={insert path={ [pt] .. controls +(0,1) and +(0,1) .. +(#1,0) [pt]}},\n  %upup/.style={insert path={ [pt] .. controls +(0,-1) and +(0,-1) .. +(#1,0) [pt]}},\n%}\n\n%\\usepackage{tikz}\n%\\usetikzlibrary{matrix,arrows,decorations.pathmorphing}\n\n\\theoremstyle{plain}\n\n\\newcommand{\\IK}{\\mathbb{K}}\n\\newcommand{\\IT}{\\mathbb{T}}\n\\newcommand{\\IN}{\\mathbb{N}}\n\\newcommand{\\IZ}{\\mathbb{Z}}\n\\newcommand{\\IQ}{\\mathbb{Q}}\n\\newcommand{\\IR}{\\mathbb{R}}\n\\newcommand{\\IC}{\\mathbb{C}}\n\\newcommand{\\cexp}{\\mathcal{E}}\n\n\n\n\\newcommand{\\BH}{\\mathcal B(H)}\n\\newcommand{\\pp}{\\prime\\prime}\n\\newcommand{\\ppp}{{\\prime\\prime}}\n\\def\\bo{\\sqr44\\,}\n\\def\\sqr#1#2{{\\,\\vcenter{\\vbox{\\hrule height.#2pt\\hbox{\\vrule width.#2pt\nheight#1pt \\kern#1pt\\vrule width.#2pt}\\hrule height.#2pt}}\\,}}\n\n\n\\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert}\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\n% Use: \\set{   \\,:\\,   }\n\\newcommand{\\ipr}[1]{\\left\\langle#1\\right\\rangle}\n\n\\newtheorem{proposition}{Proposition}[section]\n\\newtheorem{lemma}[proposition]{Lemma}\n\\newtheorem{theorem}[proposition]{Theorem}\n\\newtheorem{corollary}[proposition]{Corollary}\n\\newtheorem{fact}[proposition]{Fact}\n\\theoremstyle{definition}\n\\newtheorem{definition}[proposition]{Definition}\n\\theoremstyle{remark}\n\\newtheorem{question}{Question}\n\\newtheorem*{convention*}{Convention}\n\\newtheorem{example}[proposition]{Example}\n\\newtheorem{examples}[proposition]{Examples}\n\\newtheorem{conjecture}[proposition]{Conjecture}\n\\newtheorem{claim}[proposition]{Claim}\n\\newtheorem{remark}[proposition]{Remark}\n\\newtheorem{remarks}[proposition]{Remarks}\n\\newtheorem{notation}[proposition]{Notation}\n\n\\numberwithin{equation}{section}\n\n\\newcommand{\\ran}{\\hbox{ran\\,}}\n%end of preamble from partition file\n%\\usepackage[margin=1.5in]{geometry} % set the margins to 1.5in on all sides\n\n\n\n\\newcommand{\\calC}{\\hbox{$\\mathcal C$}}\n\\newcommand{\\calA}{\\hbox{$\\mathcal A$}}\n\\newcommand{\\calH}{\\hbox{$\\mathcal H$}}\n\\newcommand{\\calF}{\\hbox{$\\mathcal F$}}\n\\newcommand{\\calD}{\\hbox{$\\mathcal D$}}\n\\newcommand{\\calX}{\\hbox{$\\mathcal X$}}\n\\newcommand{\\calK}{\\hbox{$\\mathcal K$}}\n\\newcommand{\\calB}{\\hbox{$\\mathcal B$}}\n\\newcommand{\\calJ}{\\hbox{$\\mathcal J$}}\n\\newcommand{\\calR}{\\hbox{$\\mathcal R$}}\n\\newcommand{\\calS}{\\hbox{$\\mathcal S$}}\n\n\n\n\\numberwithin{equation}{section}\n\n\n\\newcommand{\\matr}[4]{\n\\left[\\begin{array}{cc}\n#1&#2\\\\\n#3&#4\n\\end{array}\n\\right]}\n\n\n%end of new preamble\n\n\\begin{document}\n\n\\newenvironment{dedication}\n        {\\vspace{6ex}\\begin{quotation}\\begin{center}\\begin{em}}\n        {\\par\\end{em}\\end{center}\\end{quotation}}\n\n\\title{Operator categories I. T*-categories}\n\n%\\title{The Linking category of a ternary category}\n%\\title[Crossed products of JB*-triples]{Crossed products of JB*-triples\\\\\n%(A work in progress)}\n%Derivations from a JB$^*$-triple to a Jordan triple module}\n\n\n\n\\author[Pluta]{Robert Pluta}\n\\email{plutar@tcd.ie}\n\\address{Department of Mathematics, UC Irvine, Irvine CA, USA}\n\n\\author[Russo]{Bernard Russo}\n\\email{brusso@math.uci.edu}\n\\address{Department of Mathematics, UC Irvine, Irvine CA, USA}\n\n\n\n\\date{October 26, 2020}\n\n\\begin{abstract}\nT*-categories are introduced as  a ternary generalization of C*-categories. Their linking C*-categories are constructed and the Gelfand-Naimark representation theorems of Zettl for C*-ternary rings and for W*-ternary rings, are generalized to T*-categories. Biduals of C*-categories and of T*-categories are considered.\n \\end{abstract}\n\n\\maketitle\n\n\\begin{dedication}\nDedicated to the memory of Ottmar Loos\n\\end{dedication}\n\n\n \\thispagestyle{empty}\n\n\\tableofcontents\n\n\n\\section{Introduction and Preliminaries}\n\\subsection{Introduction}\\label{sub:0913201}\n\nTo provide motivation for this paper, consider a C*-algebra $A$ and an idempotent linear map $P:A\\to A$. If $A$ is unital and $P$ is completely positive and unital, then $P(A)$ is a C*-algebra with the product $a\\cdot b=P(ab)$ for $a,b\\in P(A)$, \\cite{ChoEff77}. If instead $P$ is just positive and unital, then $P(A)$ is a Jordan C*-algebra (=JB*-algebra) with the product $a\\circ b=P((ab+ba)/2)$ for $a,b\\in P(A)$, \\cite{EffSto79}. Finally, if $P$ is just a contractive projection, then $P(A)$ is a JB*-triple with the triple product $\\{abc\\}=P((ab^*c+cb^*a)/2)$ for $a,b \\in P(A)$, \\cite{FriRus83}.  Thus, by removing a hypothesis on $P$, one is forced to consider a larger category than the category of C*-algebras and completely positive maps. In fact, the category of JB*-algebras is stable under the action of a positive projection and the category of JB*-triples is stable under the action of a contractive projection,\n% \\cite{FriRus85,Stacho82,Kaup84},\n\\cite[Theorem 3.3.1]{Chubook},\\cite[Theorem 14.4.1]{Isidrobook},\\cite[Theorem 5.6.59]{Rodriguezbook}.\n\nNow consider the notion of a C*-category, \\cite{GLR85}. It consists of objects $X,Y,\\ldots$ and morphism sets $\\operatorname{Hom}(X,Y)$ which satisfy a set of axioms relevant to  C*-algebras. In particular, in a C*-category, $\\operatorname{Hom}(X,X)$ is a C*-algebra. A W*-category was defined to be a C*-category  with the additional requirement that $\\operatorname{Hom}(X,Y)$ is the dual space of a Banach space.  Sakai's  theorem for W*-algebras was extended to W*-categories  showing  that $\\operatorname{Hom}(X,Y)$, which is not necessarily a von Neumann algebra,  has a unique predual.   In \\cite{GLR85}, the Gelfand-Naimark theorem for C*-algebras was extended to C*-categories,  and it showed  that $\\operatorname{Hom}(X,Y)$ is isomorphic to a  ternary ring of operators (TRO).  Although this fact was not explicitly mentioned, nevertheless, it was implicitly  suggested by the  following quote from \\cite[pp.79--80]{GLR85}:\n\\begin{quotation}\nNaturally, the idea of using bounded linear mappings between different\nHilbert spaces is such an obvious one that this paper may have many\npublished and unpublished forerunners quite unknown to the authors.\nIndeed one of us (J. E. R.) has been toying with the idea of writing such a\npaper for many years but initially felt that the time was not yet ripe for\nsuch a development. In any case, the roots of this development go right\nback to the beginnings of the theory of operator algebras and perhaps the\nbasic example of mappings between different Hilbert spaces are the\nintertwining operators of representation theory.\n The set of such intertwining\noperators forms a W*-category. \n  %and has been studied from this point\n%of view by Rieffel [20]. Many of his results are in fact of a general nature.\n\\end{quotation}\nIn addition, according to \\cite[p.79]{GLR85},\n\\begin{quotation}\nThere are at present many interesting\ndirections of current research where W*-categories arise naturally: For\nexample the representation theory of groupoids, the harmonic analysis\nof the action of non-Abelian groups on von Neumann algebras, the action of group duals on von Neumann algebras, and non-Abelian cohomology in an operator algebraic context.\n\\end{quotation}\nIt is also noteworthy that category theory is being used in physics, see for example \\cite{Heunenbook}.\nIt thus appears that,  in order to take full advantage of the theory which has been developed for TROs and W*-TROs,  it would be beneficial to extend these two concepts to the operator category setting. We begin that process in this paper, which will be followed by sequel in a non-associative context \\cite{PluRusII}.\n\nWe define a T*-category and a TW*-category, which are modeled on TROs and W*-TROs in much the same way that C*-categories and W*-categories are modeled on C*-algebras and W*-algebras. As an example, consider the Murray-von Neumann classification of W*-algebras into finite and infinite and types I, II,  III.  As of this writing, no such classification of W*-categories has been undertaken since the morphism sets $(X,Y)$ are not necessarily W*-algebras. However, there is a Murray-von Neumann classification of W*-TROs \\cite{Ruan04}, which can be used to decompose W*-categories in the same way that W*-algebras can be decomposed into types I,II,III, and finite, infinite (see Proposition~\\ref{prop:0910202}). Thus, by extending the notion of W*-category to TW*-category, such a decomposition is possible without leaving the category (see Proposition~\\ref{prop:0910203}).\n\nMore precisely, in this paper we give, in section~\\ref{sec:1001201}, a purely algebraic definition of  a ``ternary category'' (a concept which seems to have been overlooked in the literature)  and construct its corresponding ``linking category.''  Turning to ``operator categories'' we define, in section {\\ref{sec:1001202},  a T*-category and show that its linking category is a C*-category. We extend the Gelfand-Naimark theorem for C*-ternary rings, which characterizes them in terms of TROs, \\cite[Theorem 3.1]{Zettl83}, to T*-categories.   We also define a TW*-category and show that its linking category is a W*-category, and we extend the Gelfand-Naimark theorem for W*-ternary rings, which characterizes them in terms of W*-TROs, \\cite[Theorem 4.1]{Zettl83},  to TW*-categories.   We also show, in section~\\ref{sec:1001203}, that the bidual of a C*-category is a W*-category, and   the bidual of a T*-category is a TW*-category.\n\n\n\n\n\\subsection{Associative triple systems}\\label{sub:0910201}\n\nThe following construction is taken essentially verbatim from \\cite{Loos72} (see also \\cite[pp.\\ 28--30]{Meyberg72}) and is central to the paper.  The  complications due to taking direct sums,  which were not necessary  in \\cite{Zettl83}, are  unavoidable since the module actions defined in Lemma~\\ref{lem:0810201}(ii) make essential use of the second component and are critical to the proof of the key Proposition~\\ref{prop:0912201}(iv).\n\n\n\n\nA vector space $V$ with a trilinear map $m:V\\times V\\times V\\to V$ with $m(x,y,z)$, called the triple product, and  denoted by $(x,y,z)$ is called an  {\\it associative triple system} if\nit satisfies\n\\[\n(x,y,(z,u,v))=((x,y,z),u,v)=(x,(u,z,y),v)\n\\]\nfor all elements $x,y,z,u,v\\in V$.\nMany examples will appear in this paper. If the base field is the complex numbers, the triple product is assumed to be conjugate linear in the middle variable.\\smallskip\n\nLet $M$ be an associative triple system with triple product denoted by $[hgf]$. Let \n\\[\nE(M)=\\hbox{End}\\, (M)\\oplus[\\overline{ \\hbox{End}\\, (M)}]^{op},\n\\]\nwhere the notation $\\overline{V}$ for a complex vector space means that the scalar multiplication in $\\overline{V}$ is $(\\lambda,v)\\in \\IC\\times V\\mapsto \\lambda\\circ v=\\overline{\\lambda}v$.  \n\nWe shall often  denote the products in $E(M)^{op}$ and in $[\\hbox{End}\\, (M)]^{op}$ by $X\\circ Y=YX$.\nExplicitly, for $A=(A_1,A_2)$ and $A'=(A'_1,A'_2)$ belonging to $E(M)$,\n\\[\nAA'=(A_1,A_2)(A'_1,A'_2)=(A_1A'_1,A_2\\circ A'_2)=(A_1A'_1,A'_2 A_2),\n\\]\nand for  $B=(B_1,B_2)$ and $B'=(B'_1,B'_2)$ belonging to $E(M)^{op}$, \n\\[\nB\\circ B'=(B_1,B_2)\\circ (B'_1,B'_2)=(B'_1,B'_2)(B_1,B_2)=(B'_1B_1,B'_2\\circ B_2)=(B'_1B_1,B_2B'_2).\n\\]\n\n\nInvolutions, that is, conjugate linear anti-isomorphisms of order 2, are defined on $E(M)$  by \n\\[\nA=(A_1,A_2)\\mapsto \\overline{A}=\\overline{(A_1,A_2)}=(A_2,A_1),\n\\]\nso that  $\\overline{AA'}=\\overline{A'}\\, \\overline{A}$, and\n\\[\n\\overline{\\lambda A}=\n\\overline{(\\lambda A_1,\\lambda\\circ A_2)}=\n\\overline{(\\lambda A_1,\\overline{\\lambda}A_2)}=(\\overline{\\lambda}A_2,\\lambda A_1)=\n(\\overline{\\lambda}A_2,\\overline{\\lambda}\\circ  A_1)=\\overline{\\lambda}\\  \\overline{A};\n\\]\nand on $E(M)^{op}$ by\n\\[\nB=(B_1,B_2)\\mapsto \\overline{B}=\\overline{(B_1,B_2)}=(B_2,B_1),\n\\]\nso that $\\overline{B\\circ B'}=\\overline{B'}\\circ \\overline{B}$ and \n\\[\n\\overline{\\lambda B}=\n\\overline{(\\lambda B_1,\\lambda\\circ B_2)}=\n\\overline{(\\lambda B_1,\\overline{\\lambda}B_2)}=(\\overline{\\lambda}B_2,\\lambda B_1)=\n(\\overline{\\lambda}B_2,\\overline{\\lambda}\\circ  B_1)=\\overline{\\lambda}\\  \\overline{B}.\n\\]\n\n\n\n\n\nFor $g,h\\in M$, define $L(g,h)=[gh\\cdot], R(g,h)=[\\cdot hg]$,\n\\[\n\\ell(g,h)=(L(g,h), L(h,g))=([gh\\cdot],[hg\\cdot])\\in E(M)\n\\]\nand \n\\[\nr(g,h)=(R(h,g), R(g,h))=([\\cdot gh],[\\cdot hg])\\in E(M)^{op}.\n\\]\n\nNext, define \n\\[\nL=L(M)=\\hbox{span}\\, \\{\\ell(g,h): g,h\\in M\\}\\subset E(M)\n\\]\nand \n\\[\nR=R(M)=\\hbox{span}\\, \\{r(g,h): g,h\\in M\\}\\subset E(M)^{op}.\n\\]\n\n\n\n\nThe next three lemmas follow straightforwardly from the above construction so their proofs   are left to the reader. Their statements have their origins in \\cite{Loos72}  and are reproduced in  \\cite[pp.\\ 28--30]{Meyberg72}.\n\n\\begin{lemma}%1.1\n\\label{lem:0913201}\nWith the above notation\n\\begin{description}\n\\item[(i)] $R(f,g)L(h,k)=L(h,k)(R(f,g)$\\footnote{This is needed in the proof of the bimodule statements in Lemma~\\ref{lem:0810201}.}\n\\item[(ii)]\n$\n\\ell(g,h)\\ell(g',h')=\\ell([ghg'],h')=\\ell(g,[h'g'h])\n$\n\\item[(iii)]\n$\nr(g,h)\\circ r(g',h')=r(g,[hg'h'])=r([g'hg],h'),\n$\n%\\smallskip\n%\\noindent\nwhere, as indicated,  the product on the left  is taken in $E(M)^{op}$.\n\\item [(iv)]$L$ is a *-subalgebra of $E(M)$ and $R$ is a *-subalgebra of $E(M)^{op}$.\n\\end{description}\n\\end{lemma}\n\n%\\pagebreak\n\n\\begin{lemma} %1.2\n\\label{lem:0810201}\nLet  $A=(A_1,A_2)\\in E(M)$, $B=(B_1,B_2)\\in E(M)^{op}$, and $f\\in M$. Then\n\\begin{description}\n\\item[(i)] $M$ is a left $E(M)$-module  via \n\\[\n (A,f)\\mapsto A\\cdot f=A_1f,\n \\]\n a right $E(M)^{op}$-module via \n%  $$\n %(X,Y)\\times E(X,Y)^{op}\\rightarrow (X,Y),\n%$$\n\\[\n (f,B)\\mapsto f\\cdot B=B_1f,\n \\]\n  and  an $(L,R)$-bimodule.\n  \\smallskip\n  \n  \\item[(ii)] \n Let $\\overline{M}$ denote the vector space $M$ with the element $f$ denoted by $\\overline{f}$ and  with scalar multiplication defined by $(\\lambda,\\overline f)\\mapsto\\lambda\\circ\\overline{f}= \\overline{\\overline{\\lambda}f}$. Then\n \\medskip\n \n$\\overline{M}$ is a left $E(M)^{op}$-module  via \n%$$\n%E(X,Y)^{op}\\times \\overline{(X,Y)}\\rightarrow \\overline{(X,Y)},\n%$$\n\\[\n (B,\\overline{f})\\mapsto B\\cdot \\overline{f}=\\overline{B_2f},\n \\]\n   a right $E(M)$-module via\n%$$\n %\\overline{(X,Y)}\\times E(X,Y)\\rightarrow \\overline{(X,Y)},\n%$$\n\\[\n (\\overline{f},A)\\mapsto \\overline{f}\\cdot A=\\overline{A_2f},\n \\]\n  and  an $(R,L)$-bimodule.\n  \n%\\item[(iii)] $(X,Y)$ is an $(L,R)$-bimodule and $\\overline{(X,Y)}$ is an $(R,L)$-bimodule \n\\end{description}\n\\end{lemma}\n  \n  Thus %for $A\\in L$, $B\\in R$, and $f\\in (X,Y)$, \n    we have\n  \\[\n  (AA')\\cdot f=A\\cdot (A'\\cdot f)\\hbox{ and }f\\cdot (B\\circ B')=(f\\cdot B)\\cdot B',\n  \\]\n    \\[\n\\overline{f}\\cdot(AA')=(\\overline{f}\\cdot A)\\cdot A'\\hbox{ and }(B\\circ B')\\cdot \\overline{f}=B\\cdot(B'\\cdot\\overline{f}), \n\\]\n  \\[\n  (A\\cdot f)\\cdot B=A\\cdot(f\\cdot B)\\hbox{ and } (B\\cdot\\overline{f})\\cdot A=B\\cdot(\\overline{f}\\cdot A),\n  \\]\nwhere the product $B\\circ B'$ is taken in $E(M)^{op}$.\n\n\n\\medskip\n\nGiven an associative triple system  $M$, let \n\\[\n\\calA=\\calA(M)=L(M)\\oplus M\\oplus\\overline{M}\\oplus R(M)\n\\]\nand write the elements $a$ of $\\calA$ as matrices\n\\[\na=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] ,  (A\\in L(M), B\\in R(M), f,g \\in M).\n\\]\n\nDefine multiplication and involution in $\\calA$ by\n\\begin{equation}\\label{eq:0906201}%(1.1)\naa'=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\nA'&f'\\\\\n\\overline{g'}&B'\n\\end{matrix}\\right]\n=\\left[\\begin{matrix}\nAA'+\\ell(f,g')&A\\cdot f'+f\\cdot B'\\\\\n\\overline{g}\\cdot A'+B\\cdot\\overline{g'}&r(g,f')+B\\circ B'\n\\end{matrix}\\right]\n\\end{equation}\n(the product $B\\circ B'$ taken in $E(M)^{op}$)\nand\n\\begin{equation}\\label{eq:0906202}%(1.2)\na^\\sharp =\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]^\\#=\\left[\n\\begin{matrix}\n\\overline{A}&g\\\\\n\\overline{f}&\\overline{B}\n\\end{matrix}\\right].\n\\end{equation}\n\n\n\\begin{lemma}\\label{lem:0807201}%1.3\n$\\calA(M)$ is an associative *-algebra and for $f,g,h\\in M$,\n\\[\n\\left[\n\\begin{matrix}\n0&f\\\\\n0&0\n\\end{matrix}\\right]\n\\left[\n\\begin{matrix}\n0&g\\\\\n0&0\n\\end{matrix}\\right]^\\#\n\\left[\n\\begin{matrix}\n0&h\\\\\n0&0\n\\end{matrix}\\right]\n=\n\\left[\n\\begin{matrix}\n0&[fgh]\\\\\n0&0\n\\end{matrix}\\right].\n\\]\n\\end{lemma}\n\n\\begin{remark}\\label{rem:0912201}%1.4\nThe map $f\\mapsto \\left[\n\\begin{matrix}\n0&f\\\\\n0&0\n\\end{matrix}\\right]$ is a triple isomorphism of $M$ into $\\calA(M)$, the latter considered as an associative triple system with triple product $ab^\\#c$, for $a,b,c\\in\\calA(M)$,\nWe refer to $\\calA(M)$ as the {\\it standard embedding} of $M$.  If the associative triple system $M$ is a  normed space,  and $\\|[hgf]\\|\\le \\|f\\|\\|g\\|\\|h\\|$, then the {\\it normed standard embedding} of $M$ is defined in the same way  but  with $R$ and $L$ replaced by their closures in $B(M)$. In this case, the modules in Lemma~\\ref{lem:0810201} are continuous modules, and Banach modules if $M$ is a Banach space.\n\\end{remark}\n\nIn certain cases, the correspondence $M\\to \\calA(M)$ will be a functor from the category   of associative triple systems and triple homomorphisms to the category  of  associative *-algebras and *-homomorphisms. In the present context, we have the following lemma, whose straightforward but tedious proof is omitted.\n\n\n\\begin{lemma}%1.5\nLet $\\varphi:M_1\\to M_2$ be a surjective triple homomorphism between associative triple systems $M_1$ and $M_2$. There is a *-homomorphism $\\calA(\\varphi):\\calA(M_1)\\to \\calA(M_2)$ defined by \n\\[\n\\calA(\\varphi)\\left(\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] \\right)\n=\n\\left[\\begin{matrix}\n\\varphi_{11}(A)&\\varphi(f)\\\\\\smallskip\n\\overline{\\varphi(g)}&\\varphi_{22}(B)\n\\end{matrix}\\right] ,\n\\]\nwhere if $A=\\sum_i([g_ih_i\\cdot],[h_ig_i\\cdot])\\in L(M_1)$,\n\\[\n \\varphi_{11}(A)=\\sum_i([\\varphi(g_i)\\varphi(h_i)\\cdot],[\\varphi(h_i)\\varphi(g_i)\\cdot])\\in L(M_2),\n\\]\nand if  $B=\\sum_i([\\cdot g_ih_i],[\\cdot h_ig_i])\\in R(M_1)$,\n\\[\n \\varphi_{22}(B)=\\sum_i([\\cdot \\varphi(g_i)\\varphi(h_i)],[\\cdot \\varphi(h_i)\\varphi(g_i)])\\in R(M_2).\n\\]\n\\end{lemma}\n\n\n\n\n\n\n\n\n\\subsection{Ternary rings of operators}\\label{sub:0913202}\n\n\nLet $H$ and $K$ be complex Hilbert spaces.   \nDenote by $\\mathcal B(H, K)$  \nthe set of all bounded linear operators from $H$ to $K$,  \nand write  $\\mathcal B(H)$ for $\\mathcal B(H, H)$.      \nConsider $\\mathcal B(H, K)$ as a Banach space  \nwith the usual operator norm and additional algebraic structure  \ngiven by  {\\em ternary product}  \n$(x, y, z) \\mapsto xy^*z$, \nso that for every $x, y, z \\in \\mathcal B(H, K)$ we have:\n\\[\n\\norm{xy^*z} \\leq \\norm{x} \\norm{y} \\norm{z} \\quad \\text{ and } \\quad \n\\norm{xx^*x} = \\norm{x}^3. \n\\]\n\nA~Banach subspace $X$ of $\\mathcal B(H, K)$ \nis called a  {\\em TRO} (ternary ring of operators) \nif $xy^*z \\in X$ for every choice of $x, y, z \\in X$.      \nA~TRO $X \\subseteq  \\mathcal B(H, K)$ is called a {\\em $W^*$-TRO}  \nif it is weak$^*$ closed   \n(equivalently, weak operator closed, or strong operator closed)  \nin $\\mathcal B(H, K)$.  \nA TRO that is dual as a Banach space is a $W^*$-TRO\n\\cite[Theorem 2.6]{EffOzaRua01}, and\nevery $W^*$-TRO  \nhas a unique Banach space predual, up to isometry \\cite[Proposition 2.4]{EffOzaRua01}.\nTROs are studied extensively in \\cite[\\S 4.4, \\S8.3, 8.5.18]{BleLeM}, where we can find the following on page 351:\n\n\\begin{quotation}\nAround 1999, interest in TROs picked up with the important\npaper \\cite{EffOzaRua01}. As evidenced by the number of recent papers using them, it seems\nthat TRO and C*-module methods are playing an increasingly central role in\noperator space theory at the present time.\n\\end{quotation}\n\n\n\n\n\n\nLet $X$ be a TRO contained in $\\mathcal B(H, K)$.    \nThe left $C^*$-algebra of $X$, \ndenoted by $C$\nis the $C^*$-subalgebra of  $\\mathcal B(K)$  \ngenerated by elements of the form  $xy^*$ with $x, y \\in X$. \nSimilarly, the  right $C^*$-algebra of $X$, denoted by $D$,\nis the $C^*$-subalgebra of  $\\mathcal B(H)$   \ngenerated by elements of the form $y^* z$ with $y, z \\in X$    \n($C$ and $D$ need not be unital algebras).   \nThe connection between $C$ and $D$  \nis made via the linking $C^*$-algebra of $X$, defined as   \n$\nA_X =  \n\\bigl[\\begin{smallmatrix} \nC  &  X \\\\ \nX^* &  D  \n\\end{smallmatrix}\\bigr] \n$,\nwhere $X^* = \\set{x^* \\,:\\, x\\in X}\n$\nis the space of adjoints of elements of  $X$.  \nIt is often convenient  to make the identification \n\\[ \\mathcal B(K\\oplus H) \n=  \n\\bigl[\\begin{smallmatrix} \\mathcal B(K) & \\mathcal B(H, K) \\\\ \n\\mathcal B(K, H) & \\mathcal B(H)\\end{smallmatrix}\\bigr] \n\\] \nand regard  $A_X$  \nas a $C^*$-subalgebra of  \n$\\mathcal B(K\\oplus H)$. \nThe linking $C^*$-algebra $A_X$ is uniquely determined by $X$   \nand is independent of the Hilbert spaces $H$ and $K$ \non which $X$ is represented.   \nThus, for the most part, we may assume that  \nTROs $X \\subseteq \\mathcal B(H, K)$ act non-degenerately on $H$ and $K$     \n($XH$ is norm dense in $K$  and  $X^*K$ is norm dense in $H$).   \nIn this case, the $C^*$-algebras $C$ and $D$ act non-degenerately on $K$ and $H$, respectively.\nIt is clear that \n$C X \\subseteq  X$ and $X D \\subseteq X$, \nso $X$ is a $C$-$D$ bimodule.  \nIn fact, \n$C X = X = X D$ \nand $X$ can be regarded as \na non-degenerate and faithful \nHilbert $C$-$D$ bimodule  \nwith inner products   \n$\\prescript{}{C}{\\ipr{x, y}} = xy^* $\nand \n$\\ipr{x, y}_{D} = x^* y$ \ndefined on $X$. \n\nLet $X$ be a $W^*$-TRO contained in $\\mathcal B(H, K)$.      \nThe left von Neumann algebra of $X$,    \ndenoted by $M$,     \nis the von Neumann subalgebra of $\\mathcal B(K)$     \ngenerated by elements of the form  $xy^*$ with $x, y \\in X$.  \nThe right von Neumann algebra of $X$,     \ndenoted by $N$,       \nis the von Neumann subalgebra of $\\mathcal B(H)$    \ngenerated by elements of the form $y^* z$ with $y, z \\in X$.     \nThe linking von Neumann algebra of $X$ is defined as      \n$\nR_X =  \n\\bigl[\\begin{smallmatrix} \nM  &  X \\\\ \nX^* &  N  \n\\end{smallmatrix}\\bigr] \n$ \nand it is viewed as a\nvon Neumann subalgebra of   \n$\\mathcal B(K\\oplus H)$. \nThe weak$^*$ closure $\\bar{X}$ of a TRO $X$ is a \n$W^*$-TRO.  \n\n\\begin{example}%1.6\n\\label{ex:0912201}\nIf $M$ is a TRO, then $\\calA(M)$ (see Remark~\\ref{rem:0912201}) is a C*-algebra which is *-isomorphic to the linking algebra $A_M$ of $M$ via the map\n\n\\[\nA_M\\ni \\left[\\begin{matrix}\n\\sum_ix_iy_i^*&z\\\\\nw^*&\\sum_ju_j^*v_j\n\\end{matrix}\\right] \\mapsto \\left[\\begin{matrix}\n\\sum_i([x_iy_i\\cdot],[[y_ix_i\\cdot])&z\\\\\n\\overline{w}&\\sum_j([\\cdot u_jv_j],[\\cdot v_ju_j])\n\\end{matrix}\\right] \\in\\calA(M)\n\\]\n (cf.\\ Example~\\ref{ex:0911201}).\n\\end{example}\n\n\n\\subsection{Categories}\n\nIn this subsection, we record the basic definitions in category theory that we use. See, for example, \\cite[Chapter 0]{Heunenbook}.\n\n\\begin{definition}%1.7\nA {\\em  category} $\\mathcal{C} = \n(\\operatorname{Ob}(\\mathcal{C}), ~  \\operatorname{Mor}(\\mathcal{C}), ~ \\circ)$ \nconsists of the following entities.   \n\\begin{enumerate}\n\\item A class $\\operatorname{Ob}(\\mathcal{C})$ of {\\em objects}.  \n\n\\item For each $X, Y$ in $\\operatorname{Ob}(\\mathcal{C})$,  \n  a class $\\operatorname{Hom}(X, Y)$ \n  of {\\em morphisms} (or {\\em maps})  \n   from $X$ to $Y$, with $f$ in  $\\operatorname{Hom}(X, Y)$ written $X \\stackrel{f}{\\to} Y$ or $f\\colon X \\to Y$. The class of all morphisms is denoted $\\operatorname{Mor}(\\mathcal{C})$, so $\\operatorname{Hom}(X, Y)\\subseteq \\operatorname{Mor}(\\mathcal{C})$.    \n    \\item For each object $X$, there is a morphism $1_X\\in \\operatorname{Hom}(X, X)$ such that\n  $1_Y\\circ f=f\\circ 1_X=f$ for each $f\\in\\operatorname{Hom}(X, Y)$.\n \n   \\item For each $X, Y, Z$ in \n  $\\operatorname{Ob}(\\mathcal{C})$, a function \n\\begin{center}\n\\begin{tabular}{ r c l }\n $\\operatorname{Hom}(X, Y)\\times \\operatorname{Hom}(Y, Z)  $ & $\\to$ & $\\operatorname{Hom}(X, Z)$ \\\\ \n $(f, g)$ & $\\mapsto$ & $ g \\circ  f =gf$    \n\\end{tabular}\n\\end{center}    \ncalled {\\em morphism composition} (or just {\\em composition}), \nwhich is associative in the sense that  \n$\n(hg)f=h(gf) $ \n  for all composable morphisms in the category.    \n   \\end{enumerate}\n\\end{definition}\n\nWhen convenient and not confusing, we shall often, as in \\cite{GLR85},  denote $\\operatorname{Hom}(X,Y)$ simply by $(X,Y)$.\n\n\\begin{definition} %1.8\nLet $\\mathcal{C}$ and $\\mathcal{D}$ be categories.   \nA  ({\\em covariant}) {\\em functor} $F \\colon \\mathcal{C} \\to \\mathcal{D}$ consists of the following entities.\n\\begin{enumerate}\n\t\\item  A function\n  $\\operatorname{Ob}(\\mathcal{C})\\to \\operatorname{Ob}(\\mathcal{D})$ \n  that associates to each object $X$ in $\\mathcal{C}$ an object \n  $F(X)$  in $\\mathcal{D}$.\n\t\\item For each $X,Y$ in $\\operatorname{Ob}(\\mathcal{C})$, \n\t a function $\\operatorname{Hom}(X, Y) \\to \\operatorname{Hom}(F(X), F(Y))$ \n\t that associates to each morphism $X \\overset{f}{\\to} Y$ \n\t in $\\mathcal{C}$  a morphism $F(X) \\overset{F(f)}{\\longrightarrow} F(Y)$ \n\t in $\\mathcal{D}$ such that \n\t \\[F(g \\circ  f) = F(g) \\circ  F(f)\\quad \\hbox{and}\\quad \n\t F(1_X)=1_{F(X)}\\]\nfor all composable morphisms $f, g$ in $\\mathcal{C}$. \n\\end{enumerate}\n\\end{definition}\n\n\\begin{definition}%1.9\n A subcategory of a category $\\mathcal C$ is a category $\\mathcal S$ whose objects are objects in $\\mathcal C$ and whose morphisms are morphisms in $\\mathcal C$ with the same identities and composition of morphisms. If $X,Y$ are objects of $\\mathcal S$, then the morphism set of $\\mathcal S$ from $X$ to $Y$ is denoted $(X,Y)_{\\mathcal S}$, and  we have $(X,Y)_{\\mathcal S}\\subset (X,Y):=(X,Y)_{\\mathcal C}$.  \n\\end{definition}\n\n\n \n\n\n\\begin{definition}  %1.10\nLet $\\mathbb{K}$ be a field.   \nA category  \n$\\mathcal{C} =  \n(\\operatorname{Ob}(\\mathcal{C}), ~  \\operatorname{Mor}(\\mathcal{C}), ~ \\circ)$ \nis called a $\\mathbb{K}$-{\\em linear category}\n(or a $\\mathbb{K}$-{\\em algebroid}) \n if each \n $\\operatorname{Hom}(X, Y) \n \\subseteq \n \\operatorname{Mor}(\\mathcal{C})$\nhas the structure of  \na vector space over $\\mathbb{K}$      \nand composition of morphisms \n\\begin{center}\n\\begin{tabular}{ r c l }\n $\\operatorname{Hom}(X, Y)\\times \\operatorname{Hom}(Y, Z) $ & $\\to$ & $\\operatorname{Hom}(X, Z)$ \\\\ \n $(f, g)$ & $\\mapsto$ & $ g \\circ f$     \n\\end{tabular}\n\\end{center}     \nis $\\mathbb{K}$-bilinear. \n\\end{definition}\n\nFor any object $X$ in a $\\IK$-linear category, $(X,X)$ is a unital  associative algebra. For any such associative algebra $A$, the category with $A$ as its sole object, and $A$ as its morphisms, is a $\\IK$-linear category with composition being the product in $A$.\n\n\\begin{definition}%1.11\nLet $\\mathcal A$ be a $\\IK$-linear category and $\\mathcal J$ a subcategory.  Then $\\mathcal J$ is  an ideal of $\\mathcal A$  if for objects $X,Y$ of $\\mathcal J$, $(X,Y)_{\\mathcal J}$ is a linear subspace of $(X,Y)$ and objects $X,Y,Z$\n\n\\[\\hbox{ ({\\it right ideal}) }\\quad\n(Y,Z)_{\\mathcal J}\\circ (X,Y)\\subset (X,Z)_{\\mathcal J}\\]\n and \n\\[\\hbox{ ({\\it left ideal}) }\\quad\n  (Y,Z)\\circ (X,Y)_{\\mathcal J}\\subset (X,Z)_{\\mathcal J}\n\\]\n(composition in $\\calA$).\\smallskip\n\nIf $\\calJ$ is a two-sided ideal in $\\calC$, the quotient $\\calC/\\calJ$ is the category with the same objects as $\\calC$ and with morphism sets the quotient spaces $(X,Y)/(X,Y)_{\\calJ}$. There is a natural quotient functor from $\\calC$ to $\\calC/\\calJ$ (see \\cite[section 4]{Mitchener02}).\n\\end{definition}\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{definition} %1.12\nLet $\\mathcal{C}$ and $\\mathcal{D}$ be $\\mathbb{K}$-linear categories.   \nA functor  $F \\colon \\mathcal{C} \\to \\mathcal{D}$ is a {\\it linear functor}\nif the map $F: \\operatorname{Hom}(X, Y) \\to \\operatorname{Hom}(F(X), F(Y))$ is linear.\n\\end{definition}\n\n\n\\section{C*-ternary rings}\\label{sec:1021201}\n\nRecall that a C*-ternary ring was introduced in \\cite{Zettl83} as a complex Banach space $(Z,\\|\\cdot \\|)$ with a ternary operation $(\\cdot,\\cdot,\\cdot):Z\\times Z\\times Z\\rightarrow Z$ which is linear in the outer variables and conjugate linear in the middle variable,  associative in the sense that \n\\[\n(((v,w,x),y,z)=(v,(y,x,w),z)=(v,w,(x,y,z)),\n\\]\nand for which $\\|(x,y,z)\\|\\le \\|x\\|\\|y\\|\\|z\\|$ and $\\|(x,x,x)\\|=\\|x\\|^3$. In addition, if $Z$ is a dual Banach space, it is called a W*-ternary ring.\n\n\nIn order to prove our main results in this section (Theorems~\\ref{thm:0810201} and ~\\ref{thm:0811201} below), we shall invoke the following   Gelfand-Naimark theorem for C*-ternary rings, which uses the following terminology. A linear bijection $\\varphi:Z_1\\rightarrow Z_2$  between two C*-ternary rings $(Z_1,(\\cdot,\\cdot,\\cdot)_1)$\nand $(Z_2,(\\cdot,\\cdot,\\cdot)_2)$ is an {\\it  isomorphism} if $\\varphi((x,y,z)_1)=(\\varphi(x),\\varphi(y),\\varphi(z))_2$\nand an {\\it anti-isomorphism} if $\\varphi((x,y,z)_1)=-(\\varphi(x),\\varphi(y),\\varphi(z))_2$.\n\n  \\begin{theorem}%2.1\n[Theorem 3.1 in \\cite{Zettl83}] \\label{thm:0807201} Let $Z$ be a C*-ternary ring. \n\\begin{description}\n\\item[(i)]\n $Z$ is the direct sum of two C*-ternary subrings $Z_+$ and $Z_-$which are respectively isometrically isomorphic and isometrically anti-isomorphic to a ternary ring of operators (TRO). \n\\item[(ii)]\n The decomposition is unique: if $Z_1$ and $Z_2$ are C*-ternary subrings of $Z$   with $Z=Z_1\\oplus Z_2$, $Z_1$ isomorphic to a TRO, and $Z_2$ anti-isomorphic to a TRO, then $Z_+=Z_1$ and $Z_-=Z_2$.\n \\item[(iii)] There exists one, and only one, operator $T:Z\\to Z$ satisfying\n \\begin{itemize}\n \\item $T^2=I$;\n \\item $T((x,y,z))=(Tx,y,z)=(x,Ty,z)=(x,y,Tz)$ for $x,y,z\\in Z$;\n \\item $(Z,T\\circ (x,y,z))$ is a C*-ternary ring which is isomorphic to a TRO.\n \\end{itemize}\n \\end{description}\n\\end{theorem}\n\n\\begin{remark}%2.2\n\\label{rem:0831201}\nZettl shows (\\cite[Proposition 3.2 and p. 130]{Zettl83}) that if a  C*-ternary ring $(Z, (x,y,z))$ is a right Banach $\\frak A$-module for some C*-algebra $\\frak A$, and there is a conjugate bilinear form $\\alpha:Z\\times Z\\rightarrow \\frak A$ with $\\|\\alpha\\|\\le 1$ satisfying \n\\begin{description}\n\\item[(i)] $\\alpha(x\\cdot a, y)=\\alpha(x,y)a$\n\\item[(ii)] $\\alpha(x,y)^*=\\alpha(y,x)$\n\\item[(iii)] $(x,y,z)=x\\cdot \\alpha(z,y)$\n\\item[(iv)] $\\operatorname{span}\\alpha(Z,Z)$ is dense in $\\frak A$,\n\\end{description}\nthen $Z_+=\\{z\\in Z:\\alpha(z,z)\\ge 0\\}$ and $Z_-=\\{z\\in Z:\\alpha(z,z)\\le 0\\}$, and that $Z_+$ and $Z_-$ are orthogonal, so that $\\|(\\alpha,\\beta)\\|=\\max ( \\|\\alpha\\|,\\|\\beta\\|)$ for $(\\alpha,\\beta)\\in Z_+\\oplus Z_-$.\n\\end{remark}\n\nLet $(M,[\\cdot,\\cdot,\\cdot])$ be a C*-ternary ring.  Recall that, $M$ being a normed associative triple system, it is, by Remark~\\ref{rem:0912201}, a left $L(M)$-Banach module via $L(M) \\times M\\ni (A,f)\\mapsto A\\cdot f=A_1f \\in M$ and a right $R(M)^{op}$-Banach module via $M\\times R(M) \\ni (f,B)\\mapsto f\\cdot B=B_1f \\in M$, and that\n\\[\n\\calA=\\{a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] : A\\in L(M), B\\in R(M), f,g \\in M\\},\n\\]\nis an algebra with multiplication (\\ref{eq:0906201}) and  involution  (\\ref{eq:0906202}).\n\n\n\nWe note that the C*-algebra $\\frak A$ in Remark~\\ref{rem:0831201} is the closed span of $\\{[\\cdot gh]: g,h\\in V\\}$ and it is *-isomorphic to $R(M)$ via the map $\\frak A\\ni B_1\\mapsto \\sigma(B_1)=(B_1,B_1^*)\\in R(M)$. Similarly  $\\tau:\\frak B\\rightarrow L(V)$ is the *-isomorphism $A_1\\mapsto (A_1,A_1^*)$, where $\\frak B$ is the close span of $\\{[gh\\cdot]: g,h\\in V\\}$. The C*-ternary ring $M$ is thus both a Banach $(L,R)$-bimodule and a Banach $(\\frak B,\\frak A)$-bimodule. \n\n\n\n\n\nThe following proposition is a key to the proof of Theorem~\\ref{thm:0810201}. Because of the length of the proof of (iv), we defer it  to  section~\\ref{sec:0906201}. Also, although the proof of (i) follows from the fact, just noted, that $R(M)$ is *-isomorphic to $\\frak A$, we give a direct proof in the present context.\n\n\n\n\\begin{proposition}%2.3\n\\label{prop:0912201}\nLet $M$ be a C*-ternary ring. With the above notation, we have\n\\begin{description}\n\\item[(i)] $R(M)$  is a C*-algebra with the norm from $B(M)$.\n\\item[(ii)] $M$ is a right Banach $R(M)^{op}$-module.\n\\item[(iii)] With $\\langle f|g\\rangle=\\langle f|g\\rangle_{M}:M\\times M\\rightarrow R(M)$ defined by $\\langle f|g\\rangle=r(g,f)=([\\cdot gf],[\\cdot fg])$, we have \n\\[\n\\langle f\\cdot B|g\\rangle=\n\\langle f|g\\rangle\\circ B.\n\\]\n\\item[(iv)] If $M$ is a right $R(M)^{op}$-Hilbert module, then $\\calA$ can be normed to be a C*-algebra.\n\\end{description}\n\\end{proposition}\n\\begin{proof}\n(i) Recall that\n$\nR=R(M)$ is the closed span of\n\\[\n \\{r(f,g)=([\\cdot fg],[\\cdot gf]): f,g\\in M\\}\\subset B(M)\\oplus[\\overline{B(M)}]^{op}.\n\\]\nLet $U=\\sum_ir(f_i,g_i)=(\\sum_i[\\cdot f_ig_i],\\sum_i[\\cdot g_if_i])=(U_1,U_2)\\in R$, and recall that $\\overline{U}=(U_2,U_1)$ is the involution\\footnote{$\\overline{U}$ is obviously well defined. However, that fact, proved in \\cite{Zettl83}, that $\\sum_i[\\cdot f_ig_i]=0$ implies that $\\sum_i[\\cdot g_if_i]=0$, requires proof using associativity of the ternary product.  We don't need that argument here since it is obvious that if $(U_1,U_2)=(0,0)$, then \n$\\overline{(U_1,U_2)}=(U_2,U_1)=(0,0)$.}\non $R$. \nWe shall show, by mimicking the proof of \\cite[Proposition 3.2 (1)]{Zettl83}, that $\\|U\\|^2=\\|\\overline{U}U\\|$, proving that $R$ is a C*-algebra. \n\nLet $h=(h_1,h_2)\\in M\\oplus M$.\nWe have \n\\begin{eqnarray*}\n[Uh,Uh,Uh]&=&[U_1h_1,U_1h_1,U_1h_1]\\oplus [U_2h_2,U_2h_2,U_2h_2]\\\\\n&=&[\\sum_i[h_1f_ig_i],U_1h_1,U_1h_1]\\oplus [\\sum_i[h_2g_if_i],U_2h_2,U_2h_2]\\\\\n&=&\\sum_i[h_1,[U_1h_1,g_i,f_i],U_1h_1]\\oplus \\sum_i[h_2,[U_2h_2,f_i,g_i],U_2h_2]\\\\\n&=&[h_1\\oplus h_2,(\\sum_i[U_1h_1,g_i,f_i])\\oplus(\\sum_i[U_2h_2,f_i,g_i]),U_1h_1\\oplus U_2h_2]\\\\\n&=&[h_1\\oplus h_2,U_2U_1h_1\\oplus U_1U_2h_2,U_1h_1\\oplus U_2h_2]\\\\\n&=&[h,\\overline{U}Uh,Uh],\n\\end{eqnarray*}\nso that \n\\[\n\\|Uh\\|^3=\\|[Uh,Uh,Uh]\\|\\le \\|h\\|\\|\\overline{U}Uh\\|\\|Uh\\|\n\\]\nand \n\\[\n\\|Uh\\|^2\\le\\|h\\|\\|\\overline{U}Uh\\|\\le\\|h\\|^2\\|\\overline{U}U\\|\\le\\|\\overline{U}\\|\\|U\\|\\|h\\|^2=\\|U\\|^2\\|h\\|^2.\n\\]\n\n(ii) This is immediate from Lemma~\\ref{lem:0810201}(i), as noted in Remark~\\ref{rem:0912201}.\n\n\n\n(iii)  Let $B=(B_1,B_2)=r(h,k)=([\\cdot hk],[\\cdot kh])$. Then \n\\[\n\\langle f\\cdot B|g\\rangle=\\langle B_1f|g\\rangle=r(g,B_1f)=r(g,[fhk])=([\\cdot g[fhk]],[\\cdot[fhk]g])\n\\]\nand\n\\begin{eqnarray*}\n\\langle f|g\\rangle\\circ B&=&r(g,f)\\circ(B_1,B_2)\\\\\n&=&([\\cdot gf],[\\cdot fg])\\circ ([\\cdot hk],[\\cdot kh])\\\\\n&=& ([\\cdot hk],[\\cdot kh])([\\cdot gf],[\\cdot fg])\\\\\n&=& ([\\cdot hk][\\cdot gf],[\\cdot fg][\\cdot kh])\\\\\n&=&([[\\cdot gf]hk],[[\\cdot kh]fg]),\n\\end{eqnarray*}\nas required.\n\n(iv) See section~\\ref{sec:0906201}.\n\\end{proof}\n\n\n\n\n\n\\begin{lemma}%2.4\n\\label{lem:0811201}\nIf $M$ is a C*-ternary ring with decomposition $M= M_+\\oplus M_-$, then $M_+$ is a right $R(M)^{op}$-Hilbert module.\n\\end{lemma}\n\\begin{proof}\nIn  Remark~\\ref{rem:0831201}, with $\\alpha(f,g)=\\langle f|g\\rangle=r(f,g)$, (i) holds by Proposition~\\ref{prop:0912201}(iii), and (ii) and (iv) follow from the definition of $\\alpha$.  To prove (iii) in Remark~\\ref{rem:0831201}, it suffices to show that\n$[hgf]=h\\cdot \\langle f|g\\rangle$. But $h\\cdot \\langle f|g\\rangle=h\\cdot ([\\cdot gf],[\\cdot fg])=[hgf]$. Thus $M_+=\\{f\\in M:\\alpha(f,f)\\ge 0\\}$ and is therefore a  right $R(M)^{op}$-Hilbert module.\n\\end{proof}\n\n\\begin{lemma}%2.5\n\\label{lem:0913202}\nA surjective homomorphism between C*-ternary rings is contractive.\n\\end{lemma}\n\\begin{proof}\nLet $\\phi:M\\to N$ be a surjective homomorphism of C*-ternary rings $M=M_+\\oplus M_-$ and $N= N_+\\oplus N_-$. Then $N=\\phi(M_+)\\oplus \\phi(M_-)$ is the sum of two orthogonal ideals.  Also, $\\phi(M_+)\\simeq M_+/\\ker\\phi|_{M_+}$ which is isomorphic to a quotient of a TRO, which, by (\\cite[Proposition 2.2]{EffOzaRua01}) is a TRO.  Similarly $\\phi(M_-)\\simeq M_-/\\ker\\phi|_{M_-}$  is anti-isomorphic to a TRO.  So by uniqueness of the Zettl decomposition, $\\phi(M_{\\pm})=N_{\\pm}$.\nNote that a TRO homomorphism of TROs is contractive (\\cite[Proposition 2.1]{EffOzaRua01}), and since $\\phi$ restricts to a homomorphism of $M_{\\pm}$ onto $N_{\\pm}$, $\\phi|_{M_{\\pm}}$ is contractive.  For example, if $\\psi$ is an isomorphism of $M_+$ onto a TRO $V$, and $\\xi$ is an isomorphism of $N_+$ onto a TRO $W$, then $\\xi\\circ \\phi\\circ \\psi^{-1}$ is a homomorphism from $V$ to $W$, hence contractive, and $\\|\\phi(x_+)\\|=\\|\\xi\\phi(x_+)\\|=\\|(\\xi\\circ \\phi\\circ \\psi^{-1})(\\psi(x_+)\\|\\le\\|\\psi(x_+)\\|=\\|x_+\\|$.\nThus, \n if $x=x_++x_-\\in M$,  \n$\\|\\phi(x)\\|=\\|\\phi(x_+)+\\phi(x_-)\\|=\\max(\\|\\phi(x_+)\\|,\\|\\phi(x_-)\\|)\\le \\max(\\|x_+\\|,\\|x_-\\|)=\\|x\\|$. \n\\end{proof}\n\n\\begin{lemma}%2.6\n\\label{lem:0912201}\nLet $\\phi:M\\to N$ be a surjective homomorphism between C*-ternary rings $M$ and $N$. There is a *-homomorphism $\\calA(\\phi):\\calA(M)\\to \\calA(N)$  defined by \n\\begin{equation}\\label{eq:0911201}\n\\calA(\\varphi)\\left(\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] \\right)\n=\n\\left[\\begin{matrix}\n\\varphi_{11}(A)&\\varphi(f)\\\\\\smallskip\n\\overline{\\varphi(g)}&\\varphi_{22}(B)\n\\end{matrix}\\right] ,\n\\end{equation}\nwhere if \n%\\begin{equation}\\label{eq:0911202}\n$A=\\sum_i([g_ih_i\\cdot],[h_ig_i\\cdot])\\in L(M)$,\n%\\end{equation}\n\\begin{equation}\\label{eq:0911203}\n \\varphi_{11}(A)=\\sum_i([\\varphi(g_i)\\varphi(h_i)\\cdot],[\\varphi(h_i)\\varphi(g_i)\\cdot])\\in L(N),\n\\end{equation}\nand if  $B=\\sum_i([\\cdot g_ih_i],[\\cdot h_ig_i])\\in R(M)$,\n\\[\n \\varphi_{22}(B)=\\sum_i([\\cdot \\varphi(g_i)\\varphi(h_i)],[\\cdot \\varphi(h_i)\\varphi(g_i)])\\in R(N).\n\\]\n\\end{lemma}\n\\begin{proof}\nIt is enough to show that the mapping (\\ref{eq:0911201}) is well-defined, which will follow from $\\|\\varphi_{11}(A)\\|\\le \\|A\\|$ and  $\\|\\varphi_{22}(B)\\|\\le \\|B\\|$. The rest of the proof involves straightforward  but tedious algebra. In fact the contractivity of $\\phi_{11}$ and of  $\\phi_{22}$ follow by direct calculation from Lemma~\\ref {lem:0913202} and surjectivity of $\\phi$.\n\\end{proof}\n\n\n\n\\begin{proposition}\\label{prop:0910201}%2.7\nIf $M$ is a C*-ternary ring, then $\\calA(M)$ is a C*-algebra.\n\\end{proposition}\n\\begin{proof}\nWith $M=M_+\\oplus M_-$, $\\calA(M_+)$ is isomorphic to a C*-algebra by Lemma~\\ref{lem:0811201} and Proposition~\\ref{prop:0912201}(iv).\nIf $M_-$ is anti-isomorphic to a TRO $V$, then by Lemma~\\ref{lem:0912201}, $\\calA(M_-)$ is *-isomorphic to $\\calA(V)$, which by Example~\\ref{ex:0912201} is *-isomorphic to the linking algebra of $V$.\nThus\n$\\calA(M)=\\calA(M_+)\\oplus \\calA(M_-)$ is a C*-algebra.\n\\end{proof}\n\n\\section{Ternary categories}\\label{sec:1001201}\n\n\n\n\n\n\n\\subsection{Ternary categories}\n\n\\begin{definition}%3.1\n\\label{def:1005201}\nA {\\em ternary category} $\\mathcal{C} = \n(\\operatorname{Ob}(\\mathcal{C}), ~  \\operatorname{Mor}(\\mathcal{C}), ~ \\circ)$ \nconsists of the following entities.   \n\\begin{itemize}\n\\item A class $\\operatorname{Ob}(\\mathcal{C})$ of {\\em objects}.  \n\\item For each $X, Y$ in $\\operatorname{Ob}(\\mathcal{C})$,  \n  a class $\\operatorname{Hom}(X, Y)$ \n  of {\\em morphisms} (or {\\em maps})  \n   from $X$ to $Y$, with $f$ in  $\\operatorname{Hom}(X, Y)$ written $X \\stackrel{f}{\\to} Y$ or $f\\colon X \\to Y$. The class of all morphisms is denoted $\\operatorname{Mor}(\\mathcal{C})$, so $\\operatorname{Hom}(X, Y)\\subseteq \\operatorname{Mor}(\\mathcal{C})$.    \n   \\item For each $X, Y, Z, W$ in \n  $\\operatorname{Ob}(\\mathcal{C})$, a function \n\\begin{center}\n\\begin{tabular}{ r c l }\n $\\operatorname{Hom}(X, Y)\\times \\operatorname{Hom}(Z, Y) \\times \\operatorname{Hom}(Z, W) $ & $\\to$ & $\\operatorname{Hom}(X, W)$ \\\\ \n $(f, g, h)$ & $\\mapsto$ & $ h \\circ g^* \\circ  f ~ = ~ h g^* f, $    \n\\end{tabular}\n\\end{center}    \ncalled {\\em morphism composition} (or just {\\em composition}), \nwhich is associative  for all composable morphisms in the category, namely  \n\\begin{equation}\\label{eq:1018201}\n(l k^* h) g^* f  =  \nl  (g h^* k)^* f  =  \nl  k^* (h g^* f) \n\\end{equation}\nwhenever \n\\[\nX\\stackrel{f}{\\rightarrow}Y\\stackrel{g}{\\leftarrow}Z\\stackrel{h}{\\rightarrow}W\\stackrel{k}{\\leftarrow}U\\stackrel{\\ell}{\\rightarrow}V.\n\\]\n  To be precise, because of the twist in the middle term, (\\ref{eq:1018201}) is defined only if $U=Y$, that is, for $f\\in (X,Y),k\\in (Y,W),h\\in (Z,W), g\\in (Z,Y),\\ell\\in (Y,V)$.\n  \\end{itemize}\n\\end{definition}\n\n\nA {\\it linear ternary category} is a ternary category in which $\\operatorname{Hom}(X, Y)$ is a linear space over a field $\\IK$ and composition is linear in the outer variables and conjugate linear in the middle variable.\nIn a linear ternary category, $\\operatorname{Hom}(X, Y)$ is an associative triple system  (see subsection~\\ref{sub:0910201}). \n\n\n\\begin{example}%3.2\nIf $M$ is an associative triple system, then  the category with $M$ as its sole object, and $M$ as its morphisms, is a $\\IK$-linear ternary category with composition being the triple product in $M$.\n\\end{example}\n\n\\begin{example}%3.3\nThe class of all sets (as objects)        \ntogether with all binary relations between them (as morphisms), with composition of relations, forms a category which we denote by $\\mathcal{R}$. Thus, if $X, Y$ are sets,  $\\operatorname{Hom}(X, Y) = P(X\\times Y)$ is the power set of $X\\times Y$.  If $F \\subseteq X \\times Y$ is a relation then  $F^* = \\{ (y, x)  ~ : ~ (x, y)\\in F \\} \\subseteq Y \\times X$ is its converse.  We have $(F^*)^*=F$ and $(G \\circ F)^*= F^* \\circ G^*$ for all composable relations. It follows that $\\mathcal{R}$ is a dagger category (i.e. category with involution).  It can be viewed as a ternary category with the natural (ternary) composition of relations, $F \\circ G^* \\circ H$.    \n\\end{example}\n\n\\begin{definition}%3.4\nLet $\\calC$ be a $\\IK$-linear ternary category and $\\mathcal J$ a subcategory.  Then $\\mathcal J$ is  an  (ternary) ideal of $\\mathcal C$  if for objects $X,Y,Z,W$ of $\\mathcal J$, $(X,Y)_{\\mathcal J}$ is a linear subspace of $(X,Y)$ and \n\n\\[\n(Z,W)_{\\mathcal J}\\circ (Z,Y)\\circ (X,Y)\\subset (X,W)_{\\mathcal J},\\smallskip\n\\]\n\\[\n  (Z,W)\\circ (Z,Y)_{\\mathcal J}\\circ (X,Y)\\subset (X,W)_{\\mathcal J},\\smallskip\n\\]\n\\[\n  (Z,W)\\circ (Z,Y)\\circ (X,Y)_{\\mathcal J}\\subset (X,W)_{\\mathcal J}.\n\\]\n\nIf $\\calJ$ is an ideal in $\\calC$, the quotient $\\calC/\\calJ$ is the category with the same objects as $\\calC$ and with morphism sets the quotient spaces $[X,Y]:=(X,Y)/(X,Y)_{\\calJ}$. There is a natural quotient functor from $\\calC$ to $\\calC/\\calJ$, given by $(X,Y)\\ni f\\mapsto \\overline f=f+(X,Y)_{\\calJ}\\in [X,Y]$. The composition in $\\calC/\\calJ$ is given by\n\\[\n(\\overline f,\\overline g,\\overline h)\\mapsto \\overline{[hgf]},\n\\]\nand is easily seen to be well-defined and associative in the sense of Definition~\\ref{def:1005201}.\n\\end{definition}\n\n\n\\begin{remark}%3.5\n\\ \n\\begin{itemize}\n\\item As in the case of non-unital categories (cf.\\ \\cite[Definition 3.1]{Mitchener02}), there are no identity morphisms per se in ternary categories. However, one can call a family of morphisms $\\{u_X: X\\hbox { object of } \\calC\\}$ in a ternary category $\\calC$ which satisfy $u_Yu_Y^*f=f=fu_X^*u_X$ a ``unitary'', and more generally \nmorphisms $(u_X)$ which satisfy $u_X=u_Xu_X^*u_X$ ``tripotents,'' or ``partial isometries''.\\footnote{In this case, a maximal tripotent in a T*-category (Definition~\\ref{def:0804201}) would satisfy \n\\[\n  [u_Yu_Y^*f]+[fu_X^*u_X]=f+[[u_Yu_Y^*f]u_X^*u_X]\n  \\]\nfor $f\\in (X,Y)$. Tripotents and Peirce decompositions in T*-categories are worthy of further study.}\\item A {\\it unitary ternary category}  is a ternary category $\\calC$ containing a unitary element $(u_X)$. In this case, one has a (unital) category $\\calA$ with the same objects and the same morphisms as $\\calC$, but with composition given by $f\\circ g=fu_Y^*g$ for $g\\in (X,Y)$, $f\\in (Y,Z)$. \n\\end{itemize}\n\\end{remark}\n \n\n\n\n\\begin{example}%3.6\nThe class of all  complex  Hilbert spaces (as objects)  \ntogether with all bounded linear operators  \nbetween them (as morphisms), with morphism composition $(f, g, h) \\mapsto hg^*f$, \nforms a unitary ternary category which we will denote by $\\mathcal{H}_+$ (cf.\\ Example~\\ref{ex:0821201} and  \nRemark~\\ref{def:0812201}(iii)). \n\\end{example}\n\n\n\\begin{definition} %3.7\nLet $\\mathcal{C}$ and $\\mathcal{D}$ be ternary categories.   \nA  ({\\em covariant}) {\\em  functor} $F \\colon \\mathcal{C} \\to \\mathcal{D}$ (or ternary functor for emphasis) consists of the following entities.\n\\begin{itemize}\n\t\\item  A function\n  $\\operatorname{Ob}(\\mathcal{C})\\to \\operatorname{Ob}(\\mathcal{D})$ \n  that associates to each object $X$ in $\\mathcal{C}$ an object \n  $F(X)$  in $\\mathcal{D}$.\n\t\\item For each $X,Y$ in $\\operatorname{Ob}(\\mathcal{C})$, \n\t a function $\\operatorname{Hom}(X, Y) \\to \\operatorname{Hom}(F(X), F(Y))$ \n\t that associates to each morphism $X \\overset{f}{\\to} Y$ \n\t in $\\mathcal{C}$  a morphism $F(X) \\overset{F(f)}{\\longrightarrow} F(Y)$ \n\t in $\\mathcal{D}$ such that\\footnote{The reader is reminded  that $g^*$ and $F(g)^*$ are symbolic notations for the middle term of a ternary composition, so have no meaning if isolated. An exception occurs, for example,  in Remark~\\ref{rem:0820201}.}\n\t \\[F(h \\circ g^* \\circ  f) = F(h) \\circ F(g)^* \\circ  F(f)\\]  \nfor all composable morphisms $f, g, h$ in $\\mathcal{C}$.  \n\\end{itemize}\n\\end{definition}\n\n\n\\subsection{The linking category of a linear ternary category}\n\n\nLet $\\calC$ be a $\\IC$-linear ternary category with objects $X,Y, Z,\\ldots$ and morphisms  $(X,Y), (Z,W),\\ldots$.\nDenote the composition of morphisms $f\\in (X,Y), g\\in (Z,Y), h\\in (Z,W)$ by $[hgf]$. \n\nFor a pair of objects $X,Y$, $(X,Y)$ is an associative triple system, so all of the machinery in subsection~\\ref{sub:0910201} is available by replacing $M$ there by $(X,Y)$.  Thus,  \n\\[\nE(X,Y):=\\hbox{End}\\, ((X,Y))\\oplus[\\overline{ \\hbox{End}\\, ((X,Y))}]^{op},\n\\]\nand for $g,h\\in (X,Y)$, \n\\[\n\\ell(g,h)=(L(g,h), L(h,g))=([gh\\cdot],[hg\\cdot])\\in E(X,Y),\n\\]\n\\[\nr(g,h)=(R(h,g), R(g,h))=([\\cdot gh],[\\cdot hg])\\in E(X,Y)^{op},\n\\]\n\\[\nL=L(X,Y)=\\hbox{span}\\, \\{\\ell(g,h): g,h\\in (X,Y)\\}\\subset E(X,Y), \\hbox{ and }\n\\]\n\\[\nR=R(X,Y)=\\hbox{span}\\, \\{r(g,h): g,h\\in (X,Y)\\}\\subset E(X,Y)^{op}.\n\\]\n\nRecall that there are two reverses of multiplication in the definition of $E(X,Y)^{op}$, \nand involutions are defined on $E(X,Y)$ and $E(X,Y)^{op}$ by \n$\\overline{(A_1,A_2)}=(A_2,A_1$ and $\\overline{(B_1,B_2)}=(B_2,B_1)$.\n\nFrom Lemmas~\\ref{lem:0913201} and~\\ref{lem:0810201},\n\\begin{itemize}\n\\item $\n L$  is a *-subalgebra of $ E(X,Y)$  and $ R$  is a *-subalgebra of $E(X,Y)^{op}$.\\smallskip\n\\item\n$\n (X,Y)\\hbox{  is a left } E(X,Y)\\hbox{-module  via }\n (A,f)\\mapsto A\\cdot f=A_1f,$\\\\\n $\n \\hbox{ a right }E(X,Y)^{op}\\hbox{-module via }\n(f,B)\\mapsto f\\cdot B=B_1f,\n$\n$\n \\hbox{ and  an } (L,R)\\hbox{-bimodule};\n  $\\smallskip\n  \\item\n   $\\overline{(X,Y)}$ is a left $E(X,Y)^{op}$-module  via \n$\n (B,\\overline{f})\\mapsto B\\cdot \\overline{f}=\\overline{B_2f},\n $\\\\\n   a right $E(X,Y)$-module via\n$\n (\\overline{f},A)\\mapsto \\overline{f}\\cdot A=\\overline{A_2f},\n $\n  and an an $(R,L)$-bimodule.\n    \\end{itemize}\n\n\nGiven objects $X,Y$ in a linear ternary category $\\calC$, let \n\\[\n\\calA=\\calA(X,Y)=L(X,Y)\\oplus(X,Y)\\oplus\\overline{(X,Y)}\\oplus R(X,Y)\n\\]\nand write the elements $a$ of $\\calA$ as matrices\n\\[\na=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] ,  (A\\in L(X,Y), B\\in R(X,Y), f,g \\in (X,Y)).\n\\]\n\nDefine multiplication and involution in $\\calA$ by\n\\begin{equation}\\label{eq:0910201}\n\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\nA'&f'\\\\\n\\overline{g'}&B'\n\\end{matrix}\\right]\n=\\left[\\begin{matrix}\nAA'+\\ell(f,g')&A\\cdot f'+f\\cdot B'\\\\\n\\overline{g}\\cdot A'+B\\cdot\\overline{g'}&r(g,f')+B\\circ B'\n\\end{matrix}\\right]\n\\end{equation}\nand\n\\begin{equation}\\label{eq:0910202}\n\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]^\\#=\\left[\n\\begin{matrix}\n\\overline{A}&g\\\\\n\\overline{f}&\\overline{B}\n\\end{matrix}\\right].\n\\end{equation}\n\nFrom Lemma~\\ref{lem:0807201},\n$\\calA(X,Y)$ is an associative *-algebra and for $f,g,h\\in (X,Y)$,\n\\[\n\\left[\n\\begin{matrix}\n0&f\\\\\n0&0\n\\end{matrix}\\right]\n\\left[\n\\begin{matrix}\n0&g\\\\\n0&0\n\\end{matrix}\\right]^\\#\n\\left[\n\\begin{matrix}\n0&h\\\\\n0&0\n\\end{matrix}\\right]\n=\n\\left[\n\\begin{matrix}\n0&[fgh]\\\\\n0&0\n\\end{matrix}\\right].\n\\]\n\n\\begin{definition}\\label{def:0810201}%3.8\nGiven a linear ternary category $\\calC$, the {\\it linking category} $A_{\\calC}$  of $\\calC$ is as follows. The objects of the category $A_{\\calC}$ are the same\\footnote{Or could be considered as the same as the objects of $\\calC$, for example, in one to one correspondence with the objects of $\\calC$.} as the objects of $\\calC$.  The morphism set  $\\operatorname{Hom}(X,Y)$ is defined to be $\\{0\\}$ if $X\\ne Y$, and $\\operatorname{Hom}(X,X)=\\calA(X,X)$, with composition  as follows. If $a\\in \\operatorname{Hom}(X,Y)$ and $b\\in \\operatorname{Hom}(Y,Z)$, then\n$b\\circ a$ must be $\\{0\\}$ unless $X=Y=Z$, in which case $b\\circ a$ is defined to be the product $ab$ in $\\calA(X,X)$. \n\\end{definition}\n\nIn general, $A_{\\calC}$ is a non unital category. By adjoining the identity operator to $L$ and to $R$, one can define a unital linking category, but this is not needed for our purposes.\n\n\\begin{remark}\\label{rem:0814201}%3.9\nThe category $A_{\\calC}$ can be considered as a ternary category under the composition $[abc]=ab^\\#c$ and, by Lemma~\\ref{lem:0807201},  we obtain a linear ternary functor $F$ from $\\calC$ to $A_{\\calC}$ by associating the object $X$ of $\\calC$ to the object $X$ of $A_{\\calC}$ and the morphism $f\\in (X,Y)$ to 0 if $X\\ne Y$ and otherwise to the morphism $\\left[\n\\begin{matrix}\n0&f\\\\\n0&0\n\\end{matrix}\\right]\\in\\calA(X,X).\n$\n\\end{remark}\n\n\nIt is possible to define the morphism sets of $A_{\\calC}$ as $(X,Y)_{A_{\\calC}}=\\calA(X,Y)$ even if $X\\ne Y$.  In that case, we could then define $b\\circ a$\nto be 0 unless $X=Y=Z$ and otherwise to be the product $ab$ in $\\calA(X,X)$.  In either case, the price paid %for defining $\\calA(X,Y)$ to be zero if $X\\ne Y$\n is that the linear ternary functor of $\\calC$ into $A_{\\calC}$ in Remark~\\ref{rem:0814201} is not faithful (see Theorem~\\ref{thm:0810201} below).\n\n\n\n\\begin{example}%3.10\n\\label{ex:0818201}\nIf $M$ is an associative triple system, $A(M)$  its standard embedding  (see Remark~\\ref{rem:0912201}) and $\\calC$ is the category with $M$ as its sole object and $M$ as its morphisms with composition given by the triple product in $M$, then by \\cite[Satz 1]{Loos72} (reproduced in  \\cite[Theorem 2, p.30]{Meyberg72}), $A_{\\calC}$ is the category with $A(M)$ as its only object and the elements of $A(M)$ as morphisms with composition being multiplication in the associative algebra $A(M)$.\n\\end{example}\n\n\\begin{definition}%3.11\n\\label{def:0813201}\nIf the linear ternary category $\\calC$ is normed, that is, if $(X,Y)$ is a normed space and $\\|f\\circ g^*\\circ h\\|\\le \\|f\\|\\|g\\|\\|h\\|$, then the {\\it normed} linking category  of $\\calC$ is defined in the same way but  with $R$ and $L$ replaced by their closures in $B((X,Y))$. In this case, the modules in Lemma~\\ref{lem:0810201} are continuous modules, and Banach modules if $(X,Y)$ is a Banach space.\n\\end{definition}\n\n\n\n\n\n\n\n\n\\section{Operator categories}\\label{sec:1001202}\n\n\\subsection{C*-categories}In this subsection we recall the notion of C*-category from \\cite{GLR85} and \\cite{Mitchener02}.\n\n\\begin{definition}\\label{def:0804202}%4.1\nA {\\em C*-category} \nis a  $\\IC$-linear category\n $\\mathcal{C} = \n(\\operatorname{Ob}(\\mathcal{C}), ~  \\operatorname{Mor}(\\mathcal{C}), ~ \\circ)$ \n with the following additional properties.\n\\begin{description}\n\\item[(i)]  $(X,Y)$ is a complex  Banach space.\\medskip\n\\item[(ii)]  Composition is bilinear.\\footnote{This is part of  the definition of $\\IC$-linear, but included here for easy reference.}\\medskip\n\\item[(iii)] There is an involution, that is, a collection of maps $(X,Y)\\ni f\\mapsto f^*\\in (Y,X)$ which are conjugate linear, involutive, and satisfy $(g\\circ f)^*=f^*\\circ g^*$ for $f\\in (X,Y), \\ g\\in (Y,Z)$.\\medskip\n\\item[(iv)] $\\|g\\circ f\\|\\le \\|f\\|\\|g\\|$ for $f\\in (X,Y), \\ g\\in (Y,Z)$. \\medskip\n\\item[(v)] $\\|h\\|^2=\\|h^*h\\|$ for $h\\in (X,Y)$.\\medskip\n\\item[(vi)] For all $h\\in  \\operatorname{Hom}(X,Y)$,\n$h^*h=g^*g$ for some $g\\in \\operatorname{Hom}(X,X).$ \n\\end{description}\nA {\\it C*-functor} is a linear functor between C*-categories which satisfies $F(f^*)=F(f)^*$.\n\\end{definition}\n\nFor any object $X$ in a C*-category, $(X,X)$ is a C*-algebra, and as a consequence of Theorem~\\ref{thm:0724201} and Remark~\\ref{rem:0820201},  $(X,Y)$ is a C*-ternary ring which is isomorphic to a TRO.  For any C*-algebra $A$, the category with $A$ as its only object, and $A$ as it morphisms, with composition and involution being multiplication and involution in $A$, is a C*-category.\n\n\\begin{example}\\label{ex:0821201}%4.2\nThe class of all  complex  Hilbert spaces (as objects)  \ntogether with all bounded linear operators  \nbetween them (as morphisms), with morphism composition $(f, g) \\mapsto f\\circ g$, \nforms a C*-category which we denote by $\\mathcal{H}$. \n\\end{example}\n\n\\begin{example}%4.3\nLet $A$ be a $C^*$-algebra and let  $(H, \\rho)$, $(K, \\sigma)$  be a pair of $^*$-representations of $A$    \non Hilbert spaces $H, K$.  An operator $t \\in \\mathcal B(H, K)$ with $ t \\rho(a) = \\sigma(a) t$, for all $a\\in A$,    \nis called an {\\em intertwiner}, the collection of all intertwiners  between $\\rho$ and $\\sigma$ is denoted by   \n$\\operatorname{Hom}(\\rho,  \\sigma)$. If $t \\in \\operatorname{Hom}(\\rho,  \\sigma)$ then \n$t^* \\in \\operatorname{Hom}(\\sigma, \\rho)$, it follows that  \n$\\operatorname{Hom}(\\rho,  \\sigma)$\nis a weakly closed TRO contained in  $\\mathcal B(H, K)$ \nand  $\\operatorname{Hom}(\\rho, \\rho)$  \nis a $C^*$-subalgebra of $\\mathcal B(H)$.  The class of all  $^*$-representations of $A$   \non Hilbert spaces (as objects)    \ntogether with intertwiners of these representations (as morphisms)  \nis a $C^*$-category, denoted $\\operatorname{Rep}(A)$,  \nwhich can be viewed as a $T^*$-category  \nwith the natural (ternary) composition of intertwiners. \n\\end{example}\n\n\\begin{example}%4.4\nLet $\\Gamma$ be a countable discrete group       \nand let $(H, \\rho)$, $(K, \\sigma)$       \nbe a pair of unitary representations of $\\Gamma$   \non Hilbert spaces $H, K$. The collection   \n$\\operatorname{Hom}(\\rho, \\sigma)$ of       \nintertwining operators         \nbetween $\\rho$ and $\\sigma$, i.e.   \noperators $t \\in \\mathcal B(H, K)$ with  \n$t \\rho(g) = \\sigma(g) t$  for all $g \\in \\Gamma$,   \nis a weakly closed TRO contained in  $\\mathcal B(H, K)$,    \nand $\\operatorname{Hom}(\\rho, \\rho)$   \nis a von Neumann subalgebra of $\\mathcal B(H)$.   \nThe class of all unitary representations of $\\Gamma$  \non Hilbert spaces (as objects)     \ntogether with intertwiners of these representations (as morphisms)   \nis a $C^*$-category, denoted $\\operatorname{Rep}(\\Gamma)$,    \nwhich can be viewed as a $T^*$-category   (see Definition~\\ref{def:0804201})\nwith the natural (ternary) composition of intertwiners.   \n\\end{example}\n \n It is shown in \\cite{GLR85}  that  \nevery $C^*$-category $\\mathcal C$ can be realized as a ``concrete'' \n$C^*$-sub-category of $\\mathcal  H$ (see also \\cite{Mitchener02}, which among other things, gives the proof of Theorem~\\ref{thm:0724201} below in more detail). Theorem~\\ref{thm:0724201} can be viewed as a generalization of the  celebrated\nGelfand-Naimark representation theorem which says that every abstract $C^*$-algebra can be realized as a concrete $C^*$-subalgebra of some $B(H)$, and it serves as the motivation for the results  in this section.\n\n\n\\begin{theorem}%4.5\n[Proposition 1.14 in \\cite{GLR85}] \\label{thm:0724201}\nFor every C*-category $\\mathcal A$, there is a faithful C*-functor from $\\mathcal A$ to $\\mathcal H$.\n\\end{theorem}\n\n\\subsection{T*-categories}\n\n\\begin{definition}\\label{def:0804201}%4.6\nA {\\em T*-category} \nis a ternary category\n $\\mathcal{C} = \n(\\operatorname{Ob}(\\mathcal{C}), ~  \\operatorname{Mor}(\\mathcal{C}), ~ \\circ)$ \n with the following additional properties\\footnote{Items (ii) and (iii) are parts of the definition of ternary category, but included here for easy reference.}.\n\n\\begin{description}\n\\item[(i)]  $(X,Y)$ is a complex  Banach space.\\medskip\n \\item[(ii)] For each $X, Y, Z, W$ in \n  $\\operatorname{Ob}(\\mathcal{C})$, a function \n\\begin{center}\n\\begin{tabular}{ r c l }\n $\\operatorname{Hom}(X, Y)\\times \\operatorname{Hom}(Z, Y) \\times \\operatorname{Hom}(Z, W) $ & $\\to$ & $\\operatorname{Hom}(X, W)$ \\\\ \n $(f, g, h)$ & $\\mapsto$ & $[ h \\circ g^* \\circ  f] $    \n\\end{tabular}\n\\end{center}    \ncalled {\\em morphism composition} (or just {\\em composition}), \nwhich is associative in the sense that  \n$[[(l k^* h)] g^* f]  =  \n[l[  g h^* k]^* f]  =  \n[l  k^* [h g^* f]] $, whenever the compositions are defined (see Definition~\\ref{def:1005201}). \\medskip\n\\item[(iii)]   Composition is linear in the outer variables and conjugate linear in the middle variable. \n\\item[(iv)] $\\|[gh^*f]\\|\\le \\|h\\|\\|f\\|\\|g\\|$ for $f\\in (X,Y),h\\in(Z,Y),g\\in (Z,W)$.\\medskip\n\\item[(v)]  $\\|hh^*h\\|=\\|h\\|^3$,\\ for $h\\in (X,Y)$.\\medskip\n\\end{description}\nA {\\it $T^*$-functor}  is a linear functor between T*-categories.  A T*-category is a {\\it TW*-category}\nif each morphism set is a dual space.\n\\end{definition}\n\n\n\nFor any objects $X,Y$ in a T*-category (resp.\\ TW*-category), $(X,Y)$ is a C*-ternary ring (resp.\\ W*-ternary ring). \nA %Hestenes ternary ring $X$, in particular a \n$C^*$-ternary ring $X$, or its concrete analogue, a ternary ring of operators (TRO), can be viewed as a T*-category with one object and the elements of $X$ themselves as morphisms, with morphism composition given by the ternary operation in $X$.\n\nAs mentioned in subsection~\\ref{sub:0913201},\nZhong-Jin Ruan \\cite{Ruan04} presented a classification scheme and proved various structure theorems for weakly closed ternary rings of operators (W$^*$-TROs) of particular types.  A W$^*$-TRO $V$  of type I, II, or III was defined according to the Murray-von Neumann type of its linking von Neumann algebra $R_V$, defined in subsection~\\ref{sub:0913202}.\n\nA W$^*$-TRO $V$ is of type I, II, or III according as $R_V$ is a von Neumann algebra of the corresponding type. A W$^*$-TRO of type II is said to be of type $II_{\\epsilon,\\delta}$, where $\\epsilon,\\delta \\in \\{1,\\infty\\}$, if $M(V)$ is of type \n$II_{\\epsilon}$ and $N(V)$ is of type $II_{\\delta}$. A sample result is that a W*-TRO of  type I is TRO-isomorphic to $\\oplus_\\alpha L^\\infty(\\Omega_\\alpha, B(K_\\alpha,H_\\alpha))$  (\\cite[theorem 4.1]{Ruan04}).\n\n\\begin{definition}%4.7\nA TW*-category is of type I (resp. II,III) if each morphism set (i.e.\\ C*-ternary ring)  $(X,Y)$ is isomorphic as a C*-ternary ring (for example isomorphic or anti-isomorphic) to a W*-TRO of type I (resp. II,III). \n\\end{definition}\n\nIn connection with Theorem~\\ref{thm:0724201}, it is also proved (\\cite[Proposition 2.13]{GLR85}) that for every W*-category there is a faithful normal C*-functor into $\\calH$, which is obviously a W*-category.\nWhat is missing however, as mentioned in subsection~\\ref{sub:0913201}, is a type classification of W*-categories into W*-categories of types I, II, and III. We remedy this in Propositions~\\ref{prop:0910202} and \\ref{prop:0910203}.%One reason for this is that although morphism spaces $(X,X)$ are von Neumann algebras, if $X\\ne Y$, as a consequence of Theorem~\\ref{thm:0724201},  $(X,Y)$ is in general a W*-TRO, and it is necessary to go out of the category of  W*-categories.  %We shall use the classification theorem of Ruan \n\n\n\n\n\n\n\n\n\n\n\\begin{remark}\\label{rem:0820201}%4.8\nA C*-category (resp. W*-category) becomes a T*-category (resp. TW*-category) with ternary product $[hgf]=f\\circ g^*\\circ h$, and by Theorem~\\ref{thm:0724201} (resp. \\cite[Proposition 2.13]{GLR85}), each morphism set $(X,Y)$ in a C*-category (resp. W*-category) is isomorphic to a TRO (resp. W*-TRO). \n\\end{remark}\n\n\n\\begin{proposition}%4.9\n\\label{prop:0910202}\nEach W*-category $\\calC$,  considered as a TW*-category, is the direct sum $\\calC_I\\oplus \\calC_{II}\\oplus\\calC_{III}$, where $\\calC_i$, $i=I,II,III$, is a TW*-category of type $i$.\n\\end{proposition}\n\\begin{proof}\nBy \\cite[Proposition 2.13]{GLR85}, in a W*-category, each morphism space $(X,Y)$ is isomorphic to a W*-TRO.  By Ruan's classification $(X,Y)=(X,Y)_I\\oplus (X,Y)_{II}\\oplus (X,Y)_{III}$ and it suffices to take $\\calC_i$ to be the T*-category with morphism sets $(X,Y)_i$.\n\\end{proof}\n\n\n\nLet $\\calC$ be a T*-category.  Since $\\calA(X,Y)$ plays no role in what follows if $X\\ne Y$, we will focus on the morphism sets $(X,X)$ and for notation's sake, denote $(X,X)$ by $\\tilde X$, $L(X,X)$ by $L$,  $R(X,X)$ by $R$, and $\\calA(X,X)$ by $\\calA$. Recall that $\\tilde X$ is a left $L$-module via $L\\times \\tilde X\\ni (A,f)\\mapsto A\\cdot f=A_1f \\in \\tilde X$ and a right $R^{op}$-module via $ \\tilde X\\times R \\ni (f,B)\\mapsto f\\cdot B=B_1f \\in \\tilde X$, and that\n\\[\n\\calA=\\{a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] : A\\in L, B\\in R, f,g \\in \\tilde X\\},\n\\]\nis an algebra with multiplication (\\ref{eq:0910201}) and  involution  (\\ref{eq:0910202}).\n\n\\begin{remark}%4.10\nIf $\\calC$ is a T*-category and $\\calJ$ is a closed ideal (meaning $(X,Y)_{\\calJ}$ is a closed subspace of the Banach space $(X,Y)$), then $\\calC/\\calJ$ is a T*-category. \n\\begin{proof} Items (i)-(iii) in Definition~\\ref{def:0804201} are clear. To prove (iv), let $\\overline f\\in [X,Y], \\overline g\\in[Z,Y], \\overline h\\in[Z,W]$ and choose $f'\\in (X,Y)_{\\calJ}$, $g'\\in (Z,Y)_{\\calJ}$, $h'\\in (Z,W)_{\\calJ}$\nsuch that $\\|f+f'\\|\\le \\|\\overline f\\|+\\epsilon $, $\\|g+g'\\|\\le \\|\\overline g\\|+\\epsilon $, $\\|h+h'\\|\\le \\|\\overline h\\|+\\epsilon$.\nThen \n\\begin{eqnarray*}\n\\|[\\overline h\\overline g\\overline f]\\|&=&\\|[\\overline{h+h'},\\overline{g+g'},\\overline{f+f'}]\\|=\\|\\overline{[h+h',g+g',f+f']}\\|\\\\\n&\\le& \\|   [h+h',g+g',f+f']\\|\\le\\|[h+h'\\|\\|g+g'\\|\\|f+f'\\|\\\\\n&\\le&\\|\\overline h\\|\\|\\overline g\\|\\|\\overline f\\|+O(\\epsilon).\n\\end{eqnarray*}\nAs for (v), if $\\overline h\\in [X,Y]$, then \n\\begin{eqnarray*}\n\\|\\overline h\\|^3&=& \\inf_{k\\in (X,Y)_{\\calJ}}\\|h+k\\|^3= \\inf_{k\\in (X,Y)_{\\calJ}}\\|[h+k,h+k,h+k]\\|\\\\\n&=&  \\inf_{k\\in (X,Y)_{\\calJ}}\\|[hhh]+\\hbox{an element of }(X,Y)_{\\calJ}\\|\\\\\n&\\ge&  \\inf_{k\\in (X,Y)_{\\calJ}}\\|[hhh]+k\\|=\\|\\overline{[hhh]}\\|=\\|[\\overline h,\\overline h,\\overline h]\\|.\n\\end{eqnarray*}\n\\end{proof}\n\\end{remark}\n\n\n\n\n\n\nThe following theorem is the first main result of this paper.\n\n\\begin{theorem}\\label{thm:0810201}%4.11\nIf $\\calC$ is a T*-category  then $A_{\\calC}$ is a C*-category and there is an ideal $\\calK\\ne \\calC$ of $\\calC$ and a faithful T*-functor from $\\calC/\\calK$ to $A_{\\calC}$, the latter considered as a T*-category. \n\\end{theorem}\n\\begin{proof}\nIt is clear that $A_{\\calC}$, as defined in Definition~\\ref{def:0810201}, is a linear non-unital category which, when considered as a ternary category, satisfies (ii), (iii) and (vi) in Definition~\\ref{def:0804202}.   Items (i), (iv), and (v)  in Definition~\\ref{def:0804202}\nare tantamount  to the morphism sets of  $A_{\\calC}$ of the form $\\calA(X,X)$ being normed as  C*-algebras. This fact is immediate from Proposition~\\ref{prop:0910201}. \n\nThe ideal $\\calK$ of $\\calC$ defined by $(X,Y)_{\\calK}=(X,Y)_{\\calC}$ if $X\\ne Y$ and $(X,X)_{\\calK}=0$, is the kernel of the functor $F$ given by Remark~\\ref{rem:0814201},\n so it induces a faithful functor  $\\tilde F=F/\\calK$ from $\\calC/\\calK$ to $A_{\\calC}$.\n\\end{proof}\n\nThe following is the category analog of the Hamana extension of a TRO homomorphism to a *-homomorphism of the linking C*-algebras, \\cite[8.3.5]{BleLeM}.\n\n\\begin{remark}%4.12\nLet $\\rho$ be a T*-functor from a T*-category $\\calC$ to a T*-category $\\calD$. Then there is a C*-functor $\\widehat\\rho$  from $A_{\\calC}$ to $A_{\\calD}$ which extends $\\rho$.\\end{remark}\n\\begin{proof}\nFor each object $X$ of $A_{\\calC}$, set $\\widehat\\rho(X)=\\rho(X)$, which is an object of $\\calD$ and hence of $A_{\\calD}$. If $X\\ne Y$, then $(X,Y)_{A_{\\calC}}=0$, so set $\\widehat\\rho((X,Y)_{A_{\\calC}})=0$. For \n $\\phi=\\rho|_{(X,X)_{A_{\\calC}}}$\n  where  $(X,X)_{A_{\\calC}}=\\calA(X,X)$, let $\\widehat\\rho(\\phi)$ be the element $\\calA(\\phi)\\in (\\rho(X),\\rho(X))_{A_{\\calD}}=\\calA(\\rho(X),\\rho(X))$ given by Lemma~\\ref{lem:0912201}.\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{remark}\\label{def:0812201}%4.13\nDirect sums of categories were defined in \\cite[Definition 3.8]{Mitchener02}.  The same definition can be made for ternary categories.\n\n(i) \nIf $\\calC$ and $\\calD$ are categories (resp.\\ ternary categories) whose objects may be considered identical, then the direct sum $\\calC\\oplus\\calD$ is defined as the category (resp. ternary category) whose objects are identified with the objects of $\\calC$ or $\\calD$, and with morphism sets \n\\[\n\\operatorname{Hom}(X,Y)_{\\calC\\oplus\\calD}=\\operatorname{Hom}(X,Y)_{\\calC}\\oplus\n\\operatorname{Hom}(X,Y)_{\\calD},\n\\]\nand composition defined coordinatewise. \n\n\n\n\n(ii) If $\\calC$ is a T*-category, \n T*-subcategories $\\calC_{\\pm}$ are defined as follows. Recall that by Theorem~\\ref{thm:0807201}, we have $\n(X,Y)=(X,Y)_+\\oplus (X,Y)_-\n$  for each pair of objects $X,Y$ of $\\calC$. The objects of \n$\\calC_{\\pm}$ are the same as the objects of $\\calC$, and for such objects $X,Y$,\n\\[(X,Y)_{\\calC_{\\pm}}:=(X,Y)_{\\pm}.\\]\n It is clear that $\\calC$ is isomorphic to $\\calC_+\\oplus \\calC_-$ and that $A_{\\calC}$ is isomorphic to\n $\\calA_{C_+}\\oplus \\calA_{C_-}$ .\n%\\end{definition}\n\n\n\n\n (iii) The category $\\calH$ consisting of complex Hilbert spaces $H,K,L, \\ldots$ as objects and bounded linear maps $B(H,K)$ as morphisms is a C*-category with composition $ST$ for $S\\in B(K,L)$ and $T\\in B(H,K)$ (See Definition~\\ref{ex:0821201}). It is a T*-category with composition $RS^*T$.  We shall now denote this T*-category $\\calH$ by $\\calH_+$ and let $\\calH_-$ denote $\\calH$ as a T*-category with composition $-RS^*T$.\n\\end{remark}\n\nThe following may be called the Gelfand-Naimark theorem for T*-categories.\n\\begin{theorem}%4.14\n\\label{thm:0811201}\nLet $\\calC$ be a T*-category.  Then there is an ideal $\\calK\\ne \\calC$ in $\\calC$ and a faithful T*-functor  from $\\calC/\\calK$ to the T*-category $\\calH_+\\oplus\\calH_-$.  %More precisely, a T*-category $\\calC$ is a direct sum of T*-categories $\\calC_+$ and $\\calC_-$ and there are faithful T*-functors $F_+$ from $\\calC_+$  to $\\calH_+$ and $F_-$ from $\\calC_-$ to $\\calH_-$. \n\\end{theorem}\n\\begin{proof} By Theorem~\\ref{thm:0724201}, there is a faithful C*-functor $G_{\\pm}$ from $A_{\\calC_{\\pm}}$ to $\\calH$.  With $A_{\\calC_{\\pm}}$ considered as  a T*-category, we have that $G_{\\pm}$ is a T*-functor from $A_{\\calC_{\\pm}}$ to $\\calH_{\\pm}$. By Theorem~\\ref{thm:0810201}, there is a T*-functor $F_{\\pm}$ from $\\calC_{\\pm}$  to $A_{\\calC_{\\pm}}$, and it suffices to consider $H/\\calK$, where $\\calK$ is the ideal in Theorem~\\ref{thm:0810201}, and $ H=(G_+\\circ F_+)\\oplus (G_-\\circ F_-)$.\n\\end{proof}\n\n\n\n\n\n\nWe close this subsection with some examples of linking C*-categories.\n\n\n\\begin{example}%4.15\n\\label{ex:0911201} (Cf.\\ Example~\\ref{ex:0912201})\nIf $X$ is a TRO, and $\\calC$ is the T*-category $(\\{X\\},X)$ with $X$ as its sole object and the elements of $X$ as its morphisms from $X$ to $X$,  and with composition $[zyx]=xy^*z$, then $A_{\\calC}$ is the category $(\\{X\\}, \\calA(X,X))$ with $X$ as its sole object and the elements of \n$\\calA(X,X)$ as its morphisms from $X$ to $X$, and with composition being the multiplication in \n$\\calA(X,X)$.  As expected, the C*-algebra $\\calA(X,X)$ is *-isomorphic to the linking algebra $A_X$ of the TRO $X$ under the map\n\\[\nA_X\\ni \\left[\\begin{matrix}\n\\sum_ix_iy_i^*&z\\\\\nw^*&\\sum_ju_j^*v_j\n\\end{matrix}\\right] \\mapsto \\left[\\begin{matrix}\n\\sum_i([x_iy_i\\cdot],[[y_ix_i\\cdot])&z\\\\\n\\overline{w}&\\sum_j([\\cdot u_jv_j],[\\cdot v_ju_j])\n\\end{matrix}\\right] \\in\\calA(X,X).\n\\]\n\\end{example}\n\n\\begin{example}%4.16\nIf $(Z,(\\cdot,\\cdot,\\cdot))$ is a C*-ternary ring, and $\\calC$ is the T*-category $(\\{Z\\},Z)$ with $Z$ as its sole object and the elements of $Z$ as its morphisms from $Z$ to $Z$,  and with composition $[zyx]=(x,y,z)$, then $A_{\\calC}$ is the category $(\\{Z\\}, \\calA(Z,Z))$ with $Z$ as its sole object and the elements of \n$\\calA(Z,Z)$ as its morphisms from $Z$ to $Z$, and with composition being the multiplication in \n$\\calA(Z,Z)$.  \n%By Lemma~\\ref{lem:0912201}, the C*-algebra $\\calA(Z_+)$ is isomorphic to the linking algebra $A_X\n\nThe C*-algebra $\\calA(Z,Z)=\\calA(Z_+)\\oplus \\calA(Z_-)$ is *-isomorphic to $A_X\\oplus \\calB$ where $X$ is a TRO which is  isomorphic to $Z_+$, and $\\calB$ is a C*-algebra which is related to a TRO $Y$ which is anti-isomorphic to $Z_-$.\n Precisely, $\\calA(Z_+)$ is isomorphic to\n$\nA_X\n$, which\nis the closure of \n\\[\n\\left\\{\n\\left[\\begin{matrix}\n\\sum_ix_iy_i^*&z\\\\\nw^*&\\sum_ju_j^*v_j\n\\end{matrix}\\right]\n:x_i,y_i,u_j,v_j,z,w\\in X\n\\right\\}\n \\]\n with multiplication\n \\[\n \\left[\\begin{matrix}\n\\alpha&z\\\\\nw^*&\\beta\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\n\\alpha'&z'\\\\\nw'^*&\\beta'\n\\end{matrix}\\right]\n=\n\\left[\\begin{matrix}\n\\alpha\\alpha'+xy'^*&\\alpha x'+x\\beta'\\\\\ny^*\\alpha'+\\beta y'^*&y^*\\alpha'+\\beta\\beta'\n\\end{matrix}\\right]\n \\]\n and $\\calA(Z_-)$ is isomorphic to\n $\n\\calB,\n$ which \nis the closure of \n\\[\n\\left\\{\n\\left[\\begin{matrix}\n\\sum_ix_iy_i^*&z\\\\\nw^*&\\sum_ju_j^*v_j\n\\end{matrix}\\right]\n:x_i,y_i,u_j,v_j,z,w\\in Y\n\\right\\}\n \\]\n with multiplication\n \\[\n \\left[\\begin{matrix}\n\\alpha&z\\\\\nw^*&\\beta\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\n\\alpha'&z'\\\\\nw'^*&\\beta'\n\\end{matrix}\\right]\n=\n\\left[\\begin{matrix}\n\\alpha\\alpha'-xy'^*&-\\alpha x'-x\\beta'\\\\\n-y^*\\alpha'-\\beta y'^*&-y^*\\alpha'+\\beta\\beta'\n\\end{matrix}\\right].\n \\]\n \\end{example} \n \n \\begin{example}%4.17\n If $\\calC$ is the T*-category $\\calH_+$ of Hilbert spaces and bounded linear maps (see Remark~\\ref{def:0812201}(iii)), then $A_{\\calH_+}$ is the C*-category with the same objects as $\\calH_+$, and for each such object (Hilbert space) $H$, $(H,H)_{\\calH_+}=B(H)$  and  $(H,H)_{A_{\\calH_+}}=\\calA(H,H)=B(H)\\oplus B(H)=M_2(B(H))$.\n \\end{example}\n \n \\begin{example}%4.18\n  If $\\calC$ is any C*-category, considered as a T*-category then $A_{\\calC}$ is the C*-category with the same objects as $\\calC$, and for each such object $X$, $(X,X)_{A_{\\calC}}$ is a C*-algebra and $(X,X)_{A_{\\calC}}=\\calA(X,X)=M_2((X,X)))$.\n  \\end{example}\n \n \\begin{example}%4.19\n Let $A$ be a $C^*$-algebra. Then the class $\\calC$ of all Hilbert $C^*$-modules over $A$ (as objects) together with all bounded $A$-linear and adjointable operators (as morphisms), with morphism composition $(f, g, h) \\mapsto h g^* f$, forms a $T^*$-category.  In this case $\\calA(X,X)$ is isomorphic to the linking algebra as defined in \\cite[8.1.17, pp. 303--304]{BleLeM} and $A_{\\calC}$ is therefore a subcategory of the C*-category of C*-Hilbert $A$-modules and bounded $A$-linear maps.\n \\end{example}\n \n\n\n\\subsection{The linking W*-category of a  TW*-category}\n\nThe proofs of the main results in this section (Theorems~\\ref{thm:0831202} and ~\\ref{thm:0831203} below) are based on the tools leading up to the following   Gelfand-Naimark theorem for W*-ternary rings, which recall are C*-ternary rings with a predual.\n\n\\begin{theorem}[Theorem 4.1 in \\cite{Zettl83}] \\label{thm:0831201}%4.20\nA W*-ternary ring $Z$ is the direct sum of two W*-ternary subrings $Z_+$ and $Z_-$which are respectively normally isometrically isomorphic and normally isometrically anti-isomorphic to a W*-TRO. Normally means the isomorphism and anti-isomorphic are  weak*-continuous.\n\\end{theorem}\n\n\n\n\nLet $V$ be a C*-ternary ring with triple product denoted by $[hgf]$. By Proposition~\\ref{prop:0912201}, $V$ is the off-diagonal corner of a C*-algebra $\\calA(V)$, where\n\\[\n\\calA(V)=\\left[\\begin{matrix}\nL&V\\\\\n\\overline{V}&R\n\\end{matrix}\\right] ,\n\\]  \nand $L=L(V)$ and $R=R(V)$ are C*-algebras.  Consider\n\\begin{equation}\\label{eq:0915201}\n\\tilde A(V)=\\left[\\begin{matrix}\nM(L)&V\\\\\n\\overline{V}&M(R)\n\\end{matrix}\\right],\n\\end{equation}\nwhere $M(L)$ and $M(R)$ are the multiplier algebras of $L$ and of $R$.\n\n\n\n\n\\begin{proposition}%4.21\n\\label{prop:0915201}\nIf the C*-ternary ring $V$ is a dual space, then $M(R(V))$ and $M(L(V))$ are W*-algebras, and therefore $V$ is the off-diagonal corner of a W*-algebra.\n\\end{proposition}\n\\begin{proof}\nIn order to use the results of \\cite[section 4]{Zettl83},\nwe recall that the C*-algebra $\\frak A$ in Remark~\\ref{rem:0831201} is the closed span of $\\{[\\cdot gh]: g,h\\in V\\}$ and it is *-isomorphic to $R(V)$ via the map $\\frak A\\ni B_1\\mapsto \\sigma(B_1)=(B_1,B_1^*)\\in R(V)$. Similarly  $\\tau:\\frak B\\rightarrow L(V)$ is the *-isomorphism $A_1\\mapsto (A_1,A_1^*)$, where $\\frak B$ is the close span of $\\{[gh\\cdot]: g,h\\in V\\}$. The C*-ternary ring $V$ is thus both a Banach $(L,R)$-bimodule and a Banach $(\\frak B,\\frak A)$-bimodule. \n\nUsing only the assumption  that $V$ is a right Hilbert $\\frak A$-module, it is proved in \\cite[section 4]{Zettl83}, that $M(\\frak A)$ is a W*-algebra.  It follows that, provided $V$ is a right Hilbert $R^{op}$-module, $M(R)$ is a W*-algebra, and by a parallel argument, that $M(L)$ is also a W*-algebra. The reduction to $V$ being a Hilbert module is obtained by considering $V$ with a triple product modified by the operator $T$ in Theorem~\\ref{thm:0807201}(iii). It follows that \n\\[\n\\tilde A(V)=M(L)\\oplus V\\oplus \\overline{V}\\oplus M(R)\n\\]\nis the dual of \n\\[\n\\tilde A(V)_*=M(L)_*\\oplus V_*\\oplus \\overline{V}_*\\oplus M(R)_*,\n\\]\nwhere $V_*$ is the predual of $V$,  so $\\tilde A(V)$ is a W*-algebra.\n\\end{proof}\n\n\n\n\n\n\n\nRecall that a TW*-category is a T*-category in which each morphism set is a dual space.\nA W*-ternary ring was introduced in \\cite{Zettl83} as a  C*-ternary ring which is a dual space.\nFor any objects $X,Y$ in a TW*-category, $(X,Y)$ is a W*-ternary ring. \nA $W^*$-ternary ring $X$, or its concrete analogue, a weakly closed  ternary ring of operators (W*-TRO), can be viewed as a TW*-category with one object $X$ and the elements of $X$ themselves as morphisms, with morphism composition given by the ternary operation in $X$.\n\n\n\\begin{definition}%4.22\n\\label{def:0915201}\nGiven a TW*-category $\\calC$, the {\\it linking W*-category} $\\tilde A_{\\calC}$  of $\\calC$ is as follows. The objects of the category $A_{\\calC}$ are the same as the objects of $\\calC$.  The morphism set  $\\operatorname{Hom}(X,Y)$ is defined to be $\\{0\\}$ if $X\\ne Y$, and $\\operatorname{Hom}(X,X)=\\tilde \\calA(X,X)$, as in (\\ref{eq:0915201}) with $V=(X,X)$, and with composition  as follows. If $a\\in \\operatorname{Hom}(X,Y)$ and $b\\in \\operatorname{Hom}(Y,Z)$, then\n$b\\circ a$ must be $\\{0\\}$ unless $X=Y=Z$, in which case $b\\circ a$ is defined to be the product $ab$ in $\\tilde \\calA(X,X)$. \n\\end{definition}\n\n\n\n\n\n\nThe following is the W*-version of Theorem~\\ref{thm:0810201}.\n\n\n\n\\begin{theorem}\\label{thm:0831202}%4.23\nIf $\\calC$ is a TW*-category  then $\\tilde A_{\\calC}$ is a W*-category and there is an ideal $\\calK\\ne \\calC$ of $\\calC$ and a faithful  TW*-functor from $\\calC/\\calK$ to $\\tilde A_{\\calC}$, the latter considered as a TW*-category. \n\\end{theorem}\n\\begin{proof}\nIt is clear that $\\tilde A_{\\calC}$, as defined in Definition~\\ref{def:0915201}, is a linear non-unital category which, when considered as a ternary category, satisfies (ii), (iii) and (vi) in Definition~\\ref{def:0804202}.   Items (i), (iv), and (v)  in Definition~\\ref{def:0804202}\nare tantamount  to the morphism sets of  $\\tilde A_{\\calC}$ of the form $\\tilde \\calA(X,X)$ being W*-algebras. This fact is immediate from Proposition~\\ref{prop:0915201}. \n\nThe ideal $\\calK$ of $\\calC$ defined by $(X,Y)_{\\calK}=(X,Y)_{\\calC}$ if $X\\ne Y$ and $(X,X)_{\\calK}=0$, is the kernel of the functor $F$ given by Remark~\\ref{rem:0814201},\n so it induces a faithful functor  $\\tilde F=F/\\calK$ from $\\calC/\\calK$ to $\\tilde A_{\\calC}$.\n\\end{proof}\n\n\n\nThe following is the appropriate version of Proposition~\\ref{prop:0910202}.\n\n\n\\begin{proposition}%4.24\n\\label{prop:0910203}\nEach TW*-category $\\calC$  is the direct sum $\\calC_I\\oplus \\calC_{II}\\oplus\\calC_{III}$, where $\\calC_i$, $i=I,II,III$, is a TW*-category of type $i$.\n\\end{proposition}\n\\begin{proof}\nIn a TW*-category, each morphism space $(X,Y)$ is isomorphic as a W*-ternary ring to a W*-TRO.  By Ruan's classification \n\\[(X,Y)_{\\pm}=((X,Y)_{\\pm})_{I}\\oplus ((X,Y_{\\pm}))_{II}\\oplus((X,Y)_{\\pm})_{III}\\] and it suffices to take $\\calC_i$ to be the T*-category with morphism sets \n\\[\n(X,Y)_i=((X,Y)_{+})_{i}\\oplus ((X,Y)_{-})_{i}.\n\\]\n\\end{proof}\n\n\n\nThe following is the W*-version of Theorem~\\ref{thm:0811201}.\n\n\\begin{theorem}%4.25\n\\label{thm:0831203}\nLet $\\calC$ be a TW*-category.  Then there is an ideal $\\calK\\ne \\calC$ in $\\calC$ and a faithful TW*-functor $H$ from $\\calC/\\calK$ to the TW*-category $\\calH_+\\oplus\\calH_-$.\n\\end{theorem}\n\\begin{proof} By \\cite[Proposition 2.13]{GLR85}, there is a faithful W*-functor $G_{\\pm}$ from $\\tilde A_{\\calC_{\\pm}}$ to $\\calH$.  With $\\tilde A_{\\calC_{\\pm}}$ considered as  a TW*-category, we have that $G_{\\pm}$ is a TW*-functor from $\\tilde A_{\\calC_{\\pm}}$ to $\\calH_{\\pm}$. By Theorem~\\ref{thm:0831202}, there is a TW*-functor $F_{\\pm}$ from $\\calC_{\\pm}$  to $\\tilde A_{\\calC_{\\pm}}$, and it suffices to consider $H/\\calK$, where $\\calK$ is the ideal in Theorem~\\ref{thm:0831202}, and $ H=(G_+\\circ F_+)\\oplus (G_-\\circ F_-)$.\n\\end{proof}\n\n\n\n\n\\section{Bidual categories}\\label{sec:1001203}\n\n\\subsection{The bidual of a C*-category}\n\nWe begin by reviewing the well-known and celebrated Arens multiplications.  If $A$ is an algebra with algebraic dual $A'$ and bidual $A^\\ppp$, the following two multiplications on $A^\\ppp$ were defined in \\cite{Arens51}, and are referred to as the first and second Arens products, denoted by $FG$ and $F\\cdot G$ respectively for $F,G\\in A^\\ppp$. Each product extends the product in $A$ when $A$ is identified with its canonical image in $A^\\ppp$. \\bigskip\n\n{\\tiny\n\\begin{tabular}{ccccc}\n       domain&\\multicolumn{2}{c|}{First Arens product $FG$}&\\multicolumn{2}{c|}{Second Arens product $F\\cdot G$}\\\\\\hline\n$A\\times A$&$ (a,b)\\mapsto ba\\in A$&(product in $A$)&$(a,b)\\mapsto ab\\in A$&(product in $A$)\\\\\n$A'\\times A$&$(f,b)\\mapsto bf\\in A'$&$\\langle bf,a\\rangle=\\langle f,ba\\rangle$&$(f,b)\\mapsto fb\\in A'$&$\\langle fb,a\\rangle=\\langle f,ab\\rangle$\\\\\n%\n$A^\\ppp\\times A'$&$(F,f)\\mapsto fF\\in A'$&$\\langle fF,b\\rangle=\\langle F,bf\\rangle$&$(F,f)\\mapsto Ff\\in A'$&$\\langle Ff,b\\rangle=\\langle F,fb\\rangle$\\\\\n$A^\\ppp\\times A^\\ppp$&$(F,G)\\mapsto FG\\in A^\\ppp$&$\\langle FG,f\\rangle=\\langle F,fG\\rangle$&$(F,G)\\mapsto F\\cdot G\\in A^\\ppp$&$\\langle F\\cdot G,f\\rangle=\\langle G,Ff\\rangle$\\\\\\hline\n\\end{tabular}\n}\n\\bigskip\n\nIf $\\varphi:A\\to B$ is an algebra homomorphism, then $\\varphi^\\ppp:A^\\ppp\\to B^\\ppp$ is an algebra homomorphism  in either product extending $\\varphi$.  When the two products coincide, the algebra $A$ is called Arens regular. If $A$ is a *-algebra, its involution extends to a mapping on  $A^\\ppp$\nvia\n$\\langle F^*,f\\rangle=\\overline{\\langle F, f^*\\rangle}$ and $\\langle f^*,a\\rangle=\\overline{\\langle f, a^*\\rangle}$ for $f\\in A',a\\in A$. However, since $(FG)^*=G^*\\cdot F^*$, $F\\mapsto F^*$ is not an involution unless $A$ is Arens regular.\n\nIn the following analog of the Arens construction for categories, there is essentially only one Arens multiplication.  This simplification is due to the fact that in the morphism spaces $(X,Y)$,  $a\\circ b$ and $b\\circ a$ are simultaneously defined only if $X=Y$.  We shall therefore only use the first Arens product, with the understanding  that morphism spaces $(X,X)$ might not be Arens regular.  Also, because the composition in categories is more akin to composition of functions, we shall use the notation $G\\circ F$ for the analog of $FG$. For all other products, including composition, for notation's sake, we shall just use juxtaposition.\n\n\\begin{definition}\\label{def:0820201}%5.1\nLet $\\calC$ be a linear category with objects $X,Y,Z, \\ldots$, morphism spaces $(X,Y)=\\{a,b,c, \\dots\\}$, dual spaces $(X,Y)'=\\{f,g,h,\\ldots \\}$, and bidual spaces $(X,Y)^\\ppp=\\{F,G,H,\\ldots\\}$.  For objects $X,Y,Z$ a composition   defined on $(X,Y)^\\ppp \\times (Y,Z)^\\ppp\\rightarrow (X,Z)^\\ppp$ and given by the Arens construction is as follows.\n%, where we denote the composition in $\\calC$ by juxtaposition.\n\\bigskip\n\n\\begin{tabular}{lc}\\hline\n $(X,Y)\\times (Y,Z)\\ni (a,b) \\mapsto ba:= b\\circ a\\in (X,Z)$  &( composition in $\\calC$)\\\\\n  $(X,Z)'\\times (Y,Z)\\ni (f,b) \\mapsto bf\\in (X,Y)'$ & $\\langle bf,a\\rangle=\\langle f,ba\\rangle$, $a\\in (X,Y)$\\\\ \\smallskip\n$(X,Y)^\\ppp\\times (X,Z)'\\ni (F,f) \\mapsto fF\\in (Y,Z)'$&$\\langle fF,b\\rangle=\\langle F,bf\\rangle$,   $b\\in (Y,Z)$\\\\\\smallskip\n$(X,Y)^\\ppp\\times (Y,Z)^\\ppp\\ni (F,G) \\mapsto G\\circ F\\in (X,Z)^\\ppp$ & $\\langle G\\circ F,f\\rangle=\\langle G,fF\\rangle$, $f\\in (X,Z)'$\\\\\\hline\n\\end{tabular}\\smallskip\n\\end{definition}\n\nThe composition \\[\nG\\circ F:(X,Y)^\\ppp\\times (Y,Z)^\\ppp\\rightarrow (X,Z)^\\ppp\\] is an extension of the composition \\[b\\circ a:(X,Y)\\times (Y,Z)\\to (X,Z)\\] in $\\calC$. That is, if $a\\mapsto \\widehat a$ denotes the canonical inclusion of $(X,Y)$ into $(X,Y)^\\ppp$, then for $(a,b)\\in (X,Y)\\times (Y,Z)$, \\[\\widehat b\\circ \\widehat a=\\widehat{ba}.\\]\n\nThe following lemma is a straightforward consequence of Definition~\\ref{def:0820201} and justifies Definition~\\ref{def:0916201}. We include the proof for completeness.\n\n\\begin{lemma}%5.2\nFor $F\\in (X,Y)^\\ppp, G\\in (Y,Z)^\\ppp, H\\in (Z,W)^\\ppp$,  we have $G\\circ F\\in(X,Z)^\\ppp$, $H\\circ G\\in (Y,W)^\\ppp$, and  $(H\\circ G)\\circ F=H\\circ (G\\circ F).$\n\\end{lemma}\n\\begin{proof}\nFor  $f\\in (X,Z)'$,  \\[\\langle H\\circ (G\\circ F),f\\rangle=\\langle H,f(G\\circ F)\\rangle,\\] and \\[\\langle (H\\circ G)\\circ F,f\\rangle=\\langle H\\circ G,fF\\rangle=\\langle H, (fF)G\\rangle.\\]  Thus it suffices to prove\n\\[f(G\\circ F)=(fF)G.\\]\n\nFor $a\\in(Z,W)$, \n\\[\n\\langle f(G\\circ F),a\\rangle =\\langle G\\circ F,af\\rangle=\\langle G,(af)F\\rangle,\n\\]\nand\n\\[\n\\langle (fF)G,a\\rangle =\\langle G,a(fF)\\rangle,\n\\] \nso it suffices to prove\n\\[\na(fF)=(af)F.\n\\]\nFor $b\\in(Y,Z)$, \n\\[\n\\langle a(fF),b\\rangle =\\langle fF,ab\\rangle=\\langle F,(ab)f\\rangle,\n\\]\nand\n\\[\n\\langle (af)F,b\\rangle =\\langle F,b(af)\\rangle,\n\\] \nso it suffices to prove\n\\[\n(ab)f=b(af).\n\\]\nFor $c\\in(X,Y)$, \n\\[\n\\langle (ab)f,c\\rangle =\\langle f,(ab)c\\rangle,\n\\]\nand\n\\[\n\\langle b(af),c\\rangle =\\langle af,bc\\rangle=\\langle f,a(bc)\\rangle,\n\\] \ncompleting the proof.\n\\end{proof}\n\nThe composition $G\\circ F$ is weak*-continuous in its first variable $G$, for if $G_\\alpha\\rightarrow G$, then for $f\\in (Y,Z)'$, $\\langle G_\\alpha,f\\rangle\\rightarrow \\langle G,f\\rangle$ and so if $g\\in (X,Z)'$, $\\langle G_\\alpha\\circ F,g\\rangle=\\langle G_\\alpha, gF\\rangle\\rightarrow \\langle G,gF\\rangle=\\langle G\\circ F,g\\rangle.$\n\n\n\n\n\\begin{definition}%5.3\n\\label{def:0916201}\nThe {\\it Arens bidual} of a linear category  $\\calC$, denoted by $\\calC^\\ppp$, or by $({\\calC}^\\ppp,\\hbox{Arens})$, is the linear category having the  same objects as $\\calC$,  morphism sets $\\operatorname{Hom}(X,Y)=(X,Y)^\\ppp$ and composition %defined on $(X,Y)^\\ppp \\times (Y,Z)^\\ppp\\rightarrow (X,Z)^\\ppp$ \ngiven by the Arens construction in Definition~\\ref{def:0820201}. The category $\\calC$ is said to be {\\it Arens regular} if the composition $G\\circ F$ is separately weak*-continuous, that is, it is also weak*-continuous in the second variable.\n\\end{definition}\n\n\\begin{lemma}%5.4\n\\label{lem:0920201}\nIf $\\calC$ is an Arens regular *-linear category with involutions $(X,Y)\\ni a\\mapsto a^*\\in (Y,X)$, then the linear involution \ndefined as \n\n\\begin{tabular}{cll}\n& $(X,Y)^\\ppp\\ni F \\mapsto F^*\\in (Y,X)^\\ppp$& with  $\\langle F^*,f\\rangle=\\overline{\\langle F,f^*\\rangle}$,   $f\\in (Y,X)'$,\\\\\\smallskip\n &$(Y,X)'\\ni f \\mapsto f^*\\in (X,Y)'$ &with $\\langle f^*,a\\rangle=\\overline{\\langle f,a^*\\rangle}$,   $a\\in (X,Y)$,\n\\end{tabular}\n\nis an algebra involution. Hence,\nthe Arens bidual  \n$(\\calC^\\ppp,\\hbox{Arens})$\nis a *-linear category. \n\\end{lemma}\n\\begin{proof}\nLet $F \\in (X, Y)''$, $G \\in (Y, Z)''$, and by Arens regularity, we may assume that $F=\\hat{a}$, $G=\\hat{b}$ for $a\\in (X,Y),b\\in (Y,Z)$. Then\n\n\\begin{align*}\n\\langle (G \\circ F)^*, f \\rangle &=  \n\\overline{\\langle G \\circ F, f^* \\rangle}\n = \\overline{\\langle G, f^* F \\rangle} \n = \\overline{\\langle f^* F , b \\rangle} \n = \\overline{\\langle  F , b f^* \\rangle} \\\\\n& = \\overline{\\langle  b f^*, a \\rangle} \n = \\overline{\\langle   f^*, ba \\rangle} \n = \\langle   f, (ba)^* \\rangle \n = \\langle   f, a^* b^* \\rangle \n\\end{align*}\n\nand\n\n\n\\begin{align*}\n\\langle F^* \\circ G^*, f \\rangle &=  \n\\langle F^*, f G^*   \\rangle \n= \\overline{\\langle F, (f G^*)^* \\rangle} \n= \\overline{\\langle  (f G^*)^*, a \\rangle} \\\\\n&= \\langle  f G^*, a^* \\rangle \n= \\langle   G^*, a^*f \\rangle \n= \\overline{\\langle   G, (a^*f)^* \\rangle} \\\\\n&= \\overline{\\langle (a^*f)^*, b \\rangle} \n= \\langle a^*f, b^* \\rangle \n= \\langle f, a^* b^* \\rangle.\n\\end{align*}\n\\end{proof}\n\n\n\n\\begin{lemma}%5.5\n\\label{lem:0929201}\nA C*-category is Arens regular.\n\\end{lemma}\n\\begin{proof}\\footnote{After giving this proof, we discovered that this Lemma follows as in the proof of  Proposition~\\ref{prop:1005201}. We are including this proof since, besides its intrinsic interest, it is needed in the definition of the Sherman-Takeda bidual of a C*-category (Definition~\\ref{def:1005202}).}\nLet $\\rho$ be a faithful C*-functor from a C*-category $\\calC$ to $\\calH$, and for objects $X$ and $Y$ of $\\calC$,  consider the following commutative diagram:\n\n\\[\n\\begin{array}{cclcl}\n&&A&&\\\\\n&&\\uparrow \\subset&&\\\\\n(X,Y)&\\stackrel{\\rho}{\\longrightarrow}&\\calR&\\stackrel{\\pi}{\\longrightarrow}&\\pi(\\calR)\\\\\n\\downarrow \\kappa&&\\downarrow \\kappa&&\\downarrow \\subset\\\\\n(X,Y)^\\ppp&\\stackrel{\\rho^\\ppp}{\\longrightarrow}&\\calR^\\ppp&\\stackrel{\\pi^\\ppp}{\\longrightarrow}&\\calS\\subset B(H_\\pi),\n\\end{array}\n\\]\nwhere by Remark~\\ref{rem:0820201}, $\\rho=\\rho_{X,Y}$ is, in particular, a C*-ternary ring isomorphism onto a TRO \n$\\calR=\\calR(X,Y)=\\rho((X,Y))$, \n$\\pi=\\pi_{X,Y}$ is the restriction to $\\calR$ of the universal representation of the C*-algebra $A$ generated by $\\calR$ on the Hilbert space $H_\\pi$, $\\calS=\\calS(X,Y)$ is the weak operator closure of the TRO $\\pi(\\calR)$, and $\\kappa$ denotes the canonical inclusion of a Banach space into its bidual.\nBy \\cite[Lemma]{LanRus83}, the bi-adjoint $\\pi^\\ppp$ of $\\pi$ is, as well as a TRO-isomorphism of $\\calR^\\ppp$ onto $\\calS$,  a homeomorphism of $\\calR^\\ppp$ with its weak*-topology and $\\calS$ with its the weak operator topology from $B(H_\\pi)$ (which coincides with its weak*-topology).  It follows that composition at the level of the $\\calR(X,Y)^\\ppp$ spaces is separately weak*-continuous, and since each $\\rho^\\ppp_{X,Y}$ is a weak*-weak* homeomorphism, the same holds for composition at the level of the $(X,Y)^\\ppp$.\n\\end{proof}\n\n\n\\begin{proposition}%5.6\n If $\\calC$ is a C*-category, then it's Arens bidual $(\\calC^\\ppp,\\hbox{Arens})$ is a C*-category.\n\\end{proposition}\n\\begin{proof} \nItems (i), (ii), and (iv) in Definition~\\ref{def:0804202} are immediate. Item (iii) holds by Lemmas~\\ref{lem:0920201} and ~\\ref{lem:0929201}.\nBy Remark~\\ref{rem:0820201}, $(X,Y)$ is \na C*-ternary ring which is isomorphic to a TRO $M$. The bidual $M^\\ppp$ of $M$ is also isomorphic to a TRO, by \\cite[Lemma]{LanRus83}, from which items (v) and (vi)  in Definition~\\ref{def:0804202} follow. Indeed, for (v), since the faithful C*-functor $\\rho$ from $\\calC$ to $\\calH$ satisfies $\\rho(c\\circ b^*\\circ a)=\\rho(c)\\rho(b)^*\\rho(a)$, we have (by a familiar argument)\n\\begin{eqnarray*}\n\\|H\\|^3&=&\\|\\rho^\\ppp(H)\\|^3=\\|\\rho^\\ppp(H)\\rho^\\ppp(H)^*\\rho^\\ppp(H)\\|\n\\le \\|\\rho^\\ppp(H)\\|\\|\\rho^\\ppp(H)^*\\rho^\\ppp(H)\\|\\\\\n&=&\\|H\\|\\|\\rho^\\ppp(H^*\\circ H)\\|=\\|H\\|\\|H^*\\circ H\\| \\le \\|H^3\\|,\n\\end{eqnarray*}\nso $\\|H\\|^2=\\|H^*\\circ H\\|$.  As  for (vi), if $H\\in (X,Y)^\\ppp$, observe that $\\rho^\\ppp(H)^*\\rho^\\ppp(H)$ is a positive operator in the C*-algebra $\\rho^\\ppp(X,X)$ on the Hilbert space $\\rho(X)$.\n\\end{proof}\n\nLet us now consider a different approach to the definition of the  bidual of a C*-category which is based on the Sherman-Takeda proof that the bidual of a C*-algebra is a C*-algebra \\cite[III.2.4]{Takesakibook}, \\cite[10.1.12]{KadRinbook}, \\cite[12.1.3]{Dixmierbook}. \n\n\n\n\n\nIn the proof of  Lemma~\\ref{lem:0929201}, set $\\sigma:=\\pi\\circ \\rho$, which is also a faithful C*-functor mapping $(X,Y)$ onto $\\pi(\\calR)$, and set $\\tau=\\tau_{X,Y}:=\\sigma^\\ppp=\\pi^\\ppp\\circ\\rho^\\ppp$, which is a homeomorphism of $(X,Y)^\\ppp$ with the weak*-topology onto $\\calS$ with the weak operator topology. Then,  for $F\\in (X,Y)^\\ppp$ and $G\\in (Y,Z)^\\ppp$, note that $\\tau(G)\\in \\calS(Y,Z)$, $\\tau(F)\\in \\calS(X,Y)$, so that for $G=$w*-$\\lim_\\beta \\widehat{b_\\beta}$, $b_\\beta\\in (Y,Z)$ and $F=$w*-$\\lim_\\alpha \\widehat{a_\\alpha}$,  $a_\\alpha\\in (X,Y)$, we have \n\\begin{eqnarray*}\n\\tau(G)\\tau(F)&=&\\tau(\\hbox{w*-}\\lim_\\beta \\widehat{b_\\beta})\\tau(\\hbox{w*-}\\lim_\\alpha \\widehat{a_\\alpha})\\\\\n&=&(\\hbox{W-}\\lim_\\beta\\sigma(b_\\beta))\n(\\hbox{W-}\\lim_\\alpha\\sigma(a_\\alpha))\\\\\n&=&\n\\hbox{W-}\\lim_\\alpha(\\hbox{W-}\\lim_\\beta\n\\sigma(b_\\beta))\\sigma( a_\\alpha)\\\\\n&=&\n\\hbox{W-}\\lim_\\alpha\\hbox{W-}\\lim_\\beta\n\\sigma(b_\\beta a_\\alpha)\\in\\calS(X,Z).\n\\end{eqnarray*}\n\nThus we can define $G\\bullet F\\in (X,Z)^\\ppp$, by \n\\begin{equation}\\label{eq:0920201}%(5.1)\nG\\bullet F=\\tau^{-1}(\\tau(G)\\tau(F)),\n\\end{equation}\nmore precisely,\n\\[\nG\\bullet F=\\tau_{X,Z}^{-1}(\\tau_{Y,Z}(G)\\tau_{X,Y}(F)),\n\\]\nand we have, for $F\\in (X,Y)^\\ppp, G\\in (Y,Z)^\\ppp, H\\in (Z,W)^\\ppp$,\n\\begin{eqnarray*}\nH\\bullet (G\\bullet F)&=&\\tau^{-1}(\\tau(H)\\tau(G\\bullet F))=\\tau^{-1}(\\tau(H)\\tau(G)\\tau (F))\\\\\n&=&\\tau^{-1}(\\tau(H\\bullet G)(\\tau (F))=(H\\bullet G)\\bullet F.\n\\end{eqnarray*}\nMoreover, since $\\tau(G\\bullet F)=\\tau(G)\\tau(F)$, and $\\pi^\\ppp$ is a *-isomorphism, in the sense that\n\\[\n\\pi_{X,Z}^\\ppp(\\rho^\\ppp_{Y,Z}(G)\\rho^\\ppp_{X,Y}(F))=\\pi^\\ppp_{Y,Z}(\\rho^\\ppp_{Y,Z}(G))\\pi^\\ppp_{X,Y}(\\rho^\\ppp_{X,Y}(F)),\n\\]\nwe have\n\\[\n\\rho^\\ppp(G\\bullet F)=\\rho^\\ppp(G)\\rho^\\ppp(F),\n\\]\nthat is,\n\\[\n\\rho^\\ppp_{X,Z}(G\\bullet F)=\\rho^\\ppp_{Y,Z}(G)\\rho^\\ppp_{X,Y}(F).\n\\]\nAlso, for $a\\in (X,Y),b\\in (Y,Z)$,\n\\[\n\\hat b\\bullet \\hat a=\\tau^{-1}(\\tau(\\hat b)\\tau(\\hat a))=(\\rho^\\ppp)^{-1}(\\rho^\\ppp(\\hat b)\\rho^\\ppp(\\hat a))\n\\]\nso that \n\\[\n\\rho^\\ppp(\\hat b\\bullet \\hat a)=\\rho^\\ppp(\\hat b)\\rho^\\ppp(\\hat a)=\\widehat{\\rho(b)}\\widehat{\\rho(a)}.\n\\]\n\n\n\n\n\n\n\\begin{definition}%5.7\n\\label{def:1005202}\nThe {\\it Sherman-Takeda  bidual} of a C*-category $\\calC$, denoted by ${\\calC}^\\ppp$, or $(\\calC^\\ppp,\\hbox{S-T})$, is the linear category having the  same objects as $\\calC$,  morphism sets $\\operatorname{Hom}(X,Y)=(X,Y)^\\ppp$ and composition defined on $(X,Y)^\\ppp \\times (Y,Z)^\\ppp\\rightarrow (X,Z)^\\ppp$ \ngiven by (\\ref{eq:0920201}).\n\\end{definition}\n\n\\begin{proposition}%5.8\n If $\\calC$ is a C*-category, then it's Sherman-Takeda bidual $(\\calC^\\ppp,\\hbox{S-T})$ is a C*-category.\n\\end{proposition}\n\\begin{proof} \nItems (i)-(iii) in Definition~\\ref{def:0804202} are immediate.  As for (iv) and (v), for $F\\in (X,Y)^\\ppp$ and \n$G\\in (Y,Z)^\\ppp$, \n\\[\n\\|G\\bullet F\\|=\\|\\tau(G)\\tau(F)\\|\\le \\|\\tau(G)\\|\\|\\tau(F)\\|=\\|G\\|\\|F\\|\n\\] \nand since $\\tau_{X,X}$ is a *-isomorphism,\n\\[\n\\|F^*\\bullet F\\|=\\|\\tau(F^*)\\tau(F)\\|=\\|\\tau(F)^*\\tau(F)\\|=\\|\\tau(F)\\|^2=\\|F\\|^2.\n\\]\nFinally, since $\\tau(F)^*\\tau(F)$ is a positive operator  in $\\calS(X,X)$, it equals $A^*A$ for some $A\\in \\calS(X,X)$, and $A=\\tau(G)$ for some $G\\in (X,X)^\\ppp$, so that  $F^*\\bullet F=\\tau^{-1}(\\tau(G)^*\\tau(G))=\\tau^{-1}(\\tau(G^*)\\tau(G))=G^*\\bullet G$, proving (vi) in Definition~\\ref{def:0804202}.\n\\end{proof}\n\n\\begin{proposition}%5.9\nIf $\\calC$ is a C*-category, then $G\\circ F=G\\bullet F$, that is, the Arens bidual coincides with the Sherman-Takeda bidual.\n\\end{proposition}\n\\begin{proof}\n%For an element $\\Phi\\in\\calR^\\ppp$, $R_\\Phi$ and $L_\\Phi$ are the operators $\\varphi \\mapsto R_\\Phi(\\varphi)$ and $f\\mapsto L_\\Phi(\\varphi)$ define by their actions on $\\calR^\\pp$ by $\\langle \\Psi,R_\\Phi(\\varphi)\\rangle=\\langle \\Psi\\Phi,\\varphi\nFor $f\\in (X,Z)'$, $\\langle G\\circ F, f\\rangle=\\langle G, fF\\rangle$ and \\footnote{The elements $R_{\\rho^\\ppp(F)}:\\calR(Y,Z)^\\ppp\\rightarrow \\calR(X,Z)^\\ppp$ and $L_{\\widehat{\\rho(b)}}:\\calR(X,Y)^\\ppp\\rightarrow \\calR(Y,Z)^\\ppp$ which appear below are the operators of right multiplication and left multiplication respectively and are each weak*-continuous.} \n\\begin{eqnarray*}\n\\langle G\\bullet F,f\\rangle&=&\\langle \\tau^{-1}(\\tau(G)\\tau(F)),f\\rangle\\\\\n&=&\\langle (\\rho^\\ppp)^{-1}\\circ (\\pi^\\ppp)^{-1}(\\tau(G)\\tau(F)),f\\rangle\\\\\n&=&\\langle (\\rho^\\ppp)^{-1}(\\rho^\\ppp(G)\\rho^\\ppp(F)),f\\rangle\\\\\n&=&\\langle \\rho^\\ppp(G)\\rho^\\ppp(F),(\\rho')^{-1}f\\rangle\\\\\n&=&\\langle \\rho^\\ppp(G),R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f\\rangle\\\\\n&=&\\langle G,\\rho'\\circ R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f\\rangle.\n\\end{eqnarray*}\nHence \n$\\langle G\\circ F, f\\rangle=\\langle G\\bullet F,f\\rangle $ if and only if\n\\begin{equation}\\label{eq:0920202}%(5.2)\nfF=\\rho'\\circ R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f.\n\\end{equation}\nFor $b\\in (Y,Z)$, $\\langle fF,b\\rangle=\\langle F,bf\\rangle$ and\n\\begin{eqnarray*}\n\\langle \\rho'\\circ R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f,b\\rangle&=&\\langle R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f,\\rho(b)\\rangle\\\\\n&=&\\langle \\widehat{\\rho(b)},R'_{\\rho^\\ppp(F)}\\circ (\\rho')^{-1}f\\rangle\\\\\n&=&\\langle \\rho^\\ppp(F),L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f\\rangle\\\\\n&=&\\langle F,\\rho'\\circ L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f\\rangle,\n\\end{eqnarray*}\nso (\\ref{eq:0920202}) is equivalent to\n\\begin{equation}\\label{eq:0920203}%(5.3)\nbf=\\rho'\\circ L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f.\n\\end{equation}\nFor $a\\in (X,Y)$, $\\langle bf,a\\rangle=\\langle f,ba\\rangle=\\langle \\widehat{ba},f\\rangle$ and\n\\begin{eqnarray*}\n\\langle \\rho'\\circ L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f,a\\rangle&=&\\langle L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f,\\rho(a)\\rangle\\\\\n&=&\\langle\\widehat{\\rho(a)},L'_{\\widehat{\\rho(b)}}\\circ  (\\rho')^{-1}f\\rangle\\\\\n&=&\\langle \\widehat{\\rho(b)}\\widehat{\\rho(a)},(\\rho')^{-1}f\\rangle\\\\\n&=&\\langle (\\rho^\\ppp)^{-1}(\\widehat{\\rho(b)}\\widehat{\\rho(a)}),f\\rangle,\n\\end{eqnarray*}\nso (\\ref{eq:0920203}) is equivalent to\n\\begin{equation}\\label{eq:0920204}%(5.4)\n\\rho^\\ppp(\\widehat{ba})=\\widehat{\\rho(b)}\\widehat{\\rho(a)},\n\\end{equation}\nwhich is equivalent to \n\\begin{equation}\\label{eq:0928201}%(5.5) =5.4'\n\\rho(ba)=\\rho(b)\\rho(a),\n\\end{equation}\nwhich holds since $\\rho$ is a C*-functor.\n\nFor completeness, we give details of the last stated equivalence. First note that (\\ref{eq:0920204}) is the same as \n\\begin{equation}\\label{eq:0921201}%(5.5)\n\\widehat{\\rho(ba)}=\\widehat{\\rho(b)}\\widehat{\\rho(a)}.\n\\end{equation}\nBy (\\ref{eq:0921201}) we have\n\\[\n\\langle f,\\rho(ba)\\rangle=\\langle L'_{\\widehat{\\rho(b)}}f, \\rho(a)\\rangle\n=\\langle L'_{\\rho(b)}f,\\rho(a)\\rangle=\\langle f,\\rho(b)\\rho(a)\\rangle.\n\\]\nHence (\\ref{eq:0921201}) implies (\\ref{eq:0928201}).\nConversely, by (\\ref{eq:0928201}),\n\\begin{eqnarray*}\\langle \\widehat{\\rho(ba)},f\\rangle&=&\\langle f, \\rho(ba)\\rangle\n=\n\\langle f, \\rho(b)\\rho(a)\\rangle\\\\\n&=&\\langle L'_{\\rho(b)}f,\\rho(a)\\rangle\n=\\langle \\widehat{\\rho(a)},L'_{\\rho(b)}f\\rangle\\\\\n&=&\\langle \\widehat{\\rho(a)},L'_{\\widehat{\\rho(b)}}f\\rangle\n=\\langle \\widehat{\\rho(b)} \\widehat{\\rho(a)},f\\rangle.\n\\end{eqnarray*}\nHence (\\ref{eq:0928201}) implies (\\ref{eq:0921201}). \n\\end{proof}\n\n\\subsection{The bidual of a T*-category}\n\n\n\n\n\\begin{definition}\\label{def:0821201}%5.10\nLet $\\calC$ be a linear ternary category with objects $X,Y,Z, \\ldots$, morphism spaces $(X,Y)=\\{a,b,c, \\dots\\}$, dual spaces $(X,Y)'=\\{f,g,h,\\ldots \\}$, and bidual spaces $(X,Y)^\\ppp=\\{F,G,H,\\ldots\\}$. For objects $X,Y,Z,W$ a composition   defined on $(X,Y)^\\ppp \\times (Z,Y)^\\ppp\\times (Z,W)^\\ppp\\rightarrow (X,W)^\\ppp$, denoted by \n\\[\n(X,Y)^\\ppp\\times (Z,Y)^\\ppp\\times (Z,W)^\\ppp\\ni (F,G,H) \\mapsto [HGF]\\in (X,W)^\\ppp\\]\n and given by the Arens construction is as follows. \n  \n\\begin{enumerate}\n\\itemsep1.3em \n\\item $(X,Y)\\times (Y,Z)\\times (Z,W)\\ni (a,b,c) \\mapsto [cba]\\in (X,W)$ \\\\[1.5mm]\n      $(\\hbox{composition in }\\calC)$\n\\item $(X,W)'\\times (X,Y)\\times (Z,Y)\\ni (f,a,b) \\mapsto \\mu_0(f,a,b)\\in (Z,W)'$\\\\[1.5mm] \n       $\\langle \\mu_0(f,a,b),c\\rangle=\\langle f,[cba]\\rangle$, $c\\in (Z,W)$\n\\item $(Z,W)^\\ppp\\times (X,W)'\\times (X,Y)\\ni (F,f,a) \\mapsto \\mu_1(F,f,a)\\in (Z,Y)'$\\\\[1.5mm]  \n     $\\langle \\mu_1(F,f,a),b\\rangle=\\overline{\\langle F,\\mu_0(f,a,b)\\rangle}$,   $b\\in (Z,Y)$\n\\item $(Z,Y)^\\ppp\\times (Z,W)^\\ppp\\times (X,W)'\\ni (F,G,f) \\mapsto \\mu_2(F,G,f)\\in (X,Y)'$\\\\[1.5mm]\n      $\\langle \\mu_2(F,G,f),a\\rangle=\\overline{\\langle F,\\mu_1(G,f,a)\\rangle}$, $a\\in(X,Y)$\n\\item $(X,Y)^\\ppp\\times (Z,Y)^\\ppp\\times (Z,W)^\\ppp\\ni (F,G,H) \\mapsto [HGF]\\in (X,W)^\\ppp$\\\\[1.5mm]\n$\\langle [HGF],f\\rangle=\\langle F,\\mu_2(G,H,f)\\rangle$, $f\\in(X,W)'$\n\\end{enumerate}\n\\end{definition}\nWe note that $[HGF]$ is linear in the outer variables and conjugate linear in the middle variable, and in the case of normed ternary categories, is weak*-continuous in the right variable $F$.\n\n\n\nThe following lemma is a straightforward consequence of Definition~\\ref{def:0821201}. Again, for completeness, we include the proof.\n\\begin{lemma}%5.11\n\\label{lem:1003201}\nLet $\\calC$ be a linear normed ternary category. Then for $F\\in (X,Y)^\\ppp, G\\in (Z,Y)^\\ppp, H\\in (Z,W)^\\ppp, K\\in (U,W)^\\ppp$ and $L\\in (U,V)^\\ppp$, we have \n\\begin{description}\n\\item[(i)] $\n[LK[HGF]]=[[LKH]GF].\n$\n\\item[(ii)] Assume that the triple product $[HGF]$ is separately weak*-continuous, that is, is also weak*-continuous in the left variable $H$ and the middle variable $G$. Then\n\\[\n[LK[HGF]]=[L[GHK]F]=[[LKH]GF].\n\\]\n\\end{description}\n\\end{lemma}\n\\begin{proof}\n(i) For $f\\in (X,V)'$,\n\\[\n\\langle [LK[HGF]],f\\rangle=\\langle [HGF],\\mu_2(K,L,f)\\rangle=\\langle F, \\mu_2(G,H,\\mu_2(K,L,f))\\rangle,\n\\]\nand\n\\begin{equation}\\label{eq:0925201}\n\\langle [[LKH]GF,f\\rangle=\\langle F,\\mu_2(G,[LKH],f)\\rangle,\n\\end{equation}\nso it suffices to prove\n\\[\n\\mu_2(G,H,\\mu_2(K,L,f))=\\mu_2(G,[LKH],f).\n\\]\n\nFor $a\\in (X,Y)$,\n\\[\n\\langle\\mu_2(G,H,\\mu_2(K,L,f)),a\\rangle=\\overline{\\langle G,\\mu_1(H,\\mu_2(K,L,f),a)\\rangle},\n\\]\nand\n\\begin{equation}\\label{eq:0925202}\n\\langle \\mu_2(G,[LKH],f),a \\rangle=\\overline{\\langle G,\\mu_1([LKH],f,a) \\rangle},\n\\end{equation}\nso it suffices to prove\n\\[\n\\mu_1(H,\\mu_2(K,L,f),a)=\\mu_1([LKH],f,a).\n\\]\n\nFor $b \\in (Z,Y)$,\n\\[\n\\langle \\mu_1(H,\\mu_2(K,L,f),a),b\\rangle=\\overline{\\langle H,\\mu_0(\\mu_2(K,L,f),a,b)\\rangle},\n\\]\nand\n\\begin{equation}\\label{eq:0925203}\n\\langle \\mu_1([LKH],f,a),b\\rangle=\\overline{\\langle [LKH],\\mu_0(f,a,b) \\rangle}=\\overline{\\langle H,\\mu_2(K,L,\\mu_0(f,a,b) \\rangle},\n\\end{equation}\nso it suffices to prove\n\\[\n\\mu_0(\\mu_2(K,L,f),a,b)=\\mu_2(K,L,\\mu_0(f,a,b)).\n\\]\n\nFor $c \\in (Z,W)$,\n\\[\n\\langle \\mu_0(\\mu_2(K,L,f),a,b),c\\rangle=\\langle \\mu_2(K,L,f),[cba]\\rangle=\\overline{\\langle K,\\mu_1(L,f,[cba])\\rangle},\n\\]\nand\n\\begin{equation}\\label{eq:0925204}\n\\langle \\mu_2(K,L,\\mu_0(f,a,b),c\\rangle=\\overline{\\langle K,\\mu_1(L,\\mu_0(f,a,b),c)  \\rangle},\n\\end{equation}\nso it suffices to prove\n\\[\n\\mu_1(L,f,[cba])=\\mu_1(L,\\mu_0(f,a,b),c).\n\\]\n\nFor $d \\in (U,W)$,\n\\[\n\\langle \\mu_1(L,f,[cba]),d \\rangle=\\overline{\\langle L,\\mu_0(f,[cba],d) \\rangle},\n\\]\nand\n\\begin{equation}\\label{eq:0925205}\n\\langle \\mu_1(L,\\mu_0(f,a,b),c),d\\rangle=\\overline{\\langle L,\\mu_0(\\mu_0(f,a,b),c,d)   \\rangle},\n\\end{equation}\nso it suffices to prove\n\\[\n\\mu_0(f,[cba],d)=\\mu_0(\\mu_0(f,a,b),c,d).\n\\]\n\nFor $e \\in (U,V)$,\n\\[\n\\langle \\mu_0(f,[cba],d) ,e\\rangle=\\langle f,[ed[cba]] \\rangle,\n\\]\nand\n\\begin{equation}\\label{eq:0925206}\n\\langle \\mu_0(\\mu_0(f,a,b),c,d), e\\rangle=\\langle \\mu_0(f,a,b),[edc]    \\rangle=\\langle f,[[edc]ba]\\rangle.\n\\end{equation}\nThis proves\n$\n[LK[HGF]]=[[LKH]GF].\n$\\smallskip\n\n(ii)\nFor $f\\in (X,V)'$,\n\\begin{equation}\\label{eq:0930201}\n\\langle [L[GHK]F],f\\rangle=\\langle F,\\mu_2([GHK],L,f)\\rangle,\n\\end{equation}\nso by (\\ref{eq:0925201}) and (\\ref{eq:0930201}),\n it suffices to prove\n\\[\n\\mu_2([GHK],L,f))=\\mu_2(G,[LKH],f).\n\\]\n\n\nFor $a\\in (X,Y)$,\n\\begin{eqnarray}\\nonumber\\label{eq:0930202}\n\\langle\\mu_2([GHK],L,f)),a \\rangle&=&\\overline{\\langle [GHK],\\mu_1(L,f,a) \\rangle}\\\\\\nonumber\n&=&\\overline{\\langle R_{K,H}G,\\mu_1(L,f,a)\\rangle}\\\\\n&=&\\overline{\\langle G, R_{K,H}'(\\mu_1(L,f,a))\\rangle},\n\\end{eqnarray}\nwhere  $R_{K,H}$ is, by assumption, the weak*-continuous operator sending $G$ to $[GHK]$, \nso by (\\ref{eq:0925202}) and (\\ref{eq:0930202}),\n it suffices to prove\n\\[\nR_{K,H}'(\\mu_1(L,f,a))=\\mu_1([LKH],f,a).\n\\]\n\n\nFor $b \\in (Z,Y)$,\n\\begin{eqnarray}\\nonumber\\label{eq:0930203}\n\\langle R_{K,H}'(\\mu_1(L,f,a)),b\\rangle&=&\\langle\\widehat b,R_{K,H}'(\\mu_1(L,f,a)) \\rangle\\\\\\nonumber\n&=&\\langle [\\widehat bHK],\\mu_1(L,f,a)\\rangle\\\\\n&=&\\langle H,Q'_{\\widehat b,K}( \\mu_1(L,f,a)\\rangle)\n\\end{eqnarray}\nwhere $Q_{H,K}$ is the conjugate linear and  weak*-continuous operator sending $G$ to $[HGK]$, \nand by (\\ref{eq:0925203}) and (\\ref{eq:0930203}), it suffices to prove\n\\begin{equation}\\label{eq:0930204}\n\\overline{\\langle H,\\mu_2(K,L,\\mu_0(f,a,b))\\rangle}=\\langle H,Q'_{\\widehat{b},K}(\\mu_1(L,f,a))\\rangle.\n\\end{equation}\n\nWe shall complete the proof by verifying (\\ref{eq:0930204}), and we may assume that $H=\\widehat c$ for some $c\\in (Z,W)$.\nWe may also assume, by weak*-continuity in the right variable, that $K=\\widehat d$. Thus\n\\begin{eqnarray*}\n\\langle H,Q'_{\\widehat{b},K}(\\mu_1(L,f,a))\\rangle&=&\\langle [\\widehat b\\widehat c K],\\mu_1(L,f,a)\\rangle\\\\\n&=&\\langle K, L'_{\\widehat b\\widehat c}(\\mu_1(L,f,a))\\rangle\\\\\n&=&\\langle \\mu_1(L,f,a),[bcd]\\rangle\\\\\n&=&\\overline{\\langle L,\\mu_0(f,a,[bcd])\\rangle}\n\\end{eqnarray*}\nand \n\\begin{eqnarray*}\n\\overline{\\langle H,\\mu_2(K,L,\\mu_0(f,a,b))\\rangle}&=&\\overline{\\langle \\mu_2(K,L,\\mu_0(f,a,b)),c\\rangle}\\\\\n&=&\\langle K, \\mu_1(L, \\mu_0(f,a,b),c)\\rangle\\\\\n&=&\\langle \\mu_1(L,\\mu_0(f,a,b),c),d\\rangle\\\\\n&=&\\overline{\\langle L,\\mu_0(\\mu_0(f,a,b),c,d))\\rangle}.\n\\end{eqnarray*}\nThus (\\ref{eq:0930204}) is equivalent to\n\\begin{equation}\\label{eq:0930205}\n\\mu_0(\\mu_0(f,a,b),c,d))=\\mu_0(f,a,[bcd])\\rangle.\n\\end{equation}\nTake $e\\in (U,V)$. Then\n\\[\n\\langle \\mu_0(\\mu_0(f,a,b),c,d)),e\\rangle=\\langle \\mu_0(f,a,b),[edc]\\rangle=\\langle f,[[edc]ba]\\rangle\n\\]\nand\n\\[\n\\langle \\mu_0(f,a,[bcd]),e\\rangle=\\langle f,[e[bcd]a]\\rangle\n\\]\n thus proving (\\ref{eq:0930205}) and \n$\n[LK[HGF]]=[L[GHK]F].\n$\n\\end{proof}\n\n\n\\begin{definition}%5.12\nThe {\\it Arens bidual} of a linear ternary category  $\\calC$, denoted ${\\calC}^\\ppp$, or $(\\calC^\\ppp,\\hbox{Arens})$, is the linear category having the  same objects as $\\calC$,  morphism sets $\\operatorname{Hom}(X,Y)=(X,Y)^\\ppp$ and composition %defined on $(X,Y)^\\ppp \\times (Y,Z)^\\ppp\\rightarrow (X,Z)^\\ppp$ \ngiven by the Arens construction in Definition~\\ref{def:0821201}.  The category $\\calC$ is said to be {\\it Arens regular} if the composition $[HGF]$ is separately weak*-continuous.\n\\end{definition}\n\n\n\n\n\n\n\\begin{proposition}%5.13\n\\label{prop:1005201}\nA T*-category $\\calC$ is Arens regular, and hence its\n Arens bidual  $\\calC^\\ppp$ is a T*-category.\n\\end{proposition}\n\\begin{proof} As stated in \\cite[Remark 2.10]{PeraltaEtAl},  every multilinear map $f:X_1\\times \\cdots \\times X_n\\rightarrow Y$ from Banach spaces $X_i$ satisfying Pelczynski's property $V$ to a Banach space $Y$ admits a unique separately weak*-continuous extension from $X^\\ppp_1\\times \\cdots \\times X^\\ppp_n$ to $Y^\\ppp$.  C*-ternary rings are JB*-triples and JB*-triples satisfy Pelczynski's property V (\\cite{ChuMel97}).  As stated in \n\\cite[Remark 2.3]{PeraltaEtAl}, if $f:X_1\\times X_2\\times X_3\\rightarrow Y$ admits a norm preserving extension $F:X^\\ppp_1\\times X^\\ppp_2\\times X^\\ppp_3\\rightarrow Y^\\ppp$ (produced by any method) which is separately weak*-continuous, then $f$ is Aron-Berner regular and therefore the extension given by Definition~\\ref{def:0821201} (denoted by $f^{*\\overline{*}\\overline{*}*}$ in \\cite{PeraltaEtAl}) is separately weak*-continuous.\nThus a T*-category is Arens regular.\n\n Items (i), (iii), and (iv) in Definition~\\ref{def:0804201} are immediate. Item (ii) holds by  Lemma~\\ref{lem:1003201}. By Remark~\\ref{rem:0820201}, $(X,Y)$ is \na C*-ternary ring. The bidual $(X,Y)^\\ppp$ of $(X,Y)$ is also a C*-ternary ring, by \\cite[Theorem 2]{LanRus83}, from which item (v)   in Definition~\\ref{def:0804201} follows.\n\\end{proof}\n\n\n\n\n\n\n\\section{Proof of Proposition~\\ref{prop:0912201}(iv)}\\label{sec:0906201}\n\nLet $M$ be a C*-ternary ring.  Recall that, $M$ being a normed associative triple system, it is, by Remark~\\ref{rem:0912201}, a left $L(M)$-Banach module via $L(M) \\times M\\ni (A,f)\\mapsto A\\cdot f=A_1f \\in M$ and a right $R(M)^{op}$-Banach module via $M\\times R(M) \\ni (f,B)\\mapsto f\\cdot B=B_1f \\in M$, and that\n\\[\n\\calA=\\{a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right] : A\\in L(M), B\\in R(M), f,g \\in M\\},\n\\]\nis an algebra with multiplication (\\ref{eq:0906201}) and  involution  (\\ref{eq:0906202}).\n\n\\begin{proposition}%6.1\n[Restatement of Proposition~\\ref{prop:0912201}]\nWith the above notation, we have\n\\begin{description}\n\\item[(i)] $R(M)$  is a C*-algebra with the norm from $B(M)$.\n\\item[(ii)] $M$ is a right Banach $R(M)^{op}$-module.\n\\item[(iii)] With $\\langle f|g\\rangle=\\langle f|g\\rangle_{M}:M\\times M\\rightarrow R(M)$ defined by $\\langle f|g\\rangle=r(g,f)=([\\cdot gf],[\\cdot fg])$, we have \\[\\langle f\\cdot B|g\\rangle=\n\\langle f|g\\rangle\\circ B.\\]\n\\item[(iv)] If $M$ is a right $R(M)^{op}$-Hilbert module, then $\\calA$ can be normed to be a C*-algebra.\n\n\\end{description}\n\\end{proposition}\n\n\\begin{proof}(i)-(iii) have been proved in section~\\ref{sec:1021201}.\n\n\n (iv) We mimic the proof in \\cite[8.1.17, p. 303]{BleLeM} by showing that the map $\\pi:\\calA\\rightarrow B(M\\oplus R)$ to the bounded operators on the right $R^{op}$-Hilbert module $M\\oplus R$ defined, for $a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\\in \\calA$ by \n\\begin{equation}\\label{eq:0818201}%(6.1)\n\\pi(a)\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right] =\n\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right]\n=\\left[\\begin{matrix}\nA\\cdot f'+f \\cdot B'\\\\\nr(g,f')+B\\circ B'\n\\end{matrix}\\right],\n\\end{equation}\nis an injective  *-homorphism. Letting $\\|a\\|=\\|\\pi(a)\\|$ turns $\\calA$ into a C*-algebra.\n\nWe will use the facts that $R$ is a right $R^{op}$-Hilbert module, %denoted temporarily by $\\tilde R$, \nvia\n\\[\n  R\\times R^{op}\\ni (B',B)\\mapsto  B\\cdot B'= B'\\circ B \\in R,\\] and that\n$M\\oplus  R$ is a right $R^{op}$-Hilbert module, via\n\\[\n (M\\oplus R)\\times R^{op}\\ni ((f, B'),B)\\mapsto (f, B')\\cdot B=(f\\cdot B, B'\\circ B)\\in M\\oplus  R.\\]\n Thus for $b'=\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right]$, and $b^{\\prime\\prime}=\\left[\\begin{matrix}\nf^{\\prime\\prime}\\\\\nB^{\\prime\\prime}\n\\end{matrix}\\right]$ in $M\\oplus R$,\n\\[\n\\langle b',b^{\\prime\\prime}\\rangle_{M\\oplus R}=\\langle f',f^{\\prime\\prime}\\rangle_{M}+\\langle B',B^{\\prime\\prime}\\rangle_R,\n\\]\nwhere $\\langle f,g\\rangle_{M}:=r(g,f)=([\\cdot gf],[\\cdot fg])$\nand $\\langle B',B\\rangle_R=\\overline{B}\\circ B'$.\n\n\nFirst,  with $a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\\in \\calA$,  $b'=\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right]$, and $b^{\\prime\\prime}=\\left[\\begin{matrix}\nf^{\\prime\\prime}\\\\\nB^{\\prime\\prime}\n\\end{matrix}\\right]$ in $M\\oplus R$, we have \n\n\\begin{eqnarray*}\n\\langle\\pi(a^{\\#})b',b^{\\prime\\prime}\\rangle\n&=&\n\\langle \\left[\\begin{matrix}\n\\overline{A}&g\\\\\n\\overline{f}&\\overline{B}\n\\end{matrix}\\right]\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right],\\left[\\begin{matrix}\nf^{\\prime\\prime}\\\\\nB^{\\prime\\prime}\n\\end{matrix}\\right]\\rangle\n=\n\\left[\\begin{matrix}\n\\overline{A}\\cdot f'+g\\cdot B'\\\\\nr(f,f')+\\overline{B}\\circ B'\n\\end{matrix}\\right],\\left[\\begin{matrix}\nf^{\\prime\\prime}\\\\\nB^{\\prime\\prime}\n\\end{matrix}\\right]\\rangle\\\\\n&=&\\langle \\overline{A}\\cdot f'+g\\cdot B',f^{\\prime\\prime}\\rangle_{M}\n+\n\\langle r(f,f)+\\overline{B}\\circ B', B^{\\prime\\prime}\\rangle_R\\\\\n&=&\\langle \\overline{A}\\cdot f',f^{\\prime\\prime}\\rangle_{M}+\\langle g\\cdot B',f^{\\prime\\prime}\\rangle_{M}\n+\n\\langle r(f,f'),B^{\\prime\\prime}\\rangle_R+\\langle \\overline{B}\\circ B', B^{\\prime\\prime}\\rangle_R\n\\end{eqnarray*}\n\nand\n\n\n\\begin{eqnarray*}\n\\langle\\pi(a)^*b',b^{\\prime\\prime}\\rangle\n&=&\n\\langle\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right],\\pi(a)\\left[\\begin{matrix}\nf^{\\prime\\prime}\\\\\nB''\\end{matrix}\\right]\n\\rangle\n=\\langle \\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right],\\left[\\begin{matrix}\nA\\cdot f^{\\prime\\prime}+f\\cdot B^{\\prime\\prime}\\\\\nr(g,f^{\\prime\\prime})+\\overline{B}\\circ B^{\\prime\\prime}\n\\end{matrix}\\right]\\rangle\\\\\n&=&\n\\langle f',A\\cdot f^{\\prime\\prime}\\rangle_{M}+f\\cdot B^{\\prime\\prime}\\rangle_{M} \n+\n\\langle B', r(g,f^{\\prime\\prime})+\\overline{B}\\circ B^{\\prime\\prime}\\rangle_R.\\\\\n&=&\n\\langle f',A\\cdot f^{\\prime\\prime}\\rangle_{M}+\\langle f', f\\cdot B^{\\prime\\prime}\\rangle_{M} \n+\n\\langle B', r(g,f^{\\prime\\prime})\\rangle_R +\\langle B',\\overline{B}\\circ B^{\\prime\\prime}\\rangle_R.\n\\end{eqnarray*}\n\nThe fact that $\\pi(a^{\\#})=\\pi(a)^*$ now follows from the following four identities,\n\\begin{equation}\\label{eq:0816201}%(6.2)\n\\langle \\overline{A}\\cdot f',f^{\\prime\\prime}\\rangle_{M}=\\langle f',A\\cdot f^{\\prime\\prime}\\rangle_{M}\n\\end{equation}\n\\begin{equation}\\label{eq:0816202}%(6.3)\n\\langle g\\cdot B',f^{\\prime\\prime}\\rangle_{M}=\\langle B', r(g,f^{\\prime\\prime})\\rangle_R\n\\end{equation}\n\\begin{equation}\\label{eq:0816203}%(6.4)\n\\langle r(f,f'),B^{\\prime\\prime}\\rangle_R=\\langle f', f\\cdot B^{\\prime\\prime}\\rangle_{M}\n\\end{equation}\n\\begin{equation}\\label{eq:0816204}%(6.5)\n\\langle \\overline{B}\\circ B', B^{\\prime\\prime}\\rangle_R=\\langle B',\\overline{B}\\circ B^{\\prime\\prime}\\rangle_R.\n\\end{equation}\n\nTo prove (\\ref{eq:0816201}), we may assume that $A=\\ell(h,k)=([hk\\cdot],[kh\\cdot])$. Then\n\\begin{eqnarray*}\n\\langle \\overline{A}\\cdot f',f^{\\prime\\prime}\\rangle_{M}\n&=&\n\\langle ([kh\\cdot],[hk\\cdot])\\cdot f',f^{\\prime\\prime}\\rangle_{M}\\\\\n&=&\\langle [khf'],f^{\\prime\\prime}\\rangle_{M}\\\\\n&=&r(f^{\\prime\\prime},[khf'])\\\\\n&=&([\\cdot f^{\\prime\\prime}[khf']],[\\cdot[khf']f^{\\prime\\prime}]),\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\n\\langle f',A\\cdot f^{\\prime\\prime}\\rangle_{M}&=&\\langle f',[hkf^{\\prime\\prime}]\\rangle_{M}\\\\\n&=&r([hkf^{\\prime\\prime}],f')\\\\\n&=&([\\cdot [hkf^{\\prime\\prime}]f'],[\\cdot f'[hkf^{\\prime\\prime}]]).\n\\end{eqnarray*}\n\nTo prove (\\ref{eq:0816202}), we may assume that $B'=r(h,k)=(\\cdot[hk],[\\cdot kh])$. Then \n\\begin{eqnarray*}\n\\langle g\\cdot B',f^{\\prime\\prime}\\rangle_{M}&=&\\langle[ghk],f^{\\pp}\\rangle_{M}\\\\\n&=&r(f^{\\pp},[ghk])\\\\\n&=&([\\cdot f^{\\pp}[ghk]],[\\cdot[ghk]f^{\\pp}]),\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\n\\langle B', r(g,f^{\\prime\\prime})\\rangle_R\n&=&\\overline{r(g,f^{\\pp})}\\circ ([\\cdot hk],[\\cdot kh])\\\\\n&=&([\\cdot f^{\\pp}g],[\\cdot gf^{\\pp}])\\circ ([\\cdot hk],[\\cdot kh])\\\\\n&=&([\\cdot hk],[\\cdot kh])([\\cdot f^{\\pp}g],[\\cdot gf^{\\pp}])\\\\\n&=&([\\cdot hk][\\cdot f^{\\pp}g],[\\cdot gf^{\\pp}][\\cdot kh])\\\\\n&=&([[\\cdot f^{\\pp}g]hk],[[\\cdot kh]gf^{\\pp}]).\n\\end{eqnarray*}\n\nTo prove (\\ref{eq:0816203}), we may assume that $B^{\\pp}=r(h,k)=(\\cdot[hk],[\\cdot kh])$. Then \n\\begin{eqnarray*}\n\\langle r(f,f'),B^{\\prime\\prime}\\rangle_R&=&\\langle r(f,f'),r(h,k)\\rangle_R\\\\\n&=&\\overline{r(h,k)}\\circ r(f,f')\\\\\n&=&([\\cdot ff'],[\\cdot f'f])([\\cdot kh],[\\cdot hk])\\\\\n&=&([\\cdot ff'][\\cdot kh],[\\cdot hk][\\cdot f'f])\\\\\n&=&([[\\cdot kh]ff'],[[\\cdot f'f]hk])\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\n\\langle f', f\\cdot B^{\\prime\\prime}\\rangle_{M}&=&\\langle f',[fhk]\\rangle_{M}\\\\\n&=&r([fhk],f')\\\\\n&=&([\\cdot [fhk]f'],[\\cdot f'[fhk]]).\n\\end{eqnarray*}\n\nFinally to prove (\\ref{eq:0816204}), we have\n\\[\n\\langle \\overline{B}\\circ B', B^{\\prime\\prime}\\rangle_R=\\overline{B^{\\pp}}\\circ (B\\circ B')=(B\\circ B')\\overline{B^{\\pp}}=B'B\\overline{B^{\\pp}}\n\\]\nand\n\\[\n\\langle B',\\overline{B}\\circ B^{\\prime\\prime}\\rangle_R=\\overline{\\overline{B}\\circ B^{\\pp}}\\circ B'=B'(\\overline{B^{\\pp}\\overline{B}})=B'B\\overline{B^{\\pp}}.\n\\]\n\nNext, we show that with $a,a^{\\pp}\\in \\calA$ and $b'=\\left[\\begin{matrix}\nf'\\\\\nB'\n\\end{matrix}\\right]$,\nwe have \\[\\pi(a^{\\prime\\prime})\\pi(a)b'=\\pi(a^\\ppp a)b',\\]\nso that $\\pi$ is a homorphism. \n\nWe have \n\\begin{eqnarray*}\n\\pi(a^{\\prime\\prime})\\pi(a)b'&=&\\left[\\begin{matrix}\nA^{\\prime\\prime}&f^\\ppp\\\\\n\\overline{g^\\ppp}&B^{\\prime\\prime}\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\nA\\cdot f'+f\\cdot B'\\\\\nr(g,f')+B\\circ B'\n\\end{matrix}\\right]\\\\\n&=&\n\\left[\\begin{matrix}\nA^{\\prime\\prime}\\cdot (A\\cdot f')+A^\\ppp\\cdot(f\\cdot B')+f^\\ppp\\cdot r(g,f')+f^\\ppp\\cdot (B\\circ B')\\\\\nr(g^\\ppp,A\\cdot f')+B^\\ppp\\circ r(g,f')+r(g^\\ppp,f\\cdot B')+B^\\ppp\\circ (B\\circ B')\n\\end{matrix}\\right]\n\\end{eqnarray*}\nand \n\\begin{eqnarray*}\n\\pi(a^\\ppp a)b'&=&\n\\left[\\begin{matrix}\nA^\\ppp A+\\ell(f^\\ppp,g)&A^\\ppp\\cdot f+f^\\ppp\\cdot B\\\\\n\\overline{g^\\ppp}\\cdot A+B^\\ppp\\cdot \\overline{g}&r(g^\\ppp,f)+B^\\ppp\\circ B\n\\end{matrix}\\right]\n\\left[\\begin{matrix}\n f'\\\\\nB'\n\\end{matrix}\\right]\\\\\n&=&\\left[\\begin{matrix}\n(A^\\ppp A)\\cdot f'+\\ell(f^\\ppp,g)\\cdot f'+(A^\\ppp\\cdot f)\\cdot B'+(f^\\ppp\\cdot B)\\cdot B'\\\\\nr(\\overline{g^\\ppp}\\cdot A,f)+r(B^\\ppp\\cdot \\overline{g},f')+r(g^\\ppp,f)\\circ B'+(B^\\ppp\\circ B)\\circ B'\n\\end{matrix}\\right].\n\\end{eqnarray*}\n\nThe first components of $\\pi(a^{\\prime\\prime})\\pi(a)b'$ and $\\pi(a^\\ppp a)b'$ are equal by the module properties and \n\\begin{equation}\\label{eq:0816205}%(6.6)\n\\ell(f^\\ppp,g)\\cdot f'=f^\\ppp\\cdot r(g,f'),\n\\end{equation}\nand the second components are equal because of the three identities\n\\begin{equation}\\label{eq:0816206}%(6.7)\nr(\\overline{g^\\ppp}\\cdot A,f')=r(g^\\ppp, A\\cdot f')\n\\end{equation}\n\\begin{equation}\\label{eq:0816207}%(6.8)\nr(B^\\ppp\\cdot \\overline{g},f')=B^\\ppp\\circ r(g,f')\n\\end{equation}\n\\begin{equation}\\label{eq:0816208}%(6.9)\nr(g^\\ppp,f)\\circ B'=r(g^\\ppp,f\\cdot B').\n\\end{equation}\n\nTo prove (\\ref{eq:0816205}), we have\n\\[\n\\ell(f^\\ppp,g)\\cdot f'=([f^\\ppp g\\cdot],[gf^\\ppp\\cdot])\\cdot f'=[f^\\ppp gf']\n\\]\nand\n\\[\nf^\\ppp\\cdot r(g,f')=f^\\ppp\\cdot ([\\cdot gf'],[\\cdot f'g])=[f^\\ppp gf'].\n\\]\n\n\nTo prove (\\ref{eq:0816206}), we may assume that $A=\\ell(h,k)=([hk\\cdot],[kh\\cdot])$. Then\n\\[\nr(\\overline{g^\\ppp}\\cdot A,f')=r(\\overline{g^\\ppp}\\cdot ([hk\\cdot],[kh\\cdot]),f')=r([khg^\\ppp],f')=([\\cdot [khg^\\ppp]f'],[\\cdot f'[khg^\\ppp])\n\\]\nand\n\\[\nr(g^\\ppp,A\\cdot f')=r(g^\\ppp,([hk\\cdot],[kh\\cdot])\\cdot f')=r(g^\\ppp,[hkf'])=([\\cdot g^\\ppp[hkf'],[\\cdot[hkf']g^\\ppp]).\n\\]\n\n\n\n\n\n\n\n\nTo prove (\\ref{eq:0816207}), we may assume that $B^\\ppp=r(h,k)=(\\cdot[hk],[\\cdot kh])$. Then\n\\begin{eqnarray*}\nr(B^\\ppp\\cdot \\overline{g},f')=r([gkh],f')=([\\cdot [gkh]f'],[\\cdot f'[gkh])\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\nB^\\ppp\\circ r(g,f')&=&r(g,f')(\\cdot[hk],[\\cdot kh])\\\\\n&=&\n([\\cdot gf'],[\\cdot f'g])(\\cdot[hk],[\\cdot kh])\\\\\n&=&\n([\\cdot gf'],[\\cdot hk])(\\cdot[kh],[\\cdot f'g])\\\\\n&=&([[\\cdot hk]gf'],[[\\cdot f'g]kh]).\n\\end{eqnarray*}\n\n\n\n\n\nTo prove (\\ref{eq:0816208}), we may assume that $B'=r(h,k)=(\\cdot[hk],[\\cdot kh])$. Then\n\\begin{eqnarray*}\nr(g^\\ppp,f)\\circ B'&=&([\\cdot g^\\ppp f],[\\cdot fg^\\ppp])\\circ ([\\cdot hk],[\\cdot kh])\\\\\n&=& (\\cdot[hk],[\\cdot kh]) ([\\cdot g^\\ppp f],[\\cdot fg^\\ppp])\\\\\n&=&([\\cdot hk][\\cdot g^\\ppp f],[\\cdot fg^\\ppp][\\cdot kh])\\\\\n&=&([[\\cdot g^\\ppp f]hk],[[\\cdot kh]fg^\\ppp])\n\\end{eqnarray*}\nand\n\\[\nr(g^\\ppp,f\\cdot B')=r(g^\\ppp,[fhk])=([\\cdot g^\\ppp[fhk]],[\\cdot[fhk]g^\\ppp]).\n\\]\n\nLet us now show that $\\pi$ is injective.  \nFor  $a=\\left[\\begin{matrix}\nA&f\\\\\n\\overline{g}&B\n\\end{matrix}\\right]\\in \\calA$, if $\\pi(a)=0$, then  by (\\ref{eq:0818201})\n\\[\nA\\cdot f'+f \\cdot B'=0\\hbox{ and }\nr(g,f')+B\\circ B'=0\n\\] \n for all $f'\\in M, B'\\in R$, and in particular,\n\\begin{equation}\\label{eq:0818209}%(6.10)\nA\\cdot f'=0\\hbox{ and } f\\cdot B'=0,\n\\end{equation}\nand\n\\begin{equation}\\label{eq:08182010}%(6.11)\nr(g,f')=0\\hbox{ and } B\\circ B'=0.\n\\end{equation}\n\nFrom (\\ref{eq:0818209}) with $B'=r(f,f)$, $[fff]=0$ so $f=0$.\nFrom (\\ref{eq:08182010}), $B^*B=0$  and $r(g,g)=0$, so $B=0$ and $g=0$.\n\nIt remains to show that $A=0$.  Since $\\pi(a^\\#)=0$,  we have \n\\begin{equation}\\label{eq:08182011}%(6.12)\n\\overline{A}\\cdot f'=0 \\hbox{ for all  }f'\\in M.\n\\end{equation}\nSuppose first that  $A=\\ell(g,h)$. Then by (\\ref{eq:0818209}) and (\\ref{eq:08182011}),\n$[f'gh]=0$ and $[f'hg]=0$ so that $A=([\\cdot gh],[\\cdot hg])=0$.\nBy the same argument, if $A=\\sum_i\\ell(g_i,h_i)$, then $A=0$.\n\nNow suppose $A\\in L$, let $\\epsilon>0$ and choose $A'=\\sum_i\\ell(g_i,h_i)$ with $\\|A-A'\\|<\\epsilon$. Then $\\|A'\\cdot f'\\|=\\|(A-A')\\cdot f'\\|\\le\\epsilon\\|f'\\|$, so that $\\|A\\|\\le \\|A-A'\\|+\\|A'\\|<2\\epsilon$, and $A=0$.\n\nIt remains to show that $\\pi(\\calA)$ is a C*-algebra, that is, complete, and for this it is enough to show that the range of $\\pi$ is closed.  For $T=[t_{ij}]\\in B(M\\oplus R)$, we have  $\\|t_{ij}\\|\\le \\|T\\|$. Thus if $T \\in \\overline{\\pi(\\calA)}$, then $t_{11}\\in \\overline{L}=L$, $t_{12}\\in\\overline{M}=M$, \\ldots, and so $T\\in \\pi(\\calA)$.\n\\end{proof}\n\n\n\\begin{bibdiv}\n\\begin{biblist}\n\n\\bib{Arens51}{article}{\n   author={Arens, Richard},\n   title={Operations induced in function spaces},\n   journal={Monat. f\\\"ur Math.},\n   volume={55},\n%   number={2},\n   date={1951},\n   pages={1--19},\n  }\n\n\n\n \\bib{BleLeM}{book}{\n   author={Blecher, David P.},\nauthor={Le Merdy, Christian},\n   title={Operator algebras and their modules---an operator space approach},\n   series={London Mathematical Society Monographs. New Series 30. Oxford Science Publications},\n  %journal={Proc. Amer. Math. Soc.},\n   %volume={190},\n   publisher={The Clarendon Press, Oxford University Press, Oxford},\n    date={2004},\n   % number={2},\n     pages={x+387 pp.},\n  }\n\n\\bib{ChoEff77}{article}{\n   author={Choi, Man Duen},\nauthor={Effros, Edward G.},\n   title={Infectivity and operator spaces},\n   journal={J. Functional Analysis},\n   volume={24},\n   number={2},\n   date={1977},\n   pages={156--209},\n  }\n\n \\bib{Rodriguezbook}{book}{\n   author={Cabrera Garcia, Miguel},\n   author={Rodriguez Palacios, Angel},\n  title={Non-associative normed algebras. Vol.\\ 2. Representation theory and the Zelmanov approach},\n   series={Encyclopedia of Mathematics and its Applications},\n   volume={167},\n   publisher={Cambridge University Press, Cambridge},\n    date={2018},\n   % number={2},\n     pages={xxvii+729 pp.},\n  }\n\n\\bib{ChuMel97}{article}{\n   author={Chu, Cho-Ho},\n   author={Mellon, Pauline},\n   title={JB*-triples have Pelczynski's property V},\n   journal={Manuscripta Math.},\n   volume={93},\n   number={3},\n   date={1997},\n   pages={337--347},\n  }\n\n\n\n\n \\bib{Chubook}{book}{\n   author={Chu, Cho-Ho},\n   title={Jordan structures in geometry and analysis},\n   series={Cambridge Tracts in Mathematics},\n  %journal={Proc. Amer. Math. Soc.},\n   volume={190},\n   publisher={Cambridge University Press, Cambridge},\n    date={2012},\n   % number={2},\n     pages={x+261 pp.},\n  }\n  \n \\bib{Dixmierbook}{book}{\n   author={Dixmier, Jacques},\n   title={C*-algebras},\n   series={North Holland Mathematical Library},\n  %journal={Proc. Amer. Math. Soc.},\n   volume={15},\n   publisher={Elsevier, North Holland},\n    date={1977},\n   % number={2},\n     pages={xiii+492 pp.},\n  }\n \n    \n\\bib{EffSto79}{article}{\n   author={Effros, Edward G.},\n   author={Stormer, Erling},\n   title={Positive projections and Jordan structure in operator algebras},\n   journal={Math.\\ Scand.},\n   volume={45},\n   number={1},\n   date={1979},\n   pages={127--138},\n  }\n\n\\bib{EffOzaRua01}{article}{\n   author={Edward G.\\ Effros},\n   author={Narutaka Ozawa},\n   author={Zhong-Jin Ruan},\n   title={On injectivity and nuclearity for operator spaces},\n   journal={Duke Math. J.},\n   volume={110},\n    date={2001},\n    number={3},\n     pages={489--522},\n  }\n\n\\bib{FriRus83}{article}{\n   author={Friedman, Yaakov},\n   author={Russo, Bernard},\n   title={Contractive projections on operator triple systems},\n   journal={Math.\\ Scand.},\n   volume={52},\n   number={2},\n   date={1983},\n   pages={279--311},\n  }\n\n\n\n%\\bib{FriRus85}{article}{\n  % author={Friedman, Yaakov},\n   %author={Russo, Bernard},\n   %title={Solution of the contractive projection problem},\n   %journal={J.\\ Funct.\\ Anal.},\n   %volume={60},\n   %number={1},\n   %date={1985},\n   %pages={67--89},\n  %}\n\n\n\n\n\n\\bib{GLR85}{article}{\n   author={Ghez, P.},\n   author={Lima, R.},\nauthor={Roberts, J.\\ E.},\n   title={W*-categories},\n   journal={Pacific J.\\ Math.},\n   volume={120},\n   number={1},\n   date={1985},\n   pages={79--109},\n  }\n\n\n \\bib{Heunenbook}{book}{\n   author={Heunen, Chris},\n    author={Vicary, Jamie},\n   title={Categories in quantum theory. An introduction},\n   series={Oxford Graduate Texts in Mathematics},\n  %journal={Proc. Amer. Math. Soc.},\n   volume={28},\n   publisher={OxfordUniversity Press, Oxford},\n    date={2019},\n   % number={2},\n     pages={xii+324 pp.},\n  }\n\n \\bib{Isidrobook}{book}{\n   author={Isidro, Jose M.},\n  title={Jordan triple systems in complex and functional analysis},\n   series={Mathematical Surveys and Monographs},\n  %journal={Proc. Amer. Math. Soc.},\n   volume={243},\n   publisher={American Mathematical Society, Providence, RI},\n    date={2019},\n   % number={2},\n     pages={xiii+560 pp.},\n  }\n\n%\\bib{Kaup84}{article}{\n  % author={Kaup, Wilhelm},\n   %title={Contractive projections on Jordan C*-algebras and generalizations},\n   %journal={Math.\\ Scand.},\n   %volume={54},\n   %number={1},\n   %date={1984},\n   %pages={95--100},\n  %}\n\n\n \\bib{KadRinbook}{book}{\n   author={Kadison, Richard V.},\nauthor={Ringrose, John R.},\n   title={Fundamentals of the theory of operator algebras Volume II Advanced Theory},\n   series={Pure and Applied Mathematics Academic Press, Inc.},\n  %journal={Proc. Amer. Math. Soc.},\n   %volume={190},\n   publisher={Harcourt Brace Jovanovic},\n    date={1986},\n   % number={2},\n     pages={xiv+676 pp.},\n  }\n\n\\bib{PeraltaEtAl}{article}{\n   author={Khosravi, Amin A.},\n   author={Ebrahim Vishki, Hamid Reza},\nauthor={Peralta, Antonio M.},\n   title={Aron-Berner extensions of triple maps with application to the bidual of Jordan Banach triple systems},\n   journal={Linear Algebra Appl.},\n   volume={580},\n  % number={2},\n   date={2019},\n   pages={436--463},\n  }\n  \n\\bib{LanRus83}{article}{\n   author={Landesman, E.\\ M.},\n   author={Russo, Bernard},\n   title={The second dual of a C*-ternary ring},\n   journal={Canad.\\ Math.\\ Bull.},\n   volume={26},\n   number={2},\n   date={1983},\n   pages={241--246},\n  }\n  \n  \n\\bib{Loos72}{article}{\n   author={Loos, Ottmar},\n    title={Associative Tripelsysteme},\n   journal={Manuscripta Math.},\n   volume={7},\n  % number={3},\n   date={1972},\n   pages={103-112},\n  }\n\n\\bib{Meyberg72}{article}{\n   author={Meyberg, Kurt},\n   title={Lectures on algebras and triple systems. Notes on a course of lectures given during the academic year 1971--1972 {\\rm (Available at Jordan Theory Preprint Archive \\#385)}},\n  % series={London Mathematical Society Monographs. New Series 30. Oxford Science Publications},\n journal={},\n   volume={},\n   publisher={The University of Virginia, Charlottesville, Va.},\n    date={1972},\n   % number={2},\n     pages={v+226 pp.},\n  }\n  \n\n\n\\bib{Mitchener02}{article}{\n   author={Mitchener, Paul D.},\n    title={C*-categories},\n   journal={Proc.\\ London Math.\\ Soc.},\n   volume={84},\n   number={3},\n   date={2002},\n   pages={375--404},\n  }\n\n%\\bib{Paschke73}{article}{\n  % author={Paschke, W.\\ L.},\n   %title={Inner product modules over B*-algebras},\n   %journal={Trans. Amer.\\ Math.\\ Soc.},\n   %volume={182},\n   % date={1973},\n    %number={4},\n     %pages={443--468}\n  %}\n\n\n \\bib{PluRusII}{article}{\n   author={Pluta, Robert},\n   author={Russo, Bernard},\n   title={Operator categories II. Jordan categories},\n   journal={preprint},\n   volume={},\n    date={2020},\n    number={},\n     pages={}\n  }\n\n\n \\bib{Ruan04}{article}{\n   author={Ruan, Zhong-Jin},\n   title={Type decomposition and the rectangular AFD property for W$^*$-TROs},\n   journal={Canad. J. Math.},\n   volume={36},\n    date={2004},\n    number={4},\n     pages={843--870}\n  }\n\n% \\bib{Stacho82}{article}{\n  % author={Stacho, L.\\ L.},\n   %title={A projection principle concerning biholomorphic automorphisms},\n   %journal={Acta Sci.\\ Math.\\ (Szeged)},\n   %volume={44},\n   %number={1--2},\n   % date={1982},\n    % pages={99--124}\n  %}\n\n \\bib{Takesakibook}{book}{\n   author={Takesaki, Masamachi},\n   title={Theory of operator algebras I},\n   %series={Cambridge Tracts in Mathematics},\n  %journal={Proc. Amer. Math. Soc.},\n   %volume={190},\n   publisher={Springer-Verlag},\n    date={1979},\n   % number={2},\n     pages={vii+415 pp.},\n  }\n\n\n\\bib{Zettl83}{article}{\n   author={Zettl, Heinrich},\n   title={A characterization of ternary rings of operators},\n   journal={Advances in Math.},\n   volume={48},\n   number={2},\n   date={1983},\n   pages={117--143},\n  }\n\n\n\n\n\\end{biblist}\n\\end{bibdiv}\n\n\n\n\n\\end{document}\n\n\\begin{proposition}\\label{prop:0914201}\\ %4.19\n\n\\begin{description}\n\\item[(i)] $M(R)$ and $M(L)$ are C*-algebras.\n\\item[(ii)] $V$ is a Banach $(M(L),M(R)$-bimodule and $\\overline{V}$ is a Banach $(M(R),M(L))$-bimodule.\n\\item[(iii)] With $\\langle x|y\\rangle=\\langle x|y\\rangle_{V}:V\\times V\\rightarrow M(R)$ defined by $\\langle x|y\\rangle=r(x,y)=([\\cdot xy],[\\cdot yx])$, we have, for $T\\in M(R)$ and $x,y\\in V$,\n \\]\\langle x\\cdot T|y\\rangle=\n\\langle x|y\\rangle\\circ T.\\]\n\\item[(iv)] If $V$ is a right  Hilbert $M(R)^{op}$-module, then $\\tilde{\\calA}$ can be normed to be a C*-algebra.\n\\end{description}\n\\end{proposition}\n\\begin{proof}\nsee 9-3-20pp1-5\n\\end{proof}\n\n\nTherefore if we replace $\\varphi$ and $\\psi$ in \\cite[Proposition 4.3]{Zettl83} by $\\tilde\\varphi=\\varphi\\circ \\sigma^{-1}$, and $\\tilde\\psi=\\psi\\circ \\tau^{-1}$ we have  the following polar decomposition. We note that a modified proof in the case of W*-TROs is given in \\cite[Proposition 2.3]{EffOzaRua01}, along the lines of the proof for von Neumann J*-algebras (now called JW*-triples)  in \\cite[Theorem 1]{FriRus83}.\n\n\\begin{lemma}%4.21\nLet the C*-ternary ring $V$ be the dual of a Banach space $V_*$.  If $f\\in V_*$, then there is a partial isometry $u\\in V$, that is $[uuu]=u$, and positive functionals $\\tilde\\varphi\\in R^*$ and $\\tilde\\psi\\in L^*$, such that\n\\begin{description}\n\\item[(i)] $\\tilde \\varphi(r(x,u))=f(x)=\\tilde\\psi(\\ell(x,u))$ for $x\\in V$;\n\\item[(ii)] $f(u\\cdot B)=\\tilde\\varphi (B)$ for $B\\in R$;\n\\item[(iii)] $f(A\\cdot u)=\\tilde\\psi(A)$ for $A\\in L$.\n\\end{description}\n\\end{lemma}\n\n\n\nLet us recall, from \\cite[Corollary 4.3]{Paschke73}, the self-dual completion of a right  Hilbert $\\frak A$-module $(\\calH.\\langle \\cdot|\\cdot\\rangle)$ for a fixed C*-algebra $\\frak A$, as stated in \\cite{Zettl83}.\n\n\\begin{proposition}[Proposition 2.2 in \\cite{Zettl83}]%4.22\n\\label{prop:0924201}\n Endowed with the conjugate scalar multiplication $(\\lambda,\\tau)\\mapsto \\overline{\\lambda}\\tau$, the space $\\calH^\\ppp$ of all bounded $\\frak A$ homomorphisms of $\\calH$ into the enveloping von Neumann algebra $\\frak A^\\ppp$ of $\\frak A$ becomes a right $\\frak A^\\ppp$-module by\n\\[\n(\\tau\\cdot A)(x)=A^*\\tau(x), \\quad \\tau\\in\\calH^\\ppp, \\quad A\\in \\frak A^\\ppp,\\quad x\\in \\calH.\n\\]\nMoreover, the $\\frak A$-valued inner product can be extended to an  $\\frak A^\\ppp$-valued inner product on $\\calH^\\ppp$, denoted by $\\langle \\cdot|\\cdot\\rangle$, such that\n\\begin{description}\n\\item[(i)] $(\\calH^\\ppp, \\langle \\cdot|\\cdot\\rangle)$ is a self-dual Hilbert $\\frak A^\\ppp$-module;\n\\item[(ii)] $\\|\\cdot\\|$is the operator norm induced by $B(\\calH,\\frak A^\\ppp)$;\n\\item[(iii)] $x\\mapsto \\langle \\cdot| x\\rangle$ is an isomorphism of $(\\calH,\\langle \\cdot|\\cdot\\rangle$ into $(\\calH^\\ppp,\\langle \\cdot|\\cdot\\rangle$;\n\\item[(iv)] $\\tau(x)=\\langle x|\\tau\\rangle,\\quad x\\in\\calH,\\quad \\tau\\in\\calH^\\ppp$;\n\\end{description}\n$x$ and $ \\langle \\cdot| x\\rangle$ being identified for each $x\\in\\calH$\n\\end{proposition}\n\nZettl  also notes that $\\calH^\\ppp$ is the dual space of a unique Banach space  so it has a well defined weak*-topology.  The first statement in the  following lemma is an instance of \\cite[Lemma 4.4]{Zettl83}, and the second follows in a similar fashion.\n\n\\begin{lemma}\\label{lem:0914201}%4.23\nLet $V^\\ppp$ be the self-dual completion  of $V$.\n\\begin{description}\n\\item[(i)] \nSuppose that $V$ is a right Hilbert $R^{op}$-module and let $f\\in V_*$.\nWith $f(x)=\\tilde\\varphi(r(x,u))$, define $f^\\ppp$ on $V^\\ppp$ by $f^\\ppp(\\tau)=\\tilde\\varphi(r(\\tau,u))$. Then $f^\\ppp$ is the unique weak* continuous extension of $f$ to $V^\\ppp$, and  the adjoint  $\\Phi:V^\\ppp\\to V$ of the map $f\\mapsto f^\\ppp$ is a weak*-weak* continuous projection of norm one.\n\\item[(ii)] Suppose that $V$ is a left Hilbert $L$-module, and let $g\\in V_*$.\nWith $g(x)=\\tilde\\psi(\\ell(x,u))$, define $g^{\\ppp}$ on $V^\\ppp$ by $g^{\\ppp}(\\tau)=\\tilde\\psi(\\ell(\\tau,u))$. Then $g^{\\ppp}$ is the unique weak* continuous extension of $g$ to $V^\\ppp$, and  the adjoint  $\\Psi:V^\\ppp\\to V$ of the map $g\\mapsto g^{\\ppp}$ is a weak*-weak* continuous projection of norm one.\n\\end{description}\n\\end{lemma}\n\nBy Proposition~\\ref{prop:0912201}(iii), $(V,\\langle \\cdot|\\cdot\\rangle)$ is a right $R^{op}$-Banach module,  where\n\\[\n\\langle f,g\\rangle =r(g,f)=([\\cdot gf],[\\cdot fg])\n\\]\nand \n\\[\n\\langle f,g\\rangle\\cdot h=[hgf]=h\\cdot \\langle f,g\\rangle.\n\\]\nApplying Proposition~\\ref{prop:0924201} with $\\calH=V$, $(V^\\ppp,\\langle \\cdot|\\cdot\\rangle)$ is a right $(R^\\ppp)^{op}$-Banach module,  where\n\\[\n\\langle \\sigma|\\tau\\rangle =([\\cdot \\tau\\sigma],[\\cdot \\sigma\\tau])\n\\]\nand \n\\[\n\\langle \\sigma|\\tau\\rangle\\cdot \\rho=[\\rho\\tau\\sigma]=h\\rho\\cdot \\langle \\sigma|\\tau\\rangle.\n\\]\nFor a partial isometry $u$  in $V$, let $V_2(u)$ and $V^\\ppp_2(u)$ be the Peirce 2-spaces of $u$, that is,\n\\[\nV_2(u)=\\{x\\in V:[u[uxu]u]=x\\}\n\\]\nand\n\\[\nV^\\ppp_2(u)=\\{\\tau\\in V:[u[u\\tau u]u]=\\tau\\}.\n\\]\nIt is well known and easy to check that $V_2(u)$ is a unital  C*-algebra for the product $(x,y)\\mapsto [xuy]$ and involution $x\\mapsto [uxu]$ and $V^\\ppp_2(u)$ is a W*-algebra for the product $(\\sigma,\\tau)\\mapsto [\\sigma u\\tau]$ and involution $\\tau\\mapsto [u\\tau u]$. \n\nWith the above notation, the following lemma is a restatement of \\cite[Lemma 4.5]{Zettl83}.\n\n\n\\begin{lemma}%4.24\nLet $\\Phi$ and $\\Psi$ be the projections in Lemma~\\ref{lem:0914201}. If $w$ is a partial isometry in $V$, then $\\Phi(V_2^\\ppp(w))=V_2(w)$ and $\\Psi(V_2^\\ppp(w))=V_2(w)$. In particular, $V_2(w)$ is a dual space with predual $\\{f|_{V_2(w)}:f\\in V_*\\}$. \n\\end{lemma}\n\n\n\n\\begin{lemma}%4.25\nThe module actions in Proposition~\\ref{prop:0914201} are $\\sigma$-continuous and the projections \n$\\Phi$ and $\\Psi$  in Lemma~\\ref{lem:0914201} are module homomorphisms.  Moreover $\\ker\\Phi=V^\\ppp\\cdot (1-e)$ for a unique central projection in $R^{**}$ and $\\ker\\Psi=V^\\ppp\\cdot (1-e')$ for a unique central projection in $L^{**}$.\n\\end{lemma}\n\n\n\\begin{lemma}%4.26\n$M(L)$ and $M(R)$ are W*-algebras.\n\\begin{description}\n\\item[(i)] $M(R)$ is the range of a weak*-continuous projection $P$ on $L^{**}$, \n$\\ker P=R^{**}(1-e)$,  and $P(r(\\tau,x))=r(P(\\tau),x)$ for $\\tau\\in V^\\ppp, x\\in V$;\n\\item[(ii)] $M(L)$ \nis the range of a weak*-continuous projection $Q$ on $L^{**}$, $\\ker Q=L^{**}(1-e')$, and $Q(\\ell(\\tau,x))=\\ell(Q(\\tau),x)$ for $\\tau\\in V^\\ppp, x\\in V$.\n\\end{description}\n\\end{lemma}", "meta": {"timestamp": "2020-10-29T00:04:20", "yymm": "2010", "arxiv_id": "2010.14593", "url": "https://arxiv.org/abs/2010.14593", "source": "arxiv"}}
{"text": "\\documentclass{amsart}\n%\\addtolength{\\hoffset}{- 0.5in}\n%\\addtolength{\\voffset}{-0.8in}\n%\\addtolength{\\textwidth}{1.3in}\n%\\addtolength{\\textheight}{1.4in}\n%\\usepackage[nohug]{diagrams}\n\\usepackage[mathscr]{eucal}\n\\usepackage{color}\n%\\usepackage{graphicx}\n%\\usepackage{amscd}\n\\usepackage{xypic}\n\\usepackage{amsfonts}   \n\\usepackage{amsmath}\n\\usepackage{amsthm}\n\\usepackage{amssymb}\n\\usepackage{latexsym}\n\\usepackage[english]{babel}\n\\usepackage[utf8]{inputenc}\n%\\newfont{\\msam}{msam10}\n\\def\\neweq{\\setcounter{theorem}{0}}\n\n\n\n\n\n\n\n%\\newtheorem{theorem}{Theorem}[section]\n%\\newtheorem{lemma}[theorem]{Lemma}\n%\\newtheorem{proposition}[theorem]{Proposition}\n%\\newtheorem{corollary}[theorem]{Corollary}\n%\\theoremstyle{definition}\n%\\newtheorem{definition}[theorem]{Definition}\n%\\theoremstyle{remark}\n%\\newtheorem*{remark}[]{Remark}\n%\\newtheorem*{remark}{Remark}\n%\\theoremstyle{remark}\n%\\newtheorem{xca}[theorem]{Exercise}\n%\\newtheorem{conjecture}[theorem]{Conjecture}\n%\n%\\usepackage{authblk}\n\\let\\nc\\newcommand\n\\let\\rnc\\renewcommand\n\n\\nc{\\la}{\\label}\n\n\\def\\bg{\\begin}\n\\newtheorem{conjecture}{Conjecture}\n%\\newtheorem{condition}{Condition}\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{definition}[theorem]{Definition}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{counter}[theorem]{Counter-example}\n\\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{example}[theorem]{Example}\n\\newtheorem{remark}[theorem]{Remark}\n\\newtheorem{problem}{Problem}\n\\newtheorem{assumption}{Assumption}\n%\\def\\bthm{\\begin{theorem}}\n%\\def\\ethm{\\end{theorem}}\n%\\def\\blemma{\\begin{lemma}}\n%\\def\\elemma{\\end{lemma}}\n%\\def\\bproof{\\begin{proof}}\n%\\def\\eproof{\\end{proof}}\n%\\def\\bprop{\\begin{proposition}}\n%\\def\\eprop{\\end{proposition}}\n%\\def\\bcor{\\begin{corollary}}\n%\\def\\ecor{\\end{coroll\n\\def\\k{\\mathsf k}\n\\def\\C{\\mathbb C}\n\\newcommand{\\eq}{equation}\n\\newcommand{\\Mod}{{\\tt{Mod}}}\n\\newcommand{\\Mat}{{\\tt{Mat}}}\n\\newcommand{\\Alg}{{\\tt{Alg}}}\n\\newcommand{\\HH}{{\\rm{HH}}}\n\\newcommand{\\Res}{{\\rm{Res}}}\n\\newcommand{\\Ann}{{\\rm{Ann}}}\n\\newcommand{\\Frac}{{\\rm{Frac}}}\n\\newcommand{\\eps}{\\varepsilon}\n\\newcommand{\\Tor}{{\\rm{Tor}}}\n\\newcommand{\\pr}{{\\tt can\\,}\\,}\n\\newcommand{\\ol} {\\mbox{\\rm{$1$-length}}}\n\\newcommand{\\len} {\\mbox{\\rm{length}}}\n\\newcommand{\\Spec}{{\\rm{Spec}}}\n\\newcommand{\\Span}{{\\rm{span}}}\n\\newcommand{\\Pic}{{\\rm{Pic}_{\\c}}}\n\\newcommand{\\Aut}{{\\rm{Aut}_{\\c}}}\n\\newcommand{\\Autk}{{\\rm{Aut}}}\n\\newcommand{\\Autg}{{\\rm{Aut}_{\\Gamma}}}\n\\newcommand{\\id}{{\\rm{Id}}}\n\\newcommand{\\Der}{{\\rm{Der}}}\n\\newcommand{\\Div}{{\\rm{Div}}}\n\\newcommand{\\rk}{{\\rm{rk}}}\n\\newcommand{\\Tr}{{\\rm{Tr}}}\n\\newcommand{\\tr}{{\\rm{tr}}}\n\\newcommand{\\Ker}{{\\rm{Ker}}}\n\\newcommand{\\Inn}{{\\rm{Inn}}}\n\\newcommand{\\diag}{{\\rm{diag}}}\n\\newcommand{\\Coker}{{\\rm{Coker}}}\n\\newcommand{\\ev}{{\\rm{ev}}}\n\\newcommand{\\im}{{\\rm{Im}}}\n\\newcommand{\\balpha}{{\\boldsymbol{\\alpha}}}\n\\newcommand{\\bmu}{{\\boldsymbol{\\mu}}}\n\\newcommand{\\bn}{{\\boldsymbol{n}}}\n\\newcommand{\\bk}{{\\boldsymbol{k}}}\n\\newcommand{\\bU}{{\\boldsymbol{U}}}\n\\newcommand{\\bL}{{\\boldsymbol{L}}}\n\\newcommand{\\bM}{{\\boldsymbol{M}}}\n\\newcommand{\\be}{{\\boldsymbol{\\rm e}}}\n\\newcommand{\\Ui}{U_{\\infty}}\n\\newcommand{\\blambda}{{\\boldsymbol{\\lambda}}}\n\\newcommand{\\bgg}{{\\boldsymbol{g}}}\n\\newcommand{\\Vi}{V_{\\infty}}\n\\newcommand{\\vi}{v_{\\infty}}\n\\newcommand{\\ei}{e_{\\infty}}\n\\newcommand{\\lambdai}{\\lambda_{\\infty}}\n\\newcommand{\\supp}{{\\rm{supp}}}\n\\newcommand{\\into}{\\,\\,\\hookrightarrow\\,\\,}\n\\newcommand{\\too}{\\,\\,\\longrightarrow\\,\\,}\n\\newcommand{\\onto}{\\,\\,\\twoheadrightarrow\\,\\,}\n\n\\newtheorem{corol}{Corollary}\n\\newtheorem{condition}{Condition}\n\n\n\n\n\n\\title{Holonomic modules for rings of invariant differential operators}\n\\author{ Vyacheslav Futorny and Jo\\~ao Schwarz}\n\n\\AtEndDocument{\\bigskip{\\footnotesize%\n \n \\addvspace{\\medskipamount}\n (V.\\,Futorny) \\textsc{Instituto de Matematica e Estatistica, Universidade de S\\~{a}o Paulo, Caixa Postal 66281,\\\\ S\\~{a}o Paulo, CEP 05315-970, Brasil and International Center for Mathematics, SUSTech, Shenzhen, China} \\par\n  \\textit{E-mail address}: \\texttt{futorny@ime.usp.br}  \\par\n   (J.\\,Schwarz) \\textsc{Instituto de Matematica e Estatistica, Universidade de S\\~{a}o Paulo, Caixa Postal 66281,\\\\ S\\~{a}o Paulo, CEP 05315-970, Brasil} \\par\n  \\textit{E-mail address}: \\texttt{jfschwarz.0791@gmail.com }  \\par\n \n   \\addvspace{\\medskipamount}\n  \n}}\n\n\n\n\\begin{document}\n\\maketitle\n\n%{Representations of invariants of generalized Weyl algebras}\n\n\n\\begin{abstract}\nWe study holonomic modules for the rings of invariant  differential operators  on affine commutative domains with finite Krull dimension with respect to arbitrary actions of finite groups.\n We prove the Bernstein inequality for these rings. Our main tool is  the filter dimension introduced by Bavula. \n  We extend the results for the invariants of the Weyl algebra with respect to the symplectic action of a finite group,  for the rings of invariant differential operators on quotient varieties, and invariants of certain generalized Weyl algebras under the linear actions.\nWe show that the filter dimension  of all above mentioned algebras equals $1$.\n\n\\medskip\n\n\\noindent {\\bf Keywords: Filter dimension, holonomic modules, generalized Weyl algebras, invariant differential operators} \n\\medskip\n\n\\noindent {\\bf 2020 Mathematics Subject Classification:  16P90, 16S32, 16D30, 16W70\n}\n\\medskip\n\n\\end{abstract}\n\n\n\n\\section{Introduction}\nLet $\\k$ be the base field. All rings in the paper are $\\k$-algebras. All modules are left modules, unless said otherwise.\n\nIn this paper we address representations of   subrings of invariants of generalized Weyl algebras. The later class of algebras was introduced and studied in \\cite{B0},  \\cite{Jordan} and \\cite{Rosenberg}. Many important algebras of small Gelfand-Kirillov dimension arising in noncommutative geometry  are generalized Weyl algebras, such as the first Weyl algebra and its quantization; the quantum plane and the quantum sphere; $U(sl_2(\\k))$ and its quantization; the Heisenberg algebra and its quantizations; quantum $2 \\times 2$ matrices; Witten's and Woronowic's deformations; Noetherian down-up algebras (cf. \\cite{BY}). For the representation theory of generalized Weyl algebras we refer to \\cite{B0}, \\cite{B2}, \\cite{BX}, \\cite{B5}, \\cite{B6}.\n\nWe will consider a category of holonomic modules for certain  subrings of invariants of generalized Weyl algebras under the action of  finite groups.\n\nFor an arbitrary algebra $A$ denote by $GK(A)$ the Gelfand-Kirillov dimension of $A$. Then \na finitely generated $A$-module $M$ is called \\emph{holonomic} (cf. \\cite{Krause}, \\cite{McConnell}) if $$GK(M) =\\frac{1}{2} GK (A/Ann(M)).$$ \n\nAssume $char \\, k =0$ and consider the $n$-th Weyl algebra $A_n(\\k)$. Then $A_n(\\k)$ is isomorphic to  the ring of differential operators on the polynomial algebra $\\k[x_1,\\ldots,x_n]$, or equivalently on the affine space $\\mathbb A^n$. It has\n   generators $x_1,\\ldots, x_n, y_1,\\ldots, y_n$ and defining relations \n $$[x_i,x_j]=[y_i,y_j] = 0; [y_i,x_j]= \\delta_{ij},$$ $i,j=1,\\ldots, n$. Note that $GK (A_n(\\k))= 2n$ and  for every finitely generated $A_n(\\k)$-module $M$ holds \n  {\\it the  Bernstein inequality:}  $GK (M) \\geq n$ \\cite{Bernstein}. \n  Holonomic $A_n(\\k)$-modules\n   are exactly the modules of the minimal Gelfand-Kirillov dimension, they constitute an important abelian subcategory of modules for the Weyl algebra (\\cite{Borel}).  The Bernstein inequality holds also for the rings of differential operators on smooth affine varieties (\\cite{Borel}; cf. Section 3 bellow).\n   \nAssume $\\k$ algebraically closed  of characteristic 0 and let $\\mathfrak{g}$ be an algebraic Lie algebra of finite dimension. Then  {\\it the Gabber's inequality} $$GK \\, (U(\\mathfrak{g})/Ann(M)) \\leq 2GK (M)$$ holds for any\n finitely generated $\\mathfrak{g}$-module $M$   (cf. \\cite{Jantzen}). The holonomic $\\mathfrak{g}$-modules are those modules with the minimal Gelfand-Kirillov dimension\n (cf. \\cite{Krause}, Chapter 9). However, if $\\mathfrak{g}$ is not algebraic then it is known that the Gabber's inequality does not hold \\cite{McConnell2}.\n\nTo study holonomic modules and analogues of the Bernstein inequality for infinite-dimensional affine simple algebras over an arbitrary field, Bavula \\cite{B2} introduced the notion of the {\\it filter dimension}, denoted here by $fdim$ \n (see also \\cite{B3} for details and applications). \n Our first  main result gives the\n  filter dimension of certain algebras of invariant differential operators with respect to finite groups action.\n \n\\begin{theorem}\\label{thm-main}  The filter dimension equals $1$\nfor the following algebras:\n\\begin{itemize}\n\\item $\\mathcal{D}(A)^G$, where $A$ is an affine regular commutative domain with the finite Krull dimension and $G$ is a finite group of automorphisms of $A$;\n\\item $A_n(\\k)^G$, where $G$  a finite group of symplectic automorphisms of the Weyl algebra $A_n(\\k)$; \n\\item $\\mathcal{D}(\\mathbb{A}^n/G)$, $\\k$ is algebraically closed and \n$G$ is a finite group of linear automorphisms of the affine space $\\mathbb{A}_{\\k}^n$.\n\\end{itemize}\n\\end{theorem}\n\n\nWe also extend the results of \\cite{B4} for the invariants of generalized Weyl algebras under suitable actions of complex reflection groups of type $G(m,p,r)$. Namely, we have\n\n\\begin{theorem}\\label{thm-main2}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra rank $r$ of pure type and \n $G=G(m,p,r)$. Then $fdim \\, D(a, \\sigma)^G = 1$.\n\\end{theorem}\n \n \n \n With the idea of the filter dimension we have an alternative definition of holonomic modules.\n\n\\begin{definition}\\label{def1}\nLet $A$ be an affine infinite-dimensional simple algebra. The infimum $h_A$ of the set \n$$\\{ GK(M) | M \\mbox{is finitely generated} \\, A\\mbox{-module} \\}$$ is called the holonomic number of $A$.\n\\end{definition}\n\n Suppose that $A$ is simple, $fdim \\, A \\geq 1$ and the infimum $h_A$ in Definition \\ref{def1}  is actually the minimum.\n Then in this case the definition of a holonomic $A$-module above can be replaced  by the following: a finitely generated $A$-module $M$ is holonomic if \n  $GK (M)= h_A$ (cf. Theorem \\ref{BavBer}).\n   The situation though is unclear if $fdim \\, A <1$. \n\n%Consider the Weyl algebra $A_n(\\k)= \\mathcal{D}(\\k[x_1,\\ldots,x_n])$. We are interested in finite groups $G$ of automorphisms of the Weyl algebra that act linearly: that is, are induced from finite groups of linear automorphisms $G$ (we use the same symbol in a slight abuse of notation) of $\\k[x_1,\\ldots,x_n]$, in the following way: if $g \\in G$, $g.D$, where $ D \\in \\mathcal{D}(\\k[x_1,\\ldots,x_n])=A_n(\\k)$, is the differential operator $gDg^{-1}$. If morover $\\k$ is algebraically closed, we can consider the quotient of $\\mathbb{A}^n = Spec \\, \\k[x_1,\\ldots,x_n]$ by $G$, and the ring of differential operators on $\\mathbb{A}^n/G$, which is in general a singular variety, except when $G$ is a pseudoreflection group, by Chevalley-Shephard-Todd theorem (\\cite{Benson}, Thm 7.2.1). We are also interested in finite groups of symplectitc autmorphisms of the Weyl algebra --- those that fix the subspace $span \\langle x_1, \\ldots, x_n, y_1, \\ldots, y_n \\rangle$; and certain invariant subalgebras of generalized Weyl algebras.\n\n\nIt was shown in \\cite{B4}  that, given a finite Coxeter group $W$ action on the Weyl algebra $A_n(\\k)$, the Bernstein inequality holds for $A_n(\\k)^W$: for every finitely generated $A_n(\\k)^W$-module $M$, $GK (M) \\geq n$.\n We generalize this result and prove the Bernstein inequality for  $A_n(\\k)^G$ with linear action of an arbitrary  finite group $G$.  We note that our approach is different from the one in \\cite{B4} (cf. Theorem \\ref{Bernsteinnew} bellow). \n We also prove a similar result for more general actions of finite groups of symplectic automorphisms on $A_n(\\k)$. \nMoreover, we extend this result to the ring of invariant  differential operators $\\mathcal{D}(A)^G$ on an arbitrary affine regular commutative domain $A$ with finite Krull dimension  and any finite group $G$. In particular,  all  algebras mentioned in Theorem \\ref{thm-main} and Theorem \\ref{thm-main2}\n have a \"good\" theory of holonomic modules:\n\n\n\\begin{theorem}\\label{thm-main3} Let $A$ be an affine regular commutative domain with finite Krull dimension and $GK (A)=n$, and let \n  $B$ be  one of the algebras from Theorem \\ref{thm-main} or Theorem \\ref{thm-main2}.\n% $A_n(\\k)^G$, $D(\\mathbb{A}^n/G)$ or $D(a, \\sigma)^G$ satisfying the same hypothesis as in Theorems \\ref{thm-main} and \\ref{thm-main2}. \n Then every finitely generated holonomic $B$-module  is a cyclic torsion module of finite length and its Gelfand-Kirillov dimension is no less than $n$.\n\\end{theorem}\n\nWe apply developed technique to compute the   filtered dimension and the     Krull dimension of rational Cherednik \nalgebras. In particular, we show \n\n\\begin{theorem}\\label{thm-main4}  \nThe filtered dimension of generic rational Cherednik algebras and their spherical subalgebras equals $1$. \n\\end{theorem}\n\n%Finally, our approach include a basic analysis of consequences on representation theory using the notion of multiplicity, following ideas in, e.g, \\cite{Borel}, \\cite{Krause}, \\cite{Coutinho}.\n\n%In \\cite{FS} we showed that, under very mild conditions (cf. Theorem \\ref{thmGWA} bellow), all generalized Weyl algebras are Galois orders, and hence have a representation theory that can be studied via Gelfand-Tsetlin modules. In the same paper, invariant subrings of the Weyl algebra and other rings of differential operators were discussed. A further development, which can be seen as a quantization of the results in \\cite{FS}, is \\cite{FS2}, which consider invariants of many quantum groups.\n\n%A result that was missing in \\cite{FS} was the following: we were able to show that the invariants of the Weyl algebra $A_n(\\k)$ under the action of a finite group of the Shephard-Todd list $G(m,1,n)$ are a Galois order for a suitable $\\Gamma$, but not for al $G(m,p,n)$. In \\cite{LW}, this result was obtained in the more general setting of all spherical subalgebras of rational Cherednik algebras. One of the purpose of this paper is to obtain a generalization of our results in \\cite{FS} to a big class of generalized Weyl algebras, taking invariants under the action of the groups of the aforementioned type, and relate the class of Gelfand-Tsetlin modules with holonomic modules. We will also discuss apllications to the Gelfand-Kirillov Conjecture (\\cite{Gelfand}). \n\nThe structure of the paper is as follows. \n%In the Section 2, we recall the framework of generalized Weyl algebras and Galois algebras, and the relation between them. It finishes with a very important result on the Gelfand-Kirillov dimension of Gelfand-Tsetlin modules (Thm. \\ref{GK-GT}). \nIn Section \\ref{sec-filter}, we recall the notion of a filter dimension and its main properties. Section \\ref{sec-holonomic} is the technical core of the paper: we prove a number of results on holonomic modules for simple somewhat commutative algebras, and simple filtered semi-commutative algebras which are Noetherian but not Artinian, with particular emphasis on certain generalized Weyl algebras. All of these algebras are examples of so-called \\emph{algebras with multiplicity}.\nSome of these results are probably known to specialists but we included them for the clarity of exposition. In Section \\ref{invariants} we discuss the filter dimension of rings of invariants under the action of a finite group. \n%and prove the essential Proposition \\ref{heart}. \nIn Section \\ref{sec-hol-inv} we consider the invariants of Weyl algebras, rings of invariant differential operators on quotient varieties, and invariants of generalized Weyl algebras.\nWe show that these algebras have a nice category of holonomic modules (cf. Theorems \\ref{Bernsteinnew},  \\ref{quotient1}, \\ref{genWeyl}, \\ref{goodcategory2}). Finally, in Section \\ref{section-cherednik} we compute the filtered dimension and the Krull dimension of the rational Cherednik algebras and its spherical subalgebras. \n \n\n% In Section 7 we change our discussion to Galois algebras: we discuss the relation between many diferent classes of Galois oders introduced in the literature: linear (\\cite{EFOS}), principal and rational (\\cite{H}). We show that the Galois orders obtained in \\cite{FS}, \\cite{FS2}, all of which are invariants of generalized Weyl algebras, are principal Galois orders (Thm. \\ref{areprincipal}), conjecturing this to the case to all Galois orders; and show a very general version of the Gelfand-Kirillov Conjecture for Galois algebras --- in particular, most rational Galois orders (Thm. \\ref{GelfandKirillov}). In Section 8 we discuss the Galois order structure and Gelfand-Tsetlin modules for invariant subalgebras of generalized Weyl algebras. In Proposition \\ref{tec} we show that invariants of generalized Weyl algebras which are a Galois order are again a Galois order under very general circunstances. The main result of the section is Theorem \\ref{tmain2}, whose consequence is that the invariants $A_n(\\k)^G$, where $G$ is a complex reflection group of type $G(m,p,n)$, are a Galois order (Corollary \\ref{GK}). This reproves the result on \\cite{LW} on spherical subalgebras of rational Cherednik algebras, but in a simplified manner. Finally, we show that for the invariants of the Weyl and generalized Weyl algebras in Section 6 we have, as an important subcategory of holonomic modules, the category of Gelfand-Tsetlin modules. In an appendix, we discuss a result of independent interest: a constructive way to induce modules form maximal ideals of the defining algebra of generalized Weyl algebras to an irreducible weight module.\n\n\n%We finish this section with a crucial result on the Gelfand-Kirillov dimension of certain Gelfand-Tsetlin modules that will appear recurrently on this work.\n\n%\\begin{theorem}\\label{GK-GT}\n%Let $U$ be a Galois order in $(L*\\mathcal{M})^G$, with Harish-Chandra $\\Gamma$, and $M$ a Gelfand-Tsetlin module, where $\\mathcal{M} \\simeq \\mathbb{Z}^n$. Suppose $U \\subset \\Lambda[\\mathcal{M}]$. Then $GK \\, U \\leq n$.\n%\\begin{proof}\n%Let $F$ be any finite dimensional subspace generating $M$ as an $U$-module. Let $\\{ u_i =\\sum_{m_i \\in \\mathcal{M}} \\alpha_{m_i} m_i\\}, i=1,\\ldots, s$, be a finite set of generators of $U$ as an $\\Gamma$-algebra, containing the identity. Let $V= span \\langle u_1, \\ldots, u_s \\rangle$ be the corresponding frame, and $\\mathcal{M}' \\subset \\mathcal{M}$ be the subgroup generated by $\\bigcup_{i=1}^s supp \\, u_s$. Then, since $\\Gamma$ acts locally finitelly on $M$, so do $\\Lambda$, as it is an integral extension of $\\Gamma$ by Noether's Theorem. We also have, under this conditions, that $GK \\, \\Gamma[\\mathcal{M}] = GK\\, \\Lambda[\\mathcal{M}] = growth \\, \\mathcal{M} + GK \\, \\Gamma$ (\\cite{FO1}, (6.20), cf. \\cite{McConnell}). We have that $GK \\, \\Gamma = GK \\, \\Lambda$ (cf. \\cite{McConnell}), and $limsup \\, n \\mapsto \\infty\\,  log\\,  (dim_\\k V^i F)/ \\, log \\, n \\leq growth \\, \\mathcal{M}' \\leq Growth \\, \\mathcal{M}\\simeq \\mathbb{Z}^n = n$.\n%\\end{proof}\n%\\end{theorem}\n\n\n\n\\section{The filter dimension}\\label{sec-filter}\nLet $A$ be an algebra over $\\k$. Every finite-dimensional subspace $V\\subset A$  containing the identity will be called a \\emph{frame} of $A$. Let us recall the notion of the Gelfand-Kirillov (GK) dimension of algebras and modules (cf. \\cite{Krause}).\n\n\\begin{definition}\\[ GK (A) = sup_V \\, limsup_{n \\mapsto \\infty} \\frac{log \\, dim \\, V^n}{log \\, n}, \\] where $V$ ranges through all frames of $A$.\nLet $M$ be an $A$-module. Then\n\n\\[ GK (M) = sup_{V,F} \\, limsup_{n \\mapsto \\infty} \\frac{log \\, dim \\, V^nF}{log \\, n}, \\]\n\nwhere $F$ runs through all finite dimensional subspaces of $M$ and $V$ runs through all frames of $A$.\n\\end{definition}\n\n Recall (\\cite[8.1.9]{McConnell}) that a \\emph{finite-dimensional filtration} of an algebra $A$ is a filtration $\\mathcal{F}=\\{A_i\\}_{i \\geq 0}$ such that $A_0 = \\k$ and $dim \\, A_i < \\infty, i>0$. If $N$ is an $A$-module with filtration $\\{ N_i \\}_{i \\geq 0}$, then the filtration is finite-dimensional if $dim \\, N_i < \\infty$, $i \\geq 0$.\nSuppose that $A$ is an infinite-dimensional affine algebra generated by $a_1, \\ldots a_n$.\nDefine a finite-dimensional filtration $\\mathcal{F}=\\{A_i\\}_{i \\geq 0}$ in the following way: $A_0= \\k, \\, A_1 = span \\langle 1, a_1, \\ldots, a_n \\rangle, A_i=A_1^i$. Now let $M= A M_0$ be a finitely generated $A$-module with finite-dimensional generating space $M_0$. \nThen $\\mathcal{F}$ induces a natural filtration $\\Omega = \\{M_i \\}_{i \\geq 0}$ on $M$, where $M_i=A_i M_0$. \n\n\\emph{The return function} $f_{\\mathcal{F},M_0}: \\mathbb{N} \\rightarrow \\mathbb{N} \\cup \\{ \\infty \\}$ is defined as follows:\n $f_{\\mathcal{F},M_0}(i) =$\n\n\\[ min \\{ j \\in \\mathbb{N} \\cup \\{ \\infty \\} : A_j M_{i,g} \\supset M_0 \\, \\forall M_{i,g} \\}, \\]\nwhere $M_{i,g}\\subset M_i$ runs over the finite-dimensional  subspaces  which generate $M$ as a module.\n\n\nFor each function $f: \\mathbb{N} \\rightarrow \\mathbb{N} \\cup \\{ \\infty \\}$ define $\\Gamma(f)$ as\n\n\\[ inf\\{r \\in \\mathbb{R}|f(i) \\leq i^r, i>>0 \\}. \\]\n\nNote that, if $f(i)=p(i)$ for all sufficiently large $i$ for some polynomial $p \\in \\mathbb{Q}[x]$,   then $\\Gamma(f)= deg \\, p$ (\\cite{Krause}, Chp. 2).\n\nFor a finitely generated $A$-module $M$, the \\emph{filter dimension} is defined as (\\cite{B2})\n$$fdim(M)=\\Gamma(f_{\\mathcal{F},M_0}).$$  It\n is independent of the choice of the generating set $a_1,\\ldots, a_n$ and the  subspace $M_0$ (\\cite[Lemma 1.1]{B2}). The filter dimension of $A$, $fdim(A)$, is its filter dimension as an $A \\otimes_\\k A^{op}$-module.\n\n\n\\begin{example}[\\cite{Bnew1}]\\label{example}\nLet $B$ be an affine regular commutative algebra with finite Krull dimension. Then the filter dimension of the ring of differential operators $\\mathcal{D}(B)$ on $B$ equals  $1$.\n\\end{example}\n\n The following analog of the Bernstein inequality was shown in \\cite{B2}:\n\n\\begin{theorem}\\label{BavBer}\nLet $A$ be an  infinite-dimensional affine simple algebra and $M$ a non-zero finitely generated module. Then\n\n\\[ GK (M) \\geq \\frac{GK (A)}{1+max(1+fdim(A))}.\\]\n\\end{theorem}\n\nIn view of Example \\ref{example}, this reproves the usual Bernstein inequality for rings of differential operators on smooth affine varieties (cf. \\cite{Borel}).\n\nIn general, a  computation of the filter dimension of an algebra is a difficult problem  (\\cite{B3}, \\cite{Krause} 12.9). However, it has an important property to be Morita invariant. Namely:\n\n\\begin{theorem}[\\cite{B4},Theorem 1.3, Theorem 1.6]\\label{morita}\nMorita equivalent infinite-dimensional affine simple algebras have the same filter dimension and the same holonomic number.\n\\end{theorem}\n\n\n\n\n\n\n\n\n\\section{Holonomic modules for algebras with multiplicity}\\label{sec-holonomic}\n\\subsection{Algebras with multiplicity}\nFrom now on we assume that $char \\, \\k = 0$.\nLet $A$ be a finitely generated infinite-dimensional  simple Noetherian  algebra, with a finite-dimensional filtration $\\mathcal{F}=\\{A_i \\}_{i \\geq 0}$ such that $gr_\\mathcal{F} \\, A$ is finitely generated Noetherian.\n\n\nLet $M$ be a finitely generated module over $A$ with a filtration $\\Omega=\\{M_i \\}_{i \\geq 0}$. \nWe assume that $\\Omega$ is a \\emph{good filtration}, that is\n $gr_\\Omega M$ is a finitely generated module over $gr_\\mathcal{F} \\, A$. Recall that every finitely generated module has a good filtration (\\cite{Krause}, Ch. 6).\n\n\nConsider a short exact sequence of modules $0 \\rightarrow M' \\rightarrow M \\rightarrow M'' \\rightarrow 0$ and the filtrations $\\Omega'=\\{M_i'=M_i \\cap M'\\}_{i \\geq 0}$  and $\\Omega''=\\{M_i''=M_i +M/M\\}_{i\\geq 0}$ of $M'$ and $M''$ respectively.\nThis induces an exact sequence of $gr_\\mathcal{F} \\, A$-modules:\n\n\\[ 0 \\rightarrow gr_{\\Omega'} M' \\rightarrow gr_\\Omega M \\rightarrow gr_{\\Omega''} M'' \\rightarrow 0. \\]\n\nSince $ gr_\\Omega M$ is  finitely generated  and $gr_\\mathcal{F} \\, A$ is Noetherian then $\\Omega'$ and $\\Omega''$ are  good filtrations.\n\n\\begin{definition}\\label{{theoremB11}} \\cite[12.6]{Krause}\nWe will say that $A$ is an \\emph{algebra with multiplicity} if for every finitely generated $A$-module $0 \\neq M$, $GK (M)$ is a non-negative integer, and there is a function $M\\mapsto e(M)$, \nwhere $e(M)$ is a non-negative integer, called \\emph{the multiplicity} of $M$ such that:\n for a short exact sequence of finitely generated $A$-modules\n $$0 \\rightarrow M' \\rightarrow M \\rightarrow M'' \\rightarrow 0$$ we have $GK (M) = max \\{ GK (M'), GK (M'') \\}$, and if $GK (M) = GK (M') = GK (M'')$, then $e(M)=e(M')+e(M'')$.\n\n\n\\end{definition}\n\n\nSince the Gelfand-Kirillov dimension of finitely generated modules are non-negative integers, there exists a non-zero module whose Gelfand-Kirillov dimension is precisely the holonomic number, which is a non-negative integer. Also note that if $M$ is any non-zero finitely generated module then $GK (M) \\geq 1$ and $ e(M) \\geq 1$, as  $A$ is simple infinite-dimensional.\n\n\n\n\\subsection{Somewhat commutative algebras}\nA \\emph{somewhat commutative algebra} $A$ is an algebra with a finite-dimensional filtration \n$\\mathcal{F}=\\{A_i \\}_{i \\geq 0}$ such that the graded associated algebra is finitely generated \ncommutative  (\\cite[8.6.9]{McConnell}). Affine somewhat commutative algebras are  Noetherian. Then we have from \n\\cite[Corol. 8.6.20]{McConnell}:\n\n\\begin{corollary}\nAny simple somewhat commutative algebra is an algebra with multiplicity.\n\\end{corollary}\n\n%We remark that this notion (introduced in \\cite{McConnell}, 8.6) is slightly more general than the a similar notion, that of almost commutative algebras (discussed in \\cite{Krause}, Chapter 7). The difference is that almost commutative algebras are somewhat commutative algebras with the aditional assumption that $A_i=A_1^i$. An example of a somewhat commutative algebra that is not almost commutative can be found in \\cite{McConnell}, 14.3.9.\n\n\\begin{example}\\label{example23}\nThe Weyl algebra $A_n(\\k)$ with the Bernstein filtration  is a simple somewhat commutative algebra.\n\\end{example}\n\n\\begin{example}\\label{example21}\nThe ring of differential operators $\\mathcal{D}(X)$ on an affine smooth algebraic variety $X$ is a simple somewhat commutative algebra; or, more generally, $\\mathcal{D}(B)$ the ring of differential operators on an affine regular commutative domain (cf. [15.1.21, 15.3.7, 15.5.6]\\cite{McConnell}, \\cite[Section 5]{B3}).\n\\end{example}\n\n\n\n\n\n\\subsection{Filtered semi-commutative algebras}\n\nA \\emph{filtered semi-commutative algebra} $A$ is a finitely generated algebra with a finite-dimensional filtration $\\mathcal{F}=\\{A_i \\}_{i \\geq 0}$ such that the graded associated algebra is semi-commutative (\\cite{McConnell3}) i.e., generated by elements $x_1, \\ldots, x_n$ with relations $x_i x_j = \\lambda_{ij} x_j x_i$, for some $0 \\neq \\lambda_{ij} \\in \\k$.\n\n\n\\begin{example}\nExamples of such algebras include $\\mathcal{O}_q(\\mathbb{M}_n(\\k))$, $\\mathcal{O}_q(GL_n(\\k))$, \\\\$\\mathcal{O}_q(SL_n(\\k))$ and $U_q(sl_n)$, where $0 \\neq q$ is not a root of unity (\\cite{McConnell3}).\n\\end{example}\n\nWe have \n\n\\begin{proposition}\\cite[Theorem 3.8]{McConnell3}\nAny simple filtered semi-commutative algebra is an algebra with multiplicity.\n\\end{proposition}\n\n\n\\subsection{Generalized Weyl algebras}\nWe now introduce our main example of algebras with multiplicities.\n\nLet $D$ be an algebra over $\\k$. Let $a=(a_1, \\ldots, a_n)$ be a n-uple of elements of $Z(D)$. Let $\\sigma=(\\sigma_1, \\ldots, \\sigma_n)$ be a tuple of automorphisms of $D$ such that $\\sigma_i \\sigma_j = \\sigma_j \\sigma_i$, $\\sigma_i(a_j)= a_j$, if $j \\neq i$. The \\emph{generalized Weyl algebra} (GWA for short) of rank $n$ (\\cite{B0}) is the algebra with generators $D, X_i, Y_i$, $i=1, \\ldots, n$, and relations \n\n\\[ X_i \\lambda = \\sigma_i(\\lambda) X_i; Y_i \\lambda = \\sigma_i^{-1}(\\lambda) Y_i, \\lambda \\in D; \\]\n\\[ Y_iX_i = a_i, X_i Y_i = \\sigma_i(a_i) \\].\n\nWe will denote this algebra by $D(a, \\sigma)$ and \n call  $X_i, Y_i$'s the GWA generators,  $D$   the defining algebra. We will assume that $D$ is an affine commutative domain. In this case\n every generalized Weyl algebra is a Noetherian domain and, hence, an Ore domain.\nThe tensor product over $\\k$ of two generalized Weyl algebras $D(a,\\sigma) \\otimes D(a',\\sigma') \\simeq (D \\otimes D')(a\\ast a', \\sigma \\ast \\sigma'), $ is again a generalized Weyl algebra,  where $\\ast$ is the tensor product of automorphisms, and the concatenation of $a,a'$. In particular we have\n\n\n\n\n\\begin{definition}[\\cite{B0}]\nLet $D(a, \\sigma)$ be a GWA of rank $1$, with automorphism  $\\sigma$ of infinite order. We define $D_n(a, \\sigma)$ to be $D(a, \\sigma)^{\\otimes n}$. It is itself a GWA $D'(a=(a_1, \\ldots, a_n), \\sigma=( \\sigma_1, \\ldots, \\sigma_n))$, where $D' = D \\otimes \\ldots \\otimes D$ n times, $a_i = 1 \\otimes\\ldots \\otimes a \\otimes \\ldots 1$, $a$ in the i-th position, and $\\sigma_i=1 \\otimes\\ldots \\otimes \\sigma \\otimes \\ldots 1$, $\\sigma$ in the i-th position.\n\\end{definition}\n\n\nFollowing \\cite{B5} we introduce generalized Weyl algebras of classical and of quantum types.\n Let $A=\\k[h](a, \\sigma)$ be a generalized Weyl algebra of rank 1 with $\\sigma(h)=h-1$.\nAssume that there is no  irreducible polynomial $p \\in \\k[x]$ such that both $p, \\sigma^i(p)$ are multiples of $a$ for \nany $i \\geq 0$. Then $A$ is a generalized Weyl algebra of rank 1  of \\emph{simple classical type}.  Examples of such algebras are the Weyl algebras, certain subalgebras of their invariants, and certain  primitive quotients of $U(sl_2)$, among others (cf. \\cite[Section 2]{B5}).\n\nIf  $A=\\k[h^\\pm](a, \\sigma)$ is a generalized Weyl algebra of rank $1$ with $\\sigma(h)=\\lambda h$, $0,1 \\neq \\lambda \\in \\k$,  $a \\in \\k[h]$,  $\\lambda$ is not a root of unity and  there are no irreducible polynomials $p \\in \\k[x]$ such that both $p, \\sigma^i(p)$ are multiples of $a$ for any $i \\geq 0$, then $A$ is of \\emph{simple quantum type}. Examples of such algebras are certain primitive quotients of $U_q(sl_2)$, the quantum torus (cf. \\cite[Section 2]{B5}).\n\nBoth kinds of algebras are simple.\n\nLet $A$ be a generalized Weyl algebra of rank 1 of simple classical or quantum type, $X,Y$  the $GWA$ generators, i.e., $XY=h$. Let $m = deg \\, a$ and $\\alpha$ its leading coefficient. Define a finite-dimensional filtration by $\\mathcal{B}_A = \\{B_i \\}_{i \\geq 0}$, $B_n = span \\langle H^i v_j \\rangle, 2 |i| + m |j| \\leq n$, where $v_j = X^j$ if $j >0$, $v_j =Y^j$ if $j<0$, $v_0=1$. Let $A = \\otimes_{j=0}^s A_j$ be a generalized Weyl algebra of rank $s$, where $A_j$ are generalized Weyl algebras of simple classical or quantum types.  Consider the tensor product of the filtrations $\\mathcal{B}_A = \\otimes_{j=0}^s \\mathcal{B}_{A_j}$.   Then $\\mathcal{B}_A$ is a finite-dimensional filtration.\n\n\\begin{definition}\\label{mixed}\nA generalized Weyl algebra $A$  of rank $s$ which is the tensor product of generalized Weyl algebras of simple quantum and classical type is called a generalized Weyl algebra of mixed type. If all factors of the tensor product are of the same simple type then  the algebra $A$ is called a generalized Weyl algebra of pure type. They are simple algebras.\n\\end{definition}\n\nWe have\n\\begin{theorem}\\label{GWA}\nLet $A$ be a  generalized Weyl algebra of rank $s$. \n\\begin{itemize}\n\\item\nIf $A$ if mixed type then $GK (A)=2s$. \nIn this case for each finitely generated $A$-module $M$ we have $GK (M) \\geq s$. \n\\item If $A$ is  of pure type then $A$ is algebra with multiplicity.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof}\n The  claim about generalized Weyl algebras   of mixed type  follows from \\cite[Theorem 2.1]{B5}. For generalized Weyl algebras of pure type, the filtration  above shows that it is either somewhat commutative (the case of all tensor factors of simple classical type); or else filtered semi-commutative after taking a quotient by normal elements in the graded associated algebra (the case of all tensor factors  of simple quantum type), as shown in \\cite[Section 2]{B5} (cf. \\cite[Theorem 2.2, 3.2]{B1}).\n\\end{proof}\n\n\n\n\n\n\n\\subsection{Category $\\mathcal{H}$}\n\nFor an algebra with multiplicity $A$, denote\n by $\\mathcal{H}=\\mathcal{H}(A)$ the category of finitely generated holonomic modules, that is  for any $M\\in \\mathcal{H}$, $GK (M)= h_A$. \n\n\n%As we remarked above, this class in non-empty\n\n\\begin{theorem}\\label{abelian1}\n The category $\\mathcal{H}$ is  abelian and every module $M\\in \\mathcal{H}$ has finite length bounded by $e(M)$. Finally, if $A$ is not Artinian, every holonomic module is cyclic.\n\\end{theorem}\n\n\\begin{proof}\nFirst statement is clear. Let $M \\in \\mathcal{H}$,  $M = M_0 \\supset M_1 \\ldots \\supset M_s$ be a strictly descending chain of submodules. Hence $M_i \\in \\mathcal{H}$ and $M_i/M_{i+1} \\in \\mathcal{H}$. As $e(M_i/M_{i+1}) \\geq 1$, then we have\n $$s \\leq \\sum_{j=0}^{s-1} e(M_j/M_{j+1}) =  e(M/M_s) \\leq e(M).$$ \n Hence, every module $M \\in \\mathcal{H}$ is Artinian, and since $M$ is finitely generated then $M$ is also Noetherian. Finally, if $A$ is not Artinian, $M$ is cyclic by \\cite[Theorem 2.5]{Coutinho}.\n\\end{proof}\n\n\n%We are going to discuss now some consequences of the notion of multiplicity for algebras. Our presentation is standard (cf. \\cite{Coutinho}, \\cite{B1}, \\cite{Krause}, \\cite{Borel}).\n\n%Recall the following impressive result from ring theory\n\n%\\begin{theorem}\n%Let $R$ be a Noetherian ring that is not Artinian, and $M$ a finitely generated module which has a finite composition series. Then $M$ is cyclic.\n%\\begin{proof}\n\n\nWe immediately have\n\n\\begin{corollary}\nEvery module $M \\in \\mathcal{H}$  with $e(M)=1$ is irreducible.\n\\end{corollary}\n\n%\\begin{proof}\n%Let $ 0 \\neq N \\triangleleft M$. Consider the short exact sequence $0 \\rightarrow N \\rightarrow M \\rightarrow M/N \\rightarrow 0$. Since all modules are holonomic, we have  $e(M) = e(N) + e(M/N)$. Since $N \\neq 0$ and $e(M)=1$, then $e(M)=e(N)=1$ and $e(M/N) =0$. Hence  $M=N$.\n%\\end{proof}\n\n\n\nWe also have\n\n\\begin{corollary}\\label{prop-torsion}\nIf $GK (A) > h_A$, then every module in $\\mathcal{H}$ has torsion.\n\\end{corollary}\n\n\\begin{proof}\nLet $M \\in \\mathcal{H}$, $ 0 \\neq m \\in M$. Consider the map $\\phi: A \\rightarrow M$, $a \\mapsto am$. Then $Im \\, \\phi$ is a non-null submodule of $M$, and hence by Theorem \\ref{abelian1}, belongs to $\\mathcal{H}$. Consider the short exact sequence $0 \\rightarrow ker \\, \\phi \\rightarrow A \\rightarrow Im \\, \\phi \\rightarrow 0$. $GK (A) = max \\{ GK (ker \\, \\phi), GK (Im  \\, \\phi) \\}$, so $GK (ker \\, \\phi) = GK (A) >0$\nas $GK \\, ker (\\, \\phi) = h_A$\n; this implies that the kernel is nonzero and hence  $M$ has a torsion.\n\\end{proof}\n\nOn the other hand the following is valid.\n%There is a partial converse to Proposition \\ref{prop-torsion}\n\n\\begin{proposition}\nLet $A$ be  a domain with multiplicity and $I$ a non-zero left ideal of $A$. Then $GK (A/I) \\leq GK (A) -1$.\n\\end{proposition}\n\n\\begin{proof}\nSuppose first that $I=Aa$, $0 \\neq a \\in A$. Consider a short exact sequence \n$$0 \\rightarrow A \\rightarrow A \\rightarrow A/Aa \\rightarrow 0,$$ where the first map is a multiplication by $a$. If $GK (A/Aa) = GK (A)$, then $m(A) = m(A) + m(A/Aa) > m(A)$ which is clearly absurd. Hence, $GK (A/Aa) < GK (A)$. In the general case, $I$ contains a principal left ideal $Aa$, and $A/I$ is a quotient of $A/Aa$. Hence $GK (A/I) < GK (A)$.\n\\end{proof}\n\n\n%\\begin{remark}\n%This result also holds without a theory of multiplicity (\\cite{McConnell}, 8.3.5), but the proof is harder.\n%\\end{remark}\n\n\\begin{theorem}\\label{curious} Let $A$ be  a domain with multiplicity such that\n $GK (A) = 2$ and $h_A=1$. Then a finitely generated $A$-module  $M$ belongs to $ \\mathcal{H}$ if and only if it has a torsion.\n \\end{theorem}\n \n\n\\begin{proof}\nAssume that  the module $M$ has a torsion. Let us show that $M$ is holonomic. Suppose that $M$ is generated by elements $m_1, \\ldots, m_s$. Since $M$ has a torsion, $Am_i$ is a quotient of $A/J_i$ for certain left ideals $0 \\neq J_i \\subset A, i=1,\\ldots, s$. Each $A/ J_i$ is holonomic by the proposition above with the Gelfand-Kirillov dimension  $1$.   Hence all modules $Am_i$ and  $M = \\sum_{i=0}^s A m_i$ are  holonomic  by Theorem \\ref{abelian1}. \n\\end{proof}\n\n\nAs a consequence we immediately obtain the following well-known result\n\n\n\\begin{corollary} Let $\\k$ be algebraically closed.\nEvery finitely generated weight module for $A_n(\\k)$ is holonomic.\n\\end{corollary}\n\n\n\n\\begin{proof} Every finitely generated weight $A_n(\\k)$-module $M$ has finite length. Since $A_n(\\k)$ is an algebra with multiplicity, it suffices to consider the case when $M$ is a simple module. In this case we have that $M$ is the tensor product of $n$-simple weight modules for $A_1(\\k)$ (cf. \\cite{BBF}).\n But every such $A_1(\\k)$-module has a torsion. Hence, the result follows from Theorem \\ref{curious}.  \\end{proof}\n\n\n\n\n\n\n\n\n\n\\section{Filter dimension of invariants}\\label{invariants}\nAssume that $char \\, \\k =0$ and\n $A$ is a simple finitely generated Noetherian algebra. Let $a_1, \\ldots a_n$ be the generated of $A$.\n \n Define a filtration $\\mathcal{F}=\\{A_i\\}_{i \\geq 0}$: $A_0= \\k, \\, A_1 = span \\langle 1, a_1, \\ldots, a_n \\rangle, A_i=A_1^i$, $i=1, \\ldots, n$.\nSet $$\\nu_\\mathcal{F}(i) = inf \\{j \\in \\mathbb{N} \\cup \\{ \\infty \\} | 1 \\in A_j a A_j, \\, \\forall a \\in A_i \\}.$$\n\n\\begin{proposition}[\\cite{B5}, Lemma 1.1]\n$\\Gamma(\\nu_\\mathcal{F}) = fdim \\, A$.\n\\end{proposition}\n\n\nWe recall some facts on the invariants of noncommutative rings that will be  used in what follows (cf. \\cite[Theorem 2.5, Corollary 2.6]{Montgomery},  \\cite{Montgomery2} and \\cite[8.2.9]{McConnell}).\n\n\\begin{theorem}\\label{ring}\nLet $G$ be a finite group of outer automorphisms of $A$ and $A*G$ the skew group ring.\n\\begin{enumerate}\n\n\\item \n$A^G$ is a simple ring Morita equivalent to $A*G$ and  $GK (A^G)= GK (A)$.\n\\item\n$A^G$ is finitely generated and Noetherian; if $A$ is not Artinian then neither is $A^G$. \n\\end{enumerate}\n\\end{theorem}\n\n\n%\\begin{proof}\n%Since $G$ consists of outer automorphisms, $A*G$ and $A^G$ are Morita equivalent (\\cite{Montgomery}, Thm. 2.5). $A*G$ is Noetherian, $GK \\, A*G= GK \\, A$ and the Gelfand-Kirillov dimension is Morita invariant (\\cite{McConnell}, 8.2.9). We also have that $A^G$ is simple (\\cite{Montgomery}, Corol. 2.6). This proves point (1). Regarding point (2), we have already shown that the algebra is Noetherian. It is not Artinian:  by \\cite{Montgomery}, Thm. 2.5, $A$ is a finitely generated moduler over $A^G$. Hence, were the subalgebra of invariants Artinian, $A$ would be an Artinian module over it, and hence over itself --- which is false. Finally, $A^G$ is finitely generated by Montgomery-Small noncommutative generalization of Noether's Theorem \\cite{Montgomery2}. This proves point (3).\n%\\end{proof}\n\n\nWe are now going to explore the connection between the filter dimensions of $A$ and $A^G$. Suppose that $G$ acts by outer automorphisms.  We can assume without loss of generality that $G$ stabilizes $A_1$: just consider the set $\\{ g(a_i)| g \\in G, i=1,\\ldots, n \\}$ as generators for $A$. Then the algebra $A*G$ is simple by Theorem \\ref{ring}, and posseses a filtration $\\mathcal{F}'=\\{ B_i \\}_{i \\geq 0}$, with $B_0 = \\k$ and $B_1 = span \\langle a_1, \\ldots, a_n, g \\in G \\rangle$.\n\n\\begin{lemma}\nFor every $i$, $\\nu_{\\mathcal{F}'}(i) \\leq \\nu_\\mathcal{F}(i)$.\n\\end{lemma}\n\n\\begin{proof}\nLet $b \\in B_i$. If $\\nu_\\mathcal{F}(i) = \\infty$ then the claim is clear. Otherwise, consider the idempotent $e= \\frac{1}{|G|} \\sum_{g \\in G} g$. Then $e \\in B_j, j \\geq 1$. We also have $A_j \\subset B_j$. Symmetrizing we have $ebe \\in A^G \\subset A$; in fact $ebe \\in A_j$. Hence, if $\\nu_\\mathcal{F}(i) = k$ then $1 \\in A_k ebe A_k$, and hence $1 \\in B_k b B_k $. So we are done.\n\\end{proof}\n\n\n\\begin{proposition}\\label{heart}\nWe have\n$fdim A^G  \\leq fdim A$. Moreover, if $fdim \\, A = 1$ and there exists a finitely generated $A^G$-module $M$ such that $GK (M) \\leq \\frac{1}{2}GK (A^G)$, then $fdim \\, A= fdim \\, A^G$.\n\\end{proposition}\n\n\\begin{proof} Since  $A^G$ and $A*G$ are Morita equivalent by Theorem \\ref{ring} (2), then \nthe first claim follows from the above lemma and Theorem \\ref{morita}. If $fdim \\, A = 1$ then $fdim \\, A^G \\leq 1$. If there exists  a module $M$ which satisfying the hypothesis then $fdim \\, A^G \\geq 1$ by \\cite[Corollary 1.7(i)]{B3}.  The statement follows.\n\\end{proof}\n\n\n\\\n\n\n\n\n\n\n\n\n \\section{Holonomic modules for invariant subalgebras}\\label{sec-hol-inv}\nThis section contains our main results. We assume that $\\k$ has characteristic $0$ and use\nthe theory developed in previous sections to show that $A(\\k)^G$ and $\\mathcal{D}(\\mathbb{A}^n/G)$ have a good theory of holonomic modules  for suitable actions of $G$ (Theorems \\ref{Bernsteinnew}, \\ref{quotient1}, \\ref{goodcategory2}).\n The same holds for adequate invariant subrings of generalized Weyl algebras of pure type (Theorems \\ref{genWeyl}, \\ref{goodcategory3}). \n\n\n\n %We also show a very nice criterion relating holonomicity and torsion in modules for certain algebras of small Gelfand-Kirillov dimension (Theorem \\ref{curious3}).\n\n\\subsection{Invariant differential operators}\nLet $A$ be a commutative $\\mathsf{k}$-algebra. \nThe algebra of differential operators on $A$ is defined as follows.\nSet  $\\mathcal{D}(A)_0=A$, $\\mathcal{D}(A)_n = \\{ d \\in End_\\mathsf{k} \\, A | [d,a] \\in \\mathcal{D}(A)_{n-1}, \\forall a \\in A \\}$, and  $\\mathcal{D}(A)=\\bigcup_{i=0}^\\infty \\mathcal{D}(A)_i$. This way we obtain a natural structure of filtered associative $\\mathsf{k}$-algebra.\n\nWe recall \n\n\\begin{proposition}\\label{nsprop0}\\cite[Chapter 15]{McConnell}\nIf $A$ is affine and regular then $\\mathcal{D}(A)$ coincides with the subring of $End_\\mathsf{k} \\, A$ generated by $A$ and the module $Der_\\mathsf{k} \\, A$ of $\\mathsf{k}$-derivations. $\\mathcal{D}(A)$ is a simple affine Noetherian domain, and $GK (\\mathcal{D}(A)) = 2 \\, GK (A)$.\n\\end{proposition}\n\nThrough the rest of this subsection we assume that $A$ is an affine regular commutative domain with finite Krull dimension, i.e. the algebra of regular functions on a smooth affine irreducible variety. Then the algebra $\\mathcal{D}(A)$ has a finite-dimensional filtration $\\mathcal{F}$ such that $gr_\\mathcal{F}\\mathcal{D}(A)$ is affine commutative by \\cite[15.1.21, 15.3.7,15.5.6]{McConnell},  that is $\\mathcal{D}(A)$ is a somewhat commutative algebra (cf. Example \\ref{example21}). In particular, $\\mathcal{D}(A)$ is a simple algebra with multiplicity and $fdim \\, \\mathcal{D}(A) = 1$ (cf. Example \\ref{example}). Note that $\\mathcal{D}(A)$ is not an Artinian ring.\n\nLet $G$ be a finite group of algebra automorphisms of $A$. Then $G$ acts on $\\mathcal{D}(A)$ by conjugation:\n if $g \\in G$ and $ d \\in \\mathcal{D}(A)$ then $g.d=gdg^{-1}$. The subalgebra $\\mathcal{D}(A)^G$ of $G$-invariant differential operators \n inherits a finite-dimensional filtration $\\mathcal{F}'=\\{A_i':=A^G \\cap A_i \\}_{i \\geq 0}$.\n\n\n\\begin{proposition} \\label{nsprop1}\n$\\mathcal{D}(A)^G$ is a somewhat commutative algebra with the filtration $\\mathcal{F}'$.\n\\begin{proof} Since $A$ and $Der_\\k \\, A$ are $G$-stable then\nwithout loss of generality one can assume that for each $A_i, i \\geq 0$ in the filtration $\\mathcal{F}$ holds $G(A_i) \\subset A_i, i \\geq 0$. This is due to \\cite[Proposition 8.6.7, 8.6.9]{McConnell} and to the fact that $\\mathcal{D}(A)$ is an almost centralizing extension of $A$ \\cite[Theorem 15.1.20(i)]{McConnell}. Then we have that $gr_{\\mathcal{F}'} \\mathcal{D}(A)^G \\simeq (gr_\\mathcal{F} \\mathcal{D}(A))^G$ by \\cite[3.2.3]{Dumas}. By the Noether's Theorem, the right hand side of this isomorphism is an affine algebra and the statement follows.\n\\end{proof}\n\\end{proposition}\n\n\\begin{proposition} \\label{nsprop2}\nThe units of $\\mathcal D(A)$ are the units of $A$.\n\\end{proposition}\n\n\\begin{proof}\nLet $y_1, \\ldots, y_t$ be a transcendence basis of the field of fractions of  $A$. Suppose that $x \\in \\mathcal D(A)$ is a unit. A localization $\\mathcal D(A)_c$ of $\\mathcal D(A)$ by a certain non-zero regular element $c$ is isomorphic to an iterated Ore extension $ A[x_1; -\\partial_{y_1}], \\ldots, [x_t; -\\partial_{y_t}]$ of $A$, by \\cite[15.1.25, 15.2.6, 15.3.2]{McConnell}. \nSince  $\\mathcal D(A)$ embeds into $\\mathcal D(A)_c$, then $x$ is a unit of $ A[x_1; -\\partial_{y_1}], \\ldots, [x_t; -\\partial_{y_t}]$, and hence of  $A$. \n\\end{proof}\n\n\n%\\begin{proposition} \\label{nsprop3}\n%Let $g$ be the automorphism of $D(A)$ induced, by conjugation, from an inner automorphism $x \\mapsto y^{-1} x y$ of $A$. Then $g$ is the trivial automorphism.\n%\\begin{proof}\n%It is clear that $g$ acts trivialy on $A$. Let $D$ be a derivation, $x \\in A$. Then \\[ g.D(x) = g D(g^{-1} x) = g (D (y^{-1} x y)) = g (D(x) + xy^{-1} D(y) + xy D(y^{-1})) = g D(x) = D(x), \\]\n\n%and hence $g$ also acts trivially on $Der_\\k \\, A$. Since $A$ and $Der_\\k \\, A$ generate $D(A)$ as algebra, we are done.\n%\\end{proof}\n%\\end{proposition}\n\nFrom Proposition  \\ref{nsprop2} we immediately have\n\n\\begin{corollary}\\label{nscorol1}\nLet $G$ be a non-trivial finite group of automorphisms of $A$ with induced action on $\\mathcal D(A)$ by conjugation. Then the action of $G$ is outer.\n\\end{corollary}\n\n\n\\begin{theorem}\\label{nsthm1}\nLet $G$ be a finite group of automorphisms of $A$ with induced action on $\\mathcal D(A)$ by conjugation. Set $n = GK (A)$. Then\n\\begin{enumerate}\n\\item\n$\\mathcal D(A)^G$ is a simple ring Morita equivalent to $\\mathcal D(A)*G$, both have the Gelfand-Kirillov dimension $2n$.\n\\item\n$\\mathcal D(A)^G$ is finitely generated Noetherian but not Artinian.\n\\item $fdim \\, \\mathcal D(A)^G = 1$, $h_{\\mathcal D(A)^G}=n$, and  every finitely generated $\\mathcal D(A)^G$ module $M$ satisfies the Bernstein inequality $GK (M) \\geq n$.\n\\item Let $M\\in \\mathcal{H}(\\mathcal D(A)^G)$ be a holonomic $\\mathcal D(A)^G$-module. Then $M$ is  cyclic  torsion module with finite length bounded by $e(M)$. Moreover, $M$ is simple \nif $e(M)=1$.\n%$\\mathcal D(A)^G$ is a somewhat commutative algebra.\n\\end{enumerate}\n\\end{theorem}\n%\\begin{proof}\n%Statements (1) and (2) follow immediately from Theorem \\ref{ring}, in view of Proposition \\ref{nsprop0} and Corollary \\ref{nscorol1}. Statement (3) is Proposition \\ref{nsprop1}.\n%\\end{proof}\n\n\\begin{proof} Applying Theorem \\ref{ring}, Proposition \\ref{nsprop0} and Corollary \\ref{nscorol1} we obtain\nfirst two statements. \nRecall that $fdim \\, \\mathcal D(A)=1$. %The proof is essentially an application of Proposition \\ref{heart}. \nWe have that $A^G$ is a $\\mathcal D(A)^G$-module of the Gelfand-Kirillov dimension $n$. Hence,  by Proposition \\ref{heart}, $fdim \\, \\mathcal D(A)^G = 1$. The Bernstein inequality then follows from Theorem \\ref{BavBer}. Since we have explicitly constructed a module with the minimal possible Gelfand-Kirillov dimension, then $h_{\\mathcal D(A)^G}=n$.\n\\end{proof}\n\n\n\n\n\n\n\\subsection{Invariants of the Weyl algebra}\nLet $x_1, \\ldots, x_n, y_1, \\ldots, y_n$ be the standard generators of the Weyl algebra $A_n(\\k)$, \n identified with the algebra of $ \\mathcal{D}(\\k[x_1,\\ldots,x_n])$ of differential operators on the polynomial ring. \n  The linear actions of  finite groups of automorphisms on $A_n(\\k)$ by conjugation are   induced from the linear actions on $\\k[x_1,\\ldots,x_n]$. Recall that an automorphism of $A_n(\\k)$ that fixes the subspace $span \\langle x_1, \\ldots, x_n, y_1, \\ldots, y_n \\rangle$ is called a \\emph{symplectic automorphism}.  In particular, every  linear automorphism of $A_n(\\k)$ is a\nsymplectic automorphism \\cite{Dumas}.\n \n\n\n\\begin{corollary}\\label{Weyl} Let $G$ be a finite group of symplectic automorphisms of $A_n(\\k)$. We have:\n\\begin{enumerate}\n\\item\n$A_n(\\k)^G$ is a simple ring Morita equivalent to $A_n(\\k)*G$, both have the Gelfand-Kirillov dimension $2n$.\n\\item\n$A_n(\\k)^G$ is finitely generated Noetherian but not Artinian.\n\\item\n$A_n(\\k)^G$ is a somewhat commutative algebra.\n\\end{enumerate}\n\\begin{proof}\nStatements (1) and (2) follow immediately from Theorem \\ref{ring}. Introduce a filtration $\\mathcal{E}=\\{E_i \\}_{i \\geq 0}$ on $A_n(\\k)^G$ induced from the Bernstein filtration $\\mathcal{B}=\\{ B_i \\}_{i \\geq 0}$: $E_i = B_i \\cap A_n(\\k)^G$. Then $gr_\\mathcal{E} A_n(\\k)^G \\simeq (gr_\\mathcal{B} \\, A_n(\\k))^G$ (\\cite{Dumas}), which is a finitely generated commutative algebra by the Noether's theorem. Statement (3) follows. \\end{proof}\n\\end{corollary}\n\n\n\n\n\\begin{theorem}\\label{Bernsteinnew} Let $G$ be a finite group of symplectic automorphisms of $A_n(\\k)$. \n\\begin{itemize}\n\\item $fdim \\, A_n(\\k)^G = 1$, $h_{A_n(\\k)^G}=n$, and  every finitely generated $A_n(\\k)^G$ module $M$ satisfies the Bernstein inequality $GK (M) \\geq n$.\n\\item  If $M$ is a  holonomic $A_n(\\k)$-module then $M$ is a cyclic torsion module of finite length bounded by $e(M)$. In particular, $M$ is simple\nif $e(M)=1$.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof} If the action of $G$ is linear then the statements follow from Theorem \\ref{nsthm1}. We now consider an arbitrary action of $G$. First note that\n%The proof is essentially an application of Proposition \\ref{heart}. In the case when $G$ is a finite group that acts by linear automorphisms, we have that $\\k[x_1,\\ldots,x_n]^G$ is a $A_n(\\k)^G$-module of the Gelfand-Kirillov dimension $n$. Hence,  by Proposition \\ref{heart}, $fdim \\, A_n(\\k)^G = 1$. The Bernstein inequality then follows from Theorem \\ref{BavBer}. Since we have explicitly constructed a module with minimal possible Gelfand-Kirillov dimension, then $h_{A^G}=n$.\n $G$ preserves the Bernstein filtration of $A_n(\\k)$. Since $G$ is finite then we have $h_{A_n(\\k)*G}=h_{A_n(\\k)}=n$. Hence $h_{A^G}=n$ by Theorem \\ref{morita}. Since the algebra  $A_n(\\k)^G$ is somewhat commutative, there  exists a module $0 \\neq M$ with the minimal Gelfand-Kirillov dimension. Hence,  $fdim \\, A_n(\\k)^G =1$ by Proposition \\ref{heart}.\n\\end{proof}\n\n\n\\\n\n\n\n\n\n\\subsection{ Differential operators on quotient varieties}\nFrom now on we assume that $\\k$ is algebraically closed. Consider the quotient of $\\mathbb{A}^n = Spec \\, \\k[x_1,\\ldots,x_n]$ by $G$, and the ring of differential operators on $\\mathbb{A}^n/G$.\nNote that in general $\\mathbb{A}^n/G$ is a singular variety, except when $G$ is a pseudo-reflection group by the Chevalley-Shephard-Todd theorem (\\cite[Theorem 7.2.1]{Benson}). \n\n\nLet $W$ be a finite group of linear automorphisms of $\\k[x_1,\\ldots,x_n]$, $N\\subset W$ a subgroup generated by the pseudoreflections. Then $N$ is normal in $W$ (cf. \\cite[pp. 259]{Traves}). Further on, we have \n natural isomorphisms $$\\k[x_1,\\ldots,x_n]^W \\simeq (\\k[x_1, \\ldots, x_n]^N)^{W/N} \\simeq \\k[x_1, \\ldots, x_n]^{W/N},$$\n where the second isomorphism follows from the Chevalley-Shephard-Todd theorem.  Moreover, \n the induced action of $W/N$ on the polynomial algebra is  linear. Now we have\n\n\n\n\n%\\begin{proof}\n%For the normality of $N$, we just need to check that if $s$ is a pseudoreflection, then so is $wsw^{-1}$, for any $w \\in W$. For a $w\\in W$ denote by $H_w$ the linear subvariety  of $\\mathbb{A}^n = Spec \\, \\k[x_1,\\ldots,x_n]$.\n %fixed pointwise by $w$. We have $w(H_s) \\subset H_{wsw^{-1}}$. Then $1 \\leq codim (H_{wsw^{-1}}) \\leq codim(w(H_s))=1$ and $N$ is normal in $W$.\n\n%Let  $\\k[x_1,\\ldots,x_n]^+$ be a subspace of $\\k[x_1,\\ldots,x_n]$ which \n%consists of polynomials with {\\color{red} non-zero???? Not a subspace!!!!!} constant term.\n%Consider the vector subspace $((\\k[x_1,\\ldots,x_n]^{+})^N)^2$ of $\\k[x_1, \\ldots, x_n]^N$. \n%It has a complement $U$ in $\\k[x_1, \\ldots, x_n]^N$ with a basis $B$. Then $W/N$  acts by linear transformations on $B$. By the homogeneous Nakayama lemma, $B$ is a minimal generating set of $\\k[x_1,\\ldots,x_n]^N$, hence the result follows (cf. \\cite[pp. 259]{Traves}). \n%\\end{proof}\n\n\n\\begin{lemma}\\label{quotient1}\nLet $W$ be any finite group of linear automorphisms of the polynomial ring $\\k[x_1,\\ldots,x_n]$ (and hence of the affine space $\\mathbb{A}^n$). Then $\\mathcal{D}(\\mathbb{A}^n/W)$ is isomorphic to the ring of invariants of $A_n(\\k)$ under the action of a finite group of linear automorphisms.\n\\end{lemma}\n\n\\begin{proof}\n Since $W/N$ does not contain  pseudoreflections then using the isomorphisms above and \\cite[Theorem 5]{Levasseur} we have an isomorphism of  algebras of invariant differential operators $$\\mathcal{D}(\\k[x_1,\\ldots,x_n]^N)^{W/N}  \\simeq \\mathcal{D}(\\k[x_1, \\ldots, x_n]^W).$$  Since $W/N$  acts linearly on $$\\k[x_1,\\ldots,x_n]^N \\simeq \\k[x_1,\\ldots,x_n],$$ we have $\\mathcal{D}(\\mathbb{A}^n/W) \\simeq \\mathcal{D}(\\mathbb{A}^n)^{W'}$\n with linear action of $W'\\simeq W/N$.\n\\end{proof}\n\nFrom Lemma \\ref{quotient1} and Theorem \\ref{Bernsteinnew} we immediately have\n%In particular, Theorem \\ref{quotient1} shows  that rings of differential operators $\\mathcal{D}(\\mathbb{A}^n/W)$ are always Noetherian and finitely generated, which is false for general singular varieties (cf. \\cite{McConnell}, Chp. 15).\n\n\n\\begin{theorem}\\label{goodcategory2} Let $W$ be a finite group of linear automorphisms of $\\mathbb{A}^n$.\n\\begin{itemize}\n\\item\nThe ring  $\\mathcal{D}(\\mathbb{A}^n/W)$ has the filter dimension $1$;\n\\item If  $M$ is a holonomic $\\mathcal{D}(\\mathbb{A}^n/W)$-module then $M$ is  cyclic  torsion module with finite length bounded by $e(M)$. In particular, \nif $e(M)=1$  then $M$ is simple.\n\\end{itemize}\n\\end{theorem}\n\n\\\n\n\n\\subsection{Invariants of generalized Weyl algebras of pure type}\n We keep the hypothesis that $\\k$ is algebraically closed.\nLet us recall the definition of the Shephard-Todd groups of type $G(m,p,n)$.\nLet $G_m \\subset \\k $ be the cyclic group in $m$ elements, generated by the $m$-th roots of unity. Let $A(m,p,n)$ be the subgroup of $G_m^{\\otimes n}$ consisting of $(h_1, \\ldots, h_n)$ such that $(\\prod h_i)^{m/p}=1$. Set $G(m,p,n)= A(m,p,n) \\rtimes S_n$.  It is always a normal subgroup of $G(m,1,n)$, and the quotient group is isomorphic to $G_p$. The groups of type $G(m,p,n)$ are the non-exceptional irreducible complex reflection groups in the classification of Shephard-Todd.\n\nThe following is clear.\n\n\\begin{proposition} \\label{action}\nLet $A=D(a, \\sigma)$ be a generalized Weyl algebra of rank $n$ of pure type, so that $D=  k[h_1,\\ldots,h_n]$ or $\\k[h_1^\\pm,\\ldots,h_n^\\pm]$. Then $A$ is equipped with the following natural action of $G(m,p,n)$:\n if $\\xi = (g, \\pi) \\in A(m,p,n) \\rtimes S_n$, $g=(g_1, \\ldots, g_n)$, then $\\xi(h_i) =  h_{\\pi(i)}$, $\\xi X_i =g_i X_{\\pi(i)}$, $\\xi Y_i = g_i^{-1} Y_{\\pi(i)}$. \n\\end{proposition}\n\n\nWe have\n\n\\begin{theorem}\\label{genWeyl}\nLet $A=D(a, \\sigma)$ be a generalized Weyl algebra of rank $n$ of pure type, and $G=G(m,p,n)$. Then we have:\n\\begin{itemize}\n\\item\n$A^G$ is a finitely generated simple Noetherian ring which is not Artinian;  $A^G$  is Morita equivalent to $A*G$.\n\\item\nFor every finitely generated $A^G$-module $M$, $GK (M) \\geq n$.\n\\item\n$fdim \\, A^G = 1$.\n\\end{itemize}\n\\end{theorem}\n\n\\begin{proof} Since $G=G(m,p,n)$ acts by outer automorphisms on $A$, we are in the position to apply Theorem \\ref{ring} and Proposition \\ref{heart}.\nItem (1) follows by the same proof as of Corollary \\ref{Weyl}. Since $G$ preserves the filtration $\\mathcal{B}_A$, it is clear  that $h_{A*G}=h_A=n$. Hence the statement (2) follows from Theorem \\ref{morita}. Finally, Statement (3) follows from Proposition \\ref{heart}.\n\\end{proof}\n\nFinally, consider the category of holonomic modules $\\mathcal{H}(A)$ for $A=D(a, \\sigma)^{G(m,p,n)}$. \n\n\\begin{theorem}\\label{goodcategory3}\nLet $A=D(a, \\sigma)^{G(m,p,n)}$ be the invariant subalgebra of a generalized Weyl algebra of rank $n$ of pure type. \n If $M \\in \\mathcal{H}(A)$ then $M$ is a cyclic torsion module with finite length bounded by $e(M)$. If \n $e(M)=1$  then $M$ is simple.\n\\end{theorem}\n\nLet us now revisit Theorem \\ref{curious}. We have\n\n\n\\begin{theorem}\\label{curious3}\nLet $A$ be one of the following algebras:\n\\begin{enumerate}\n\\item\n Any  subalgebra of invariants of $A_1(\\mathbb{C})$ under the action of a finite group;\n\\item\nThe ring of differential operators $\\mathcal{D}(X)$, where $X$ is an smooth affine curve;\n\\item\nA generalized Weyl algebra of rank $1$ of simple classical or quantum type.\n\\end{enumerate}\n If $M$ is a finitely generated $A$-module then $GK (M) =1$ if and only if $M$ has a torsion.\n\\end{theorem}\n\n\n\\begin{proof} Let $G$ be any finite group of automorphisms of $A_1(\\mathbb{C})$. Then $G$ is conjugated in $Aut_\\mathbb{C} A_1(\\mathbb{C})$ to a group of symplectic automorphisms \\cite{AD} (cf. \\cite{Dumas}).\nNow the statement in the case of the first Weyl algebra follows from Theorem \\ref{curious} and Theorem \\ref{Bernsteinnew}. The case of differential operators on curves follows from Theorem \\ref{curious} and Example \\ref{example21}. The case of generalized Weyl algebras follows from Theorem \\ref{curious} and Theorem \\ref{GWA}.\n\\end{proof}\n\n\n\n%{\\color{red} How important is this remark? Can we just delete it and not mention at all?\n\n%{\\color{magenta} I've read the relevant papers again; I don't think that it is very important. We can just ignore it}\n\n%\\begin{remark}\n%The results of this section could be also obtained  using \\cite[Corollary 2.3]{B4}. However, there is a flaw in its proof. The proof of the aforementioned result uses the fact that, if $G$ is a finite subgroup of algebra automorphisms of a simple affine algebra $A$, such that $|G|^{-1} \\in A$, then $A, A^G$ are Morita equivalent. This is not true:\n\n\n%Let $G$ be a finite subgroup of $SL_2(\\mathbb{C})$. $A_1(\\mathbb{C})^G$ is a noncommutative deformation of the corresponding Kleinian singularity. Let $m$ be the number of conjugacy classes in $G$. Then considering Hochschild homology, we have:\n\n%\\[ dim_{\\mathbb{C}} HH_0(A_1(\\mathbb{C})^G) = m-1, \\]\n\n%(cf. \\cite[pp. 566]{AFLS}). Hence, Hochschild homology distinguish such invariants subalgebras of the first Weyl algebra. However, Hochschild homology is a Morita invariant (cf. \\cite[pp. 567]{AFLS}, \\cite{Dennis}, \\cite[(5.21)]{Kassel}). Hence it is impossible that  $A_1(\\mathbb{C})^G$ and  $A_1(\\mathbb{C})$ are Morita equivalent.\n\n\n%\\end{remark}\n\n%}\n\n\n%\\section{A family of holonomic modules for invariant differential operators}\n%We will assume that $\\k$ is algebraically closed field of zero characteristic. Denote by $\\mathcal{A}_n$ the alternating groups.% $\\mathbb{T}^n = Spec \\, \\k[x_1^\\pm, \\ldots, x_n^\\pm]$ the $n$-torus and $W_n \\in \\{ S_n, B_n=C_n, D_n \\}$ be a classical Weyl group.\n%Let $A$ be an associative algebra, $\\Gamma$ a maximal commutative subalgebra of $A$. A finitely generated $A$-module $M$ is called \\emph{generalized weight module}\\footnote{Generalized weight modules are also known as Harish-Chandra or Gelfand-Tsetlin modules with respect to $\\Gamma$, cf. \\cite{DFO}, \\cite{FO2}}  with respect to $\\Gamma$ if $\\Gamma$ acts locally finitely\n%on $M$, that is\n\n%\\[  M = \\bigoplus_{n \\in Specm \\, \\Gamma} M(n), \\, M(n):= \\{ v \\in M| n^k v = 0, \\mbox{for some n} \\}. \\] \n%Here $Specm \\, \\Gamma$ denotes the set of maximal ideals of $\\Gamma$.\n%Moreover, we assume that $dim \\, M(n) < \\infty$.  \n\n\n%We have\n\n%\\begin{proposition}\\label{ppp}\n%Suppose $A$ is somewhat commutative\n% with  a finite dimensional filtration $\\mathcal{F}= \\{A_i \\}_{i \\geq 0}$  and there exists $i \\geq 1$ with $\\Gamma \\subset A_i \\setminus A_{i-1}$. Then any generalized weight $A$-module $M$ satisfies the inequality $GK \\, M \\leq GK \\, gr_\\mathcal{F}A - GK \\, \\Gamma$.\n %\\end{proposition}\n \n%\\begin{proof}\n%Set $B= gr_\\mathcal{F}A$. Consider a natural finite dimensional filtration $\\Omega= \\{M_i \\}_{i \\geq 0 }$ \n%of $M$ by\n%setting $M_i = A_i M_0$, where $M_0$ is a finite dimensional vector space generating $M$. Set $M' =  gr_\\Omega M$. Then \\cite[Proposition 6.6]{Krause} shows that $GK \\, M$ (as an $A$-module) is the same as $GK \\, M'$ (as a $B$-module). We also have that $GK \\, M'$ is the same as its Gelfand-Kirillov dimension as a $B/Ann(M')$-module.  Since $\\Gamma$ acts locally finitely on $M$, then $gr_\\mathcal{F} \\Gamma \\simeq \\Gamma$ acts locally finitely on $M'$. {\\color{red} Hence, $\\Gamma \\subset Ann(M')$.  Why? }. Hence $GK \\, B/Ann(M') \\leq GK \\, B - GK \\, \\Gamma$ by \\cite[Corollary 4.4.]{Krause}, and we conclude $GK \\, M' \\leq GK \\, B - GK \\, \\Gamma$.\n%\\end{proof}\n\n\n%We will consider the algebras of invariant differential operators $A_n(\\k)^{G(m,p,n)}$ and  $A_n(\\k)^{\\mathcal{A}_n}$ together with commutative subalgebras $ \\k[t_1,\\ldots,t_n]^{S_n}$ and $\\k[t_1,\\ldots,t_n]^{\\mathcal{A}_n}$  respectively. Note that these commutative subalgebras are maximal in the corresponding algebras. {\\color{red} Reference for maximality}. \n\n%Let $A$ be one of the algebras $A_n(\\k)^{G(m,p,n)}$ or $A_n(\\k)^{\\mathcal{A}_n}$ and $\\Gamma$ one of the corresponding \n%commutative subalgebras above.  With each pair $(A, \\Gamma)$ we associate a multi-valued map $\\phi$ which assigns to every maximal ideal $m$ of $\\Gamma$ a set of of simple $A$-modules $V$\n%on which $\\Gamma$ has a torsion by $m$, that is there exists a nonzero element $v\\in V$ such that $mv=0$. We have\n\n%{\\color{red} Please Check\n%\\begin{theorem}\\label{areholonomic}\n%For every maximal ideal $m$ of $\\Gamma$ the set\n% $\\phi(m)$ is not empty and finite and consists of holonomic $A$-modules. Moreover, {\\color{green}\n %$\\{ \\phi(m) \\} \\cap \\{ \\phi(m') \\} = \\varnothing$ for $m, m' \\in Specm \\, \\Gamma, m \\neq m'$. Nao entendi!!!  Isso n\u00e3o pode ser verdade!!!}\n%\\end{theorem}\n\n\n\n%\\begin{proof}\n%We note that every simple module  $M$  in $\\phi(m)$ is a generalized weight module, cf. \\cite{DFO}.    Consider commuting algebraically independent elements $t_i = y_i x_i$, $i=1, \\ldots, n$  of the Weyl algebra.  If $A$ is $A_n(\\k)^{G(m,p,n)}$ and $\\Gamma = \\k[t_1,\\ldots,t_n]^{S_n}$ then the first claim of the theorem follows from \\cite[Theorem 27]{FS} and \\cite[Main Theorem, Theorem 4.12]{FO2} when $p=1$, and from  \\cite[Proposition 30, Theorem 32]{FS} when  $p >1$. \n% If $A$ is $A_n(\\k)^{\\mathcal{A}_n}$ and $\\Gamma=\\k[t_1,\\ldots,t_n]^{\\mathcal{A}_n}$ then the first claim  follows from \\cite[Corollary 24]{FS} and \\cite[Main Theorem, Theorem 4.12]{FO2}. Now, both pairs $(A, \\Gamma)$ satisfy  the conditions of Proposition \\ref{ppp}. Hence, for each $m \\in Specm \\, \\Gamma$, the set $\\phi(m)$ consists of modules $M$ with $GK \\, M \\leq GK \\, A - GK \\, \\Gamma = n$. But  $GK \\, M \\geq n$ by Theorem \\ref{Bernsteinnew}. Hence $GK \\, M =n$ and all modules in $\\phi(m)$  are holonomic.\n%\\end{proof}\n\n%}\n\n\n\n\\section{Rational Cherednik algebras}\\label{section-cherednik}\n\\subsubsection{Generalized somewhat commutative algebras}\nLet us recall the notion of  rational Cherednik algebras.\n\nLet $W$ be a complex reflection group acting on a complex vector space $H$, $S$  the set of reflections.\n For each $s \\in S$, take $\\alpha_s \\in H^*$ and $\\alpha_s^\\vee \\in H$ such that $ \\alpha_s$ is an eigenvector of $\\lambda_s$ (the non-trivial eigenvalue of $s$ in $h^*$); and $\\alpha_s  ^\\vee$ is an eigenvector of $\\lambda_s^{-1}$ (the non-trivial eigenvalue of $s$ in $H$). Normalize them in such a way  that  $(\\alpha_s, \\alpha_s^\\vee)=2$ with respect to the natural pairing $H^* \\times H \\rightarrow \\C$. Finally, let $c: S \\rightarrow \\mathbb{C}$ be the  invariant  conjugation function. \n\n The {\\it rational Cherednik algebra} $H_{c,t}(W,H)$, $t \\in \\C$ is the quotient of $\\mathbb{C}W \\ltimes T(H \\oplus H^*)$ by the relations:\n\n\\[ [x,x']=[y,y']=0; \\, [y,x]=tx(y)-\\sum_{s \\in S} c(s)(y, \\alpha_s) (x, \\alpha_s^\\vee) s, \\]\nwith $x,x' \\in H^*, y,y' \\in H$.\n\nWe also consider the {\\it spherical subalgebra} $U_{c,t}(W,H):= e H_{c,t}(W,H) e$ of $H_{c,t}(W,H)$, where $e:= \\frac{1}{|W|} \\sum_{w \\in W} w$.\n\n\nWithout loss of generality we assume $t=1$ and for simplicity  just write $H_c$ and $U_c$ for the algebras above, and $\\mathsf{n}$ for $dim \\, H$. Recall that for a generic $c$, both algebras are Morita equivalent, simple Noetherian but not Artinian rings  (cf. \\cite{Thompson}).\n\n\n\\\n\n\nLet us call an algebra $A$ \\emph{generalized somewhat commutative algebra} if it has a finite filtration $\\mathcal{F}=\\{A_i \\}_{i \\geq 0}$ with $\\k \\subset A_0$ and $dim \\, A_i < \\infty, i \\geq 0$, such that the associated graded algebra is affine commutative.\n The difference between this definition and the definition of somewhat commutative algebra is that we do not impose a condition $A_0 = \\k$. Nonetheless, we have:\n\n\\begin{theorem}  Let $A$ is an affine simple generalized somewhat commutative algebra. Then \n$A$ is an algebra with multiplicity.\n\\end{theorem}\n\n\\begin{proof}\nIt follows from \\cite[Theorem 3.2, Proposition 3.3]{B1}, using the fact the dimension defined there equals to the Gelfand-Kirillov dimension by \\cite[Lemma 2.1, Proposition 6.6]{Krause}.\n\\end{proof}\n\n\\begin{corollary}\\label{cherednik1}\nFor a generic  $c$, the spherical subalgebra $U_c$ is a generalized somewhat commutative algebra with multiplicity. Moreover,  $GK (H_c) = GK (U_c) = 2 \\mathsf{n}$.\n\\end{corollary}\n\n\n\\begin{proof}\n The first statement follows from \\cite[1.6]{Bellamy}, as it shows that for an adequate finite filtration, $gr \\, U_c \\simeq \\C[h \\oplus h^*]^W$. Then the second statement follows from  \\cite[Proposition 6.6]{Krause} and \\cite[Propostion 8.2.9(iii)]{McConnell}.\n\\end{proof}\n\n\n\n\\\n\n\n\\subsection{Filter and Krull dimensions of rational Cherednik algebras}\n We assume that $c$ is a generic parameter.\n\n\\begin{lemma}\\label{cherednik11}\n$fdim \\,  H_c = fdim \\, U_c \\geq 1$.\n\\end{lemma}\n\n\\begin{proof}\nThe Gelfand-Kirillov  dimension the polynomial representation of $H_c$ equals  $\\frac{1}{2} GK (H_c)$. Hence, $fdim \\, H_c \\geq 1$ by \\cite[Corollary 1.7(i)]{B3}. Since $fdim$ is Morita invariant,  we conclude that $fdim \\, U_c \\geq 1$.\n\\end{proof}\n\n\n\\begin{corollary}\\label{cherednik3}\nIf $M \\in \\mathcal{H}(U_c)$ then $M$ is a cyclic torsion module with finite length bounded by $e(M)$. Moreover, if \n $e(M)=1$  then $M$ is simple.\n \\end{corollary}\n \n \n\\begin{proof}\nFollows from Lemma \\ref{cherednik11}, Theorem \\ref{BavBer} and Theorem \\ref{cherednik2}.\n\\end{proof}\n\nWe have\n\n\\begin{theorem}\\label{cherednik2}\n$fdim \\, H_c = fdim \\, U_c = 1$.\n\\end{theorem}\n\n\n\n\\begin{proof}\nThe algebra $U_c$ is an algebra with multiplicity by Corollary \\ref{cherednik1}. Let $h$ be the holonomic number of $U_c$. Then there exists a finitely generated $U_c$-module $M$ such that $GK (M) =h$. Since the Bernstein's inequality  holds for $M$ (cf. \\cite[Proposition 3.7]{Thompson}), $h = \\frac{1}{2} GK (U_c)$. Hence  $fdim U_c \\leq 1$ by Theorem \\ref{BavBer}. Since $fdim$ is a Morita invariant by Theorem \\ref{morita}, then we have  $fdim \\, U_c = fdim \\, H_c=1$ by Lemma \\ref{cherednik11}.\n\\end{proof}\n\n\n\nNext we compute the Krull dimension $\\mathcal{K}$ (in the sense of Gabriel-Rentschler, cf. \\cite[Chapter 6]{McConnell}) of these algebras.\n\n\\begin{theorem}\\label{cherednik4}\n$\\mathcal{K}(H_c)= \\mathcal{K}(U_c) = \\mathsf {n}$.\n\\end{theorem}\n\n\n\\begin{proof}\nSince the Krull dimension is a Morita invariant (\\cite[Proposition 6.5.1]{McConnell}), it suffices to show it for $U_c$. By the Dunkl embedding we have that a localization of the spherical subalgebra is isomorphic to $D(h_{reg}/W)$ (\\cite[Proposition 4.4.1]{Bellamy}). By \\cite[Lemma 6.5.3(iib)]{McConnell}, $\\mathcal{K}(U_c) \\geq \\mathcal{K}(D(h_{reg}/W))$, and the later equals  $\\mathsf{n}$ by \\cite[Theorem 15.3.7]{McConnell}. Since $fdim \\, U_c =1$ and  $GK (U_c) =2 \\mathsf{n}$, by \\cite[Theorem 1.3]{Bnew1}, then we  have $\\mathcal{K}(U_c) \\leq \\mathsf{n}$. Hence the equality follows.\n\\end{proof}\n\n\n\n\n\\section*{Acknowledgments}\n\nV.\\,F.\\ is supported in part by the CNPq (304467/2017-0) and by the Fapesp (2018/23690-6); J.S. is supported by the Fapesp (2018/18146-5). \n\n\n\n\\\n\n\\begin{thebibliography}{9}\n\n%\\bibitem{Bass} H. Bass. Big projective modules are free, Illinois J. Math., vol 7,  (1963), 24-31.\n%\\bibitem{AD0} J. Alev, F. Dumas, Rigidit\u00e9 des plongements des quotients primitifs minimaux de Uq(sl(2)) dans l'alg\u00e8bre quantique de Weyl-Hayashi, Nagoya Math. J. 143 (1996), 119-146.\n\\bibitem{AD} J. Alev, F. Dumas. Invariants du corps de Weyl sous l\u2019action de groupes finis, Commun. Algebra 25 (1997), 1655-1672.\n%\\bibitem{AFLS} J. Alev, M. A. Farinati, T. Lambre, A. Solotar, Homologie des invariants d\u2019une alg\u00e8bre de Weyl sous l\u2019action d\u2019un groupe fini, J. Algebra 232 (2000), no. 2, 564-577.\n\\bibitem{B0} V. Bavula. Generalized Weyl algebras and their representations, Algebra i Analiz 4 (1992) 75-97. English translation: St. Petersburg Math. J. 4 (1993) 71-92.\n\\bibitem{B1} V. Bavula. Identification of the Hilbert function and Poincar\u00e9 series, and the dimension of modules over filtered rings. Russian Acad. Sci. Izv. Math., 44:225-246, 1995.\n\\bibitem{B2} V. Bavula. Filter dimension of algebras and modules, a simplicity criterion for generalized Weyl algebras. Comm. Algebra, 24:1971-1992, 1996.\n\\bibitem{BX} V. Bavula. Classification of the simple modules of the quantum Weyl algebra and the quantum plane. Quantum groups and quantum spaces (Warsaw, 1995), 193-201, Banach Center Publ., 40, Polish Acad. Sci. Inst. Math., Warsaw, 1997.\n\\bibitem{Bnew1} V. Bavula.  Krull, Gelfand-Kirillov, and filter dimensions of simple affine algebras, J. Algebra 206 (1998), no. 1, 3-39.\n\\bibitem{BBF} V. Bavula, V. Bekkert, V. Futorny. Weight modules for Weyl algebras. Kac-Moody Lie algebras and related topics, 17-42, Contemp. Math., 343, Amer. Math. Soc., Providence, RI, 2004.\n\\bibitem{B3} V. Bavula. Filter dimension. Handbook of algebra. Vol. 4, 77-105, Handb. Algebr., 4 (ed. M. Hazewinkel), Elsevier/North-Holland, Amsterdam, 2006.\n\\bibitem{BY} V. Bavula. Quiver generalized Weyl algebras, skew category algebras and diskew polynomial rings. Math. Comput. Sci. 11 (2017), no. 3-4, 253268.\n\\bibitem{B4} V. Bavula and V.  Hinchcliffe. Morita invariance of the filter dimension and of the inequality of Bernstein. Algebr. Represent. Theory 11 (2008), no. 5, 497-504.\n\\bibitem{B5} V. Bavula and F. van Oystaeyen. Simple holonomic modules over the second Weyl algebra A2. Adv. Math. 150 (2000), no. 1, 80\u2013116\n\\bibitem{B6} V. Bavula and F. van Oystaeyen. Simple modules of the Witten-Woronowicz algebra, J. Algebra 271 (2004), no. 2, 827-845.\n%\\bibitem{BFN} A. Braverman, M. Finkelberg, H. Nakajima. Towards a mathematical definition of Coulomb branches of 3-dimensional N=4 gauge theories, II. Adv. Theor. Math. Phys. 22 (2018), no. 5, 1071-1147.\n%\\bibitem{Bellamy} G. Bellamy .Symplectic reflection algebras. Noncommutative algebraic geometry, 167-238, Math. Sci. Res. Inst. Publ., 64, Cambridge Univ. Press, New York, 2016.\n\\bibitem{Bellamy} G. Bellamy. Symplectic reflection algebras. Noncommutative algebraic geometry, 167-238, Math. Sci. Res. Inst. Publ., 64, Cambridge Univ. Press, New York, 2016.\n\n\\bibitem{Benson} D. J. Benson, Polynomial Invariants of Finite Groups. London Mathematical Society Lecture Notes Series 190 (1993), Cambridge University Press.\n%\\bibitem{Berest} Y. Berest, O. Chalykh. Quasi-invariants of complex reflection groups. Compos. Math. 147 (2011), no. 3, 965-1002.\n%\\bibitem{Berest} Y. Berest, P. Etingof and V. Ginzburg, Cherednik algebras and differential operators on quasiinvariants, Duke Math. J., 118 (2003), 279-337\n\\bibitem{Bernstein} I.N. Bernstein. Modules over a ring of differential operators. An investigation of the fundamental solutions of equations with constant coefficients. Funkcional. Anal. i Prilozen. 5 (1971), no. 2, 1-16.\n\\bibitem{Borel} A. Borel. Algebraic D-Modules, Perspectives in Mathematics, Academic Press, 1987.\n%\\bibitem{CH} R. Cannings and M. P. Holland, Differential operators on varieties with a quotient subvariety, J. Algebra 170 (1994), no. 3, 735-753.\n\\bibitem{Coutinho} S.C.Coutinho, A primer of algebraic D-modules. London Mathematical Society Student Texts 33. Cambridge University Press, 1995.\n%\\bibitem{Dennis} R. K. Dennis, K. Igusa. Hochschild homology and the second obstruction for pseudoisotopy. Algebraic K-theory, Part I (Oberwolfach, 1980), pp. 7-58, Lecture Notes in Math., 966, Springer, Berlin-New York, 1982.\n%\\bibitem{Dixmier} J. Dixmier. Alg\u00e8bres enveloppantes. (French) Cahiers Scientifiques, Fasc. XXXVII.Gauthier-Villars Editeur, Paris-Brussels-Montreal, Que., 1974. ii+349 pp. 150 F.\n%\\bibitem{DFO} Y. Drozd, V. Futorny, S. Ovsienko. Harish-Chandra subalgebras and Gel'fand-Zetlin modules. Finite-dimensional algebras and related topics (Ottawa, ON, 1992), 79-93, NATO Adv. Sci. Inst. Ser. C Math. Phys. Sci., 424, Kluwer Acad. Publ., Dordrecht, 1994.\n\\bibitem{Dumas} F. Dumas, Noncommutative Invariants. Trabajos de Matem\u00e1tica, S\u00e9rie B, n. 60/2011, Universidade Nacional de C\u00f3rdoba, Facultad de Matem\u00e1tica, F\u00edsica y Astronom\u00eda, 2011. http://math.univ-bpclermont.fr/\\~fdumas/fichiers/B-Mat60.pdf\n%\\bibitem{EFOS} F. Eshmatov, V. Futorny, S. Ovsienko, J. Schwarz. Noncommutative Noether's Problem for Unitary Reflection Groups, Proceedings of the American Mathematical Society, 145 (2017), 5043-5052.\n%\\bibitem{Etingof} P. Etingof, V. Ginzburg, Symplectic reflection algebras, Calogero-Moser space, and deformed Harish-Chandra homomorphism, Invent. Math. 147 (2002), 43-348.\n%\\bibitem{Proceedings} V. Futorny .Proceedings of the International Congress of Mathematicians\u2014Rio de Janeiro 2018. Vol. II. Invited lectures, 1303\u20131320, World Sci. Publ., Hackensack, NJ, 2018.\n%\\bibitem{FMO} V. Futorny, A. Molev, S. Ovsienko. The Gelfand-Kirillov conjecture and Gelfand-Tsetlin modules for finite W-algebras. Advances in Mathematics, 223:773-796, 2010.\n%\\bibitem{FO1} V. Futorny, S. Ovsienko. Galois orders in skew monoid rings. J. Algebra 324 (2010), no. 4, 598-630.\n%\\bibitem{FO2} V. Futorny, S. Ovsienko. Fibers of characters in Gelfand-Tsetlin categories. Trans. Amer. Math. Soc. 366 (2014), no. 8, 4173-4208.\n%\\bibitem{FS2} V. Futorny, J. Schwarz. Quantum linear Galois orders. Comm. Algebra 47 (2019), no. 12, 5361-5369.\n%\\bibitem{FS} V. Futorny, J. Schwarz, Algebras of invariant differential operators. J. Algebra 542 (2020), 215-229.\n%\\bibitem{FS3}. V. Futorny, J. Schwarz, Noncommutative Noether\u2019s problem vs classic Noether\u2019s problem. Math. Z. (2019). https://doi.org/10.1007/s00209-019-02397-4.\n\\bibitem{Jantzen} J. C. Jantzen, Einh\u00fcllende Algebren halbeinfacher Lie-Algebren. (German) [Enveloping algebras of semisimple Lie algebras] Ergebnisse der Mathematik und ihrer Grenzgebiete (3) [Results in Mathematics and Related Areas (3)], 3. Springer-Verlag, Berlin, 1983. ii+298 pp. ISBN: 3-540-12178-1.\n%\\bibitem{FGRZ} V. Futorny, D. Grantcharov,  L. E.  Ramirez,  P. Zadunaisky.  Gelfand-Tsetlin theory for rational Galois algebras, arXiv:1801.09316v1[math.RT].\n\\bibitem{Krause} G. R.  Krause and T. H. Lenegan. Growth of Algebras and Gelfand-Kirillov Dimension, Graduates Studies in Mathematics 22, American Mathematical Society, revised edition, 2000.\n%\\bibitem{Gelfand} I. M. Gelfand , K. K. Kirillov. Sur les corps li\u00e9s aux alg\u00e8bres envoloppantes des alg\u00e8bres de Lie, volume 31 of Inst. Hautes Etudes Sci. Publ. Mat., p\u00e1ginas 5-19. 1966.\n%\\bibitem{GT} I. M Gelfand, M. L. Tsetlin.  Finite-dimensional representations of groups of orthogonal matrices. (Russian) Doklady Akad. Nauk SSSR (N.S.) 71, (1950). 1017\u20131020\n%\\bibitem{H} J. Hartwig. Principal Galois orders and Gelfand-Zeitlin modules. Adv. Math. 359 (2020), 106806, 23 pp.\n%\\bibitem{Jauch} E. C. Jauch. An Alternating Analogue of U(gln) and Its Representations, arXiv:1907.13254v2 [math.RT], 2019.\n\\bibitem{Jordan} D. A. Jordan. Primitivity in skew Laurent polynomial rings and related rings, Math. Z. 213 (1993), 353-71.\n%\\bibitem{JW} D.A. Jordan, I.E. Wells, Invariants for automorphisms of certain iterated skew polynomial rings, Proc.Edinburgh Math. Soc. 39 (1996) 461-472.\n%\\bibitem{LW} E. LePage, B. Webster. Rational Cherednik algebras of G(l,p,n) from the Coulomb perspective, arXiv:1912.00046v1 [math.RA].\n%\\bibitem{Kassel} C. Kassel, Homology and cohomology of associative algebras. A concise introduction to cyclic homology. \u00c9cole th\u00e9matique. Ao\u00fbt 2004 \u00e0 ICTP, Trieste (Italie), 2006. HAL Id: cel-00119891.\n\\bibitem{Levasseur} T. Levasseur.  Anneaus d\u2019operateurs differentiels. Em S\u00e9minaire d\u2019Algebre Paul Dubreil et Marie-Pau le Malliavin, Lecture Notes in Mathematics 867, p\u00e1ginas 157\u2013173, Paris, 1980. Springer-Verlag.\n%\\bibitem{Mazorchuk} V. Mazorchuk, Orthogonal Gelfand-Zetlin Algebras I, Contributions to Algebra and Geometry 40 (1999), no. 2, 399-415.\n\\bibitem{McConnell3} J.C. McConnell. Quantum groups, filtered rings and Gel'fand-Kirillov dimension. Noncommutative ring theory (Athens, OH, 1989), 139-147, Lecture Notes in Math., 1448, Springer, Berlin, 1990.\n\\bibitem{McConnell2} J.C. McConnell. Representations of solvable Lie algebras V: On the Gelfand-Kirillov dimension of simple modules, J. Algebra 76 (1982), 489-493.\n\\bibitem{McConnell} J.C. McConnell and J. C. Robson. Noncommutative noetherian rings, revised edition, Graduate Studies in Mathematics 30, American Mathematical Society, Providence, 2001.\n\\bibitem{Montgomery} S. Montgomery. Fixed rings of finite automorphism groups of associative rings, Lecture Notes in Mathematics, 818. Springer Berlin Heidelberg, 1980, 126 pp.\n\\bibitem{Montgomery2} S. Montgomery and L. W. Small. Fixed rings of noetherian rings. Bull. London. Math. Soc., 13:33-38, 1981.\n%\\bibitem{N} H. Nakajima. Introduction to a provisional mathematical definition of Coulomb branches of 3-dimensional N=4 gauge theories. Modern geometry: a celebration of the work of Simon Donaldson, 193-211, Proc. Sympos. Pure Math., 99, Amer. Math. Soc., Providence, RI, 2018.\n\\bibitem{Rosenberg} A. L. Rosenberg. Noncommutative algebraic geometry and representations of quantized algebras, Kluwer, Dordrecht (1995).\n%\\bibitem{Shestakov} I. P. Shestakov, U. U. Umirbaev. The Nagata automorphism is wild. Proc. Natl. Acad. Sci. USA 100 (2003), no. 22, 12561-2563.\n\\bibitem{Thompson} D. Thompson. Holonomic modules over Cherednik algebras, I. J. Algebra 493 (2018), 150-170.\n\\bibitem{Traves} W. N. Traves. Invariant theory and differential operators. Gr\u00f6bner bases in symbolic analysis, 245-265, Radon Ser. Comput. Appl. Math., 2, Walter de Gruyter, Berlin, 2007.\n%\\bibitem{Terao} H. Terao. The Jacobians and the discriminants of finite reflection groups T\u00f4hoku Math. J., 41 (1989), pp. 237-247.\n%\\bibitem{Webster} B. Webster, Gelfand-Tsetlin modules in the Coulomb context, arXiv:1904.05415v2 [math.RT].\n\\end{thebibliography}\n\n\\end{document}\nLet $W$ be a classical complex  reflection group. Recall the action of $W$ on  $\\tilde{A_{n}}$.  \n%We will consider  the action of the reflection group of type $B_n$ ($n\\geq 2$)  and the reflection group of type $D_n$ ($n\\geq 4$) on $X$.  \n%Fix $s$ and consider a space $V_s$ with a basis $\\lambda_{1},\\dots,\\lambda_{s}$. \n The reflection  group of type  $B_n$ ($n\\geq 2$) is the semi-direct product of the symmetric group $S_{n}$ and  \n $(\\mathbb{Z}/2\\mathbb{Z})^n$.  Tha latter group is generated by $\\varepsilon_i$, $i=1, \\ldots, n$.\n% Hence, it acts naturally on $V_s$, where the elements of $S_s$  permute the basis vectors and the generators  $\\varepsilon_{i}$, $i=1, \\ldots, s$ of $Z_2^s$ act by \n%reflections $$\\varepsilon_{i}(\\lambda_{i})=-\\lambda_{i},\\, \\varepsilon_{i}(\\lambda_{j})=\\lambda_{j},j\\neq i,\\, i,j=1,\\dots, s.$$\nThere is a natural action of $B_n$\non $\\tilde{A_n}\\simeq \\tilde{A_{1}}^{\\otimes n}$,  where $S_n$ acts by  permutations \n and $(\\mathbb{Z}/2\\mathbb{Z})^n$  acts as follows: $\\varepsilon_i(\\partial_i)=x_i^{2}\\partial_i$, $\\varepsilon_i(x_i)=-x_i^{-1}$,  and $\\varepsilon_i(\\partial_j)=\\partial_j$, \n $\\varepsilon_i(x_j)=x_j$, $i,j=1, \\ldots, n$, $i\\neq j$. \n \n The  group $D_n$  is generated by $S_{n}$ and  $(\\mathbb{Z}/2\\mathbb{Z})^{n-1}$, where the latter group consists  \n   of  elements  $(\\varepsilon_{1}^{a_{1}},\\dots, \\varepsilon_{n}^{a_{n}})\\in \n   (\\mathbb{Z}/2\\mathbb{Z})^{n}$, $a_{i}=0,1, i=1,\\dots, n$, such that $a_{1}+\\dots+a_{n}$ is even. \nThe action of\n $D_n$\non $\\tilde{A_n}\\simeq \\tilde{A_{1}}^{\\otimes n}$  is defined as follows: \n $S_n$ acts by  permutations, $\\varepsilon_i(\\partial_i)=-x_i^{2}\\partial_i$, $\\varepsilon_i(x_i)=x_i^{-1}$ and\n$\\varepsilon_i(\\partial_j)=\\partial_j$, \n $\\varepsilon_i(x_j)=x_j$, $i,j=1, \\ldots, n$, $i\\neq j$.\n%Recall that $\\Gamma=\\k[t_1, \\ldots, t_n]$  and set $L=Frac \\, \\Gamma=\\k(t_1, \\ldots, t_n)$. \n%Then applying Proposition 7.4 of \\cite{FO1} we obtain that $\\D(X)^{W}$ is a Galois ring over $\\Gamma^{W}$ in $(L * \\mathbb Z^n)^{W}$. \n\nRecall that \n$$\\tilde{A_n}\\simeq \\mathbb C [t_1, \\ldots, t_n, \\sigma_1^{\\pm 1}, \\ldots, \\sigma_n^{\\pm 1}]\\simeq \\mathbb C  [t_1, \\ldots, t_n] * \\Z^n,$$\nwhere $t_i=\\partial_i x_i$,  $\\sigma_i\\in \\Aut \\mathbb C [t_1, \\ldots, t_n] $, $\\sigma_i(t_j)=t_j-\\delta_{ij}$,     $i,j=1, \\ldots, n$ (cf. \\cite{Futorny}, Section 7.3).\nAlso, the generators of $(\\mathbb{Z}/2\\mathbb{Z})^n$  act on $t_i$'s as follows: $\\varepsilon_i(t_i)=2-t_i$ and  $\\varepsilon_i(t_j)=t_j, j \\neq i$,  $i, j=1, \\ldots, n$. \n\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\n\n\n\n\n\\begin{corollary}\\label{Weyl}\n\\begin{enumerate}\n\\item\n$A_n(\\k)^G$ is a simple ring Morita equivalent to $A_n(\\k)*G$, both have the Gelfand-Kirillov dimension $2n$.\n\\item\n$A_n(\\k)^G$ is finitely generated Noetherian but not Artinian.\n\\item\n$A_n(\\k)^G$ is a somewhat commutative algebra.\n\\end{enumerate}\n\\begin{proof}\nStatements (1) and (2) follow immediately from Theorem \\ref{ring}. Introduce a filtration $\\mathcal{E}=\\{E_i \\}_{i \\geq 0}$ on $A_n(\\k)^G$ induced from the Bernstein filtration $\\mathcal{B}=\\{ B_i \\}_{i \\geq 0}$: $E_i = B_i \\cap A_n(\\k)^G$. Then $gr_\\mathcal{E} A_n(\\k)^G \\simeq (gr_\\mathcal{B} \\, A_n(\\k))^G$ (\\cite{Dumas}), which is a finitely generated commutative algebra by the Noether's theorem. Statement (3) follows. \\end{proof}\n\\end{corollary}\n\n\n\n\n\\begin{theorem}\\label{Bernsteinnew}\n$fdim \\, A_n(\\k)^G = 1$, $h_{A^G}=n$, and  every finitely generated $A_n(\\k)^G$ module $M$ satisfies the Bernstein inequality $GK \\, M \\geq n$.\n\\end{theorem}\n\n\\begin{proof} \\textbf{Linear automorphisms case.}\nThe proof is essentially an application of Proposition \\ref{heart}. In the case when $G$ is a finite group that acts by linear automorphisms, we have that $\\k[x_1,\\ldots,x_n]^G$ is a $A_n(\\k)^G$-module of the Gelfand-Kirillov dimension $n$. Hence,  by Proposition \\ref{heart}, $fdim \\, A_n(\\k)^G = 1$. The Bernstein inequality then follows from Theorem \\ref{BavBer}. Since we have explicitly constructed a module with minimal possible Gelfand-Kirillov dimension, then $h_{A^G}=n$.\n\n\n{\\color{magenta}\n\\begin{theorem}\\label{goodcategory}\nLet $W$ be a finite group of linear automorphisms of $\\mathbb{A}^n$ and consider $\\mathcal{D}(\\mathbb{A}^n/W)$. Let $\\mathcal{H}$ be the category of holonomic modules  and $M\\in \\mathcal{H}$. Then $M$ is a cyclic module with torsion. Moreover, \nif $e(M)=1$  then $M$ is irreducible.\n\\end{theorem}\n}\n\n\\begin{theorem}\\label{quotient1}\nLet $W$ be any finite group of linear automorphisms of the polynomial ring $\\k[x_1,\\ldots,x_n]$ (and hence of the affine space $\\mathbb{A}^n$). Then $\\mathcal{D}(\\mathbb{A}^n/W)$ is isomorphic to the ring of invariants of $A_n(\\k)$ under the action of a finite group of linear automorphisms.\n\\end{theorem}\n\n\\begin{proof}\nBy the above lemma and \\cite[Theorem 5]{Levasseur}, we have an isomorphism of  algebras $$\\mathcal{D}(\\k[x_1,\\ldots,x_n]^N)^{W/N}  \\simeq \\mathcal{D}(\\k[x_1, \\ldots, x_n]^W),$$ since $W/N$ does not contain  pseudoreflections. Also $W/N$  acts linearly on $$\\k[x_1,\\ldots,x_n]^N \\simeq \\k[x_1,\\ldots,x_n]$$ by Lemma \\ref{lem-lin}. Hence $\\mathcal{D}(\\mathbb{A}^n/W) \\simeq \\mathcal{D}(\\mathbb{A}^n)^{W'}$\n with linear action of $W'\\simeq W/N$.\n\\end{proof\n\n\n\n\n\n\n\n\\begin{lemma}\\label{lem-lin}\nLet $W$ be a finite group of linear automorphisms of $\\k[x_1,\\ldots,x_n]$, $N\\subset W$ a subgroup generated by the pseudo-reflections. Then $N$ is normal in $W$ and   $W/N$ has the induced  linear action on the polynomial algebra.\n\\end{lemma}\n\n{\\color{magenta}\n\\begin{proof}\nFor the normality of $N$, we just need to check that if $s$ is a pseudoreflection, then so is $wsw^{-1}$, for any $w \\in W$. For a $w\\in W$ denote by $H_w$ the linear subvariety fixed pointwise by $w$. We have $w(H_s) \\subset H_{wsw^{-1}}$. Then $1 \\leq codim (H_{wsw^{-1}}) \\leq codim(w(H_s))=1$ and $N$ is normal in $W$.\nFurther on, we have \nthe natural isomorphisms $$\\k[x_1,\\ldots,x_n]^W \\simeq (\\k[x_1, \\ldots, x_n]^N)^{W/N} \\simeq \\k[x_1, \\ldots, x_n]^{W/N},$$\n where the second isomorphism follows from the Chevalley-Shephard-Todd theorem.  \nConsider the following vector subspace of $\\k[x_1, \\ldots, x_n]^N$,  $(\\k[x_1,\\ldots,x_n]^{+N})^2$, where $\\k[x_1,\\ldots,x_n]^+$ consist of polynomials with non-zero constant term. It has an $W/N$ complement $U$ with a basis $B$. Then $W/N$  acts by linear transformations on $B$. By the homogeneous Nakayama lemma, $B$ is a minimal generating set of $\\k[x_1,\\ldots,x_n]^N$, hence the result follows (cf. \\cite[pp. 259]{Traves}).\n\\end{proof}\n}\n\n\\begin{theorem}\\label{quotient1}\nLet $W$ be any finite group of linear automorphisms of the polynomial ring $\\k[x_1,\\ldots,x_n]$ (and hence of the affine space $\\mathbb{A}^n$). Then $\\mathcal{D}(\\mathbb{A}^n/W)$ is isomorphic to the ring of invariants of $A_n(\\k)$ under the action of a finite group of linear automorphisms.\n\\end{theorem}\n\n\\begin{proof}\nBy the above lemma and \\cite[Theorem 5]{Levasseur}, we have an isomorphism of  algebras $$\\mathcal{D}(\\k[x_1,\\ldots,x_n]^N)^{W/N}  \\simeq \\mathcal{D}(\\k[x_1, \\ldots, x_n]^W),$$ since $W/N$ does not contain  pseudoreflections. Also $W/N$  acts linearly on $$\\k[x_1,\\ldots,x_n]^N \\simeq \\k[x_1,\\ldots,x_n]$$ by Lemma \\ref{lem-lin}. Hence $\\mathcal{D}(\\mathbb{A}^n/W) \\simeq \\mathcal{D}(\\mathbb{A}^n)^{W'}$\n with linear action of $W'\\simeq W/N$.\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\\section{Principal, rational and linear Galois orders, and the Gelfand-Kirillov Conjecture}\n\nNow we begin our discussion on Galois algebras and orders, and their category of Gelfand-Tsetlin modules. From now on, until the rest of the paper, the basis field is algebraically closed of zero characteristics.\n\nIn this section we discuss the notion of principal and rational Galois orders introduced in \\cite{H}, with relation to subrings of invariants, and show that all the Galois algebras in \\cite{FS}, \\cite{FS2} are principal Galois orders. We remark that all of them are examples of invariant subalgebras of generalized Weyl algebras (cf. proof of Theorem \\ref{areprincipal}) We also compare the notion of rational Galois algebra with that of linear Galois algebra, introduced in \\cite{EFOS}.\n\n\nWe begin recalling the notion of principal Galois orders.\n\n\\begin{definition}[\\cite{H}] \\label{principal}\nLet $U$ be a Galois order embedded in skew monoid ring $(L*\\mathcal{M})^G$. For $u \\in U, u = \\sum_{m \\in \\mathcal{M}} \\alpha_m m, \\alpha_m \\in L$, we define the evaluation map $u: L \\mapsto L$, as $u(l)=\\sum_{m \\in \\mathcal{M}} \\alpha_m m(l)$. $U$ is a principal Galois order if for each $u \\in U$, $a \\in \\Gamma$, $u(a) \\in \\Gamma$; or, in other words, $U(\\Gamma) \\subset \\Gamma$.\n\\end{definition}\n\nNow we recall the notion of rational Galois orders, introduced in \\cite{H}, their representations considered in \\cite{FGRZ}. First, some preliminary work.\n\n\\begin{theorem}\n Let $G \\subset GL(V)$, $V$ a finite dimensional complex vetcor space, be a finite complex reflection group, $\\chi$ a character of $G$ and $\\Gamma_\\chi= \\{ f \\in S(V^*)|g.f=\\chi(g)f \\}$. There exists a uniquely defined $d_\\chi \\in S(V^*)$ such that $\\Gamma_\\chi = S(V^*) d_\\chi$.\n\\end{theorem}\n\\begin{proof}\n\\cite{Terao}, Thm 2.5.\n\\end{proof}\n\n\\begin{definition}[\\cite{H}] \\label{rational}\nLet  $V$ be a complex $n$-dimensional vector space. It acts on $S(V^*)$  the following way: $v.f(x)= f(x-v), x, v \\in V, f \\in S(V^*)$. Let $G \\subset GL(V)$ be a finite complex reflection group, $L= Frac \\, S(V^*)$ , with the natural extended action of $V$,  and $X$ a subset of $L*V$ such that :\n\\begin{itemize}\n\\item\n$g(X) = X, \\forall g \\in G, x \\in X$;\n\\item\nFor all $x \\in X$ there exists a character $\\chi$ such that $d_\\chi X \\in S(V^*)*V$.\n\\end{itemize}\nThen the subalgebra of $(L*V)^G$ generated by $S(V^*)$ and $X$ is called a rational Galois order.\n\\end{definition}\n\nFinally, we recall the definition of linear Galois algebras (\\cite{EFOS}):\n\n\\begin{definition} \\label{linear}\nLet  $V$ be a complex $n$-dimensional vector space, such that we have $L\\simeq \\mathbb C (t_{1},\\dots, t_{n}, z_1, \\ldots, z_s)$  as the field of fractions of the symmetric algebra $S(V^*)$. \nLet $G$ be a classical reflection group  acting on $V$\n by reflections. This action can be extended to the action of $G$ on $L$ and we set\n $K=L^G$.  Suppose $G$ normalizes a fixed submonoid$\\mathcal {M}\\subset Aut_\\mathbb{C}L$ and $\\Gamma$ is  a polynomial subalgebra such that $\\Frac \\  \\Gamma\\simeq K$.\n   A Galois order $U$ over $\\Gamma$ in $(L*\\mathcal M)^G$ is called  \\emph{linear Galois algebra}. If $\\mathcal{M} \\simeq \\mathbb{Z}^n$ and the canonical generators $e_1, \\ldots, e_n$ act by shifts $e_i(t_j)= t_j - \\delta_{ij}$ fixing the $z's$, then we have a linear Galois algebras of \\emph{shift} type. If $\\mathcal{M} \\simeq \\mathbb{Z}^n$ or $\\mathbb{N}^n$, $e_i(t_j) = q^{\\delta_{ij}} t_j$ fixing the $z's$, $0 \\neq q \\in \\mathbb{C}$ is not a root of unity, we have quantum linear Galois algebra (\\cite{FS2}, Section 5.4)\n\\end{definition}\n\n\n%In \\cite{H}, the notion of rational Galosi algebra was introduced, their representations studied in \\cite{FGRZ}. It is supposed to be a very broad class of galois Orders (\\cite{H}, \\cite{Webster}).\n\n\nWe compare the classes. First, we remark that all known examples of Galois orders are linear (\\cite{EFOS}, \\cite{FS}, \\cite{FS2}, \\cite{H}, Section 4 , 5, \\cite{Webster}, Prop. 4.2, \\cite{LW}, Section 3.4 ) with some minor expections involving the alternating group (\\cite{Jauch}, \\cite{FS}, Corol. 24). Now, we will give an example of linear Galois algebra that is not of shift type and neither quantum type, and neither is a rational Galois order.\n\n\\begin{example}\nLet $R = \\mathbb{C}[x_1,\\ldots,x_3]$, and $\\sigma$ the Nagata automorphisms, known to be wild (\\cite{Shestakov}). Let $R'= R_1 \\otimes R_2 \\otimes R_3$, where each $R_i$ is a copy of $R$, $i=1,2,3$; and let $\\sigma_1 = \\sigma \\otimes 1 \\otimes 1$, $\\sigma_2 = 1 \\otimes \\sigma \\otimes 1$, $\\sigma_3 = 1 \\otimes 1 \\otimes \\sigma$. Consider $R'*\\mathbb{Z}^3$, the skew group ring of $R'$ with the group generated by $\\sigma_i, i=1,2,3$.  The symmetric group $S_3$ acts on this ring permuting the $R_i$ factors and by conjugation on $\\mathbb{Z}^3$. $U=(R'*\\mathbb{Z}^3)^{S_3}$ is then an example of linear Galois algebra which cannot be of any of the above mentioned types.\n\\end{example}\n\nNow we proceed to show that the linear Galois orders considered in \\cite{FS} and \\cite{FS2} are principal.\n\n\\begin{lemma}\\label{lemma0}\nEvery Galois order $U$ of the the form a skew monoid ring or a generalized Weyl algebra is a principal Galois order.\n\\end{lemma}\n\\begin{proof}\nThe first claim is obvious; the second one follows from Theorem \\ref{thmGWA}.\n\\end{proof}\n\n\\begin{proposition} \\label{prop0}\nIf $U$ is a principal Galois order over $\\Gamma$, and $U^G$ is a Galois ring over $\\Gamma^G$, for some finite group of automorphisms of $U$, $G$, with $G(\\Gamma) \\subset \\Gamma$, then $U^G$ is a principal Galois order.\n\\begin{proof}\nCall $K := Frac(\\Gamma)$. Since $U^G \\subset U$ and the later is a principal Galois order, $U^G(\\Gamma) \\subset \\Gamma$. On the other hand, by \\cite{H} Lemma 2.19, $U^G(K^G) \\subset K^G$.  These two facts combined implies that $U^G(\\Gamma^G) \\subset \\Gamma^G$.\n\\end{proof}\n\\end{proposition}\n\n\\begin{theorem}\\label{areprincipal}\nAll the invariants of the Weyl algebra $A_n(\\k)^G$, where $G$ belongs to $\\{ G_m^{\\otimes n}, \\mathcal{A}_n, G(m,1,n) \\}$; all the invariants of the ring of differential operators on the torus $\\mathcal{D}(\\mathbb{T}^n)^W$, where $W \\in \\{ A_n, B_n=C_n, D_n \\}$, the natural invariants of $\\mathcal{O}_q(k^{2n})$ (the quantum affine aspace) and  $\\mathcal{O}_q(k^{*2n})$ (the quantum torus)  under the action of groups $G(m,p,n)$; the invariants of the $\\mathbb{C}_q[x,y]$ and $A_1^q(\\mathbb{C})$  (the quantization of the first Weyl algebra) under the action of any finite group; and $A_n^q(\\k)^{S_n}$ (the symmetric elements on $A_1^q(\\k)^{\\otimes n}$), are all principal Galois orders.\n\\begin{proof}\nImmediate from Lemma \\ref{lemma0} and Proposition \\ref{prop0}, and, respectively,  \\cite{FS} Proposition 22, Corollary 24, Proposition 25, Theorem 27 and Theorem 33; and \\cite{FS2}, Theorem 5, Theorem 6, Theorem 6, Proposition 5, Theorem 7.\n\\end{proof}\n\\end{theorem}\n\nWith this result in mind, we think the following conjecture is natural:\n\n\\begin{conjecture}\nAll Galois orders are principal Galois orders.\n\\end{conjecture}\n\nWe now discuss a generalization of the Gelfand-Kirillov Conjecture for linear Galois algebras of shift type discussed in \\cite{EFOS} (Theorem 6), that also reproves the result in \\cite{Jauch} (Theorem 8.4).\n\n\\begin{theorem}\\label{GelfandKirillov}\nLet $U$ be a Galois algebra in $(\\k(t_1,\\ldots,t_n;z_1,\\ldots, z_s)*\\mathcal{M})^G$ such that $\\mathcal{M} \\simeq \\mathbb{Z}^n$ with canoical basis acting by shifts in $t_1, \\ldots, t_n$ and fixing the $z_1, \\ldots, z_s$. If $G$ is a pseudoreflection group or $\\k(t_1,\\ldots,t_n;z_1,\\ldots, z_s))^G$ is rational, then the Gelfand-Kirillov Conjecture holds for $U$: $Frac \\, U \\simeq Frac, A_n(\\k(z_1,\\ldots,z_s))$. In particular, if $U$ is a rational Galois order and, in the notation of Definition \\ref{rational}, the group generated by $\\bigcup_{x \\in X} supp \\, X$  is $\\mathbb{C}$-linearly independent in $V$, then the Gelfand-Kirillov Conjecture holds for it.\n\\begin{proof}\nThe first part follows directly from \\cite{FS3}, Theorem 6.1, and \\cite{FO1} Proposition 4.2. The second follows from the obervation that, under the hyphotesis, the action as definided in Definition \\ref{rational} is just the action by shifts by a lattice in $V$.\n\\end{proof}\n\\end{theorem}\n\n\\begin{remark}\nThe first part of last Theorem holds without the hyphothesis in Assumption \\ref{Hartwig}.\n\\end{remark}\n\n\n\\\n\n\n\n\\section{Invariants of generalized Weyl algebras}\n%\\begin{definition}\n%Let $D$ be a commutative finitely generated somain over $k$. Let $a=(a_1, \\ldots, a_n)$ be a n-uple of elements of $D$ which are not zero divisors neither units. Let $\\sigma=(\\sigma_1, \\ldots, \\sigma_n)$ be a tuple of automorphisms of $D$ such that $\\sigma_i \\sigma_j = \\sigma_j \\sigma_i$, $\\sigma_i(a_j)= a_j$, if $j \\neq i$. The GWA of rank $n$ is the algebra with generators $D, X_i, Y_i$, $i=1, \\ldots, n$, and relations\n\n%[ X_i \\lambda = \\sigma_i(\\lambda) X_i; Y_i \\lambda = \\sigma_i^{-1}(\\lambda) Y_i, \\lambda \\in D; \\]\n%\\[ Y_iX_i = a_i, X_i Y_i = \\sigma_i(a_i). \\]\n\n%We will call the $X_i, Y_i$ the GWA generators.\n%\\end{definition}\n\n%Notice that under the assumptions in the above definition, every GWA will be a Noetherian domain --- hence an Ore domain. Unless specified otherwise, we discuss GWA's of arbitrary rank $n$.\n\nIn this section, we discuss the realization of a wide class of invariants of generalized Weyl algebras as (principal) Galois orders, and show that this gives us an important subcategory of the category of holonomic modules considered in Section 6.\n\nWe begin with the following general condition for invariants of a generalized Weyl algebra be a Galois order.\n\n%\\begin{proposition} \\label{prop1}\n%There is a birational embedding $D(a, \\sigma)$ into $D*\\mathbb{Z}^n$, where $ye_i$ acts as $\\sigma_i^y$, $y \\in \\mathbb{Z}$. The embedding sends $X_i$ to $e_i$ and $Y_i$ to $a_i e_i^{-1}$.\n%\\end{proposition}\n%\\begin{proof}\n%Identical to [FS] prop 13, prop 15.\n%\\end{proof}\n\n%\\begin{proposition} \\label{prop2}\n%Under the same hyphotesis of [FS] Theorem 14, $D(a, \\sigma)$ is a Galois order in $Frac(D)*\\mathbb{Z}^n$, with $D$ a Harish-Chandra subalgebra. It is also a \\emph{Principal Galois order}.\n%\\end{proposition}\n\n%Notice that $D*\\mathbb{Z}^n$ and $Frac(D)*\\mathbb{Z}^n$ are also Noetherian domains.\n\n\\begin{proposition} \\label{tec}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra. Let $G$ be a finite group of automorphisms of $D$ that normalizes the set $ \\{ \\sigma_i \\}$. If $g \\sigma_i g^{-1} = \\sigma_{i'}, g \\in G$, call $g(i):=i'$. If $g(a_i)=a_{g(i)}$, we have an extension of the $G$ action on $D(a, \\sigma)$, with $gX_i = X_{(g(i))}$, $gY_i = Y_{(g(i))}$. The embbeding in Theorem \\ref{thmGWA} is $G$-equivariant, and if $D(a, \\sigma)$ is a principal Galois order in $Frac(D)*\\mathbb{Z}^n$, $D(a,\\sigma)^G$ is a principal Galois order in $(Frac(D)*\\mathbb{Z}^n)^G$ with Harish-Chandra subalgebra $D^G$. Moreover if $D$ is a projective module over $D^G$, then $D(a, \\sigma)^G$ is a free $D^G$-module\n\\end{proposition}\n\\begin{proof}\nThat the defined map is indeed an extension of $G$ to a group of automorphisms on $D(a, \\sigma)$ is clear by the defining relations of generalized Weyl algebras. $(D*\\mathbb{Z}^n)^G$  is a Galois algebra in $(Frac(D)*\\mathbb{Z}^n)^G$ by \\cite{H} Lemma 2.10(iii). Hence by Proposition \\ref{prop-1} and the definition of Galois algebra ,there exists $X \\subset (D*\\mathbb{Z}^n)^G$ such that $\\bigcup_{x \\in X} supp \\, x$ generates $\\mathbb{Z}^n$ as a monoid. By the form of the embedding in Theorem \\ref{thmGWA}, we can find a set $Y$ with the same property in $D(a,\\sigma)^G$, so that it is a Galois ring in the same invariant skew group ring, again by Proposition \\ref{prop-1}. By Proposition \\ref{prop0} we conclude that it is a principal Galois order.\nAbout freeness: since $D(a, \\sigma)$ is free over $D$, we can apply Lemma \\ref{lemma2} and \\cite{Bass} Corol. 4.5.\n\\end{proof}\n\n\\begin{definition} \\label{def}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra of rank 1, with $\\sigma$ an automorphism of infinite order. We define $D_n(a, \\sigma)$ to be $D(a, \\sigma)^{\\otimes n}$. It is itself a generalized Weyl algebra (cf. Proposition \\ref{prop-tensor}) $D'(a=(a_1, \\ldots, a_n), \\sigma=( \\sigma_1, \\ldots, \\sigma_n))$, where $D' = D \\otimes \\ldots \\otimes D$ n times, $a_i = 1 \\otimes\\ldots \\otimes a \\otimes \\ldots 1$, $a$ in the i-th position, and $\\sigma_i=1 \\otimes\\ldots \\otimes \\sigma \\otimes \\ldots 1$, $\\sigma$ in the i-th position.\n\\end{definition}\n\nWe observe that, under these conditions, $D_n(a, \\sigma)$ is allways a Galois order (\\cite{FO1}, \\cite{FS}). We now discuss the same action as in Proposition \\ref{action} in a much wider context:\n\n\n\\begin{corollary}\\label{maincorol2}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra, where $D=k[h]$ or $D=k[h^\\pm]$. Let $D_n(a, \\sigma)$ be definide as above (note that in this case $D'=k[h_1, \\ldots, h_n]$ or the ring of Laurent polynomials). We have an action of $S_n$ by algebra automorphisms such that $\\pi(h_i)=h_{\\pi(i)}$, $\\pi(X_i)=X_\\pi(i)$ and $\\pi(Y_i)= Y_{\\pi(i)}$. Suppose $\\sigma$ is an automorphism of $D$ of infinite order. Then $D_n(a, \\sigma)^{S_n}$ is a principal Galois order in $(k(h_1, \\ldots, h_n)*\\mathbb{Z}^n)^{S_n}$ with Harish-Chandra $k[h_1,\\ldots,h_n]^{S_n}$ (or $k[h_1^\\pm,\\ldots,h_n^\\pm]^{S_n}$). $D_n(a, \\sigma)^{S_n}$ is free over the Harish-Chandra subalgebra.\n\\begin{proof}\nProposition \\ref{tec}.\n\\end{proof}\n\\end{corollary}\n\n\\begin{corollary}\nThe same result holds with $\\mathcal{A}_n$ in place of $S_n$ everywhere --- except freeness.\n\\end{corollary}\n\n\n\n\\begin{theorem}\\label{tec2}\nLet $G_m=\\langle g \\rangle \\subset k$ be the cyclic group with $m$ elements, with action on $D(a, \\sigma)$ being $gX = \\xi X$, $g Y = \\xi^{-1} Y$, and trivially on $D$ ($\\xi$ is a primitive $m$-root of unity that generates $G_m$). Then $D(a, \\sigma)^{G_m}$ is isomorphic to $D(a_m, \\sigma^m)$, where $a_m$ is $a \\sigma^{-1}(a) \\ldots \\sigma^{-(m-1)}a$. If $X,Y$ are the GWA generators of $D(a, \\sigma)$ and $X', Y'$ the ones from $D(a_m, \\sigma^m)$, the isomorphism sends $X^m \\mapsto X'$, $Y^m \\mapsto Y'$.\n\\end{theorem}\n\\begin{proof}\n\\cite{JW}, Thm. 2.7.\n\\end{proof}\n\n\\begin{proposition}\\label{mainprop}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra of rank 1, where $D=k[h]$ or $D=k[h^\\pm]$. Consider the diagonal action of $G_m^{\\otimes n}$ on $D_n(a, \\sigma)$, induced by the action above. Then $D_n(a,\\sigma)^{G_m^{\\otimes n}} \\simeq D_n(a_m, \\sigma^m)$. If $X_i,Y_i$ are the GWA generators of $D_n(a, \\sigma)$ and $X_i', Y_i'$ the ones from $D_n(a_m, \\sigma^m)$, the isomorphism sends $X_i^m \\mapsto X_i'$, $Y_i^m \\mapsto Y_i'$.\n\\end{proposition}\n\\begin{proof}\nImmediate from the above theorem.\n\\end{proof}\n\nWe discuss now the same action as in Proposition \\ref{mainprop2}, but in a much wider context.\n\\begin{proposition} \\label{mainprop2}\nLet $D_n(a, \\sigma)$ be a generalized Weyl algebra in the context of definition \\ref{def}, with $D=k[h],k[h^\\pm]$. Let $\\mathbb{Z}^n$ be the group of automorphisms of $k[h_1,\\ldots,h_n]$ (or $k[h_1^\\pm,\\ldots,h_n^\\pm]$) such that $e_i(h_j)=\\sigma_i(h_j)$, $e_1, \\ldots, e_n$ the canonical basis of $\\mathbb{Z}^n$. Let $\\mathcal{M} = \\langle e_1^m, \\ldots, e_n^m \\rangle \\subset \\mathbb{Z}^n$. Then for $G=G(m,1,n)$, $D_n(a,\\sigma)^G$ is a principal Galois order in $(k(h_1, \\ldots, h_n)*\\mathcal{M})^G$. The subalgebra $k[h_1,\\ldots,h_n]^{S_n}$ (or $k[h_1^\\pm,\\ldots,h_n^\\pm]^{S_n}$) is the Harish-Chandra subalgebra and the Galois order is free over it.\n\\end{proposition}\n\\begin{proof}\nBy Corollary \\ref{maincorol2} and Proposition \\ref{mainprop}.\n\\end{proof}\n\n\\begin{remark}\nWe notice that this action differs, in the case of the quantum affine space and the quantum torus, of the action considered in \\cite{FS2}.\n\\end{remark}\n\n%Let $A(m,p,n)$ be the subgroup of $G_m^{\\otimes n}$ consisting of $(h_1, \\ldots, h_n)$ sucht that $(\\prod h_i)^{m/p}=1$. $G(m,p,n)= A(m,p,n) \\rtimes S_n$. It is allways a normal subgroup of $G(m,1,n)$, and the quotient group is isomorphic to $G_p$.\n\n\nGiven this action of $G(m,1,n)$, we also have one of the subgroup $G(m,p,n)$ on $D_n(a,\\sigma)$, where $D=k[h],k[h^\\pm]$.\n\n\\begin{theorem}\\label{tmain1}\n$D_n(a, \\sigma)^{G(m,p,n)} = \\bigoplus_{k=0}^{p-1} (X_1 \\ldots X_n)^{km/p} D_n(a, \\sigma)^{G(m,1,n)}$.\n\\end{theorem}\n\\begin{proof}\nLet $\\Xi = (g, \\pi) \\in A(m,1,n) \\rtimes S_n$, $g=(g_1, \\ldots, g_n)$ be an element of $G(m,1,n)$ that, in the quotient by $G(m,p,n)$, maps to generator of $G_p$. We have $\\Xi (X_1, \\ldots X_n)^{m/p} = \\xi (X_1, \\ldots X_n)^{m/p}  $, where $\\xi$ is a $p$-root of unity. Hence in $(X_1 \\ldots X_n)^{km/p} D_n(a, \\sigma)^{G(m,1,n)}$ $\\Xi$ acts with eigenvalue $\\xi^{m}$. Since $\\Xi$ is an operator with order $p$, $0=\\prod_{i=0}^{p-1}(\\Xi - \\xi^i I)$ anihilates $D_n(a, \\sigma)^{G(m,p,n)}$. The direct sum, then, is just the eigenspace decomposition for the operator $\\Xi$.\n\\end{proof}\n\n\n\\begin{theorem} \\label{tmain2}\nLet $D_n(a, \\sigma)$ be a generalized Weyl algebra in the context of definition \\ref{def}, with $D=k[h],k[h^\\pm]$. Let $\\mathbb{Z}^n$ be the group of automorphisms of $k[h_1,\\ldots,h_n]$ (or $k[h_1^\\pm,\\ldots,h_n^\\pm]$) such that $e_i(h_j)=\\sigma_i(h_j)$, $e_1, \\ldots, e_n$ the canonical basis of $\\mathbb{Z}^n$. Let $\\mathfrak{M} = \\langle e_1^m, \\ldots, e_n^m, (e_1 e_2 \\ldots e_n)^{m/p} \\rangle \\subset \\mathbb{Z}^n$. Then for $G=G(m,p,n)$, $D_n(a,\\sigma)^G$ is a principal Galois order in $(k(h_1, \\ldots, h_n)*\\mathfrak{M})^G$. The subalgebra $k[h_1,\\ldots,h_n]^{S_n}$ (or $k[h_1^\\pm,\\ldots,h_n^\\pm]^{S_n}$) is the Harish-Chandra subalgebra and the Galois order is free over it.\n\\end{theorem}\n\\begin{proof}\nBy Propopostion \\ref{mainprop2} and Theorem \\ref{tmain1}.  Being explict: $D_n(a,\\sigma)^G$ is generated by by $X_i^m, Y_i^m, (X_1 \\ldots X_n)^{m/p}$ over $D$, and the embedding that realizes the invariant algebra as a Galois algebra is $X_i^m \\mapsto e_i^m$, $Y_i \\mapsto a_{mi} e_i^{-m}$, $ (X_1 \\ldots X_n)^{m/p} \\mapsto (e_1 e_2 \\ldots e_n)^{m/p}$, $a_{mi}= a_i \\sigma_i^{-1}(a_i) \\ldots \\sigma_i^{-(m-1)}a_i$, $i=1,\\ldots,n$.\n\\end{proof}\n\n\n\\begin{corollary} \\label{GK}\nThe invariants of the Weyl algebra $A_n(\\k)^{G(m,p,n)}$ are principal Galois order in  $(k(h_1, \\ldots, h_n)*\\mathfrak{M})^G$, where $e_i(h_j)=h_j-\\delta_{ij}$, and $h_i=\\partial_i x_i$. The Harish-Chandra subalgebra is  $\\k[h_1,\\ldots,h_n]^{S_n}$.\n\\begin{proof}\nA particular case of the above theorem, since $A_1(\\k)=\\k[h](h, \\sigma)$, where $\\sigma(h)=h-1$.\n\\end{proof}\n\\end{corollary}\n\nThis reproves the result in \\cite{LW} in the particular case of the invariants of the Weyl algebra in a different and simpler way. Finally, we show that for invariants of generalized Weyl algebras of pure type under the action of the groups of type $G(m,p,n)$, and in particular the Weyl algebra itself, the category of holonomic modules is a supercategory of the category of Gelfand-Tsetlin modules.\n\n\\begin{theorem} \\label{connection}\nLet $D(a, \\sigma)$ be a generalized Weyl algebra of pure type (Defition \\ref{mixed}) of rank $n$ (in particular $A_n(\\k)$), and consider its invariant $D(a, \\sigma)^{G(m,p,n})$. Then all Gelfand-Tsetlin modules for this Galois order are holonomic modules.\n\\begin{proof}\nFollows imediatly from Theorems \\ref{tmain2} and \\ref{GK-GT}.\n\\end{proof}\n\\end{theorem}\n\n\\section{Appendix}\n\nLet $D$ be an affine commutative algebra and domain, $D(a, \\sigma)$ be a completely arbitrary generalized Weyl algebra of rank $n$ over an algebraically closed field $\\k$ of any characteristic. For every $m \\in Specm \\, D$, we will show that the liftng result to irreducible weight-modules for $D(a, \\sigma)$ in case of Galois orders holds in this generality. Denote by $f_m:D/m \\rightarrow \\k$ the canonical isomorphism. Let $\\phi$ be any automorphism of $D$. Then it is easy to see that:\n\n\\[ (\\dagger) f_{\\phi^{-1} m}(a)= f_m(\\phi(a)).\\]\n\nIn the classical clase of Gelfand-Tsetlin modules for $gl_n$ they are parametrized up to finitness by the Gelfand-Tsetlin tableaux. These are nothing but elements of the maximal spectrum of of the Gelfand-Tsetlin subalgebra, since it is polynomial (cf. \\cite{DFO}). Motivated by this and the construction of generic Gelfand-Tsetlin modules in \\cite{DFO}, we have the following construction.\n\nFix a maximal ideal $m$ of $D$. Consider the symbols $T(\\theta(m))$, where $\\theta$ runs throught all the elements of the group of automorphisms of $D$ generated the $\\sigma_i$'s. We call those $T(.)$ \\emph{generalized tableaux}. Let $T_m$ be the free vector space on the generalized tableaux.\n\nFor each basis element $T(n) \\in T_m$, where $n$ is an ideal of the form $\\theta(m)$, define the following linear actions:\n\n \\[ z.T(n)=f_n(z)T(n); \\]\n \\[ X_i.T(n) = T(\\sigma_i n); \\]\n \\[ Y_i T(n) = f_{\\sigma_i^{-1}  n}(a_i)T(\\sigma_i n),\\]\n \\[ z \\in D, X_i, Y_i \\in D(a , \\sigma), i=1,\\ldots, n .\\] \n Then, by repeated use of $\\dagger$, it is easy to see that the formulas above satisfies the relations of the generators of the generalized Weyl algebra. Hence:\n\n\\begin{theorem} \\label{gentableaux}\nFor each $m \\in Specm \\, D$, there exists an irreducible $D(a, \\sigma)$-module $T_m$ which has a weight-space decomposition with respect to $D$, lifting $m$.\n\\end{theorem}\n\\begin{proof}\nImmediate by the above considerations.\n\\end{proof}\n\n%\\begin{corol} \\label{GK}\n%The invariants of the Weyl algebra $A_n(k)^{G(m,p,n)}$ are principal Galois order in  $(k(h_1, \\ldots, h_n)*\\mathfrak{M})^G$, where $e_i(h_j)=h_j-\\delta_{ij}$, and $h_i=\\partial_i x_i$. The Harish-Chandra subalgebra is  $k[h_1,\\ldots,h_n]^{S_n}$ and we have the invariants of the Weyl algebra a free module over it. Moroever, $(k(h_1, \\ldots, h_n)*\\mathfrak{M})^G$ has as division quotient ring the Weyl field $Q(A_n(k))$.\n%\\begin{proof}\n%A particular case of the above theorem, since $A_1(k)=k[h](h, \\sigma)$, where $\\sigma(h)=h-1$. The Gelfand-Kirillov Conjecture follow by \\cite{FO1} and the Noncommutative Noether's Problem for the Weyl algebra.\n%\\end{proof}\n%\\end{corol}\n\n%\\begin{definition}\n%A $GWA$ of rank one $D(a, \\sigma)$ is called of \\emph{classical type} if $D=k[h]$ or $D=k[h^\\pm]$ and $\\sigma(h)=h-\\alpha$. Up to isomorphism, we can allways suppose $\\alpha=1$.\n%\\end{definition}\n\n%\\begin{theorem} \\label{GelfandKirillov2}\n%Let $D_n(a, \\sigma)^{G(m,p,n)}$ be the invariants of the tensor product of a $GWA$ of classical type. Then its quotient division ring is $Q(A_n(k))$ and hence the Gelfand-Kirillov Cojecture holds.\n%\\begin{proof}\n%By Thm. \\ref{main2} and Corol \\ref{GK}.\n%\\end{proof}\n%\\end{theorem}\n\n%\\begin{theorem}\n%\\begin{proof}\n%We first show that $X=\\Gamma-\\{0\\}$ is an Ore set in $U$, the rest follows from the definition of Galois ring. By \\cite{Hartwig}, Lemma 2.7(iv), given $u \\in U, x \\in X$, $x^{-1} u = \\sum_{i=0}^n u y_i x_i^{-1},y_i \\in \\Gamma, x_i \\in S.$ Then $u x_1, \\ldots x_n =\n\n%\\begin{theorem}\n%Let $U$ be a Galois order in $(L*\\mathcal{M})^G$, with Harish-Chandra $\\Gamma$, and $M$ a Gelfand-Tsetlin module, where $\\mathcal{M} \\simeq \\mathbb{Z}^n$. Then $GK \\, M \\leq n$.\n%\\begin{proof}\n%Let $F$ be any finite dimensional subspace generating $M$ as an $U$-module. Let $\\{ u_i =\\sum_{m_i \\in \\mathcal{M}} \\alpha_{m_i} m_i\\}, i=1,\\ldots, s$ be a finite set of generators of $U$, containing the identity. Let $V= span \\langle u_1, \\ldots, u_s \\rangle$ be the corresponding frame, and $\\mathcal{M}' \\subset \\mathcal{M}$ be the submonoid generated by $\\bigcup_{i=1}^s supp \\, u_s$. Then, since $\\Gamma$ acts locally finitelly on $M$, we have that $limsup \\, n \\mapsto \\infty\\,  log\\,  (dim_\\k V^i F)/ \\, log \\, n \\leq growth \\, \\mathcal{M}' \\leq growth \\, \\mathcal{M}\\simeq \\mathbb{Z}^n = n$.\n%\\end{proof}\n%\\end{theorem}\nGalois algebras and orders were developed in \\cite{FO1} and \\cite{FO2}, in a further refinement of the theory of Harish-Chandra categories in \\cite{DFO}, in case we have a pair of algebra/subalgebra $\\Gamma \\supset U$, with $\\Gamma$ commutative, and a certain embedding of $U$ in a skew monoid ring. This theory has led to breakthrough in representation theory for many algebras, in particular $U(gl_n)$ and its quantization, and finite $W$-algebras of $A$ type (see \\cite{Proceedings} for a detailed discussion). Recently, there were further developments: in \\cite{H} it was developed a somewhat different formalism of these algebras and contributions were made to the study of maximal commutative subalgebras and certain parabolic subalgebras of the algebras mentioned previously. Another formalism was introduced in \\cite{Webster} --- namely, that of a flag Galois order. We remark that they are all equivalent to the orignal one of \\cite{FO1} and \\cite{FO2}. In \\cite{Webster} it was also noted the remarkable connection between quantized Coulomb branches and Galois orders --- in particular $OGZ$ algebras of type $A$ (\\cite{Mazorchuk}) and spherical subalgebras of cyclotomic Cherednik algebras (\\cite{Etingof}). The rigorous mathematical definition of the Coulomb branch of a $3d \\, \\mathcal{N}=$ SUSY gauge theory was studied first in \\cite{N} (to which we refer to the physics background on the subject), and a satisfactory definition, with a rich theory, developed in \\cite{BFN}.\n\n\n\n\n{\\color{magenta} \\textbf{If} the results on rational Cherednik algebras introduced in this new version are OK, then we can remove the bellow theorem\nWe have the following immediate application which is a generalization of \\cite[Corolary 1.8]{B5}. \n\n\\begin{theorem}\nLet $H_{1,c}(V, W)$ be a rational Cherednik algebra with an integral parameter $c$ and arbitrary complex reflection group $W$ (cf. \\cite{Berest}). Then $$fdim \\, H_c(V,W) = 1.$$\n\\end{theorem}\n\n\\begin{proof}\nThe algebra $H_{1,c}(V, W)$ is Morita equivalent to the spherical subalgebra $U_{1,c}(V,W)$ and both  are simple affine with the Gelfand-Kirillov dimension $2 dim \\, V$.  The spherical subalgebra\n has a module of the Gelfand-Kirillov dimension $dim \\, V$ --- the module of quasi-invariants $Q_c(W)$ (\\cite[Theorem 3.3, Corollary 3.5]{Berest}. Moreover,  $U_{1,c}(V,W) \\simeq \\mathcal{D}(Q_c(W))^W$, where $W$ acts by outer automorphisms on the simple ring $\\mathcal{D}(Q_c(W))$, which is Morita equivalent to the Weyl algebra $\\mathcal{D}(V)$ (\\cite[Proposition 4.3, Theorem 1.2]{Berest}. Since the filter dimension of the Weyl algebras is $1$, the result follows from Proposition \\ref{heart} and Theorem \\ref{morita}.\n\\end{proof}\n}", "meta": {"timestamp": "2020-10-29T00:02:37", "yymm": "2010", "arxiv_id": "2010.14562", "url": "https://arxiv.org/abs/2010.14562", "source": "arxiv"}}
{"text": "\\documentclass[11pt,reqno]{amsart}\r\n\\usepackage{amsmath, amsthm, amssymb}\r\n%\\usepackage{amsmath, amsthm, amssymb, stmaryrd}\r\n%\\usepackage{fullpage}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{array}\r\n\\usepackage{caption}\r\n\r\n\\topmargin 0.0cm\r\n  \\textheight 22.2cm\r\n\\oddsidemargin 0.8cm\r\n\\evensidemargin \\oddsidemargin\r\n\\marginparwidth 2cm\r\n\\textwidth 15.2cm\r\n\\def\\a{{\\mathbf a}}\r\n\\def\\c{{\\mathbf c}}\r\n\\def\\b{{\\mathbf b}}\r\n\\def\\n{{\\mathbf n}}\r\n\\def\\B{\\mathcal B}\r\n\\def\\e{\\varepsilon}\r\n\\newcommand{\\mmod}[1]{\\,\\,(\\text{\\rm mod}\\,\\, #1)}\r\n\\def\\bfh{{\\mathbf h}}\r\n\\def\\bfb{{\\mathbf b}}\r\n\\def\\bfc{{\\mathbf c}}\r\n\\def\\bfy{{\\mathbf y}}\r\n\\def\\bfx{{\\mathbf x}}\r\n\\def\\bfz{{\\mathbf z}}\r\n\\def\\bfr{{\\mathbf r}}\r\n\\def\\bfw{{\\mathbf w}}\r\n\\def\\bfv{{\\mathbf v}}\r\n\\def\\bfn{{\\boldsymbol n}}\r\n\\def\\bfgamma{{\\boldsymbol \\gamma}}\r\n\\def\\bfalpha{{\\boldsymbol \\alpha}}\r\n\\def\\bfbeta{{\\boldsymbol \\beta}}\r\n\\def\\bfnu{{\\boldsymbol \\nu}}\r\n\\def\\bftau{{\\boldsymbol \\tau}}\r\n\\def\\numset#1{{\\mathbb #1}}\r\n\\newtheorem{thm}{Theorem}\r\n\\newtheorem{cor}{Corollary}\r\n\\newtheorem{propos}{Proposition}\r\n\\newtheorem{problem}{Problem}\r\n\\newtheorem{remark}{Remark}\r\n\\newtheorem{lem}{Lemma}\r\n\\newtheorem{claim}{Claim}\r\n\\newtheorem{conj}{Conjecture}\r\n\\newtheorem{defn}{Definition}\r\n\\newtheorem{exam}{Example}\r\n\\newtheorem{prop}{Proposition}\r\n\\newcommand{\\E}{\\ensuremath{\\mathbb E}}\r\n\\newcommand{\\U}{\\ensuremath{\\mathcal U}}\r\n\\numberwithin{equation}{section} \\numberwithin{thm}{section}\r\n\\numberwithin{lem}{section} \\numberwithin{problem}{section}\r\n\\numberwithin{cor}{section}\r\n\\newcommand{\\cc}{\\mathbf c}\r\n\\newcommand{\\ccc}{\\overline{\\mathbf c}}\r\n\\newcommand{\\aaa}{\\overline{\\alpha}}\r\n\\newcommand{\\p}{\\mathbf p}\r\n\\newcommand{\\ex}{\\text{ex}}\r\n\\def\\grm{{\\mathfrak m}}\\def\\grM{{\\mathfrak M}}\\def\\grN{{\\mathfrak N}}\\def\\grn{{\\mathfrak n}}\\def\\grT{{\\mathfrak T}}\\def\\grp{{\\mathfrak p}}\\def\\grP{{\\mathfrak P}}\r\n\\newcommand{\\q}{\\mathbf q}\r\n\\newcommand{\\rr}{\\mathbf r}\r\n\\newcommand{\\pp}{\\overline{\\mathbf p}}\r\n\\newcommand{\\qq}{\\overline{\\mathbf q}}\r\n\\newcommand{\\nuu}{\\overline{\\mathbf \\nu}}\r\n\\newcommand{\\Real}{\\mathbb R}\r\n\\newcommand{\\RPlus}{\\Real^{+}}\r\n\\newcommand{\\norm}[1]{\\left\\Vert#1\\right\\Vert}\r\n\\newcommand{\\abs}[1]{\\left\\vert#1\\right\\vert}\r\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\r\n\\newcommand{\\seq}[1]{\\left<#1\\right>}\r\n\\newcommand{\\eps}{\\varepsilon}\r\n\\newcommand{\\To}{\\longrightarrow}\r\n\\newcommand{\\BX}{\\mathbf{B}(X)}\r\n\\newcommand{\\A}{\\mathcal{A}}\r\n\\newcommand{\\Ha}{\\mathcal{H}}\r\n\\newcommand{\\Beta}{B}\r\n\\newcommand{\\Ar}{\\text{Arc}}\r\n\\newcommand{\\M}{\\mathcal{M}}\r\n\\newcommand{\\G}{\\mathcal{G}}\r\n\\newcommand{\\W}{\\mathcal{W}}\r\n\\newcommand{\\N}{\\mathcal{N}}\r\n\\newcommand{\\Ll}{\\mathcal{L}}\r\n\\newcommand{\\Fa}{\\mathcal{F}}\r\n\\newcommand{\\Z}{\\mathbb{Z}}\r\n\\newcommand{\\Lom}{\\mathcal{L}}\r\n\\newcommand{\\Comp}{\\mathcal{K}}\r\n\\newcommand{\\Basis}{\\mathcal{B}}\r\n\\newcommand{\\nnu}{\\mathbf{\\nu^n}}\r\n\\newcommand{\\F}{\\mathbb F}\r\n\\newcommand{\\FF}{\\mathcal F}\r\n\\newcommand{\\MM}{\\mathcal M}\r\n\\def\\f{\\frac{|\\A||B|}{|G|}}\r\n\\def\\AB{|\\A\\cap B|}\r\n%%% ----------------------------------------------------------------------\r\n%\\nopagenumber\r\n%\\renewcommand{\\baselinestretch}{1.5}\r\n%\\textwidth=14cm\r\n\\parskip 1.5mm\r\n\r\n\r\n\\begin{document}\r\n\\title{Uniform bounds in Waring's problem over some diagonal forms}\r\n\\author[Javier Pliego]{Javier Pliego}\r\n\\address{School of Mathematics, University of Bristol, University Walk, Clifton, Bristol BS8 1TW, United \r\nKingdom.}\r\n\r\n\\address{Current address: Purdue Mathematical Science Building, 150 N University St, West Lafayette, IN 47907, United States of America.}\r\n\r\n\\email{jp17412@bristol.ac.uk}\r\n\\subjclass[2010]{11E76, 11P05, 11P55}\r\n\\keywords{Waring's problem, Hardy-Littlewood method, Diagonal forms}\r\n\r\n\r\n\\begin{abstract} We investigate the existence of representations of every large positive integer as a sum of $k$-th powers of integers represented as certain diagonal forms. In particular, we consider a family of diagonal forms and discuss the problem of giving a uniform upper bound over the family for the number of variables needed to have such representations.\r\n\\end{abstract}\r\n\\maketitle\r\n\r\n\\section{Introduction} \r\nWaring's problem (first resolved by Hilbert) asserts that for every $k\\in\\mathbb{N}$ there exists $s=s_{0}(k)$ such that all positive natural numbers can be written as a sum of $s$ positive integral $k$-th powers. Likewise, the problem of representing a sufficiently large natural number $n$ in the shape \r\n\\begin{equation}\\label{solu}n=x_{1}^{k}+\\dots+x_{s}^{k},\\end{equation} with $x_{i}\\in \\mathcal{S},$ where $\\mathcal{S}$ is a given subset of the integers, has also been studied for particular cases.  However, little has been written about Waring's problem when one considers specific sparse sets, and apart from the set of prime numbers, not much can be found on the literature. It is then rare to encounter examples of sparse sets with a structure fundamentally different in nature in which Waring's problem along the lines of equation (\\ref{solu}) is solvable. \r\n\r\nFor a general set $\\mathcal{A}\\subset\\mathbb{N}$, denote by $G_{\\mathcal{A}}(k)$ the least positive integer $s$ such that for all sufficiently large natural numbers $n$, the equation (\\ref{solu}) possesses a solution with $x_{i}\\in\\mathcal{A}.$ If such a number does not exist, define it as $\\infty$. Let $\\alpha>0$ and consider sets $\\mathcal{A}_{\\alpha}\\subset\\mathbb{N}$ well distributed on arithmetic progressions and with the property that $\\lvert\\mathcal{A}_{\\alpha}\\cap[1,N]\\lvert\\gg N^{\\alpha}$. Then, on denoting $$W(k,\\alpha)=\\sup_{\\mathcal{A}_{\\alpha}}\\big\\{G_{\\mathcal{A}_{\\alpha}}(k)\\big\\},$$one would hope to have $W(k,\\alpha)<\\infty.$ In what follows we describe a particular family of sets satisfying the above property for which we expect the previous uniform bound to hold, but first we introduce, for convenience, some notation. For fixed $k,l,t\\in\\mathbb{N}$, let $\\mathbf{x}=(x_{1},\\ldots,x_{t})\\in\\mathbb{N}^{t}$, consider the function $T_{t}(\\mathbf{x})=x_{1}^{l}+\\ldots+x_{t}^{l}$ and take the set \r\n$$\\mathcal{T}_{t}=\\big\\{T_{t}(\\mathbf{x}):\\ \\mathbf{x}\\in\\mathbb{N}^{t}\\big\\}.$$ \r\n\r\nIn this memoir we restrict our attention to the analysis of the solubility of (\\ref{solu}) for the choice $\\mathcal{S}=\\mathcal{T}_{t}$ with $t$ lying in the following two regimes:\r\n\r\n$(i)$ When $t=C(k)l$ for any fixed integer-valued function satisfying $C(k)\\geq \\textstyle{\\frac{1}{2}}\\log (k(k+1)).$ Work of Wooley \\cite{Woo1} then yields the lower bound $\\lvert \\mathcal{T}_{t}\\cap [1,N]\\lvert \\gg N^{1-\\beta/k^{2}}$ for some constant $\\beta>0$. The reader may notice that once we fix $k$, the above bound is uniform over the family of sets $\\mathcal{T}_{t}$, whence in view of the preceding discussion we expect to have $G_{\\mathcal{T}_{t}}(k)<G_{C}(k)$ for all $t$ in this regime with $G_{C}(k)$ being a constant depending on $k$ and $C$. As will be discussed afterwards, the lower bound for the cardinality of the sets available is not strong enough to prove such a statement, and we end up showing something weaker.\r\n\r\n$(ii)$ When $t\\geq \\textstyle{\\frac{l}{2}}\\big(\\log l+\\log(k(k+1))+2\\big)$ then work of Wooley \\cite{Woo1} yields the stronger lower bound $\\lvert \\mathcal{T}_{t}\\cap [1,N]\\lvert \\gg N^{1-\\gamma/lk^{2}}$ for some absolute constant $\\gamma>0$ at the cost of taking more variables. Were the sets $\\mathcal{T}_{t}$ to have positive density, the argument would be considerably simplified and a pedestrian approach of the circle method would suffice. We use though the estimate available for the cardinality of these sets to derive a bound for $G_{\\mathcal{T}_{t}}(k)$ that only depends on $k$. \r\n\r\nFor the rest of the introduction we discuss each of the two regimes described above and provide some motivation underlying their choice. As experts will realise, an application of the Hardy-Littlewood method delivers the solubility of (\\ref{solu}) for $\\mathcal{S}=\\mathcal{T}_{t}$ when $t=C(k)l$ and $s$ is large enough in terms of $k$ and $l$. We denote by $S_{C}(k,l)$ the minimum $s$ with such a property and consider\r\n$$P_{C}(k)=\\sup_{l\\geq 2}\\big\\{S_{C}(k,l)\\big\\},$$ which does not necessarily have to be finite. We also define the constant\r\n\\begin{equation}\\label{cono}\\delta_{r}=\\exp(1-2r/l)\\end{equation}for each $r\\in\\mathbb{N}$ and note that then combining the corollary to Theorem 2.1 of Wooley \\cite{Woo1} and a standard argument involving Cauchy's inequality one obtains the lower bound\\begin{equation}\\label{1.fi}\\lvert \\mathcal{T}_{t}\\cap [1,N]\\rvert \\gg N^{1-\\delta_{t}},\\end{equation}where $\\delta_{t}=\\exp\\big(1-2C(k)\\big)$ just depends on $k$. As previously mentioned, the estimate (\\ref{1.fi}) is uniform once we fix $k$, whence the discussion made above motivates the following conjecture.\r\n\r\n\\begin{conj}\\label{con1}\r\nLet $k\\in\\mathbb{N}.$ There exists a positive integer-valued function $C:\\mathbb{N}\\rightarrow\\mathbb{N}$ such that $P_{C}(k)<\\infty.$\r\n\\end{conj}\r\nThis conjecture seems to be out of reach with the methods available in the literature for any value of $k$. However, in this paper we make some progress by using an argument which permits us to prove a weaker version which we describe next after introducing first some notation. For $s\\in\\mathbb{N}$, the choice of $t$ described above and any $r\\geq 0$, consider the equation\r\n\\begin{equation}\\label{conje}\r\nn=\\sum_{i=1}^{s}T_{t}(\\mathbf{x}_{i})^{k}+\\sum_{i=1}^{r}x_{i}^{k},\r\n\\end{equation}\r\nwhere $\\mathbf{x}_{i}\\in\\mathbb{N}^{t}$ and $x_{i}\\in\\mathbb{N}.$ Let $S_{C}(k,l,r)$ denote the minimum number such that for $s\\geq S_{C}(k,l,r),$ the equation (\\ref{conje}) has a solution for all sufficiently large $n$ and take $$P_{C}(k,r)=\\sup_{l\\geq 2}\\{S_{C}(k,l,r)\\},$$which, as before, does not necessarily have to be finite. We define $R_{C}(k)$ to be the minimum $r\\geq 0$ such that $P_{C}(k,r)$ is finite. After the preceding discussion we are now equipped to state the main theorem of the paper.\r\n\\begin{thm}\\label{thm1.2}\r\nLet $k\\geq 2$ and consider any positive integer-valued function $C(k)$ with the property that $$C(k)\\geq \\max\\big(4,\\textstyle{\\frac{1}{2}}\\log (k(k+1))+3/2\\big).$$ Then one has the bound\r\n$$R_{C}(k)\\leq 4,$$ and for every $r\\geq 4$ one finds that $P_{C}(k,r)\\leq k^{2}+O(k).$ Moreover, $R_{C}(2)\\leq 2$.\r\n\\end{thm}\r\nWe should emphasize that one could obtain the more precise bound $P_{C}(k,r)\\leq k(k+1)$ by introducing suitable weights in the exponential sums that we make use of and exploiting the information provided by such sums on the major arc analysis. We have omitted providing that discussion to make the exposition simpler. The reader might as well want to observe that $R_{C}(k)=0$ is equivalent to Conjecture \\ref{con1}, whence the statement containing the relevant information in the above theorem is the upper bound on $R_{C}(k)$. \r\n\r\nLet $G(k)=G_{\\mathbb{N}}(k)$ be the smallest number such that for all $s\\geq G(k)$, every large enough natural number can be written as a sum of $s$ positive integral $k$-th powers. Vinogradov \\cite{Vi}, Karatsuba \\cite{K} and Vaughan \\cite{Vau3} made progress to achieve upper bounds for $G(k)$, the best current one for large $k$ being \\begin{equation}\\label{G(k)}G(k)\\leq k\\Bigg(\\log k+\\log\\log k+2+O\\Big(\\frac{\\log\\log k}{\\log k}\\Big)\\Bigg)\\end{equation} due to Wooley \\cite{Woo2}. Note that as a consequence of this bound one trivially has $$R_{C}(k)\\leq k\\big(\\log k+\\log\\log k+O(1)\\big).$$ The reader then might want to observe that Theorem \\ref{thm1.2} improves this bound substantially. It is also worth noting that if Conjecture \\ref{con1} were true for any fixed $k$, there would exist some $s=s(k)$ with the property that for any $l\\geq 2$, every sufficiently big enough integer $n$ would have a representation of the shape\r\n\\begin{equation*}\r\nn=\\sum_{i=1}^{s}T_{t}(\\mathbf{x}_{i})^{k}\r\n\\end{equation*}\r\nwith $\\mathbf{x}_{i}\\in\\mathbb{N}^{t}$. Observe that the right side of the above equation would consist of sums of $Cl$ positive integral $l$-th powers gathered in groups and raised to the power $k$ for some constant $C=C(k)>0$ depending on $k$. This problem seems then even harder than the problem of proving that every sufficiently large integer can be written as the sum of $Cl$ positive integral $l$-th powers, which would be a big breakthrough in view of (\\ref{G(k)}).\r\n\r\nBefore describing the other regime for $t$ analysed in the memoir, we note that as a consequence of the aforementioned work on $G(k)$, it follows that whenever $t\\geq t_{0}(l)$ with \\begin{equation}\\label{tfor}t_{0}(l)=\\frac{l}{2}\\big(\\log l+\\log\\log l+2+o(1)\\big)\\end{equation} then $\\mathcal{T}_{t}$ has positive density, which greatly simplifies things (see, for example Br\\\"udern, Kawada and Wooley \\cite[Theorem 1.5]{BKW}). With the current state of knowledge, this turns out to be the threshold for which we can guarantee to have a lower bound of the shape $\\lvert\\mathcal{T}_{t}\\cap [1,N]\\rvert\\gg N^{1-\\varepsilon}.$ Therefore, for fixed $k$ and $l$ large enough, the cardinality of the sets $\\mathcal{A}_{l}=\\mathcal{T}_{\\xi_{0}(k,l)}\\cap [1,N]$ with $\\xi_{0}(k,l)=\\lceil l/2\\big(\\log l+\\log\\big(k(k+1)\\big)+2\\big)\\rceil$ is not known to satisfy $\\lvert \\mathcal{A}_{l}\\rvert\\gg N^{1-\\varepsilon},$ the best lower bound known being\r\n$$\\lvert \\mathcal{A}_{l}\\rvert\\gg N^{1-1/k(k+1)le},$$which is a consequence of (\\ref{1.fi}).\r\n\\begin{thm}\\label{thm1.3}\r\nLet $k,l\\geq 2$ and take $\\xi\\geq \\xi_{0}(k,l)$ and $s\\geq s_{0}(k)$ with $s_{0}(k)=k^{2}+O(k).$ Then every sufficiently large $n$ can be represented as\r\n$$n=\\sum_{i=1}^{s}x_{i}^{k},$$\r\nwhere $x_{i}\\in\\mathcal{T}_{\\xi}$.\r\n\\end{thm}\r\nThe reader may want to observe that even if the sets $\\mathcal{T}_{\\xi}$ are not known to satisfy the estimate $\\lvert\\mathcal{T}_{\\xi}\\cap [1,N]\\rvert\\gg N^{1-\\varepsilon}$, the bound on the number $s$ of variables needed does not depend on $l$. This suggests that one should search for ideas which don't just make use of the polynomial structure of the sets $\\mathcal{T}_{\\xi}$ in order to prove such result. Experts in the area may also notice that one could prove a weaker version of the theorem by combining Corollary 1.4 of Wooley \\cite{Woo4} with a pointwise bound over the minor arcs derived from Lemma 5.4 of Vaughan \\cite{Vau}. This strategy though would entail the restriction $s\\geq (3/2)k^{2}+O(k)$. We instead use a similar idea than the one we employ for the minor arc treatment in the proof of Theorem \\ref{thm1.2} that avoids relying on such pointwise bounds and enables us to win $k(k+1)/2$ variables. It is worth mentioning that one could also introduce suitable weights in the exponential sum that we make use of to obtain a more precise error term in the expression for $s_{0}(k)$.\r\n\r\nBack to equation (\\ref{solu}), the case when the set $\\mathcal{S}$ is taken to be the prime numbers has been of interest to many mathematicians. Among others, Hua first (\\cite{Hua}, \\cite{Hua2}) and then Thanigasalam (\\cite{Tha1}, \\cite{Tha2}),  Kumchev \\cite{Kum},  Kawada and Wooley \\cite{KW}, and Kumchev and Wooley (\\cite{KW1}, \\cite{KW2}) have worked to give upper bounds for $H(k)$, where $H(k)$ is defined as the minimum number such that for every $s\\geq H(k)$, the equation $$n=p_{1}^{k}+\\dots+p_{s}^{k}$$ has a solution for all sufficiently large $n$ with the property that $n\\equiv s\\pmod{K(k)},$ where $K(k)$ is a constant defined in terms of $K(k)$ to ensure appropiate local solubility conditions (see \\cite{KW1} for a more precise definition of $K(k)$). We note that the best current bound for large $k$ is $H(k)\\leq (4k-2)\\log k-(2\\log 2-1)k-3$ due to Kumchev and Wooley \\cite{KW2}.\r\n\r\n\r\nAt the same time, some authors have been trying to find sparse sets with minimum density such that the problem of representing every sufficiently large positive number as a sum of $k$-th powers of elements of the set is still soluble with strong upper bounds for the number of variables needed. This other approach in Waring's problem has been studied by Nathanson\r\n\\cite{Nat}, where he used the probabilistic method to prove that for all $s\\geq G(k)+1,$ there exist sets $A$ with $\\text{card}(A\\cap [1,N])\\sim c N^{1-1/s+\\varepsilon}$  such that (\\ref{solu}) is soluble on $A$. The result was partially improved by Vu \\cite{Vu}, when he showed under the condition $s\\geq k^{4}8^{k}$ the existence of a set $A\\subset\\mathbb{N}$ with $\\text{card}(A\\cap[1,N])=\\Theta\\big(N^{k/s}(\\log N)^{1/s}\\big)$ such that $R_{A}(n)\\asymp \\log n,$ where $R_{A}(n)$ denotes the number of solutions of (\\ref{solu}) with the variables lying in $A$. Later on, Wooley \\cite{Woo3} proved the same result for $s\\geq T(k)+2$, where $T(k)$ is bounded above by an explicit version of the right-hand side of (\\ref{G(k)}).  However, though the size of the sets is near optimal, the arguments used by the authors are probabilistic, so they don't give a description of those sets. Therefore, the approach of this paper might be the first one in which by giving an explicit family of sets with similar density, one tries to find a uniform bound for the number of variables needed to solve (\\ref{solu}), as discussed at the beginning of the introduction. \r\n\r\n\r\nTheorems \\ref{thm1.2} and \\ref{thm1.3} are proved via the circle method, and the exposition is organised as follows. We bound a mean value via restriction estimates in Section \\ref{sec2} and we expose the key argument which permits us to estimate mean values of a suitable exponential sum over the minor arcs uniformly on $l$. Section \\ref{sec3} is devoted to a brief study of the singular series. In Section \\ref{sec4} we approximate the generating function for the problem over the major arcs. We give an asymptotic formula for the integral of the product of some exponential sums over the major arcs in Section \\ref{sec5} and we use it to complete the proof of Theorem \\ref{thm1.2}. We have included a small note in Section \\ref{sec6} that deals with the case $k=2$. In Section \\ref{sec7} we slightly modify the exponential sum taken in Section \\ref{sec2} and use a similar argument to obtain a suitable estimate for the contribution of the minor arcs in the setting of Theorem \\ref{thm1.3}. We combine such work with a standard major arc analysis to prove the theorem.\r\n\r\nFor the rest of the paper, we fix positive integers $l\\geq 2$ and $k\\geq 2$. For the sake of simplicity concerning local solubility, we assume that $t\\geq 4l$, though most of the results throughout the paper don't require this restriction. For ease of notation we also write $T(\\mathbf{x})$ instead of $T_{t}(\\mathbf{x})$. The main objective of Theorem \\ref{thm1.2} is to prove a non-trivial uniformity bound for $S_{C}(k,l,r)$, and thus we just focus our attention in large values of $l$ in terms of $k$. As mentioned above, even if we provide explicit bounds for $P_{C}(k,r)$ and $C(k)$, the relevant part of the result is the estimate on $R_{C}(k)$. For such purposes, we haven't included an investigation of the behaviour of $P_{C}(k,r)$ and $C(k)$ for small $k$.\r\n\r\n\r\nAs usual in analytic number theory, we denote $e^{2\\pi i z}$ by $e(z)$, and for every $q\\in\\mathbb{N}$, we put $e_{q}(z)=e^{2\\pi i z/q}$. When we write $a\\leq \\mathbf{x}\\leq b$ for a vector $\\mathbf{x}=(x_{1},\\ldots,x_{s})\\in\\mathbb{R}^{s}$ we will mean that $a\\leq x_{i}\\leq b$ for all $1\\leq i\\leq s.$ We denote $\\mathbf{x}\\equiv \\mathbf{y}\\pmod{q}$ when $x_{i}\\equiv y_{i}\\pmod{q}$ for all $1\\leq i\\leq s.$ We write $p^{r}|| n$ to denote that $p^{r}| n$ but $p^{r+1}\\nmid n.$ Whenever $\\varepsilon$ appears in any bound, it will mean that the bound holds for every $\\varepsilon>0$, though the implicit constant then may depend on $\\varepsilon$. We adopt the convention that when we write $\\delta$ in the computations we mean that there exists a positive constant such that the bound holds. We use $\\ll$ and $\\gg$ to denote Vinogradov's notation. \r\n\r\n\\emph{Acknowledgements}: The author's work was supported in part by a European Research Council Advanced\r\nGrant under the European Union's Horizon 2020 research and innovation programme via grant agreement No. 695223 during his studies at the University of Bristol. It was completed while the author was visiting Purdue University under Trevor Wooley's supervision. The author would like to thank him for his guidance and helpful comments, and both the University of Bristol and Purdue University for their support and hospitality.\r\n\r\n\r\n\\section{Minor arc estimate}\\label{sec2}\r\nWe will begin by displaying an upper bound for mean values of an exponential sum which will be of later use in the analysis of the minor arcs in the setting of both Theorems \\ref{thm1.2} and \\ref{thm1.3}. This will be a straightfoward consequence of the work of Wooley \\cite{Woo4} on Vinogradov's mean value theorem with weights. \r\nLet $r\\in \\mathbb{N}$, let $Y>0$ be a real parameter and consider the set\r\n\\begin{equation}\\label{Sr}\\mathcal{S}_{r}(Y)=\\Big\\{x_{1}^{l}+\\ldots+x_{r}^{l}:\\ \\ \\ x_{i}\\in\\mathcal{A}(Y,Y^{\\eta}),\\ \\ (1\\leq i\\leq r) \\Big\\},\\end{equation} where\r\n\\begin{equation*}\\mathcal{A}(Y,R)=\\{n\\in [1,Y]\\cap \\mathbb{N}: p\\mid n\\text{ and $p$ prime}\\Rightarrow p\\leq R\\}\\end{equation*} and $\\eta$ is a sufficiently small but positive parameter. Note that then the corollary to Theorem 2.1 of  Wooley \\cite{Woo1} and a routine argument using Cauchy's inequality yield \\begin{equation}\\label{1.1}\\lvert \\mathcal{S}_{r}(Y)\\rvert \\gg Y^{l-l\\delta_{r}},\\end{equation}where $\\delta_{r}$ was defined in (\\ref{cono}). In order to make further progress we need to introduce first some notation. Let $n$ be a positive integer and take $X=n^{1/k}$ and $P=X^{1/l}.$ Define for $\\alpha\\in [0,1)$ and $\\bfalpha\\in[0,1)^{k}$ the exponential sums\r\n\\begin{equation}\\label{falphap}f\\big(\\alpha,\\mathcal{S}_{r}(Y)\\big)=\\sum_{x\\in \\mathcal{S}_{r}(Y)}e(\\alpha x^{k}),\\  \\ \\ \\ \\ \\ \\ \\ \\ f\\big(\\bfalpha,\\mathcal{S}_{r}(Y)\\big)=\\sum_{x\\in \\mathcal{S}_{r}(Y)}e(\\alpha_{1}x+\\ldots+\\alpha_{k}x^{k}).\\end{equation} For future purposes in the analysis, we consider the mean value\r\n\\begin{equation}\\label{ec2.9}J_{s,r}^{(k)}(Y)=\\int_{[0,1)^{k}}\\big\\lvert f\\big(\\bfalpha,\\mathcal{S}_{r}(Y)\\big)\\big\\rvert^{2s} d\\bfalpha,\\end{equation} which by orthogonality counts the solutions to the system $$x_{1}^{j}+\\ldots+x_{s}^{j}=x_{s+1}^{j}+\\ldots+x_{2s}^{j}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (1\\leq j\\leq k),$$ where $x_{i}\\in\\mathcal{S}_{r}(Y).$\r\n\r\n\\begin{prop}\\label{prop1}\r\nLet $s\\geq k(k+1)/2.$ Then one has that\r\n\\begin{equation*}J_{s,r}^{(k)}(Y) \\ll \\lvert \\mathcal{S}_{r}(Y)\\rvert ^{2s}Y^{-lk(k+1)/2+l\\Delta_{r}+\\varepsilon},\\end{equation*}\r\nwhere $\\Delta_{r}=\\delta_{r}k(k+1)/2$.\r\n\\end{prop}\r\n\\begin{proof}\r\nDefine the weights $a_{x}=1$ if $x\\in \\mathcal{S}_{r}(Y)$ and $0$ otherwise. Then, we can rewrite $f(\\bfalpha,\\mathcal{S}_{r}(Y))$ as\r\n$$f(\\bfalpha,\\mathcal{S}_{r}(Y))=\\sum_{x\\leq rY^{l}}a_{x}e(\\alpha_{1}x+\\ldots+\\alpha_{k}x^{k}).$$ Therefore, combining Corollary 1.4 of Wooley \\cite{Woo4} with (\\ref{1.1}) and the triangle inequality we obtain $$J_{s,r}^{(k)}(Y)\\ll \\lvert\\mathcal{S}_{r}(Y)\\rvert ^{2s}\\lvert \\mathcal{S}_{r}(Y)\\rvert^{-k(k+1)/2}Y^{\\varepsilon}\\ll\\lvert \\mathcal{S}_{r}(Y)\\rvert ^{2s}Y^{-lk(k+1)/2+l\\Delta_{r}+\\varepsilon},$$ which yields the desired result. \r\n\\end{proof}\r\n\r\nBefore introducing the main ingredients for the minor arc analysis, we recall from the introduction that whenever $t\\geq t_{0}(l)$, where $t_{0}(l)$ was defined in (\\ref{tfor}), then $\\mathcal{T}_{t}$ has positive density. We deliberately avoid this situation by considering $l$ sufficiently large in terms of $k$. The difficulty of the Conjecture \\ref{con1} then lies on the fact that $\\mathcal{T}_{t}$ is not known to have positive density, and the best lower bounds available on the cardinality of the set are not strong enough. Moreover, any approach making use of the fact that $T_{t}(\\mathbf{x})^{k}$ is a polynomial of degree $kl$ and applying a Weyl estimate for the corresponding exponential sum or any multivariable version of Vinogradov's Mean Value Theorem (see Theorem 1.3 and Theorem 2.1 of \\cite{PPW}) would entail a restriction in the number of variables that would depend on the degree of the polynomial. \r\n\r\nWe make though some progress by obtaining a uniform bound in $l$ of a suitable exponential sum over the minor arcs. Our argument here is motivated by the treatment of Vaughan \\cite[Chapter 5]{Vau}, and it requires the estimate in Proposition \\ref{prop1}. For such purposes, we introduce first some notation. Consider a positive integer-valued function $C(k)$ and set \\begin{equation*}\\label{tes}t=C(k)l,\\ \\ \\ \\ \\ \\ \\ \\ \\ t_{1}=C(k)l-l.\\end{equation*} We take the parameter \\begin{equation}\\label{varphi}\\varphi_{k,t_{1}}=1-k(k+1)\\delta_{t_{1}}/2-e^{-1},\\end{equation} which for the sake of concision will be denoted by $\\varphi_{k}$. Observe that whenever $C(k)$ satisfies the lower bound included in the hypothesis of Theorem \\ref{thm1.2} then one has $\\varphi_{k}\\geq 1/2-e^{-1}>0.$ We also define the constants\r\n\\begin{equation}\\label{C1}C_{1}=\\big(k(k+1)2^{k+1}t_{1}^{k}\\big)^{-1/lk},\\ \\ \\ \\ \\ \\ \\ C_{2}=\\min\\Big((2lk)^{-1/l},\\big(k(k+1)2^{k+1}l^{k}\\big)^{-1/lk}\\Big).\\end{equation}\r\nand the natural numbers\r\n\\begin{equation}\\label{Pt}P_{1}=\\lfloor C_{1}P\\rfloor,\\ \\ \\ \\ P_{2}=\\lfloor C_{2}P\\rfloor.\\end{equation}For ease of notation, we denote $\\mathcal{S}_{t_{1}}(P_{1}),$ and $\\mathcal{S}_{l}(P_{2})$ by $\\mathcal{S}_{1},$ and $\\mathcal{S}_{2}$ respectively. It is then convenient to define, for $m\\in\\mathcal{S}_{2},$ the exponential sums\r\n\\begin{equation*}f_{m}(\\alpha)=\\sum_{x\\in\\mathcal{S}_{1}}e\\big(\\alpha(x+m)^{k}\\big)\\ \\ \\ \\ \\ \\ \\ \\  \\text{and}\\ \\ \\ \\ \\ \\ \\ \\mathcal{F}(\\alpha)=\\sum_{m\\in \\mathcal{S}_{2}}f_{m}(\\alpha).\\end{equation*}\r\nIn order to make further progress we make a Hardy-Littlewood dissection. When $1\\leq Q\\leq X$ we define the major arcs $\\grM(Q)$ to be the union of \r\n\\begin{equation}\\label{grM}\\grM(a,q)=\\Big\\{ \\alpha\\in [0,1): \\lvert \\alpha-a/q\\rvert \\leq \\frac{Q}{qn}\\Big\\}\\end{equation} with $0\\leq a\\leq q\\leq Q$ and $(a,q)=1$. For the sake of brevity we write\r\n$$\\grM=\\grM(X),\\ \\ \\ \\ \\ \\ \\ \\ \\grN=\\grM(P^{1/2}),\\ \\ \\ \\ \\ \\ \\ \\ \\grP=\\grM(\\log P)$$and we take $\\grm=[0,1)\\setminus \\grM$ and $\\grn=[0,1)\\setminus \\grN$ to be the minor arcs. \r\n\r\n\\begin{prop}\\label{prop22}\r\nLet $\\alpha\\in \\grm$. Then one has\r\n$$\\mathcal{F}(\\alpha)\\ll |\\mathcal{S}_{1}||\\mathcal{S}_{2}|X^{-\\varphi_{k-1}/k(k-1)+\\varepsilon},$$ where $\\varphi_{k-1}$ was defined in (\\ref{varphi}). \r\nMoreover, for $s\\geq k(k+1)/2$ we obtain the mean value estimate\r\n\\begin{equation*}\\int_{\\grm}\\lvert\\mathcal{F}(\\alpha)\\rvert^{2s}d\\alpha\\ll |\\mathcal{S}_{1}|^{2s}|\\mathcal{S}_{2}|^{2s}X^{-k-\\varphi_{k}+\\varepsilon}.\\end{equation*}\r\n\\end{prop}\r\nAs experts will realise throughout the proof, one could obtain a similar result for the analogous Vinogradov generating function by using ideas of the proof of Theorem 5.2 of Vaughan \\cite{Vau}. We have ommited such analysis for the clarity of the exposition.\r\n\\begin{proof}\r\nFor every $m\\in\\mathcal{S}_{2}$ consider $\\gamma(m)=(\\gamma_{1}(m),\\ldots,\\gamma_{k-1}(m))$, where the entries taken are\r\n\\begin{equation}\\label{ec1.33}\\gamma_{j}(m)=\\alpha\\binom{k}{j}m^{k-j},\\ \\ \\ \\ \\ \\ (1\\leq j\\leq k-1).\\end{equation}\r\nObserve that then for every $x\\in\\mathcal{S}_{1}$ one obtains the relation\r\n\\begin{equation*} \\alpha(x+m)^{k}=\\bfnu^{(k-1)}(x)\\cdot \\gamma(m)+\\alpha x^{k}+\\alpha m^{k},\\end{equation*} where we adopted the notation $\\bfnu^{(k-1)}(x)=(x,\\ldots,x^{k-1}).$ It is also convenient to define for $s\\in\\mathbb{N}$ the set of $(k-1)$-tuples of natural numbers\r\n$$\\mathcal{N}=\\Big\\{(n_{1},\\ldots,n_{k-1}):\\ \\ 1\\leq n_{i}\\leq sX^{i},\\ \\ (1\\leq i\\leq k-1)\\Big\\}.$$\r\nBy using the above relation we find that\r\n\\begin{equation}\\label{ec2.8}\\sum_{m\\in\\mathcal{S}_{2}}\\lvert f_{m}(\\alpha)\\rvert^{2s}=\\sum_{m\\in\\mathcal{S}_{2}}\\Big\\lvert\\sum_{\\bfn\\in\\mathcal{N}}a(\\bfn)e\\big(\\bfn\\cdot\\gamma(m)\\big)\\Big\\rvert^{2},\\end{equation}\r\nwhere on denoting\r\n$$\\mathcal{X}(\\bfn)=\\Big\\{\\mathbf{x}\\in\\mathcal{S}_{1}^{s}:\\ x_{1}^{i}+\\ldots+x_{s}^{i}=n_{i}, \\ \\ \\ (1\\leq i\\leq k-1)\\Big\\}$$ the coefficient $a(\\bfn)$ is defined as \r\n\\begin{equation}\\label{a(n}a(\\bfn)=\\sum_{\\mathbf{x}\\in \\mathcal{X}(\\bfn)}e\\big(\\alpha(x_{1}^{k}+\\ldots+x_{s}^{k})\\big).\\end{equation}\r\n\r\nWe devote the rest of the proof to apply a version of the large sieve inequality (Lemma 5.3 of Vaughan \\cite{Vau}) to the right side of (\\ref{ec2.8}). For such purpose, we shall consider the spacing modulo $1$ of $\\{\\gamma(m)\\}_{m}.$ Take $x,y\\in\\mathcal{S}_{2}$ with $x\\neq y$. Note that in view of (\\ref{C1}) then one has\\begin{equation}\\label{z}x,y\\leq X/2k.\\end{equation} Observe that applying Dirichlet's approximation to each $\\alpha\\in\\grm$ we obtain $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ such that $0\\leq a\\leq q$ and $$\\lvert \\alpha-a/q\\rvert \\leq q^{-1}X^{1-k},$$ where $X<q\\leq X^{k-1}.$ Note as well that by the choice of $\\gamma_{j}(m)$ in (\\ref{ec1.33}) we find that\r\n$$\\|k\\alpha(x-y)\\|=\\|\\gamma_{k-1}(x)-\\gamma_{k-1}(y)\\|.$$\r\nThen by the above discussion we obtain the lower bound\r\n$$\\|k\\alpha(x-y)\\|\\geq \\|ka(x-y)/q\\|-(2q)^{-1}X^{2-k}.$$\r\nNote that the only instance in which the first term on the right-hand side of the above equation can be $0$ is when $y=x+nq(q,k)^{-1}$ for some $n\\in\\mathbb{N}$ with $n\\neq 0$. However, $q(q,k)^{-1}\\geq X/k,$ which would contradict (\\ref{z}). Therefore, by the preceding discussion we get\r\n$$\\|k\\alpha(x-y)\\|\\geq (2q)^{-1},$$which delivers\r\n$\\| \\gamma_{k-1}(x)-\\gamma_{k-1}(y)\\|\\gg X^{-k+1}$ and provides the spacing condition that we were seeking to prove.\r\n\r\nApplying Lemma 5.3 of Vaughan \\cite{Vau} to (\\ref{ec2.8}) we obtain the upper bound\r\n\\begin{equation}\\label{minstr}\\sum_{m\\in\\mathcal{S}_{2}}\\lvert f_{m}(\\alpha)\\rvert^{2s}\\ll X^{k(k-1)/2}\\sum_{\\bfn\\in\\mathcal{N}}|a(\\bfn)|^{2}.\\end{equation} Note first that by bounding the coefficients $a(\\bfn)$ trivially one gets\r\n$$\\sum_{m\\in\\mathcal{S}_{2}}\\lvert f_{m}(\\alpha)\\rvert^{2s}\\ll X^{k(k-1)/2}J_{s,t_{1}}^{(k-1)}(P_{1}),$$\r\nwhere $J_{s,t_{1}}^{(k-1)}(P_{1})$ was defined in (\\ref{ec2.9}). Then combining the above equation with an application of Cauchy's inequality we obtain\r\n\\begin{equation}\\label{Falphat}\\mathcal{F}(\\alpha)^{2s}\\ll |\\mathcal{S}_{2}|^{2s-1}\\sum_{m\\in\\mathcal{S}_{2}}\\lvert f_{m}(\\alpha)\\rvert^{2s} \\ll |\\mathcal{S}_{2}|^{2s-1}X^{k(k-1)/2}J_{s,t_{1}}^{(k-1)}(P_{1}),\\end{equation} and hence for $s\\geq k(k-1)/2$ then Proposition \\ref{prop1} delivers\r\n$$\\mathcal{F}(\\alpha)\\ll |\\mathcal{S}_{1}||\\mathcal{S}_{2}|\\big(X^{\\delta_{t_{1}}k(k-1)/2}|\\mathcal{S}_{2}|^{-1}\\big)^{1/2s}X^{\\varepsilon}.$$ Therefore, fixing $s=k(k-1)/2$ and recalling (\\ref{1.1}) one gets\r\n\\begin{align*}\\mathcal{F}(\\alpha)&\r\n\\ll|\\mathcal{S}_{1}||\\mathcal{S}_{2}|X^{-\\varphi_{k-1}/k(k-1)+\\varepsilon},\r\n\\end{align*} where $\\varphi_{k-1}$ was defined in (\\ref{varphi}). \r\n\r\nFor the second claim of the proposition we combine (\\ref{minstr}) and Cauchy's inequality in the same way as in (\\ref{Falphat}) and we integrate over $\\grm$ to get\r\n$$\\int_{\\grm}\\lvert\\mathcal{F}(\\alpha)\\rvert^{2s}d\\alpha\\ll |\\mathcal{S}_{2}|^{2s-1}X^{k(k-1)/2}J_{s,t_{1}}^{(k)}(P_{1}).$$An application of Proposition \\ref{prop1} and the estimate (\\ref{1.1}) to the above line then yields, for $s\\geq k(k+1)/2$, the bound\r\n $$\\int_{\\grm}\\lvert\\mathcal{F}(\\alpha)\\rvert^{2s}d\\alpha\\ll |\\mathcal{S}_{1}|^{2s}||\\mathcal{S}_{2}|^{2s}X^{-k-\\varphi_{k}+\\varepsilon},$$from where the second part of the proposition follows.\r\n\\end{proof}\r\nObserve that the argument just makes use of the fact that $\\mathcal{T}_{t}=\\mathcal{T}_{t_{1}}+\\mathcal{T}_{l}$, where \r\n$\\lvert\\mathcal{T}_{t_{1}}\\cap [1,N]\\rvert$ and $\\lvert\\mathcal{T}_{l}\\cap [1,N]\\rvert$ are appropriately large. Therefore, it could also be applied to other problems for sets with a similar property that don't necessarily have a polynomial structure. We conclude the investigation of the minor arcs by applying Weyl differencing to derive a bound for the exponential sum \\begin{equation}\\label{fte}f(\\alpha)=\\sum_{T_{t}(\\mathbf{z})\\leq P^{l}}e(\\alpha T_{t}(\\mathbf{z})^{k}),\\end{equation} where in the above sum $z\\in\\mathbb{N}^{t}$. For ease of notation, we avoid writing the dependance on $t$. Note that then one can rewrite $f(\\alpha)$ as \r\n\\begin{equation}\\label{f(alpha)}\r\nf(\\alpha)=\\sum_{\\substack{\\mathbf{x}\\in\\mathbb{N}^{t-1}\\\\ P_{\\mathbf{x}}\\geq 1}}f_{\\mathbf{x}}(\\alpha),\\ \\ \\ \\ \\ \\ \\ \\text{where}\\ f_{\\mathbf{x}}(\\alpha)=\\sum_{1\\leq x\\leq P_{\\mathbf{x}}}e\\big(\\alpha T(\\mathbf{x},x)^{k}\\big)\\end{equation} and where we took the parameter $P_{\\mathbf{x}}=\\big(P^{l}-T_{t-1}(\\mathbf{x})\\big)^{1/l}.$\r\n\\begin{lem}\\label{lem2} Let $\\alpha\\in [0,1)$ and suppose that there exist $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ such that $(a,q)=1$ and $\\lvert \\alpha-a/q\\rvert\\leq q^{-2}.$ Then\r\n\\begin{equation*} f(\\alpha) \\ll P^{t+\\varepsilon}(q^{-1}+P^{-1}+qP^{-kl})^{2^{1-kl}}.\r\n\\end{equation*}\r\n\\end{lem}\r\n\\begin{proof}\r\nObserve that the polynomial $T(\\bfx,x)$ is monic and of degree $kl$ on $x$. Note that the implicit constant in Weyl's inequality (Vaughan \\cite[Lemma 2.4]{Vau}) does not depend on the coefficients which are not the leading one. Therefore, an application of such inequality to $f_{\\bfx}(\\alpha)$ delivers\r\n$$f_{\\bfx}(\\alpha)\\ll P_{\\mathbf{x}}^{1+\\varepsilon}\\big(q^{-1}+P_{\\mathbf{x}}^{-1}+qP_{\\mathbf{x}}^{-kl}\\big)^{2^{1-kl}},$$ which yields the above estimate by combining the bound $P_{\\mathbf{x}}\\leq P$ and (\\ref{f(alpha)}).\r\n\\end{proof}\r\n\r\n\\section{Singular series}\\label{sec3}\r\nThroughout this section we will always assume that $t\\geq 2l.$ Define for $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1$ the complete exponential sums\r\n\\begin{equation}\\label{S(q,a)}S(q,a)=\\sum_{1\\leq\\mathbf{r}\\leq q}e_{q}\\big(aT(\\mathbf{r})^{k}\\big)\\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ S_{k}(q,a)=\\sum_{r=1}^{q}e_{q}(ar^{k}).\\end{equation}Note that by orthogonality we can express $S(q,a)$ as\r\n$$S(q,a)=q^{-1}\\sum_{u=1}^{q}S_{l}(q,u)^{t}S_{k}(q,a,-u),\\ \\ \\ \\ \\ \\ \\ \\ \\text{where}\\ \\ S_{k}(q,a,-u)=\\sum_{r=1}^{q}e_{q}(ar^{k}-ur).$$ Because of the quasi-multiplicative structure of the exponential sum, we will focus on the case $q=p^{h}$, where $p$ is a prime number. Then, with the above notation one has that\r\n\\begin{equation}\\label{sing}S(p^{h},a)=p^{(t-1)h}S_{k}(p^{h},a)+E(p^{h},a),\\end{equation}\r\nwhere\r\n$$E(p^{h},a)=p^{-h}\\sum_{u=1}^{ p^{h}-1}S_{l}(p^{h},u)^{t}S_{k}(p^{h},a,-u).$$\r\nWe estimate $E(p^{h},a)$ by using classical estimates for the sums $S_{l}(p^{h},u)$ and $S_{k}(p^{h},a,-u)$. Applying then Theorems 4.2 and 7.1 of Vaughan \\cite{Vau} we obtain\r\n\\begin{align}\\label{ec3.2}E(p^{h},a)\\ll p^{-h/k+\\varepsilon}\\sum_{u=1}^{p^{h}-1}p^{th(1-1/l)}(u,p^{h})^{t/l}&\r\n\\ll p^{h(t-1/k-t/l+1)+\\varepsilon}\\sum_{d=0}^{h-1}p^{d(t/l-1)}\\nonumber\r\n\\\\\r\n&\\ll p^{ht-h/k-(t/l-1)+\\varepsilon}.\r\n\\end{align}\r\nIn order to provide more explicit bounds for the exponential sum $S(q,a)$ it is convenient to introduce first the multiplicative function $w_{k}(q)$ defined as \r\n$$w_{k}(p^{uk+v})=p^{-u-1}\\ \\ \\ \\ \\text{when $u\\geq 0$ and $2\\leq v\\leq k$},$$\r\n\\begin{equation*}w_{k}(p^{uk+v})=kp^{-u-1/2}\\ \\ \\ \\ \\text{when $u\\geq 0$ and $v=1$}.\\end{equation*} \r\nThen, by Lemma 3 of Vaughan \\cite{Vau1} we obtain \\begin{equation}\\label{putill}q^{-1}\\lvert S_{k}(q,a)\\rvert\\ll w_{k}(q),\\end{equation} \r\nwhence combining (\\ref{sing}) and (\\ref{ec3.2}) with the quasi-multiplicative property of $S(q,a)$ we get \\begin{equation}\\label{piu}q^{-t}\\lvert S(q,a)\\rvert \\ll w_{k}(q).\\end{equation}\r\nFor future purposes in the memoir, we note that by applying the definition of $w_{k}(q)$ and multiplicativity then we obtain for $Q>0$ and $s\\geq \\max(4,k+1)$ the bounds\r\n\\begin{equation}\\label{pri}\\sum_{q\\leq Q}w_{k}(q)^{2}\\leq \\prod_{p\\leq Q}\\big(1+C/p\\big)\\ll Q^{\\varepsilon},\\ \\ \\ \\ \\ \\ \\ \\ \\ \\sum_{q\\leq Q}qw_{k}(q)^{s}\\leq \\prod_{p\\leq Q}\\big(1+C/p\\big)\\ll Q^{\\varepsilon}.\r\n\\end{equation}\r\n\r\nBefore defining the singular series, we need to consider first the exponential sum\r\n\\begin{equation}\\label{WW}W(q,a)=\\sum_{\\substack{r=1\\\\ (r,q)=1}}^{q}e_{q}(a r^{k}),\\end{equation} where $a\\in\\mathbb{Z}$ and $q\\in\\mathbb{N}$ with $(a,q)=1.$ Here the reader might want to observe that one can express the sum $W(p^{h},a)$ in terms of $S_{k}(p^{h},a)$ and $S_{k}(p^{h-k},a)$, and hence one can deduce the estimate \r\n\\begin{equation}\\label{varp}\\varphi(q)^{-1}\\lvert W(q,a)\\rvert\\ll w_{k}(q)\\end{equation} by just applying multiplicativity and the bound (\\ref{putill}). In order to make further progress, it is worth defining\r\n\\begin{equation*}S_{n}(q)=\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big(q^{-t}S(q,a)\\big)^{s}\\big(q^{-1}S_{k}(q,a)\\big)^{2}\\big(\\varphi(q)^{-1}W(q,a)\\big)^{2}e_{q}(-an).\\end{equation*} \r\nWe also consider for convenience the series\r\n\\begin{equation}\\label{sigma}\\mathfrak{S}(n)=\\sum_{q=0}^{\\infty}S_{n}(q),\\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\sigma(p)=\\displaystyle\\sum_{h=0}^{\\infty} S_{n}(p^{h}),\\end{equation} where $p$ is a prime number. We can provide a more arithmetic description of $\\sigma(p)$ by defining the set \r\n$$\\mathcal{M}_{n}(p^{h})=\\Big\\{(\\mathbf{y},\\mathbf{X})\\in [1,p^{h}]^{4}\\times [1,p^{h}]^{st}: \\ p\\nmid y_{1}y_{2},\\ n\\equiv \\sum_{i=1}^{4}y_{i}^{k}+\\sum_{i=1}^{s}T(\\bfx_{i})^{k}\\pmod{p^{h}}\\Big\\}$$\r\nand considering the counting function $M_{n}(p^{h})=\\lvert\\mathcal{M}_{n}(p^{h})\\rvert$. For each prime $p$ take $\\tau\\geq 0$ such that $p^{\\tau}\\| k$ and \r\n\\begin{equation}\\label{gama}\\gamma=\\begin{cases}\\tau +1,&\\text{when $p>2$ or when $p=2$ and $\\tau=0$},\\\\ \\tau+2,& \\text{when $p=2$ and $\\tau>0$}.\\end{cases}\\end{equation}\r\n\r\n\r\n\r\n\r\n\\begin{lem}\\label{lem4.3}\r\nSuppose that $s+3\\geq \\frac{p}{p-1}\\big(k,p^{\\tau}(p-1)\\big)$ when $\\gamma=\\tau+1$, that $s+3\\geq 2^{\\tau+2}$ when $\\gamma=\\tau+2$ and $k>2$, and that $s\\geq 2$ when $p=k=2.$ Suppose as well that $t\\geq 4l.$ Then one has $M_{n}(p^{\\gamma})>0.$\r\n\\end{lem}\r\n\r\n\\begin{proof}\r\nIt is worth noting first that Lemma 2.15 of Vaughan \\cite{Vau} implies that $$T(\\mathbf{x})=x_{1}^{l}+\\dots+x_{t}^{l}\\equiv m\\pmod{p^{\\gamma}}$$ is soluble for all $m\\in\\mathbb{N}.$ \r\nThe result follows then using the previous remark and observing that under the conditions described above, the same lemma delivers a representation\r\n$$\\sum_{i=1}^{3}y_{i}^{k}+\\sum_{i=1}^{s}z_{i}^{k}\\equiv n\\pmod{p^{\\gamma}}$$with $p\\nmid y_{1}.$\r\n\\end{proof}\r\n\\begin{prop}\\label{prop3}\r\nLet $s\\geq \\max(1,k-2).$ Then one has that \\begin{equation}\\label{produ}\\mathfrak{S}(n)=\\prod_{p}\\sigma(p),\\end{equation} the singular series $\\mathfrak{S}(n)$ converges and $\\mathfrak{S}(n)\\ll 1.$ Also, for $Q>0$ we obtain the estimate\r\n\\begin{equation}\\label{qkes}\\sum_{q=1}^{Q}q^{1/k}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon}.\\end{equation}\r\nMoreover, if $s$ satisfies the conditions of Lemma \\ref{lem4.3} then $\\mathfrak{S}(n)\\gg 1$.\r\n\\end{prop}\r\n\\begin{proof}\r\nThe application of (\\ref{putill}), (\\ref{piu}) and (\\ref{varp}) delivers $S_{n}(p^{h})\\ll p^{h}w_{k}(p^{h})^{s+4},$ whence combining such bound with the definition of $w_{k}(q)$ we obtain the estimates\r\n\\begin{equation}\\label{piy}\\displaystyle\\sum_{h=1}^{\\infty}\\lvert S_{n}(p^{h})\\rvert\\ll p^{-3/2},\\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sum_{h=1}^{\\infty}p^{h/k}\\lvert S_{n}(p^{h})\\rvert\\ll p^{-1}.\\end{equation}Therefore, by the multiplicative property of $S_{n}(q)$ we get (\\ref{produ}) and $$\\sum_{q=1}^{Q}\\lvert S_{n}(q)\\rvert\\ll \\prod_{p\\leq Q}(1+Cp^{-3/2})\\ll 1,$$\r\nwhich delivers the upper bound for $\\mathfrak{S}(n)$. The estimate (\\ref{qkes}) follows in a similar way.\r\n\r\nObserve that expressing $S_{n}(p^{h})$ as the difference of two complete exponential sums and using orthogonality we get\r\n\\begin{equation}\\label{Snm}\\sum_{j=0}^{h}S_{n}(p^{j})=M_{n}(p^{h})p^{-h(st+1)}\\varphi(p^{h})^{-2}.\\end{equation} We use Lemma \\ref{lem4.3} and the fact that if $m$ with $(m,p)=1$ is a $k$-th power modulo $p^{\\gamma}$ then it is also a $k$-th power modulo $p^{h}$ for $h\\geq \\gamma$ to obtain the lower bound $M_{n}(p^{h})\\geq p^{(st+3)(h-\\gamma)}$. Combining such lower bound with the above expression and (\\ref{sigma}) we find that $\\sigma(p)\\geq p^{-\\gamma(st+3)}.$ Therefore, by the preceding discussion and equation (\\ref{piy}) we get $\\frak{S}(n)\\gg 1$.\r\n\\end{proof}\r\n\r\nWe next define an analogous singular series that arises in the analysis of the major arc contribution in Theorem \\ref{thm1.3}. This series will be in nature quite similar to $\\frak{S}(n)$, so we will skip some details for the sake of brevity. For such purposes, consider\r\n\\begin{equation}\\label{Sn'}S'_{n}(q)=\\sum_{\\substack{a=1\\\\ (a,q)=1}}^{q}\\big(q^{-t}S(q,a)\\big)^{s}e_{q}(-an).\\end{equation} \r\nObserve that using (\\ref{piu}) then we have\r\n\\begin{equation}\\label{appst}S'_{n}(p^{h})\\ll p^{h}w_{k}(p^{h})^{s}.\\end{equation}\r\nMoreover, for any prime $p$ and $h\\in\\mathbb{N}$ and combining (\\ref{sing}), (\\ref{ec3.2}), (\\ref{putill}) and (\\ref{piu}) we can rewrite $S'_{n}(p^{h})$ as\r\n\\begin{equation}\\label{apps}S_{n}'(p^{h})=\\sum_{\\substack{a=1\\\\ (a,p)=1}}^{p^{h}}\\big(p^{-h}S_{k}(p^{h},a)\\big)^{s}e_{p^{h}}(-an)+E(p^{h}),\\end{equation}\r\nwhere the first term is the analogous sum for the original Waring's problem and the error term satisfies $$E(p^{h})\\ll p^{h-h/k-(t/l-1)+\\varepsilon} w_{k}(p^{h})^{s-1}.$$ \r\n\r\nWe define next the aforementioned series\r\n\\begin{equation*}\\mathfrak{S}'(n)=\\sum_{q=0}^{\\infty}S'_{n}(q),\\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\sigma'(p)=\\displaystyle\\sum_{h=0}^{\\infty} S'_{n}(p^{h}),\\end{equation*} where $p$ is a prime number. We can provide a more arithmetic description of $\\sigma'(p)$ by considering the set \r\n$$\\mathcal{M}^{*}_{n}(p^{h})=\\Big\\{\\mathbf{X}\\in [1,p^{h}]^{st}: \\ p\\nmid x_{1,1},\\ p\\nmid T(\\mathbf{x}_{1}),\\ \\ n\\equiv \\sum_{i=1}^{s}T(\\bfx_{i})^{k}\\pmod{p^{h}}\\Big\\},$$ where $\\mathbf{x}_{1}=(x_{1,1},\\ldots, x_{1,t})$, and taking the counting function $M_{n}^{*}(p^{h})=\\lvert\\mathcal{M}_{n}^{*}(p^{h})\\rvert$. For each prime $p$ take $\\tau_{1}\\geq 0$ such that $p^{\\tau_{1}}\\| kl$ and $\\nu=\\nu(p)=2\\tau_{1}+1.$ Before stating the following lemma, recall (\\ref{gama}).\r\n\r\n\\begin{lem}\\label{lem4.45}\r\nSuppose that $s\\geq \\frac{p}{p-1}\\big(k,p^{\\tau}(p-1)\\big)$ when $\\gamma=\\tau+1$, that $s\\geq 2^{\\tau+2}$ when $\\gamma=\\tau+2$ and $k>2$, and that $s\\geq 5$ when $p=k=2.$ Suppose as well that $t\\geq 4l.$ Then one has $M_{n}^{*}(p^{\\nu})>0.$\r\n\\end{lem}\r\n\\begin{proof}\r\nIt is worth noting first that since $\\nu \\geq \\gamma$ then Lemma 2.15 of Vaughan \\cite{Vau} and the fact that if $b\\in\\mathbb{N}$ with $(b,p)=1$ is a $k$-th power modulo $p^{\\gamma}$ then it is also a $k$-th power modulo $p^{\\nu}$ imply that $$T(\\mathbf{x})=x_{1}^{l}+\\dots+x_{t}^{l}\\equiv m\\pmod{p^{\\nu}}$$ with $p\\nmid x_{1}$ is soluble for all $m\\in\\mathbb{N}.$ \r\nThe lemma follows using the previous remarks and observing that under the conditions described above, Lemma 2.15 of Vaughan \\cite{Vau} delivers a representation\r\n$$\\sum_{i=1}^{s}y_{i}^{k}\\equiv n\\pmod{p^{\\nu}}$$with $p\\nmid y_{1}.$\r\n\\end{proof}\r\n\\begin{prop}\\label{Prop4}\r\nLet $s\\geq \\max(5,k+2).$ Then one has that \\begin{equation*}\\label{prod}\\mathfrak{S}'(n)=\\prod_{p}\\sigma(p),\\end{equation*} the singular series $\\mathfrak{S}'(n)$ converges and $\\mathfrak{S}'(n)\\ll 1.$ Also, for $Q>0$ we obtain the estimate\r\n\\begin{equation}\\label{qkesqt}\\sum_{q=1}^{Q}q^{1/k}\\lvert S_{n}'(q)\\rvert\\ll Q^{\\varepsilon}.\\end{equation}\r\nMoreover, if $s$ satisfies the conditions of Lemma \\ref{lem4.45} then $\\mathfrak{S}'(n)\\gg 1$.\r\n\\end{prop}\r\n\\begin{proof}Equation (\\ref{appst}) and the multiplicativity of $w_{k}(q)$ yield\r\n\\begin{equation}\\label{piyi}\\displaystyle\\sum_{h=1}^{\\infty}\\lvert S_{n}'(p^{h})\\rvert\\ll p^{-3/2},\\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sum_{h=1}^{\\infty}p^{h/k}\\lvert S_{n}'(p^{h})\\rvert\\ll p^{-1},\\end{equation} which imply the convergence, the upper bound for the singular series and (\\ref{qkesqt}). For obtaining the lower bound for $\\frak{S}'(n)$ we observe that Lemma \\ref{lem4.45}, an application of Hensel's Lemma and the argument used to derive (\\ref{Snm}) allow one to obtain  $\\sigma'(p)\\geq p^{-\\nu(st-1)}$, whence combining such estimate with (\\ref{piyi}) we then get $\\frak{S}'(n)\\gg 1$.\r\n\\end{proof}\r\nScholars in the area will realise that one could use (\\ref{apps}) and the bounds available in the literature for the singular series in the original Waring's problem (see \\cite[Theorem 4.5]{Vau}) to obtain $\\mathfrak{S}'(n)\\gg 1$ for the range $s\\geq \\max(4,k+1)$. One could also deduce (\\ref{qkesqt}) but with an extra factor of $n^{\\varepsilon}$ in the right side of the bound for the same range (see \\cite[Lemma 4.8]{Vau}).\r\n\\section{Approximation of some exponential sum over the major arcs}\\label{sec4}\r\nIn this section we approximate $f(\\alpha)$ on the major arcs by some auxiliary function. For such purpose it is convenient to introduce first some notation. Let $\\alpha\\in [0,1)$ and $a\\in\\mathbb{Z}$, $q\\in\\mathbb{N}$ with $(a,q)=1$. Denote $\\beta=\\alpha-a/q$ and consider the aforementioned function $U(\\alpha,q,a)=c_{t,l}q^{-t}S(q,a)u(\\beta)$, where\r\n\\begin{equation}\\label{Ualp}u(\\beta)=k^{-1}\\sum_{m=1}^{n}m^{t/kl-1}e(\\beta m),\\ \\ \\ \\  \\ \\ \\ \\ c_{t,l}=\\Gamma(1+1/l)^{t}\\Gamma(t/l)^{-1},\\end{equation} and $S(q,a)$ was defined in (\\ref{S(q,a)}). \r\n\\begin{prop}\\label{prop200}\r\nLet $q<P$ and $\\alpha,a,q,\\beta$ as above. Then one has\r\n$$f(\\alpha)=U(\\alpha,q,a)+O\\big(qP^{t-1}(1+n\\lvert\\beta\\rvert)\\big).$$\r\n\\end{prop}\r\n\\begin{proof}\r\nBefore embarking on our task, it is convenient to consider for each $\\mathbf{r}\\in\\mathbb{N}^{t}$ and $r\\in\\mathbb{N}$ the sums\r\n \\begin{equation*}K_{\\mathbf{r}}(\\beta)=\\displaystyle\\sum_{\\substack{T(\\mathbf{x})\\leq P^{l}\\\\ \\mathbf{x}\\equiv\\mathbf{r}\\pmod{q}}}e\\big(\\beta T(\\mathbf{x})^{k}\\big),\\ \\ \\ \\ \\ \\ \\ B_{r}(x)=\\displaystyle\\sum_{\\substack{0<z\\leq x\\\\ z\\equiv r\\pmod{q}}}1.\\end{equation*} Observe that by sorting the summation into arithmetic progressions modulo $q$ we find that\r\n\\begin{equation}\\label{halpa}\r\nf(\\alpha)=\\sum_{\\mathbf{r}\\leq q}e_{q}\\big(aT(\\mathbf{r})^{k}\\big)K_{\\mathbf{r}}(\\beta).\r\n\\end{equation} \r\nFor each $\\mathbf{r}\\in\\mathbb{N}^{t}$ write $\\mathbf{r}=(\\mathbf{r}_{t-1},r_{t}),$ where $\\mathbf{r}_{t-1}\\in\\mathbb{N}^{t-1}$. Then recalling the definition of $P_{\\mathbf{x}}$ after (\\ref{f(alpha)}) and using Abel's summation formula we find that\r\n\\begin{align*}\r\nK_{\\mathbf{r}}(\\beta)=&\r\n\\sum_{\\mathbf{x}}B_{r_{t}}(P_{\\mathbf{x}})e\\big(\\beta T(\\mathbf{x},P_{\\mathbf{x}})^{k}\\big)-\\sum_{\\mathbf{x}}\\int_{0}^{P_{\\mathbf{x}}}\\frac{\\partial }{\\partial z}e\\big(\\beta T(\\mathbf{x},z)^{k}\\big)B_{r_{t}}(z)dz,\r\n\\end{align*}\r\nwhere $\\mathbf{x}\\in\\mathbb{N}^{t-1}$ runs over tuples satisfying $T_{t-1}(\\mathbf{x})\\leq P^{l}-1$ and $\\mathbf{x}\\equiv \\mathbf{r}_{t-1}\\mmod{q}$. Consequently, combining the formula $B_{r_{t}}(x)=x/q+O(1)$ and an application of integration by parts one gets\r\n\\begin{equation*}K_{\\mathbf{r}}(\\beta)= q^{-1}\\sum_{\\mathbf{x}}\\int_{0}^{P_{\\mathbf{x}}}e\\big(\\beta T(\\mathbf{x},z)^{k}\\big)dz+O\\big(q^{-t+1}P^{t-1}(1+n\\lvert\\beta\\rvert)\\big).\\end{equation*} We have included a brief discussion of the next step in the argument since it involves a technical detail which was not required before. Note first that Abel's summation formula combined with the above equation yields\r\n\\begin{align*}K_{\\mathbf{r}}(\\beta)= q^{-1}\\sum_{\\mathbf{x}}B_{r_{t-1}}(P_{(\\mathbf{x},0)})I(P_{(\\mathbf{x},0)})\r\n&-q^{-1}\\sum_{\\mathbf{x}}\\int_{0}^{P_{(\\mathbf{x},0)}}\\frac{\\partial I}{\\partial z_{t-1}}(z_{t-1})B_{r_{t-1}}(z_{t-1})dz_{t-1}\r\n\\\\\r\n&+O\\big(q^{-t+1}P^{t-1}(1+n\\lvert\\beta\\rvert)\\big),\r\n\\end{align*}\r\nwhere $\\mathbf{x}\\in\\mathbb{N}^{t-2}$ runs over tuples satisfying $T_{t-2}(\\mathbf{x})\\leq P^{l}$ with $\\mathbf{x}\\equiv \\mathbf{r}_{t-2}\\mmod{q}$ and $$I(z_{t-1})=\\int_{0}^{P_{\\mathbf{x},z_{t-1}}}e\\big(\\beta T(\\mathbf{x},z_{t-1},z_{t})^{k}\\big)dz_{t}.$$ Observe that combining the Fundamental Theorem of Calculus and the exchangeability of derivation and integration we find that $$\\frac{\\partial}{\\partial z_{t-1}}I(z_{t-1})\\ll \\frac{\\partial}{\\partial z_{t-1}}P_{\\mathbf{x},z_{t-1}}+n\\lvert\\beta\\rvert,$$whence another combination of the formula $B_{r_{t-1}}(x)=x/q+O(1)$ and integration by parts yields\r\n\\begin{equation*}K_{\\mathbf{r}}(\\beta)= q^{-2}\\sum_{\\mathbf{x}}\\int_{\\mathcal{C}}e\\big(\\beta T(\\mathbf{x},z_{t-1},z_{t})^{k}\\big)dz_{t-1}dz_{t}+O\\big(q^{-t+1}P^{t-1}(1+n\\lvert\\beta\\rvert)\\big),\\end{equation*}\r\nwhere $\\mathcal{C}$ is the set of pairs $(z_{t-1},z_{t})\\in\\mathbb{R}_{+}^{2}$ satisfying $T(\\mathbf{x},z_{t-1},z_{t})\\leq P^{l}$. We repeat a similar argument for the rest of the variables to obtain\r\n\\begin{equation}\\label{krb}K_{\\mathbf{r}}(\\beta)=q^{-t}u_{1}(\\beta)+O\\big(q^{-t+1}P^{t-1}(1+n\\lvert\\beta\\rvert)\\big),\\end{equation} where $u_{1}(\\beta)$ here denotes the integral version of $u(\\beta)$, which we define by\r\n$$u_{1}(\\beta)=\\int_{T(\\mathbf{x})\\leq P^{l}}e\\big(\\beta T(\\mathbf{x})^{k}\\big)d\\mathbf{x},$$\r\nwhere $\\mathbf{x}\\in\\mathbb{R}_{+}^{t}.$ Observe that by several changes of variables, one can rewrite $u_{1}(\\beta)$ as\r\n$$u_{1}(\\beta)=k^{-1}l^{-t}\\int_{0}^{n}w^{1/k-1}e(\\beta w)\\int_{\\mathbf{X}\\in \\mathcal{M}}B(w,\\mathbf{X})d\\mathbf{X}dw,$$ with $B(w,\\mathbf{X})=x_{1}^{1/l-1}\\cdots x_{t-1}^{1/l-1}(w^{1/k}-x_{1}-\\ldots-x_{t-1})^{1/l-1}$ and $\\mathcal{M}\\subset \\mathbb{R}^{t-1}$ is the corresponding set determined by the underlying inequalities. Consequently, combining the formula for the Euler-Beta function and subsequent changes of variables we get\r\n$$u_{1}(\\beta)=c_{t,l}u_{2}(\\beta),\\ \\ \\ \\ \\ \\text{where}\\ u_{2}(\\beta)=k^{-1}\\int_{0}^{n}w^{t/kl-1}e(\\beta w)dw.$$\r\n\r\nWe devote the rest of the proof to compute the error term when we approximate $u_{2}(\\beta)$ by $u(\\beta)$. We believe that working with $u(\\beta)$ instead makes the analysis a bit more transparent and less tedious. Consider the function $$G(\\gamma)=\\sum_{1\\leq y\\leq \\gamma}y^{t/kl-1}$$ and note that the Euler-Maclaurin formula (see Vaughan \\cite[(4.8)]{Vau}) yields \r\n$$G(\\gamma)=klt^{-1}\\gamma^{t/kl}+O\\big(Z(\\gamma)\\big),$$ where $Z(\\gamma)=1+\\gamma^{t/kl-1}.$ Observe that then Abel's summation formula, integration by parts and the previous discussion yield \r\n\\begin{align*}u(\\beta)&\r\n=lt^{-1}n^{t/kl}e(\\beta n)-2\\pi i \\beta\\int_{0}^{n}lt^{-1}\\gamma^{t/kl}e(\\beta\\gamma)d\\gamma+O\\big(Z(n)(1+n\\lvert\\beta\\rvert)\\big)\r\n\\\\\r\n&=u_{2}(\\beta)+O\\big(Z(n)(1+n\\lvert\\beta\\rvert)\\big).\r\n\\end{align*}\r\nThe lemma then follows combining the above approximation with (\\ref{halpa}) and (\\ref{krb}).\r\n\\end{proof}\r\nNote that the error term in the above proposition differs from the trivial bound by a factor of $Pq^{-1}(1+n\\vert\\beta\\rvert)^{-1}$, and this saving is gained by fixing $t-1$ variables in the expression for $K_{\\mathbf{r}}(\\beta)$ and using a one-dimensional argument. The saving obtained in Proposition \\ref{prop200}, however, is not enough for our choice of the major arcs when $l$ is large enough. Likewise, the possible approaches involving the use of all of the variables don't seem to improve the error term substantially. We devote the rest of the section to provide an upper bound for $u(\\beta).$\r\n\r\n\\begin{lem}\\label{lem4.1}\r\nLet $\\lvert\\beta\\rvert\\leq 1/2.$ Then one has\r\n$$u(\\beta)\\ll \\frac{P^{t}}{(1+n\\lvert\\beta\\rvert)^{\\gamma_{k,l}}},$$\r\nwhere $\\gamma_{k,l}=\\min(1,t/kl).$\r\n\\end{lem}\r\n\\begin{proof}\r\nWhen $\\lvert\\beta\\rvert\\leq n^{-1}$ one finds that\r\n$$u(\\beta)\\ll \\sum_{m=1}^{n}m^{t/kl-1}\\ll P^{t},$$ which yields the required bound for that particular range. When $\\lvert\\beta\\rvert> n^{-1}$ then denoting $M=\\lfloor\\lvert\\beta\\rvert^{-1}\\rfloor$, we observe that $$\\sum_{m=1}^{M}m^{t/kl-1}e(\\beta m)\\ll \\lvert\\beta\\rvert^{-t/kl}.$$ For the remaining range we combine partial summation and the monotonicity of $m^{t/kl-1}$ to obtain \r\n$$\\sum_{m>M}^{n}m^{t/kl-1}e(\\beta m)\\ll \\lvert\\beta\\rvert^{-1}\\big(\\lvert\\beta\\rvert^{1-t/kl}+n^{t/kl-1}\\big)=\\lvert\\beta\\rvert^{-t/kl}+P^{t}\\lvert\\beta\\rvert^{-1}n^{-1},$$ which delivers the required estimate.\r\n\\end{proof}\r\n\r\n\\section{Treatment of the major arcs and proof of the main theorem}\\label{sec5}\r\nIn this section we prune back to the narrower set $\\grP$ of major arcs and deduce an asymptotic formula for the contribution of such set. In view of the weak bound obtained in Proposition \\ref{prop200} and the discussion made after it we are forced to introduce $k$-th powers of natural numbers and prime numbers, whose behaviour is much better understood, to provide strong enough estimates over $\\grM$. For such purposes, it is convenient to present first some notation. Let \\begin{equation*}X_{1}=2^{-1}(2k)^{-1/(k-1)}X.\\end{equation*}Consider the exponential sums\r\n$$g(\\alpha)=\\sum_{X_{1}< x\\leq 2X_{1}}e(\\alpha x^{k}),\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ h(\\alpha)=\\sum_{p\\leq X}e(\\alpha p^{k}),$$\r\nthe weighted sums\r\n\\begin{equation*}v(\\beta)=\\sum_{X_{1}^{k}< x\\leq (2X_{1})^{k}}k^{-1}x^{1/k-1}e(\\beta x),\\ \\ \\ \\ \\ \\ \\ w(\\beta)=\\sum_{2\\leq x\\leq n}k^{-1}x^{1/k-1}(\\log x)^{-1}e(\\beta x),\\end{equation*} and the functions\r\n$$V(\\alpha,q,a)=q^{-1}S_{k}(q,a)v(\\beta)\\ \\ \\ \\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ \\ \\  W(\\alpha,q,a)=\\varphi(q)^{-1}W(q,a)w(\\beta),$$ where $S_{k}(q,a)$ and $W(q,a)$ were defined in (\\ref{S(q,a)}) and (\\ref{WW}) respectively. For the sake of simplicity we further define the auxiliary functions \\begin{equation}\\label{f*}f^{*}(\\alpha)=U(\\alpha,q,a),\\ \\ \\ \\ \\ \\ \\ g^{*}(\\alpha)=V(\\alpha,q,a),\\ \\ \\ \\ \\ \\ \\ h^{*}(\\alpha)=W(\\alpha,q,a)\\end{equation} when $\\alpha\\in\\grM(a,q)\\subset \\grM$ and $f^{*}(\\alpha)=g^{*}(\\alpha)=h^{*}(\\alpha)=0$ for $\\alpha\\in\\grm.$ We recall for convenience that $U(\\alpha,q,a)$ was defined just before (\\ref{Ualp}). Before providing an asymptotic formula for the major arc contribution it is convenient to consider for any set $\\frak{B}\\subset [0,1)$ the integral\r\n$$R_{\\frak{B}}(n)=\\int_{\\frak{B}}f(\\alpha)^{s}g(\\alpha)^{2}h(\\alpha)^{2}e(-\\alpha n)d\\alpha,$$ and to define the singular integral as\r\n$$J(n)=\\int_{0}^{1}u(\\beta)^{s}v(\\beta)^{2}w(\\beta)^{2}e(-\\beta n)d\\beta.$$ Here the reader might want to observe that as a consequence of orthogonality then $J(n)$ equals\r\n$$\\sum_{x_{1},\\dots,x_{4},y_{1},\\dots,y_{s}}k^{-4-s}(x_{1}x_{2}x_{3}x_{4})^{1/k-1}\\big(\\log x_{3}\\log x_{4}\\big)^{-1}y_{1}^{t/kl-1}\\cdots y_{s}^{t/kl-1},$$\r\nwhere the sum is over $x_{1},\\ldots,x_{4},y_{1},\\ldots,y_{s}$ satisfying $x_{1}+\\ldots+x_{4}+y_{1}+\\ldots+y_{s}=n$ with\r\n$$X_{1}^{k}<x_{1},x_{2}\\leq (2X_{1})^{k},\\ \\ \\ \\ \\ \\ \\ 2\\leq x_{3},x_{4}\\leq n\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\ 1\\leq y_{j}\\leq n\\ \\ \\ \\ \\ (1\\leq j\\leq s).$$\r\nIt is worth observing that then one obtains the lower bound \\begin{equation}\\label{JNN}J(n)\\gg P^{st}X^{4}n^{-1}(\\log n)^{-2}.\\end{equation}\r\n\\begin{prop}\\label{prop55} Let $s\\geq \\max(1,k-2).$ One has that\r\n\\begin{equation}\\label{Rma}R_{\\grM}(n)=\\frak{S}(n)J(n)+O\\big(P^{st}X^{4}n^{-1}(\\log n)^{-2-\\delta}\\big).\\end{equation} Moreover, if $s$ satisfies the hypothesis of Lemma \\ref{lem4.3} then $R_{\\grM}(n)\\gg P^{st}X^{4}n^{-1}(\\log n)^{-2}.$\r\n\\end{prop}\r\n\\begin{proof}\r\nObserve that Lemma 6.1 of Vaughan \\cite{Vau} for the choice of $X_{1}$ made yields that whenever $\\alpha\\in\\grM$ then\r\n\\begin{equation}\\label{pro}g(\\alpha)-g^{*}(\\alpha)\\ll q^{1/2+\\varepsilon}.\\end{equation} \r\nLikewise, Lemma 6.2 of Vaughan \\cite{Vau} delivers the bound $v(\\beta)\\ll X(1+n\\lvert\\beta\\rvert)^{-1}$, whence combining such estimate with (\\ref{putill}) we get \\begin{equation}\\label{ges} g^{*}(\\alpha)\\ll w_{k}(q)X(1+n\\lvert\\beta\\rvert)^{-1}.\\end{equation}\r\nIt is also worth noting that for any $q\\leq X$, the number $N(q)$ of pairs of primes $(p_{1},p_{2})$ with $p_{1}^{k}\\equiv p_{2}^{k}\\pmod{q}$ and $p_{1},p_{2}\\leq X$ satisfies $N(q)\\ll X^{2}(\\log X)^{-2}q^{-1+\\varepsilon}.$ Consequently, by orthogonality we find that\r\n\\begin{equation}\\label{orti}\\sum_{a=1}^{q}\\lvert h(a/q+\\beta)\\rvert^{2}\\ll X^{2}(\\log X)^{-2}q^{\\varepsilon}.\\end{equation}\r\nCombining the previous discussion with Lemma \\ref{lem2} we obtain\r\n\\begin{align*}R_{\\grM\\setminus \\grN}(n)\\ll P^{st-2^{-lk}+\\varepsilon}X^{4}n^{-1}\\big(1+\\sum_{q\\leq X}w_{k}(q)^{2}\\big)\\ll P^{st-\\delta}X^{4}n^{-1},\r\n\\end{align*}\r\nwhere in the last step we applied (\\ref{pri}). The reader might want to observe that the bounds available for the exponential sums of $k$-th powers are robust enough to enable us to prune back to a set of narrower major arcs. It becomes transparent that in view of the weak estimates for $f(\\alpha)$ available when $\\alpha\\in\\grM\\setminus \\grN$, the use of such Weyl sums in this setting seems inevitable. Before moving on, it is convenient to observe that whenever $\\alpha\\in\\grN$ then equations (\\ref{piu}), (\\ref{Ualp}) and Proposition \\ref{prop200} deliver $f(\\alpha)\\ll w_{k}(q)P^{t}$. Likewise, observe that (\\ref{pro}) and (\\ref{ges}) yield the estimate $g(\\alpha)\\ll w_{k}(q)X(1+n\\lvert\\beta\\rvert)^{-1}$ for the same range. Consequently, combining the previous discussion with (\\ref{pri}) and (\\ref{orti}) we obtain\r\n\\begin{align*}R_{\\grN\\setminus\\grP}(n)\\nonumber\r\n&\\ll P^{st}X^{4}n^{-1}(\\log P)^{-2}\\big((\\log P)^{-1}\\sum_{q\\leq \\log P}q^{1+\\varepsilon}w_{k}(q)^{s+2}+\\sum_{q>\\log P}w_{k}(q)^{s+2}\\big)\r\n\\\\\r\n&\\ll P^{st}X^{4}n^{-1}(\\log P)^{-2-\\delta}.\r\n\\end{align*}\r\n\r\nIn order to make further progress in the analysis, we note that \r\n\\begin{equation*}\\label{hes}h(\\alpha)=W(\\alpha,q,a)+O(Xe^{-C_{1}\\sqrt{\\log X}})\\end{equation*} for some $C_{1}>0$, which is an immediate consequence of Lemma 7.15 of Hua \\cite{Hua2}. Observe as well that Proposition \\ref{prop200} delivers $f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\ll P^{st-1+\\varepsilon}$ whenever $\\alpha\\in\\grP$. Combining these estimates with (\\ref{pro}) we find that\r\n$$\\int_{\\grP} \\big\\lvert f(\\alpha)^{s} g(\\alpha)^{2}h(\\alpha)^{2}-f^{*}(\\alpha)^{s} g^{*}(\\alpha)^{2}h^{*}(\\alpha)^{2}\\big\\rvert d\\alpha\\ll P^{st}X^{4}n^{-1}e^{-C\\sqrt{\\log X}}.$$\r\nObserve as well that (\\ref{qkes}) and the estimate for $v(\\beta)$ stated before (\\ref{ges}) deliver the bounds\r\n$$\\sum_{q>Q}\\lvert S_{n}(q)\\rvert\\ll Q^{\\varepsilon-1/k},\\ \\ \\ \\ \\ \\int_{\\lvert\\beta\\rvert>(\\log P)q^{-1}n^{-1}}\\lvert v(\\beta)\\rvert^{2} d\\beta\\ll X^{2}n^{-1}q(\\log P)^{-1}$$ for any $Q>0$ and $q\\leq \\log P$ respectively. Consequently, the above estimates and a change of variables yield\r\n$$\\int_{\\grP}f^{*}(\\alpha)^{s}g^{*}(\\alpha)^{2}h^{*}(\\alpha)^{2}e(-\\alpha n)d\\alpha=\\frak{S}(n)J(n)+O\\big(P^{st}X^{4}n^{-1}(\\log P)^{-2-\\delta}\\big),$$whence the preceding discussion and the pruning bounds for $R_{\\grM\\setminus \\grN}(n)$ and $R_{\\grN\\setminus\\grP}(n)$ deliver the main result of the proposition. The second part of the proposition follows combining  (\\ref{JNN}) with (\\ref{Rma}) and Proposition \\ref{prop3}.\r\n\\end{proof}\r\nWe now gather all the work done previously to prove Theorem \\ref{thm1.2} by using the following quantitative version.\r\n\\begin{prop}\\label{propthm}\r\nLet $s\\geq 4k-3$ and $H=k(k+1).$ Then, one has the lower bound\r\n$$\\int_{0}^{1} \\mathcal{F}(\\alpha)^{H}f(\\alpha)^{s}g(\\alpha)^{2}h(\\alpha)^{2}e(-\\alpha n)d\\alpha\\gg |\\mathcal{S}_{1}|^{H}|\\mathcal{S}_{2}|^{H}P^{st}X^{4}n^{-1}(\\log n)^{-2}.$$\r\n\\end{prop}\r\n\\begin{proof}\r\nIt is worth observing that the estimate over the minor arcs on Proposition \\ref{prop22} and the trivial bounds for $f(\\alpha),$ $g(\\alpha)$ and $h(\\alpha)$ yield\r\n\\begin{equation}\\label{min}\\int_{\\grm} \\lvert\\mathcal{F}(\\alpha)\\rvert^{H}\\lvert f(\\alpha)\\rvert^{s}\\lvert g(\\alpha)\\rvert^{2}\\lvert h(\\alpha)\\rvert^{2}d\\alpha\\ll |\\mathcal{S}_{1}|^{H}|\\mathcal{S}_{2}|^{H}P^{st}X^{4}n^{-1-\\delta}\\end{equation} for some $\\delta>0$. In order to compute the major arc contribution it is convenient to define for each $m\\in\\mathbb{N}$ the counting function\r\n$$Q(m)=\\Big\\lvert \\Big\\{(\\mathbf{x},\\mathbf{y})\\in \\mathcal{S}_{1}^{H}\\times \\mathcal{S}_{2}^{H} :\\ \\ \\ m=\\sum_{i=1}^{H}(y_{i}+z_{i})^{k}\\Big\\}\\Big\\rvert.$$Observe that with the previous notation one finds that\r\n$$\\mathcal{F}(\\alpha)^{H}=\\sum_{m}Q(m)e(\\alpha m).$$ Moreover, using (\\ref{C1}), (\\ref{Pt}) and the definitions of $\\mathcal{S}_{1}$ and $\\mathcal{S}_{2}$ described after those equations we have $Q(m)=0$ for $m>n/2.$ Therefore, Proposition \\ref{prop55} yields\r\n\\begin{align}\\label{Ma}\\int_{\\grM} \\mathcal{F}(\\alpha)^{H}f(\\alpha)^{s}g(\\alpha)^{2}h(\\alpha)^{2}e(-\\alpha n)d\\alpha\r\n&=\\sum_{m\\leq n/2}Q(m)R_{\\grM}(n-m)\\nonumber\r\n\\\\\r\n&\\gg |\\mathcal{S}_{1}|^{H}|\\mathcal{S}_{2}|^{H} P^{st}X^{4}n^{-1}(\\log n)^{-2}.\r\n\\end{align}\r\nThe combination of the equations (\\ref{min}) and (\\ref{Ma}) concludes the proof. Here the reader might want to observe that the choices for $C_{1}$ and $C_{2}$ guarantee that we get the expected lower bound. \r\n\\end{proof}\r\n\r\n\\emph{Proof of Theorem \\ref{thm1.2}}. Note that the integral in Proposition \\ref{propthm} counts the number of solutions of equation (\\ref{conje}) with certain multiplicities. Consequently, for all $r\\geq 4$ we have\\begin{equation*}\\label{pytr}S_{C}(k,l,r)\\leq k(k+1)+4k-3,\\end{equation*}\r\nwhich delivers the same bound for $P_{C}(k,r)$ and yields $R_{C}(k)\\leq 4$. As experts will realise, we could have avoided including the extra $4k-3$ copies of $f(\\alpha)$ by introducing suitable weights for each of $x$ and $m$ in the definition of $\\mathcal{F}(\\alpha)$ to exploit the information given by such variables in the analysis of the singular series. However, we have prioritised the simplicity of the exposition over the preciseness of the upper bound for $P_{C}(k,r)$.\r\n\\section{The case $k=2$}\\label{sec6}\r\nWe briefly sketch the proof for $R_{4}(2)\\leq 2$. For the rest of the exposition then we take $t=4l$. Let $$g(\\alpha)=\\sum_{X/2<x\\leq X}e(\\alpha x^{2}),$$and on recalling (\\ref{falphap}) consider the mean value\r\n$$\\int_{0}^{1}\\lvert g(\\alpha)\\rvert^{2} \\lvert f(\\alpha,\\mathcal{S}_{t})\\rvert^{4}d\\alpha,$$which by orthogonality counts the solutions to the equation $$x_{1}^{2}+y_{1}^{2}+y_{2}^{2}=x_{2}^{2}+y_{3}^{2}+y_{4}^{2}$$with $X/2\\leq x_{i}\\leq X$ and $y_{i}\\in\\mathcal{S}_{t}$. Observe that by a divisor function argument, the number of solutions of $$y_{1}^{2}+y_{2}^{2}=y_{3}^{2}+y_{4}^{2}$$ is $O(n^{\\varepsilon}\\lvert\\mathcal{S}_{t}\\rvert^{2})$, and hence the contribution of the subset of solutions satisfying $x_{1}=x_{2}$ is $O(n^{1/2+\\varepsilon}\\lvert\\mathcal{S}_{t}\\rvert^{2})$. Likewise, the number of solutions of the above equation with $x_{1}\\neq x_{2}$ is $O(n^{\\varepsilon}\\lvert \\mathcal{S}_{t}\\rvert^{4})$, whence equation (\\ref{1.1}) and the above estimates deliver\r\n$$\\int_{0}^{1}\\lvert g(\\alpha)\\rvert^{2} \\lvert f(\\alpha,\\mathcal{S}_{t})\\rvert^{4}d\\alpha\\ll n^{1/2+\\varepsilon}\\lvert\\mathcal{S}_{t}\\rvert^{2}+n^{\\varepsilon}\\lvert \\mathcal{S}_{t}\\rvert^{4}\\ll n^{\\varepsilon}\\lvert \\mathcal{S}_{t}\\rvert^{4}.$$ Define $\\grM_{\\tau}=\\grM(P^{\\tau})$ and $\\grm_{\\tau}=[0,1)\\setminus \\grM_{\\tau}$ for some small enough $\\tau>0$. Then, combining the above estimate with Lemma \\ref{lem2} one gets\r\n$$\\int_{\\grm_{\\tau}}\\lvert f(\\alpha,\\mathcal{S}_{t})\\rvert^{4}\\lvert g(\\alpha)\\rvert^{2} \\lvert f(\\alpha)\\rvert^{3}d\\alpha\\ll \\lvert \\mathcal{S}_{t}\\rvert^{4}P^{3t-\\delta}.$$ \r\nThe reader might want to observe that in order to ensure local solubility and the convergence of the singular series, one should take $3$ copies of $f(\\alpha)$ instead of just $2$ since we only have two Weyl sums of degree $2$ available. The rest of the analysis of the major arcs is done using the estimates obtained throughout the memoir. This argument then yields $P_{4}(2,2)\\leq 7$. As experts will realise, one could prove the bound $P_{4}(2,2)\\leq 5$ by introducing suitable weights in the definition of $f(\\alpha,\\mathcal{S}_{t})$ to simplify the singular series analysis and just use one copy of $f(\\alpha)$. We have avoided discussing such refinement here for the sake of brevity.\r\n\\section{Proof of Theorem \\ref{thm1.3}}\\label{sec7}\r\nWe combine the work of previous sections with slightly different ideas employed in the minor arc analysis to give a proof of Theorem \\ref{thm1.3}. We first introduce an exponential sum restricted to elements in a convenient set that will provide the saving needed for the minor arc contribution. On recalling the parameter $\\xi_{0}(k,l)$ defined before Theorem \\ref{thm1.3}, we write $\\xi=\\xi_{0}(k,l)$ for ease of notation and consider $$\\xi_{1}=\\xi-1,\\ \\ \\ \\ \\ \\ C_{3}=\\big(2^{k+1}k(k+1)\\big)^{-1/kl}\\xi_{1}^{-1/l}.$$ Recalling (\\ref{Sr}) as well, take $P_{3}=C_{3}P$ and set $\\mathcal{S}=\\mathcal{S}_{\\xi_{1}}(P_{3})$. It is then convenient to consider for $P/2\\leq p\\leq P$ prime the exponential sums\r\n\\begin{equation*}f_{p}(\\alpha)=\\sum_{x\\in\\mathcal{S}}e\\big(\\alpha(x+p^{l})^{k}\\big)\\ \\ \\ \\ \\ \\ \\ \\  \\text{and}\\ \\ \\ \\ \\ \\ \\ \\mathcal{G}(\\alpha)=\\sum_{P/2<p\\leq P}f_{p}(\\alpha).\\end{equation*}\r\n\r\n\\begin{prop}\\label{prop223}\r\nLet $\\alpha\\in[0,1)$ and let $M>0$ be a parameter with $M\\leq P.$ Denote by $\\grm_{M}$ the set of $\\alpha$ with the property that $\\alpha=\\beta+a/q$ with $a\\in\\mathbb{Z},$ $q\\in\\mathbb{N}$ and $(a,q)=1$ satisfying $\\lvert\\beta\\rvert\\leq (2kqX)^{-1}$, $q\\leq 2kX$ and such that whenever $q\\leq M$ one has $\\lvert\\beta\\rvert\\geq Mq^{-1}n^{-1}.$ Then for each $\\alpha\\in\\grm_{M}$ one gets\r\n$$\\mathcal{G}(\\alpha)\\ll |\\mathcal{S}|P^{1+\\varepsilon}M^{-1/k(k-1)}X^{\\delta_{\\xi_{1}}/2},$$ where $\\delta_{\\xi_{1}}$ was defined in (\\ref{cono}). Moreover, for $s\\geq k(k+1)/2$ we obtain the mean value\r\n\\begin{equation*}\\int_{\\grm_{M}}\\lvert\\mathcal{G}(\\alpha)\\rvert^{2s}d\\alpha\\ll |\\mathcal{S}|^{2s}P^{2s}M^{-1}X^{-k+\\Delta_{\\xi_{1}}+\\varepsilon},\\end{equation*}where $\\Delta_{\\xi_{1}}=\\delta_{\\xi_{1}}k(k+1)/2.$\r\n\\end{prop}\r\n\\begin{proof}\r\nRecalling the notation used in the proof of Proposition \\ref{prop22} we find that\r\n\\begin{equation*}\\sum_{P/2< p\\leq P}\\lvert f_{p}(\\alpha)\\rvert^{2s}=\\sum_{P/2< p\\leq P}\\Big\\lvert\\sum_{\\bfn\\in\\mathcal{N}}a(\\bfn)e\\big(\\bfn\\cdot\\gamma(p^{l})\\big)\\Big\\rvert^{2},\\end{equation*}\r\nwhere $\\mathcal{N}$ here denotes the set\r\n$$\\mathcal{X}(\\bfn)=\\Big\\{\\mathbf{x}\\in\\mathcal{S}^{s}:\\ x_{1}^{i}+\\ldots+x_{s}^{i}=n_{i}\\ (1\\leq i\\leq k-1)\\Big\\}$$ and the coefficient $a(\\bfn)$ is defined in the same way as in (\\ref{a(n}). Let $q_{1}=q(q,k)^{-1}.$ Before going into the discussion for the spacing modulo $1$ of $\\{\\gamma(p^{l})\\}_{p}$, the reader might find useful to observe that for fixed $h\\in\\mathbb{Z}$ with $(h,q_{1})=1$, the number of solutions $L$ of the congruence $$x^{l}\\equiv h\\mmod{q_{1}}$$ satisfies $L\\ll q_{1}^{\\varepsilon}.$ Therefore, we can partition the primes into $L$ classes $\\mathcal{P}_{j}$ such that for any pair of distinct primes $p_{1},p_{2}\\in\\mathcal{P}_{j}$ with $p_{1}^{l}\\equiv p_{2}^{l}\\mmod{q_{1}}$ then $p_{1}\\equiv p_{2}\\mmod{q_{1}}.$\r\n\r\nNext observe that by the choice of $\\gamma(p^{l})$ made in (\\ref{ec1.33}) we find that \r\n$$\\|k\\alpha(p_{1}^{l}-p_{2}^{l})\\|=\\|\\gamma_{k-1}(p_{1}^{l})-\\gamma_{k-1}(p_{2}^{l})\\|.$$ Then using the hypothesis on $\\lvert\\beta\\rvert$ described above we obtain $$\\|k\\alpha(p_{1}^{l}-p_{2}^{l})\\|\\geq \\| ka(p_{1}^{l}-p_{2}^{l})/q\\|-\\frac{1}{2}q^{-1}\\geq \\frac{1}{2}q^{-1}$$ provided that $p_{1}\\not\\equiv p_{2}\\mmod{q_{1}}.$\r\n\r\nWhen $q_{1}>P$ one cannot have pairs of distinct primes $p_{1},p_{2}\\in\\mathcal{P}_{j}$ with $p_{1}\\equiv p_{2}\\mmod{q_{1}},$ whence we always have $\\|\\gamma_{k-1}(p_{1}^{l})-\\gamma_{k-1}(p_{2}^{l})\\|\\gg X^{-1}.$ Whenever $M/k< q_{1}\\leq P$ then we partition each of $\\mathcal{P}_{j}$ into $L_{j}$ classes $\\mathcal{P}_{j,i}$ with the property that no pair of distinct primes belonging to $\\mathcal{P}_{j,i}$ are congruent modulo $q_{1}$ and with $L_{j}$ satisfying the bound $L_{j}\\ll Pq_{1}^{-1}.$ Consequently, the same argument leads to the estimate $\\|\\gamma_{k-1}(p_{1}^{l})-\\gamma_{k-1}(p_{2}^{l})\\|\\gg X^{-1}$ for distinct $p_{1},p_{2}\\in \\mathcal{P}_{j,i}.$ Finally, when $q_{1}\\leq M/k$ one has $q\\leq M$, whence whenever $p_{1}\\equiv p_{2}\\mmod{q_{1}}$ then the condition on $\\beta$ described in the proposition yields\r\n$$\\|\\gamma_{k-1}(p_{1}^{l})-\\gamma_{k-1}(p_{2}^{l})\\|=\\|k\\alpha(p_{1}^{l}-p_{2}^{l})\\|=\\lvert \\beta\\rvert \\lvert k(p_{1}^{l}-p_{2}^{l})\\rvert\\gg P^{l-1}Mn^{-1}.$$\r\n\r\nWe combine Lemma 5.3 of Vaughan \\cite{Vau} and the above discussion to obtain the upper bound\r\n\\begin{equation}\\label{minst}\\sum_{\\substack{P/2<p\\leq P\\\\ p\\in\\mathcal{P}_{j}}}\\lvert f_{p}(\\alpha)\\rvert^{2s}\\ll X^{k(k-1)/2}P(q+M)^{-1}\\sum_{\\bfn\\in\\mathcal{N}}|a(\\bfn)|^{2}\\end{equation} for $q$ in any of the ranges described above. Bounding the coefficients $a(\\bfn)$ trivially one gets\r\n\\begin{equation*}\\label{mins}\\sum_{\\substack{P/2<p\\leq P\\\\ p\\in\\mathcal{P}_{j}}}\\lvert f_{p}(\\alpha)\\rvert^{2s}\\ll X^{k(k-1)/2}P(q+M)^{-1}J_{s,\\xi_{1}}^{(k-1)}(P_{3}),\\end{equation*}\r\nwhere $J_{s,\\xi_{1}}^{(k-1)}(P_{3})$ was defined in (\\ref{ec2.9}). Then combining the above equation with an application of Cauchy's inequality we get\r\n\\begin{equation*}\\label{Falpha}\\lvert\\mathcal{G}(\\alpha)\\rvert^{2s}\\ll P^{2s-1+\\varepsilon}\\sum_{j}\\sum_{\\substack{P/2<p\\leq P\\\\ p\\in\\mathcal{P}_{j}}}\\lvert f_{p}(\\alpha)\\rvert^{2s} \\ll P^{2s+\\varepsilon}X^{k(k-1)/2}M^{-1}J_{s,\\xi_{1}}^{(k-1)}(P_{3}),\\end{equation*} and hence for the choice $s=k(k-1)/2$ then Proposition \\ref{prop1} delivers\r\n$$\\mathcal{G}(\\alpha)\\ll |\\mathcal{S}|P^{1+\\varepsilon}M^{-1/k(k-1)}X^{\\delta_{\\xi_{1}}/2}.$$ \r\n\r\nFor the second claim of the proposition we combine (\\ref{minst}) and Cauchy's inequality in the same way as above and we integrate over $\\grm_{M}$ to obtain\r\n$$\\int_{\\grm_{M}}\\lvert\\mathcal{G}(\\alpha)\\rvert^{2s}d\\alpha\\ll P^{2s+\\varepsilon}M^{-1}X^{k(k-1)/2}J_{s,\\xi_{1}}^{(k)}(P_{3}).$$An application of Proposition \\ref{prop1} to the above line then yields \r\n $$\\int_{\\grm_{M}}\\lvert\\mathcal{G}(\\alpha)\\rvert^{2s}d\\alpha\\ll |\\mathcal{S}|^{2s}P^{2s+\\varepsilon}M^{-1}X^{-k+\\Delta_{\\xi_{1}}},$$from where the second statement follows.\r\n\\end{proof}\r\nIn the rest of the section we deliver a lower bound for the major arc contribution. We will work with the auxiliary functions $f(\\alpha)$, $S_{n}'(q)$, $u(\\beta)$ and $f^{*}(\\alpha)$, defined in (\\ref{fte}), (\\ref{Sn'}), (\\ref{Ualp}) and (\\ref{f*}) respectively but replacing $\\xi$ by $t$ whenever such parameters appear in any of the definitions. We have avoided making such distinction in the notation explicit for the sake of simplicity. For future purposes we define the singular integral as $$J_{s}'(n)=\\int_{-1/2}^{1/2}u(\\beta)^{s}e(-\\beta n)d\\beta.$$ \r\n\\begin{lem}\\label{lem7.1}\r\nSuppose that $s\\geq 2$. Then,\r\n$$J_{s}'(n)=n^{s\\xi/kl-1}\\Big(k^{-s}\\Gamma(\\xi/kl)^{s}\\Gamma(s\\xi/kl)^{-1}+O\\big(B(n)\\big)\\Big),$$\r\nwhere $B(n)=n^{-1}+n^{-\\xi/kl}.$\r\n\\end{lem}\r\n\\begin{proof}\r\nWe will proceed by induction. We consider for convenience the function $\\phi(\\gamma)=\\gamma^{\\xi/kl-1}(n-\\gamma)^{\\xi/kl-1}$. When $s=2$ then orthogonality yields\r\n\\begin{align*}J_{2}'(n)&\r\n=k^{-2}\\sum_{m=1}^{n-1}\\phi(m)=k^{-2}\\int_{0}^{n}\\phi(\\gamma)d\\gamma+O\\big(n^{2\\xi/kl-1}B(n)\\big)\r\n\\\\\r\n&=k^{-2}\\Gamma(\\xi/kl)^{2}\\Gamma(2\\xi/kl)^{-1}n^{2\\xi/kl-1}+O\\big(n^{2\\xi/kl-1}B(n)\\big),\r\n\\end{align*}\r\nwhere we used the fact that $\\phi(\\gamma)$ has at most one stationary point on the interval $(0,n).$ By using the inductive hypothesis we obtain\r\n\\begin{align*}J_{s+1}'(n)&\r\n=k^{-1}\\sum_{m=1}^{n-1}m^{\\xi/kl-1}J_{s}'(n-m)\r\n\\\\\r\n&=k^{-s-1}\\Gamma(\\xi/lk)^{s}\\Gamma(s\\xi/kl)^{-1}\\sum_{m=1}^{n-1}m^{\\xi/kl-1}(n-m)^{s\\xi/kl-1}+O\\big(n^{(s+1)\\xi/kl-1}B(n)\\big).\r\n\\end{align*}\r\nApplying the same argument we used for the case $s=2$ we find that\r\n$$\\sum_{m=1}^{n-1}m^{\\xi/kl-1}(n-m)^{s\\xi/kl-1}=n^{(s+1)\\xi/kl-1}\\big(\\lambda_{s}+O\\big(B(n)\\big)\\big),$$ where $\\lambda_{s}=\\Gamma(s\\xi/kl)\\Gamma(\\xi/kl)\\Gamma\\big((s+1)\\xi/kl\\big)^{-1},$ whence combining the above equations we obtain the desired result.\r\n\\end{proof}\r\nIn order to make further progress we consider the set of major arcs $\\grN_{\\iota}=\\grM(P^{1/2+\\iota})$, where $\\grM$ was defined in (\\ref{grM}) and where we take $\\iota=1/1000.$ Likewise, we define the minor arcs $\\grn_{\\iota}=[0,1)\\setminus \\grN_{\\iota}.$ Note that using equation (\\ref{piu}) and Proposition \\ref{prop200} we obtain for $\\alpha\\in\\grN_{\\iota}$ the bound $$f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\ll P^{s\\xi-s/2+s\\iota}+P^{\\xi-1/2+\\iota}w_{k}(q)^{s-1}u(\\beta)^{s-1}.$$  Consequently, whenever $s\\geq k+2$ then Lemma \\ref{lem4.1} gives\r\n\\begin{align*}\\int_{\\grN_{\\iota}}\\lvert f(\\alpha)^{s}-f^{*}(\\alpha)^{s}\\rvert d\\alpha&\r\n\\ll P^{s\\xi-s/2+(s+2)\\iota+1}n^{-1}+P^{s\\xi-1/2+\\iota}n^{-1}\\sum_{q\\leq P^{1/2+\\iota}}qw_{k}(q)^{s-1}\r\n\\\\\r\n&\\ll P^{s\\xi-\\delta}n^{-1},\r\n\\end{align*}\r\nwhere in the last step we used (\\ref{pri}). Observe as well that (\\ref{qkesqt}) and Lemma \\ref{lem4.1} deliver the bounds\r\n$$\\sum_{q>Q}\\lvert S'_{n}(q)\\rvert\\ll Q^{\\varepsilon-1/k},\\ \\ \\ \\ \\ \\ \\ \\ \\ \\int_{\\lvert\\beta\\rvert>P^{1/2+\\iota}q^{-1}n^{-1}}\\lvert u(\\beta)\\rvert^{s}d\\beta\\ll P^{s\\xi}n^{-1}q^{\\delta}P^{-\\delta(1/2+\\iota)}$$ whenever $s\\geq \\max(5,k+2)$ for any $Q>0$ and $q\\leq P^{1/2+\\iota}$ respectively. Therefore, Lemma \\ref{lem7.1}, the above estimates and a change of variables give\r\n\\begin{equation}\\label{JNu}\\int_{\\grN_{\\iota}}f(\\alpha)^{s}e(-\\alpha n)d\\alpha=C_{k,l,\\xi}n^{s\\xi/kl-1}\\frak{S}'(n)+O\\big(n^{s\\xi/kl-1-\\delta}\\big),\\end{equation} where $C_{k,l,\\xi}=k^{-s}c_{\\xi,l}^{s}\\Gamma(\\xi/lk)^{s}\\Gamma(s\\xi/kl)^{-1}$ and $c_{\\xi,l}$ was defined in (\\ref{Ualp}). Observe that when $s\\geq 4k$ then Proposition \\ref{Prop4} yields the lower bound $\\frak{S}'(n)\\gg 1.$ Likewise, Proposition \\ref{prop223} delivers\r\n\\begin{equation*}\\int_{\\grn_{\\iota}}\\lvert\\mathcal{G}(\\alpha)\\rvert^{k(k+1)}d\\alpha\\ll |\\mathcal{S}|^{k(k+1)}P^{k(k+1)-1/2-\\iota}X^{-k+\\Delta_{\\xi_{1}}+\\varepsilon}\\ll |\\mathcal{S}|^{k(k+1)}P^{k(k+1)}X^{-k-\\delta},\\end{equation*}whence using (\\ref{JNu}) and the ideas of the proof of Proposition \\ref{propthm} to derive a lower bound for the major arc contribution and combining such bound with the above minor arc estimate we obtain\r\n$$\\int_{0}^{1}\\mathcal{G}(\\alpha)^{k(k+1)}f(\\alpha)^{s}e(-\\alpha n)d\\alpha\\gg |\\mathcal{S}|^{k(k+1)}P^{k(k+1)+s\\xi}(\\log P)^{-k(k+1)}n^{-1},$$which concludes the proof of Theorem \\ref{thm1.3}.\r\n\r\n\\begin{thebibliography}{9}\r\n\\bibitem{BKW} J. Br\\\"udern, K. Kawada, T. D. Wooley, \\emph{Additive representation in thin sequences, V: Mixed problems of Waring's type}, Math. Scand. 92 (2003), No. 2, 181--209.\r\n\\bibitem{Hua} L. K. Hua, \\emph{Some results in prime number theory}, Quart. J. Math. Oxford 9 (1938), 68--80.\r\n\\bibitem{Hua2} L. K. Hua, \\emph{Additive theory of prime numbers}, (American Mathematical Society, Providence, RI, 1965).\r\n\\bibitem{K} A. A. Karatsuba, \\emph{The function G(n) in Waring's problem}, Izv. Akad. Nauk SSSR Ser. Mat. 49  (1985), No. 5, 935--947, 1119. \r\n\\bibitem{KW} K. Kawada, T. D. Wooley, \\emph{On the Waring--Goldbach problem for fourth and fifth powers}, Proc. London Math. Soc.(3) 83 (2001), No. 1, 1--50.\r\n\\bibitem{Kum} A. V. Kumchev, \\emph{The Waring--Goldbach problem for seventh powers}, Proc. Amer. Math. Soc. 133 (2005), No. 10, 2927--2937.\r\n\\bibitem{KW1} A. V. Kumchev, T. D. Wooley, \\emph{On the Waring--Goldbach problem for eighth and higher powers}, J. Lond. Math. Soc. (2) 93 (2016), No. 3, 811--824.\r\n\\bibitem{KW2} A. V. Kumchev, T. D. Wooley, \\emph{On the Waring--Goldbach problem for seventh and higher powers}, Monatsh. Math. 183 (2017), No. 2, 303--310.\r\n\\bibitem{Nat} M. B. Nathanson, \\emph{Waring's problem for sets of density zero. Analytic number theory (Philadelphia, Pa., 1980)}, 301--310, Lecture Notes in Math., 899, Springer, Berlin--New York, 1981.\r\n\\bibitem{PPW} S. T. Parsell, S. M. Prendiville, T. D. Wooley, \\emph{Near-optimal mean value estimates for multidimensional Weyl sums,} Geom. Funct. Anal. 23 (2013), No. 6, 1962--2024.\r\n\\bibitem{Tha1} K. Thanigasalam, \\emph{Improvement on Davenport's iterative method and new results in additive number theory, I}, Acta Arith. 46 (1985), No. 1, 1--31.\r\n\\bibitem{Tha2} K. Thanigasalam, \\emph{Improvement on Davenport's iterative method and new results in additive number theory III}, Acta Arith. 48 (1987), No. 2,  97--116.\r\n\\bibitem{Vau1} R. C. Vaughan, \\emph{On Waring's problem for smaller exponents,} Proc. London Math. Soc. (3) 52 (1986), 445--463.\r\n\\bibitem{Vau3} R. C. Vaughan, \\emph{A new iterative method in Waring's problem}, Acta Math. 162 (1989), 1--71.\r\n\\bibitem{Vau} R. C. Vaughan, \\emph{The Hardy-Littlewood method}, 2nd edition, Cambridge University Press, Cambridge, 1997.\r\n\\bibitem{Vi} I. M. Vinogradov, \\emph{On an upper bound for G(n)}, Izv. Akad. Nauk SSSR, Ser. Mat. 23 (1959), 637--642. \r\n\\bibitem{Vu} Van H. Vu, \\emph{On a refinement of Waring's problem,} Duke Math. J. 105 (2000), No. 1, 107--134.\r\n\\bibitem{Woo1} T. D. Wooley, \\emph{The application of a new mean value theorem to the fractional parts of polynomials}, Acta Arith. 65 (1993), No. 2, 163--179.\r\n\\bibitem{Woo2} T. D. Wooley, \\emph{New estimates for smooth Weyl sums}, J. London Math. Soc. (2) 51 (1995), 1--13. \r\n\\bibitem{Woo3} T. D. Wooley, \\emph{On Vu's thin basis theorem in Waring's problem,} Duke Math. J. 120 (2003), No. 1, 1--34. \r\n\r\n\\bibitem{Woo4} T. D. Wooley, \\emph{Nested efficient congruencing and relatives of Vinogradov's mean value theorem}, Proc. London Math. Soc. (3) 118 (2019), No. 4, 942--1016.\r\n\r\n\r\n\r\n\\end{thebibliography}\r\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:03:00", "yymm": "2010", "arxiv_id": "2010.14567", "url": "https://arxiv.org/abs/2010.14567", "source": "arxiv"}}
{"text": "\\documentclass[10pt, twocolumn, journal, final]{IEEEtran}          % twocolumn\n\\IEEEoverridecommandlockouts\n\\usepackage{amsmath}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\usepackage{examplep}  %% for \\pverb command\n\\usepackage{graphicx}\n\\usepackage{cite}\n\\usepackage{algorithmicx}\n\\usepackage[ruled]{algorithm}\n\\usepackage{algpseudocode}\n\\usepackage{mathtools}\n\\usepackage{dsfont}\n\\usepackage{amsfonts}\n\\usepackage{amssymb}\n\\usepackage{tabularx} % in the preamble\n\n\n%\\usepackage{subcaption}\n\\usepackage{multirow}\n\\usepackage{textcomp}\n %%%%%%%%%%%% \n\n% \\usepackage{multicol}\n\\usepackage[usestackEOL]{stackengine}\n\\usepackage[hyphens]{url}\n\\usepackage{pict2e}\n\\usepackage{color}\n\\usepackage[keeplastbox]{flushend}\n\\usepackage{enumerate}\n\\usepackage{float}\n% \\usepackage{caption}\n\\usepackage{mathrsfs}\n\\usepackage{mathtools}\n\\usepackage{caption}\n\\usepackage{subcaption}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\usepackage{tikz}\n\\usetikzlibrary{shapes.arrows,decorations.pathreplacing,decorations.markings,shapes.geometric}\n\\tikzset{radiation/.style={{decorate,decoration={expanding waves,angle=0,segment length=2pt}}}} %%two above for wifi symbol\n\\usetikzlibrary{positioning}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\usepackage{graphicx}\n\\usepackage[normalem]{ulem}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%% BAN LOGIC MACROS %%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\newcommand{\\trusted}[1]{\\text{sup}(#1)}\n\\newcommand{\\unavailable}{\\triangleleft ||}\n\\newcommand{\\believes}{\\mid\\!\\equiv}\n\\newcommand{\\oncesaid}[1]{{\\overset{{{ {#1}}}}{\\mid\\!\\sim}}}\n\\newcommand{\\controls}{\\Rightarrow}\n\\newcommand{\\fresh}[1]{\\#(#1)}\n\\newcommand{\\combine}[2]{{\\langle #1 \\rangle}_{#2}}\n\\newcommand{\\encrypt}[2]{{ \\{ #1 \\} }_{#2}}\n\\newcommand{\\sees}[1]{{\\overset{{{ { #1 }}}}{ \\triangleleft }}}\n\\newcommand{\\pubkey}[1]{{\\overset{{{{#1}}}}{\\rightarrow}}}\n\\newcommand{\\secret}[1]{{\\overset{{{{#1}}}}{\\leftrightharpoons}}}\n\\newcommand{\\sharekey}[1]{{\\overset{{{ {#1}}}}{\\leftrightarrow}}}\n\\newcommand{\\isitequal}{\\overset{\\scalebox{0.6}{\\textbf{?}}}{=}}\n\n\\DeclareMathAlphabet\\mathbfcal{OMS}{cmsy}{b}{n}\n%%%% BOLD MATHCAL\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n  \n\\DeclarePairedDelimiter{\\ceil}{\\lceil}{\\rceil}\n\\DeclarePairedDelimiter{\\floor}{\\lfloor}{\\rfloor}\n\\DeclareMathOperator*{\\argmax}{argmax}\n%\\setlength{\\columnsep}{0.215 in}\n\\DeclarePairedDelimiter\\abs{\\lvert}{\\rvert}\n\\DeclarePairedDelimiter\\norm{\\lVert}{\\rVert}\n% \\captionsetup[algorithm]{labelfont=bf}\n%\\newcommand{\\TODO}[1]{\\textcolor{blue}{TODO: #1}}\n\\newcommand{\\TODO}[1]{}\n%\\newcommand{\\mjreed}[1]{\\textcolor{green}{Martin: #1}}\n\\hyphenation{me-thods}\n\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{lemma}{Lemma}\n%%%% if we need to squeeze space\n% \\addtolength{\\floatsep}{-3mm}\n% \\addtolength{\\textfloatsep}{-4mm}\n% \\addtolength{\\abovecaptionskip}{-4mm}\n% \\addtolength{\\abovedisplayskip}{-0.22mm}\n% \\addtolength{\\belowdisplayskip}{-0.22mm}\n%%%%\n\\makeatletter\n\\def\\blfootnote{\\gdef\\@thefnmark{}\\@footnotetext}\n\\makeatother\n\n\\begin{document}\n\\title{Multi-factor Physical Layer Security Authentication in Short Blocklength Communication}\n\\author{Miroslav Mitev, \\and Mahdi Shekiba-Herfeh,~\\IEEEmembership{Member,~IEEE},         \\and\n        Arsenia Chorti,~\\IEEEmembership{Senior Member,~IEEE},        \\and\n        Martin Reed,~\\IEEEmembership{Member,~IEEE}        \n      \\thanks{ M. Mitev, M. Shakiba-Herfeh and A. Chorti are with ETIS UMR8051, CY Cergy Paris University, ENSEA, CNRS, F-95000, Cergy, France (\\{miroslav.mitev, mahdi.shakiba-herfeh, arsenia.chorti\\}@ensea.fr); }\n      \\thanks{M. Reed is with the CSEE, University of Essex, Colchester (mjreed@essex.ac.uk), UK;}\n      \\thanks{M. Mitev is supported by the DIM RFSI project SAFEST; M. Shakiba-Herfeh and A. Chorti are supported by the ELIOT ANR-18-CE40-0030 - FAPESP 2018/12579-7 and the INEX Project eNiGMA; M. Reed  is supported by the H2020 project SerIoT with project agreement no 780139 funded by the EU.}\n}\n\n\\maketitle\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\begin{abstract} \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\nLightweight and low latency security mechanisms are becoming increasingly important for a wide range of Internet of things (IoT) applications. Promising schemes from the physical layer include (i) physical unclonable functions (PUFs), (ii) localization based authentication, and, (iii) secret key generation (SKG) from wireless fading coefficients. In this paper, we focus on short blocklengths and propose a complete, fast, multi-factor authentication protocol that uniquely combines PUFs, proximity estimation and SKG. To demonstrate the performance of the SKG scheme in the short blocklength (with a focus on delay constrained applications), we provide a numerical comparison of three families of channel codes, including low density parity check codes (LDPC), Bose Chaudhuri Hocquenghem (BCH), and, Polar codes. The SKG keys are incorporated in a zero-round-trip-time resumption protocol for fast re-authentication. All schemes of the proposed mutual authentication protocol are shown to be secure through formal proofs using Burrows, Abadi and Needham (BAN) and Mao and Boyd (MB) logic as well as the Tamarin-prover. \n\n\n\\end{abstract}\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Introduction}\n\\label{sec:intro}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\TODO{Max pages 13. rewrite so it is not like EURASIP}\n\\TODO{Make it clear here that we have relatively low key rate, also that we combine SKG with classical symmetric cryptography}\n\n\nAuthentication is central in building secure Internet of things (IoT) networks; confirming the identity of devices and their role in the network hierarchy eliminates the possibility of numerous attacks~\\cite{iot_security_survey}. However, the low latency and computational power constraints present in many IoT systems \\cite{Chorti_sensors}, render the design of IoT authentication mechanisms a  challenging task. Current solutions rely on modulo arithmetic in large fields and typically incur considerable latency, in the order of tens of milliseconds; as an example, it has been reported that verifying digital signatures on a vehicle with a $400$ MHz processor takes around $20$ msec \\cite{Teniou18}, exceeding the delays that are tolerated in vehicle to everything (V2X) communications. In this direction, a 3GPP report on the security of ultra reliable low latency communication (URLLC) systems notes that authentication for URLLC is still an open problem \\cite{3gppURLLC}. On a more general note, with the advance of quantum computing, traditional asymmetric key cryptographic schemes will become semantically insecure, unless the key sizes increase to impractical lengths. Therefore, the introduction of new security primitives for device authentication is timely. \n\nIn this sense, physical layer security (PLS) has proven itself as a lightweight alternative to the computational complexity based mechanisms \\cite{A_Chorti_PLS0, A_Chorti_PLS1}. The increasing interest in PLS has been stimulated by many practical needs. Notably, many critical IoT networks require fast authentication, e.g., in  V2X applications, telemedicine and haptics. Moreover, PLS, that relies upon information-theoretic security proofs, could resist quantum computers, unlike corresponding asymmetric key schemes relying on the (unproven) intractability in polynomial time of certain algebraic problems. \n\nPLS schemes exploit physical layer entropy sources, including  both in the hardware, as well as in the communication medium~\\cite{Eurasip2020,Mitev_sub-scheduling, Globecom_2019_MiM}. With respect to the former, physical unclonable functions (PUFs) are hardware entities harnessing entropy from physically unclonable variations that occur during the production process of silicon~\\cite{First_silicon_puf,PUF}. These unique and unpredictable variations allow the extraction of uniformly distributed binary sequences that can be used as authentication IDs or keys. Due to their unclonability and simplicity, PUFs are seen as lightweight security primitives that can offer alternatives to today's authentication mechanisms. \n\nMoreover, a straightforward secret key generation (SKG) approach can be built by exploiting the reciprocity of the wireless fading coefficients between two terminals within the channel coherence time. When SKG and PUF encoders are employed in URLLC systems, it is critical to employ good error correction codes so as to achieve good reliability without any information leakage, while operating in the short blocklength. The employed codes should be able to reconcile any mismatched bits with high probability (reliability) while on the other hand they should not reveal any information about the key (security).\n\nFollowing from the above, in this work we introduce a fast, multi-factor authentication protocol for short blocklength communication. To achieve a high security level the proposed scheme combines the following set of factors: 1) PUFs that are used as hardware fingerprints of IoT devices; 2) quick proximity verification using the received signal strength indicator (RSSI); and, 3) SKG to generate symmetric resumption keys used to speed up authentication by resuming sessions (as opposed to re-establishing sessions). With respect to SKG, we further provide a numerical comparison between different reconciliation encoders in the short blocklength regime, bench-marked against the theoretical upper bound. The aforementioned factors are combined in a PLS resumption protocol that allows for data exchange within zero-round-trip time (0-RTT). Finally, the security of the authentication protocol is verified through formal methods:  Burrows, Abadi, Needham (BAN)~\\cite{Ban_logic} as well as  Mao  and  Boyd  (MB) logic and the  Tamarin-prover~\\cite{Tamarin-prover}.  \n\n\nThe main contributions of this paper are as follows:\n\\begin{enumerate}\n     \\item We discuss the performance of three families of codes in the short blocklength for Slepian Wolf (SW) based SKG reconciliation.\n     \\item  We propose a lightweight and fast proximity detection using Kalman filters, suitable for constrained IoT devices.\n     \\item We introduce a forward secure 0-RTT resumption authentication mechanism.\n    \\item We develop a fast multi-factor authentication protocol that combines an initial proximity check with PUF authentication and SKG resumption keys.\n    \\item We formally prove the security of the proposed individual schemes and of the full protocol.\n\\end{enumerate}\n\nThe rest of the paper is organized as follows: Section \\ref{sec:related_work} discusses related work, Section   \\ref{sec:SKG_short} discusses the  performance of different short blocklength SKG reconciliation encoders. Section \\ref{sec:proximity} introduces a fast proximity estimation mechanism and Section \\ref{sec:authentication} presents the proposed authentication protocol whose security properties are verified in Section \\ref{sec:sec_analysis}. Finally Section \\ref{sec:conclusions} concludes this paper.\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{Related Work and Contributions}\n\\label{sec:related_work}\nIt is well established that SKG can be performed at PHY by using the channel fading as a source of common randomness. \nDuring the channel's coherence time, two parties, referred to as Alice and Bob in the following, can observe highly correlated channel states that can be used to generate a shared secret key between them  \\cite{SKG_implementation_survey}.\n As Alice's and Bob's measurements differ due to noise, to generate a common key, Slepian Wolf (SW) decoding of the observed sequence is required for reconciliation~ \\cite{coding1,coding3,coding4,coding7}. However, most prior works have not considered SW decoding with short blocklengths. In the present work, we implement and compare the performance of three families of SW decoders that show promising performance in short blocklength communication \\cite{URLLC,LDPCshortDESIGN}.\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\nFurthermore, we introduce a lightweight method of proximity verification, to be employed as an early authentication step. The literature of localization  and RF-fingerprinting based authentication is vast, e.g., see the surveys \\cite{local_survey1,local_survey2}. Although any of the many existing algorithms could be  employed  in  our proposed  protocol, here we present an alternative approach in which a (single) mobile unit (typically an IoT node) can verify the proximity of a fixed location node (typically an access point acting as an edge server). To render the scheme robust against impersonation type of attacks, in which a malicious server changes its transmission power to falsify its location information, we leverage mobility. Instead of relying on a single RSSI measurement, we propose taking multiple RSSI measurements that, thanks to they mobility of the authenticating entity, are unpredictable by an attacker. To the best of our knowledge, this  approach has only been reported once in the literature so far in the recent paper \\cite{Domuta20}, where the authors leverage the mobility of a mobile handset to localize a base station using unscented Kalman filters with the time of arrival (ToA) and angle of arrival (AoA) information as inputs. Our proposed proximity estimator is much simpler and faster as it relies solely on RSSI measurements and uses a simple Kalman filter with scalar inputs, so it is an attractive approach for inverse proximity estimation in IoT networks.\n\nFinally, central to our proposed authentication protocol is the role of PUFs. A PUF can be used in a challenge -- response authentication protocol, where a challenge can refer to measuring the jitter of a ring oscillator, power-on state, etc. A typical PUF-based authentication protocol consists of two main phases, referred to as \\textit{enrollment} and \\textit{authentication}, respectively \\cite{PUF_Location, Auth_protocol_pre-shared-key, Auth_protocol-sess_key-from_nonces1}. During the \\textit{enrollment} phase each node runs a set of challenges on its PUF and characterizes the variance of the measurement noise in order to generate helper data. Next, a verifier creates a database with all challenge-response pairs (CRPs) corresponding to the nodes within its network. Later, during the \\textit{authentication} phase the verifier sends a random challenge to the corresponding node. The node computes the response by running the challenge on its PUF and sends it to the verifier to confirm its authenticity. Numerous authentication protocols have been proposed based on this approach~\\cite{PUF_auth_survey}. \\textcolor{black}{However,  relying on PUFs as a single security factor can expose the system to a variety of threats, especially in an IoT scenario~\\cite{PUFs_challenges}. In this sense, combining two or more independent credentials can be used to built a secure multi-factor authentication protocol. For example, PUFs have been combined with shared-key~\\cite{2_factor_privacy_preserving_PUF}, localization~\\cite{PUF_Location}, and channel characteristics~\\cite{Eurasip2020}. }\n\nAny two PUF measurements at the same node are never exactly the same due to measurement noise, thus reconciliation between successive measurements is needed. To this end, the verifier uses helper data stored during the enrollment to re-generate the initially derived authentication key. Reconciliation can be implemented using fuzzy extractors (FE)~\\cite{PUF_forensics}. A FE is built from a pair of randomized functions, i.e.,  \\texttt{Gen} and \\texttt{Rep}, where  \\texttt{Gen} takes as input a PUF response and produces two outputs: helper data and a uniformly distributed key; \\texttt{Rep}, which stands for deterministic reproduction, reproduces the key by using the initial helper data and a new noisy version of the response~\\cite{fuzzy_possible}. Overall, authentication is achieved by comparing a key generated from the initial response, to a key generated from a later response. Generally, the \\texttt{Rep} function has greater computational complexity than the \\texttt{Gen}. In IoT networks it is desirable that the more complex operations are performed on a resourceful device (e.g., an edge server) rather than on a constrained IoT node. \n\n\n\n\n\n\n\nPUF authentication can greatly reduce computational overhead. However, the size of the CRP space of a single PUF is limited. To overcome this limitation, we propose a solution inspired by the 0-RTT authentication mode introduced in TLS 1.3. The 0-RTT feature allows users to send data on the first flight without re-authentication (early data), nevertheless, this fast resumption introduces new vulnerabilities \\cite{0-RTT_attacks1}. To address these issues, a secure, mutual authentication protocol is presented. The scheme is multi-factor, i.e., node authentication is verified by: i) the combination of an initial proximity detection with PUFs and unique session IDs that ensure properties such as untraceability, anonymity, protection against impersonation attacks and many more; and, ii) an additional SKG mechanism that allows for uniform session key generation. By introducing SKG resumption keys in a 0-RTT type of protocol we achieve both forward secrecy and protection against replay attacks. \n\n\n\n\n\n\\section{SKG SW Decoding in the Short Blocklength} \\label{sec:SKG_short}\n\\TODO{need to make it clear keys are used on more then one block and that we have a relatively low key rate, also need a sentence in the introduction that makes it clear we have relatively low key rates.}\n\nIn this section we focus on SW coding aspects in short blocklengths and implement three different families of codes and compare their performance against a known upper bound. In our system model, we assume Alice and Bob generate binary sequences $Y_A, Y_B$ of length $n$ by quantizing their respective observations of the channel coefficient $H_0$, denoted by $X_A$ and $X_B$, respectively. For simplicity, in this work we assume that a passive adversary, referred to as Eve, cannot obtain any information for the generated sequences\\footnote{Due to large scale fading and path-loss, the channel coefficients between Alice, Bob and Eve are typically correlated. However, it is possible through pre-processing of the coefficients to remove correlations with the observation of Eve, e.g., see \\cite{Prena13}, \\cite{Zhu17}, \\cite{LoRa19}. In the rest of this paper, for compactness of presentation we assume this assumption holds.}.\n\nWe assume that the generated binary sequences are independent and identically distributed (i.i.d.) with equal probabilities to be $0$ or $1$, i.e., $Pr\\left(Y_A[i]=0\\right)=Pr\\left(Y_B[i]=0\\right)=0.5, i=1,\\ldots,n$. Alice and Bob aim to agree on a secret key $K$ of length $k$ that needs to be drawn uniformly from $K = \\{0, 1\\}^k$. To this end, Alice transmits her syndrome $S_A$, of length $n-k$, through a public channel to assist Bob to obtain an estimate $\\hat{Y}_A$ of her sequence $Y_A$. The code rate is defined as $R = \\frac{k}{n}$ and the frame error rate (FER) is defined as the probability that Bob's estimation of $Y_A$ is erroneous $Pr(Y_A \\neq \\hat{Y}_A)$. In this set-up, Bob first estimates the sequence $\\hat{Y}_A$ and then based on that, Alice and Bob independently extract the key $K$ using privacy amplification (Fig. \\ref{Fig:SysModel}).\n\n\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.46\\textwidth]{SystemModel.pdf}\n\\caption{The system model for coding on secret key generation.}\n\\label{Fig:SysModel}\n\\end{figure}\n\n\n\nMotivated by the promising performance of low density parity check codes (LDPC) \\cite{LDPCList}, polar codes \\cite{PolarList} and Bose Chaudhuri Hocquenghem (BCH) codes \\cite{BCHList} with list decoding in short blocklengths for standard channel coding applications, in this paper we implement and compare against the upper bound in \\cite{SKG_upperbound} the SKG achievable rates when these three families of SW decoders are employed.\n\n\\begin{figure*} [!ht]\n  \\includegraphics[width=\\textwidth,height=7cm]{FERN128_3.pdf}\n  \\caption{Comparison of FER performance of codes with the upper bound in \\cite{SKG_upperbound} for $n=128$.}\\label{Fig:FERN128}\n\\end{figure*}\n\n\\begin{figure}[!ht]\n\\centering\n\\includegraphics[ width=0.5\\textwidth]{FERN1024_3.pdf}\n\\caption{Comparison of FER performance of polar code with the upper bound in \\cite{SKG_upperbound} for $n=1024$.}\n\\label{Fig:FERN1024}\n\\end{figure} \n\n\\subsection{LDPC codes with ordered statistic decoding}\nLDPC codes are powerful error correcting codes that can approach the Shannon limit \\cite{LDPC_capacity} at very large blocklengths. However, in general, LDPC codes do not perform well in short blocklengths. To address such shortcomings, LDPC codes enhanced with ordered statistic decoding (OSD) is one of the techniques that has been suggested to achieve near maximum likelihood (ML) performance for short blocklengths \\cite{LDPCList}.\nThe central idea behind  OSD is that first we pick the $\\tilde k$ most reliable independent positions, where $\\tilde k$ is the rank of the code. Then, based on the log-likelihood ratios (LLR) we make hard decisions on the value of the selected bits. Subsequently, we generate a candidate list of codewords by flipping the values of up to $t$ bits among them. Finally, by performing ML search in the list we choose the most likely codeword \\cite{OSD2}. The size of the candidate OSD list increases with respect to $t$ as $\\sum^t_{i=0} \\binom ki$. In our implementation, Bob first feeds $Y_B$ and $S_A$ to the LDPC decoder to generate soft information of the bits (i.e., the LLRs). Then the LLRs are passed to the OSD block to estimate $\\hat{Y}_A$. The public message is given as $S_A = Y_A H^t$, where $H^t$ is the transpose of the parity check matrix.\n\n\n\n\\subsection{Polar codes with list decoding}\nPolar codes are linear block error correcting codes that can provably achieve the capacity of a binary-input discrete memoryless channel as the code length tends to infinity \\cite{Polar}. A significant improvement in the performance of polar codes in finite blocklengths can be achieved by utilizing successive cancellation list decoding, that keeps a list of most likely decoding paths. List decoding can be improved further by utilizing  cyclic redundancy check (CRC). The CRC assists the decoder to pick the correct decoding path in the list, even if it is not the most probable one \\cite{PolarList}.\n\nIn our implementation (similar to \\cite{Polar_source}), Alice encodes her sequence $Y_A$ as $U = Y_A G_n$, where $G_n = \\big(\\begin{smallmatrix}\n  1 & 0\\\\\n  1 & 1\n\\end{smallmatrix}\\big)^{\\otimes n}$ is the encoder matrix as defined in \\cite{Polar_source}. Alice sends the syndrome $S_A$ which contains $S_1$ and CRC bits with length $l$. $S_1$ has length $n-k-l$ and contains high-entropy bits of $U$ as follows\n\\begin{equation}\\label{eq:Polar_encoder}\nH(U[i]|Y_A,U^{i-1})\\geq H(U[j]|Y_A,U^{j-1}),\\; 1\\leq i,j\\leq n,\n\\end{equation}\nwhere $i$ is the position of transmitted bits and $H(\\cdot)$ denotes entropy. Therefore, the actual rate of the  polar code is $R=\\frac{k+l}{n}$. On the other side, Bob applies CRC-aided successive cancellation list decoding to estimate $\\hat Y_A$. Note that the complexity of list decoding polar coding grows linearly with the list size. \n\n\\subsection{BCH codes with list decoding}\nBCH codes are a class of cyclic error-correcting codes constructed by polynomials over a finite field. One of the main features of BCH codes during code design is the number of guaranteed correctable error bits. A binary BCH code is defined by $(n_{BCH} ,k_{BCH} ,t_{BCH} )$, where $n_{BCH}=2^w-1$ is the blocklength, $k_{BCH}$ is the message length, and $t_{BCH}$ represents the number of guaranteed correctable error bits. To improve their error correcting capability, BCH codes can be armed with list decoding.\n\nIn our implementation of list decoding, Alice calculates the syndromes as $S_A = Y_A H^t$, where $H$ is the parity check matrix of the BCH code, and transmits it through the public channel. On the other side, Bob, first generates a candidate codeword list by flipping up to $t$ bits of the measured sequence $Y_B$. After feeding the list to the BCH decoder, it picks the solution which has the lowest Hamming distance with the measured sequence $Y_B$. In our implementation of list decoding, the size of the list increases with respect to $t$ as $\\sum^t_{i=0} \\binom ni$.\n \n\n\n\n\\subsection{Numerical results}\nIn this subsection, we analyse the FER performance of the aforementioned codes in the SKG setting and compare them with the finite length upper bound reported in \\cite{SKG_upperbound}, noting that optimization of the degree distributions is out of the scope of this study.\nFor instance, we consider $n=128$ and we implement a $(n,k)=(128,75)$ polar code with 11 bits CRC and a $(127,64,10)$ BCH code. Also, we pick regular $(3,6)$ LDPC codes with length 128 bits\\footnote{We note that the performance of LDPC codes can be improved by optimizing the variable and check nodes degree distributions \\cite{Mahdi_LDPCdesign}, however the degree optimization of the LDPC codes is out of the scope of this work.}. In Fig. \\ref{Fig:FERN128}, the FER performances of half rate codes with $128$ bits blocklength are depicted (i.e., the key length after privacy amplification is $64$) and compared to the upper bound reported in \\cite{SKG_upperbound}. Note that the upper bound becomes inaccurate for short blocklength while their accuracy improves as the blocklength increases. That is the reason we observe comparatively a large gap between the upper bound and the codes' FER performances for $n=128$ \\cite{coding7}.\n\nAs it is depicted in Fig. \\ref{Fig:FERN128}, the polar code with list size $128$, and the order two BCH list decoding code show the best performance among the codes. Also, the results demonstrate that although classical polar codes do not perform well in the short blocklength, their performance can be significantly improved by arming them with list decoding. For example, the polar code with list size $128$, provides around two orders lower FER compared to the classical polar code at $H(Y_A[i]|Y_B[i])=0.1944$. However, this improvement comes at the cost of $128$ times more decoding complexity. List decoding also improves the performance of the BCH code, but the improvement with respect to the additional complexity is not as notable as in the case of the polar code. The improvement in the LDPC code performance is still observed by using OSD, however it is not very significant.\n\nMoreover, we consider an instance of $n=1024$. In Fig. \\ref{Fig:FERN1024}, the FER performances of a half rate polar code with $(n,k)=(1024,523)$ and $11$ bits CRC for different list sizes are shown. As it is demonstrated in Fig. \\ref{Fig:FERN1024}, utilizing list decoding can significantly improve performance. For a list size larger than $8$, the improvement by increasing the size of the list is not significant. Also we observe that, at blocklength $n=1024$, the gap between the FER of the polar code and the upper bound is less than the case $n=128$. We posit that one of the reasons is that the upper bound at this length is tighter than the first instance.\n\n\n\\section{Fast Proximity Estimation}\n\\label{sec:proximity}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n{Introducing a  ``smart movement\" environment brings number of advantages to IoT systems, including energy saving, control over the node mobility and increased overall quality-of-experience (QoE)~\\cite{smart_movement}. In this direction, we propose in this Section a fast proximity estimation approach, based on the mobility of IoT devices. The novelty in our strategy relies upon the fact that if Alice (a mobile IoT node) moves in an  manner unpredictable for adversaries, she can take successive measurements of the RSSI and use them for proximity estimation of a static Bob (e.g., a static edge server), as shown in Fig. \\ref{fig: proximity}. In fact, this lightweight proximity estimation approach allows Alice to detect impersonation attacks\\footnote{An impersonation attack when proximity estimation is used as an authentication factor can be mounted by altering the transmission power level, e.g., as in some false base station types of attack. By taking successive measurements of the RSSI in unpredictable locations, this attack can be mitigated. } when used in combination with the authentication protocol presented in the next section. }\n\n\\begin{figure}[t]\n\\centering\n\\includegraphics[ width=0.3\\textwidth]{MovingScheme.png}\n\\caption{Proposed proximity estimation.}\n\\label{fig: proximity}\n\\end{figure} \n\nDue to the ease of implementation and signal availability, RSS-based localization is usually a favoured technique. According to the inverse-square law, the RSSI at Alice can be used to estimate the distance between her and Bob. We assume that the channel coefficients follow a log-normal power distribution. In this sense, the traditional path loss model for noisy environment is~\\cite{path_loss1, path_loss2}:\n\\begin{equation}\n    P(dBm)=P_{0}(dBm)-10n \\log_{10}  \\left(\\frac{d}{d_{0}}\\right)+X_{\\sigma},  \\label{eq:path_loss_model}\n\\end{equation}\nwhere $P$ is the strength of the received signal in dB, $P_{0}$ represents the average received signal strength at some reference distance $d_{0}$ in dB, $d$ is the distance of the transmitter, $n$ is an attenuation factor that gives the relation between distance and received power, and $X_{\\sigma} \\sim \\mathcal{N}(0, \\sigma^2_{X_\\sigma})$ is a zero mean Gaussian random variable modelling shadowing \\cite{Rappaport}. Based on the model for noisy RSSI,\nthe distance can be estimated as~\\cite{rssi-to-distance2}:\n\\begin{equation}\n    \\hat{d}=d_{0}10^{\\frac{P_{0}-P}{10n}}e^{-\\frac{1}{2}\\left(\\frac{\\sigma_{X_{\\sigma}\\ln(10)}}{10n} \\right)^2}. \\label{eq:distance-estimation}\n\\end{equation}\nFinally, we employ a Kalman filter for the proposed proximity algorithm. A Kalman filter can successfully lower the impact of noise present in the RSSI and thus improves the reliability of the proposed localization approach. The filter's parameters are usually in the form of matrices, however, the target in the scenario assumed here is static, and as a result all parameters reduce to scalar values. This greatly reduces the complexity of the filter and makes the algorithm suitable for a resource constrained device (for details on Kalman filters see \\cite{Kalman_filter}). The filter works by the assumption that the current state $x_i$ has a relation to the previous state $x_{i-1}$, and this relation is expressed as follows:\n\\begin{equation}\nx_i=Ax_{i-1}+Bu_{i-1}+w_{i-1},\n\\end{equation}\nwhere the transition matrix $A$ links the current state $x_i$ with the previous one $x_{i-1}$, $B$ is a control matrix which relates the control vector $u$ to the state and $w$ is i.i.d. normally distributed process noise such that $w\\sim N(0,Q)$. Following that a measurement is given by \n \\begin{math}\nz_i=Hx_i+R_i,\n\\end{math}\nwhere $H$ is an observation matrix used to translate each state to a measurement and $R$ is i.i.d. normally distributed measurement noise such that $R\\sim N(0,\\sigma_{R}^2)$.\n\nGiven the above, the recursive process of the filter is presented in Fig. \\ref{fig:Kalman}. It is based on two main steps: prediction and correction (time and measurement update, respectively). During the time update step: i) the next state is updated based on the previous state; ii) the error covariance matrix $P$ is updated. In the above $\\hat{x}_i{\\kern 1pt\\bar{}}$ and $P_i{\\kern 1pt\\bar{}}$ are the \\textit{a priori} estimated state and covariance matrix, respectively. Next, during the measurement update step: i) the so called Kalman gain $K$ is computed; ii) the estimate is updated based on the measurement using the Kalman gain; and, iii) the error covariance matrix is updated using the Kalman gain. \n \\begin{figure}[!t]\n \\centering\n \\resizebox{!}{3.5cm}{\n \\begin{tikzpicture}\n\\tikzset{>=latex}\n \\begin{scope}[xshift=2cm]\n \\draw (2.3,10.3) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=4.5cm, align=left] (node1) {\\Longstack[l]{\\centerline{Time update}\\\\ \\hspace{-0.23cm} \\noindent\\rule[0.5ex]{4.72cm}{1pt}\\\\ \n     $\\hat{x}_i{\\kern 1pt\\bar{}}=A\\hat{x}_{i-1}+Bu_{i-1}$\n \\\\ \\vspace{0.5\\baselineskip}\\\\\n    $P_i{\\kern 1pt\\bar{}}=AP_{i-1}A^T+Q$\n }};\n \\draw (7.3,10.3) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=4.5cm, align=left] (node2) {\\Longstack[l]{\n \\centerline{Measurement update}\\\\ \\hspace{-0.23cm} \\noindent\\rule[0.5ex]{4.72cm}{1pt}\\\\\n $K_i=\\bar{P}_iH^T(H\\bar{P}_iH^T+R)^{-1}$\\\\\n $\\hat{x}_i=\\hat{x}_i{\\kern 1pt\\bar{}}+K_i(z_i-H\\hat{x}_i{\\kern 1pt\\bar{}})$\\\\\n $P_i=(I-K_iH)P_i{\\kern 1pt\\bar{}}$}};\n \\draw [->,thick] (node2.north) to [out=150,in=30] (node1.north);\n\\draw [->,thick] (node1.south) to [out=-30,in=-150] (node2.south);\n \\end{scope}\n \\end{tikzpicture}\n }\n \\caption{Kalman filter steps}\n \\label{fig:Kalman}\n \\end{figure}\nIn the following subsection, we provide the details of our implementation of the fast proximity estimation using a simple Kalman filter.\n\n\\subsection{Implementation of the fast proximity algorithm}\n\n\\begin{figure}[!t]\n    \\centering\n      \\hspace{-6cm} \\includegraphics[clip, trim=3.5cm 12.4cm 4cm 12.5cm, width=0.48\\textwidth]{Measurements/all.pdf}\n    \\hspace{-3cm}\n     {\\hspace{-5cm}\\raisebox{2.3cm}{\n      \\includegraphics[clip, trim=4.95cm 20.62cm 12.75cm 8.2cm, height=0.5cm]{Measurements/all.pdf}%\n    }}\n    \\caption{Measured RSSI data (dashed) and filtered data using Kalman filter (solid) at distance of $3$ meters. The measurement noise variance is set to $\\sigma_R=0.1$.}\n    \\label{fig:RSSI_measurements}\n    \\end{figure}\nWe have performed a set of experiments at two different environments: i) in a small auditorium; and, ii) in a library. In both scenarios we had a static Bluetooth low energy (BLE) beacon, transmitting at $1$ dBm and a smartphone (mobile node) measuring the RSSI at different locations. This decision is motivated by the scenario assumed for this study, i.e., the access point (Bob) is fixed while the mobile IoT device (Alice) takes consecutive proximity measurements. The line of sight between the two devices was not always present due to moving people in the area. Moreover, there were other BLE and WiFi devices in the vicinity, causing further interference. \n\nFirst, in Fig. \\ref{fig:RSSI_measurements}, we demonstrate the performance of the Kalman filter. The chosen  parameters are as follows: the prediction of the error variance was set to  $P_{\\text{e},i-1}=0.1$; the process variance to $Q=10^{-6}$; the measurement noise variance for the specific environment was chosen as $\\sigma_{R}=0.1$. The figure shows that the filtered data quickly stabilizes eliminating the noise in the measurements, while the raw RSSI data wildly fluctuated by tens of dBms.\n\nNext, the path loss model for each environment was determined. In both scenarios the smartphone was used to measure the RSSI at different distances from the BLE beacon (1, 3, 6 meters). For each distance, we performed 50 measurements while during each measurement the mobile device collected 20 samples of the RSSI. The motivation behind this value is that in a realistic online phase, Alice could quickly (in a matter of seconds) collect 20 samples. Furthermore, as it can be seen in Fig. \\ref{fig:RSSI_measurements} even before the 20th sample the Kalman filter has already converged and its output varies only by a few dBms. Therefore, for our proximity estimation we assume that the 20th output of the Kalman filter is the ``decision\" output which Alice uses to determine her distance to Bob.\n\nThe curve fitting of the path loss model in both scenarios is given in Fig. \\ref{fig:rssi-fit1}. The curves show the standard deviation of the collected RSSI data and the standard deviation of the ``decision\" outputs of the Kalman filter. The estimated channel parameters for both scenarios are given in Table \\ref{tab:table_parameters}. \n\\begin{figure}[!t]\n    \\centering\n    \\includegraphics[clip, trim=3.5cm 9.4cm 4cm 10cm, width=0.48\\textwidth]{Measurements/combine1.pdf}\n    \\caption{Curve fitting of the path loss model for a small auditorium (TOP) and a library (BOTTOM). }\n    \\label{fig:rssi-fit1}\n\\end{figure}\n\\begin{table}[!t]\n    \\centering\n        \\caption{Estimation of channel parameters for both scenarios }\n    \\label{tab:table_parameters}\n    \\begin{tabular}{p{2cm}|p{1.78cm}|p{1.78cm}|p{1.55cm}}\nScenario & $P_0$  & $n$ & $\\sigma_{X_{\\sigma}}$ \\\\\nSmall auditorium & -60.12 @ 1m & 1.7 & 6.49 \\\\\nLibrary & -61.91 @ 1m & 1.85 & 6.30 \n\\end{tabular}\n\\end{table}\nFinally, the distance estimations based on (\\ref{eq:distance-estimation}) using the collected RSSI data and the ``decision\" outputs of the Kalman filter are shown in Fig. \\ref{fig:rssi-fit2}. Overall, in Figs. \\ref{fig:rssi-fit1} and \\ref{fig:rssi-fit2} it can be seen that the Kalman filter greatly improves the reliability of the proposed method. As expected, the signal strength decreases as the distance increases. Furthermore, it can be observed that the environmental impact over the signal, such as noise and objects, increases at greater distance. This directly influences the distribution of the RSSI and increases the variation from the mean value. However, at the output of the Kalman filter these variations are limited and the mobile node (Alice) can successfully determine whether the static access point (Bob) is in one of the three regions: immediate (1 m), near (3 m), or far (6 m). Moreover, since Alice moves in a manner that is unpredictable  for adversaries, a malicious node cannot impersonate Bob unless they are co-located. This simple proximity estimation technique is used as a independent factor in a multi-factor authentication protocol presented in the next section.\n\n\\begin{figure}[!t]\n    \\centering\n    \\includegraphics[clip, trim=3.5cm 9.4cm 4cm 10cm, width=0.48\\textwidth]{Measurements/combine2.pdf}\n    \\caption{Distance estimation for a small auditorium (TOP) and a library (BOTTOM). }\n    \\label{fig:rssi-fit2}\n\\end{figure}\n\n\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Proposed Mutli-factor Authentication Protocol}\\label{sec:authentication}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis section presents a lightweight multi-factor authentication scheme, leveraging PUFs, proximity estimation and SKG; it consists of two phases: an enrollment phase and an authentication phase and uses SKG as a quick resumption mechanism. We note that in the proposed protocol, only Alice (an IoT node) performs proximity verification. To do so, during the pilot exchange, she positions herself in diverse (unpredictable) locations and takes multiple measurements of the RSSI. The RSSI is used to estimate Bob's location as discussed Section \\ref{sec:proximity}. \n\nWe first present all individual primitives and then provide an overall security analysis. The notation used throughout this section is defined as follows:\n\\begin{itemize}\n    \\item A SKG scheme generating as outputs binary vectors ${K}$ and ${S}_A$ of sizes $k=|{K}|$ and $|{S}_A|$, respectively, with ${K}\\in\\mathcal{K} $ denoting the key obtained after privacy amplification and ${S}_A \\in \\mathcal{S}$ denoting \n   Alice's syndrome.\n\\item Alice's PUF denoted by $P_A$  that generates a response $R \\in \\mathcal{R}$ to a challenge $Ch \\in \\mathcal{C}h$, i.e., $R=P_A(Ch)$. Also, a pair of fuzzy extractor algorithms, denoted by $\\texttt{Gen}: \\mathcal{R} \\rightarrow \\mathcal{K}_R \\times \\mathcal{H}_R$, accepting as input the PUF response and generating as outputs the identification (fuzzy) key and helper data, with corresponding reproduce algorithm $\\texttt{Rep}: \\mathcal{R} \\times \\mathcal{H}_R \\rightarrow \\mathcal{K}_R$, such that:\n\\begin{align}\n   &\\texttt{Gen}(R)=(H_{R},K_{R}),\\\\ &\\texttt{Rep}(R',H_{R})=K_{R},\n\\end{align}\nwhere $R,R' \\in \\mathcal{R}, K_{R} \\in \\mathcal{K_R}$ and $H_{R} \\in \\mathcal{H}_R$. \n\n\\item A symmetric encryption algorithm, e.g., AES-256 in Galois field counter mode (GCM)\\footnote{We note that using a block cipher such as AES-256 in a GCM operation allows to the use of the same key $K$ to encrypt typically Gigabytes of data.}, denoted by $\\verb\"Es\": \\mathcal{K}\\times \\mathcal{M} \\rightarrow \\mathcal{C_T} $ where $\\mathcal{C_T}$ denotes the ciphertext space with corresponding decryption $\\verb\"Ds\": \\mathcal{K}\\times \\mathcal{C_T} \\rightarrow \\mathcal{M}$, i.e., \n\\begin{eqnarray*}\n    \\verb\"Es\"({K}, {M})={C},\\\\\n    \\verb\"Ds\"({K}, {C})={M},\n\\end{eqnarray*}\nfor ${M}\\in \\mathcal{M}$, ${C}\\in\\mathcal{C_T}$.\n\n\\item A pair of message authentication code (MAC) algorithms, denoted by $\\verb\"Sign\": \\mathcal{K}\\times \\mathcal{M}\\rightarrow \\mathcal{T}$, with a corresponding verification algorithm $\\verb\"Ver\": \\mathcal{K}\\times \\mathcal{M} \\times \\mathcal{T} \\rightarrow \\{yes, no\\}$:\n\\begin{eqnarray*}\n&&\\verb\"Sign\" ({K}, {M})={T},\\\\\n&&\\verb\"Ver\" ({K}, {M}, {T})=\\left\\{\\begin{array}{ll}\n\\it{yes}, & \\text{if integrity verified}\\\\\n\\it{no}, & \\text{if integrity not verified}\n\\end{array}\\right. \n\\end{eqnarray*}\n\n\\item A cryptographic (irreversible) one-way hash function\n$$Hash: \\{0,1\\}^{q}\\rightarrow \\{0,1\\}^k,$$\nthat is used to compress the size of an input binary vector of length $q $ to a binary vector of length $k=|K|$.\n\\end{itemize}\n\nIn all of the previously defined functions, the insertion of an index $i-1$ denotes the value of a variable or quantity one instance earlier than its corresponding value at instance $i$, e.g., $Ch_1$ denotes the PUF challenge at instance $1$ while $Ch_2$ denotes the PUF challenge at instance $2$. Furthermore, following from the definition of PUFs, every challenge produces a unique response and corresponding helper data and authentication keys, i.e., $P_A(Ch_1)\\neq P_A(Ch_2)$ and $ \\texttt{Gen}(P_A(Ch_1)) \\neq \\texttt{Gen}(P_A(Ch_2))$. \\textcolor{black}{Finally, concatenation of two binary vectors $X$ and $Y$ is denoted by $(X||Y)$}.\n\n\\begin{figure}[!t]\n\\centering\n\\begin{tikzpicture}\n\\tikzset{>=latex}\n\\begin{scope}[xshift=2cm]\n%%% Node\n\\draw (0.3,12.49) node[draw,anchor=west, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (node) {\\Longstack[c]{\\textbf{IoT node} \\\\Alice ID-$A$}};\n\n%%% Messages \n\\draw[thick,dashed, <->] (1.4,11) -- (7.4,11) node[midway,above] {Pilots exchange} node[midway,below] {Link established};\n\\draw[thick,dashed, ->] (1.4,9.2) -- (7.7,9.2)\nnode[midway,above] {$(A||\\texttt{Request})$ };\n\\draw[thick,dashed, <-] (1.1,6) -- (7.4,6) node[midway,above] {\\Longstack[l]{$(Ch_1|| Ch_2|| A_{\\texttt{ID},1}|| \\mathcal{C}_{emerg}|| \\mathcal{A}_{\\texttt{ID},emerg})$}};\n\\draw[thick,dashed, ->] (1.4,1.8) -- (7.7,1.8) node[midway,above] {\\Longstack[l]{$(R_2|| \\mathcal{R}_{emerg}||K_{R,1}||\\mathcal{K}_{R,emerg})$}};\n\n%%% All Wifi symbols \n\\draw[thick,radiation,decoration={angle=45}](7.7,11) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,11) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,9.2) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](7.7,6) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,1.8) -- +(0:0.25);\n\n\n%%% Computations at node \n\n\\draw (0.3,4) node[draw, anchor=west, rounded corners=1pt,line width=1pt, text width=6.8cm, align=left] (node2) {\\Longstack[l]{\n$R_1=P_A(Ch_1)$\\\\\n$R_2=P_A(Ch_2)$\\\\\n$\\mathcal{R}_{emerg}=P_A(\\mathcal{C}_{emerg})$\\\\\n$\\texttt{Gen}(R_1)=(H_{R,1},K_{R,1})$\\\\\n$\\texttt{Gen}(\\mathcal{R}_{emerg})=(\\mathcal{H}_{\\mathcal{R},emerg},\\mathcal{K}_{R,emerg})$\\\\\n\\textbf{Store}: $A_{\\texttt{ID},1}, K_{R,1}, \\mathcal{K}_{R,emerg}, \\mathcal{A}_{\\texttt{ID},emerg}$\n}};\n\n \n%%% Connection lines between rectangles\n\\coordinate[left=0.5cm of node.south] (node00);\n \\draw[thick] (node00.south)--(node00|-node2.north);\n%  \\draw[thick] (node.south)--(node|-node2.north);\n\\coordinate (d1) at (1.1,0);\n \\draw[thick] (d1.north)--(d1|-node2.south);\n \n\n\\end{scope}\n\n\\begin{scope}[xshift=8.5cm]\n%%% AP node\n\\draw (2,12.49) node[draw,anchor=east, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (server) {\\Longstack[c]{  \\textbf{Server} \\\\Bob ID-$B$}};\n\n%%% Computations at server\n\\draw (2,7.8) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=5cm, align=left]  (server2) {\\Longstack[l]{%\\textbf{Read}: RSSI\\\\\n%\\textbf{Set}: proximity threshold $\\zeta$ for $A$\\\\\n\\textbf{Generate}: $Ch_1, Ch_2, A_{\\texttt{ID},1},$\\\\ \n\\hspace{1.6cm}$\\mathcal{C}_{emerg}, \\mathcal{A}_{\\texttt{ID},emerg}$}};\n\\draw (2,0.6) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=5cm, align=left]  (server3) {\\Longstack[l]{\\textbf{Store}: $A_{\\texttt{ID},1}, K_{R,1}, Ch_2, R_2$,\\\\\n%$\\zeta$,\n$\\mathcal{C}_{emerg}, \\mathcal{R}_{emerge}$,\\\\\n$\\mathcal{K}_{R,emerg},\\mathcal{A}_{\\texttt{ID},emerg}$}};\n\n%Connection lines for server\n\\coordinate[right=0.5cm of server.south] (server00);\n\\draw[thick] (server00.south)--(server00|-server2.north);\n\\coordinate[right=1.85cm of server2.south] (server22);\n\\draw[thick] (server22.south)--(server22|-server3.north);\n\\end{scope}\n\\end{tikzpicture}\n% }\n\\caption{Enrollment phase}\n\\label{fig:enrollment}\n\\end{figure}\n\n\\subsection{Device enrollment}\nThe enrollment is a one-time operation carried out over a secure channel between Alice (referred to in the following as node $A$) and Bob (referred to in the following as node $B$). The steps taken during enrollment are summarized in Fig. \\ref{fig:enrollment} and are performed as follows:\n\\begin{enumerate}\n    \\item In order to establish the link between them, both devices need to exchange pilot signals. During this exchange $A$ measures the RSSI. Furthermore $A$ downloads (or creates) a map of the premises which contains the location of $B$ to enable proximity based authentication. \n    \\item  After establishing the connection, Alice sends her ID $A$ with a request for registration \\texttt{Request}.\n    \n     \n    \\item   Upon receiving the request, $B$ first  checks if the received ID has already been registered. If $B$ finds the ID within his database the request is rejected. If $A$ has not been registered % $B$ links the ID $A$ with the computed proximity range(s) $\\zeta$.\n    $B$ generates two initial PUF challenges $Ch_1, Ch_2$ and an initial one-time alias ID  ${A}_{\\texttt{ID},1}$. These challenges will be used during subsequent authentication and will be updated with each run of the protocol. Next, $B$ generates \\textit{sets} of emergency challenges and one-time alias IDs $\\mathcal{C}_{emerg}$ and $\\mathcal{A}_{\\texttt{ID},emerg}$, respectively, such that $|\\mathcal{C}_{emerg}|=|\\mathcal{A}_{\\texttt{ID},emerg}|$. The emergency sets are used only in a case of de-synchronisation between the devices and have multiple entries to allow for multiple recoveries. Finally, Bob sends the message $(Ch_1|| Ch_2|| A_{\\texttt{ID},1}|| \\mathcal{C}_{emerg}|| \\mathcal{A}_{\\texttt{ID},emerg})$ to Alice. Note that the two emergency sets are linked such that each element has a corresponding one in the other set.\n    \\item After receiving the message, Alice excites her PUF $P_A$ with $Ch_1, Ch_2$ and all challenges from the set $\\mathcal{C}_{emerg}$, producing responses $R_1, R_2$ and $\\mathcal{R}_{emerg}$, respectively. Next, she uses $R_1$ and $\\mathcal{R}_{emerg}$ as inputs to her fuzzy extractor to generate the pair $(H_{R,1}, K_{R,1})$ and the sets of pairs $(\\mathcal{H}_{R,emerg}, \\mathcal{K}_{R, emerg})$. Afterwards, Alice stores ${A}_{\\texttt{ID},1}, K_{R,1}, \\mathcal{K}_{R, emerg}, \\mathcal{A}_{\\texttt{ID},emerg}$ and sends the following message to Bob $(R_2||\\mathcal{R}_{emerg}|| K_{R,1}|| \\mathcal{K}_{R,emerg})$.\n    \\item To finalise the registration process, $B$ stores the following elements that correspond to ID $A$ in his database: %proximity range(s) $\\zeta$, \n    initial authentication parameters ${A}_{\\texttt{ID},1}, K_{R,1}, Ch_2, R_2$ and emergency authentication parameters in case of de-synchronisation $\\mathcal{C}_{emerg}, \\mathcal{R}_{emerge}, \\mathcal{K}_{R,emerg}, \\mathcal{A}_{\\texttt{ID},emerg}$.\n\\end{enumerate}\n\n\\subsection{Authentication}\n\\begin{figure}[!ht]\n\\centering\n% \\resizebox{6cm}{!}{\n\\begin{tikzpicture}\n\\tikzset{>=latex}\n\\begin{scope}[xshift=2cm]\n%%% Node\n\\draw (0.3,12.49) node[draw,anchor=west, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (node) {\\Longstack[c]{\\textbf{IoT node} \\\\Alice ID-$A$}};\n\n%%% Messages \n\\draw[thick,dashed, <->] (1.4,11) -- (7.4,11) node[midway,above] {Pilots exchange} node[midway,below] {Link established};\n\\draw[thick,dashed, ->] (1.4,8.2) -- (7.7,8.2)\nnode[midway,above] {$(A_{\\texttt{ID},1}||N_1)$ };\n\\draw[thick,dashed, <-] (1.1,4.5) -- (7.4,4.5) node[midway,above] {\\Longstack[l]{\\textcolor{black}{$(C_B|| T_B)$}}};\n\\draw[thick,dashed, ->] (1.4,-3) -- (7.7,-3) node[midway,above] {\\Longstack[l]{\\textcolor{black}{$(C_A||T_A|| H_{R',2})$}}};\n\\draw[thick,dashed, <->] (1.4,-7.8) -- (7.4,-7.8) node[midway,above] {Secure communication} node[midway,below] {Generate $Z$};\n\n%%% All Wifi symbols \n\\draw[thick,radiation,decoration={angle=45}](7.7,11) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,11) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,8.2) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](7.7,4.5) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,-3) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](7.7,-7.8) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,-7.8) -- +(0:0.25);\n\n%%% Computations at node \n\\draw (.3,9.7) node[draw, anchor=west, rounded corners=1pt,line width=1pt, text width=3.8cm, align=left] (node1) {\\Longstack[l]{Fast proximity estimation\\\\Generate: $N_1$\\\\ Obtain: ${Y}_A, {S}_A, {K}$}};\n\\draw (.3,1) node[draw, anchor=west, rounded corners=1pt,line width=1pt, text width=6.4cm, align=left] (node2) {\\Longstack[l]{\n$\\texttt{Ver}(K_{R1,2},C_B,T_B)$\\\\\n$\\texttt{Ds}(K_{R1,1},C_B)=(A||B||Ch_2||N_1||N_B)$\\\\\nGenerate: $N_A$\\\\\n$R_2'=P_A(Ch_2)$\\\\\n$\\texttt{Gen}(R_2')=(H_{R',2}, K_{R',2})$\\\\\n$Ch_{3}=Hash(Ch_2||N_A)$\\\\\n$Ch_{4}=Hash(Ch_3||N_B)$\\\\\n$R_3=P_A(Ch_3)$\\\\\n% $R_3^*=R_3 \\oplus N_A$\\\\\n$R_4=P_A(Ch_4)$\\\\\n% $R_4^*=R_4 \\oplus R_3$\\\\\n% $N_A^*=N_A \\oplus N_S$\\\\\n$\\texttt{Gen}(R_3)=(H_{R,3}, K_{R,3})$\\\\\n$A_{\\texttt{ID},2}=Hash(A||N_B||R_{3})$\\\\\nBreak: $K_{R',2}=(K_{R'2,1},K_{R'2,2})$\\\\\n$C_A=\\texttt{Es}(K_{R'2,1},(A||B||S_A||N_A||R_{3}|| R_4))$\\\\\n$T_A=\\texttt{Sign}(K_{R'2,2}, C_A)$\\\\\nStore: $K_{R,3}, A_{\\texttt{ID},2}$\n}};\n\n \n%%% Connection lines between rectangles\n\\coordinate[left=0.5cm of node.south] (node00);\n \\draw[thick] (node00.south)--(node00|-node1.north);\n\\coordinate[left=1.25cm of node1.south] (node11);\n \\draw[thick] (node11.south)--(node11|-node2.north);\n\\coordinate (d1) at (1.1,-8.2);\n \\draw[thick] (d1.north)--(d1|-node2.south);\n \n%  \\draw (4.75,-8) node[draw, double arrow, text width=5.7cm, align=center] {Secure Communication, Generate $z$}; \n\n\\end{scope}\n\n\\begin{scope}[xshift=8.5cm]\n%%% Server node\n\\draw (2,12.49) node[draw,anchor=east, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (server) {\\Longstack[c]{  \\textbf{Server} \\\\Bob ID-$B$}};\n\n%%% Computations at server\n\\draw (2,9.9) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=3cm, align=left] (server1) {\\Longstack[l]{%Proximity detection\\\\ \nObtain: ${Y_B}$}};\n\\draw (2,6.6) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=5.8cm, align=left]  (server2) {\\Longstack[l]{Verify: $A$ is at the expected distance\\\\\nRead: CRP $(Ch_2,R_2)$ for $A_{\\texttt{ID},1}$\\\\\nBreak: $K_{R,1}=(K_{R1,1}, K_{R1,2})$\\\\\nGenerate: $N_B$\\\\\n$C_B=\\texttt{Es}(K_{R1,1},(A||B||Ch_2||N_1||N_B)\\textcolor{red}{)}$\\\\\n$T_B=\\texttt{Sign}(K_{R1,2},C_B)$\n}};\n\\draw (2,-5.2) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=6.6cm, align=left]  (server3) {\\Longstack[l]{$\\texttt{Rep}(R_2, H_{R',2}) \\isitequal K_{R',2}$\\\\\n$\\texttt{Ver}(K_{R'2,2}, C_A, T_A)$\\\\\n$\\texttt{Ds}(K_{R'2,1},C_A)=(A||B||S_A||N_A||R_{3}|| R_4))$\\\\\n% $N_A=N_A^* \\oplus N_S$ \\\\\n% $C_3=H(C_2||N_A)$\\\\\n$Ch_3=Hash(Ch_2||N_A)$\\\\\n$Ch_4=Hash(Ch_3||N_B)$\\\\\n% $R_3=R_3^* \\oplus N_A$\\\\\n% $R_4=R_4^* \\oplus R_3$\\\\\n$\\texttt{Gen}(R_3)=(H_{R,3},K_{R,3})$\\\\\n$A_{\\texttt{ID},2} = Hash(A||N_B||R_{3})$\\\\\n\\textcolor{black}{Obtain: $K$}\\\\\nStore: $K_{R,3}, A_{\\texttt{ID},2}, Ch_{4}, R_{4}$\n}};\n\n%Connection lines for server\n\\coordinate[right=0.5cm of server.south] (server00);\n\\draw[thick] (server00.south)--(server00|-server1.north);\n\\coordinate[right=0.9cm of server1.south] (server11);\n\\draw[thick] (server11.south)--(server11|-server2.north);\n\\coordinate[right=2.25cm of server2.south] (server22);\n\\draw[thick] (server22.south)--(server22|-server3.north);\n\\coordinate (d2) at (1.22,-8.2);\n \\draw[thick] (d2.north)--(d2|-server3.south);\n\\end{scope}\n\\end{tikzpicture}\n% }\n\\caption{Authentication protocol}\n\\label{fig:authentication}\n\\end{figure}\n\nOnce the enrollment is finished, both devices can use the established parameters for  authentication. The steps taken during authentication are summarized in Fig. \\ref{fig:authentication} and are performed as follows:\n\\begin{enumerate}\n    \\item The devices exchange pilot signals and observe $X_A, X_B$, respectively, which they subsequently quantize to bit strings ${Y}_A$ and ${Y}_B$, correspondingly. From this step, $A$ also measures the RSSI of the received signals.\n    \\item Next, $A$ runs the proximity verification discussed in Section \\ref{sec:proximity} to confirm the location of $B$. If the verification fails, she stops the authentication process. If it succeeds, she completes the steps of the SKG process, calculating her syndrome ${S}_A$ and key ${K}$. The key will be used later as a session key if the authentication is successful. Then, $A$ sends her request for authentication which contains a one-time alias ID $A_{\\texttt{ID},i}$ and a fresh random nonce $N_1$.\n    \\item Upon reception, \n    %$B$ first confirms whether $A$ is at the expected distance. If the check fails, he rejects the authentication request. If it succeeds he\n    $B$ accesses the database and loads the parameters that corresponds to the ID, i.e., CRP $(Ch_2, R_2)$ and key ${K}_{R,1}$. Then he generates a fresh random nonce $N_B$ and breaks $K_{R1}$ into two parts as follows: $K_{R,1}=(K_{R1,1},K_{R1,2})$. He uses the first part to encrypt $C_B=\\texttt{Es}(K_{R1,1},(A||B||Ch_2||N_1||N_B))$,  and uses the second part to sign $M_B$ as: $T_B=\\texttt{Sign}(K_{R1,2},C_B)$. Finally, he  sends the ciphertext $M_B$ and the signature $T_B$ to $A$.\n    \\item By using her stored key $K_{R,1}$, $A$ verifies the authenticity of $B$ and the integrity of the message $M_B$. If one of the verification checks fail $A$ rejects the message's claim to authenticity. If the verification succeeds she accepts and excites her PUF with the received challenge $Ch_2$. By running it on her PUF she obtains a new measurement $R'_2=P_A(Ch_2)$ and $\\texttt{Gen}(R'_2)=({H}_{R',2},K_{R',2})$. Afterwards, she generates a new fresh random nonce $N_A$ and calculates the next two challenges as follows: $Ch_{3}={Hash}(Ch_2||N_A)$ and $Ch_{4}={Hash}(Ch_3||N_B)$. Next, she excites her PUF to produce $R_{3}$ and $R_{4}$. In order to generate the key that will be used in a future execution of the authentication protocol, $A$ executes $\\texttt{Gen}(R_3)=({H}_{R,3}, K_{R,3}) $. Next, she calculates the one-time alias ID for future execution of the protocol as $A_{\\texttt{ID},2}={Hash}(A||N_B||R_{3})$ which due to the randomness of $N_B$ and $R_3$, cannot be linked to $A_{\\texttt{ID},1}$. The pairs $(Ch_{4}, R_{4})$ and $(K_{R3}, A_{\\texttt{ID},2})$ will be used in a subsequent connection with $B$. Next, $A$ breaks her key $K_{R',2}$ into two parts $K_{R',2}=(K_{R'2,1},K_{R'2,2})$. Similarly, to the previous step she uses half of the key to encrypt the message $C_A=\\texttt{Es}(K_{R'2,1},(A||B||S_A||N_A||R_{3}|| R_4))$.\n    %where: $N_A^*=N_A \\oplus N_S, R_{3}^*=R_3 \\oplus N_A, R_4^*=R_4 \\oplus R_3$.\n    Then, $A$ uses the second half of the key to sign the ciphertext $T_A=\\texttt{Sign}(K_{R'2,2},C_A)$. Finally, $A$  sends $C_A$, $T_A$ and ${H}_{R',2}$ to $B$ and stores the pair $K_{R,3}, A_{\\texttt{ID},2}$.\n    \\item Upon receiving the preceding message, $B$ verifies the condition $\\texttt{Rep}(R_2, {H}_{R',2}) \\isitequal K_{R',2}$ by using the stored $R_2$ (from the enrollment phase) and the received helper data ${H}_{R',2}$. If the verification fails, $B$ rejects the claim to authenticity. If the claim is accepted, he verifies the integrity of $C_A$ using the signed ciphertext $T_A$. Next,\n    %, using $N_S$ he obtains $N_A=N_A^*\\oplus N_S$, $R_3=R_3^* \\oplus N_A$ and $R_4=R_4^* \\oplus R_3$.\n    using $R_3$ and the principles of the fuzzy extractor $B$ performs $\\texttt{Gen}(R_3)=({H}_{R,3}, K_{R,3})$. He calculates $A_{\\texttt{ID},2}={Hash}(A||N_B||R_3)$. Following that, he stores the pairs $(K_{R,3}, A_{\\texttt{ID},2}), (Ch_{4}, R_{4})$ which will be used during the next round of the protocol. Finally, using the received syndrome ${S}_A$, $B$ corrects the discrepancies in his observation ${Y}_B$ to obtain ${Y}_A$ and calculates the session key  $K=Hash({Y}_A)$.\n    \\item After the authentication process finishes $A$ and $B$ enter the secure communication stage with session key $K$. During this stage, they generate a resumption secret ${Z}$, leveraging SKG. Instead of performing full authentication in subsequent sessions, the secret can be used as a parameter to quickly ``resume\" sessions in 0-RTT. \n\\end{enumerate}\n\n\\subsection{Resumption protocol}\n\n\n\\begin{figure}[!ht]\n\\centering\n% \\resizebox{12cm}{!}{\n\\begin{tikzpicture}\n\\tikzset{>=latex}\n\\begin{scope}[xshift=2cm]\n%%% Node\n\\draw (0.3,12.49) node[draw,anchor=west, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (node) {\\Longstack[c]{\\textbf{IoT node} \\\\Alice ID-$A$}};\n\n%%% Messages \n\\draw[thick,dashed, <->] (1.4,11) -- (7.4,11) node[midway,above] {Pilots exchange} node[midway,below] {Link established};\n\\draw[thick,dashed, ->] (1.4,4.6) -- (7.7,4.6)\nnode[midway,above] {$(S^*|| A_{\\texttt{ID},i}|| N_1|| C|| T)$};\n\\draw[thick,dashed, <->] (1.4,-1) -- (7.4,-1) node[midway,above] {Secure communication} node[midway,below] {Update $Z$};\n\n\n%%% All Wifi symbols \n\\draw[thick,radiation,decoration={angle=45}](7.7,11) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,11) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,4.6) -- +(0:0.25);\n\\draw[thick,radiation,decoration={angle=45}](7.7,-1) -- +(180:0.25);\n\\draw[thick,radiation,decoration={angle=45}](1.1,-1) -- +(0:0.25);\n\n\n%%% Computations at node \n\\draw (0.3,7.9) node[draw, anchor=west, rounded corners=1pt,line width=1pt, text width=4.3cm, align=left] (node1) {\\Longstack[l]{Fast proximity estimation\\\\\nEstimate: $Y_A$\\\\\nGenerate: $N_1$\\\\ \nRead: Resumption secret $Z$\\\\\n$Y^*=Z \\oplus Y_A$\\\\\nPerform SKG using $Y^*$:\\\\\nObtain: $S^*$, $K^*=Hash(Y^*)$\\\\\n$A_{\\texttt{ID},i+1}=Hash(A||Y_A)$\\\\\nBreak: $K^*=(K^*_1, K^*_2)$\\\\\n$\\texttt{Es}(K^*_1,M)=C$\\\\\n$\\texttt{Sign}(K^*_2,C)=T$\\\\\nStore: $A_{\\texttt{ID},i+1}$}};\n\n\n \n%%% Connection lines between rectangles\n\\coordinate[left=0.5cm of node.south] (node00);\n \\draw[thick] (node00.south)--(node00|-node1.north);\n% \\coordinate[right=1.2cm of node1.south] (node11);\n\\coordinate (d1) at (1.1,-1.5);\n \\draw[thick] (d1.north)--(d1|-node1.south);\n \n %%Arrow\n% \\draw (4.75,-0.8) node[draw, double arrow, text width=5.7cm, align=center] {Secure Communication, Update $z$};\n\\end{scope}\n\n\\begin{scope}[xshift=8.5cm]\n%%% Server node\n\\draw (2,12.49) node[draw,anchor=east, rounded corners=13pt,line width=1pt, text width=2.3cm, align=center] (server) {\\Longstack[c]{  \\textbf{Server} \\\\Bob ID-$B$}};\n\n%%% Computations at server\n\\draw (2,9.8) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=2.8cm, align=left] (server1) {\\Longstack[l]{%Proximity detection\\\\\nEstimate: $Y_B$}};\n\\draw (2,2) node[draw, anchor=east, rounded corners=1pt,line width=1pt, text width=5.5cm, align=left]  (server2) {\\Longstack[l]{Verify: $A$ is at the expected distance\\\\\nRead: Resumption secret $Z$\\\\\n$Y^{*'}=Z \\oplus Y_B$\\\\\nFinish SKG: $(Y^{*'},S^*)=(Y^*)$\\\\\n$K^{*'}=Hash(Y^*)$\\\\\n$K^{*'} \\isitequal K^{*}$\\\\\n$\\texttt{Ver}(K_2^*, C, T)$\\\\\n$\\texttt{Ds}(K_1^*, C)=M$\\\\\n$Y_A=Y^* \\oplus Z$\\\\\n$A_{\\texttt{ID},i+1}=Hash(A||Y_A)$\\\\\nStore: $A_{\\texttt{ID},i+1}$\n}};\n\n\n%Connection lines for server\n\\coordinate[right=.5cm of server.south] (server00);\n\\draw[thick] (server00.south)--(server00|-server1.north);\n\\coordinate[right=0.75cm of server1.south] (server11);\n\\draw[thick] (server11.south)--(server11|-server2.north);\n\\coordinate (d2) at (1.2,-1.5);\n \\draw[thick] (d2.north)--(d2|-server2.south);\n\n\n\n\\end{scope}\n\\end{tikzpicture}\n% }\n\\caption{Resumption protocol}\n\\label{fig:resumption}\n\\end{figure}\n\nThis Section presents a novel physical layer resumption protocol that allows $A$ to send encrypted data in 0-RTT. During the secure communication stage of the authentication protocol in Fig. \\ref{fig:authentication}, $B$ sends to $A$ a look-up identifier. Then, both derive a resumption secret $Z$ that is a function of the look-up identifier and the session parameters. \n% and session keys have the same length $|K|$.\nThe usage of a resumption secret for authentication helps avoid man-in-the-middle attacks in the scenario assumed here. Given the above, the resumption protocol follows the steps:\n\n\\begin{enumerate}\n    \\item As before, in order to establish the link both devices perform pilot exchange. $A$ and $B$ obtain  channel observations and generate sequences $Y_A$ and $Y_B$, respectively. Furthermore, $A$ measures the RSSI. Note that, $Z$ \\textcolor{black}{and  $Y_A, Y_B$ have the same length.} \n    \\item Following the above, $A$ performs the proximity detection mechanism to verify whether Bob is at the expected location. If the verification fails, she aborts the connection. If the verification succeeds she generates a fresh random nonce $N_1$ and reads the resumption secret $Z$ to generate $Y^*=Z \\oplus Y_A$. Then, using her Slepian Wolf decoder she calculates the new syndrome $S^*$, that corresponds to $Y^*$, and generates the session key as $K^*=Hash(Y^*)$. She also calculates the one-time alias ID that will be used for subsequent session as: $A_{\\texttt{ID},i+1}=Hash(A||Y_A)$. $A$ breaks her key into two parts $K^*=(K_1^*, K_2^*)$ and uses the first part to encrypt the early 0-RTT data $M$ as $\\texttt{Es}(K^*_1,M)=C$. The second part she uses to sign the cipher text $\\texttt{Sign}(K^*_2,C)=T$. Finally, she sends $(S^*|| A_{\\texttt{ID},i}|| N_1|| C|| T)$. Note that the key ${K^*}$ can only be obtained if both the physical layer generated key and the resumption key are valid and this method can be shown to be forward secure~\\cite{0-RTT_example}.\n    \\item Upon receiving that, $B$  reads the resumption secret $Z$ and obtains $Y^{*'}=Z \\oplus Y_B$. Using that and the received syndrome $S^*$, $B$ obtains $K^*=Hash(Y^*)$. He uses the condition $K^{*'} \\isitequal K^{*}$ to verify the authenticity of $A$ and the integrity of the message. If the above succeeds he  calculates $Y_A=Y^* \\oplus Z$ and stores $A_{\\texttt{ID},i+1}=Hash(A||Y_A)$.\n    \\item After the resumption process finishes the two devices enter the secure communication stage using $K^*$ as a session key. During the secure  communication stage, they use the channel and session properties  to  generate  new shared resumption secrets that can be used in subsequent resumptions. \n\\end{enumerate}\n\n\n\\section{Security Analysis}\\label{sec:sec_analysis}\n\\TODO{rearrange this, remove proof where it is not a clear proof, call these properties(?), put properties first, then proofs}\nIn this Section, we analyze the security of the proposed multi-factor authentication protocol illustrated in Fig.\\ \\ref{fig:authentication}. For the purpose of our security proofs we consider a Dolev-Yao \\cite{dolev_yao} type of adversary, who has control over the wireless channel between $A$ and $B$. Furthermore: 1) the adversary can send any type of messages and queries using its knowledge gained through observation; 2) all functions and operations performed by the legitimate users  during the execution of the protocol are public except from $P_A(\\cdot)$ and the entire enrollment phase; and, 3) the adversary can launch denial of service (DoS) attacks and block parts of the protocol in order to de-synchronize the connection between $A$ and $B$. In terms of the SKG, for simplicity, in this work we assume a rich Rayleigh multipath environment where the adversary is more than a few wavelengths away from each of the legitimate parties and the SKG rates are given as in Section III. %This forms the basis of our hypothesis that the measurements of $A$ and $B$ are uncorrelated to the adversary's observations. \n\n\n\\subsection{Mutual authentication}\nThe proposed protocol uses a set of factors to achieve mutual authentication. It uses a fast  proximity estimation as a first factor of authentication. This verifies whether the server %both parties are \nis at the expected distance. Next, $A$ authenticates $B$ by verifying whether the correct key is used for creating $C_B$ and $T_B$. On the other hand, $B$ authenticates $A$ by first confirming the validity of the received one-time alias ID $A_{\\texttt{ID},i}$ and second by verifying whether she produced a valid response to $Ch_i$. The second condition is confirmed only if $A$ uses the correct key to generate the pair $C_A$, $T_A$.   \n\n\\subsection{Untraceability and anonymity}\nDuring the execution of the authentication protocol, $A$ must posses a valid one-time alias ID ${A}_{\\texttt{ID}}$ for each session. The one-time alias identity cannot be used twice and there is no direct relationship between subsequent IDs. Thus, no one except $B$ would know the origin of the message. Furthermore, in case of de-synchronization the device can use the set of emergency IDs $\\mathcal{A}_{\\texttt{ID},emerg}$. After using an emergency ID it has to be deleted from $A$'s and $B$'s memory. This approach provides privacy against eavesdroppers and ensures user's anonymity and identity untraceability properties.\n\n\\subsection{Perfect forward secrecy}\nAssuming an attacker compromises $A$ and obtains all stored secrets, i.e., $(K_R, A_{\\texttt{ID}})$, he cannot obtain previous keys or one-time alias IDs. First, each $K_R$ is generated using a CRP and CRPs are randomly generated and independent. Hence, by obtaining $K_{R,i}$ an adversary cannot learn $K_{R,i-1}$. Next, one-time alias IDs are generated using a one-way hash function of unique parameters for each session; if an adversary obtains $A_{\\texttt{ID},i}$, he can not inverse the hash function. Furthermore, using the randomness of the wireless channel ensures that session keys are unique and independent for each session. Therefore, the proposed authentication protocol ensures the perfect forward secrecy property.\n\n\\subsection{Protection against replay attack}\\label{subsec:replay_attacks}\nIf an adversary intercepts previous communication between $A$ and $B$, he can replay the same messages and try to pass the authentication process. In the protocol presented in Fig.\\ \\ref{fig:authentication} none of the parameters in the initial request are allowed to be sent twice, hence, if an attacker resends the same message to $B$ the attack will be detected and the request will be rejected. Next, if the adversary tries to re-send $C_B$ to $A$, he will be detected, since the key used to encrypt $C_B$ is changed during every session. Similarly, if the adversary tries to re-send $C_A$, he will be detected and the request will be rejected because the key used to encrypt $C_A$ is changed every session. The above shows that the proposed protocol provides resistance against replay attacks.\n\n\\subsection{Protection against impersonation attack}\nA successful impersonation attack will allow the adversary to be authenticated as a legitimate user. Following from above, an adversary cannot perform a replay attack, which limits his options to perform an impersonation attack. Following from that, in order to impersonate $A$ he must generate 1) a valid one-time alias ID, and, 2) a valid ciphertext $C_A$. %, 3) be at the expected distance from $B$.\nHowever, due to the unclonability properties of the PUF and the fact that the connection between a device and its PUF is secure, (i.e., system on chip) the adversary cannot generate a valid ciphertext $C_A$,  hence cannot impersonate $A$. Next, in order to impersonate $B$, the adversary must posses a valid key $K_{R,1}$ and generate a valid ciphertext $C_B$. To obtain the key an adversary must compromise $A$ (an example of such a scheme vulnerable to this attack can be found in \\cite{Auth_protocol_pre-shared-key}). However, even if $A$ gets compromised the attack will be detected using the proposed proximity detection approach. This shows that our multi-factor authentication protocol provides resistance against impersonation attacks.\n\n\\subsection{Resistance to DoS attack}\nTo ensure security against DoS and de-syncronization attacks, the authentication protocol uses unlinkable one-time alias IDs and pairs of sets with emergency parameters $(\\mathcal{C}_{emerg}, \\mathcal{R}_{emerge})$ and $(\\mathcal{K}_{R,emerg}, \\mathcal{A}_{\\texttt{ID},emerg})$. If an adversary manages to block a message from a legitimate party, such that it does not reach its intended receiver, the authentication process will stop and the used $A_{\\texttt{ID},i}$ will not be updated. To overcome that $A$ can use one of her emergency IDs from the set $\\mathcal{A}_{\\texttt{ID},emerg}$. $B$ will then read the corresponding ${K}_{R,emerg}$ from the set $\\mathcal{K}_{R,emerg}$ and use it to encrypt a message containing an emergency challenge ${C}_{emerg}$ from the set $\\mathcal{C}_{emerg}$. Next, both parties can continue the authentication process as usual and setup a new one-time alias ID. In order to prevent replay attacks all used emergency parameters must be deleted from the corresponding set. This approach provides resiliency against DoS to de-synchronization attacks.\n\n\\subsection{Protection against cloning attacks}\nA successful cloning attack allows the adversary to use a captured device in order to obtain secrets stored on another device. In the proposed protocol each device posses a unique pair $(K_R, A_{\\texttt{ID}})$. Furthermore, all devices have unique PUFs and will produce a unique response to a challenge. Hence, the adversary cannot use secrets derived from one device in order to clone another. \n\n\n\\begin{figure*}\n\\begin{tikzpicture}\n\\node at (0,3.5) { $\n\\begin{aligned}\n\\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle B \\believes \\fresh{N_B} \\wedge B \\sees{K_{R',2}} R_3 \\mathfrak{R} N_B}{\\scriptstyle B \\believes \\fresh{R_3}}  \\wedge \\frac{ \\scriptstyle B \\believes A \\sharekey{K_{R',2}} B \\wedge B \\sees{K_{R',2}} R_3 }{\\scriptstyle B \\believes A \\oncesaid{K_{R',2}} R_{3}}}{\\scriptstyle B \\believes A \\believes A \\sharekey{K_{R,2}'} B}  \\wedge B \\believes A \\believes A^c \\unavailable R_3 \\wedge B \\believes A \\oncesaid{K_{R,2}'} R_3}{{\\scriptstyle B \\believes A \\believes \\{B \\cup A \\}^c \\unavailable R_3} } \\wedge B \\believes \\trusted{A}}{{\\scriptstyle B \\believes\\{ B \\cup A \\}^c \\unavailable R_3} } \\wedge B \\believes \\fresh{R_3}}{ \\scriptstyle B \\believes A \\sharekey{R_3} B}  \\nonumber   \n\\end{aligned}$};\n\\node at (0,1.5) { (a)};\n\n\\node at (8.1,4.3) { $\n\\begin{aligned}\n\\scriptstyle \\cfrac{\\scriptstyle \\cfrac{ \\scriptstyle A \\believes A \\sharekey{K_{R,2}'} B \\wedge A \\believes B^c \\unavailable R_3 \\wedge A \\oncesaid{K_{R,2}'} R_3}{ \\scriptstyle A \\believes \\{A \\cup B\\}^c \\unavailable R_3} \\wedge A \\believes \\fresh{R_3}}{ \\scriptstyle A \\believes A \\sharekey{R_3} B}\n\\end{aligned}$};\n\\node at (8.1,1.5) { (b)};\n\n\\node at (0,-1) { $\n\\begin{aligned}\n\\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle \\cfrac{ \\scriptstyle A \\believes \\fresh{N_1} \\wedge A \\sees{K_{R,1}} N_B \\mathfrak{R} N_1}{\\scriptstyle A \\believes \\fresh{N_B}}  \\wedge \\frac{ \\scriptstyle A \\believes A \\sharekey{K_{R,1}} B \\wedge A \\sees{K_{R,1}} N_B }{\\scriptstyle A \\believes B \\oncesaid{K_{R,1}} N_B}}{\\scriptstyle A \\believes B \\believes A \\sharekey{K_{R,1}} B}  \\wedge A \\believes B \\believes B^c \\unavailable N_B \\wedge A \\believes B \\oncesaid{K_{R,1}} N_B}{{\\scriptstyle A \\believes B \\believes \\{A \\cup B \\}^c \\unavailable N_B} } \\wedge A \\believes \\trusted{B} }{{\\scriptstyle A \\believes\\{ A \\cup B \\}^c \\unavailable N_B} } \\wedge A \\believes \\fresh{N_B}}{ \\scriptstyle A \\believes A \\sharekey{N_B} B}  \\nonumber    \n\\end{aligned}$};\n\\node at (0,-3) { (c)};\n\n\\node at (8.1,-0.2) { $\n\\begin{aligned}\n\\scriptstyle \\cfrac{\\scriptstyle \\cfrac{ \\scriptstyle B \\believes A \\sharekey{K_{R,1}} B \\wedge B \\believes A^c \\unavailable N_B \\wedge B \\oncesaid{K_{R,1}} N_B}{ \\scriptstyle B \\believes \\{B \\cup A\\}^c \\unavailable N_B} \\wedge B \\believes \\fresh{N_B}}{ \\scriptstyle B \\believes A \\sharekey{N_B} B}\n\\end{aligned}$};\n\\node at (8.1,-3) { (d)};\n\\end{tikzpicture}\n\\caption{Secrecy proofs: (a) $B$ believes $R_3$ is a good shared secret between $A$ and $B$; (b) $A$ believes $R_3$ is a good shared secret between $A$ and $B$; (c) $A$ believes $N_B$ is a good shared secret between $A$ and $B$; (d) $B$ believes $N_B$ is a good shared secret between $A$ and $B$.} \\label{fig:secrecy_proofs_ban_logic}\n\\end{figure*}\n\n\\subsection{Protection against physical attacks}\nSuccessful physical attacks could be performed by physical tampering of the IoT device in order to change its behavior. However, by changing its behavior, the PUF will not produce the desired response and therefore $B$ will detect the attack. Therefore, the proposed protocol is resistant against physical attacks.\n\n\\subsection{Secrecy proofs using BAN and MB logic}\nThe secrecy evaluation of security protocols  ensures that an adversary cannot obtain or alter secret parameters. In this regards, the BAN logic~\\cite{Ban_logic} is a widely used secrecy verification tool. However, some weaknesses were identified by the authors of \\cite{Mao_Boyd}. They extended and improved the BAN logic to a more reliable version, namely MB logic, which is used in this paper. Formal proofs are deduced using a set of initial beliefs and rules and are based upon the message exchange within the protocol. The initial steps of MB logic are idealization of the protocol and identification of the initial beliefs. The protocol message idealization is used to interpret the implicit context-dependent information into explicit protocol specification. Based on the set of rules defined in~\\cite{Mao_Boyd}, the protocol in Fig. \\ref{fig:authentication} is idealised as:\n\\begin{enumerate}\n    \\item $A \\rightarrow B : A,N_1$\n    \\item $B \\rightarrow A : \\{N_B \\mathfrak{R} N_1\\}_{K_{R,1}}$\n    \\item  $A \\rightarrow B : \\{R_3 | R_4 \\mathfrak{R} N_A {\\mathfrak{R}} N_B \\}_{K_{R,2}}$\n\\end{enumerate}\nwhere $\\mathfrak{R}$ gives the relation of the parameters, as defined in~\\cite{Mao_Boyd}. Next, denoting  principal as $A, B$, messages and keys as $M, K$, respectively and formulas as $X$, the main properties of MB logic are: $A \\believes X$ denotes $A$ believes $X$ is true; $A \\sees{K} M$ denotes $A$ sees $M$ using key $K$, if $M$ is not encrypted we have $A \\sees{} M$; $A \\oncesaid{K} M$ denotes $A$ encrypts $M$ using key $K$; $\\fresh{M}$ denotes $M$ is of type fresh; $A \\sharekey{K} B$ denotes $K$ is a good shared key between $A$ and $B$; $A \\unavailable M$ denotes $M$ is not available to $A$; $\\trusted{B}$ denotes $B$ is a super-principal. Following that, the inference rules defined in \\cite{Mao_Boyd} and used in this paper are given in Table \\ref{table_logic_rules} (Note, $\\{\\cdot\\}^C$ denotes complement).\n\\renewcommand{\\arraystretch}{2}\n\\begin{table}\n\\caption{Inference rules adopted from MB logic}\n\\label{table_logic_rules}\n\\resizebox{0.48\\textwidth}{!}{\n\\begin{tabular}{ |c|l|  }\n\\hline\n \\multicolumn{1}{|l|}{\\textbf{Notation}} & \\textbf{Description}\\\\ [0cm] \n \\hline\n$\\frac{A \\believes A \\sharekey{K} B \\wedge A \\sees{K} M }{A \\believes B \\oncesaid{K} M}$ & Authentication rule\\\\ [0.2cm]\n \\hline\n $\\frac{A \\believes A \\sharekey{K} B \\wedge B^C \\unavailable M \\wedge A \\oncesaid{K} M }{A \\believes (A \\cup B)^C \\unavailable M}$ & Confidentiality rule\\\\ [0.1cm]\n \\hline\n $\\frac{A \\believes \\fresh{M} \\wedge A \\sees{} N \\mathcal{R} M }{A \\believes \\fresh{N} }$ & Fresh rule\\\\ [0.1cm]\n \\hline\n $\\frac{A \\believes \\{A,B\\}^C \\unavailable K \\wedge A\\believes \\fresh{K}}{A \\believes A \\sharekey{K} B}$ & Good-key rule\\\\ [0.2cm]\n \\hline\n  $\\frac{A \\believes \\fresh{N} \\wedge A \\believes B \\oncesaid{K} N }{A \\believes B \\believes A \\sharekey{K} B}$ & Nonce verification rule\\\\[0.2cm]\n  \\hline\n$\\frac{A \\believes B \\believes X \\wedge A \\believes \\trusted{B}}{ A \\believes X}$ & Super-principal rule\\\\[0.1cm]\n  \\hline\n$\\frac{A \\believes X \\wedge A \\believes Y}{ A \\believes (X \\wedge Y)}$ & Belief axiom 1 \\\\[0.1cm]\n  \\hline\n$\\frac{A \\believes X \\wedge A \\believes X/Y}{ A \\believes Y}$ & Belief axiom 2\\\\[0.1cm]\n\\hline\n\\end{tabular}}\n% \\vspace{0.4cm}\n\\end{table}\nGiven the above we define the initial beliefs as follows:\n\\begin{enumerate}\n    \\item[A1] $A \\believes A \\sharekey{K_{R,1}} B$ and $B \\believes A \\sharekey{K_{R,1}} B$  \n    \\item[A2] $A \\believes A \\sharekey{K_{R,2}'} B$ and $B \\believes A \\sharekey{K_{R,2}'} B$ \n    \\item[A3] $B \\believes A \\believes A^C \\unavailable R_3 | R_4 \\mathfrak{R} N_A {\\mathfrak{R}} N_B$ \n    \\item[A4] $B \\believes \\trusted{A}$ \n    \\item[A5] $B \\sees{K_{R,2}'} R_{3}|R_{4} \\mathfrak{R} N_A \\mathfrak{R} N_B$ \n    \\item[A6] $A \\believes B^C \\unavailable R_3 | R_4 \\mathfrak{R} N_A {\\mathfrak{R}} N_B$ \n    \\item[A7] $A \\oncesaid{K_{R,2}'} R_3 | R_4 \\mathfrak{R} N_A {\\mathfrak{R}} N_B$\n    \\item[A8] $A \\believes \\fresh{N_1}$, $A \\believes \\fresh{N_A}$, $A \\believes \\fresh{R_3}$, $A \\believes \\fresh{R_4}$  \n    \\item[A9] $A \\sees{K_{R,1}} N_B \\mathfrak{R} N_1$  \n    \\item[A10] $A \\believes B \\believes B^C \\unavailable N_B$ and $B \\believes \\fresh{N_B}$ \n    \\item[A11] $A \\believes \\trusted{B}$ \n    \\item[A12] $B \\believes A^C \\unavailable N_B {\\mathfrak{R}} N_1$ \n    \\item[A13] $B \\oncesaid{K_{R,1}} N_B \\mathfrak{R} N_1$ \n    \\end{enumerate}\n\n\\begin{figure}\n\\begin{tikzpicture}\n\\node at (0,3.5) { $\n\\begin{aligned}\n \\frac{A  \\believes A \\sharekey{K_{R,1}} B \\wedge A \\sees{K_{R,1}} N_B }{A \\believes B \\oncesaid{K_{R,1}} N_B} \\end{aligned}$};\n \\node at (4.6,3.5) { $\n\\begin{aligned}\n\\frac{A \\believes A \\sharekey{K_{R',2}} B \\wedge B \\sees{K_{R',2}} N_A }{B \\believes A \\oncesaid{K_{R',2}} N_A}\n \\end{aligned}$};\n \\node at (0,2.5) { (a)};\n \\node at (4.6,2.5) { (b)};\n\\end{tikzpicture}\n% \\[ \\frac{A  \\believes A \\sharekey{K_{R,1}} B \\wedge A \\sees{K_{R,1}} N_B }{A \\believes B \\oncesaid{K_{R,1}} N_B} \\]\\\\ \\vspace{-0.6cm}\\[\\text{(a)}\\] \\\\ \\vspace{-0.5cm} \\[ \\frac{A \\believes A \\sharekey{K_{R',2}} B \\wedge B \\sees{K_{R',2}} N_A }{B \\believes A \\oncesaid{K_{R',2}} N_A} \\] \\\\ \\vspace{-0.6cm}\\[\\text{(b)}\\]\n\\caption{Proof of authentication (a) $B$ to $A$; (b) $A$ to $B$.}\n    \\label{fig:authentication_proof_formulas}%\n\\end{figure}\n\nThe authentication property of the current run of the protocol can be verified using the authentication rule as shown on Fig. \\ref{fig:authentication_proof_formulas}. The authentication of $B$ to $A$ can be achieved by the fact $A \\believes B \\oncesaid{K_{R,1}} N_B$, i.e., $A$ believes that $B$ sent $N_B$ using  $K_{R,1}$ to encrypt the message. As seen in Fig. \\ref{fig:authentication_proof_formulas}, two facts imply  authentication 1) $A \\believes A \\sharekey{K_{R,1}} B$ meaning $A$ believes that $K_{R,1}$ is a good shared secret between $A$ and $B$; 2) $A \\sees{K_{R,1}} N_B$, i.e., $A$ used $K_{R,1}$ as a decryption key to see $N_B$. Following from the fact that the enrollment stage is performed on a secure channel both of these statements are part of the initial beliefs of the protocol, hence, the authentication of $B$ to $A$ is directly established as shown on Fig. \\ref{fig:authentication_proof_formulas} a).  The authentication of $A$ to $B$ is identical following from Fig. \\ref{fig:authentication_proof_formulas} b). Next, we  prove the secrecy of parameters $R_3$ (the proofs for secrecy of $N_A$ and $R_4$ are identical) which could be used as initial belief for the next run of the protocol. First, by combining the confidentiality rule and two axioms from Table \\ref{table_logic_rules} the following rule is derived:  \n\\begin{equation}\n    \\frac{A \\!\\! \\believes \\!\\! B \\oncesaid{K} M \\wedge A \\believes B \\believes A \\sharekey{K} B \\wedge A \\believes B \\believes B^C \\unavailable M}{A \\believes B \\believes \\{A \\cup B \\}^C \\unavailable M}.\n\\end{equation}\n\n\n\n\\noindent Given that, the security proofs on Fig. \\ref{fig:secrecy_proofs_ban_logic} (a) and (b) show that both parties $A$ and $B$ agree that $R_3$ is a good shared secret (similarly, one can show the property holds for $R_4$). Given that and using the fuzzy extractor properties \\cite{fuzzy_possible} it can be concluded that $K_{R,3}$ and $K_{R,4}$ are good shared keys between $A$ and $B$. Next, Fig. \\ref{fig:secrecy_proofs_ban_logic} (c) and (d) illustrates that $A$ and $B$ agree that $N_B$ is a good shared secret. As a consequence of the above and by using the properties of privacy amplification \\cite{Generalized_PA} we can conclude that $A_{\\texttt{ID},2}$ is also a good shared secret.\n\n\\subsection{Session key agreement}\n\nIt is a common practice in literature to use nonces as part of the session key generation process \\cite{PUF_Location, Auth_protocol_pre-shared-key, Auth_protocol-sess_key-from_nonces1}. However, note that even if $N_A$ and $N_B$ are good shared secrets between $A$ and $B$ the low entropy of pseudo-random number generator (PRNG) modules may provoke a set of  attacks, such as side-channel and prediction attacks \\cite{PRNG_prediction_attack}, and lead to information leakage. Furthermore, it has been shown that true-random number generators (TRNGs) can greatly increase the time complexity in a resource limited systems making the generation time infeasible \\cite{TRNG_infeasible}. Therefore, we limit the role of the nonces in the proposed scheme to only a source of freshness. On the other hand, the randomness already present in the wireless channel allows for a secure and lightweight key generation process through the SKG procedure, as illustrated in Section III. % can be used to produce a uniform random key with size as much as~\\cite{Eurasip2020}:\n%\\begin{equation}\n%    |{K}| \\leq H({X}_A) - I({X}_A;{X_E})-H({X}_A|{X}_B)-r_0,\n%\\end{equation}\n%where $H({X}_A)$ represents the entropy of the measurement, $I({X}_A;{X_E})$ represents the mutual information between Alice's and eavesdropper's observations, $H({X}_A|{X}_B)$ represents the entropy revealed during information reconciliation -- which in our scheme is zero due to the encryption of the syndrome $S_A$, and $r_0>0$ is an extra security parameter that ensures uncertainty on the key at an eavesdropper's side. For details and estimation of these parameters in a practical scenario please see \\cite{Privacy_amplification_key-size}. \nFinally, we note that if the session key somehow gets compromised, the authentication process remains secure as the adversary cannot obtain the PUF response using the session key.\n\n\\subsection{Security verification using the Tamarin-prover}\nThe security properties of the authentication protocol given in Section \\ref{sec:authentication} were verified using the formal verification tool, Tamarin-prover~\\cite{Tamarin-prover}. Tamarin was used to prove: secrecy, aliveness, weak agreement, non-injective agreement, injective agreement, untraceablity and anonymity. The model of our authentication protocol in Tamarin syntax is provided in the supplementary material to this paper, due to space limitations. \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Conclusions}\n\\label{sec:conclusions}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\nIn this work we introduced a fast, multi-factor mutual authentication protocol for IoT systems, leveraging SKG from fading coefficients, proximity estimation using Kalman filters and PUFs. To demonstrate the SKG performance in delay constrained applications we provided a numerical comparison of three families of channel SW codes in the short and medium blocklength regimes. \nNext, we conducted a set of experiments to demonstrate the applicability of our proposed fast proximity detection in BLE networks, that leverages mobility of an IoT node. Finally, we validated the properties of the proposed authentication protocol through a detailed security analysis, using BAN and MB logic as well as the Tamarin-prover. Our analysis proves the potential of the proposed protocol as a lightweight, multi-factor alternative to the currently used computationally intensive authentication schemes, with a particular interest in IoT networks of constrained devices and wireless sensor networks.\n\n\n\\bibliographystyle{IEEEtran}\n\n\\bibliography{refs}\n\n\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:14", "yymm": "2010", "arxiv_id": "2010.14457", "url": "https://arxiv.org/abs/2010.14457", "source": "arxiv"}}
{"text": "\\documentclass[twocolumn,aps,prl,reprint]{revtex4-1}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n \\usepackage[toc,page]{appendix}\n\\usepackage[usenames,dvipsnames]{xcolor}\n%\\usepackage{tensor}\n\\usepackage[normalem]{ulem}%allows sout\n%\\usepackage{amsmath}\n%\\usepackage{amssymb}\n%\\usepackage{color}\n\\newcommand{\\tcb}{\\textcolor{blue}}\n\\newcommand{\\tcr}{\\textcolor{red}}\n\\let\\normalcolor\\relax\n\\newcommand{\\tcg}{\\textcolor{ForestGreen}}\n\\newcommand{\\tcp}{\\textcolor{purple}}\n\\newcommand{\\green}{\\textcolor{green}}\n \\newcommand{\\tco}{\\textcolor{orange}}\n\\newcommand{\\rbm}[1]{{\\color{red}\\bf [Robb: #1]}}\n\\newcommand{\\mr}[1]{{\\color{blue}\\bf [Matthew: #1]}}\n\n\\usepackage{tikz}\n\\usetikzlibrary{decorations.markings}\n\\usepackage{braket}\n\\usepackage{amsfonts}\n\\newcommand{\\Tr}{\\text{Tr}}\n\\usepackage{verbatim}\n\\usepackage{subcaption}\n\\usepackage{graphicx}\n%\\usepackage[margin=0.25in]{geometry}\n\\usepackage{tikz}\n\\usepackage{lipsum}\n\\usepackage{float}\n\n\\begin{document}\n\n\\title{Entanglement Amplification from Rotating Black Holes}\n\\author{Matthew P. G. Robbins${}^{1,2,3}$, Laura J. Henderson${}^{1,4}$, and Robert B. Mann${}^{1,2,3,4}$}\n\\affiliation{Department of Physics and Astronomy, University of Waterloo, Waterloo ON, Canada, N2L 3G}\n\\affiliation{Perimeter Institute for Theoretical Physics, 31 Caroline Street North, Waterloo ON, Canada, N2L 2Y5}\n\\affiliation{Waterloo Centre for Astrophysics, University of Waterloo, Waterloo ON, Canada, N2L 3G1}\n\\affiliation{Institute for Quantum Computing, University of Waterloo, Waterloo ON, Canada, N2L 3G}\n\n\\begin{abstract}\nThe quantum vacuum has long been known to be characterized by field   correlations between spacetime points.  These correlations can be swapped with a pair of  \nparticle detectors, modelled as simple  two-level quantum systems (Unruh-DeWitt detectors) via a process known as entanglement harvesting.   We study this phenomenon in the presence of a rotating BTZ black hole, and find that rotation can significantly amplify the harvested vacuum entanglement. Concurrence between co-rotating detectors is amplified by as much as an order of magnitude at intermediate distances from the black hole relative to that at large distances.  The effect is most pronounced for  near-extremal small mass black holes, and allows for harvesting at large spacelike detector separations.  We also find that the entanglement shadow -- a region near the black hole from which entanglement cannot be extracted -- is diminished in size as  the black hole's angular momentum increases. \n\\end{abstract}\n\n\\maketitle\n\\noindent{\\it Introduction}\\label{sec: into} $\\quad$\nThe natural entanglement of the vacuum in quantum field theory  plays a crucial role in multiple areas of physics, including black hole entropy \\cite{Solodukhin2011,Brustein2005}, the AdS/CFT correspondence \\cite{Ryu2006}, quantum information \\cite{Peres2004,Lamata1997},  \nand metrology \\cite{Ralph2009}. Quantum vacuum correlations have long been known to be between both timelike and spacelike separated regions~\\cite{summers1985bell,summers_bells_1987}, and are at the heart of\nthe black hole information paradox~\\cite{Preskill:1992tc,Mathur:2009hf} and its proposed solutions~\\cite{Almheiri:2012rt,Braunstein:2009my,Mann:2015luq}, as well as  playing a key role in quantum energy teleportation~\\cite{doi:10.1143/JPSJ.78.034001,Hotta:2011xj}.  It was  later realized   \\cite{Valentini1991} that    vacuum entanglement can be swapped with \na physical system: two initially uncorrelated atoms (either spacelike or timelike separated) interacting with the electromagnetic vacuum for a finite time can exhibit nonlocal correlations. \nThe process is best explicated in an idealized system of two qubits (modelled as Unruh-DeWitt (UDW) detectors  \\cite{Unruh1976,deWitt}) interacting\nwith a scalar field \\cite{Reznik2003,Reznik2005}. A protocol known as entanglement harvesting  \\cite{Salton2015} was then developed \nin which the entanglement in the scalar quantum vacuum is transferred to the UDW detectors. This phenomenon has proven to be very useful in\ncharacterizing properties of the quantum vacuum that are not accessible to a single detector, including the thermal character of de Sitter spacetime\n\\cite{PhysRevD.79.044027,Huang2017}, probing spacetime topology \\cite{Smith2016},  and finding new structures such as separability islands in anti-de Sitter \nspacetime \\cite{Ng:2018drz,Henderson2019}. \n\n\nSurprisingly little is known about the extraction of vacuum entanglement  for spacetimes with black holes.  \n The first such study\n \\cite{Henderson2018} indicated that black holes have entanglement shadows: a region outside the black hole within which it is not possible to\n harvest entanglement.  Although the study was carried out for the $(2+1)$-dimensional Banados-Teitelboim-Zanelli (BTZ) black hole \\cite{Banados1992}, the phenomenon is\n expected to be universal \\cite{Henderson:2019uqo}.  A recent study of entanglement harvesting   in Schwartzschild/Vaidya spacetimes is commensurate with this expectation \\cite{Tjoa2020}.\n \n We present  here the results of the first study of entanglement harvesting for rotating black hole spacetimes.  Concentrating specifically on a rotating BTZ black hole,  we find the remarkable result  that rotation markedly amplifies the harvested entanglement:   as much as a 10-fold increase in the concurrence between 2 UDW detectors at proper distances as far as 100 horizon radii from the black hole is possible. The effect is most dramatic for near-extremal small-mass black holes, and allows for harvesting at large spacelike detector separations that would otherwise yield zero concurrence.  We also find that the entanglement shadow diminishes with increasing angular momentum and that the concurrence  does not monotonically increase with increasing energy gap, in contrast to the static case.\n\n{\\it  Entanglement Harvesting Protocol}\\; \n\\label{sec: fundamentals}\nThe  light-matter interaction, assuming no angular momentum exchange, is well described as a local interaction between  a scalar quantum field $\\phi(x)$\nand a UDW detector (whose respective ground $\\ket{0}_D$ and excited $\\ket{1}_D$ states are separated by an energy gap $\\Omega_D$) moving along a spacetime trajectory $x_D(\\tau)$ \\cite{Funai:2018wqq}.  The interaction Hamiltonian is\n\\begin{align}\nH_D=\\lambda\\chi_D(\\tau)\\left(e^{i\\Omega\\tau}\\sigma^+ + e^{-i\\Omega\\tau}\\sigma^-\\right)\\otimes\\phi[x_D(\\tau)]\n\\end{align}\n%\\begin{align}\n%H_D=\\lambda\\chi_D(\\tau)\\left(e^{i\\Omega\\tau}e\\ket{1}_D\\bra{0}_D+e^{-i\\Omega\\tau}\\ket{0}_D\\bra{1}_D\\right)\\otimes\\phi[x_D(\\tau)]\n%\\end{align}\nwhere $\\chi_D(\\tau) \\leq 1 $ is a switching function controlling the duration of the interaction,\n$\\lambda\\ll1$ is the field/detector coupling constant, and $\\sigma^+= \\ket{1}_D\\bra{0}_D$, $\\sigma^-= \\ket{0}_D\\bra{1}_D$ are ladder operators that raise and lower the energy levels of the UDW detectors.  \n\nSuppose we have two detectors $A$ and $B$ with trajectories $x_A(\\tau_A)$ and $x_B(\\tau_B)$. If the initial state of the detector-field system is $\\ket{\\Psi_i}=\\ket{0}_A\\ket{0}_B\\ket{0}$, then after a time $t$, $\\ket{\\Psi_f}=U(t,0)\\ket{\\psi_i}$, where $U(t,0)=\\mathcal{T}e^{-i\\int dt\\left[\\frac{d\\tau_A}{dt}H_A(\\tau_A)+\\frac{d\\tau_B}{dt}H_B(\\tau_B)\\right]}$, with $\\mathcal{T}$  the time-ordering operator. Letting $\\rho_{AB}=\\Tr_\\phi\\ket{\\Psi_f}\\bra{\\Psi_f}$ be the reduced density operator describing the detectors after tracing over the scalar field degrees of freedom, we have \\cite{Smith2016,Smith:2017vle}\n\\begin{align}\n\\rho_{AB}=\\begin{pmatrix}\n1-P_A-P_B& 0 & 0   & X   \\\\\n0  & P_B  &  L_{AB}& 0  \\\\\n 0 & L_{AB}^* &  P_A &0  \\\\\n  X^* & 0& 0  &   0\n\\end{pmatrix}\n+\\mathcal{O}(\\lambda^4)\n\\end{align}\nin the basis $\\{\\ket{0}_A\\ket{0}_B,\\ket{0}_A\\ket{1}_B,\\ket{1}_A\\ket{0}_B,\\ket{1}_A\\ket{1}_B\\}$,  where $P_D$ is the probability for detector $D$ ($D=A,B$) to become excited, the non-local corrections are denoted by $X$, and $L_{AB}$ describes the non-entangling correlations. See the Supplementary Material for explicit calculations of $P_D$, $X$, and $L_{AB}$. These quantities are all dependent on the two-point correlation function, $W(x,x')=\\braket{0|\\phi(x)\\phi(x')|0}$ (also called the Wightman function) of the vacuum. The entanglement present in the system can be quantified using the concurrence \\cite{Smith2016,Smith:2017vle,Wooters1998}\n\\begin{align}\n\\mathcal{C}\\left[\\rho_{AB}\\right]=2\\max\\left[0,|X|-\\sqrt{P_AP_B}\\right]+\\mathcal{O}(\\lambda^4)\n\\end{align}\nwhich qualitatively is non-zero when non-local detector correlations are greater than the geometric mean of detector noise.\n\n{\\it Entanglement Harvesting around a Rotating BTZ Black Hole}\\; \n\\label{sec: BTZ}\n\nWe are interested in implementing the entanglement harvesting protocol near a rotating BTZ black hole, whose line element is  \\cite{Banados1992}\n\\begin{equation}\\label{btzmet}\nds^2=-(N^\\perp)^2dt^2+f^{-2}dr^2+r^2(d\\phi+N^{\\phi}dt)^2\n\\end{equation}\nwhere, $N^\\perp=f=\\sqrt{-M+\\frac{r^2}{\\ell^2}+\\frac{J^2}{4r^2}}$ and $N^\\phi =-\\frac{J}{2r^2}$ with $M=\\frac{r_+^2+r_-^2}{\\ell^2}$  and $J=\\frac{2r_+ r_-}{\\ell}$ the respective mass and angular momentum of the black hole, whose respective inner and outer horizon radiii are $r_-$ and $r_+$; $\\ell$ is the AdS length. Note that   $|J|\\leq M\\ell$, with equality yielding extremality ($r_+=r_-$).\n\nFor a conformally coupled scalar field (in the Hartle-Hawking vacuum) the Wightman function is known analytically \\cite{Lifschytz1994,Carlip1998}, and\ncan be written as the image sum\n\\begin{align}\nW_{BTZ}(x,x')=\\sum_{n=-\\infty}^\\infty \\eta^nW_{AdS_3}(x,\\Gamma^nx')\n\\end{align}\nover the vacuum Wightman functions for AdS${}_3$, where $\\Gamma x'$ takes $(t,r,\\phi)\\to(t,r,\\phi+2\\pi)$ and $\\eta=\\pm 1$ describes the untwisted/twisted nature of the scalar field. With this identification, we have \\cite{Hodgkinson2012,Smith:2013zqa}\n\\begin{widetext}\n\\begin{align}\nW_{BTZ}=\\frac{1}{4\\pi}\\frac{1}{2\\sqrt{\\ell}}\\sum_{n=-\\infty}^{n=\\infty}\\eta^n\\left(\\frac{1}{\\sqrt{\\sigma_{\\epsilon}(x,\\Gamma^nx')}}-\\frac{\\zeta}{\\sqrt{\\sigma_{\\epsilon}(x,\\Gamma^nx')+2}}\\right)\n\\label{eq: sum}\n\\end{align}\nwhere\n\\begin{equation}\n\\begin{aligned}\n\\sigma_\\epsilon(x,\\Gamma^nx')^2=&-1+\\sqrt{\\alpha(r)\\alpha(r')}\\cosh\\left[\\frac{r_+}{\\ell}(\\Delta\\phi-2\\pi n)-\\frac{r_-}{\\ell^2}(t-t')\\right]\\\\\n&-\\sqrt{(\\alpha(r)-1)(\\alpha(r')-1)}\\cosh\\left[\\frac{r_+}{\\ell^2}(t-t')-\\frac{r_-}{\\ell}(\\Delta\\phi-2\\pi n)\\right]\n\\label{eq: sigma 0}\n\\end{aligned}\n\\end{equation}\n\\end{widetext}\nand \n\\begin{align}\n\\alpha(r)&=\\frac{r^2-r_-^2}{r_+^2-r_-^2}\\qquad\n\\Delta\\phi=\\phi-\\phi'\\ .\n\\end{align}\nThe boundary conditions for the scalar field (Dirichlet, Neumann, transparent) are represented by $\\zeta=1,-1,0$, respectively. We shall consider detectors with equal energy gaps $\\Omega_A=\\Omega_B=\\Omega$ and switching functions $\\chi(\\tau_A)=e^{-\\tau_A^2/2\\sigma^2}$ and $\\chi(\\tau_B)=e^{-\\tau_B^2/2\\sigma^2}$ (see Supplementary Material). We also set the AdS length to be $\\ell/\\sigma=10$ and only consider untwisted scalar fields with $\\eta=1$ with Dirichlet boundary conditions of $\\zeta=1$. We obtain qualitatively similar results for $\\zeta=-1$ and $0$.\n\n%\\section{Entanglement harvesting near a rotating BTZ black hole}\n%\\label{sec: plots}\n\n%\\tcr{\\bf{Note: A few extra plots need to be generated. They are noted in the text. Furthermore, the quality of the plots need to be improved, such as their sizes (including their text) and instead of having a legend on each subfigure, making it so that only a single legend is present in the overall figure. This last point will be accomplished once all plots are in place. The plots should also be larger}}\n\n %Using the detector probabilities and non-localities previously derived in the appendix, we are now in a position to investigate the effect of angular momentum on the amount of entanglement generated between the detectors in a rotating BTZ spacetime. \n\nWe consider two detectors $A$ and $B$, respectively located at $R_A$ and $R_B$\n whose proper separation is\n\\begin{align}\nd(R_A,R_B)=\\ell\\log\n   \\left(\\frac{\\sqrt{R_B^2-r_-^2}+\\sqrt{R_B^2-r_+^2}}{\\sqrt{R_A^2-r_-^2}+\\sqrt{R_A^2-r_+\n   ^2}}\\right)\n\\end{align}\nat fixed $(t,\\phi)$. The proper time $\\tau_D$ for each detector is related to these coordinates via\n\\begin{align}\n\\phi_D &=  \\frac{r_{-}} {\\ell r_+} t_D =  \\frac{  r_-\\tau_D }{\\sqrt{R_D^2-r_+^2}\\sqrt{r_+^2-r_-^2}}   \n \\label{eq: CRM}\n\\end{align}\nin the co-rotating frame \\cite{Hodgkinson2012} for $D=A,B$. We keep \n $d(R_A,R_B)/\\sigma$ fixed whilst computing the concurrence for as a function of  the proper distance  $d(r_+,R_A)/\\sigma$ between detector $A$ and the outer horizon at $r=r_+$.\n \n\n\\begin{comment}\nUsing the Gaussian switching function discussed in the previous section, the detector probabilities and non-localities are\n\\begin{widetext}\n\\begin{align}\nP_D&=\\sum_{n=-\\infty}^{-1}\\eta^n\\{I_n^--\\zeta I_n^+\\}+I_0-\\zeta I_0^++\\sum_{n=1}^{\\infty}\\eta^n\\{I_n^--\\zeta I_n^+\\}\\\\\nX&=\\sum_{n=-\\infty}^\\infty\\eta^n\\left[\\left(I^-_{AB,n}+I^-_{BA,-n}\\right)-\\zeta\\left(I^+_{AB,n}+I^+_{BA,-n}\\right)\\right]\n\\end{align}\nwhere\nI_n^\\pm&=\\frac{\\lambda^2\\sigma_D}{4\\sqrt{2}\\pi\\ell}(\\alpha(r)-1)^{-1/2}\\left(\\frac{r_+^2-r_-^2}{R^3}\\right)^{-1}\\int_{-\\infty}^{\\infty}dz\\frac{e^{-a\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)^2}e^{-i\\beta\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)}}{\\sqrt{\\left(\\cosh(\\alpha_n^\\pm)-\\cosh\\left[z\\right]\\right)}}\n\\end{align}\nand $T=\\frac{1}{2\\pi}\\left(\\frac{r_+^2-r_-^2}{R^3}\\right)$, $a=\\frac{1}{4\\sigma_D^2}\\left(\\frac{R^3}{r_+^2-r_-^2}\\right)^2$, $\\beta=\\frac{\\Omega_DR^3}{r_+^2-r_-^2}$\n\\end{widetext}\n\\end{comment}\n\\begin{figure*}[htb!]\n        \\begin{subfigure}{\\textwidth}\n\\centering\n\\includegraphics[scale=0.9]{AllLegend.pdf}\n\\end{subfigure}\n\\begin{subfigure}{\\textwidth}\n\\foreach \\y in {1,2,3}\n{\n  \\centering\n    \\includegraphics[width=0.32\\linewidth]{M=0,001_plotCAll_Omega=\\y_zeta=1.pdf}\n}\n\\end{subfigure}\n\\caption{Concurrence of two UDW detectors separated by a distance $d(R_A,R_B)=1$ orbiting a black hole of mass $M=10^{-3}$ for various angular momenta. We have set $\\zeta=1$ and $\\ell/\\sigma=10$.\n}\n\\label{fig: ConcurrenceJ}\n\\end{figure*}\n\n\nOur main result is illustrated in figure~\\ref{fig: ConcurrenceJ}, which shows that rotation has a profound effect on the entanglement that can be harvested.\nFor small gap and small angular momenta, the concurrence is a monotonically increasing function of proper separation of detector $A$ from the horizon, until it asymptotes to its \nvalue in AdS spacetime, independent of both the angular momentum and mass, which we have verified numerically.\nAs the angular momentum of the black hole increases, there is relatively little change from the $J=0$ case.  However departures become apparent once $J/M\\ell \\geq 0.9$: we see  that the concurrence slowly grows and (from the insets) that the  entanglement shadow shrinks in size. The growth in the concurrence becomes quite rapid as the black hole approaches extremality, peaking at a value 8 times as large as the non-rotating case for $\\Omega\\sigma = 0.01$. The peak occurs quite far from the horizon, at about $d(r_+,R_A) = 25\\sigma$, or about 100 horizon radii.  \n\nAs the gap $\\Omega$ increases, these trends are exaggerated. The entanglement shadow shrinks further and the maximal concurrence near extremality grows larger, becoming  as much as 10 times greater than the $J=0$ case for $\\Omega\\sigma = 0.1$. \n  The growth in $\\mathcal{C}$ becomes even more rapid and the shadow continues to decrease in size as $\\Omega \\to \\sigma$, but \nthe maximal concurrence  begins to diminish slightly, becoming 4 times larger than the $J=0$ case.  As  $d(r_+,R_A)$ become large, the concurrence decreases, asymptoting to its AdS value regardless of the value of $J/M\\ell$. We find that for smaller values of  $J$ there is both enhancement and diminishment in the concurrence before asymptoting to the AdS value at large distances, whose detailed structure we will investigate in future work.\n\\begin{figure}[h!]\n\\includegraphics[width=\\columnwidth]{splot_Omega=1_Zeta=1_M=0,001}\n\\caption{Concurrence as a function of $d(r_+,R_A)/\\sigma$ for various co-rotating detector separations $d(R_A,R_B)$, for $M=10^{-3}$,  $\\zeta=1$, $\\ell/\\sigma=10$, $\\Omega\\sigma=1$, and $J/M\\ell=0.9999$.}\n\\label{fig: proper distance}\n\\end{figure}\n\nThe effect diminishes as proper separation between the detectors increases, though still persists at intermediate distances (up to a maximum proper separation), as shown in Figure \\ref{fig: proper distance} for $\\Omega\\sigma=1$. We find it is possible to extract entanglement at what are effectively spacelike\ndetector separations where the overlap between the switching functions is $\\lesssim 10^{-8}$; indeed entanglement can be extracted for separations as large \n $d(R_A,R_B)=10\\sigma$, where the overlap is $\\lesssim 10^{-22}$.   \nThis is quite remarkable -- small mass near-extremal black holes allow for entanglement extractions at large detector separations that would otherwise not be possible. \n\n\\begin{figure*}[t]\n    \\begin{subfigure}{\\textwidth}\n\\centering\n\\includegraphics[scale=0.85]{AllLegend.pdf}\n\\end{subfigure}\n\\centering\n    \\begin{subfigure}{0.3\\textwidth}\n  \\centering\n    \\includegraphics[width=\\textwidth]{M=0,001_plotPA_Omega3_zeta=1.pdf}\n    \\caption{$P_A$}\n    \\end{subfigure}\n\\begin{subfigure}{0.3\\textwidth}\n  \\centering\n    \\includegraphics[width=\\textwidth]{M=0,001_plotPB_Omega3_zeta=1.pdf}\n    \\caption{$P_B$}\n    \\end{subfigure}\n    \\begin{subfigure}{0.3\\textwidth}\n  \\centering\n    \\includegraphics[width=\\textwidth]{M=0,001_plotX_Omega3_zeta=1.pdf}\n    \\caption{$|X|$}\n    \\end{subfigure}\n           \\begin{subfigure}{0.3\\textwidth}\n  \\centering\n    \\includegraphics[width=\\textwidth]{PlotC_M=0,001_Zeta=1_Omega=1_J=0,9999_LargerText.pdf}\n    \\caption{$\\mathcal{C}$}\n    \\label{fig: partial sum}\n    \\end{subfigure}\n        \\hspace*{-0.8cm}\n               \\begin{subfigure}{0.01\\textwidth}\n               \\vspace*{-0.8cm}\n  \\centering\n    \\includegraphics[scale=0.5]{PartialSumLegendColumn.pdf}\n    \\end{subfigure}\n        \\caption{(a-c) Transition probabilities and non-locality for UDW detectors orbiting a rotating BTZ black hole. (d) Partial image sums of the concurrence for UDW detectors orbitting a rotating BTZ black hole of angular momentum $J/M\\ell=0.9999$. In each plot, the UDW detectors are have a proper separation of $d(R_A,R_B)=1$, the energy gap is $\\Omega\\sigma=1$, the black hole, has a mass of $M=10^{-3}$, $\\zeta=1$ and $\\ell/\\sigma=10$.}\n        \\label{fig: PX0.001}\n\\end{figure*}\n\nThe origin of this entanglement amplification as the black hole approaches extremality is quite subtle. It is not due to any divergences in the respective coefficients  $K_P$ and  $K_X$ of detector probability and non-locality, both of which are independent of $r_-$ and thus are well-behaved as $r_+\\to r_-$ (see Supplemental Material).\nIt is also not a kinematic effect of the type found in\nAdS-Rindler spacetime \\cite{jennings2010response,Henderson:2019uqo}, as an investigation of the partial image sum reveals. In Figure \\ref{fig: partial sum}, we plot the detector probabilities, non-locality, and concurrence for several different partial image sums (whose general expressions we provide in the Supplementary Material). There is no  entanglement amplification for the $n=0$ term, which corresponds to the AdS-Rindler case \\cite{Henderson:2019uqo}.  Instead, as the number of terms in the sums increases, the peak in $P_A$ shifts to the right and the peak in $X$ tends to broaden;  the peak in the concurrence becomes evident once $|n|>3$. Close to the horizon and at intermediate distances, the sum rapidly converges for $|n| > 30$; indeed,\nthe difference between $\\sum_{n=-1}^1$ and $\\sum_{n=-7}^7$ is greater than the difference between $\\sum_{n=-7}^7$ and $\\sum_{n=-100}^{100}$.\nPlotting $P_A$, $P_B$, and $|X|$ in figure~\\ref{fig: PX0.001}, we see that there is  a monotonic increase in $|X|$ with increasing $J$ \nin the intermediate zone about $20\\sigma < d(r_+,R_A) < 40\\sigma$, whilst both   $P_A$ and $P_B$ reach a maximum and then begin to decrease, as illustrated in  figure~\\ref{fig: PX0.001}.\nThe spacetime thus has relatively enhanced non-local correlations in regions far, but not too far, for near-extremal black holes. \n\n\nWe also find that the  ergosphere plays no significant role in harvesting. Requiring $-(N^\\perp)^2 + r^2 (N^\\phi)^2 =  M - r^2/L^2 > 0$, the ergosphere extends out to $R=\\sqrt{M}\\ell$. The entanglement shadow extends beyond the ergosphere for the cases of $\\Omega\\sigma=0.01$ and $\\Omega\\sigma=0.1$, though lies entirely within the ergosphere for $\\Omega\\sigma=1$.  From  figure~\\ref{fig: PX0.001} we see that as detector $A$ approaches the horizon its response $P_A$ increases to a maximum before sharply dropping off. This takes place for all values of $J$, and is signatory of the anti-Hawking effect recently observed for static black holes \\cite{Henderson2019b}.  We find for larger gaps that $P_A$ experiences a sharp increase near the horizon before decreasing.\n\nWhat of other vacuum correlations? An investigation of the mutual information \n\\begin{equation}\n  I_{AB} = \\mathcal{L}_+ \\log \\mathcal{L}_+  + \\mathcal{L}_- \\log \\mathcal{L}_-  - {P}_A  \\log{P}_A  -{P}_B  \\log{P}_B \n\\end{equation}\nwhere $ \\mathcal{L}_\\pm = \\frac{1}{2}\\left({P}_A   + {P}_B   \\pm \\sqrt{({P}_A  -{P}_B )^2+ 4 |L_{AB} |^2 } \\right)$ \nindicates that it  peaks away from the black hole, \nalbeit at smaller distances than the concurrence, and likewise undergoes significant amplification as extremality is approached.  The nearer location of the peak\noccurs because  $P_A$, $P_B$, and $|L_{AB}|$ are all sharply peaked relatively close to the horizon, whereas $|X|$ peaks at notably larger distances. Hence  only the quantum correlations are enhanced in the intermediate regime.\n\n\n\n\n{\\it Conclusion}\\;\n\\label{sec: conclusion}\nWe have shown that near-extremal BTZ black holes amplify the amount of quantum vacuum entanglement that can be extracted by a pair of idealized detectors.\nRemarkably the concurrence can reach a maximum value as large as 10 times that of its static counterpart, depending on the energy gap of the detectors, \nand occurs at intermediate distances from the black hole. Significant harvesting is possible at large spacelike detector separations.  This is due to a diminishment of detector noise at such distances  relative to non-local correlations, which monotonically increase for increasing $J$ at any fixed distance within this intermediate region.\n\nThe effects we find are present for small mass black holes.   For larger mass black holes we find that the quantities $P_A$, $P_B$, and $|X|$ (and therefore $\\mathcal{C}$) are increasingly insensitive to the angular momentum, and for $M\\geq 1$, the sensitivity is vanishingly small.  This is because the additional terms in the image sum of equation (\\ref{eq: sum}) become very tiny, and the physics is dominated by AdS-Rindler effects described previously \\cite{Henderson2019b}. \n\nIt is quite remarkable that the effects of rotation can amplify vacuum correlations so dramatically.  How this effect persists for other black holes remains an interesting subject for future study. \\\\\n \n\n\n\n\n{\\it Acknowledgements}\n$\\quad$ \nWe thank Erickson Tjoa and Jorma Louko their useful comments and discussions. MR and LJH were funded by Natural Science and Engineering Research Council of Canada (NSERC) graduate scholarships. This research was supported in part by NSERC and the Perimeter Institute for Theoretical Physics. Research at Perimeter Institute is supported in part by the Government of Canada through the Department of Innovation, Science and Economic Development Canada and by the Province of Ontario through the Ministry of Colleges and Universities.\n\n\n\\bibliographystyle{unsrt}\n\\bibliography{EntanglementHarvestingRefs}\n\n\\onecolumngrid\n\\appendix\n\n\\section{Supplementary material: calculations for detector probabilities, non-localities, and correlations}\n\n\\subsection{Probabilities and Non-local Correlations}\nIn general, the detector probabilities ($P_D$) and non-locality term $X$ are given by\n\\begin{align}\nP_D&=\\lambda^2\\int d\\tau_Dd\\tau_D'\\chi_D(\\tau_D)\\chi_D(\\tau_D')e^{-i\\Omega_D(\\tau_D-\\tau_D')}W(x_D,x_D(\\tau_D'))\\label{eq: PD}\\\\\nX&=-\\lambda^2\\int d\\tau_Ad\\tau_B\\chi(\\tau_A)\\chi(\\tau_B)e^{-i(\\Omega_A\\tau_A+\\Omega_B\\tau_B)}\\left[\\Theta[t-t']W(x_A(t),x_B(t'))+\\Theta[t-t']W(x_B(t'),x_A(t))\\right] \\label{eq: X}\n\\end{align}\nwhere $\\chi$ is the switching function, $\\Omega_D$ is the energy gap of detector $D$, $x_D$ is the trajectory of detector D, $\\Theta$ is the Heaviside step function, $\\lambda\\ll1$ is the file/director coupling constant, and $W$ is the Wightman function,\n\\begin{align}\nW_{BTZ}=\\frac{1}{4\\pi}\\frac{1}{\\sqrt{2}\\ell}\\lim_{\\epsilon\\to 0}\\sum_{n=-\\infty}^{n=\\infty}\\eta^n\\left(\\frac{1}{\\sqrt{\\sigma_{\\epsilon}(x,\\Gamma^nx')}}-\\frac{\\zeta}{\\sqrt{\\sigma_{\\epsilon}(x,\\Gamma^nx')+2}}\\right)\n\\end{align}\nwhere\n\\begin{equation}\n\\begin{aligned}\n\\sigma_\\epsilon(x,\\Gamma^nx')=&-1+\\sqrt{\\alpha(r)\\alpha(r')}\\cosh\\left[\\frac{r_+}{\\ell}(\\Delta\\phi-2\\pi n)-\\frac{r_-}{\\ell^2}(t-t'-i\\epsilon)\\right]\\\\\n&-\\sqrt{(\\alpha(r)-1)(\\alpha(r')-1)}\\cosh\\left[\\frac{r_+}{\\ell^2}(t-t'-i\\epsilon)-\\frac{r_-}{\\ell}(\\Delta\\phi-2\\pi n)\\right]\n\\label{eq: sigma 0}\n\\end{aligned}\n\\end{equation}\nis the squared geodesic distance between any two points (which can be determined by radar ranging in any frame),\nand\n\\begin{align}\n\\alpha(r)&=\\frac{r^2-r_-^2}{r_+^2-r_-^2}\\qquad\n\\Delta\\phi=\\phi-\\phi'\n\\end{align}\n We calculate these quantities by assuming Gaussian switching: $\\chi(\\tau_A)=e^{-\\tau_A^2/2\\sigma_D^2}$ and $\\chi(\\tau_B)=e^{-\\tau_B^2/2\\sigma_D^2}$. For simplicity, we also take the width $\\sigma_D$ of the two switching functions to be the same as well as the energy gap $\\Omega_A=\\Omega_B=\\Omega$. and we work in the co-rotating frame:\\begin{align}\nt&=\\frac{\\ell r_+\\tau}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}} \\label{eq: CRM t}\\\\\n\\phi&=\\frac{r_-\\tau}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}} \\label{eq: CRM phi}\\ .\n\\end{align}\nThrough straightforward though tedious manipulations, we find $P_D=\\sum_{n=-\\infty}^\\infty\\eta^n\\left\\{I_n^--\\zeta I_n^+\\right\\}$, where\n\\begin{align}\nI_n^\\pm=K_P\\int_{-\\infty}^{\\infty}dz\\frac{e^{-a\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)^2}e^{-i\\beta\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)}}{\\sqrt{\\left(\\cosh(\\alpha_n^\\pm)-\\cosh\\left[z\\right]\\right)}}\n\\label{eq: In}\n\\end{align}\nand\n\\begin{align}\nK_P&=\\frac{\\lambda ^2 \\sigma_D}{4 \\sqrt{2 \\pi }}\\\\\na&=\\left(\\frac{R^3}{r_+^2-r_-^2}\\right)^2/4\\sigma_D^2\\\\\n\\beta&=\\frac{\\Omega_DR^3}{r_+^2-r_-^2}\\\\\n\\cosh(\\alpha_n^\\pm)&=\\frac{1}{\\alpha(r)-1}\\left[\\pm1+\\alpha(r)\\cosh\\left(2\\pi n\\frac{r_+}{\\ell}\\right)\\right]\n\\end{align}\n\n\n\nTo calculate the non-locality $X$, let\n\\begin{align}\nx_A(\\tau_A)&:=\\left\\{t=\\frac{\\ell r_+\\tau_A}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}},r=R_A,\\phi_A=\\frac{r_-\\tau_A}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}}\\right\\}\\\\\nx_B(\\tau_B)&:=\\left\\{t'=\\frac{\\ell r_+\\tau_B}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}},r=R_B,\\phi_B=\\frac{r_-\\tau_B}{\\sqrt{r^2-r_+^2}\\sqrt{r_+^2-r_-^2}}\\right\\}\n\\end{align}\nSimilarly tedious calculations show $X=\\sum_{n=-\\infty}^\\infty\\eta^n\\left[\\left(I^-_{AB,n}+I^-_{BA,-n}\\right)-\\zeta\\left(I^+_{AB,n}+I^+_{BA,-n}\\right)\\right]$ where\n\\begin{align}\nI_{AB,n}^\\pm+I_{BA,-n}^\\pm=\\frac{K_X}{2}\\int_0^\\infty dz\\left[\\frac{e^{-a_X\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)^2}e^{-i\\beta_X\\left(z-\\frac{2\\pi nr_-}{\\ell}\\right)}+e^{-a_X\\left(z+\\frac{2\\pi nr_-}{\\ell}\\right)^2}e^{i\\beta_X\\left(z+\\frac{2\\pi nr_-}{\\ell}\\right)}}{\\sqrt{\\cosh(\\alpha_n^\\pm)-\\cosh z}}\\right]\n\\end{align}\nwith\n\\begin{align}\nK_X&=-\\frac{\\lambda ^2 \\sigma _A \\sigma _B \\sqrt[4]{\\left(R_A^2-r_+^2\\right)\n   \\left(R_B^2-r_+^2\\right)} \\exp \\left(-\\frac{\\sigma _A^2 \\sigma _B^2 \\left(\\Omega _A\n   \\sqrt{R_A^2-r_+^2}+\\Omega _B \\sqrt{R_B^2-r_+^2}\\right){}^2}{2 \\left(\\sigma _A^2\n   \\left(R_B^2-r_+^2\\right)+\\sigma _B^2 \\left(R_A^2-r_+^2\\right)\\right)}\\right)}{2\n   \\sqrt{\\pi } \\sqrt{\\sigma _A^2 \\left(R_B^2-r_+^2\\right)+\\sigma _B^2\n   \\left(R_A^2-r_+^2\\right)}}\\\\\na_X&=\\frac{1}{2(\\bar\\sigma_A^2+\\bar\\sigma_B^2)}\\left(\\frac{\\ell^2 r_+}{r_+^2-r_-^2}\\right)^2\\\\\n\\beta_X&=\\frac{(\\bar\\sigma_B^2\\bar\\Omega_B-\\bar\\sigma_A^2\\bar\\Omega_A)}{\\bar\\sigma_A^2+\\bar\\sigma_B^2}\\left(\\frac{\\ell^2 r_+}{r_+^2-r_-^2}\\right)\\\\\n\\end{align}\nand\n\\begin{equation}\n\\begin{aligned}\n\\bar\\sigma_A&=\\sigma_A/\\gamma_A\\\\\n\\bar\\sigma_B&=\\sigma_B/\\gamma_B\\\\\n\\Omega_A\\tau_A&=\\Omega_A\\gamma_At:=\\bar\\Omega_A t\\\\\n\\Omega_B\\tau_B&=\\Omega_B\\gamma_Bt:=\\bar\\Omega_B t\n\\end{aligned}\n\\end{equation}\n\n\\subsection{Detector Correlations}\n\nThe detector correlations are given by \n\n\\begin{align}\nL_{AB}=\\lambda^2\\int dtdt'\\eta_B(t')\\eta_A(t)e^{-i[\\Omega_B\\tau_B(t')-\\Omega_A\\tau_A(t)]}W(x_A(t),x_B(t'))\\ ,\n\\label{eq: C}\n\\end{align}\nwhere $\\eta_D(t)=\\frac{d\\tau_D}{dt}\\chi(\\tau_D)=\\gamma_De^{-\\tau_D^2/2\\sigma_D^2}$ and\n\\begin{equation}\n\\begin{aligned}\n\\gamma_A&=\\frac{\\sqrt{R_A^2-r_+^2}\\sqrt{r_+^2-r_-^2}}{\\ell r_+}\\\\\n\\gamma_B&=\\frac{\\sqrt{R_B^2-r_+^2}\\sqrt{r_+^2-r_-^2}}{\\ell r_+}\n\\end{aligned}\n\\end{equation}\nWorking in the co-rotating frame, we can write $L_{AB}=\\sum_{n=-\\infty}^\\infty\\left(I_n^--\\zeta I_n^+\\right)$ where\n\\begin{align}\nI_n^\\pm=K_L\\int_{-\\infty}^\\infty dz \\frac{e^{-a_L(z-2\\pi nr_-/\\ell)^2}e^{-i\\beta_L(z-2\\pi nr_-/\\ell)}}{\\sqrt{\\cosh(\\alpha_n^\\pm)-\\cosh\\left[z\\right]}}\n\\end{align}\nwith\n\\begin{align}\nK_L&=\\frac{1}{\\sqrt{\\sqrt{\\alpha(R_A)-1}\\sqrt{\\alpha(R_B)-1}}}\\frac{\\lambda^2}{8\\pi\\sqrt{2}\\ell}\\gamma_B\\gamma_A\\left(\\frac{2\\sqrt{2\\pi}\\bar\\sigma_A\\bar\\sigma_B}{\\sqrt{\\bar\\sigma_A^2+\\bar\\sigma_B^2}}\\right)e^{-\\frac{\\bar\\sigma_A^2\\bar\\sigma_B^2(\\bar\\Omega_A-\\bar\\Omega_B)^2}{2(\\bar\\sigma_A^2+\\bar\\sigma_B^2)}}\\frac{\\ell^2r_+}{r_+^2-r_-^2}\\\\\na_L&=\\frac{1}{2(\\bar\\sigma_A^2+\\bar\\sigma_B^2)}\\left(\\frac{\\ell^2 r_+}{r_+^2-r_-^2}\\right)^2\\\\\n\\beta_L&=\\frac{(\\bar\\sigma_B^2\\bar\\Omega_B+\\bar\\sigma_A^2\\bar\\Omega_A)}{\\bar\\sigma_A^2+\\bar\\sigma_B^2}\\left(\\frac{\\ell^2 r_+}{r_+^2-r_-^2}\\right)\n\\end{align}\n\nTo calculate   detector correlations, equation \\eqref{eq: C} was applied by using the co-rotating frame in conjunction with the methodology discussed in Ref [30] to a precision of $10^{-4}$. We approximated the integral as $-5s<\\tau_A,\\tau_B<5s$ and integrated $\\tau_B$ on the contour shown in Figure \\ref{fig: contour}.\n\n\\begin{figure}[h]\n\\centering\n\\begin{tikzpicture}\n  \\draw[thick, ->] (-6,0) -- (6,0) coordinate (xaxis);\n\n  \\draw[thick, ->] (0,0) -- (0,4) coordinate (yaxis);\n\n  \\node[above] at (xaxis) {$\\mathrm{Re}(\\tau_B)$};\n\n  \\node[right]  at (yaxis) {$\\mathrm{Im}(\\tau_B)$};\n\n\\begin{scope}[very thick,decoration={\n    markings,\n    mark=at position 0.5 with {\\arrow[line width=3pt]{<}}}\n    ] \n    \\draw[postaction={decorate}] (4,0)--(4,0) node[below, black] {$5s$};\n    \\draw[blue, postaction={decorate}] (4,0)--(4,2) node[above, black] {$5s+i$};\n    \\draw[blue, postaction={decorate}] (4,2)--(-4,2) node[above, black] {$-5s+i$};\n    \\draw[blue, postaction={decorate}] (-4,2)--(-4,0) node[below, black] {$-5s$};\n\\end{scope}\n\\end{tikzpicture}\n\\caption{Contour to integrate over the $\\tau_B$ variable when calculating $L_{AB}$.}\n\\label{fig: contour}\n\\end{figure}\n\n\n%\\onecolumngrid\n \n\n%\\section{Detector Probabilities, Non-localities, and Partial Sums}\n\n\n%Figure 3 was here\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:00:19", "yymm": "2010", "arxiv_id": "2010.14517", "url": "https://arxiv.org/abs/2010.14517", "source": "arxiv"}}
{"text": "\\documentclass[11pt]{article}\r\n%DIF LATEXDIFF DIFFERENCE FILE\r\n\r\n\r\n%DIF 2c2\r\n%DIF < \\usepackage{amsmath, amssymb, amsthm, verbatim,enumerate,bbm, color}\r\n%DIF -------\r\n\\usepackage{amsmath, amssymb, amsthm} %DIF >\r\n%DIF -------\r\n\r\n\\usepackage{dsfont}\r\n\r\n%\\usepackage{appendix}\r\n\r\n\\interfootnotelinepenalty=10000\r\n\r\n\\allowdisplaybreaks\r\n\\expandafter\\let\\expandafter\\oldproof\\csname\\string\\proof\\endcsname\r\n\\let\\oldendproof\\endproof\r\n\\renewenvironment{proof}[1][\\proofname]{%\r\n\t\\oldproof[\\bf #1]%\r\n}{\\oldendproof}\r\n\\renewcommand{\\qedsymbol}{$\\blacksquare$}\r\n\r\n\r\n\\parindent 5mm\r\n\\parskip 0.2mm\r\n\\oddsidemargin  0pt \\evensidemargin 0pt \\marginparwidth 0pt\r\n\\marginparsep 0pt \\topmargin 0pt \\headsep 0pt \\textheight 8.8in\r\n\\textwidth 6.75in\r\n\\renewcommand{\\baselinestretch}{0.95}\r\n\r\n\\allowdisplaybreaks\r\n\r\n\\theoremstyle{plain}\r\n% \\newtheorem{theorem}{Theorem}[section]\r\n\\newtheorem{theorem}{Theorem}\r\n\\newtheorem{lemma}{Lemma}[section]\r\n\\newtheorem{claim}[lemma]{Claim}\r\n\\newtheorem{proposition}[lemma]{Proposition}\r\n\\newtheorem{observation}[lemma]{Observation}\r\n\\newtheorem{corollary}[theorem]{Corollary}\r\n\\newtheorem{conjecture}[lemma]{Conjecture}\r\n\\newtheorem{problem}[lemma]{Problem}\r\n\\newtheorem{remark}[lemma]{Remark}\r\n\\newtheorem{definition}[lemma]{Definition}\r\n\\newtheorem{property}[lemma]{Property}\r\n\\newtheorem{strategy}[lemma]{Strategy}\r\n\\newtheorem{construction}[lemma]{Construction}\r\n\r\n\\newcommand{\\Bin}{\\ensuremath{\\textrm{Bin}}}\r\n\\newcommand{\\whp}{w.h.p.}\r\n\\newcommand{\\prob}{probability}\r\n\\newcommand{\\rn}{random}\r\n\\newcommand{\\rv}{random variable}\r\n%Hypergraphs\r\n\\newcommand{\\hpg}{hypergraph}\r\n\\newcommand{\\hpgs}{hypergraphs}\r\n\\newcommand{\\subhpg}{subhypergraph}\r\n\\newcommand{\\subhpgs}{subhypergraphs}\r\n%Letters\r\n\\newcommand{\\wt}{\\widetilde}\r\n\\newcommand{\\D}{\\mathcal D}\r\n\\newcommand{\\C}{\\mathcal C}\r\n\\newcommand{\\V}{\\mathcal V}\r\n\\newcommand{\\M}{\\mathcal M}\r\n\\newcommand{\\K}{\\mathcal K}\r\n\\newcommand{\\Q}{\\mathcal Q}\r\n\\newcommand{\\R}{\\mathcal R}\r\n\\newcommand{\\Prop}{\\mathcal P}\r\n\\newcommand{\\Part}{\\mathcal P}\r\n\\newcommand{\\F}{\\mathcal F}\r\n\\newcommand{\\T}{\\mathcal T}\r\n\\newcommand{\\U}{\\mathcal U}\r\n\\newcommand{\\W}{\\mathcal W}\r\n\\newcommand{\\X}{\\mathcal X}\r\n\\newcommand{\\Y}{\\mathcal Y}\r\n% \\newcommand{\\V}{\\mathcal V}\r\n\\newcommand{\\Image}{\\text{Im}}\r\n\\newcommand{\\homleq}{\\leq_{\\hom}}\r\n\\newcommand{\\poly}{\\text{poly}}\r\n%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF\r\n%DIF UNDERLINE PREAMBLE %DIF PREAMBLE\r\n\\RequirePackage[normalem]{ulem} %DIF PREAMBLE\r\n\\RequirePackage{color}\\definecolor{RED}{rgb}{1,0,0}\\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE\r\n\\providecommand{\\DIFadd}[1]{{\\protect\\color{blue}\\uwave{#1}}} %DIF PREAMBLE\r\n\\providecommand{\\DIFdel}[1]{{\\protect\\color{red}\\sout{#1}}}                      %DIF PREAMBLE\r\n%DIF SAFE PREAMBLE %DIF PREAMBLE\r\n\\providecommand{\\DIFaddbegin}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFaddend}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFdelbegin}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFdelend}{} %DIF PREAMBLE\r\n%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE\r\n\\providecommand{\\DIFaddFL}[1]{\\DIFadd{#1}} %DIF PREAMBLE\r\n\\providecommand{\\DIFdelFL}[1]{\\DIFdel{#1}} %DIF PREAMBLE\r\n\\providecommand{\\DIFaddbeginFL}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFaddendFL}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFdelbeginFL}{} %DIF PREAMBLE\r\n\\providecommand{\\DIFdelendFL}{} %DIF PREAMBLE\r\n%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF\r\n\r\n\\newcommand{\\ex}{\\text{ex}}\r\n\r\n\\title{Constructing Dense Grid-Free Linear $3$-Graphs}\r\n\r\n\\author{Lior Gishboliner\\thanks{ETH Zurich. \r\n\t\t\tEmail: lior.gishboliner@math.ethz.ch.}\r\n\t\\and Asaf Shapira\\thanks{\r\n\t\tSchool of Mathematics, Tel Aviv University, Tel Aviv 69978, Israel.\r\n\t\tEmail: asafico@tau.ac.il. Supported in part by ISF Grant 1028/16 and ERC Starting Grant 633509.}\r\n}\r\n\r\n\\begin{document}\r\n\t\\maketitle \r\n\t\r\n\t\\begin{abstract}\r\n\t\tWe show that there exist linear $3$-uniform hypergraphs with $n$ vertices and $\\Omega(n^2)$ edges which contain no copy of the $3 \\times 3$ grid. This makes significant progress on a conjecture of F\\\"{u}redi and \\nolinebreak Ruszink\\'{o}. We also discuss connections to proving lower bounds for the $(9,6)$ Brown-Erd\\H{o}s-S\\'{o}s problem and to a problem of Solymosi and Solymosi. \r\n\t\\end{abstract}\r\n\t\r\n\t\\section{Introduction}\r\n\tIn recent years there has been some interest in Tur\\'{a}n-type results in linear hypergraphs \\cite{FR, Ge_Shangguan, GS}. \r\n\tIn this paper, all hypergraphs are $3$-uniform. For a family $\\mathcal{H}$ of $3$-uniform hypergraphs, we let $\\ex_{\\text{lin}}(n,\\mathcal{H})$ denote the maximum number of edges in a linear $3$-uniform $\\mathcal{H}$-free hypergraph on $n$ vertices. When $\\mathcal{H}$ has a single element $H$, we will write $\\ex_{\\text{lin}}(n,H)$. Arguably, the interest in problems of this type is motivated by the famous Brown-Erd\\H{o}s-S\\'{o}s conjecture \\cite{BHS1,BHS2}, which states that for every $k \\geq 3$, if $\\mathcal{H}_{k+3,k}$ is the set of $3$-uniform hypergraphs with $k$ edges and at most $k+3$ vertices (such hypergraphs are called {\\em $(k+3,k)$-configurations}), then\\footnote{The Brown-Erd\\H{o}s-S\\'{o}s conjecture is usually stated about general (i.e., not necessarily linear) hypergraphs, but it is well-known that it suffices to consider linear hypergraphs, for if a hypergraph $H$ contains no $(k+3,k)$-configuration, then it has a linear subhypergraph with $\\Omega(e(H))$ edges.} $\\ex_{\\text{lin}}(n,\\mathcal{H}_{k+3,k}) = o(n^2)$. So far, this conjecture has only been proven in the case $k = 3$. This is a celebrated result of Ruzsa and Szemer\\'{e}di \\cite{RS}, which became known as the {\\em $(6,3)$ theorem}. Ruzsa and Szemer\\'{e}di \\cite{RS} have also given a construction which shows that $\\ex_{\\text{lin}}(n,\\mathcal{H}_{6,3}) \\geq n^{2-o(1)}$, implying that the exponent $2$ in the $(6,3)$ theorem cannot be improved. \r\n\tFor $k \\geq 4$, the Brown-Erd\\H{o}s-S\\'{o}s conjecture remains widely open despite considerable effort, with the best approximate result recently obtained in \\cite{CGLS} (see also \\cite{Sarkozy_Selkow, Solymosi}).\r\n\t\r\n\tIt turns out that $\\mathcal{H}_{6,3}$ contains only one linear hypergraph: the triangle $\\mathbb{T}$, which is the hypergraph with vertices $1,2,3,4,5,6$ and edges $\\{1,2,3\\},\\{3,4,5\\},\\{5,6,1\\}$. Thus, the aforementioned results of Ruzsa and Szemer\\'{e}di \\cite{RS} are equivalent to the statement \r\n\t$n^{2-o(1)} \\leq \\ex_{\\text{lin}}(n,\\mathbb{T}) \\leq o(n^2)$. \r\n\t\r\n\tIt is natural to try and prove that $\\ex_{\\text{lin}}(n,\\mathcal{H}_{k+3,k}) \\geq n^{2-o(1)}$ for every $k \\geq 3$, which would mean that, in a sense, the Brown-Erd\\H{o}s-S\\'{o}s conjecture is optimal. For $k = 4,5$, such a lower bound follows from the simple observation that every $(7,4)$- or $(8,5)$-configuration contains a $(6,3)$-configuration. Similar considerations were used in \\cite{Ge_Shangguan} to handle the cases $k = 7,8$. For $k = 6$, however, such arguments could not be used, since there exists a $(9,6)$-configuration which contains no $(6,3)$-configuration; this is the {\\em $3 \\times 3$ grid} $\\mathbb{G}_{3 \\times 3}$, which is the $3$-uniform hypergraph whose vertices are the nine points in a $3 \\times 3$ point array, and whose edges correspond to the $6$ horizontal and vertical lines of this array.\r\n%\twhich is the $3$-uniform hypergraph with vertices $\\{p_i,q_i,r_i : 1 \\leq i \\leq 3\\}$ and edges \r\n%\t$\\{ \\{p_i,q_i,r_i\\},\\{p_{i+1},q_{i+2},r_{i}\\} : 1 \\leq i \\leq 3\\}$, where indices are taken modulo $3$. \r\n\tAs it turns out, every linear $(9,6)$-configuration either contains a triangle $\\mathbb{T}$ or is isomorphic to $\\mathbb{G}_{3 \\times 3}$. Hence, $\\ex_{\\text{lin}}(n,\\mathcal{H}_{9,6}) = \\ex_{\\text{lin}}(n,\\{\\mathbb{T},\\mathbb{G}_{3 \\times 3}\\})$. This relation has led F\\\"{u}redi and Ruszink\\'{o} \\cite{FR} to study extremal problems related to the grid. In particular, they conjectured that \r\n\t$\\ex_{\\text{lin}}(n,\\mathbb{G}_{3 \\times 3}) = \r\n\t\\left( \\frac{1}{6} - o(1) \\right)n^2$, and, more strongly, that for every large enough admissible $n$, there is a Steiner triple system of order $n$ which is $\\mathbb{G}_{3 \\times 3}$-free. \r\n%\tThe previous best lower bound on $\\ex_{\\text{lin}}(n,\\mathbb{G}_{3 \\times 3})$, obtained in \\cite{FR,GS}, is of order $n^{1.6}$. \r\n\tUsing a standard probabilistic alterations argument, F\\\"{u}redi and Ruszink\\'{o} \\cite{FR} showed that $\\ex_{\\text{lin}}(n,\\mathbb{G}_{3 \\times 3}) = \\Omega(n^{1.8})$, which was then slightly improved (as a special case of a more general result) to $\\Omega(n^{1.8}\\log^{1/5}{n})$ by Shangguan and Tamo \\cite{ST}.\r\n\tHere we make significant progress on the conjecture of F\\\"{u}redi and Ruszink\\'{o} \\cite{FR}, by showing that \r\n\t$\\ex_{\\text{lin}}(n,\\mathbb{G}_{3 \\times 3}) = \\Omega(n^2)$. \r\n\t\\begin{theorem}\\label{thm:main}\r\n\t\tFor infinitely many $n$, there exists a linear $\\mathbb{G}_{3 \\times 3}$-free $3$-uniform hypergraph with $n$ vertices and $(\\frac{1}{16} - o(1))n^2$ edges. \r\n\t\\end{theorem}\r\n\t\\noindent\r\n\tTheorem \\ref{thm:main} is proved in the following section. Then, in Section \\ref{sec:concluding_remarks}, we discuss some related open problems. \r\n\t\r\n\t\\section{The Construction}\r\n%\tA {\\em $3$-partition} of a $3$-uniform hypergraph $H$ is a partition $V(H) = X \\cup Y \\cup Z$ such that every edge of $H$ contains one element from each of the sets $X,Y,Z$. \r\n%\tRecall that the {\\em $3 \\times 3$ grid} $\\mathbb{G}_{3 \\times 3}$ has vertices $\\{p_i,q_i,r_i : 1 \\leq i \\leq 3\\}$ and edges \r\n%\t$\\{ \\{p_i,q_i,r_i\\},\\{p_{i+1},q_{i+2},r_{i}\\} : 1 \\leq i \\leq 3\\}$, where indices are taken modulo $3$. Observe that $\\{p_1,p_2,p_3\\},\\{q_1,q_2,q_3\\},\\{r_1,r_2,r_3\\}$ is a $3$-partition of $\\mathbb{G}_{3 \\times 3}$, and that every two $3$-partitions of $\\mathbb{G}_{3 \\times 3}$ are equivalent, in the sense that there is an automorphism of $\\mathbb{G}_{3 \\times 3}$ which maps one to the other. \r\n\r\n%\t\\begin{construction}\\label{construction}\r\n%\t\tLet $p$ be a prime power and let $X,A \\subseteq \\mathbb{F}_p$. Define $H(X,A)$ to be the $3$-partite $3$-uniform hypergraph with sides $X$, $Y := \\{x + a : x \\in X, a \\in A\\}$ and $Z := \\{ x \\cdot a : x \\in X, a \\in A \\}$, and with an edge consisting of $x \\in X, x+a \\in Y, x \\cdot a \\in Z$ for every $x \\in X$ and $a \\in A$.    \r\n%\t\\end{construction}\r\n%\t\\begin{construction}\\label{construction}\r\n%\t\tLet $\\mathbb{F}$ be a field and let $X,A \\subseteq \\mathbb{F}$. Define $H(X,A)$ to be the $3$-partite $3$-uniform hypergraph with sides $X$, $Y := \\{x + a : x \\in X, a \\in A\\}$ and $Z := \\{ x \\cdot a : x \\in X, a \\in A \\}$, and with an edge consisting of $x \\in X, x+a \\in Y, x \\cdot a \\in Z$ for every $x \\in X$ and $a \\in A$.    \r\n%\t\\end{construction}\r\n\t\\begin{construction}\\label{construction}\r\n\t\tLet $\\mathbb{F}$ be a field and let $X,A \\subseteq \\mathbb{F}$. Define $H(X,A)$ to be the $3$-partite $3$-uniform hypergraph with sides $X$, $Y := \\{x + a : x \\in X, a \\in A\\}$ and $Z := \\{ x \\cdot a : x \\in X, a \\in A \\}$, and with an edge $(x,x+a,x \\cdot a) \\in X \\times Y \\times Z$ for every $x \\in X$ and $a \\in A$.    \r\n\t\\end{construction}\r\n\tWe now prove that the hypergraph $H(X,A)$ defined in Construction \\ref{construction} is always \r\n\t$\\mathbb{G}_{3 \\times 3}$-free. We will then show that it contains a dense linear subhypergraph.\r\n\tWe denote the vertices of $\\mathbb{G}_{3 \\times 3}$ by $\\{p_i,q_i,r_i : 1 \\leq i \\leq 3\\}$ and its edges by \r\n\t$\\{ \\{p_i,q_i,r_i\\},\\{p_{i+1},q_{i+2},r_{i}\\} : 1 \\leq i \\leq 3\\}$, where (here and later on) indices are taken modulo $3$.\r\n\tA {\\em $3$-partition} of a $3$-uniform hypergraph $F$ is a partition $V(F) = P \\cup Q \\cup R$ such that every edge of $F$ contains one element from each of the sets $P,Q,R$. \r\n\tObserve that $\\{p_1,p_2,p_3\\},\\{q_1,q_2,q_3\\},\\{r_1,r_2,r_3\\}$ is a $3$-partition of $\\mathbb{G}_{3 \\times 3}$. It can be verified\\footnote{Indeed, every $3$-partition of $\\mathbb{G}_{3 \\times 3}$ is either obtained from the $3$-partition $(P,Q,R)$ by permuting its classes, or equals $\\left( \\{p_1,q_3,r_2\\},\\{p_2,q_1,r_3\\},\\{p_3,q_2,r_1\\} \\right)$ or one of its permutations.} that every two $3$-partitions of $\\mathbb{G}_{3 \\times 3}$ are equivalent, in the sense that there is an automorphism of $\\mathbb{G}_{3 \\times 3}$ which maps every class of one to a class of the other. \r\n\t\\begin{lemma}\\label{lem:grid_copy}\r\n\t\tLet $\\mathbb{F}$ be a field and let $X,A \\subseteq \\mathbb{F}$.\r\n\t\tThen $H(X,A)$ is $\\mathbb{G}_{3\\times 3}$-free. \r\n\t\\end{lemma}\r\n\t\r\n\t\\begin{proof}\r\n\t\tSuppose, for the sake of contradiction, that $H(X,A)$ contains a copy of $\\mathbb{G}_{3 \\times 3}$. \r\n%\t\tWe denote the vertices of $\\mathbb{G}_{3 \\times 3}$ by $\\{p_i,q_i,r_i : 1 \\leq i \\leq 3\\}$ and its edges by \r\n%\t\t$\\{ \\{p_i,q_i,r_i\\},\\{p_{i+1},q_{i+2},r_{i}\\} : 1 \\leq i \\leq 3\\}$, where (here and throughout the proof) indices are taken modulo $3$.\r\n%\t\tA {\\em $3$-partition} of a $3$-uniform hypergraph $F$ is a partition $V(F) = P \\cup Q \\cup R$ such that every edge of $F$ contains one element from each of the sets $P,Q,R$. \r\n%\t\tObserve that $\\{p_1,p_2,p_3\\},\\{q_1,q_2,q_3\\},\\{r_1,r_2,r_3\\}$ is a $3$-partition of $\\mathbb{G}_{3 \\times 3}$. It can be verified that every two $3$-partitions of $\\mathbb{G}_{3 \\times 3}$ are equivalent, in the sense that there is an automorphism of $\\mathbb{G}_{3 \\times 3}$ which maps one to the other. \r\n\t\tSince all $3$-partitions of $\\mathbb{G}_{3 \\times 3}$ are equivalent (as explained above), we may assume, without loss of generality, that $p_1,p_2,p_3 \\in X$, $q_1,q_2,q_3 \\in Y = \\{x + a : x \\in X, a \\in A\\}$ and $r_1,r_2,r_3 \\in Z = \\{ x \\cdot a : x \\in X, a \\in A \\}$. \r\n\t\tBy definition of $H(X,A)$, for every edge $\\{x,y,z\\} \\in E(H)$ (with $x \\in X$, $y \\in Y$ and $z \\in Z$) there is $a \\in A$ such that $y = x + a$ and $z = x \\cdot a$; hence, $z = x \\cdot (y - x)$. \r\n\t\tIt follows that for every $1 \\leq i \\leq 3$, \\nolinebreak we \\nolinebreak must \\nolinebreak have \r\n%\t\t$$r_i = p_i \\cdot (q_i - p_i)$$ \r\n%\t\tand \r\n%\t\t$$r_i = p_{i+1} \\cdot (q_{i+2} - p_{i+1}).\r\n%\t\t$$ \r\n\t\t$r_i = p_i \\cdot (q_i - p_i) \\text{ and } r_i = p_{i+1} \\cdot (q_{i+2} - p_{i+1}).\r\n\t\t$\r\n\t\tHere and throughout the proof, indices are taken modulo $3$. By comparing these two expressions for $r_i$, we see that \r\n\t\t%\t\t\\begin{equation}\\label{eq:grid_copy_equation_1}\r\n\t\t%\t\tp_i + (q_i - p_i)^2 = r_i = p_{i+1} + (q_{i+2} - p_{i+1})^2\r\n\t\t%\t\t\\end{equation}\r\n\t\t\\begin{equation}\\label{eq:grid_copy_equation_1}\r\n\t\tp_i \\cdot (q_i - p_i) = p_{i+1} \\cdot (q_{i+2} - p_{i+1}).\r\n\t\t\\end{equation}\r\n\t\tfor every $1 \\leq i \\leq 3$. Multiplying \\eqref{eq:grid_copy_equation_1} by $p_{i+2}$ and then summing over $1 \\leq i \\leq 3$, we obtain\r\n\t\t$$\r\n\t\t\\sum_{i = 1}^{3}{p_ip_{i+2} \\cdot (q_i - p_i)} = \r\n\t\t\\sum_{i = 1}^{3}{p_{i+1}p_{i+2} \\cdot (q_{i+2} - p_{i+1})}.\r\n\t\t$$\r\n\t\tIt is easy to see that for every $1 \\leq i \\leq 3$, both sides have the term $p_ip_{i+2}q_i$. Cancelling out these terms and rearranging, we get\r\n\t\t$$\r\n\t\t0 = \\sum_{i = 1}^{3}{p_i^2p_{i+2}} - \\sum_{i = 1}^{3}{p_{i+1}^2p_{i+2}} = \r\n\t\t(p_1 - p_2)(p_2 - p_3)(p_3 - p_1).\r\n\t\t$$\r\n\t\tHence, there must be $1 \\leq i \\leq 3$ such that $p_{i+1} = p_i$. However, this is impossible as $p_1,p_2,p_3 \\in X$ must correspond to distinct vertices of a copy of $\\mathbb{G}_{3 \\times 3}$. This contradiction completes the proof. \r\n\t\\end{proof} \r\n\t\\begin{proof}[Proof of Theorem \\ref{thm:main}]\r\n\t\tWe first prove Theorem \\ref{thm:main} with a slightly worse bound, namely, with the fraction $\\frac{1}{16}$ replaced by $\\frac{1}{18}$. We then explain how our argument can be modified to give $\\frac{1}{16}$.\r\n\t\t\r\n\t\tLet $p$ be an odd prime power, and set $X := A := \\mathbb{F}_p \\setminus \\{0\\}$. Let $H = H(X,A)$ be the hypergraph from Construction \\ref{construction}. By Lemma \\ref{lem:grid_copy}, $H$ is $\\mathbb{G}_{3 \\times 3}$-free. \r\n\t\t% Recall that each edge of $H$ is of the form $(x,x+a,x\\cdot a) \\in X \\times Y \\times Z$ with $x \\in X$ and $a \\in A$. \r\n\t\tWe claim that for each edge $e = (x,x+\\nolinebreak a,x\\cdot \\nolinebreak a) \\in E(H) \\subseteq X \\times Y \\times Z$, if $f \\in E(H) \\setminus \\{e\\}$ satisfies that $|e \\cap f| = 2$ then $f = (a,x+a,x \\cdot a)$. So let $f = (y,y+b,y \\cdot b) \\in E(H) \\setminus \\{e\\}$ be such that $|e \\cap f | = 2$. We cannot have $(x,x+a) = (y,y+b)$ or $(x,x \\cdot a) = (y,y \\cdot b)$, for otherwise we would have $x = y, a = b$ and hence $e = f$. Therefore, we must have $(x+a,x \\cdot a) = (y+b, y\\cdot b)$, which gives \r\n\t\t$\r\n\t\ty(x + a - y) = x \\cdot a.\r\n\t\t$\r\n\t\tSolving this quadratic equation for $y$, we get that $y = x$ or $y = a$, and hence $(y,b) = (x,a)$ or $(y,b) = (a,x)$. In the former case, $f = e$, and in the latter case $f = (a,x+a,x \\cdot a)$. This proves our claim. \r\n\t\tIt follows that for each $e \\in E(H)$ there is at most one other edge $f \\in E(H)$ such that $|e \\cap f| = 2$. By deleting one edge from each such pair $(e,f)$, we obtain a linear sub-hypergraph $H'$ of $H$ with \r\n\t\t$e(H') \\geq \\frac{e(H)}{2} = |X||A| = (\\frac{1}{2} - o(1))p^2 = (\\frac{1}{18} - o(1))v(H)^2$, where in the last equality we used the fact that $v(H) = 3p-2$ as $|X| = p-1$, $|Y| = p$ and $Z = p-1$. This shows that $\\ex_{\\text{lin}}(n,\\mathbb{G}_{3 \\times 3}) \\geq \r\n\t\t(\\frac{1}{18} - o(1))n^2$.\r\n\t\t\r\n\t\tTo improve the constant, we choose $X$ and $A$ differently: let $X$ be the set of (non-zero) quadratic residues and $A$ be the set of (non-zero) quadratic non-residues in $\\mathbb{F}_p$. Evidently, $|X| = |A| = \\frac{p-1}{2}$ and $|Y| \\leq p$. As\r\n\t\t$Z = \\{ x \\cdot a : x \\in X, a \\in A \\} = A$, one also has $|Z| = \\frac{p-1}{2}$. Altogether we get \r\n\t\t$v(H) = |X| + |Y| + |Z| \\leq 2p-1$. Moreover, $e(H) = |X||A| = (\\frac{1}{4} - o(1))p^2 = (\\frac{1}{16} - o(1))v(H)^2$. Crucially, we observe that $H$ is linear, because for every $e = (x,x+a,x \\cdot a) \\in E(H)$, the edge $f = (a, x + a, x \\cdot a)$ is not in $H$, as $x$ is a quadratic residue while $a$ is not. This completes the proof.\r\n%\t\tSet $X := \\{x \\in \\mathbb{F}_p : 1 \\leq x < \\frac{p}{12}\\}$ \r\n%\t\tand let $A$ be the set of all $a \\in \\mathbb{F}_p$ satisfying \r\n%\t\t$\\frac{p}{12} \\leq a,a^2 < \\frac{p}{6}$. \r\n%\t\tSet $X := \\{x \\in \\mathbb{F}_p : 1 \\leq x < p/12\\}$ \r\n%\t\tand $A := \\{a \\in \\mathbb{F}_p : p/12 \\leq a < p/6\\}$. \r\n%\t\tBy Lemma \\ref{lem:equidistribution} we have $|A| = \\Omega(p)$. \r\n%\t\t\t\t\tLet $H := H(X,A)$ be as in Construction \\ref{construction}. \r\n%\t\t\t\t\tNote that the sides $X,Y,Z$ of $H$ have sizes $|X| \\leq p/12$, $|Y| \\leq p/4$ (since $Y = X + A$) and $|Z| \\leq p$. Hence, $v(H) \\leq p/12 + p/4 + p = 4p/3$.  \r\n%\t\t\t\t\tMoreover, every pair $(x,a) \\in X \\times A$ defines an edge of $H$, and distinct pairs define distinct edges. This implies that $e(H) = |X| \\cdot |A| = (1/144 - o(1))p^2$. \r\n%\t\t\t\t\tObserve that every pair of vertices of $H$ belongs to at most $2$ edges. Indeed, suppose that triples $e_1 = (x_1,x_1+a_1,x_1+a_1^2)$ and $e_2 = (x_2,x_2+a_2,x_2+a_2^2)$ have two equal coordinates. If these are the two first coordinates, then we have $x_1 = x_2$ and $a_1 = a_2$, implying that $e_1 = e_2$; if the first and third coordinates are equal then we have $x_1 = x_2$ and $a_1^2 = a_2^2$, and hence $a_2 = \\pm a_1$; and if the two last coordinates are equal, then we have $x_1 + a_1 = x_2 = a_2$ and $x_1 + a_1^2 = x_2 + a_2^2$ and hence $a_1 + a_1^2 = a_2 + a_2^2$, which implies that $(x_2,a_2) = (x_1,a_1)$ or $(x_2,a_2) = (x_1+2a_1-1,1-a_1)$. In any case, we see that every pair of vertices of $H$ is contained in at most $2$ edges, as claimed. It follows that $H$ contains a linear subhypergraph with at least \r\n%\t\t\t\t\t$e(H)/2 = (1/288 - o(1))p^2$ edges. \r\n%\t\t\t\t\tWe claim that for every edge  $e_1 = (x_1,x_1+a_1,x_1+a_1^2)$ of $H$, there are at most $2$ other edges which intersect $e_1$ in two vertices.\r\n%\t\t\t\t\tIndeed, consider any other edge $e_2 = (x_2,x_2+a_2,x_2+a_2^2) \\neq e_1$ which intersects $e_1$ in two vertices. Since $e_2 \\neq e_1$, it must be the case that $(x_1,a_1) \\neq (x_2,a_2)$. Therefore, we must have either $(x_1,x_1+a_1^2) = (x_2,x_2 + a_2^2)$ or $(x_1 + a_1,x_1+a_1^2) = (x_2 + a_2,x_2 + a_2^2)$. In the former case, we have $x_1 = x_2$ and $a_1^2 = a_2^2$, which means, as $a_1 \\neq a_2$, that $a_2 = -a_1$. And in the latter case, we have $x_1 + a_1 = x_2 + a_2$ and $x_1 + a_1^2 = x_2 + a_2^2$, which gives $a_1 + a_1^2 = a_2 + a_2^2$. Solving for $a_2$ and using that $(x_1,a_1) \\neq (x_2,a_2)$, we get $a_2 = 1 - a_1$ and hence $x_2 = x_1+2a_1-1$. All in all, we see that, as claimed, there are only two options for $e_2$: either $e_2 = (x_1,x_1-a_1,x_1 + a_1^2)$ or $e_2 = (x_1+2a_1-1,x_1+a_1,x_1 + a_1^2)$. \r\n%\t\t\t\t\tIt follows that $H$ contains a linear subhypergraph with at least \r\n%\t\t\t\t\t$e(H)/3 = (1/432 - o(1))p^2$ edges. \r\n\t\\end{proof}\r\n%\t\\begin{construction}\\label{construction}\r\n%\t\tLet $p$ be a prime power and let $X,A \\subseteq \\mathbb{F}_p$. Define $H(X,A)$ to be the $3$-partite $3$-uniform hypergraph with sides $X$, $Y := \\{x + a : x \\in X, a \\in A\\}$ and $Z := \\{ x + a^2 : x \\in X, a \\in A \\}$, and with an edge consisting of $x \\in X, x+a \\in Y, x+a^2 \\in Z$ for every $x \\in X$ and $a \\in A$.    \r\n%\t\\end{construction}\r\n%\t\\begin{lemma}\\label{lem:grid_copy}\r\n%\t\tLet $p$ be a power of an odd prime, and let $X,A \\subseteq \\mathbb{F}_p$.\r\n%\t\tIf $H(X,A)$ contains a copy of $\\mathbb{G}_{3 \\times 3}$, then there are $x_1,x_2 \\in X$ and $a \\in A$ such that $4x_2 + 4a = 4x_1 + 1$.\r\n%\t\\end{lemma}\r\n%\t\\begin{proof}\r\n%\t\tConsider a copy of $\\mathbb{G}_{3 \\times 3}$ in $H(X,A)$. Without loss of generality, we may assume that $p_1,p_2,p_3 \\in X$, $q_1,q_2,q_3 \\in Y = \\{x + a : x \\in X, a \\in A\\}$ and $r_1,r_2,r_3 \\in Z := \\{ x + a^2 : x \\in X, a \\in A \\}$. \r\n%\t\tBy definition of $H$, for every edge $\\{x,y,z\\} \\in E(H)$ (with $x \\in X$, $y \\in Y$ and $z \\in Z$), there is $a \\in A$ such that $y = x + a$ and $z = x + a^2$; hence, $z - x = (y - x)^2$. \r\n%\t\tIt follows that for every $1 \\leq i \\leq 3$, we must have $r_i - p_i = (q_i - p_i)^2$ and $r_i - p_{i+1} = (q_{i+2} - p_{i+1})^2$. (Throughout the proof, indices are taken modulo $3$.) So we see that for every $1 \\leq i \\leq 3$, it holds that\r\n%%\t\t\\begin{equation}\\label{eq:grid_copy_equation_1}\r\n%%\t\tp_i + (q_i - p_i)^2 = r_i = p_{i+1} + (q_{i+2} - p_{i+1})^2\r\n%%\t\t\\end{equation}\r\n%\t\t\\begin{equation}\\label{eq:grid_copy_equation_1}\r\n%\t\tp_i + (q_i - p_i)^2 = p_{i+1} + (q_{i+2} - p_{i+1})^2\r\n%\t\t\\end{equation}\r\n%\t\tWe now do the following variable substitution: put $u_i := p_{i+1} - p_i$ and $v_i := q_i - p_{i+1}$ for $1 \\leq i \\leq 3$. Then\r\n%\t\t$q_i - p_i = v_i + p_{i+1} - p_i = v_i + u_i$ and $q_{i+2} - p_{i+1} = v_{i+2} + p_i - p_{i+1} = v_{i+2} - u_i$. \r\n%\t\tPlugging this into \\eqref{eq:grid_copy_equation_1}, we get that\r\n%%\t\t\\begin{equation}\\label{eq:grid_copy_equation_2}\r\n%%\t\t(v_i + u_i)^2 = u_i + (v_{i+2 - u_i})^2\r\n%%\t\t\\end{equation}\r\n%\t\t$(v_i + u_i)^2 = u_i + (v_{i+2} - u_i)^2$\r\n%\t\tfor every $1 \\leq i \\leq 3$. Expanding and simplifying, we obtain that \r\n%\t\t\\begin{equation}\\label{eq:grid_copy_equation_2}\r\n%\t\t(2v_i + 2v_{i+2} - 1)u_i = v_{i+2}^2 - v_i^2\r\n%\t\t\\end{equation}\r\n%\t\tholds for every $1 \\leq i \\leq 3$. We now consider two cases. Suppose first that $2v_i + 2v_{i+2} = 1$ for some $1 \\leq i \\leq 3$. Then $v_{i+2}^2 - v_i^2 = 0$ by \\eqref{eq:grid_copy_equation_2}. Plugging in $v_{i+2} = 1/2 - v_i$, we get \r\n%\t\t$0 = v_{i+2}^2 - v_i^2 = (1/2 - v_i)^2 - v_i^2 = 1/4 - v_i$, giving $v_i = 1/4$. Recalling that $v_i = q_i - p_{i+1}$ and that $q_i = x + a$ for some $x \\in X$ and $a \\in A$ (by the definition of $Y$), we see that $x + a = q_i = p_{i+1} + 1/4$ and hence $4x + 4a = 4p_{i+1} + 1$. Thus, the assertion of the lemma holds for $x_2 = x$ and $x_1 = p_{i+1} \\in X$.\r\n%\t\t\r\n%\t\tNow suppose that $2v_i + 2v_{i+2} \\neq 1$ for every $1 \\leq i \\leq 3$. Then from \\eqref{eq:grid_copy_equation_2} we get that \\linebreak $u_i = (v_{i+2}^2 - v_i^2)/(2v_i + 2v_{i+2} - 1)$ for every $1 \\leq i \\leq 3$. The definition of $u_i$ readily implies that $u_1 + u_2 + u_3 = 0$. Hence,\r\n%%\t\t\\begin{align*}\r\n%%\t\t0 &= \r\n%%\t\tu_1 + u_2 + u_3 = \r\n%%\t\t\\frac{v_3^2-v_1^2}{2v_1+2v_3-1} + \\frac{v_1^2-v_2^2}{2v_2+2v_1-1} + \\frac{v_2^2-v_3^2}{2v_3+2v_2-1} \r\n%%\t\t\\\\ &=\r\n%%\t\t\\frac{-2(v_3-v_1)(v_1-v_2)(v_2-v_3)}{(2v_1+2v_3-1)(2v_2+2v_1-1)(2v_3+2v_2-1)} \\; .\r\n%%\t\t\\end{align*}\r\n%\t\t\\begin{align*}\r\n%\t\t0 = \r\n%\t\t\\frac{v_3^2-v_1^2}{2v_1+2v_3-1} + \\frac{v_1^2-v_2^2}{2v_2+2v_1-1} + \\frac{v_2^2-v_3^2}{2v_3+2v_2-1} \r\n%\t\t=\r\n%\t\t\\frac{-2(v_3-v_1)(v_1-v_2)(v_2-v_3)}{(2v_1+2v_3-1)(2v_2+2v_1-1)(2v_3+2v_2-1)} \\; .\r\n%\t\t\\end{align*}\r\n%\t\tWe conclude that $v_i = v_{i+2}$ for some $1 \\leq i \\leq 3$. Plugging this into \\eqref{eq:grid_copy_equation_2} and using the fact that $2v_i + 2v_{i+2} \\neq 0$ by assumption, we get that $0 = u_i = p_{i+1} - p_i$. But then $p_{i+1} = p_i$, which is impossible since $p_i,p_{i+1} \\in X$ are distinct vertices.\r\n%\t\tThis completes the proof. \r\n%\t\\end{proof}\r\n%\t\r\n%\r\n%\t\\begin{theorem}\r\n%\t\tFor every large enough odd prime power $p$, there exists a linear $\\mathbb{G}_{3 \\times 3}$-free $3$-uniform hypergraph with $4p/3$ vertices and $(1/432 - o(1))p^2$ edges. \r\n%\t\\end{theorem}\r\n%\t\\begin{proof}\r\n%%\t\tSet $X := \\{x \\in \\mathbb{F}_p : 1 \\leq x < \\frac{p}{12}\\}$ \r\n%%\t\tand let $A$ be the set of all $a \\in \\mathbb{F}_p$ satisfying \r\n%%\t\t$\\frac{p}{12} \\leq a,a^2 < \\frac{p}{6}$. \r\n%\t\tSet $X := \\{x \\in \\mathbb{F}_p : 1 \\leq x < p/12\\}$ \r\n%\t\tand $A := \\{a \\in \\mathbb{F}_p : p/12 \\leq a < p/6\\}$. \r\n%%\t\tBy Lemma \\ref{lem:equidistribution} we have $|A| = \\Omega(p)$. \r\n%\t\tLet $H := H(X,A)$ be as in Construction \\ref{construction}. \r\n%\t\tNote that the sides $X,Y,Z$ of $H$ have sizes $|X| \\leq p/12$, $|Y| \\leq p/4$ (since $Y = X + A$) and $|Z| \\leq p$. Hence, $v(H) \\leq p/12 + p/4 + p = 4p/3$.  \r\n%\t\tMoreover, every pair $(x,a) \\in X \\times A$ defines an edge of $H$, and distinct pairs define distinct edges. This implies that $e(H) = |X| \\cdot |A| = (1/144 - o(1))p^2$. \r\n%%\t\tObserve that every pair of vertices of $H$ belongs to at most $2$ edges. Indeed, suppose that triples $e_1 = (x_1,x_1+a_1,x_1+a_1^2)$ and $e_2 = (x_2,x_2+a_2,x_2+a_2^2)$ have two equal coordinates. If these are the two first coordinates, then we have $x_1 = x_2$ and $a_1 = a_2$, implying that $e_1 = e_2$; if the first and third coordinates are equal then we have $x_1 = x_2$ and $a_1^2 = a_2^2$, and hence $a_2 = \\pm a_1$; and if the two last coordinates are equal, then we have $x_1 + a_1 = x_2 = a_2$ and $x_1 + a_1^2 = x_2 + a_2^2$ and hence $a_1 + a_1^2 = a_2 + a_2^2$, which implies that $(x_2,a_2) = (x_1,a_1)$ or $(x_2,a_2) = (x_1+2a_1-1,1-a_1)$. In any case, we see that every pair of vertices of $H$ is contained in at most $2$ edges, as claimed. It follows that $H$ contains a linear subhypergraph with at least \r\n%%\t\t$e(H)/2 = (1/288 - o(1))p^2$ edges. \r\n%\t\tWe claim that for every edge  $e_1 = (x_1,x_1+a_1,x_1+a_1^2)$ of $H$, there are at most $2$ other edges which intersect $e_1$ in two vertices.\r\n%\t\tIndeed, consider any other edge $e_2 = (x_2,x_2+a_2,x_2+a_2^2) \\neq e_1$ which intersects $e_1$ in two vertices. Since $e_2 \\neq e_1$, it must be the case that $(x_1,a_1) \\neq (x_2,a_2)$. Therefore, we must have either $(x_1,x_1+a_1^2) = (x_2,x_2 + a_2^2)$ or $(x_1 + a_1,x_1+a_1^2) = (x_2 + a_2,x_2 + a_2^2)$. In the former case, we have $x_1 = x_2$ and $a_1^2 = a_2^2$, which means, as $a_1 \\neq a_2$, that $a_2 = -a_1$. And in the latter case, we have $x_1 + a_1 = x_2 + a_2$ and $x_1 + a_1^2 = x_2 + a_2^2$, which gives $a_1 + a_1^2 = a_2 + a_2^2$. Solving for $a_2$ and using that $(x_1,a_1) \\neq (x_2,a_2)$, we get $a_2 = 1 - a_1$ and hence $x_2 = x_1+2a_1-1$. All in all, we see that, as claimed, there are only two options for $e_2$: either $e_2 = (x_1,x_1-a_1,x_1 + a_1^2)$ or $e_2 = (x_1+2a_1-1,x_1+a_1,x_1 + a_1^2)$. \r\n%\t\tIt follows that $H$ contains a linear subhypergraph with at least \r\n%\t\t$e(H)/3 = (1/432 - o(1))p^2$ edges. \r\n%\t\t\r\n%%\t\tevery pair of vertices of $H$ belongs to at most $2$ edges. Indeed, suppose that triples $e_1 = (x_1,x_1+a_1,x_1+a_1^2)$ and $e_2 = (x_2,x_2+a_2,x_2+a_2^2)$ have two equal coordinates. If these are the two first coordinates, then we have $x_1 = x_2$ and $a_1 = a_2$, implying that $e_1 = e_2$; if the first and third coordinates are equal then we have $x_1 = x_2$ and $a_1^2 = a_2^2$, and hence $a_2 = \\pm a_1$; and if the two last coordinates are equal, then we have $x_1 + a_1 = x_2 = a_2$ and $x_1 + a_1^2 = x_2 + a_2^2$ and hence $a_1 + a_1^2 = a_2 + a_2^2$, which implies that $(x_2,a_2) = (x_1,a_1)$ or $(x_2,a_2) = (x_1+2a_1-1,1-a_1)$. In any case, we see that every pair of vertices of $H$ is contained in at most $2$ edges, as claimed. It follows that $H$ contains a linear subhypergraph with at least \r\n%%\t\t$e(H)/2 = (1/288 - o(1))p^2$ edges. \r\n%\t\t\r\n%\t\tTo complete the proof, let us show that $H$ is $\\mathbb{G}_{3 \\times 3}$-free. By Lemma \\ref{lem:grid_copy}, if $H$ contained a copy of $\\mathbb{G}_{3 \\times 3}$ then there would be $x_1,x_2 \\in X$ and $a \\in A$ such that $4x_2 + 4a = 4x_1 + 1$. Since \\linebreak $1 \\leq x_1,x_2,a < p/6$, this equality holds over the integers as well (i.e., there is no ``wrap-around\"), but this is clearly impossible (as $0 \\not \\equiv 1 \\pmod{4}$). Hence $H$ is $\\mathbb{G}_{3 \\times 3}$-free, as  required.  \r\n%\t\\end{proof}\r\n\\section{Concluding Remarks And Open Problems}\\label{sec:concluding_remarks}\r\n\\begin{itemize}\r\n\\item Another problem raised in \\cite{FR} is to prove that \r\n$\\ex_{\\text{lin}}(n,\\mathcal{H}_{9,6}) \\geq n^{2-o(1)}$. This problem remains open. Recalling that $\\ex_{\\text{lin}}(n,\\mathcal{H}_{9,6}) = \\ex_{\\text{lin}}(n,\\{\\mathbb{T},\\mathbb{G}_{3 \\times 3}\\})$, we see, in light of Lemma \\ref{lem:grid_copy}, that it suffices to show that there is a choice of sets $X,A \\subseteq \\mathbb{F}_p$, $|X|,|A| \\geq p^{1-o(1)}$, such that the hypergraph $H(X,A)$ has no triangles (i.e., no copies of $\\mathbb{T}$). For this, one needs that there are no $x \\in X$ and distinct $a,b,c \\in A$ such that $(x + a - b) \\cdot b = x \\cdot c$. This remains an open problem. \r\n\r\n\\item There is another construction of a linear $3$-uniform grid-free hypergraph with $\\Omega(n^2)$-edges. For sets $X,A \\subseteq \\mathbb{F}_p$, define a $3$-partite hypergraph with sides $X,Y,Z$ by placing the edge \\linebreak $(x,x+a,x+a^2) \\in X \\times Y \\times Z$ for every $x \\in X, a \\in A$. Here one needs to be more careful: unlike Construction \\ref{construction}, this hypergraph can contain a copy of $\\mathbb{G}_{3 \\times 3}$, but only if there are $x_1,x_2 \\in X$ and $a \\in A$ satisfying $4x_1 + 4a = 4x_2 + 1$. Thus, it suffices to choose $X,A$ that avoid such solutions; for example, one can take $X = A = \\{1,\\dots,\\lfloor p/8 \\rfloor \\}$. This hypergraph can also be a candidate for a construction showing that $\\ex_{\\text{lin}}(n,\\mathcal{H}_{9,6}) \\geq n^{2-o(1)}$\r\n%; again, one needs to show that there is a choice of $X,A \\subseteq \\mathbb{F}_p$ with $|X|,|A| \\geq p^{1-o(1)}$ which avoids triangles.\r\nAgain, the issue is choosing $X,A$ so as to avoid triangles, which in this case correspond to solutions to the equation $a + c^2 - c = b^2$ with distinct $a,b,c \\in A$. Thus, to show that $\\ex_{\\text{lin}}(n,\\mathcal{H}_{9,6}) \\geq n^{2-o(1)}$, it suffices to show that there exists $A \\subseteq \\mathbb{F}_p$, $|A| = p^{1-o(1)}$, with no non-trivial solution to this \\nolinebreak  equation.   \r\n \r\n%\\item A related conjecture of Solymosi and Solymosi \\cite{Solymosi} states that if an $n$-vertex hypergraph $H$ contains no {\\em $2$-core} on $9$ vertices, then $e(H) = o(n^2)$. Here, a $2$-core is a hypergraph with minimum degree $2$. This conjecture is a strengthening of the case $k = 6$ of the Brown-Erd\\H{o}s-S\\'{o}s conjecture, since a $9$-vertex $2$-core must have at least $6$ edges. As always, it suffices to consider $3$-partite linear hypergraphs. It turns out that there are exactly two non-isomorphic linear $3$-partite $2$-cores on $9$ vertices: one is the grid $\\mathbb{G}_{3 \\times 3}$, and the other is the hypergraph with vertices $x_1,x_2,x_3,y_1,y_2,y_3,z_{1,2},z_{2,3},z_{3,1}$ and edges \r\n%$$\r\n%\\{x_1,z_{1,2},x_2\\},\\{x_2,z_{2,3},x_3\\},\\{x_3,z_{3,1},x_1\\},\r\n%\\{y_1,z_{1,2},y_2\\},\\{y_2,z_{2,3},y_3\\},\\{y_3,z_{3,1},y_1\\}.\r\n%$$ \r\n%We denote this hypergraph by $F_9$. \r\n\r\n\\item A related conjecture of Solymosi and Solymosi \\cite{Solymosi} states that \r\n% if an $n$-vertex hypergraph $H$ contains no {\\em $2$-core} on at most $9$ vertices, then $e(H) = o(n^2)$. \r\nevery (large enough) $3$-uniform hypergraph with $n$ vertices and $\\Omega(n^2)$ edges contains a $2$-core on at most $9$ vertices, \r\nwhere a {\\em $2$-core} is a hypergraph with minimum degree $2$. This conjecture is closely related\\footnote{Strictly speaking, the Solymosi-Solymosi conjecture does not imply the case $k=6$ of the Brown-Erd\\H{o}s-S\\'{o}s conjecture, since the former allows the $2$-core to have less than $9$ vertices, and hence less than $6$ edges.} to the case $k=6$ of the Brown-Erd\\H{o}s-S\\'{o}s conjecture, since a $2$-core on $9$ vertices has at least $6$ edges.\r\n%if one could show that every $3$-uniform hypergraph with $\\Omega(n^2)$ edges contains a $2$-core on $9$ vertices, then this would imply the case $k = 6$ of the Brown-Erd\\H{o}s-S\\'{o}s conjecture, since a $2$-core on $9$ vertices has at least $6$ edges.\r\n\r\n%conjecture is a strengthening of the case $k = 6$ of the Brown-Erd\\H{o}s-S\\'{o}s conjecture, \r\n%%since a $9$-vertex $2$-core must have at least $6$ edges. \r\n%since a $2$-core on $v$ vertices has at least $\\frac{2v}{3}$ edges, which is at least $v - 3$ for $v \\leq 9$. \r\n%Solymosi and Solymosi \\cite{Solymosi} proved an analogue of this conjecture where $9$ is replaced with $15$. \r\n%As always, it suffices to consider $3$-partite linear hypergraphs. It turns out that there are exactly two non-isomorphic linear $3$-partite $2$-cores on $9$ vertices: one is the grid $\\mathbb{G}_{3 \\times 3}$, and the other is the hypergraph with vertices $x_1,x_2,x_3,y_1,y_2,y_3,z_{1,2},z_{2,3},z_{3,1}$ and edges \r\n%$$\r\n%\\{x_1,z_{1,2},x_2\\},\\{x_2,z_{2,3},x_3\\},\\{x_3,z_{3,1},x_1\\},\r\n%\\{y_1,z_{1,2},y_2\\},\\{y_2,z_{2,3},y_3\\},\\{y_3,z_{3,1},y_1\\}.\r\n%$$ \r\n%We denote this hypergraph by $F_9$. \r\n%It turns out that there exist (linear) $n$-vertex hypergraphs with $\\Omega(n^2)$ edges which avoid all cores on at most $9$ vertices except for the grid $\\mathbb{G}_{3 \\times 3}$. \r\n\r\nLet $H$ be the $3$-partite hypergraph with sides $X,Y,Z$, all equal to  $\\mathbb{F}_p$, and with edge-set \r\n\\linebreak $\\{(x,x+a,x+2a) \\in X \\times Y \\times Z : x,a \\in \\mathbb{F}_p\\}$. \r\nAlternatively, this is the hypergraph whose edges are all triples $(x,y,z) \\in X \\times Y \\times Z$ satisfying $y = (x+z)/2$. \r\nBy a somewhat lengthy case analysis, one can show that $H$ avoids all $2$-cores on at most $9$ vertices except for the grid $\\mathbb{G}_{3 \\times 3}$. \r\nThus, the hypergraph corresponding to a linear relation (namely, the relation $y = (x+z)/2$) avoids all but one of the $2$-cores on at most $9$ vertices, whereas in order to avoid $\\mathbb{G}_{3 \\times 3}$ one needs a non-linear relation (as in Construction \\ref{construction} or in the construction described in the previous item). It would be interesting to understand the connection between the structure of a configuration $F$ and the relation which can be used to define a hypergraph which avoids $F$.\r\n\r\nWe note that inspite of the above construction, it is plausible that the Solymosi-Solymosi conjecture is true; namely, that while there exist dense linear hypergraphs which avoid any individual $2$-core on at most $9$ vertices (and even hypergraphs which avoid all but one of them), avoiding all such $2$-cores in a dense linear hypergraph is impossible.  \r\n\\end{itemize}  \r\n\r\n\\begin{thebibliography}{99}\r\n\\bibitem{BHS1}\r\nW. G. Brown, P. Erd\\H{o}s and V. T. S\\'{o}s, Some extremal problems on $r$-graphs, in: New Directions in\r\nthe Theory of Graphs, Proc. 3rd Ann Arbor Conference on Graph Theory, Academic Press, New York, 1973, 55--63.\r\n\r\n\\bibitem{BHS2}\r\nW. G. Brown, P. Erd\\H{o}s and V. T. S\\'{o}s, On the existence of triangulated spheres in 3-graphs and\r\nrelated problems, Period. Math. Hungar. 3 (1973), 221--228.\r\n\r\n\\bibitem{CGLS}\r\nD. Conlon, L. Gishboliner, Y. Levanzov and A. Shapira, A new bound for the Brown\u2013Erdos\u2013S\u00f3s problem, arXiv preprint arXiv:1912.08834, 2019. \r\n\r\n\\bibitem{FR}\r\nZ. F\\\"{u}redi and M. Ruszink\\'{o}, Uniform hypergraphs containing no grids. Advances in Mathematics, 240, pp.302-324, 2013.\r\n\r\n\\bibitem{Ge_Shangguan}\r\nG. Ge and C. Shangguan, Sparse hypergraphs: new bounds and constructions. arXiv preprint arXiv:1706.03306, 2017.\r\n\r\n\\bibitem{GS}\r\nA. Gy\\'{a}rf\\'{a}s and G. N. S\\'{a}rk\\\"{o}zy, Tur\u00e1n and Ramsey numbers in linear triple systems, 2020.\r\n\r\n\\bibitem{RS}\r\nI. Z. Ruzsa and E. Szemer\\'{e}di, Triple systems with no six points carrying three triangles, in\r\nCombinatorics (Proc. Fifth Hungarian Colloq., Keszthely, 1976), Vol. II, pp. 939--945,\r\nColloq. Math. Soc. J\\'{a}nos Bolyai, 18, North-Holland, Amsterdam-New York, 1978.\r\n\r\n\\bibitem{Sarkozy_Selkow}\r\nG. N. S\\'{a}rk\\\"{o}zy and S. Selkow, An extension of the Ruzsa-Szemer\\'{e}di theorem, Combinatorica 25 (2004), 77--84.\r\n\r\n\\bibitem{ST}\r\nC. Shangguan and I. Tamo, Sparse Hypergraphs with Applications to Coding Theory, SIAM Journal on Discrete Mathematics 34 (3), 1493-1504, 2020.\r\n\r\n\\bibitem{Solymosi}\r\nD. Solymosi and J. Solymosi, Small cores in 3-uniform hypergraphs, J. Combin. Theory Ser. B 122 (2017), 897--910.\r\n\\end{thebibliography}\r\n\r\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:23:14", "yymm": "2010", "arxiv_id": "2010.14469", "url": "https://arxiv.org/abs/2010.14469", "source": "arxiv"}}
{"text": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage{amsmath,amsfonts,amssymb}\n\\usepackage{amsthm}\n\\usepackage[noadjust]{cite}\n\\usepackage{enumitem}\n\\setlength{\\oddsidemargin}{0cm}\n\\setlength{\\textwidth}{16cm}\n\\newcommand{\\e}{\\mathsf{E}}\n\\newcommand{\\p}{\\mathsf{P}}\n\\newcommand{\\di}{\\mathsf{Var}}\n\\newcommand{\\eps}{\\varepsilon}\n\\newtheorem{definition}{Definition}\n\\newtheorem*{cond1}{Condition}\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{cor1}{Corollary}\n\\newtheorem{lm1}{Lemma}\n\\newtheorem{rem1}{Remark}\n\\renewcommand{\\baselinestretch}{1.3}\n\\title{Jackson network in a random environment: strong approximation}\n\\author{Elena Bashtova\\footnote{Lomonosov Moscow State University; supported by RFBR grant 20-01-00487; e-mail: elena.bashtova@math.msu.ru}, Elena Lenena\\footnote{Lomonosov Moscow State University} }\n\\date{}\n%\\journal{FEMJ}\n\n\\begin{document}\n\n%\\begin{frontmatter}\n\n%% Title, authors and addresses\n\\maketitle{}\n%% use the tnoteref command within \\title for footnotes;\n%% use the tnotetext command for the associated footnote;\n%% use the fnref command within \\author or \\address for footnotes;\n%% use the fntext command for the associated footnote;\n%% use the corref command within \\author for corresponding author footnotes;\n%% use the cortext command for the associated footnote;\n%% use the ead command for the email address,\n%% and the form \\ead[url] for the home page:\n%%\n%% \\title{Title\\tnoteref{label1}}\n%% \\tnotetext[label1]{}\n%% \\author{Name\\corref{cor1}\\fnref{label2}}\n%% \\ead{email address}\n%% \\ead[url]{home page}\n%% \\fntext[label2]{}\n%% \\cortext[cor1]{}\n%% \\address{Address\\fnref{label3}}\n%% \\fntext[label3]{}\n\n\n%% use optional labels to link authors explicitly to addresses:\n%% \\author[label1,label2]{<author name>}\n%% \\address[label1]{<address>}\n%% \\address[label2]{<address>}\n\n%\\author[label1]{Elena Lenena\\corref{cor1}}\n%\\cortext[cor1]{Corresponding author}\n%\\ead{elenalenena@gmail.com}\n%\\author[label1]{Peter Ivanov}\n%\\ead{p\\_ivanov@email.mail}\n%\\address[label1]{Lomonosov Moscow State University, Moscow, Russian Federation}\n\n\\begin{abstract}\n\n%% Text of abstract\nWe consider a Jackson network with regenerative input flows in which every server is subject to a random environment influence generating breakdowns and repairs. They occur in accordance with two  independent sequences of i.i.d. random variables. We establish a theorem on the strong approximation of the vector of queue lengths by a reflected Brownian motion in positive orthant.\n\\end{abstract}\n\n%\\begin{keyword}\nKeywords: Jackson network, Strong approximation, Heavy traffic, Unreliable systems\n%% keywords here, in the form: keyword \\sep keyword\n\n%% MSC codes here, in the form: \\MSC code \\sep code\n%% or \\MSC[2008] code \\sep code (2000 is the default)\n\n%\\end{keyword}\n\n%\\end{frontmatter}\n\\pagestyle{empty}\n%%\n%% Start line numbering here if you want\n%%\n%\\linenumbers\n\n%% main text\n\\section{Introduction}\n\\label{S:1}\n%Jackson network story \nJackson networks are one of the most fundamental objects in the theory of stochastic processing networks. \nSuch network models have long been used for a wide range of applications in transportation, production, computer science, social networks etc., so results concerning their asymptotic behavior present a practical interest.\n\nThere are multiple research directions: one is to evaluate the limit distribution and its product forms in the case when this limit distribution exists. Another research direction considers systems with heavy traffic.       \n%\u0418\u0437\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0438 \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0443\u043a\u0442 \u0444\u043e\u0440\u043c\u044b, \u043a\u043e\u0433\u0434\u0430 \u0440\u0430\u0441\u043f\u0440 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442. \u042d\u0442\u043e\u043c\u0443 \u043f\u043e\u0441\u0432\u044f\u0449\u0435\u043d\u044b [x], \u043f\u0440\u0435\u0434\u0435\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u0432 \u0443\u0441\u043b\u043e\u0432\u0438\u044f\u0445 \u0441\u0442\u0430\u0431\u0438\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0441\u0438\u0441\u0442\u0435\u043c\u044b (\u0431\u0435\u0437 \u0440\u0430\u0441\u0442\u0443\u0449\u0438\u0445 \u043e\u0447\u0435\u0440\u0435\u0434\u0435\u0439)\u044e \u0414\u0440\u0443\u0433\u043e\u0435 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0438\u0445\u0443\u0447\u0435\u043d\u0438\u044f -- \u0441\u0438\u0442\u0443\u0430\u0446\u0438\u044f \u0432\u044b\u0441\u043e\u043a\u043e\u0439 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0443\u0437\u043b\u043e\u0432. \nHeavy traffic and overloaded system cases are analytically non-trivial and at the same time the most crucial, as overloading may lead to breakdowns, production shutdown, losses from downtime, repair costs and other overheads. \n\n%\u0414\u0438\u0444\u0444\u0443\u0437\u0438\u043e\u043d\u043d\u0430\u044f \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u044f \n%Limit theorems \nHeavy traffic limit theorems of the type considered in this paper have attracted a lot of attention previously.\n%Brownian motion [reflected]\n Harrison \\cite{harrison} considered tandem queueing systems and proved a heavy traffic limit theorem for the stationary distribution of the sojourn times. His limit was also given as a complicated function of multidimensional Brownian motion. Harrison later again considered tandem queueing systems, and introduced reflected Brownian motion on the non-negative orthant as the diffusion limit. Other work in the areas of heavy traffic limit theorems and diffusion approximations is surveyed in Whitt  \\cite{whitt} and Lemoine \\cite{lemoine}. Reiman \\cite{reiman} presented heavy traffic limit theorems for the queue length and sojourn time processes associated with open queueing networks. These limit theorems state that properly normalized sequences of queue length and sojourn time converge to a reflected Brownian motion in an orthant. Furthermore, strong (almost sure) approximation with infinite time horizons and a reliable server networks were considered by Chen and Yao \\cite{chen}.\n%Unreliable server\nThere has been also a growing literature on queues with an unreliable server. To emphasize the significance of queueing models with unreliable servers in applications we will refer to some works \\cite{djellab}, \\cite{gaver}, \\cite{sherman}, \\cite{kalimulina}.\n \n \nThe system under consideration in \\cite{coupling} is a single queue system with an unreliable server, and it emerged  as a mathematical model of unregulated crossroads. The simplest model of a vehicle crossing problem in probabilistic terms was considered in \\cite{harreim}. There is a one-lane road $S_{1}$ which is intersected on one side by a single-lane secondary road $S_{2}$. A car waiting on the secondary road $S_{2}$ will turn right only if there is at least distance $J$ between the intersection and the first car on $S_{1}$. We may consider the crossroads with respect to cars arriving on the secondary road $S_{2}$ as a queueing system with an unreliable server. The server is in working state when there are no cars within a distance $J$ of the crossroads on the road $S_{1}$ and it becomes out of order when the first car appears on this interval. By the nature of the system we have to suppose that the breakdown of the server can occur at any time, even when the server is free. Note that a queueing system with an unreliable server may also be considered in the stochastic analysis of crossroads with traffic lights.\n\nIn this paper we present a strong Gaussian approximation for a more functionally complicated system with unreliable servers and generalized input flows. Additionally, we do not require input flows to be independent. \n\n\\begin{definition}\nWe say that a vector-valued random process $\\zeta =\\{\\zeta_t,\\, t\\geq 0\\}$ admits a $r$-strong approximation by  some process $\\overline{\\zeta}=\\{\\overline{\\zeta}_t,t\\geq 0\\}$,\nif there exists a probability space $(\\Omega,\\mathcal{F},\n\\mathsf{P})$ on which one can define both $\\zeta$ and $\\overline{\\zeta}$ in such a way that\n$$\\sup\\limits_{0\\le u\\le t}\\|\\zeta_u-\\overline{\\zeta}_u\\| = o(t^{1/r}),\\text{ a.s., when }t\\to\\infty. $$\n\n\\end{definition}\n\n%\\cite{}\n\n%\\begin{itemize}\n%\\item Bullet point one\n%\\end{itemize}\n%\\begin{enumerate}\n%\\item Numbered list item one\n%\\end{enumerate}\n%\\begin{figure}[h]\n%\\centering\\includegraphics[width=0.4\\linewidth]{placeholder}\n%\\caption{Figure caption}\n%\\end{figure}\n\n\\section{System description}\n\\label{S:2}\n\n%Reference to Section \\ref{S:1}. \n\n%Let $\\xi_{j} = X(\\theta_{j})- X(\\theta_{j-1})$. So that $\\xi_{j}$ - is the number of arrivals during the $j$th regeneration period. \n%Assume that $E \\xi_{j}<\\infty$ and $E\\tau_{j}<\\infty$. Then there exists the limit (w.p.1)\n%$$\\lim_{t\\to\\infty} \\frac{X(t)}{t} = \\lambda_{X} = \\frac{E \\xi_{j}}{E\\tau_{j}} $$\n%For the sake of brevity we assume that the distribution of  $\\tau_{j}$ has an absolutely continuous component.\n\n%\\begin{definition}\n\n%Let $\\{X(t), t\\geq 0\\}$ be a regenerative flow with regeneration points %$\\{\\theta_{j}\\}_{j-0}^{\\infty}, (\\theta_{0} = 0)$. \n%We call $X(t)$ strongly regenerative flow if the following conditions hold\n\n%\\\\1. $\\tau_{n}= \\tau_{n}^{(1)}+ \\tau_{n}^{(2)}$, \n%where $\\tau_{n}^{(1)}$ and $\\tau_{n}^{(2)}$\n%are nonnegative random variables and $\\tau_{n}^{(1)}$ has an exponential %distribution with parameter $\\delta \\in (0,\\infty)$\n\n%\\\\2. $\\{X(\\theta_{n-1}+t)- X(\\theta_{n-1})= A_{n}(t)$\n%w.p.1 \u0434\u043b\u044f $t\\in[0,\\tau_{n}^{(1)} $.\n%Here $A_{n}(t)$ - is a Poisson processes with rate $\\alpha\\in[0,\\infty)$\n\n%\\\\3. Random elements\n%$\\{A_{n}(t),t\\in[0,\\tau_{n}^{(1)}),\\tau_{n}^{(1)}\\}$ \u0438 \n%$\\{X(\\theta_{n-1}+\\tau_{n}^{(1)}+t)- %X(\\theta_{n-1}+\\tau_{n}^{(1)}),t\\in[0,\\tau_{n}^{(2)})\\}$, $\\tau_{n}^{(2)}$\n%are independent ones.\n%\\end{definition}\n%\\textbf{Definition 3.}\n\n%Lets assume on the probability space $(\\Omega_{1},F_{1},P_{1})$ exists Markov process $\\{U(t), t\\geq 0\\}$ with T transition probabilities, continuous sample paths, and on the another probability space $(\\Omega_{2},F_{2},P_{2})$ exists Poison process $\\{N^{*}(t), t\\geq0\\}$ that is independent from U(t).\n%Let assume functions \n%$\\lambda(t)=$\\sum_{i=1}^{T}\\lambda_{i}I\\{U(t)=i\\}$ \n%and \n%\\Lambda(t)= \\int_{0}^{t} \\lambda(y) dy$ exist, \n%Then on the probability space $(\\Omega_{1}\\times \\Omega_{2},\\sigma (F_{1}, F_{2}),P_{1} \\times P_{2})$\n\n%random process $N(t)=N^{*}(\\Lambda(t))$ exists and is a Markov modulated process.\n\n\\subsection{The queuing network with unreliable servers}\n\nThe queuing network $\\mathcal N$ we study has $K$ single server stations, and each of them has an associated infinite capacity waiting room. At least one station has an arrival stream from outside the network, and the vector $A(\\cdot)$ of arrival streams is assumed to be a multi-dimensional regenerative flow. Recall\n\n\\begin{definition}\n\nA multi-dimensional coordinatewise c\\`{a}dl\\`{a}g stochastic process $A (t)$ is called regenerative one if there exists an increasing sequence of random variables $\\{\\theta_{i}, i \\geq 0\\}$, $\\theta_{0} = 0$  such that the sequence\n$$\\{\\kappa_i\\}_{i=1}^{\\infty} = \\{ A(\\theta_{i-1}+t)- A(\\theta_{i-1}),\\theta_{i} - \\theta_{i-1}, t \\in [0, \\theta_{i} - \\theta_{i-1})\\}_{i=1}^{\\infty}$$\nconsists of independent identically distributed  random elements.\nThe random variable $\\theta_{j}$ is said to be the $j$th regeneration point of  $A,$ and $\\tau_{j}= \\theta_{j} - \\theta_{j-1}$ $($where $\\theta_{0} = 0)$ to be the $j$th regeneration period. \n\\end{definition}\n\nFrom Smith \\cite{Smith1955} it is known that we can  define the asymptotic intensity vector $\\lambda = \\lim\\limits_{t\\to\\infty}\\frac{A(t)}{t}$ a.s., and the asymptotic covariance matrix $V = \\lim\\limits_{t\\to\\infty}\\frac{\\mathsf{Var}A(t)}{t}$.\n\nEach station's service times $\\{\\eta_{j}^{i}\\}_{i=1}^{\\infty}$, $j=1,\\ldots, K,$ are mutually independent sequences of i.i.d. random variables with mean $1/\\mu_j$ and variance $\\sigma^2_j$. After being served at station $k,$ the customer is routed to station $j$ $(j=1,\\ldots,K)$ with probability $p_{kj}$.\nThe routing matrix $P=\\|p_{kj}\\|_{k,j=1}^K$ \n%- semistochastic, so that $\\sum_{j=1}^{K}p_{ij}<1$, so that with %probability  $\\alpha=1-\\sum_{j=1}^{k}p_{ij}$ customers served at %station k leave the network. j) Additionally, the matrix $P$ \nis assumed to have spectral radius strictly less than unity, i.e. there is always a positive probability than a served customer leaves the system immediately.\nFor  $i=1,2,\\ldots$ and $k=1,\\ldots K$, define $\\varphi_{k}^{i}$ to be a random variable equal to $j = 1,\\dots, K$ whenever $i$th customer served on station $k$ is routed to station $j,$ and $\\varphi_{k}^{i} = 0$ if this customer exits the network.\nRouting vectors are defined by $\\phi_{k}^{i}=e_{\\varphi_{k}^{i}}$, where $e_{j}$ is the $K$-vector whose $j$th component is 1 and other components are 0, if $j=1,\\ldots,K$, and  $e_0=0$. \nCustomers routing happens independently and immediately.\n\n\nIn our model the service on every channel is influenced by  a random environment which causes breakdowns of the server  (falling into OFF state from ON state) at random moments. The repair of the server also takes a random time.\nWe suppose that consecutive  time intervals of states ON and OFF form two independent sequences of i.i.d. random variables and, for $j$th server, denote them  by $\\{u_j^{i}\\}_{i=1}^\\infty$ and  $\\{v_j^{i}\\}_{i=1}^\\infty$ respectively. Let $a_j = \\mathsf{E}u_j^{1} $, $b_j = \\mathsf{E}v_j^{1}$, $\\alpha_j = {a_j}({b_j+a_j})^{-1}$,  $s^2_j = \\mathsf{Var}u_j^{1} $, $d^2_j = \\mathsf{Var}v_j^{i}$ for $j=1,\\ldots,K$.\n We suppose that the service that was interrupted by the breakdown is continued upon repair from the point at which it was interrupted. \n%We suppose that sequences ${}$\n\n\n%We suppose that all the servers are in critical state, i.e.   $\\lambda_j=\\alpha_j\\mu_j$ for each $j=1,\\ldots,K.$\nLet $Q(t) = (Q_1(t),\\dots, Q_K(t))$  be the vector of number of customers in each channel at time $t$. \nNext we need  vector-valued busy time processes $B(t) = (B_1(t), \\dots, B_K(t))$.  The $j$th component of  $B(t)$, where $j=1,\\ldots,K,$ indicates the amount of time up to $t$ the server at station $j$  is busy (i.e. in state ON and serving jobs). %$I(t) = t-B(t)$.\nThen,\n%$S_{c}^{k}(t)=\\hat S_{k}(t)- \\alpha_{k}\\mu_{k}(P-E)_{k} t$\n\n$$Q(t)= A(t)+\\sum\\limits_{j=1}^{K} {L_{j}(B_{j}(t))},$$\nwhere \n$$ L_{j}(u) = \\sum\\limits_{i=1}^{S_{j}(u)} (\\phi_{j}^{i}-e_{j}),\\quad 1\\leq k \\leq K. $$\n\nNext, we consider a system of equations \n\\begin{equation}\n\\label{eq:tau}\n\\gamma_{j}=\\lambda_{j}+ \\sum_{i=1}^{k} (\\gamma_i\\wedge\\alpha_i\\mu_i) p_{ij},\\quad j=1,\\ldots,K.\n\\end{equation}\n\nIn the Jackson networks theory, the systems like above play a significant role and are known as the traffic equations. Due to Theorem 7.3 in Chen and Yao \\cite{chen} our traffic equation (\\ref{eq:tau}) has a unique solution $\\gamma = (\\gamma_{1},\\dots, \\gamma_{K})$. \nTherefore we may define a $j$th station traffic coefficient $\\rho_j= \\frac{\\gamma_j}{\\alpha_j\\mu_j}$, $j=1,\\ldots,K$. \nBuffer $j$ is called a nonbottleneck if $\\rho_j<1$, a bottleneck if $\\rho_j\\ge1$, a balanced bottleneck if $\\rho_j=1$, and a strict bottleneck if $\\rho_j>1$.\n\n\n\n\n\n\\subsection{Reflected Brownian motion in orthant}\nIn order to articulate the key result we will introduce one more definition.\n%Our objective in this paper is to construct and characterize a $K$-dimensional stochastic process $Z = \\{Z(t); t\\geq0)\\}$ which has the following properties. First, $Z$ is a Markov process with stationary transition probabilities, continuous sample paths, and state space S. Second, $Z$ behaves on the interior of $S$ like a $K$-dimensional Brownian Motion with covariance matrix $A$ and drift vector b. Third, $Z$ reflects instantaneously at the boundary of S. Finally, the direction, of reflection everywhere on the boundary surface $Z_{i} = 0$ is the $i$th row of the reflection matrix $I-Q$. In assuming that the reflection matrix has ones on the diagonal, we are simply adopting a convenient normalization, since these diagonal elements must be positive. (The direction of reflection at each point on the boundary must have a positive inward normal.) In assuming that $Q$ is nonnegative, we restrict attention to the case where reflection is downward (toward the origin) at every point on the boundary. With $Q$ assumed nonnegative, the requirement that it have spectral radius less than unity is in a sense necessary, as we shall explain later.\nConsider a pair of $K$-dimensional processes $Z=\\{ Z(t); t\\geq 0\\}$ and $Y=\\{ Y(t); t\\geq 0\\}$  which jointly satisfy the following conditions: \n\n%\\begin{equation} \\label{first} \n$$Z(t)= W(t)+Y(t)(I-P),t\\geq 0,$$ \n%\\end{equation},\nwhere $W=\\{ W(t); t\\geq 0\\}$ is a $K$-dimensional Brownian motion with covariance matrix $ \\Gamma$, drift vector $b$ and $W(0)\\in \\mathbb{R}^K_+$; \n$Z(t)$ takes values in $\\mathbb{R}^K_+$, $t\\geq 0$;\n$Y_{j}(.)$ is continuous and nondecreasing with \n$Y_{j}(0)=0$; \nand $Y_{j}(.)$ increases only at those times $t$ where \n$Z_{j}(t)=0,$ $j=1,\\dots K$.\nIt was shown in \\cite{harreim} that for any given Brownian motion $W$ there exists a unique pair of processes $Y$ and $Z$ satisfying conditions above. \n%Each component of Z is the sum of a continuous martingale and a continuous process of bounded variation. \n\nIn the language of \\cite{harreim}  and \\cite{chen}, $Z$ is a reflected Brownian motion on $\\mathbb{R}^K_+$ with drift $b$, covariance matrix $\\Gamma$, and reflection matrix $(I-P)$.\n\n\\section{Main result}\n\\label{S:3}\n\n\\begin{theorem}\nLet $\\mathsf{E}\\tau_i^p<\\infty$, $\\mathsf{E}\\|A(\\theta_{i+1}) - A(\\theta_i)\\|^p<\\infty$, $\\mathsf{E}(\\eta^i_j)^p<\\infty$ for $i\\in\\mathbb{N}$ and any $j=1,\\ldots,K$. Then $Q$ admits $p'$-strong approximation by  a reflected Brownian motion on $\\mathbb{R}^K_+$ with drift $\\lambda-\\alpha\\mu(I-P)$, reflected matrix $(I-P)$, covariance matrix $\\Gamma = ||\\Gamma_{kl}||_{k,l = 1}^K$,\n$$\n\\Gamma_{kl} =V_{kl} +\\sum\\limits_{j=1}^K (\\gamma_j\\wedge\\alpha_j\\mu_j)p_{jk}(\\delta_{kl} - p_{jl})+ (\\sigma^2_j\\mu^3_j\\alpha_j +\\mu_j^2D_j)(\\rho_j\\wedge 1)(p_{jk}-\\delta_{jk})(p_{jl} - \\delta_{jl}) ,\n$$\nwhere\n$$\nD_j = \\frac{a^2_{j} d^2_{j}+b^2_{j} s^2_{j}}{(a_{j}+b_{v^j})^3}\n$$\nand $p'=p$ for $p<4$ and $p'$ is any number less than $4$ for $p\\ge 4$.\n\\end{theorem}\n\\begin{proof}\nTo begin with introduce a number of auxiliary processes. Let $\\chi(t)$, $\\overline{\\chi}(t)$  indicate that at  time  $t$ server is in ON and OFF respectively,\n$$S_j(t) = \\max\\{k: \\sum\\limits_{i=1}^k\\eta_j^i\\le t\\},\\quad\nN_j(t) = \\max\\{k: \\sum\\limits_{i = 1}^k(u^{i}_j+v^{i}_j)\\le t\\},$$ \n$$C_{j}(t)=\\sum\\limits_{i=1}^{N_{j}(t)} u^i_{j}+\\chi(t)\\left(t-\\sum_{i=1}^{N_{j}(t)} (u^{i}_j+v^{i}_j)\\right) + \\overline{\\chi}(t) u^{N_j(t)+1}_j. $$ \nSo, $C_j(t)$ equals the total time before $t$  $j$th server being in the state ON.\n\nNow consider a process\n$\\widetilde{S}_j(t) = S_j(C_j(t))$ and a new network $\\widetilde{\\mathcal N}$ which is defined in the same way as initial network $\\mathcal N$ with the following difference. Service times $\\widetilde{\\eta}_j^i$, $i=1,2,\\dots$ for $j$th server are defined as\n$$\n\\widetilde{\\eta}^i_j = \\inf\\{t: \\widetilde{S}_j(t) = i\\} - \\inf\\{t: \\widetilde{S}_j(t) = i-1\\},\\quad i=1,\\dots.\n$$\nNote that random variables $\\widetilde{\\eta}^i_j$, $i=1,2,\\dots,$ in general are not independent or identically distributed but, as one will see below, the network $\\widetilde{\\mathcal N}$ is more convenient to handle. \n\nFor the network $\\widetilde{\\mathcal N}$, we denote the vector of number of customers at time $t$ and the vector of busy times up to time $t$  by $\\widetilde{Q}(t)$ and $\\widetilde{B}(t)$ respectively. \nThen\n$$\\widetilde{Q}(t)= A(t)+\\sum\\limits_{j=1}^{K} { \\widetilde{L}_{j}(B_{j}(t))},\\,\\,\\text{where}\\,\\, \\widetilde{L}_{j}(u) = \\sum\\limits_{i=1}^{\\widetilde{S}_{j}(u)} (\\phi_{j}^{i}-e_{j}),\\quad 1\\leq j \\leq K. $$\n\n%is a renewal process for any $j=1,\\ldots K$ . Indeed, if we define $\\{\\theta_m^j\\}_{m=0}^{\\infty}$, such that $\\theta_0^j=0$, $\\theta_m^j=\\{ \\inf t: S_j(C_j(t))=m \\}$,  $j=1,\\ldots K$, we can see that \n%As $u^j_i$ are distributed exponentially, so the sequences $\\{\\tau_m^j\\}_{m=1}^{\\infty}= \\{\\theta_m^j-\\theta_{m-1}^{j}\\}$ consist of iid random elements, \n%\\begin{equation}\n%\\label{eq:tau}\n%\\tau_m^j=\\sum_{i=0}^{N_{ON}(\\eta)} v_{i}+\\eta,\\qquad\n%\\hat S^*_j(\\theta_{m-1}+t)=m-1,\\quad t\\in [0, \\tau_m^j ]\n%\\end{equation}\n\n\nSo, due to Theorem 1 in Bashtova, Shashkin \\cite{bashtshash}  the vector-valued process $C=(C_1,\\ldots,C_K)$ admits $p$-strong approximation by a Wiener process  $W^C$ whose components are independent  with drifts $c_j = \\alpha_j$ and variances $D_j$, $j=1,\\dots,K$. In particular $C$ satisfies the functional law of the iterated logarithm.   Also, since each $S_j$ is a renewal process ($j=1,\\dots ,K$), by Cs\\\"{o}rg\\H{o}, Horv\\'{a}th and Steinebach \\cite{CHS}  the process $S$ also admits  $p$-strong approximation by a Wiener process $W^S$ with independent components having drifts $\\mu_j $ and variances $\\sigma_j^2\\mu_j^3$. Hence by Lemma 6.21 in Chen, Yao \\cite{chen} the process $\\tilde{S}$ admits $p$-strong approximation by a Wiener process with independent components having drifts $\\mu_j\\alpha_j$ \nand variances $\\mu_j^2D_j+\\sigma_j^2\\mu_j^3\\alpha_j,$ $j=1,\\ldots,K.$ Additionally $A$ admits a $p$-strong approximation by  a $K$-dimensional Wiener process $W_0$ with drift $\\lambda$ and covariance matrix $V$, and we can assume $W_0$ to be independent of all approximating Wiener processes above.\n\n\nThe Remark 7.17 of Chen, Yao \\cite{chen} is applicable to both Theorems 7.13 and 7.19 there. Thus as by our construction the network $\\tilde{N}$ satisfies the conditions (7.65), (7.66) and (7.68) of the latter theorem,  its first statement  implies the desired result.\n\n\n\n\n\\end{proof}\n\n\n\n\n\n\n\n\n%It can be easily seen:\n%$X(t)- \\tilde X(t)= \\sum_{j=1}^k (\\hat S_{j}(C_{j}(t)-\\hat S_{j}(B_{j}(t)))+ Y(t)(E-P)$, where $Y(t)=(\\alpha_{1},\\mu_{1}, I_{1}(t), \\dots %\\alpha_{k},\\mu_{k}, I_{k}(t))$\n\n%$X(t)- \\tilde X(t)= \\sum_{j=1}^k (\\hat S_{j}(C_{j}(t)- \\mu_{j} (P-E)_{j}C_{j}(t)-\\hat S_{j}(B_{j}(t))+\\mu_{j} (P-E)_{j}B_{j}(t))+\\sum_{j=1}^k \\mu_{j} %(P-E)(C_{j}(t)-B_{j}(t)- \\alpha_{j}I_{j}(t))= \\sum_{j=1}^k [\\hat S_{j}(C_{j}(t)-\\hat S_{j}(B_{j}(t))]+\\sum_{j=1}^k \\mu_{j} %(P-E)(I_{j}(C_{j}(t)-\\alpha_{j}I_{j}(t))$\n\n\n%% The Appendices part is started with the command \\appendix;\n%% appendix sections are then done as normal sections\n%% \\appendix\n\n%% \\section{}\n%% \\label{}\n\n%% References\n%%\n%% Following citation commands can be used in the body text:\n%% Usage of \\cite is as follows:\n%%   \\cite{key}          ==>>  [#]\n%%   \\cite[chap. 2]{key} ==>>  [#, chap. 2]\n%%   \\citet{key}         ==>>  Author [#]\n\n%% References with bibTeX database:\n\n% \\bibliographystyle{model1-num-names}\n\n%% New version of the num-names style\n%\\bibliographystyle{elsarticle-num-names}\n%\\bibliography{sample}\n\n\n%% Authors are advised to submit their bibtex database files. They are\n%% requested to list a bibtex style file in the manuscript if they do\n%% not want to use model1-num-names.bst.\n\n%% References without bibTeX database:\n\n \\begin{thebibliography}{00}\n\n%% \\bibitem must have the following form:\n%%   \\bibitem{key}...\n%%\n\n\n\\bibitem{coupling} L. G. Afanasyeva,  E. E. Bashtova. Coupling method for asymptotic analysis of queues with regenerative input and unreliable server. Queueing Systems, 2014, V. 76, pp. 125--147.\n\\bibitem{afrud} L. G. Afanasyeva, I. V. Rudenko. $G|G|\\infty$ queues and their applications to the transport models analysis. Theory Probab. Appl., 2012, V. 57, No. 3, pp. 427--452.\n\\bibitem{bashtshash}\nE.Bashtova, A.Shashkin. Strong Gaussian approximation for cumulative processes with heavy tails. \\texttt{arXiv:2007.15481}\n\\bibitem{chen}\nH. Chen, D. D. Yao. Fundamentals of Queueing Networks. Springer, New York,  2001.\n\\bibitem{CHS} M.Cs\\\"{o}rg\\H{o}, L.Horv\\'{a}th, J.Steinebach. Invariance principles for renewal processes. Ann. Probab., 1987, V. 15, N. 4, p. 1441--1460.\n\\bibitem{djellab}\nN. V. Djellab. On the $M|G|1$ retrial queue subjected to breakdowns. RAIRO - Oper. Res., 2002, V. 36, pp 299\u2013310.\n\\bibitem{gaver}\nD. P. Gaver. A waiting line with interrupted service, including priorities. J. R. Stat. Soc. (B), 1962, V. 24, No. 1, pp. 73--90.\n\\bibitem{harrison}\nJ. M. Harrison. The heavy traffic approximation for single server queues in series. J. Appl. Probab., 1973, V. 10, No. 3, pp. 613--629.\n\\bibitem{harreim}\nJ. M. Harrison, M. I. Reiman. Reflected Brownian motion on an orthant. Ann. Probab., 1981,\nV. 9, No. 2, pp. 302--308.\n\\bibitem{horvath} L. Horv\\'{a}th. Strong approximations of open queueing networks. Mathematics of Operations Research, 1992, V. 17, No. 2, pp. 487--508.\n\\bibitem{reiman} M. I. Reiman. Open queueing networks in heavy traffic. Mathematics of Operations Research, 1984, V. 9, No. 3 , pp. 441--458.\n\n\\bibitem{igwh1}\nD. L. Iglehart,  W. Whitt. Multiple channel queues in heavy traffic, I. Adv. Appl. Probab., 1970, V. 2, No .1, pp. 150--177.\n\\bibitem{igwh2}\nD. L. Iglehart,  W. Whitt. Multiple channel queues in heavy traffic, II: sequences, networks, and batches. Adv. Appl. Probab., 1970, V. 2, No. 2, pp. 355--369.\n\\bibitem{kalimulina} E. Kalimulina. Analysis of unreliable Jackson-type queueing networks with dynamic routing.  SSRN: https://ssrn.com/abstract=2881956.\n\\bibitem{lemoine}\nA. J. Lemoine. State of the art -- networks of queues: a survey of weak convergence results. Manag. Sci., 1978,  V. 24, No. 11, pp. 1175--1193.\n\n\\bibitem{sherman}\nN. Sherman, J. Kharoufen, M. Abramson. An $M|G|1$ retrial queue with unreliable server for streaming multimedia applications. Prob. Eng. Inf. Sci., 2009, V. 23, pp. 281--304.\n\n\\bibitem{Smith1955} W.L.Smith. Regenerative stochastic processes. Proc. Royal Soc. London Ser. A, 1955, V. 232, N. 1188, p. 6--31. \n\\bibitem{whitt}\nW. Whitt. Heavy traffic limit theorems for queues: a survey. In Mathematical Methods in Queueing Theory (Springer, ed. A. B. Clarke), 1974, V. 98., pp. 307--350.\n\n\n \\end{thebibliography}\n\n\n\\end{document}\n\n%%\n%% End of file `elsarticle-template-1-num.tex'.", "meta": {"timestamp": "2020-10-29T00:03:28", "yymm": "2010", "arxiv_id": "2010.14582", "url": "https://arxiv.org/abs/2010.14582", "source": "arxiv"}}
{"text": "\\documentclass[12pt,onecolumn,journal,letterpaper]{IEEEtran}%\n%\n%\n%\n\n%\n%\n%\n\n\\usepackage{soul}\n\\usepackage[normalem]{ulem}\n\\usepackage{microtype}\n\n\n\\usepackage[hidelinks]{hyperref}\n\\usepackage{bookmark}\n\\usepackage[latin1]{inputenc}\n\\usepackage[english]{babel}\n\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{amsthm,amsfonts,amssymb,amsmath,color}\n\\usepackage{graphicx}\n%\n\\usepackage{placeins}\n\\usepackage{algorithm}\n\\usepackage[]{algpseudocode}\n\n\\usepackage{mathtools}\n%\n%\n\n\\usepackage{tikz}\n\\usetikzlibrary{shapes,arrows,calc}\n\n\\newcommand{\\map}[3]{#1: #2 \\rightarrow #3}\n\\newcommand{\\setdef}[2]{\\{#1 \\mid #2\\}}\n%\n%\n\\newcommand{\\blkdiag}{\\operatorname{diag}}\n\\renewcommand{\\AA}{\\mathcal{A}}\n\\newcommand{\\CC}{\\mathcal{C}} \\newcommand{\\DD}{\\mathcal{D}}\n\\newcommand{\\EE}{\\mathcal{E}} \\newcommand{\\FFF}{\\mathcal{F}}\n\\newcommand{\\GG}{\\mathcal{G}}\\newcommand{\\LL}{\\mathcal{L}}\n\\newcommand{\\II}{\\mathcal{I}}\\newcommand{\\JJ}{\\mathcal{J}}\n\\newcommand{\\MM}{\\mathcal{M}}\n\\newcommand{\\NN}{\\mathcal{N}} \\newcommand{\\PP}{\\mathcal{P}}\n\\newcommand{\\OO}{\\mathcal{O}}\n\\newcommand{\\QQ}{\\mathcal{Q}} \\newcommand{\\RR}{\\mathcal{R}}\n\\newcommand{\\TT}{\\mathcal{T}} \\newcommand{\\UU}{\\mathcal{U}}\n\\newcommand{\\VV}{\\mathcal{V}} \\newcommand{\\WW}{\\mathcal{W}}\n\\newcommand{\\ZZ}{\\mathcal{Z}}\n\n\\newcommand{\\prox}{\\mathbf{prox}}\n\\newcommand{\\argmin}{\\mathop{\\rm argmin}}\n\\newcommand{\\argmax}{\\mathop{\\rm argmax}}\n\\newcommand{\\lexmin}{\\mathop{\\rm lex\\text{-}min}}\n\\DeclareMathOperator{\\rank}{rank}\n\n\\newcommand{\\subj}{\\textnormal{subj. to}}\n\\newcommand{\\subject}{\\text{subject to}} \n\\newcommand{\\maximize}{\\text{maximize}}\n\\newcommand{\\minimize}{\\text{minimize}}\n\\newcommand{\\nbrs}{\\mathcal{N}}\n\\newcommand{\\subgrad}{\\widetilde{\\nabla}}\n\n\\newcommand{\\dom}{\\mathop{\\bf dom}} %\n\\newcommand{\\real}{{\\mathbb{R}}}\n\\renewcommand{\\natural}{{\\mathbb{N}}}\n\\newcommand{\\integer}{{\\mathbb{Z}}}\n\\newcommand{\\expv}{{\\mathbb{E}}}\n%\n\\newcommand{\\conv}[1]{\\textnormal{conv}(#1)}\n\\newcommand{\\vertex}[1]{\\text{vert}(#1)}\n\\newcommand{\\until}[1]{\\{1,\\ldots,#1\\}} \n\\newcommand{\\fromto}[2]{\\{#1,\\ldots,#2\\}}\n\\newcommand{\\convXi}{\\textnormal{conv}(X_i)}\n\n\n%\n\\newcommand\\oprocendsymbol{\\hbox{$\\square$}}\n\\newcommand\\oprocend{\\relax\\ifmmode\\else\\unskip\\hfill\\fi\\oprocendsymbol}\n\\def\\eqoprocend{\\tag*{$\\square$}}\n\n\\renewcommand{\\theenumi}{(\\roman{enumi})}\n\\renewcommand{\\labelenumi}{\\it \\theenumi}\n\n\n\\newtheorem{theorem}{Theorem}[section]\n\\newtheorem{proposition}[theorem]{Proposition}\n\\newtheorem{corollary}[theorem]{Corollary}\n\\newtheorem{definition}[theorem]{Definition} \\newtheorem{lemma}[theorem]{Lemma}\n\\newtheorem{remark}[theorem]{Remark} \\newtheorem{remarks}[theorem]{Remarks}\n\\newtheorem{example}[theorem]{Example} \\newtheorem{algo}[theorem]{Algorithm}\n\\newtheorem{problem}[theorem]{Problem}\n\\newtheorem{assumption}[theorem]{Assumption}\n\\newtheorem{conjecture}[theorem]{Conjecture} \\newtheorem{fact}[theorem]{Fact}\n%\n\\def\\QEDclosed{\\mbox{\\rule[0pt]{1.3ex}{1.3ex}}} %\n%\n%\n\\def\\QEDopen{{\\setlength{\\fboxsep}{0pt}\\setlength{\\fboxrule}{0.2pt}\\fbox{\\rule[0pt]{0pt}{1.3ex}\\rule[0pt]{1.3ex}{0pt}}}}\n\\def\\QED{\\QEDclosed} %\n\\newcommand{\\margin}[1]{\\marginpar{\\tiny\\color{red} #1}}\n\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\br}{\\mathbf{r}}\n%\n%\n%\n\n\\newcommand{\\inc}{\\Gamma}\n\n\\newcommand{\\bDeltax}{\\boldsymbol{\\Delta}\\mathbf{x}}\n\\newcommand{\\bDelta}{\\boldsymbol{\\Delta}}\n\\newcommand{\\bepsilon}{\\boldsymbol{\\varepsilon}}\n\\newcommand{\\bdelta}{\\boldsymbol{\\delta}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\newcommand{\\bZ}{\\mathbf{Z}}\n\\newcommand{\\bY}{\\mathbf{Y}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bw}{\\mathbf{w}}\n\\newcommand{\\by}{\\mathbf{y}}\n\\newcommand{\\bA}{\\mathbf{A}}\n\\newcommand{\\bW}{\\mathbf{W}}\n\\newcommand{\\bg}{\\mathbf{g}}\n\\newcommand{\\bh}{\\mathbf{h}}\n\\newcommand{\\bJ}{\\mathbf{J}}\n\\newcommand{\\bI}{\\mathbf{I}}\n\\newcommand{\\0}{\\mathbf{0}}\n\\newcommand{\\1}{\\mathbf{1}}\n\\newcommand{\\bpi}{\\boldsymbol{\\pi}}\n\\newcommand{\\bxi}{\\boldsymbol{\\xi}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\brho}{\\boldsymbol{\\rho}}\n\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n\\newcommand{\\bphi}{\\boldsymbol{\\phi}}\n\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\n\\newcommand{\\bPhi}{\\boldsymbol{\\Phi}}\n\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n\\newcommand{\\bgamma}{\\boldsymbol{\\gamma}}\n\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n\\newcommand{\\bLambda}{\\boldsymbol{\\Lambda}}\n\\newcommand{\\tbLambda}{\\boldsymbol{\\Lambda}}\n\\newcommand{\\Mmu}{M_{\\bmu}}\n\\newcommand{\\Mtheta}[1]{M_{\\btheta_{#1}}}\n\\newcommand{\\kron}{\\otimes}\n\\newcommand{\\smallsum}{\\textstyle\\sum\\limits}\n\n\\newcommand{\\tp}{\\tilde{p}}\n\\newcommand{\\prob}{\\sigma}\n\\newcommand{\\rvedge}{\\nu}\n\\newcommand{\\cvmat}{\\Pi}\n\\newcommand{\\best}{\\mathrm{best}}\n\n\\DeclarePairedDelimiter \\card{\\lvert}{\\rvert}\n\\let\\Im\\relax\n\\DeclareMathOperator{\\Im}{Im}\n\\DeclareMathOperator{\\Ker}{Ker}\n\n\\renewcommand{\\d}{\\mathrm{d}}\n\n%\n%\n\n\\makeatletter\n\\newcommand{\\StatexIndent}[1][3]{%\n  \\setlength\\@tempdima{\\algorithmicindent}%\n  \\Statex\\hskip\\dimexpr#1\\@tempdima\\relax}\n\\makeatother\n\n\n%\n\\renewcommand{\\inf}{\\operatornamewithlimits{inf\\vphantom{p}}}\n\\renewcommand{\\liminf}{\\operatornamewithlimits{liminf\\vphantom{p}}}\n\\renewcommand{\\limsup}{\\operatornamewithlimits{limsup\\vphantom{p}}}\n\\renewcommand{\\lim}{\\operatornamewithlimits{lim\\vphantom{p}}}\n\n\n\\newcommand{\\AC}[1]{{\\color{red} #1}}\n\\newcommand{\\FF}[1]{{\\color{ForestGreen} #1}}\n\\newcommand{\\IN}[1]{{\\color{MidnightBlue} #1}}\n\\newcommand{\\GN}[1]{{ #1}}\n\n\n\\graphicspath{{figs/}}\n\n\n\\newcommand{\\missingfigure}[1]{\n\\centering\n\\begin{tikzpicture}\n  \\draw[orange, fill=orange!10] (0,0) rectangle +(#1);\n\\end{tikzpicture}\n}\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n%\n\n%\n\n%\n\n%\n\n%\n%\n\n%\n%\n\n%\n%\n\n%\n\n\\def \\algname/{Distributed Primal Decomposition for Time-Varying graphs}\n\\def \\algacronym/{DPD-TV}\n%\n\n\\title{\\Large \\bf\nDistributed Constraint-Coupled Optimization via \\\\ Primal Decomposition over Random Time-Varying Graphs\n}\n\n\\author{Andrea Camisa,\n  Francesco Farina,\n  Ivano Notarnicola,\n  Giuseppe Notarstefano\n  \\thanks{The authors are with the Department of Electrical, \n  Electronic and Information Engineering, Alma Mater Studiorum -- Universit\\`{a} di Bologna, Bologna, Italy,\n  \\texttt{\\{a.camisa, franc.farina, ivano.notarnicola, giuseppe.notarstefano\\}@unibo.it}.\n  %\n  This result is part of a project that has received funding from the European Research\n  Council (ERC) under the European Union's Horizon 2020 research and innovation\n  programme (grant agreement No 638992 - OPT4SMART).\n  }\n  \\thanks{A preliminary version of this work has appeared in\n  the Proceedings of the 58th Conference on Decision and Control~\\cite{camisa2019primal}.\n  The present manuscript provides all the theoretical proofs under a more general\n  communication model, with nonuniform edge probabilities.\n  Moreover, convergence rates are established and a discussion about the algorithm\n  tuning is provided.}\n}\n\n\n\\begin{document}\n\n\\maketitle\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n\\begin{abstract}\n  The paper addresses large-scale, convex optimization problems that need to be\n  solved in a distributed way by agents \n  communicating according to a random\n  time-varying graph.\n  %\n  Specifically, the goal of the network\n  is to minimize the sum of local costs,\n  while satisfying local and coupling constraints.\n  %\n  Agents communicate according to a time-varying model in which edges of an\n  underlying connected graph are active at each iteration with certain\n  non-uniform probabilities.\n  %\n  By relying on a primal decomposition scheme applied to an equivalent problem\n  reformulation, we propose a novel distributed algorithm in which agents\n  negotiate a local allocation of the total resource only with neighbors with\n  active communication links.\n  %\n  The algorithm is studied as a subgradient method with block-wise updates, in\n  which blocks correspond to the graph edges that are active at each iteration.\n  %\n  Thanks to this analysis approach, we show almost sure convergence to the\n  optimal cost of the original problem and almost sure asymptotic primal\n  recovery without resorting to averaging mechanisms typically employed in dual\n  decomposition schemes.\n  %\n  Explicit sublinear convergence rates are provided under the assumption of\n  diminishing and constant step-sizes.\n  %\n  Finally, an extensive numerical study on a plug-in electric vehicle charging\n  problem corroborates the theoretical results.\n\\end{abstract}\n%\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n%\n%\n\n\\section{Introduction}\n\\label{sec:intro}\n\nLarge-scale systems consisting of several independent control systems can be\nfound in numerous contexts ranging from smart grids to autonomous vehicles and\ncooperative robotics.\n%\nIn order to perform cooperative control tasks, such systems (or agents)\nmust employ their computation capabilities and collaborate with each other\nby means of neighboring communication, without resorting to a centralized\ncomputing unit.\n%\nThese cooperative tasks can be often formulated as distributed optimization\nproblems consisting of a large number of decision variables,\neach one associated to an agent in the network and satisfying private constraints.\nFurthermore, a challenging feature of such optimization problems is that\nall the decision variables are intertwined by means of a global coupling constraint,\nthat can be used to model, e.g., formation maintenance requirements or\na total budget that must not be exceeded.\n%\n%\n%\n%\n%\nThis set-up is referred to as \\emph{constraint coupled} optimization.\n%\n%\n%\n%\n%\n%\n\nThe majority of the literature on distributed optimization has focused on a\nframework in which, differently from the constraint-coupled set-up, cost functions and\nconstraints depend on the same, common decision variable, and agents\naim for \\emph{consensual} optimal solutions.\n%\nAn exemplary, non-exhaustive list of works for this optimization set-up is\n\\cite{nedic2009distributed,duchi2012dual,zhu2012distributed,\nmota2013dadmm,shi2014linear,jakovetic2014fast,shi2015extra}.\n%\n%\n%\n%\n%\n%\n%\n%\n%\nOnly recently has the constraint-coupled set-up gathered more attention\nfrom our community, due to its applicability in control.\n%\nIn~\\cite{simonetto2016primal} consensus-based dual decomposition is combined\nwith a primal recovery mechanism, whereas~\\cite{falsone2017dual} considers a\ndistributed dual algorithm based on proximal minimization.\n%\nIn~\\cite{notarnicola2017constraint} a distributed algorithm based on successive\nduality steps is proposed. Differently from~\\cite{simonetto2016primal,falsone2017dual},\nwhich employ running averages for primal recovery, \\cite{notarnicola2017constraint}\ncan guarantee feasibility of primal iterates without averaging schemes.\n%\n%\nIn~\\cite{chang2014distributed} a\nconsensus-based primal-dual perturbation algorithm is proposed to solve smooth\nconstraint-coupled optimization problems. A distributed saddle-point\nalgorithm with Laplacian averaging is proposed in~\\cite{mateos2017distributed}\nfor a class of min-max problems. \nIn~\\cite{burger2014polyhedral}, a distributed algorithm based on cutting planes is formulated.\nRecently, in~\\cite{liang2019distributed} a primal-dual algorithm\nwith constant step-size is proposed under smoothness assumption of both \ncosts and constraints.\n%\nThe works in~\\cite{necoara2015linear, alghunaim2018dual, sherson2019distributed}\nconsider a similar set-up, but the proposed algorithms strongly rely on the sparsity \npattern of the coupling constraints.\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\nLinear constraint-coupled problem set-ups have been also tackled by means of distributed \nalgorithms based on the Alternating Direction Method of Multipliers (ADMM). In~\\cite{chang2014multi}\nthe so-called consensus-ADMM is applied to the dual problem formulation, which is\nthen tailored for an application in Model Predictive Control by~\\cite{wang2017distributed}.\nIn~\\cite{carli2019distributed} an ADMM-based algorithm is proposed and\nanalyzed using an operator theory approach while in~\\cite{zhang2018consensus}\nan augmented Lagrangian approach equipped with a tracking mechanism is proposed.\nHowever, the last two approaches require agents to perform multiple communication rounds \nto converge in a neighborhood of an optimal solution. In~\\cite{falsone2019tracking}\nADMM is combined with a tracking mechanism to design a distributed algorithm\nwith exact convergence to an optimal solution.\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n\\GN{\n%\n%\n%\n%\n%\n%\nThe analysis of our algorithm for random time-varying graphs} builds on\nrandomized block subgradient methods, \\GN{therefore let us} recall some related\nworks from the centralized literature.\n%\nA survey on block coordinate methods is given in~\\cite{beck2013convergence},\nwhile a unified framework for nonsmooth problems can be found~\\cite{razaviyayn2013unified}.\nIn~\\cite{richtarik2014iteration}, a randomized block coordinate descent method\nis formulated, whereas~\\cite{dang2015stochastic} investigates a stochastic block mirror\ndescent approach with random block updates.\n%\n\\GN{In~\\cite{necoara2013random}, a distributed algorithm for a linearly constrained\nproblem is analyzed with coordinate descent methods.\nThis technique is also used in~\\cite{necoara2014random}, which considers a constraint-coupled\nproblem. However, the approach used in~\\cite{necoara2013random,necoara2014random}\nonly allow for a single pair of agents updating at a time and requires smooth\ncost functions.}\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n\n\n%\n%\n%\n%\n%\n%\n%\n\nIn this paper, we propose a distributed algorithm to solve \\GN{nonsmooth}\nconstraint-coupled optimization problems over random, time-varying communication networks. \nWe consider a communication model in which edges of an underlying, connected graph \nhave a certain probability of being active at each time step.\n%\n%\n%\n%\n%\n%\n%\n%\nThe proposed algorithm consists in a two-step procedure in which agents first solve\na local optimization problem and then update a vector representing the local\nallocation of total resource. \n%\n\\GN{\nThe algorithmic structure is inspired to the algorithm for fixed graphs\nin~\\cite{notarnicola2017constraint}. However, the line of analysis\nproposed in~\\cite{notarnicola2017constraint} hampers extension to\ntime-varying graphs. Therefore, in this paper, we develop a new\ntheoretical analysis to deal with the significant challenges arising in\nthe time-varying context. In particular,} this method is interpreted as a primal decomposition scheme\napplied to an equivalent, relaxed version of the target constraint-coupled\nproblem.\n%\nFor this scheme, we prove that almost surely the objective value converges to\nthe optimal cost, and any limit point of the local solution estimates is an\noptimal (feasible) solution.\n%\nMoreover, we prove a sublinear convergence rate of the objective value under the\nassumption of constant or diminishing step-size.  As for constant step-size,\nconvergence to a neighborhood of the solution is attained with a rate\n$O(1/\\sqrt{t})$, while for a diminishing step-size of the type $1/t$,\nexact convergence is attained with rate $O(1/\\log(t))$.\n%\nTo show these results, we employ a graph-induced change of variables to derive\nan equivalent, unconstrained problem formulation. This allows us to recast the\ndistributed algorithm as a randomized block subgradient method in which blocks\ncorrespond to edges in the graph.\n%\n%\n%\n%\n%\n%\nAs a side result, we also provide an almost sure convergence result for a block\nsubgradient method in which (multiple) blocks are drawn according to non-uniform\nprobabilities. This generalized block subgradient method results into updates in\nwhich different combinations of multiple blocks can be chosen. To the best of\nour knowledge, these nontrivial challenges have not been addressed so far in the\n\\GN{block subgradient} literature.\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\\GN{A thorough comparison of the contributions provided in this paper\nwith existing work will be performed in light of the analysis\nprovided in Section~\\ref{sec:analysis}.}\n\nThe paper is organized as follows. In Section~\\ref{sec:set-up_and_algorithm}, we\nintroduce the distributed optimization set-up and we describe the proposed\ndistributed algorithm. In Section~\\ref{sec:block_subgrad_method}, we provide\nintermediate results on a (centralized) block subgradient method, which are then\nused in Section~\\ref{sec:analysis} for the analysis of the distributed\nalgorithm. Convergence rates and a discussion on algorithm tuning are\nenclosed in Section~\\ref{sec:rates_and_discussion}. Finally, in\nSection~\\ref{sec:simulations}, an extensive numerical study on a control\napplication is presented.\n\n\\paragraph*{Notation} %\nThe symbols $\\0$ and $\\1$ denote the vector of zeros\nand ones respectively. %\nThe $n \\times n$ identity matrix is denoted by $I_n$. Where\nthe size of the matrix is clear from the context, we drop the subscript $n$.\nGiven a vector $\\bx \\in \\real^n$ and a positive definite matrix\n$W \\in \\real^{n \\times n}$, we denote by $\\|\\bx\\|_W = \\sqrt{\\bx^\\top W \\bx}$\nthe norm of $\\bx$ weighted by $W$, which we also term $W$-norm.\nGiven two vectors $\\bx,\\by\\in\\real^n$ we write $\\bx \\le \\by$ (and\nconsistently for other sides) to denote component-wise inequalities.\nThe symbol $\\kron$ denotes the Kronecker product.\n%\nGiven a convex function $f(\\bx) : \\real^n \\rightarrow \\real$\nand a vector $\\bar{\\bx} \\in \\real^n$, we denote by\n$\\subgrad f(\\bar{\\bx})$ a subgradient of $f$ at $\\bar{\\bx}$.\n%\nGiven a vector $\\bz$ arranged in $m$ blocks, its $\\ell$-th block\n(or portion) is denoted by $\\bz_\\ell$ or, interchangeably, by $[\\bz]_\\ell$,\nand the complete vector is written $\\bz = (\\bz_1, \\ldots, \\bz_m)$.\n%\n%\n%\n\n%\n%\n\n\\section{Optimization Set-up and Distributed Algorithm}\n\\label{sec:set-up_and_algorithm}\n\nIn this section, we formalize the investigated problem and\nnetwork set-up. Then, we present the proposed\ndistributed algorithm together with its convergence result.\nFinally, we recall some preliminaries for the subsequent analysis.\n\n\\subsection{Distributed Constraint-Coupled Optimization}\n\\label{sec:set-up}\n\nWe deal with a network of $N$ agents that must solve\na \\emph{constraint-coupled} optimization problem, which can be\nstated as follows\n%\n\\begin{align}\n\\label{eq:problem_original}\n\\begin{split}\n  \\min_{\\bx_1, \\ldots, \\bx_N} \\: & \\: \\sum_{i=1}^N f_i(\\bx_i)\n  \\\\\n  \\subj \\: & \\: \\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0,\n  \\\\\n  & \\: \\bx_i \\in X_i, \\hspace{1cm} i \\in \\until{N},\n\\end{split}\n\\end{align}\n%\n%\n%\nwhere $\\bx_1,\\ldots,\\bx_N$ are the decision variables with each $\\bx_i \\in \\real^{n_i}$, $n_i \\in \\natural$.\nMoreover, for all $i \\in \\until{N}$, $\\map{f_i}{\\real^{n_i}}{\\real}$\ndepends only on $\\bx_i$, $X_i \\subset \\real^{n_i}$ is the\nconstraint set associated to $\\bx_i$ and\n$\\map{\\bg_i}{\\real^{n_i}}{\\real^S}$ is the $i$-th contribution to the\n(vector-valued) \\emph{coupling} constraint $\\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0$.\n%\n%\n%\n%\n%\n\nIn the considered distributed computation framework, the problem data\nare assumed to be scattered throughout the network. Agents have only a\npartial knowledge of the entire problem and must cooperate with each other\nin order to find a solution.\n%\nEach agent $i$ is assumed to know only its local constraint $X_i$,\nits local cost $f_i$ and its own contribution $\\bg_i$ to the\ncoupling constraints, and is only interested in computing its own\nportion $\\bx_i^\\star$ of an optimal solution\n$(\\bx_1^\\star, \\ldots, \\bx_N^\\star)$ of problem~\\eqref{eq:problem_original}.\n\nThe following two assumptions guarantee that\n\\emph{(i)} the optimal cost of problem~\\eqref{eq:problem_original} is finite\nand at least one optimal solution exists,\n\\emph{(ii)} duality arguments are applicable.\n%\n\\begin{assumption}\n\\label{ass:problem}\n  For all $i \\in \\until{N}$, the set $X_i$ is non-empty, convex and compact, the\n  function $f_i$ is convex and each component of $\\bg_i$ is a convex function.\n  \\oprocend\n\\end{assumption}\n%\n\\begin{assumption}[Slater's constraint qualification]\n\\label{ass:slater}\n  There exist $\\bar{\\bx}_1 \\in X_1, \\ldots, \\bar{\\bx}_N \\in X_N$ such that\n  $\\sum_{i=1}^N \\bg_i(\\bar{\\bx}_i) < \\0$.\n  \\oprocend\n\\end{assumption}\n\n%\n%\n\n\\subsection{Random Time-Varying Communication Model}\n\\label{sec:communication model}\n\nAgents are assumed to communicate according to a time-varying\ncommunication graph, obtained as subset of an \\emph{underlying} graph\n$\\GG_u = (\\until{N}, \\EE_u)$, assumed to be undirected and connected, where\n$\\EE_u \\subseteq \\until{N} \\times \\until{N}$ is the set of edges.\nAn edge $(i,j)$ belongs to $\\EE_u$ if and only if agents $i$ and $j$ can\ntransmit information to each other, in which case also $(j,i) \\in \\EE_u$.\n%\nIn many applications, the communication links are not always active\n(due, e.g., to temporary unavailability). This is taken into account\nby considering that each undirected edge $(i,j)\\in\\EE_u$ has a probability\n$\\prob_{ij} \\in (0,1]$ of being active.\n%\nAs a result, the actual communication network is a random, time-varying graph\n$\\GG^t = (\\until{N}, \\EE^t)$, where $t \\in \\natural$ represents a universal\ntime index and $\\EE^t\\subseteq\\EE_u$ is the set of active edges at time $t$.\n%\nThe set of neighbors of agent $i$ in $\\GG^t$ is denoted by\n$\\nbrs_i^t = \\left\\{j \\in \\until{N} \\mid (i,j) \\in \\EE^t \\right\\}$. Consistently,\nthe set of neighbors of agent $i$ in the underlying graph $\\GG_u$\nis denoted by $\\nbrs_{i,u}$.\n\nLet us define $\\rvedge_{ij}^t$ as the Bernoulli random variable that is equal\nto $1$ if $(i,j) \\in \\EE^t$ and $0$ otherwise, for all $(i,j) \\in \\EE_u$ with\n$j > i$ and $t \\ge 0$.\n%\n%\nThe following assumption is made.\n%\n\\begin{assumption}\n\\label{ass:iid_var}\n  For all $(i,j) \\in \\EE_u$ with $j > i$, the random variables\n  $\\{\\rvedge_{ij}^t\\}_{t \\ge 0}$ are independent and identically\n  distributed (i.i.d.). Moreover, for all $t \\ge 0$, the random variables\n  $\\{\\rvedge_{ij}^t\\}_{(i,j) \\in \\EE_u, \\: j > i}$ are mutually independent.\n  \\oprocend\n\\end{assumption}\n\n\\noindent A pictorial representation of the time-varying communication\nmodel is provided in Figure~\\ref{fig:network_model}.\n%\n\\begin{figure}[htbp]\\centering\n\\vspace{0.15cm}\n\n  \\includegraphics{tikz_network}\n  \n  \\caption{\n    Example of random time-varying network with $N = 4$ agents.\n    Active edges are denoted with red lines, while inactive edges are depicted\n    with dashed gray lines. The (connected) underlying graph is the union of\n    all such edges, and the activation probabilities are specified in the table.\n  }\n\\label{fig:network_model}\n\\end{figure}\n\n%\n%\n\n\\subsection{Distributed Algorithm Description}\n\\label{sec:algorithm_description}\n\nLet us now introduce the \\algname/ (\\algacronym/) algorithm to compute an optimal solution\n$(\\bx_1^\\star, \\ldots, \\bx_N^\\star)$ of problem~\\eqref{eq:problem_original}.\nInformally, the algorithm works as follows.\n%\nEach agent stores and updates a local solution estimate $\\bx_i^t \\in \\real^{n_i}$\nand the auxiliary variables $\\rho_i^t \\in \\real, \\bmu_i^t, \\by_i^t \\in \\real^{S}$.\n%\nAt the beginning, the variable $\\by_i^t$ is initialized such that\n$\\sum_{i=1}^N \\by_i^0 = \\0$ (e.g., $\\by_i^0 = \\0$ for all $i$).\nAt each iteration $t$, agents solve a local optimization problem using the\ncurrent value of $\\by_i^t$. The variables $(\\bx_i^t, \\rho_i^t)$ are set to the\nprimal solution of this problem, where $\\bx_i^t$ forms an estimate of\n$\\bx_i^\\star$ and $\\rho_i^t$ is \\GN{%\na transient} violation of the coupling\nconstraints (more details are given in Section~\\ref{sec:relaxation_primal_decomp}).\nThe variable $\\bmu_i^t$ is set to the dual solution of the problem and,\ntogether with the information gathered from neighbors,\nis used to update $\\by_i^t$.\n\nFormally, let $\\alpha^t \\ge 0$ denote the step-size and let $M > 0$ be a\ntuning parameter (see Section~\\ref{sec:discussion_M} for a discussion).\nThe next table summarizes the \\algacronym/ algorithm from the perspective of node $i$,\nwhere the notation ``$\\bmu_i :$'' in~\\eqref{eq:alg_local_prob}\nmeans that $\\bmu_i$ is the Lagrange multiplier associated to %\n$\\bg_i(\\bx_i) \\leq \\by_i^t + \\rho_i\\1$.\n\n%\n\\begin{algorithm}[H]\n\\renewcommand{\\thealgorithm}{}\n\\floatname{algorithm}{Algorithm}\n\n  \\begin{algorithmic}[0]\n    \n    \\Statex \\textbf{Initialization}: $\\by_i^0$ such that $\\sum_{i=1}^N \\by_i^0 = \\0$\n    \\medskip\n\n    \\Statex %\n    \\textbf{For} $t = 0, 1,  2, \\ldots$\n    \\medskip\n    \n      \\StatexIndent[0.75]\n      \\textbf{Compute} $((\\bx_i^t, \\rho_i^t), \\: \\bmu_i^t)$ as a primal-dual\n      solution of\n      %\n      \\begin{align}\n      \\label{eq:alg_local_prob}\n      \\begin{split}\n        \\min_{\\bx_i, \\rho_i} \\hspace{1.2cm} &\\: f_i(\\bx_i) + M \\rho_i\n        \\\\\n        \\subj \\:\n        \\:\\: \\bmu_i : \\:\n        & \\: \\bg_i(\\bx_i) \\leq \\by_i^t + \\rho_i\\1\n        \\\\\n        & \\: \\bx_i \\in X_i, \\: \\: \\rho_i \\ge 0\n      \\end{split}\n      \\end{align}\n\n      \\StatexIndent[0.75]\n      \\textbf{Gather} $\\bmu_j^t$ from $j \\in \\nbrs_i^t$ and update\n      %\n      \\begin{align}\n        \\label{eq:alg_update}\n        \\by_i^{t+1} = \\by_i^t + \\alpha^t \\sum_{j \\in \\nbrs_i^t} \\big( \\bmu_i^t - \\bmu_j^t \\big)\n      \\end{align}\n\n  \\end{algorithmic}\n  \\caption{\\algacronym/}\n  \\label{alg:algorithm}\n\\end{algorithm}\n\n\\GN{\nThe algorithmic updates of \\algacronym/ are inspired to the scheme proposed\nin~\\cite{notarnicola2017constraint}, where different agent states are considered\nin place of $\\by_i$. This notational variation reflects the different analysis approach\nof \\algacronym/ based on primal decomposition.}\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\nSome appealing features of the \\algacronym/ are worth highlighting.\nThe algorithm naturally preserves privacy of all the agents, in the sense\nthey do not communicate any of their private information (such as the \nlocal cost $f_i$, the local constraint $X_i$ or the local solution \nestimate $\\bx_i^t$).\nIn addition, the algorithm is scalable, i.e., the amount of local computation\nonly depends on the number of neighbors and not on the network size.\n%\n\n\nIn order to state the main result of this paper, let us make the\nfollowing assumption on the step-size sequence.\n%\n\\begin{assumption}\n  \\label{ass:stepsize}\n  The step-size sequence $\\{\\alpha^t\\}_{t \\ge 0}$, with each $\\alpha^t \\ge 0$,\n  satisfies $\\sum_{t=0}^\\infty \\alpha^t \\!=\\! \\infty$ and\n  $\\sum_{t=0}^\\infty (\\alpha^t)^2 \\!< \\!\\infty$.\\oprocend\n\\end{assumption}\n%\n%\nNext we provide the convergence properties of \\algacronym/.\nDespite its simple form, the analysis is quite involved and requires several\ntechnical tools that will be provided in the forthcoming sections.\n%\n\\begin{theorem}\n\\label{thm:convergence}\n\tLet Assumptions~\\ref{ass:problem},~\\ref{ass:slater},~\\ref{ass:iid_var}\n\tand~\\ref{ass:stepsize} hold.\n  %\n\tMoreover, let $\\bmu^\\star$ be an optimal Lagrange multiplier of\n\tproblem~\\eqref{eq:problem_original} associated to the constraint\n\t$\\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0$ and assume $M > \\|\\bmu^\\star\\|_1$.\n  %\n  Consider a sequence $\\{\\bx_i^t, \\rho_i^t\\}_{t \\ge 0}, \\: i \\in \\until{N}$\n  generated by the \\algacronym/ algorithm with allocation\n  vectors $\\by_i^0$ initialized such that $\\sum_{i=1}^N \\by_i^0 = \\0$.\n  %\n  Then, almost surely,\n  %\n  \\begin{enumerate}\n    \\item[(i)] $\\sum_{i=1}^N \\big( f_i(\\bx_i^t) + M \\rho_i^t \\big) \\to f^\\star$\n      as $t \\to \\infty$, where $f^\\star$ is the optimal cost\n      of~\\eqref{eq:problem_original};\n    \n    \\item[(ii)] every limit point of $\\{(\\bx_1^t, \\ldots\\, \\bx_N^t)\\}_{t \\ge 0}$\n      is an optimal (feasible) solution of~\\eqref{eq:problem_original}.\n    \\oprocend\n  \\end{enumerate}\n\\end{theorem}\n%\n\\GN{\nIn principle, in order to satisfy the assumption $M>\\|\\bmu^\\star\\|_1$ in\nTheorem~\\ref{thm:convergence}, knowledge is needed of the dual optimal\nsolution $\\bmu^\\star$. However, this is not necessary in practice, as a\nlower bound of $M$ can be efficiently computed when a Slater point is known.\nIn Section~\\ref{sec:discussion_M}, we provide a sufficient condition to select\nvalid values of $M$ without any knowledge on $\\bmu^\\star$.\n\nNote also that the algorithm does not employ any averaging mechanism typically\nappearing in dual algorithms when the cost functions are not strictly convex.\nHowever, thanks to the primal decomposition approach, we are still able to prove\nasymptotic feasibility (other than optimality) of the sequence\n$\\{(\\bx_1^t, \\ldots\\, \\bx_N^t)\\}_{t \\ge 0}$.\nAs shown in Section~\\ref{sec:simulation_comparison_dual_subg}, the absence of\nrunning averages allows for faster practical convergence, compared to existing methods.\n}\n\n\\GN{\n\\begin{remark}[Computational load of \\algacronym/]\n\tAs many of duality-based distributed algorithms, \\algacronym/ requires the repeated\n\tsolution of local optimization problems and also to compute the\n\tLagrange multiplier $\\bmu_i^t$ associated to the inequality constraint.\n\t%\n%\n%\n  As a matter of fact, the computation of $\\bmu_i^t$ has a minor\n  impact on the computational load.\n\tIndeed, if a solver based on interior-point methods is used,\n\tit will provide $\\bmu_i^t$ as a byproduct of the solution process.\n\tAlternatively, denoting $(\\bx_i^t, \\rho_i^t)$ the optimal solution at time $t$,\n\ta Lagrange multiplier $\\bmu_i^t$ can be easily computed as the solution\n\tof a linear system with positivity constraints\n\t(cf.~\\cite[Proposition 5.1.5]{bertsekas1999nonlinear}), i.e.,\n\t%\n\t\\begin{align*}\n\t  \\bmu_{i,s} (\\bg_{i,s}(\\bx_i^t) - \\by_{i,s}^t - \\rho_i^t) = 0\n\t  \\quad \\forall \\: s, \\hspace{0.3cm} \\text{with }\n\t  \t\\bmu_i \\ge 0.\n\t  \t\\eqoprocend\n\t\\end{align*}\n\\end{remark}\n}\n\n\n%\n\n%\n%\n\n\\subsection{\\GN{Preliminaries on} Relaxation and Primal Decomposition}\n\\label{sec:relaxation_primal_decomp}\n\n\\GN{\nIn this subsection we recall two preliminary building\nblocks for the algorithm analysis, namely the relaxation and \nthe primal decomposition approach for problem~\\eqref{eq:problem_original}\noriginally introduced in~\\cite{silverman1972primal,bertsekas1999nonlinear,notarnicola2017constraint,camisa2018primal}.}\n%\n%\n%\n%\n%\n%\nIn a primal decomposition scheme, also called right-hand side allocation,\n%\nthe coupling constraints $\\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0$\nare interpreted as a limited resource to be shared among nodes.\n%\nA two-level structure is formulated, where independent subproblems,\nwith a fixed resource allocation, are ``coordinated'' by a master problem\ndetermining the optimal resource allocation.\n%\nWe will apply such approach to an equivalent, relaxed version of\nproblem~\\eqref{eq:problem_original}.\n%\nFormally, consider the following modified version of\nproblem~\\eqref{eq:problem_original},\n%\n\\begin{align}\n\\label{eq:problem_relaxed}\n\\begin{split}\n  \\min_{\\bx_1, \\ldots, \\bx_N, \\rho} \\: & \\: \\sum_{i=1}^N f_i(\\bx_i) + M \\rho\n  \\\\\n  \\subj \\: & \\: \\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\rho \\1,\n  \\\\\n  & \\: \\rho \\ge 0, \\:\\: \\bx_i \\in X_i, \\hspace{0.5cm} i \\in \\until{N},\n\\end{split}\n\\end{align}\n%\nwhere $M > 0$ is a scalar \\GN{and we added the\nscalar optimization variable $\\rho$. In principle, the new variable\nallows for a violation of the coupling constraints (in this sense,\nwe say that problem~\\eqref{eq:problem_relaxed} is a relaxed version of\nproblem~\\eqref{eq:problem_original}). However, \n%\n%\n%\n%\n%\n%\nif the constant $M$ appearing in the penalty term $M \\rho$ is large enough,\nproblem~\\eqref{eq:problem_relaxed} is equivalent\nto~\\eqref{eq:problem_original}, as we recall in the next lemma.}\n%\n\\begin{lemma}[\\cite{notarnicola2017constraint}, Proposition III.3]\n\\label{lemma:relaxation}\n  Let Assumptions~\\ref{ass:problem} and~\\ref{ass:slater} hold.\n  Moreover, let $M$ be such that $M > \\|\\bmu^\\star\\|_1$, with $\\bmu^\\star \\in \\real^S$\n  an optimal Lagrange multiplier for problem~\\eqref{eq:problem_original}\n  associated to the constraint $\\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0$.\n  %\n  Then, the optimal solutions of the relaxed problem~\\eqref{eq:problem_relaxed} are\n  in the form $(\\bx_1^\\star, \\ldots, \\bx_N^\\star, 0)$, where $(\\bx_1^\\star, \\ldots, \\bx_N^\\star)$\n  is an optimal solution of~\\eqref{eq:problem_original}, i.e., the solutions\n  of~\\eqref{eq:problem_relaxed} must have $\\rho = 0$.\n  Moreover, the optimal costs of~\\eqref{eq:problem_relaxed}\n  and~\\eqref{eq:problem_original} are equal.\n\\oprocend\n\\end{lemma}\n\nThe primal decomposition scheme applied to problem~\\eqref{eq:problem_relaxed}\ncan be formulated as follows.\nFor all $i \\in \\until{N}$ and $\\by_i \\in \\real^S$, the $i$-th \\emph{subproblem} is\n%\n\\begin{align}\n\\label{eq:primal_decomp_subprob}\n\\begin{split}\n  p_i(\\by_i) \\triangleq \\min_{\\bx_i, \\rho_i} \\: & \\: f_i(\\bx_i) + M \\rho_i\n  \\\\\n  \\subj \\: & \\: \\bg_i(\\bx_i) \\le \\by_i + \\rho_i \\1\n  \\\\\n  & \\: \\rho_i \\ge 0, \\:\\: \\bx_i \\in X_i,\n\\end{split}\n\\end{align}\n%\nwhere $\\by_i \\in \\real^S$ is a (given) local \\emph{allocation} for node $i$ and\n$p_i(\\by_i)$ denotes the optimal cost as a function of $\\by_i$.\n%\nThe local allocations are ``coordinated'' by the \\emph{master} problem, i.e.,\n%\n\\begin{align}\n\\label{eq:primal_decomp_master}\n\\begin{split}\n  \\min_{\\by_1, \\ldots, \\by_N} \\: & \\: \\sum_{i=1}^N p_i(\\by_i)\n  \\\\\n  \\subj \\: & \\: \\sum_{i=1}^N \\by_i = \\0.\n\\end{split}\n\\end{align}\n%\nIn the next, we will denote the cost function\nof~\\eqref{eq:primal_decomp_master} as $p(\\by) = \\sum_{i=1}^N p_i(\\by_i)$,\nwhere $\\by = (\\by_1, \\ldots, \\by_N) \\in \\real^{SN}$.\n%\n%\n%\n%\n%\n%\n%\n%\nNotice that subproblem~\\eqref{eq:primal_decomp_subprob} is always feasible\nfor all $\\by_i \\in \\real^S$.\n%\nThe following lemma establishes the equivalence between the master\nproblem~\\eqref{eq:primal_decomp_master} and the relaxed\nproblem~\\eqref{eq:problem_relaxed}.\n%\n\\begin{lemma}[\\cite{silverman1972primal}]\n\\label{lemma:primal_decomp_equivalence}\n  Let Assumption~\\ref{ass:problem} hold. Then,\n  problems~\\eqref{eq:problem_relaxed} and~\\eqref{eq:primal_decomp_master}\n  are equivalent, in the sense that \\emph{(i)} the optimal costs are equal, \\emph{(ii)} if\n  $(\\bx_1^\\star, \\ldots, \\bx_N^\\star)$ is an optimal solution of~\\eqref{eq:problem_relaxed} and\n  $(\\by_1^\\star, \\ldots, \\by_N^\\star)$ is an optimal solution of~\\eqref{eq:primal_decomp_master},\n  then $(\\bx_i^\\star, 0)$ is an optimal solution of~\\eqref{eq:primal_decomp_subprob},\n  with $\\by_i = \\by_i^\\star$, for all $i \\in \\until{N}$.\n  \\oprocend\n\\end{lemma}\n\nThanks to Lemma~\\ref{lemma:relaxation} and Lemma~\\ref{lemma:primal_decomp_equivalence},\nsolving problem~\\eqref{eq:problem_original} is equivalent to solving\nproblem~\\eqref{eq:primal_decomp_master}. We will show\nthat indeed the \\algacronym/ algorithm solves~\\eqref{eq:primal_decomp_master},\nthereby indirectly providing a solution to~\\eqref{eq:problem_original}.\n%\nConsider now the update~\\eqref{eq:alg_update}.\nOwing to the discussion in~\\cite[Section 5.4.4]{bertsekas1999nonlinear},\n%\ncan be rewritten as\n%\n\\begin{align*}\n  \\by_i^{t+1} = \\by_i^{t}\n    - \\alpha^t \\sum_{j \\in \\nbrs_i^t} \\big( \\subgrad p_i(\\by_i^t) - \\subgrad p_j(\\by_j^t) \\big),\n\\end{align*}\n%\nfor $i \\in \\until{N}$. This equivalent form highlights that,\nat each iteration $t$, agents adjust their local allocation $\\by_i^t$\nby performing a subgradient-like step, based only on local and neighboring\ninformation. Note also that, by direct calculation, using the fact that\nthe underlying graph is undirected, one can see that\n$\\sum_{i=1}^N \\by_i^{t} = \\sum_{i=1}^N \\by_i^{0} = \\0$\nfor all $t$,\n%\nwhich means that the allocation sequence produced by the algorithm\nsatisfies the constraint $\\sum_{i=1}^N \\by_i = \\0$ appearing\nin problem~\\eqref{eq:primal_decomp_master} at each time step $t$.\n\n\\GN{\n\\begin{remark}[On the variables $\\rho_i$]\nFinally, let us comment on the role of the variables $\\rho_i$\nappearing in problem~\\eqref{eq:alg_local_prob}.\nIf we impose $\\rho_i = 0$, problem~\\eqref{eq:alg_local_prob}\nmay become infeasible for some values of $\\by_i$.\nThus, the variable $\\rho_i$ guarantees that\nthe agents can always select a sufficiently large value\nof $\\rho_i$ in order to satisfy the constraint\n$\\bg_i(\\bx_i) \\le \\by_i^t + \\rho_i\\1$.\n%\nBy Theorem~\\ref{thm:convergence}, the sequences $\\{\\rho_i^t\\}_{t \\ge 0}$\nconverge to zero and, hence, they represent only a temporary violation.\n\nStrictly speaking, if one wanted to apply the primal decomposition method\ndirectly to problem~\\eqref{eq:problem_original} (or, equivalently,\nto problem~\\eqref{eq:problem_relaxed} with $\\rho_i = 0$),\nadditional constraints of the type $\\by_i \\in Y_i$, $i \\in \\until{N}$\nshould be included in problem~\\eqref{eq:primal_decomp_master},\nwith each $Y_i$ being the set of $\\by_i$ such that the subproblems are\nfeasible \\cite[Section 6.4.2]{bertsekas1999nonlinear}.\n%\nHowever, as it will be clear from the forthcoming analysis, this would prevent us\nfrom obtaining a purely distributed scheme (in particular, problem~\\eqref{eq:problem_z}\nwould not be unconstrained).\n\\oprocend\n\\end{remark}\n}\n\n%\n%\n\n\\section{Randomized Block Subgradient for Convex Problems}\n\\label{sec:block_subgrad_method}\n\nIn this section, we formulate a (centralized) randomized block subgradient\nmethod for convex problems and formally prove its convergence.\nThis algorithm will be used in the next to solve an equivalent form of\nproblem~\\eqref{eq:primal_decomp_master}, where the update of blocks is\nassociated to the activation of edges in the graph.\nThe results provided here hold for a more general class of optimization\nproblems, therefore for this section we temporarily stop our\ndiscussion to formalize and analyze the randomized block subgradient method.\nSubsequently, we loop back to the main focus of this work and apply the results\nof this section for the analysis of \\algacronym/.\n\nLet us consider the unconstrained convex problem\n%\n\\begin{align}\n\\label{eq:prob_block_subgrad}\n\\begin{split}\n  \\min_{\\theta \\in \\real^m} \\: & \\: \\varphi(\\theta),\n\\end{split}\n\\end{align}\n%\nwhere $\\theta$ is the optimization variable and\n$\\map{\\varphi}{\\real^m}{\\real}$ is a convex function.\nWe assume that problem~\\eqref{eq:prob_block_subgrad} has finite optimal cost,\ndenoted by $\\varphi^\\star$, and that (at least) an optimal solution\n$\\theta^\\star \\in \\real^m$ exists, such that\n$\\varphi^\\star = \\varphi(\\theta^\\star)$.\n\nLet us consider a partition of $\\real^m$ into $B \\in \\natural$ parts, i.e.,\n$\\real^m = \\real^{m_1} \\times \\cdots \\times \\real^{m_B}$, such that\n$m = \\sum_{\\ell=1}^B m_\\ell$. Therefore, the optimization variable is\nthe stack of $B$ blocks,\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\\begin{align*}\n  \\theta = (\\theta_1, \\ldots, \\theta_B),\n\\end{align*}\n%\nwhere $\\theta_\\ell \\in \\real^{m_\\ell}$ for all $\\ell \\in \\until{B}$.\n%\nNow, we develop a subgradient method with block-wise updates to solve\nproblem~\\eqref{eq:prob_block_subgrad}. At each iteration $t \\in \\natural$,\neach block $\\ell$ is updated with a probability $\\prob_\\ell > 0$.\n\nWe stress that according to the considered model,\nblocks can have different update probabilities and\nmultiple blocks can be updated simultaneously.\n\n%\n%\n%\nFor all $t$, we denote by\n$B^t \\subseteq \\until{B}$ the index set of the blocks selected at time $t$.\nFor all $\\ell \\in \\until{B}$ and $t \\ge 0$, let us define\n$\\rvedge_{\\ell}^t$ as the Bernoulli random variable that is equal\nto $1$ if $\\ell \\in B^t$ and $0$ otherwise.\n%\n%\n%\nThe following assumption is made (compare with Assumption~\\ref{ass:iid_var}).\n%\n\\begin{assumption}\n\\label{ass:iid_var_blocks}\n  For all $\\ell \\in \\until{B}$, the random variables\n  $\\{\\rvedge_{\\ell}^t\\}_{t \\ge 0}$ are independent and identically\n  distributed (i.i.d.). Moreover, for all $t \\ge 0$, the random variables\n  $\\{\\rvedge_{\\ell}^t\\}_{\\ell \\in \\until{B}}$ are mutually independent.\n  \\oprocend\n\\end{assumption}\n%\n%\n%\n%\n%\n%\n\nThe algorithm considered here is based on a subgradient method.\nHowever, at each iteration $t$, only the blocks in $B^t$ are updated, i.e.,\n%\n\\begin{align}\n\\theta_\\ell^{t+1}\n=\n\\begin{cases}\n  \\theta_\\ell^t - \\alpha^t [\\subgrad \\varphi(\\theta^t)]_\\ell,\n  \\hspace{0.5cm}\n  & \\text{if } \\ell \\in B^t,\n\\\\\n  \\theta_\\ell^t,\n  & \\text{if } \\ell \\notin B^t,\n\\end{cases}\n\\label{eq:block_algorithm}\n\\end{align}\n%\nwhere $\\alpha^t$ is the step-size.\n%\n%\n%\n%\nNote that algorithm~\\eqref{eq:block_algorithm} allows for multiple block updates at once and,\nfurthermore, blocks have non-uniform update probabilities.\nTo the best of our knowledge, this general block-subgradient method has not been studied in the literature.\n%\nTherefore, we now provide the convergence proof for\nalgorithm~\\eqref{eq:block_algorithm}.\n%\n\\begin{theorem}\n  Let Assumption~\\ref{ass:iid_var_blocks} hold and let the step-size sequence\n  $\\{\\alpha^t\\}_{t\\geq 0}$ satisfy Assumption~\\ref{ass:stepsize}.\n  %\n  Moreover, assume the subgradients of $\\varphi$ are block-wise bounded, i.e.,\n  assume for all $\\ell \\in \\until{B}$ there exists $C_\\ell > 0$ such that\n  $\\| [ \\subgrad \\varphi(\\theta) ]_\\ell \\| \\le C_\\ell$ for all\n  $\\theta \\in \\real^{m}$.\n  %\n  Consider a sequence $\\{\\theta^t\\}_{t \\ge 0}$\n  generated by algorithm~\\eqref{eq:block_algorithm},\n  initialized at any $\\theta^0 \\in \\real^{m}$.\n  %\n  Then, almost surely, it holds\n  %\n  \\begin{align*}\n    \\lim_{t \\to \\infty} \\varphi(\\theta^t) = \\varphi^\\star.\n  \\end{align*}\n\\label{thm:block_subgrad_method}\n\\end{theorem}\n%\n\\begin{proof}\\renewcommand{\\qedsymbol}{}\n  To keep the notation light, let us denote the computed subgradients by\n\t$\\beta^t \\triangleq \\subgrad \\varphi(\\theta^t)$. Each block $\\ell$ is\n\tdenoted by $\\beta_\\ell^t = [ \\subgrad \\varphi(\\theta^t) ]_\\ell$.\n\t%\n\tMoreover, for all $\\ell \\in \\until{B}$, let us define the matrix\n\t$U_{\\ell} \\in \\real^{m \\times m}$, obtained by setting to zero\n\tin the identity matrix all the blocks on the diagonal, except for the\n\t$\\ell$-th block. Thus, when applied to a vector $\\theta \\in \\real^{m}$,\n\tall the blocks other than the $\\ell$-th one are set to zero, i.e.,\n\t%\n\t\\begin{align*}\n\t  [ U_{\\ell} \\theta ]_\\kappa\n\t  =\n\t  \\begin{cases}\n\t    \\theta_\\ell & \\text{if } \\kappa = \\ell,\n\t    \\\\\n\t    \\0 & \\text{otherwise},\n\t  \\end{cases}\n\t  \\hspace{0.5cm}\n\t  \\forall \\: \\kappa \\in \\until{B}.\n\t\\end{align*}\n\t%\n\tMoreover, for the sake of analysis, let us define\n\t%\n\t\\begin{align*}\n\t  W \\triangleq \\blkdiag \\Big( \\frac{1}{\\prob_1} I_{m_1}, \\: \\ldots, \\: \\frac{1}{\\prob_B} I_{m_B} \\Big),\n\t\\end{align*}\n\t%\n\twhere $\\blkdiag(\\cdot)$ is the (block) diagonal operator\n%\n%\n\tand we recall that $I_{m_\\ell}$ is the $m_\\ell \\times m_\\ell$\n\tidentity matrix.\n\tNote that $W$ is positive definite, thus we can consider the weighted norm\n\t$\\| \\theta \\|_W$, for which, by definition, it holds\n\t%\n\t\\begin{align*}\n\t  \\| \\theta \\|_W^2 = \\sum_{\\ell=1}^B \\frac{\\| \\theta_\\ell \\|^2}{\\prob_\\ell},\n\t  \\hspace{1cm}\n\t  \\theta \\in \\real^{m}.\n\t\\end{align*}\n\t\n\tNext we analyze algorithm~\\eqref{eq:block_algorithm}. Let us focus on an\n  iteration $t$ and consider any vector $\\theta \\in \\real^{m}$. As\n  for the activated blocks $\\ell \\in B^t$, it holds\n\t%\n\t\\begin{align*}\n\t  \\|\\theta_{\\ell}^{t+1} - \\theta_{\\ell}\\|^2\n\t  &=\n\t  \\|\\theta_{\\ell}^t - \\alpha^t \\beta_\\ell^t - \\theta_{\\ell}\\|^2\n\t  \\\\\n\t  & =\n\t  \\|\\theta_{\\ell}^t - \\theta_{\\ell}\\|^2 + (\\alpha^t)^2 \\|\\beta_\\ell^t\\|^2\n\t  \\\\\n\t  & \\hspace{1cm}\n\t    - 2\\alpha^t (\\beta_\\ell^t)^\\top\n\t      \\big( \\theta_\\ell^t - \\theta_\\ell \\big),\n\t  \\\\\n\t  & \\le\n\t  \\|\\theta_{\\ell}^t - \\theta_{\\ell}\\|^2 + (\\alpha^t)^2 C_{\\ell}^2\n\t  \\\\\n\t  & \\hspace{1cm}\n\t    - 2\\alpha^t U_\\ell (\\beta^t)^\\top\n\t      \\big( \\theta^t - \\theta \\big),\n\t  \\hspace{0.2cm}\n\t  \\forall \\: \\ell \\in B^t,\n\t\\end{align*}\n\t%\n\twhere $\\|\\beta_\\ell^t\\| \\leq C_{\\ell}$ holds by assumption.\n\t%\n\tAs for the other blocks $\\ell \\notin B^t$, we have\n\t%\n\t\\begin{align*}\n\t  \\|\\theta_{\\ell}^{t+1} - \\theta_{\\ell}\\|^2\n\t  &=\n\t  \\|\\theta_{\\ell}^t - \\theta_{\\ell}\\|^2,\n\t  \\hspace{1cm}\n\t  \\forall \\: \\ell \\notin B^t.\n\t\\end{align*}\n\t%\n\tLet us now write the overall evolution in $W$-norm, i.e.,\n\t%\n\t\\begin{align}\n\t  \\|\\theta^{t+1} \\!\\!- \\theta \\|_W^2\n\t  &=\n\t  \\sum_{\\ell \\in B^t}\n\t    \\frac{\\|\\theta_{\\ell}^{t+1} - \\theta_{\\ell}\\|^2}{\\prob_\\ell}\n\t  +\n\t  \\sum_{\\ell \\notin B^t} \n\t    \\frac{\\|\\theta_{\\ell}^{t+1} - \\theta_{\\ell}\\|^2}{\\prob_\\ell}\n\t  \\nonumber\n\t  \\\\\n\t  & \\le\n\t  \\sum_{\\ell=1}^B \\frac{\\|\\theta_{\\ell}^{t} - \\theta_{\\ell}\\|^2}{\\prob_\\ell}\n\t  +\n\t  (\\alpha^t)^2 \\sum_{\\ell \\in B^t} \\frac{C_{\\ell}^2}{\\prob_\\ell}\n\t  \\nonumber\n\t  \\\\\n\t  & \\hspace{0.4cm}\n\t  - 2 \\alpha^t \\bigg( \\sum_{\\ell \\in B^t}\n\t     \\frac{1}{\\prob_\\ell} U_\\ell \\bigg) (\\beta^t)^\\top \\big( \\theta^t - \\theta \\big)\n\t  \\nonumber\n\t  \\\\\n\t  & \\le\n\t  \\|\\theta^{t} - \\theta \\|_W^2\n\t  +\n\t  (\\alpha^t)^2 C\n\t  \\nonumber\n\t  \\\\\n\t  & \\hspace{0.4cm}\n\t  - 2 \\alpha^t \\bigg( \\sum_{\\ell \\in B^t}\n\t    \\frac{1}{\\prob_\\ell} U_\\ell \\bigg) (\\beta^t)^\\top \\big( \\theta^t - \\theta \\big),\n\t\\label{eq:basic_ineq}\n\t\\end{align}\n\t%\n\twhere $C \\triangleq \\sum_{\\ell=1}^B \\frac{C_\\ell^2}{\\prob_\\ell} > 0$.\n\t%\n\tRegarding the matrix $\\sum_{\\ell \\in B^t} \\frac{1}{\\prob_\\ell} U_\\ell$\n\tappearing in~\\eqref{eq:basic_ineq}, its expected value is\n\t%\n\t\\begin{align}\n\t  \\expv\\Bigg[ \\sum_{\\ell \\in B^t} \\frac{1}{\\prob_\\ell} U_\\ell \\Bigg]\n\t  = \\expv\\Bigg[ \\sum_{\\ell=1}^B \\frac{\\rvedge_\\ell^t}{\\prob_\\ell} U_\\ell \\Bigg]\n\t  = \\sum_{\\ell=1}^B U_\\ell = I_{m}.\n\t\\label{eq:expected_value_u_ell}\n\t\\end{align}\n  %\n\tNow, by taking the conditional expectation of~\\eqref{eq:basic_ineq} with\n  respect to $\\FFF^t = \\{\\theta^0, \\ldots, \\theta^t\\}$ (namely the sequence generated by\n  algorithm~\\eqref{eq:block_algorithm} up to iteration $t$),\n  we obtain for all $\\theta \\in \\real^{m}$ and $t \\ge 0$\n\t%\n\t\\begin{align*}\n\t  \\expv\\Big[ \\|\\theta^{t+1} \\!\\!- \\theta \\|_W^2 \\: \\big\\vert \\: \\FFF^t \\Big]\n\t  &\\stackrel{(a)}{\\le}\n\t  \\|\\theta^{t} - \\theta \\|_W^2\n\t    + (\\alpha^t)^2 C\n%\n\t  \\\\\n\t  & \\hspace{0.6cm}\n\t    - 2 \\alpha^t (\\beta^t)^\\top \\big( \\theta^t - \\theta \\big),\n%\n\t  \\\\\n\t  &\\stackrel{(b)}{\\le}\n    \\|\\theta^{t} - \\theta \\|_W^2\n\t    + (\\alpha^t)^2 C\n%\n\t  \\\\\n\t  & \\hspace{0.6cm}\n\t    - 2 \\alpha^t \\big( \\varphi(\\theta^t) - \\varphi(\\theta) \\big),\n%\n\t\\end{align*}\n\t%\n\twhere in $(a)$ we used~\\eqref{eq:expected_value_u_ell} and\n\tthe independence of the drawn blocks from the previous iterations\n\t(cf.~Assumption~\\ref{ass:iid_var_blocks}), and $(b)$ follows\n\tby definition of subgradient of the function $\\varphi$.\n\tBy restricting the above inequality to any optimal solution\n\t$\\theta^\\star$ of problem~\\eqref{eq:problem_z}, we obtain\n\t%\n  \\begin{align}\n\t  \\expv\\Big[ \\|\\theta^{t+1} \\!\\!- \\theta^\\star \\|_W^2 \\: \\big\\vert \\: \\FFF^t \\Big]\n\t  &\\le\n    \\|\\theta^{t} - \\theta^\\star \\|_W^2\n\t    + (\\alpha^t)^2 C\n\t  \\nonumber\n\t  \\\\\n\t  & \\hspace{0.9cm}\n\t    - 2 \\alpha^t \\big( \\varphi(\\theta^t) - \\varphi^\\star \\big).\n\t\\label{eq:basic_ineq_exp}\n\t\\end{align}\n\t%\n\tInequality~\\eqref{eq:basic_ineq_exp} satisfies the assumptions\n\tof~\\cite[Proposition~8.2.10]{bertsekas2003convex}. Thus,\n\tby following the same arguments as in~\\cite[Proposition 8.2.13]{bertsekas2003convex},\n\twe conclude that, almost surely,\n\t%\n\t\\begin{align*}\n\t  \\lim_{t \\to \\infty} \\varphi(\\theta^t) = \\varphi^\\star.\n\t  \\eqoprocend\n\t\\end{align*}\n\\end{proof}\n\n\\begin{remark}\n%\n%\n  By employing a different probabilistic model and by slightly adapting the\n  previous proof, almost sure cost convergence can also be proved for a block\n  subgradient method with single block update, thus complementing,\n  e.g., the results in~\\cite{dang2015stochastic}.\n  \\oprocend\n\\end{remark}\n\n%\n%\n\n\\section{Analysis of \\algacronym/}\n\\label{sec:analysis}\n\nIn this section, we provide the analysis of \\algacronym/. To this end, we first\nreformulate problem~\\eqref{eq:primal_decomp_master} by properly exploiting\nthe graph structure. This reformulation is then used to show that our distributed\nalgorithm is equivalent to a (centralized) randomized block subgradient method.\nWe finally rely on the results of Section~\\ref{sec:block_subgrad_method} to prove\nTheorem~\\ref{thm:convergence}.\n\n\\subsection{Encoding the Coupling Constraints in Cost Function}\n\\label{sec:pb_reformulation}\nAs already mentioned in Section~\\ref{sec:relaxation_primal_decomp},\na solution of problem~\\eqref{eq:problem_original} can be indirectly obtained\nby solving problem~\\eqref{eq:primal_decomp_master}.\n%\nIn order to put problem~\\eqref{eq:primal_decomp_master} into a form that is\nmore convenient for distributed computation, let us apply a graph-induced\nchange of variables.\n%\nSuch a manipulation has a twofold benefit: \\emph{(i)} it allows for the\nsuppression and implicit satisfaction of the constraint $\\sum_{i=1}^N \\by_i = \\0$,\n\\emph{(ii)} it allows for the application of the randomized block subgradient\nmethod to take into account the random activation of edges.\n\nConsider the underlying communication graph $\\GG_u$.\nAssuming an ordering of the edges, let\n$\\inc \\in \\real^{|\\EE_u| \\times N}$ denote the incidence matrix of $\\GG_u$,\nwhere each row (corresponding to an edge in the graph) contains all zero entries\nexcept for the column corresponding to the edge tail (equal to $1$), and for the\ncolumn corresponding to the edge head (equal to $-1$).\n%\nNamely, if the $k$-th row of $\\inc$ corresponds to the edge $(i,j)$, then\nthe $(k,\\ell)$-th entry of $\\inc$ is\n%\n\\begin{align*}\n  ( \\inc )_{k \\ell} =\n  \\begin{cases}\n    1 & \\text{if } \\ell = i,\n    \\\\\n    -1 \\hspace{0.2cm} & \\text{if } \\ell = j,\n    \\\\\n    0 & \\text{otherwise},\n  \\end{cases}\n\\end{align*}\n%\nfor all $\\ell \\in \\until{N}$.\n%\nFor all $(i,j) \\in \\EE_u$, let $\\bz_{(ij)} \\in \\real^{S}$ be a vector associated\nto the edge $(i,j)$ and denote by $\\bz \\in \\real^{S |\\EE_u|}$ the vector stacking\nall $\\bz_{(ij)}$, with the same ordering as in $\\inc$.\nConsider the change of variables for problem~\\eqref{eq:primal_decomp_master}\ndefined through the following linear mapping\n%\n\\begin{align}\n  \\by &= \\cvmat \\bz,\n  \\hspace{1cm}\n  \\bz \\in \\real^{S |\\EE_u|},\n\\label{eq:change_of_variable}\n\\end{align}\n%\nwhere the matrix $\\cvmat$ is defined as\n%\n%\n%\n%\n\\begin{align}\n  \\cvmat \\triangleq (\\inc^\\top \\kron I_S)  \\in \\real^{SN \\times S |\\EE_u|}.\n\\label{eq:change_variable_matrix}\n\\end{align}\n%\nBy using the properties of the Kronecker product, the blocks of $\\by$\ncan be written as\n%\n\\begin{align*}\n  \\by_i\n  = [ \\cvmat \\bz ]_i\n  = \\sum_{j \\in \\nbrs_{i,u}} \\! (\\bz_{(ij)} - \\bz_{(ji)}),\n  \\hspace{0.5cm}\n  \\forall \\: i \\in \\until{N}.\n\\end{align*}\n%\n%\n%\n%\nThe next lemma formalizes the fact that the change of\nvariable~\\eqref{eq:change_of_variable} implicitly encodes the\nconstraint $\\sum_{i=1}^N \\by_i = \\0$.\n%\n\\begin{lemma}\n\\label{lemma:properties_change_of_variable}\n  The matrix $\\cvmat$ in~\\eqref{eq:change_variable_matrix} satisfies:\n  %\n  \\begin{itemize}\n    \\item[(i)] $\\sum_{i=1}^N [\\cvmat \\bz]_i = \\0$ for all $\\bz \\in \\real^{S|\\EE_u|}$;\n    \n    \\item[(ii)] for all $\\tilde{\\by} \\in \\real^{SN}$ satisfying $\\sum_{i=1}^N \\tilde{\\by}_i = \\0$\n      there exists $\\tilde{\\bz} \\in \\real^{S|\\EE_u|}$ such that $\\tilde{\\by} = \\cvmat \\tilde{\\bz}$.\n  \\end{itemize}\n\\end{lemma}\n%\n\\begin{proof}\n  To prove \\emph{(i)}, we see that\n  %\n  \\begin{align*}\n    \\sum_{i=1}^N [\\cvmat \\bz]_i\n    &=\n    (\\1^\\top \\kron I_S) \\cvmat \\bz\n    \\\\\n    &= (\\1^\\top  \\kron I_S) (\\inc^\\top \\kron I_S) \\bz\n    \\\\\n    &= \\big( (\\inc \\kron I_S) (\\1 \\kron I_S) \\big)^\\top \\bz\n    \\\\\n    &\\stackrel{(a)}{=} \\big( (\\inc \\1) \\kron I_S \\big)^\\top \\bz\n    \\\\\n    &\\stackrel{(b)}{=} \\big( \\0 \\kron I_S \\big)^\\top \\bz = \\0,\n  \\end{align*}\n  %\n  where in $(a)$ we used the fact $(A \\kron B)(C \\kron D) = (AC) \\kron (BD)$\n  since the matrix dimensions are compatible,\n  and $(b)$ follows by the property $\\inc \\1 = \\0$ of incidence matrices.\n  \n  To prove \\emph{(ii)}, let $\\tilde{\\by} \\in \\real^{SN}$ be such that\n  $\\sum_{i=1}^N \\tilde{\\by_i} = \\0$, or, equivalently, $(\\1^\\top \\kron I_S) \\tilde{\\by} = \\0$.\n  %\n  Let us first show that $\\bv^\\top \\tilde{\\by} = 0$ for all $\\bv \\in \\Ker (\\cvmat^\\top)$.\n  To this end, take $\\bv \\in \\Ker (\\cvmat^\\top)$.\n  %\n  Since $\\GG_u$ is connected, then $\\rank(\\inc) = N-1$.\n  Thus, by the properties of the Kronecker product, it holds\n  %\n  \\begin{align*}\n    \\rank(\\cvmat^\\top)\n    &=\n    \\rank(\\inc \\kron I_S)\n    \\\\\n    &=\n    \\rank(\\inc) \\rank(I_S)\n    \\\\\n    &= (N-1)S.\n  \\end{align*}\n  %\n  Moreover, by the Rank-Nullity Theorem, it holds\n  %\n  \\begin{align*}\n    \\dim \\Ker(\\cvmat^\\top)\n    &=\n    SN - \\rank(\\cvmat^\\top) = S.\n  \\end{align*}\n  %\n  But since the columns of $(\\1 \\kron I_S) \\in \\real^{SN \\times S}$ are linearly\n  independent, and since the point \\emph{(i)} of the lemma implies that they\n  belong to $\\Ker(\\Pi^\\top)$, it follows that they are actually a basis of\n  $\\Ker(\\Pi^\\top)$, so that the vector $\\bv$ can be written\n  as $\\bv = (\\1 \\kron I_S) \\blambda$, for some $\\blambda \\in \\real^S$.\n  %\n  Therefore, it holds\n  %\n  \\begin{align*}\n    \\bv^\\top \\tilde{\\by}\n    = \\blambda^\\top \\underbrace{ (\\1^\\top \\kron I_S) \\tilde{\\by} }_{= \\: \\0}\n    = 0.\n  \\end{align*}\n  %\n  Thus, since $\\bv$ is arbitrary, it follows that $\\bv^\\top \\tilde{\\by} = 0$\n  for all $\\bv \\in \\Ker (\\cvmat^\\top)$. By definition of orthogonal complement,\n  this means that $\\tilde{\\by} \\in \\Ker (\\cvmat^\\top)^{\\bot} = \\Im(\\cvmat)$.\n  Equivalently, there exists $\\tilde{\\bz}$ such that\n  $\\tilde{\\by} = \\cvmat \\tilde{\\bz}$. The proof follows since $\\tilde{\\by}$\n  is arbitrary.\n\\end{proof}\n\nWe now plug the change of variable~\\eqref{eq:change_of_variable} into\nproblem~\\eqref{eq:primal_decomp_master}. Formally, for all $i \\in \\until{N}$,\ndefine the functions\n%\n\\begin{align*}\n  \\tp_i \\big( \\{\\bz_{(ij)}, \\bz_{(ji)}\\}_{j \\in \\nbrs_{i,u}} \\big)\n  \\triangleq\n  p_i\\big( [\\Pi \\bz]_i \\big),\n  \\hspace{0.7cm}\n  \\bz \\in \\real^{S|\\EE_u|}.\n\\end{align*}\n%\nBy Lemma~\\ref{lemma:properties_change_of_variable}, we directly\nobtain the following result.\n%\n\\begin{corollary}\n\\label{corollary:equivalence_master_prob_z}\n  Problem~\\eqref{eq:primal_decomp_master} is equivalent to the\n  unconstrained optimization problem\n  %\n  \\begin{align}\n\t  \\min_{\\bz \\in \\real{S|\\EE_u|}} \\:\n\t    \\sum_{i=1}^N\n\t    \\tp_i \\big( \\{\\bz_{(ij)}, \\bz_{(ji)}\\}_{j \\in \\nbrs_{i,u}} \\big),\n\t\\label{eq:problem_z}\n\t\\end{align}\n\t%\n\tin the sense that \\emph{(i)} the optimal costs are equal, and\n  \\emph{(ii)} if $\\bz^\\star$ is an optimal solution\n  of~\\eqref{eq:problem_z}, then $\\by^\\star = \\cvmat \\bz^\\star$ is an\n  optimal solution of~\\eqref{eq:primal_decomp_master}.\n\t\\oprocend\n\\end{corollary}\n\nIn the following, we denote the cost function of~\\eqref{eq:problem_z}\nas $\\tp(\\bz) = \\sum_{i=1}^N \\tp_i \\big( \\{\\bz_{(ij)}, \\bz_{(ji)}\\}_{j \\in \\nbrs_{i,u}} \\big) = p(\\cvmat \\bz)$.\n\n%\n%\n\n\\subsection{Equivalence of \\algacronym/ and Randomized Block Subgradient}\n\\label{sec:block_subgrad_method_equiv}\n\nDifferently from problem~\\eqref{eq:primal_decomp_master},\nits equivalent formulation~\\eqref{eq:problem_z} is unconstrained.\nHence, it can be solved via subgradient methods without projections steps.\n%\nIt is possible to exploit the particular structure of problem~\\eqref{eq:problem_z}\nto recast the random activation of edges as the random update of blocks\nwithin a block subgradient method~\\eqref{eq:block_algorithm} applied\nto problem~\\eqref{eq:problem_z}.\n%\nWe will use the following identifications,\n%\n\\begin{align}\n  \\theta\n    = \\bz,\n  \\hspace{0.5cm}\n  \\text{and}\n  \\hspace{0.5cm}\n  \\varphi(\\theta)\n    = \\sum_{i=1}^N \\tp_i \\big( \\{\\bz_{(ij)}, \\bz_{(ji)}\\}_{j \\in \\nbrs_{i,u}} \\big).\n\\label{eq:identification_z_phi}\n\\end{align}\n%\n%\n%\n%\nAs for the block structure, the mapping is as follows.\nEach block $\\ell \\in \\until{B}$ of $\\bz$, i.e., $\\bz_\\ell \\in \\real^{2S}$,\nis associated to an undirected edge $(i,j) \\in \\EE_u$, with $j > i$,\nand is defined as\n%\n\\begin{align}\n  \\bz_\\ell\n  =\n  \\begin{bmatrix}\n    \\bz_{(ij)}\n    \\\\\n    \\bz_{(ji)}\n  \\end{bmatrix}.\n\\label{eq:identification_blocks}\n\\end{align}\n%\nTherefore, there is a total of $B = |\\EE_u|/2$ blocks.\nAt each iteration $t$, each block $\\bz_\\ell$ is updated if the corresponding\nedge $(i,j) \\in \\EE^t$, i.e., if $\\rvedge_{ij}^t = 1$.\n%\nA pictorial representation of the block structure of $\\bz$ is provided in\nFigure~\\ref{fig:blocks}.\n%\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{tikz_blocks_edges.pdf}\n  \\caption{\n    Block structure of the variable $\\bz$. Each block, say $\\ell$, is\n    associated to an undirected edge, say $(i,j)$.\n    The block is the stack of $\\bz_{(ij)}$, associated to the edge $(i,j)$,\n    and $\\bz_{(ji)}$ associated to the edge $(j,i)$.\n  }\n\\label{fig:blocks}\n\\end{figure}\n\n\\noindent\nConsistently with the notation of Section~\\ref{sec:block_subgrad_method},\nwe use the shorthands $\\prob_\\ell = \\prob_{ij}$ and\n$\\rvedge_\\ell^t = \\rvedge_{ij}^t$.\n%\n%\n%\n%\n%\n%\nAt each iteration $t$ of algorithm~\\eqref{eq:block_algorithm}, the set\n$B^t$ contains all and only the blocks associated\nto the edges in $\\EE^t$.\n\nNext, we explicitly write the evolution of the sequences\ngenerated by \\algacronym/ as a function of the sequences generated by\nthe block subgradient method~\\eqref{eq:block_algorithm}.\n%\nFor this purpose, let us write a subgradient of $\\tp$ at any\n$\\bz \\in \\real^{S|\\EE_u|}$. By definition, it holds $\\tp(\\bz) = p(\\cvmat \\bz)$.\nThus, by using the subgradient property for affine transformations of the\ndomain\\footnote{This property of subgradients is the counterpart of the chain rule\nfor differentiable functions.}, it holds\n%\n\\begin{align}\n  \\subgrad \\tp(\\bz)\n%\n%\n%\n%\n  = (\\inc \\kron I_S) \\subgrad p(\\cvmat \\bz).\n\\label{eq:subgrad_p_tilde}\n\\end{align}\n%\n%\nBy exploiting the structure of $p$,\nthe $i$-th block of $\\subgrad p(\\by)$ is equal to\n$\\frac{\\tilde{\\partial} p(\\by)}{\\partial \\by_i} = \\subgrad p_i(\\by_i)$.\nMoreover, since problem~\\eqref{eq:primal_decomp_subprob} enjoys strong duality,\na subgradient of $p_i$ at $\\by_i$ can be computed as $\\subgrad p_i(\\by_i) = -\\bmu_i$,\nwhere $\\bmu_i$ is an optimal Lagrange multiplier of problem~\\eqref{eq:primal_decomp_subprob}\n(cf.~\\cite[Section 5.4.4]{bertsekas1999nonlinear}).\n%\n%\nBy collecting these facts together with~\\eqref{eq:subgrad_p_tilde}, it\nfollows that the blocks of $\\subgrad \\tp(\\bz)$ can be computed as\n%\n\\begin{align}\n  \\frac{\\tilde{\\partial} \\tp(\\bz)}{\\partial \\bz_{(ij)}}\n  &=\n  \\subgrad p_i\\Big( [ \\cvmat \\bz ]_i \\Big)\n  - \\subgrad p_j\\Big( [ \\cvmat \\bz ]_j \\Big)\n  \\nonumber\n  \\\\\n  &=\n  \\bmu_j - \\bmu_i,\n  \\hspace{2cm}\n  \\forall \\: (i,j) \\in \\EE_u,\n\\label{eq:subgrad_p_tilde_ij}\n\\end{align}\n%\nwhere $\\frac{\\tilde{\\partial} \\tp(\\bz)}{\\partial \\bz_{(ij)}}$ denotes the\nblock of $\\subgrad \\tp(\\bz)$ associated to $\\bz_{(ij)}$ and,\nfor all $k \\in \\until{N}$, $\\bmu_k$ denotes an optimal Lagrange\nmultiplier for the problem\n%\n\\begin{align}\n\\label{eq:subgrad_local_prob}\n\\begin{split}\n  \\min_{\\bx_k, \\rho_k} \\: & \\: f_k(\\bx_k) + M \\rho_k\n  \\\\\n  \\subj \\: & \\: \\bg_k(\\bx_k) \\le [ \\cvmat \\bz ]_k + \\rho_k \\1\n  \\\\\n  & \\: \\rho_k \\ge 0, \\:\\: \\bx_k \\in X_k.\n\\end{split}\n\\end{align}\n%\nCombining~\\eqref{eq:identification_z_phi},~\\eqref{eq:identification_blocks}\nand~\\eqref{eq:subgrad_p_tilde_ij}, the update~\\eqref{eq:block_algorithm}\ncan be recast as\n%\n\\begin{align}\n  \\bz_{(ij)}^{t+1}\n  =\n  \\begin{cases}\n    \\bz_{(ij)}^t + \\alpha^t \\big( \\bmu_i^t - \\bmu_j^t \\big),\n    \\hspace{0.5cm}\n    & \\text{if } (i,j) \\in \\EE^t,\n  \\\\\n    \\bz_{(ij)}^t,\n    & \\text{if } (i,j) \\notin \\EE^t,\n  \\end{cases}\n\\label{eq:alg_z_ij}\n\\end{align}\n%\nwhere $\\bmu_k^t$ denotes an optimal Lagrange multiplier\nof~\\eqref{eq:subgrad_local_prob} with $\\bz = \\bz^t$ (with a slight\nabuse of notation\\footnote{\nIndeed, the symbol $\\bmu_i^t$ was already defined in\nSection~\\ref{sec:algorithm_description} in the \\algacronym/ table.\nIn fact, as per the equivalence of the two algorithms (which is being shown here),\nthe two quantities coincide.}).\n%\nThus,\n%\n\\begin{align}\n  [ \\cvmat \\bz^{t+1} ]_i\n  &=\n  \\sum_{j \\in \\nbrs_{i,u}} \\! (\\bz_{(ij)}^{t+1} - \\bz_{(ji)}^{t+1})\n  \\nonumber\n  \\\\\n  &\\stackrel{(a)}{=}\n  \\underbrace{\n    \\sum_{j \\in \\nbrs_{i,u}} \\! (\\bz_{(ij)}^{t} - \\bz_{(ji)}^{t})\n  }_{\\by_i^t}\n  +\n  2 \\alpha^t \\sum_{j \\in \\nbrs_i^t} \\big( \\bmu_i^t - \\bmu_j^t \\big)\n  \\nonumber\n  \\\\\n  &= \\by_i^{t+1},\n  \\hspace{2cm}\n  i \\in \\until{N},\n  \\label{eq:dpd_block_alg_equivalence}\n\\end{align}\n%\nwhere $(a)$ follows by~\\eqref{eq:alg_z_ij}. Therefore the\n\\algacronym/ algorithm and the block subgradient\nmethod~\\eqref{eq:block_algorithm} are equivalent\n(up to a factor $2$ in front of the step-size $\\alpha^t$, which can\nbe embedded in its definition).\n\nBefore going on, let us state the following technical result.\n%\n\\begin{lemma}\n\\label{lemma:bounded_subgradients}\n  For all $\\bz \\in \\real^{S|\\EE_u|}$, the subgradients of $\\tp$ at $\\bz$\n  are block-wise bounded, i.e.,\n  %\n  \\begin{align*}\n    \\| [ \\subgrad \\tp(\\bz) ]_\\ell \\| \\le C_\\ell,\n    \\hspace{0.5cm}\n    \\forall \\: \\ell \\in \\until{B}, \\forall \\: \\bz \\in \\real^{S|\\EE|}.\n  \\end{align*}\n  %\n  where each $C_\\ell > 0$ is a sufficiently large constant \n  proportional to $M$.\n\\end{lemma}\n%\n\\begin{proof}\n  Fix a block $\\ell$ and suppose that it is associated to the edge $(i,j)$.\n  According to the previous discussion,\n  the $\\ell$-th block of $\\subgrad \\tp(\\bz)$ is equal to\n  %\n  \\begin{align*}\n    [ \\subgrad \\tp(\\bz) ]_\\ell\n    =\n    \\begin{bmatrix}\n      \\bmu_j - \\bmu_i\n      \\\\\n      \\bmu_i - \\bmu_j\n    \\end{bmatrix},\n  \\end{align*}\n  %\n  where each $\\bmu_k$ is a Lagrange multiplier of problem~\\eqref{eq:subgrad_local_prob}.\n  %\n  As shown in~\\cite[Section III-B]{notarnicola2017constraint}, it holds\n  $\\|\\bmu_k\\|_1 \\le M$ for all $k \\in \\until{N}$.\n  %\n  Thus, the proof follows by using the equivalence of norms and by choosing\n  a sufficiently large $C_\\ell > 0$.\n\\end{proof}\n\n%\n%\n\n\\subsection{Proof of Theorem~\\ref{thm:convergence}}\n\\label{sec:proof_theorem_convergence}\nThe arguments used here rely on the convergence of\nthe randomized block subgradient method~\\eqref{eq:block_algorithm}\nand on the algorithm equivalence discussed in\nSection~\\ref{sec:block_subgrad_method_equiv}.\n\nTo prove \\emph{(i)}, let us consider the block subgradient method~\\eqref{eq:block_algorithm}\napplied to problem~\\eqref{eq:problem_z}. Note that the function $\\tp(\\bz)$\nis convex (because the functions $p_i$ are convex, cf.\n\\cite[Section 5.4.4]{bertsekas1999nonlinear}) and its optimal cost is\nequal to $f^\\star$, the optimal cost of~\\eqref{eq:problem_original}\n(cf. Corollary~\\ref{corollary:equivalence_master_prob_z},\nLemma~\\ref{lemma:primal_decomp_equivalence} and Lemma~\\ref{lemma:relaxation}).\n%\nBy Lemma~\\ref{lemma:bounded_subgradients} and by the theorem's\nassumptions, we can apply Theorem~\\ref{thm:block_subgrad_method}\nto conclude that, almost surely,\n%\n\\begin{align*}\n  f^\\star\n  &=\n  \\lim_{t \\to \\infty}\n    \\sum_{i=1}^N \\tp_i \\big( \\{ \\bz_{(ij)}^t, \\bz_{(ji)}^t \\}_{j \\in \\nbrs_{i,u}} \\big)\n  \\\\\n  &\\stackrel{(a)}{=}\n  \\lim_{t \\to \\infty} \\sum_{i=1}^N p_i(\\by_i^t)\n  \\\\\n  &\\stackrel{(b)}{=}\n  \\lim_{t \\to \\infty} \\sum_{i=1}^N \\big( f_i(\\bx_i^t) + M \\rho_i^t \\big),\n\\end{align*}\n%\nwhere $(a)$ follows by definition of $\\tp_i$ and\nby~\\eqref{eq:dpd_block_alg_equivalence} and $(b)$ follows by\nconstruction of $(\\bx_i^t, \\rho_i^t)$.\n\nTo prove \\emph{(ii)}, it is possible to follow the same line of proof\nof~\\cite{notarnicola2017constraint}. However, as here we are considering\na probabilistic setting in a primal decomposition framework, we report\nthe proof for completeness.\n%\nLet us consider the sample set $\\bar{\\Omega}$ for which point\n\\emph{(i)} of the theorem holds, and pick any sample path $\\omega \\in \\bar{\\Omega}$.\n%\nConsider the primal sequence\n$\\{(\\bx_1^t, \\ldots, \\bx_N^t, \\rho_1^t, \\ldots, \\rho_N^t)\\}_{t \\ge 0}$ generated\nby the \\algacronym/ algorithm corresponding to $\\omega$.\nBy summing over $i \\in \\until{N}$ the inequality\n$\\bg_i(\\bx_i^t) \\le \\by_i^t + \\rho_i^t \\1$\n(which holds by construction), it holds\n%\n\\begin{align}\n  \\sum_{i=1}^N \\bg_i(\\bx_i^t)\n  \\le\n  \\sum_{i=1}^N \\by_i^t + \\sum_{i=1}^N \\rho_i^t \\1\n  =\n  \\sum_{i=1}^N \\rho_i^t \\1.\n\\label{eq:proof_primal_recovery_t}\n\\end{align}\n%\nDefine $\\rho^t = \\sum_{i=1}^N \\rho_i^t$.\nBy construction, the sequence $\\{(\\bx_1^t, \\ldots, \\bx_N^t, \\rho^t)\\}_{t \\ge 0}$ is bounded (as a consequence of point \\emph{(i)} and continuity of the functions $f_i(\\bx_i)+ M\\rho_i$), so that\nthere exists a sub-sequence of indices $\\{t_h\\}_{h \\ge 0} \\subseteq \\{t\\}_{t \\ge 0}$\nsuch that the sequence $\\{(\\bx_1^{t_n}, \\ldots, \\bx_N^{t_h}, \\rho^{t_h})\\}_{h \\ge 0}$\nconverges. Denote the limit point of such sequence as\n$(\\bar{\\bx}_1, \\ldots, \\bar{\\bx}_N, \\bar{\\rho})$.\nFrom point \\emph{(i)} of the theorem, it follows that\n%\n\\begin{align*} %\n  \\sum_{i=1}^N f_i(\\bar{\\bx}_i) + M \\bar{\\rho} = f^\\star.\n\\end{align*}\n%\nBy Lemma~\\ref{lemma:relaxation}, it must hold $\\bar{\\rho} = 0$.\nAs the functions $\\bg_i$ are continuous, by taking the limit\nin~\\eqref{eq:proof_primal_recovery_t} as $h \\to \\infty$, with $t = t_h$, it holds\n%\n\\begin{align*} %\n  \\sum_{i=1}^N \\bg_i(\\bar{\\bx_i}) \\le \\bar{\\rho} \\1 = \\0.\n\\end{align*}\n%\n%\n%\nTherefore, the point $(\\bar{\\bx}_1, \\ldots, \\bar{\\bx}_N)$ is an optimal solution\nof problem~\\eqref{eq:problem_original}.\nSince the sample path $\\omega \\in \\bar{\\Omega}$ is arbitrary,\nevery limit point of $\\{(\\bx_1^t, \\ldots, \\bx_N^t)\\}_{t \\ge 0}$\nis feasible and cost-optimal for problem~\\eqref{eq:problem_original},\nalmost surely.\n\\oprocend\n\n\\GN{\n\\subsection{Comparison with Existing Works}\n\\label{sec:comparison_existing_works}\n\nIn this subsection, we are in the position to properly highlight how our\nalgorithm differs from other works proposed in the literature.\n%\n%\n%\nIn the special case of static graphs, the algorithm proposed in this\npaper can be shown, with an appropriate\nchange of variables, to have the same evolution of the algorithm\nproposed in \\cite{notarnicola2017constraint}).\nHowever, several differences are present and are listed hereafter.\n%\nFirst, note that \\algacronym/ requires only one communication step\nper iteration and $S$ local states, whereas\nthe algorithm in \\cite{notarnicola2017constraint} requires\ntwo communication steps per iteration and has a storage demand\nof $2S|\\nbrs_i|$ local states.\n%\nMoreover, the analysis in \\cite{notarnicola2017constraint} relies\non a dual decomposition-based technique which necessarily\nfreezes the graph topology in the problem formulation and does\nnot allow for time-varying networks. Instead, in this paper\nwe consider a primal decomposition approach that allows\nus to deal with random, time-varying graphs.\n\nAs regards other algorithms working on time-varying networks, \none can apply a distributed subgradient method to the dual \nof problem~\\eqref{eq:problem_original}. In this approach, an averaging \nmechanism to obtain a feasible primal solution is also necessary.\nThe primal decomposition rationale behind \\algacronym/ allows us to\navoid this procedure and obtain a faster convergence rate as shown through \nextensive simulations in Section~\\ref{sec:simulation_comparison_dual_subg}.\n\n\n%\n%\n%\n%\n%\n%\n%\n}\n\n%\n%\n\n\\section{Convergence Rates and Further Discussion}\n\\label{sec:rates_and_discussion}\n\nIn this section, we provide convergence rates of \\algacronym/\nand a discussion on the parameter $M$.\n\n\\subsection{Convergence Rates}\nThe \\algacronym/ algorithm enjoys a sublinear rate for both constant\nand diminishing step-size rules. For constant step-size, the cost sequence\nconverges as $O(1/t)$, while for diminishing step-size, the rate is\n$O(1/\\log(t))$.\n%\nThe results provided here are expressed in terms of the quantity\n%\n\\begin{align*}\n  f_\\best^t \\triangleq \\min_{\\tau \\le t} \\sum_{i=1}^N \\expv[ f_i(\\bx_i^\\tau) + M \\rho_i^\\tau ],\n\\end{align*}\n%\nwhere the expression in the expected value is the optimal cost of\nproblem~\\eqref{eq:alg_local_prob} for agent $i$ at time $\\tau$.\nIntuitively, this value represents the best cost value obtained by the algorithm\nup to a certain iteration $t$, in an expected sense.\n\nThe following analysis is based on deriving convergence rates for our generalized\nblock subgradient method and thus also complements the ones in, e.g.,\n\\cite{dang2015stochastic}.\n%\n%\n%\n%\n%\n%\nIn the next lemma we derive a basic inequality.\n%\n\\begin{lemma}\n  Let Assumptions~\\ref{ass:problem},~\\ref{ass:slater} and~\\ref{ass:iid_var} hold.\n  Then, for all $t \\ge 0$ it holds\n  %\n  \\begin{align}\n\t  2 \\Bigg( \\! \\sum_{\\tau=0}^t \\alpha^\\tau \\! \\Bigg) ( f_\\best^t - f^\\star )\n\t  \\le \n\t  \\|\\bz^0 - \\bz^\\star \\|_W^2\n\t    + C \\sum_{\\tau=0}^t (\\alpha^\\tau)^2.\n\t \\label{eq:basic_ineq_convergence_rate}\n\t\\end{align}\t \n\\end{lemma}\n%\n\\begin{proof}\n  We consider the same line of proof of Theorem~\\ref{thm:block_subgrad_method}\n  up to~\\eqref{eq:basic_ineq_exp}, specialized for $\\theta^t = \\bz^t$,\n  $\\theta^\\star = \\bz^\\star$ (an optimal solution of problem~\\eqref{eq:problem_z}),\n  with corresponding cost $\\varphi^\\star = \\tp(\\bz^\\star) = f^\\star$\n  (the optimal cost of problem~\\eqref{eq:problem_original}).\n  %\n\tTaking the total expectation (with respect to $\\FFF^t$) of~\\eqref{eq:basic_ineq_exp},\n\tit follows that, for all $t \\ge 0$,\n\t%\n\t\\begin{align*}\n\t  \\expv\\Big[ \\|\\bz^{t+1} \\!\\!- \\bz^\\star \\|_W^2 \\Big]\n\t  &=\n\t  \\expv\\Big\\{ \\expv\\Big[ \\|\\bz^{t+1} \\!\\!- \\bz^\\star \\|_W^2 \\big\\vert \\FFF^t \\Big] \\Big\\}\n\t  \\\\\n\t  &\\le\n\t    \\expv\\Big[ \\|\\bz^{t} - \\bz^\\star \\|_W^2 \\Big]\n\t    + (\\alpha^t)^2 C\n\t  \\\\\n\t  & \\hspace{0.9cm}\n\t    - 2 \\alpha^t \\Big( \\expv[ \\tp(\\bz^t) ] - f^\\star \\Big).\n\t\\end{align*}\n\t%\n  Applying recursively the previous inequality yields\n  %\n\t\\begin{align*}\n\t  \\expv\\Big[ \\|\\bz^{t+1} \\!\\!- \\bz^\\star \\|_W^2 \\Big]\n\t  &\\le\n\t    \\|\\bz^0 - \\bz^\\star \\|_W^2\n\t    + C \\sum_{\\tau=0}^t (\\alpha^\\tau)^2\n\t  \\\\\n\t  & \\hspace{0.9cm}\n\t    - 2 \\sum_{\\tau=0}^t \\alpha^\\tau \\Big( \\expv[ \\tp(\\bz^\\tau) ] - f^\\star \\Big)\n\t\\end{align*}\n\t%\n\tfor all $t \\ge 0$. By using the fact $\\|\\bz^{t+1} \\!\\!- \\bz^\\star \\|_W^2 \\ge 0$,\n\twe obtain\n\t%\n\t\\begin{align*}\n\t  2 \\sum_{\\tau=0}^t \\alpha^\\tau \\Big( \\expv[ \\tp(\\bz^\\tau) ] - f^\\star \\Big)\n\t  &\\le\n\t    \\|\\bz^0 - \\bz^\\star \\|_W^2\n\t    + C \\sum_{\\tau=0}^t (\\alpha^\\tau)^2,\n\t\\end{align*}\n\t%\n\tfor all $t \\ge 0$. The proof follows by combining the previous inequality with\n\t$\\displaystyle\\expv[ \\tp(\\bz^t) ] \\ge \\min_{\\tau \\le t} \\expv[ \\tp(\\bz^\\tau) ]$\n\tand $\\tp(\\bz^\\tau) = p(\\by^\\tau) = \\sum_{i=1}^N p_i(\\by_i^\\tau)\n\t= \\sum_{i=1}^N f_i(\\bx_i^\\tau) + M \\rho_i^\\tau$.\n\\end{proof}\n\n%\n%\nFor constant step-sizes, it is possible to prove a sublinear convergence\nrate $O(1/t)$, as formalized next.\n%\n\\begin{proposition}[Sublinear rate for constant step-size]\n  Let the same assumptions of Theorem~\\ref{thm:convergence} hold (except\n  for Assumption~\\ref{ass:stepsize}). Assume $\\alpha^t = \\alpha > 0$ for all\n  $t \\ge 0$. Then, it holds\n  %\n  \\begin{align*}\n\t  f_\\best^t - f^\\star\n\t  \\le \n\t  \\frac{\\|\\bz^0 - \\bz^\\star \\|_W^2}{2 \\alpha (t+1)}\n\t    + \\frac{C \\alpha}{2}.\n  \\end{align*}\n\\label{prop:convergence_rate_constant}\n\\end{proposition}\n%\n\\begin{proof}\n  It is sufficient to set $\\alpha^t = \\alpha$\n  in~\\eqref{eq:basic_ineq_convergence_rate}.\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\\end{proof}\n\nNote that the previous convergence rate has a term that goes to zero as $t$\ngoes to infinity, plus a constant (positive) term. In general, without further\nassumptions, only convergence within a neighborhood of the optimum can be\nproved when a constant step-size is used.\n\nFor the case of exact convergence with diminishing step-size, we assume it\nhas the form $\\alpha^t = \\frac{K}{t+1}$ with $K > 0$ (which satisfies\nAssumption~\\ref{ass:stepsize}).\nWe can obtain a sublinear rate $\\OO(1/\\log(t))$, as proved next.\n%\n\\begin{proposition}[Sublinear rate for diminishing step-size]\n  Let the same assumptions of Theorem~\\ref{thm:convergence} hold.\n  Assume $\\alpha^t = \\frac{K}{t+1}$ for all $t \\ge 0$, with $K > 0$.\n  Then, it holds\n  %\n  \\begin{align*}\n\t  f_\\best^t - f^\\star\n\t  \\le \n\t  \\frac{ \\|\\bz^0 - \\bz^\\star \\|_W^2 + C K^2 }\n\t    { 2 K \\log (t+2) }.\n  \\end{align*}\n\\label{prop:convergence_rate_diminishing}\n\\end{proposition}\n%\n\\begin{proof}\n  Let us set $\\alpha^t = \\frac{K}{t+1}$ in~\\eqref{eq:basic_ineq_convergence_rate},\n  then it holds\n  %\n  \\begin{align*}\n    f_\\best^t - f^\\star\n\t  \\le \n\t  \\frac{ \\|\\bz^0 - \\bz^\\star \\|_W^2 + C K^2 \\sum_{\\tau=1}^{t+1} \\frac{1}{\\tau^2} }\n\t    { 2 K\\sum_{\\tau=1}^{t+1} \\frac{1}{\\tau} }.\n  \\end{align*}\n  %\n  The proof follows by using the inequalities $\\sum_{\\tau=1}^{t} \\frac{1}{\\tau^2} \\le 1$\n  and $\\sum_{\\tau=1}^{t} \\frac{1}{\\tau} \\ge \\log (t+1)$.\n\\end{proof}\n\n\\begin{remark}\n  Convergence rates can be also derived under the assumption of fixed (connected)\n  graph by following essentially the same arguments, without block randomization\n  in algorithm~\\eqref{eq:block_algorithm}. This recovers the approach in\n  \\cite{notarnicola2017constraint}.\n  For constant step-sizes the rate is\n  %\n  \\begin{align*}\n    f_\\best^t - f^\\star\n\t  \\le \n\t  \\frac{\\|\\bz^0 - \\bz^\\star \\|^2}{2 \\alpha (t+1)}\n\t    + \\frac{C \\alpha}{2},\n  \\end{align*}\n  %\n  while for diminishing step-sizes the rate is\n  %\n  \\begin{align*}\n    f_\\best^t - f^\\star\n\t  \\le \n\t  \\frac{ \\|\\bz^0 - \\bz^\\star \\|^2 + C K^2 }\n\t    { 2 K \\log (t+2) },\n  \\end{align*}\n  %\n  where here the quantities $f_\\best^t$ and $C$ are defined as\n  $f_\\best^t \\triangleq \\min_{\\tau \\le t} \\sum_{i=1}^N f_i(\\bx_i^\\tau) + M \\rho_i^\\tau$\n  and $C \\triangleq \\sum_{\\ell=1}^B C_\\ell^2$.\n  \\oprocend\n\\end{remark}\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n%\n%\n\n\\subsection{Discussion on the Parameter $M$}\n\\label{sec:discussion_M}\n\nIn this subsection, we discuss the choice of the parameter $M$ in the\nlocal minimization problem of the \\algacronym/ algorithm (cf.~\\eqref{eq:alg_local_prob}).\n%\n%\n%\n\nAs per Theorem~\\ref{thm:convergence}, it must hold $M > \\|\\bmu^\\star\\|_1$,\nwhere $\\bmu^\\star$ is any dual optimal solution of the original\nproblem~\\eqref{eq:problem_original}. This assumption is needed for\nthe relaxation approach of Section~\\ref{sec:relaxation_primal_decomp} to apply.\n%\nIn general, a dual optimal solution $\\bmu^\\star$ of the original\nproblem~\\eqref{eq:problem_original} may not be known in advance. \nHowever, if a Slater point %\nis available (cf.\nAssumption~\\ref{ass:slater}), it is possible for the agents to compute a\nconservative lower bound on $M$.\n%\nThe next proposition provides a sufficient condition to satisfy $M > \\|\\bmu^\\star\\|_1$.\n%\n%\n\\begin{proposition}\n  \\label{prop:upper_bound_M}\n  Let Assumptions~\\ref{ass:problem} and~\\ref{ass:slater} hold.\n  Moreover, let $(\\bar{\\bx}_1, \\ldots, \\bar{\\bx}_N)$ be a Slater point, i.e.,\n  a feasible point for problem~\\eqref{eq:problem_original} with $\\sum_{i=1}^N \\bg_i(\\bar{\\bx}_i) < \\0$.\n  Then, a valid choice of $M$ for Theorem~\\ref{thm:convergence} is any\n  number satisfying\n\t%\n\t\\begin{align}\n\t  M > \\frac{1}{\\gamma} \\sum_{i=1}^N \\Big( f_i(\\bar{\\bx}_i) - \\min_{\\bx_i \\in X_i} f_i(\\bx_i) \\Big),\n\t\\label{eq:upper_bound_M}\n\t\\end{align}\n\t%\n\twhere $\\gamma = \\min_{1 \\le s \\le S} \\{ - \\sum_{i=1}^N g_{is} (\\bar{\\bx}_i) \\}$.\n\\end{proposition}\n%\n\\begin{proof}\n\tLet us consider the dual problem associated to~\\eqref{eq:problem_original} when\n\tonly the constraint $\\sum_{i=1}^N \\bg_i(\\bx_i) \\le \\0$ is dualized, i.e.,\n\t%\n\t\\begin{align}\n\t\\begin{split}\n\t  \\max_{\\bmu \\in \\real^S} \\: & \\: q(\\bmu)\n\t  \\\\\n\t  \\subj \\: & \\: \\bmu \\ge 0,\n\t\\end{split}\n\t\\label{eq:dual_prob}\n\t\\end{align}\n\t%\n\t\\GN{with $q(\\bmu)$ being the dual function, defined as\n\t%\n\t\\begin{align*}\n\t  q(\\bmu)\n\t  &= \\inf_{\\bx_1 \\in X_1, \\ldots, \\bx_N \\in X_N} \\bigg\\{\n\t  \\sum_{i=1}^N \\big( f_i(\\bx_i) + \\bmu^\\top \\bg_i(\\bx_i) \\big) \\bigg\\}\n\t  \\\\\n\t  &= \\sum_{i=1}^N \\inf_{\\bx_i \\in X_i} \\big( f_i(\\bx_i) + \\bmu^\\top \\bg_i(\\bx_i) \\big),\n\t  \\\\\n\t  &= \\sum_{i=1}^N \\min_{\\bx_i \\in X_i} \\big( f_i(\\bx_i) + \\bmu^\\top \\bg_i(\\bx_i) \\big),\n\t\\end{align*}\n\t%\n\twhere the $\\inf$ can be split because the summands\n\tdepend on different variables and the operator $\\inf$ can be replaced by $\\min$ since\n\tthe sets $X_i$ are compact and $f_i, g_i$\n\tare continuous due to convexity (cf. Assumption~\\ref{ass:problem}).}\n\t%\n\tLet us denote by $\\bmu^\\star$ an optimal solution of problem~\\eqref{eq:dual_prob}.\n\tBy Assumptions~\\ref{ass:problem} and~\\ref{ass:slater}, strong duality holds,\n\ttherefore $q(\\bmu^\\star) = \\sum_{i=1}^N f_i(\\bx_i^\\star)$, where\n\t$(\\bx_1^\\star, \\ldots, \\bx_N^\\star)$ is an optimal solution of\n\tproblem~\\eqref{eq:problem_original}. Also, note that $\\bmu^\\star$ is also\n\ta Lagrange multiplier of problem~\\eqref{eq:problem_original} (see, e.g.,\n\t\\cite[Proposition 5.1.4]{bertsekas1999nonlinear}).\n\t%\n\tTo upper bound $\\|\\bmu^\\star\\|_1$, we invoke\n\t\\cite[Lemma 1]{nedic2009approximate},\n\t%\n\t\\begin{align}\n\t  \\|\\bmu^\\star\\|_1\n\t  &\\le\n\t  \\frac{1}{\\gamma} \\Bigg( \\sum_{i=1}^N f_i(\\bar{\\bx}_i) - q(\\bmu^\\star) \\Bigg)\n\t  \\nonumber\n\t  \\\\\n\t  &=\n\t  \\frac{1}{\\gamma} \\sum_{i=1}^N \\big( f_i(\\bar{\\bx}_i) - f_i(\\bx_i^\\star) \\big)\n\t  \\nonumber\n\t  \\\\\n\t  &\\le\n\t  \\frac{1}{\\gamma} \\sum_{i=1}^N \\Big( f_i(\\bar{\\bx}_i) - \\min_{\\bx_i \\in X_i} f_i(\\bx_i) \\Big),\n\t  \\label{eq:upper_bound_mustar}\n\t\\end{align}\n\t%\n\t\\GN{where the minimum in the right-hand side of~\\eqref{eq:upper_bound_mustar}\n\texists by Weierstrass's Theorem,}\n\tand the proof follows by choosing $M$ as any number strictly greater\n\tthan the right-hand side of~\\eqref{eq:upper_bound_mustar}.\n\\end{proof}\n\nNote that, if each agent knows its portion $\\bar{\\bx}_i$ of the Slater vector\n$(\\bar{\\bx}_1, \\ldots, \\bar{\\bx}_N)$, the network can run a combination\nof $\\min$-consensus and average consensus protocols to determine\nthe right-hand side of~\\eqref{eq:upper_bound_M}, because the quantities in\nthe sum are locally computable. As such, the calculation of $M$ can be\ncompletely distributed.\n\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n%\n\n%\n%\n\n\\section{Numerical Study}\n\\label{sec:simulations}\n\nIn this section, we show the efficacy of \\algacronym/ and validate the theoretical\nfindings through numerical computations. \\GN{We first concentrate on a simple\nexample to show the main algorithm features. Then, we perform an in-depth\nnumerical study on an electric vehicle charging scenario.\n%\nAll the simulations are performed with the \\textsc{disropt}\nPython package~\\cite{farina2019disropt} on a desktop PC, with\nMPI-based communication.\n\n\\subsection{Basic Example}\nWe begin by considering a network of $N = 5$ agents that must solve the\nconvex problem\n%\n\\begin{align}\n\\begin{split}\n  \\min_{\\bx_1, \\ldots, \\bx_N} \\: & \\: \\sum_{i=1}^N \\|\\bx_i - \\br_i\\|_1\n  \\\\\n  \\subj \\: & \\: \\sum_{i=1}^N i \\cdot \\bx_i \\le \\0\n  \\\\\n  & \\: -10 \\cdot \\1 \\le \\bx_i \\le 10 \\cdot \\1, \\hspace{0.5cm} i \\in \\until{N},\n\\end{split}\n\\label{eq:nonsmooth_example}\n\\end{align}\n%\nwhere each $\\bx_i \\in \\real^{3}$, and $\\br_i \\in \\real^3$ is a random\nvector with entries in the interval $[15, 20]$.\nProblem~\\eqref{eq:nonsmooth_example} is in the\nform~\\eqref{eq:problem_original} with the positions\n$f_i(\\bx_i) = \\|\\bx_i - \\br_i\\|_1$,\n$X_i = \\big\\{ \\bx_i \\in \\real^3 | -10 \\cdot \\1 \\le \\bx_i \\le 10 \\cdot \\1 \\big\\}$\nand $\\bg_i(\\bx_i) = i \\cdot \\bx_i$. \nNote that the objective function and the coupling constraint functions\nare convex but not smooth.\n\nAs for the communication graph, we generate a random connected graph\nwith random edge activation probabilities. The resulting edge probability\nmatrix is\n%\n\\begin{align*}\n  \\begin{bmatrix}\n    0 & 0 & 0 & 0.5 & 0.6\n    \\\\\n    0 & 0 & 0.4 & 0 & 0.7\n    \\\\\n    0 & 0.4 & 0 & 0 & 0\n    \\\\\n    0.5 & 0 & 0 & 0 & 0\n    \\\\\n    0.6 & 0.7 & 0 & 0 & 0\n  \\end{bmatrix}\n\\end{align*}\n\nIn order to apply the \\algacronym/ algorithm, we compute a valid value of\nthe parameter $M$ appearing in problem~\\eqref{eq:alg_local_prob} by using\nProposition~\\ref{prop:upper_bound_M}\nwith the Slater vector $(\\bar{\\bx}_1, \\ldots, \\bar{\\bx}_N)$ with each\n$\\bar{\\bx}_i = -10 \\cdot \\1$.\nAfter performing all the computations, we obtain the condition $M > 1$\nand we finally choose $M = 6$. The \\algacronym/ algorithm\nis initialized at $\\by_i^0 = 0$ for all $i \\in \\until{N}$ and the\nstep-size $\\alpha^t = 1/(K+1)^{0.6}$ is used (which satisfies\nAssumption~\\ref{ass:stepsize}).\n%\nThe simulation results are reported in Figures~\\ref{fig:simulation_nonsmooth_cost}\nand~\\ref{fig:simulation_nonsmooth_coupling}. The asymptotic behavior of\nTheorem~\\ref{thm:convergence} is confirmed.\n\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_nonsmooth_cost.pdf}\n  \\caption{\n    \\GN{Evolution of the normalized cost error for the basic example.}\n  }\n\\label{fig:simulation_nonsmooth_cost}\n\\end{figure}\n\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_nonsmooth_coupling.pdf}\n  \\caption{\n    \\GN{Evolution of the coupling constraint for the basic example.\n    A value below zero means that the solution\n    computed by the algorithm at that iteration is feasible.}}\n\\label{fig:simulation_nonsmooth_coupling}\n\\end{figure}\n\n}\n\n\\subsection{Electric Vehicle Charging Problem}\n\\GN{Let us now} consider the charging of Plug-in Electric Vehicles (PEVs),\nwhich is formulated in detail in~\\cite{vujanic2016decomposition} and is slightly\nchanged here in order to better highlight the algorithm behavior.\n\\GN{The simulations reported in the remainder of this section are all referred\nto this application scenario.}\n\nThe problem consists of determining an optimal charging schedule\nof $N$ electric vehicles. Each vehicle $i$ has an initial state of charge\n$E_i^\\text{init}$ and a target state of charge $E_i^\\text{ref}$ that must be\nreached within a time horizon of $8$ hours, divided into $T = 12$ time slots\nof $\\Delta T = 40$ minutes. Vehicles must further satisfy a coupling constraint,\nwhich is given by the fact that the total power drawn from the (shared)\nelectricity grid must not exceed $P^\\text{max} = N/2$.\n%\nIn this paper, we consider the ``charge-only'' case. In order to make\nsure the local constraint set are convex (cf. Assumption~\\ref{ass:problem}),\nwe drop the additional integer constraints considered\nin~\\cite{vujanic2016decomposition}. Thus, the vehicles optimize their charging\nrate rather than activating or de-activating the charging mode at each time slot.\n%\nFormally, the resulting linear program is\n%\n\\begin{align*}\n%\n\\begin{split}\n  \\min_{\\bx_1, \\ldots, \\bx_N} \\: & \\: \\sum_{i=1}^N c_i^\\top \\bx_i\n  \\\\\n  \\subj \\: & \\: \\sum_{i=1}^N A_i \\bx_i \\le b,\n  \\\\\n  & \\: \\bx_i \\in X_i, \\hspace{1cm} i \\in \\until{N},\n\\end{split}\n\\end{align*}\n%\nwhere the local constraint sets $X_i$ are compact polyhedra and a total\nof $S = 12$ coupling constraints are present. For a complete reference\non the other quantities involved in the problem and not explicitly specified\nhere, we refer the reader to the extended formulation\nin~\\cite{vujanic2016decomposition}.\n\nWe consider a network of $N = 50$ agents where the underlying graph $\\EE_u$\nis generated as an Erd\\H{o}s-R\\'{e}nyi graph with edge probability $0.2$.\nThe edge activation probabilities $\\prob_{ij}$ are randomly picked\nin $[0.3, 0.9]$.\n%\nIn particular, in the next subsections we \\emph{(i)} compare our algorithm with\nthe state of the art, \\emph{(ii)} discuss the parameter $M$ and \\emph{(iii)}\nshow the convergence rate.\n\n\\subsection{Comparison with State of the Art}\n\\label{sec:simulation_comparison_dual_subg}\n\nWe compare \\algacronym/ with the existing Distributed Dual Subgradient\nalgorithm~\\cite{falsone2017dual}.\n%\n%\nAs for the algorithm tuning \\GN{(i.e., the step-size $\\alpha^t$\nin the update~\\eqref{eq:alg_update} and the parameter $M$ appearing\nin problem~\\eqref{eq:alg_local_prob})}, we choose $M = 30$ and the\ndiminishing step-size $\\alpha^t = \\frac{1}{(t+1)^{0.6}}$.\nOur algorithm is initialized in $\\by_i^0 = \\0$ for all $i$ and the Distributed\nDual Subgradient algorithm is initialized in $\\blambda_i^0 = \\0$ for all $i$.\n%\nIn Figure~\\ref{fig:simulation_cost}, the cost error of both algorithms is shown,\ncompared with the result of a centralized problem solver. For\nour algorithm, the symbol $\\bx_i^t$ represents the local solution\nof problem~\\eqref{eq:alg_local_prob} at time $t$, while for the\nDistributed Dual Subgradient, the same symbol represents the (unweighted)\nrunning average of the local solutions over the past iterations.\nThe figure highlights that, in this simulation, \\algacronym/ reached\nalmost exact cost convergence shortly after $10,000$ iterations with a sudden\nchange of approximately $10$ orders of magnitude. In principle, for the\nDistributed dual subgradient, it is not possible to have such rapid changes\nbecause of the use of running averages.\n%\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_comparison_cost.pdf}\n  \\caption{\n    Evolution of the normalized cost error for the comparative study\n    with the state of the art.\n  }\n\\label{fig:simulation_cost}\n\\end{figure}\n\nIn Figure~\\ref{fig:simulation_coupling}, we show the value of the coupling\nconstraints. The picture highlights that both algorithms are able to provide\nfeasible solutions within less than 500 iterations, confirming the primal recovery\nproperty.\n%\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_comparison_coupling.pdf}\n  \\caption{\n    Evolution of the coupling constraint for the comparative study\n    with the state of the art. A value below zero means that the solution\n    computed by the algorithm at that iteration is feasible.}\n\\label{fig:simulation_coupling}\n\\end{figure}\n\n\\subsection{Impact of the Parameter $M$}\nWe also perform a numerical comparison of the algorithm behavior for\ndifferent values of the parameter $M$ (see also\nSection~\\ref{sec:discussion_M}).\n%\nUnder the same set-up of the previous simulation, we \\GN{use a\ndifferent initialization to guarantee the requirements\nimposed by Theorem~\\ref{thm:convergence} and also to create some\nasymmetry among the initial allocations of the agents. Thus, in this simulation\nwe consider the initialization rule $\\by_i^0 = 5(N - 2i) \\1$}\nfor all $i$, which satisfies $\\sum_{i=1}^N \\by_i^0 = \\0$.\n\nIn Figure~\\ref{fig:simulation_M_cost} we plot the cost error, including the\nextra penalty term $\\sum_{i=1}^N M \\rho_i^t$, for three different values\nof $M$ (all of which satisfy the assumption $M > \\|\\bmu^\\star\\|_1$).\nIt can be seen that the slope of the curve decreases as $M$ increases,\nwhich agrees with the fact that the larger is $M$, the larger is the set in\nwhich subgradients can be found\n(Lemma~\\ref{lemma:bounded_subgradients}).\n\n%\n%\n%\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_M_cost.pdf}\n  \\caption{\n    Evolution of the normalized cost error for different values of $M$,\n    under diminishing step-size.\n  }\n\\label{fig:simulation_M_cost}\n\\end{figure}\n\nFigure~\\ref{fig:simulation_M_rho} shows the maximum value of $\\rho_i^t$\namong agents. Recall that $\\rho_i^t$ is an upper bound on the violation\nof the local allocation $\\by_i^t$. The picture underlines that such a quantity\nis forced to zero faster as $M$ gets bigger. This can be intuitively\nexplained by the fact that larger values of the penalty $M \\rho_i$ drive the\nalgorithm more quickly towards feasibility of the coupling constraint.\n\n%\n%\n%\n%\n%\n%\n%\n%\n\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_M_rho.pdf}\n  \\caption{ Evolution of the value of $\\max_i \\rho_i^t$ for varying values of\n    $M$. The quantity represents an upper bound on the coupling constraint\n    violation.\n  }\n\\label{fig:simulation_M_rho}\n\\end{figure}\n\n\\subsection{Numerical Study on Convergence Rates}\nWe finally perform a simulation to point out the different behavior of the\nalgorithm with constant and diminishing step-sizes.\n%\nUnder the same set-up of the previous example, with $M = 10$,\nwe run the algorithm with the diminishing step-size law\n$\\alpha^t = \\frac{0.5}{(t+1)^{0.6}}$ and with the constant\nstep-size $\\alpha^t = 0.01$. As before, agents initialize their local\nallocation at $\\by_i^0 = 5(N - 2i) \\1$ for all $i$.\n\nFigure~\\ref{fig:simulation_rate_cost} shows the different algorithm behavior\nunder the two step-size choices. For constant step-size, the algorithm\nconverges within a certain tolerance (which is seen in the picture\nat around iteration $6,000$), confirming the observations in\nSection~\\ref{sec:rates_and_discussion}. Moreover, the sublinear behavior\nwith the diminishing step-size is confirmed.\n%\nInterestingly, in this example the constant step-size behaved linearly up to\niteration $4,000$ and superlinearly in the interval $4,000$--$6,000$,\ntherefore performing much better than the sublinear bound in\nProposition~\\ref{prop:convergence_rate_constant}.\n%\n%\n\\begin{figure}[!htpb]\n\\centering\n  \\includegraphics[scale=1]{fig_rate_cost.pdf}\n  \\caption{\n    Evolution of the cost error for the comparative study on step-sizes.\n  }\n\\label{fig:simulation_rate_cost}\n\\end{figure}\n\n%\n%\n\n\\section{Conclusions}\n\nIn this paper, we presented the \\algacronym/ algorithm to solve\nconstraint-coupled, large-scale, convex optimization problems over random time-varying networks.\n%\n%\nThe proposed algorithm is based on a relaxation and primal decomposition approach,\nand, for the sake of analysis, it is viewed as an instance of a randomized block\nsubgradient method, in which blocks correspond to edges in the communication graph.\n%\nAlmost sure convergence to the optimal cost of the original problem\nand an almost sure asymptotic primal recovery property are proved.\nSublinear convergence rates are provided under different\nstep-size assumptions.\n%\nNumerical computations on an electric vehicle charging problem\nsubstantiated the theoretical results.\n\n%\n%\n\n%\n\n\\begin{small}\n  \\bibliographystyle{IEEEtran}\n  \\bibliography{primal_decomp_biblio}\n\\end{small}\n\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:57", "yymm": "2010", "arxiv_id": "2010.14489", "url": "https://arxiv.org/abs/2010.14489", "source": "arxiv"}}
{"text": "\\documentclass[12pt]{article}\n\n\\usepackage{macro}\n\n\\usetikzlibrary{arrows,positioning} \n\\tikzset{\n\t%Define standard arrow tip\n\t>=stealth',\n\t%Define style for boxes\n    every node/.style={align=center},\n\tpunkt/.style={\n\t\t   rectangle,\n\t\t   rounded corners,\n\t\t   draw=black, very thick,\n\t\t   text width=6.5em,\n\t\t   minimum height=2em,\n\t\t   text centered},\n\t% Define arrow style\n\tpil/.style={\n\t\t   ->,\n\t\t   thick,\n\t\t   shorten <=2pt,\n\t\t   shorten >=2pt,}\n}\n\n\n\\begin{document}\n\n\\title{Nested Grassmanns for Dimensionality Reduction}\n  \n\\author{Chun-Hao Yang$^1$, and Baba C. Vemuri$^2$\\\\\n    $^1$Department of Statistics\\\\\n    $^2$Department of Computer Information Science \\& Engineering\\\\ University of Florida}\n\\maketitle\n\n\\begin{abstract}\n\nGrassmann manifolds have been widely used to represent the geometry of feature spaces in a variety of problems in computer vision including but not limited to face recognition, action recognition, subspace clustering and motion segmentation. For these problems, the features usually lie in a very high-dimensional Grassmann manifold and hence an appropriate dimensionality reduction technique is called for in order to curtail the computational burden. To this end, the Principal Geodesic Analysis (PGA), a nonlinear extension of the well known principal component analysis, is applicable as a general tool to many Riemannian manifolds. In this paper, we propose a novel dimensionality reduction framework suited for Grassmann manifolds by utilizing the geometry of the manifold. Specifically, we project points in a Grassmann manifold to an embedded lower dimensional Grassmann manifold. A salient feature of our method is that it leads to higher expressed variance compared to PGA which we demonstrate via synthetic and real data experiments. \n\n%We apply our method to planar shape analysis applied to Corpus Callosi shapes derived from the OASIS database, for which the shape space is characterized by a Grassmann manifold in the complex vector space.\n\n\\end{abstract}\n \n\n\\section{Introduction}\\label{intro}\n\nIn computer vision, non-Euclidean spaces are commonly used to model descriptive features extracted from the data or even the data itself. For example, the region covariance descriptors \\citep{tuzel2006region} are symmetric positive-definite (SPD) matrices that reside on a manifold and the $L_2$-normalized histogram of oriented gradients can be modeled by points on a hypersphere which is a constant curvature manifold. Another example is the Kendall's shape space (Procrustes shape space) \\citep{kendall1984shape} which is a manifold used to model shapes. However in most cases the differential structure of the manifold is far from sufficient for rigorous statistical analysis and thus the manifolds are endowed with a suitable Riemannian metric which induces distance and geodesics (the analogy of the straight lines in Euclidean spaces). The manifolds with additional Riemannian structure are then called a Riemannian manifolds. Usually the data and features in the above examples are high-dimensional and thus dimensionality reduction techniques, if applied appropriately, can benefit the the subsequent statistical analysis.\n\nPrincipal component analysis (PCA) is the simplest and most well-known (unsupervised) dimensionality reduction technique for data in $\\R^n$. Using PCA, the data in $\\R^n$ is projected to a vector subspace of dimension $k \\ll n$ such that maximal variance in the original data is captured in the projected data. The extension of PCA to Riemannian manifolds, called principal geodesic analysis (PGA) \\citep{fletcher2004principal}, seeks to project the data on a $n$-dimensional Riemannian manifold to a $k$-dimensional geodesic submanifold by first mapping the data to the tangent space (which is a vector space) at the Fr\\'{e}chet mean (FM) and applying PCA on the tangent space. However this approach requires the data to be clustered around the FM, otherwise the tangent space approximation to the manifold leads to inaccuracies. The exact PGA (EPGA) was then proposed by \\citet{sommer2010manifold} without using the tangent space PCA approximation. However, EPGA can be computationally rather challenging when the sample size is large since it involves two non-linear optimizations steps per iteration (projection to the geodesic submanifold and finding the new geodesic direction such that the loss of information is minimum). \\citet{chakraborty2016efficient} improved upon EPGA\nby deriving the closed-form expressions for the projection in the case of constant curvature manifolds, e.g.\\  hyperspheres and hyperbolic spaces. Thus, for constant curvature manifolds, one only needs a single optimization. There are several other variants of PGA, see \\citet{banerjee2017sparse}, \\citet{zhang2013probabilistic}, \\citet{huckemann2010intrinsic}, and \\citet{huckemann2006principal}. Instead of projecting data to a geodesic submanifold, one may also find a curve on the manifold, called the principal curve \\citep{hauberg2016principal} (this is a generalization of the principal curve on the Euclidean space by \\citet{hastie1989principal}), to represent the data using a lower dimensional submanifold.\n\nPGA and its variants provided a dimensionality reduction technique for general Riemannian manifolds. Nonetheless, different Riemannian manifolds possess different geometric structures, e.g.\\ curvature and symmetry.  Therefore, by exploiting the geometry or other properties, one may design a more efficient and better dimensionality reduction method for a specific Riemannian manifold. For example, by utilizing the fact that $S^q$ embedded inside $S^p$ with $q < p$ is a geodesic submanifold of $S^p$, \\citet{jung2012analysis} proposed a method called the {\\it principal nested spheres} to perform dimensionality reduction on $S^p$. By translating the nested spheres, PGA on $S^p$ can be seen as a special case of principal nested spheres. Another example is that of the manifold on SPD matrices, $P_n$. \\citet{harandi2018dimensionality} proposed to project data on $P_n$ to $P_m$ where $m \\ll n$ by designing a projection map from $P_n$ to $P_m$ that maximized the projected variance or inter-class discrimination in the case of supervised dimensionality reduction. Although in this case, $P_m$ is not a geodesic submanifold of $P_n$ which makes it different from PGA, such an algorithm has the ability to handle supervised dimensionality reduction which PGA lacks.\n\nIn this work, we focus our attention on the unsupervised and supervised dimensionality reduction for data on the Grassmann manifold $\\gr(p, V)$ which is the space of all $p$-dimensional linear subspaces of the vector space $V$ where $1 \\leq p \\leq \\dim V$. We will assume that $V$ is either $\\R^n$ or $\\C^n$. The Grassmann manifold is commonly used to model feature spaces derived from images or videos with different invariances, e.g.\\ faces with illumination-invariance or pose-invariance \\citep{hamm2008grassmann}. In shape analysis, the space of planar shapes, i.e.\\ shapes that are represented by $k$ ordered points in $\\R^2$, is a complex projective space $\\C P^{k-2} \\cong \\gr(1, \\C^{k-1})$. In the above examples, the dimension of $V$ is usually large (in planar shapes, this would be the number of points minus one) and dimension of the subspaces $p$ is small. Hence the core idea of our dimensionality reduction is to approximate $\\mc{X} \\in \\gr(p, V)$ by $\\hat{\\mc{X}} \\in \\gr(p, \\tilde{V})$ where $\\dim \\tilde{V} \\ll \\dim V$.\n\nThe rest of the paper is organized as follows. In Section~\\ref{theory}, we review the geometry of the Grassmann manifold and present the formulation and algorithm for our unsupervised and supervised dimensionality reduction technique on the Grassmann manifold. In Section~\\ref{exp}, we demonstrate the efficacy of our method via both synthetic experiments and real data experiments on shape data. Finally, we conclude our work in Section~\\ref{conc}.\n \\section{Theory}\\label{theory}\n\nWe will first review the Riemannian geometry of the Grassmann manifold in Section~\\ref{sub:geometry} and then the nested Grassmann model will be derived in Section~\\ref{sub:embedding}. In Section~\\ref{sub:distance}, we will discuss some technical details required for implementation. A technique for the choosing the dimension of the 'reduced' model is then presented in Section~\\ref{sub:nested_grassmann}.\n\n\\subsection{The Riemannian Geometry of Grassmann Manifold}%\n\\label{sub:geometry}\n\nFor the sake of simplicity, we assume $V=\\R^n$. For the case of $V=\\C^n$, the results hold by replacing real matrices with complex matrices, $M^T$ with the conjugate transpose $M^H$, and the orthogonal group $\\text{O}(n)$ with the unitary group $\\text{U}(n)$. Let $n,p \\in \\mathbb{N}$, $p \\leq n$. The \\textit{Grassmann manifold} $\\gr(p, n) \\coloneqq \\gr(p, \\R^n)$ is the space of all $p$-dimensional linear subspaces in $\\R^n$. The dimension of $\\gr(p, n)$ is given by $p(n-p)$. In this paper, for elements $\\mc{X} \\in \\gr(p, n)$, we write $\\mc{X}=\\spn(X)$ where $X=[x_1,\\ldots,x_p]$ is an orthonormal basis (o.n.b) for $\\mc{X}$. The \\textit{compact Stiefel manifold} is defined as \n\\[\n    \\st(p, n) \\coloneqq \\left\\{ M \\in \\R^{n \\times p}: M^TM = I_p\\right\\}.\n\\]\nLet $\\text{O}(n)$ be the set of $n \\times n$ orthogonal matrices. Then $\\gr(p, n)$ admits the following quotient manifold representation \\citep{edelman1998geometry}\n\\[\n\\gr(p, n) \\cong \\st(p, n)/\\text{O}(p).\n\\]\n\nWith the above quotient manifold representation, the canonical Riemannian metric on the Grassmann manifold can be constructed as in \\citet{edelman1998geometry} and \\citet{absil2004riemannian}. We now state a few important geometric concepts and results that will be relevant to our work in this paper.\n\n\\paragraph{Vertical space and Horizontal space}\nThe tangent space of $\\gr(p,n)$ at $\\mc{X} \\in \\gr(p, n)$ is denoted $T_{\\mc{X}}\\gr(p,n)$ and can be decomposed as the direct sum of the \\emph{vertical space} $V_{\\mc{X}}\\gr(p,n)$ and the \\emph{horizontal space} $H_{\\mc{X}}\\gr(p, n)$. The vertical space at $\\mc{X} = \\spn(X)$ is simply the tangent space to the fiber, i.e.\\ $V_{\\mc{X}}\\gr(p, n) \\cong XT_I\\text{O}(p,n)$ and the horizontal space is \n\\[\n    H_{\\mc{X}}\\gr(p, n) = \\{ V \\in \\R^{n \\times p}: V^TX = 0\\}.\n\\]\nThe \\emph{horizontal lift} of $U \\in T_{\\mc{X}}\\gr(p, n)$ is the projection of $U$ onto $H_{\\mc{X}}\\gr(p, n)$ and is denoted by $U_{\\diamond}$. \n\n\\paragraph{Geodesic}\nLet $\\mc{X}=\\spn(X), \\mc{Y}=\\spn(Y) \\in \\gr(p,n)$ where $X, Y \\in \\st(p, n)$. If $X^TY$ is invertible, then the geodesic connecting $\\mc{X}$ and $\\mc{Y}$ is \n\\[\n    \\gamma_{\\mc{X}, \\mc{Y}}(t) = \\spn(XV \\cos \\Theta t + U \\sin \\Theta t)\n\\]\nwhere $(I - XX^T)Y(X^TY)^{-1} = U\\Sigma V^T$, $U\\in\\st(p, n)$, $V \\in \\text{O}(p)$, and $\\Theta = \\tan^{-1}\\Sigma$.  The diagonal entries of $\\Theta = \\diag(\\theta_1,\\ldots,\\theta_p)$ are known as the principal angles. Hence, the \\emph{geodesic distance} between $\\mc{X}$ and $\\mc{Y}$ is given by,\n\\[\n    d_g^2(\\mc{X}, \\mc{Y}) = \\sum_{i=1}^p\\theta_i^2.\n\\]\nSince $X$ and $Y$ are orthonormal, an alternative way to calculate the principal angles is as follows. Let $X^TY=U\\Sigma V^T$. The principal angles are $\\Theta = \\cos^{-1}\\Sigma$. Another way to parametrize a geodesic is the following. Let $\\mc{X} = \\spn(X) \\in \\gr(p, n)$ and $W \\in T_{\\mc{X}}\\gr(p, n)$. The geodesic $\\gamma_{\\mc{X}, W}(t)$ such that $\\gamma(0) = \\mc{X}$ and $\\gamma^{\\prime}(0) = W$ is\n\\[\n\\gamma_{\\mc{X},W}(t) = \\spn(XV\\cos \\Sigma t + U\\sin \\Sigma t)\n\\]\nwhere $W_{\\diamond} = U\\Sigma V^T$, $U \\in \\st(p, n)$, and $V \\in \\text{O}(p)$. The \\emph{exponential map} at $\\mc{X}$ is a map from $T_{\\mc{X}}\\gr(p, n)$ to $\\gr(p, n)$ defined by\n\\[\n\\text{Exp}_{\\mc{X}}W = \\gamma_{\\mc{X}, W}(1) = \\spn(XV\\cos \\Sigma + U\\sin \\Sigma)\n\\]\nfor $W \\in T_{\\mc{X}}\\gr(p, n)$.\n\n\n\\paragraph{Gradient}\nLet $f:\\gr(p,n) \\to \\R$. The gradient of $f$ at $\\mc{X}=\\spn(X)$, $X \\in \\st(p, n)$, is \n\\begin{equation} \\label{eq:riem_grad}\n    (\\grad f)_{\\mc{X}} = (I - XX^T)\\frac{\\partial f}{\\partial X}\n\\end{equation}\nwhere $\\frac{\\partial f}{\\partial X}$ is the Euclidean gradient, i.e.\\ $\\frac{\\partial f}{\\partial X} = \\big[ \\frac{\\partial f}{\\partial X_{ij}}\\big]_{i,j}$. \n\n\\subsection{The embedding of $\\gr(p, m)$ in $\\gr(p, n)$}%\n\\label{sub:embedding}\n\nLet $\\mc{X} = \\spn(X) \\in \\gr(p, m)$. The map $\\iota:\\gr(p, m) \\to \\gr(p, n)$, for $m < n$, defined by\n\\[\n    \\iota(\\mc{X})=\\spn\\left( \n        \\left[\n            \\begin{array}{c}\n                X\\\\\n                0_{(n-m)\\times p}\n            \\end{array}\n        \\right]\n    \\right)\n\\]\nis an embedding. Let $\\iota(\\mc{X}) = \\mc{Y}$ and  $Y = \\left[\\begin{array}{c} X\\\\ 0_{(n-m)\\times p} \\end{array} \\right]$. For $M=[M_1, M_2] \\in \\text{O}(n)$, where $M_1 \\in \\st(m, n)$ and $M_2 \\in \\st(n-m, n)$, $MY=M_1X$. Hence, for a given $A \\in \\st(m, n)$, we define the associated embedding $\\iota_A: \\gr(p, m) \\to \\gr(p, n)$ by $\\iota_A(\\mc{X})=\\spn(AX)$. Hence the corresponding projection map $\\pi_A : \\gr(p, n) \\to \\gr(p, m)$ is given by $\\pi_A(\\mc{X}) = \\spn(A^TX)$ where $\\mc{X} = \\spn(X) \\in \\gr(p, n)$. A schematic of the relationship between $\\gr(p, n)$ and $\\gr(p,m)$ is shown in Figure~\\ref{fig:diagram}, i.e.\\ the projection $\\pi_A$ is used to reduce the dimension and the embedding $\\iota_A$ is used for reconstruction.\n\n\\begin{figure}[ht]\n    \\centering\n    \\vspace{0.3cm}\n\t\\scalebox{0.8}{\n    \\begin{tikzpicture}[node distance=1cm, auto,]\n        \\node[punkt] (space2) {$\\gr(p, m)$};\n        \\node[punkt, above=of space2] (space1) {$\\gr(p, n)$}\n            edge[pil, bend right=45] node[auto] {$\\pi_A$} (space2.west)\n            edge[pil, <-, bend left=45] node[auto] {$\\iota_A$} (space2.east); \n        \\node[left=0.3cm of space1] (X) {$\\mc{X}=\\spn(X)$};\n        \\node[inner sep=5pt, right=0.3cm of space1] (Xrecon) {$\\hat{\\mc{X}}_i = \\spn(AA^TX)$};\n        \\node[left=0.3cm of space2] (Xproj) {$\\spn(A^TX)$};\n        \\node[right=0.3cm of space2] (Xproj) {$\\spn(A^TX)$};\n    \\end{tikzpicture}\n\t}\n    \\vspace{0.3cm}\n    \\caption{Illustration of the embedding of $\\gr(p, m)$ in $\\gr(p, n)$ parameterized by $A \\in \\st(m, n)$.}\n    \\label{fig:diagram}\n\\end{figure}\n\nNow we see that the $\\gr(p, m)$ can be embedded as a submanifold of $\\gr(p, n)$ via $\\iota_A$. However as in PGA which tries to project points on a manifold to a geodesic submanifold, we would like to know whether this embedding gives us a geodesic submanifold of $\\gr(p, n)$. The answer is affirmative by the following proposition. \n\n\\begin{proposition}\n    Given $A \\in \\st(m, n)$, $\\iota_A$ is an isometric embedding of $\\gr(p, m)$ in $\\gr(p, n)$. Hence $\\iota_A(\\gr(p, m))$ is a totally geodesic submanifold of $\\gr(p, n)$. \n\\end{proposition}\n\\begin{proof}\n    For $\\mc{X}=\\spn(X), \\mc{Y}=\\spn(Y) \\in \\gr(p, m)$ where $X$ and $Y$ are o.n.b, \n    \\[\n        d^2_g(\\mc{X}, \\mc{Y}) = \\sum_{i=1}^p \\theta^2_i\n    \\]\n    where $X^TY = U(\\cos \\Theta) V^T$ is the SVD for $X^TY$ and $\\Theta = \\diag(\\theta_1,\\ldots\\theta_p)$. On the other hand, $\\iota_A(\\mc{X}) = \\spn(AX)$ and $AX$ is also an o.n.b for $\\iota_A(\\mc{X})$ since $(AX)^TAX=X^TA^TAX = X^TX = I$. Thus to compute $d_g(\\iota_A(\\mc{X}), \\iota_A(\\mc{Y}))$, we need the SVD for $(AX)^T(AY)$ first which is $(AX)^TAY=X^TA^TAY=X^TY=U(\\cos \\Theta)V^T$. Hence, \n    \\[\n        d^2_g(\\iota_A(\\mc{X}), \\iota_A(\\mc{Y})) = \\sum_{i=1}^p \\theta^2_i =\n        d^2_g(\\mc{X}, \\mc{Y})\n    \\]\n    and by the Myers-Steenrod Theorem, $\\iota_A$ is an isometric embedding of $\\gr(p, m)$ in $\\gr(p, n)$.\n\\end{proof}\n\n\\begin{remark}\n    We would like to point out that the converse is in general not true, i.e.\\ not all totally geodesic submanifolds of $\\gr(p,n)$ are of the form $\\iota_A(\\gr(p,m))$ for some $A \\in \\st(m, n)$ and $m < n$. However for the special case of $p=1$, i.e.\\ the projective spaces, the opposite direction is true. \n\\end{remark}\n\n\\subsection{Unsupervised Dimensionality Reduction}\\label{sub:dr}\n\nWe can now apply the nested Grassmann (NG) structure to the problem of unsupervised dimension reduction. Suppose that we are given the points, $\\mc{X}_1,\\ldots,\\mc{X}_N \\in \\gr(p, n)$. We would like to have lower dimensional representations in $\\gr(p,m)$ for $\\mc{X}_1,\\ldots,\\mc{X}_N$ with $m \\ll n$. The desired projection map $\\pi_A$ that we seek is obtained by the minimizing the reconstruction error, i.e.\\\n\\begin{align*}\n    L_u(A) & = N^{-1}\\sum_{i=1}^N d^2(\\mc{X}_i, \\hat{\\mc{X}}_i) = N^{-1}\\sum_{i=1}^N d^2(\\mc{X}_i, \\iota_A(\\pi_A(\\mc{X}_i)))\\\\\n         & = N^{-1} \\sum_{i=1}^N d^2(\\spn(X_i),\\spn(AA^TX_i))\n\\end{align*}\nwhere $d$ is a distance metric on $\\gr(p, n)$. It is clear that $L_u$ has a $\\text{O}(m)$-symmetry, i.e.\\ $L_u(AO) = L_u(A)$ for $O \\in \\text{O}(m)$. Hence the optimization is done over the space $\\st(m, n)/\\text{O}(m) \\cong \\gr(m, n)$ when optimizing with respect to this particular loss function. Now we can apply the Riemannian gradient descent algorithm \\citep{edelman1998geometry} to solve the following optimization problem:\n\\[\n    A^{\\star} = \\arg \\min_{\\spn(A) \\in \\gr(m, n)} L_u(A).\n\\]\n\n%\\begin{remark} \n%The reduction of the space of all possible projections from $\\mathsf{ST}(m,n)$ to $\\gr(m,n)$ is a consequence of the choice of the loss function $L$. With a different loss function, one might have a different space of possible projections.\n%\\end{remark}\n\n\\subsection{Supervised Dimensionality Reduction}\\label{sub:supervised_dr}\n\nIf in addition to $\\mc{X}_1,\\ldots,\\mc{X}_N \\in \\gr(p, n)$, we are given the associated labels $y_1,\\ldots,y_N \\in \\{1,\\ldots,k\\}$, then we would like to utilize this extra information to sharpen the result of dimensionality reduction. Specifically, we expect that after reducing the dimension, points from the same class are still close to each other while points from different classes are separated. We use an \\emph{affinity function} $a: \\gr(p,n) \\times \\gr(p, n) \\to \\R$ to encode the structure of the data as suggested by \\citet{harandi2018dimensionality}. \n\n\\[\na(\\mc{X}_i,\\mc{X}_j) = g_w(\\mc{X}_i, \\mc{X}_j) - g_b(\\mc{X}_i, \\mc{X}_j)\n\\]\nwhere,\n\\begin{align*}\n    g_{w}(\\mc{X}_i,\\mc{X}_j)& =\\begin{cases}\n1 & \\text{if }\\mc{X}_i\\in N_{w}(\\mc{X}_j)\\text{ or }\\mc{X}_j\\in N_{w}(\\mc{X}_i)\\\\\n0 & \\text{\\text{Otherwise}}\n\\end{cases}\\\\\n    g_{b}(\\mc{X}_i,\\mc{X}_j)& =\\begin{cases}\n1 & \\text{if }\\mc{X}_i\\in N_{b}(\\mc{X}_j)\\text{ or }\\mc{X}_j\\in N_{b}(\\mc{X}_i)\\\\\n0 & \\text{\\text{Otherwise}}\n\\end{cases}\n\\end{align*}\nand $N_w(\\mc{X}_i)$ is the set of $\\nu_w$ nearest neighbors of $\\mc{X}_i$ that have the \\emph{same} labels as $y_i$ and $N_b(\\mc{X}_i)$ is the set of $\\nu_b$ nearest neighbors of $\\mc{X}_i$ that have \\emph{different} labels from $y_i$. The nearest neighbors can be computed using the geodesic distance. The desired projection map $\\pi_A$ that we seek is obtained by the minimizing the following loss function \n\\begin{align*}\n    L_s(A) & = \\frac{1}{N^2}\\sum_{i, j=1}^N a(\\mc{X}_i, \\mc{X}_j) d^2(\\pi_A(\\mc{X}_i), \\pi_A(\\mc{X}_j))\\\\\n         & = \\frac{1}{N^2}\\sum_{i, j=1}^N a(\\mc{X}_i, \\mc{X}_j) d^2(\\spn(A^TX_i),\\spn(A^TX_j))\n\\end{align*}\nwhere, $d$ is a distance metric on $\\gr(p, m)$. Note that if the distance metric $d$ has $\\text{O}(m)$-symmetry, e.g.\\ the geodesic distance, so does $L_s$. In this case the optimization can be done on $\\st(m,n)/\\text{O}(m) \\cong \\gr(m,n)$. Otherwise it is on $\\st(m, n)$. This supervised dimensionality reduction is termed supervised nested Grassmann (sNG).\n\n\\subsection{Choice of the distance $d$}%\n\\label{sub:distance}\n\nThe loss functions $L_u$ and $L_s$ depend on the choice of the distance $d:\\gr(p, n) \\times \\gr(p, n) \\to \\R_{\\geq 0}$. In this work, we use two different distance metrics: (1) the geodesic distance $d_g$ and (2) the projection distance. The geodesic distance was defined in Section~\\ref{sub:geometry} and the projection distance is defined as follows. For $\\mc{X}, \\mc{Y} \\in \\gr(p, n)$, denote the projection matrices onto $\\mc{X}$ and $\\mc{Y}$ by $P_{\\mc{X}}$ and $P_{\\mc{Y}}$ respectively. Then the distance between $\\mc{X}$ and $\\mc{Y}$ is given by\n\\[\n    d_{p}(\\mc{X}, \\mc{Y}) = \\frac{1}{\\sqrt{2}}\\Vert P_{\\mc{X}} - P_{\\mc{Y}} \\Vert_F = \\Big(\\sum_{i=1}^p \\sin^2\\theta_i\\Big)^{1/2}.\n\\]\nwhere, $\\theta_1,\\ldots,\\theta_p$ are the principal angles of $\\mc{X}$ and $\\mc{Y}$.  If $\\mc{X}=\\spn(X)$, then $P_{\\mc{X}}=X(X^TX)^{-1}X^T$. It is also easy to see the the projection distance has $\\text{O}(n)$-symmetry. There are other choices for the distance metric on $\\gr(p, n)$ (see for example, \\citet[p.\\ 337]{edelman1998geometry}). We choose the projection distance mainly for its ease of computation when computing the gradient. Let the four loss functions arising from the above two choices of the distance metrics respectively be\n\\begin{align*}\n    L_{u,p}(A) & = \\frac{1}{N} \\sum_{i=1}^N d^2_{p}(\\spn(X_i), \\spn(AA^TX_i))\\\\\n    L_{u,g}(A) & = \\frac{1}{N}  \\sum_{i=1}^N d^2_{g}(\\spn(X_i), \\spn(AA^TX_i))\\\\\n    L_{s,p}(A) & = \\frac{1}{N^2}  \\sum_{i, j=1}^N a(\\mc{X}_i, \\mc{X}_j)d^2_{p}(\\spn(A^TX_i), \\spn(A^TX_j))\\\\\n    L_{s,g}(A) & = \\frac{1}{N^2}  \\sum_{i, j=1}^N a(\\mc{X}_i, \\mc{X}_j)d^2_{g}(\\spn(A^TX_i), \\spn(A^TX_j))\\\\\n\\end{align*}\nClosed form expressions for the Euclidean gradients of the above two loss functions are derived in the following proposition and the Riemannian gradients can be obtained from \\eqref{eq:riem_grad}.\n\n\\begin{proposition}\\label{prop:gradient}\nFor $A \\in \\st(m,n)$, the (Euclidean) gradients of loss function $L_{u,p}$ and $L_{u,g}$ are given by:\n\\begin{align*}\n    \\frac{\\partial L_{u,p}}{\\partial A} & = -\\frac{2}{N}\\sum_{i=1}^N X_iX_i^TA\\\\\n    \\frac{\\partial L_{u,g}}{\\partial A} & = -\\frac{4}{N}\\sum_{i=1}^NX_iV_i\\widetilde{\\Sigma}_iV_i^TX_i^TA\n\\end{align*}\nwhere, $X_i^TAA^TX_i = V_i(\\cos \\Theta_i)^2V_i^T$ and $\\widetilde{\\Sigma}_i = \\diag(\\theta_{i1}\\csc 2\\theta_{i1},\\ldots,\\theta_{ip}\\csc 2\\theta_{ip})$.\n\\end{proposition}\n\\begin{proof}\nObserve that\n\\begin{align*}\n    d^2_{p}(\\spn(X), \\spn(AA^TX)) & = \\frac{1}{2}\\Vert XX^T - AA^TX(X^TAA^TX)^{-1}X^TAA^T\\Vert_F^2\\\\\n    & = \\frac{1}{2}\\tr( XX^T - 2XX^TAA^T \\\\\n    & \\quad \\quad + AA^TX(X^TAA^TX)^{-1}X^TAA^T)\\\\\n    & = \\frac{1}{2}\\tr(I_p) - \\tr(XX^TAA^T) + \\frac{1}{2}\\tr(I_p).\n\\end{align*}\nTherefore,\n\\begin{align*}\nL_{u,p}(A) = p -\\tr\\left(\\left(N^{-1}\\sum_{i=1}^N X_iX_i^T\\right)AA^T\\right).\n\\end{align*}\nHence,\n\\begin{align*}\n    \\frac{\\partial L_{u,p}}{\\partial A} = -\\frac{2}{N}\\sum_{i=1}^NX_iX_i^TA.\n\\end{align*}\n\nFrom Section~\\ref{sub:geometry}, the geodesic distance is the 2-norm of the principal angles,\n\\begin{align*}\n    d^2_g(\\spn(X), \\spn(AA^TX)) = \\sum_{j=1}^p \\theta_j^2.\n\\end{align*} \nwhere, $(I-XX^T)AA^TX(X^TAA^TX)^{-1} = U(\\tan \\Theta)V^T$ and $\\Theta = \\diag(\\theta_1,\\ldots,\\theta_p)$. After a few steps of matrix algebra, we arrive at the formula, $X^TAA^TX = V(\\cos \\Theta)^2 V^T$. Thus,\n\\[\n    (\\cos \\theta_j)^2 = v_j^T X^TAA^TXv_j.\n\\]\nTaking the derivative on both sides and we get, \n\\begin{align*}\n    \\frac{\\partial \\theta_j}{\\partial A} & =\n    -\\frac{1}{\\cos\\theta_j\\sin\\theta_j}Xv_jv_j^TX^TA\n    = -2\\csc 2\\theta_jXv_jv_j^TX^TA .\n\\end{align*}\nThus,\n\\begin{align*}\n    \\frac{\\partial}{\\partial A} d^2_g(\\spn(X), \\spn(AA^TX))\n    & = \\sum_{j=1}^p2\\theta_j\\frac{\\partial \\theta_j}{\\partial A}\\\\\n    & = \\sum_{j=1}^p -4\\theta_j \\csc 2\\theta_j X^Tv_jv_j^TX^TA\\\\\n    & = -4XV\\widetilde{\\Sigma}V^TX^TA.\n\\end{align*}\nWhere, $\\widetilde{\\Sigma} = \\diag(\\theta_1\\csc 2\\theta_1,\\ldots,\\theta_p\\csc 2\\theta_p)$. Hence,\n\\[\n    \\frac{\\partial L_{u,g}}{\\partial A} = -\\frac{4}{N}\\left(\\sum_{i=1}^NX_iV_i\\widetilde{\\Sigma}_iV_i^TX_i^T\\right)A.\n\\]\n\\end{proof}\n\nFrom Proposition~\\ref{prop:gradient}, we can see that the major advantage of the projection distance is the computational efficiency, which will be demonstrated via experiments in Section~\\ref{exp}.\n\n\\subsection{Nested Grassmann Analysis}%\n\\label{sub:nested_grassmann}\n\nIn practice, we might not have prior knowledge about $m$. So one can choose $p < m_1 < \\ldots < m_k < n$ and construct a sequence of Grassmann manifolds\n\\[\n\\gr(p, m_1) \\stackrel{A_1}{\\hookrightarrow} \\gr(p, m_2)\n\\stackrel{A_2}{\\hookrightarrow} \\ldots \\stackrel{A_{k-1}}{\\hookrightarrow}\n\\gr(p, m_k) \\stackrel{A_k}{\\hookrightarrow} \\gr(p, n).\n\\]\nThen for each nested Grassmann, we compute the percentage of variance explained. Suppose $\\mc{X}_1 = \\spn(X_1),\\ldots,\\mc{X}_N=\\spn(X_N) \\in \\gr(p,n)$ and $A_1,\\ldots,A_k$ are obtained from the algorithm described in the previous section. The percentage of variance explained in $\\gr(p,m_i)$ is given by,\n\\[\n    \\frac{\\sum_jd_g^2(\\hat{\\mc{X}}_j,\n    \\bar{\\hat{\\mc{X}}})}{\\sum_jd_g^2(\\mc{X}_j, \\bar{\\mc{X}})} .\n\\]\nWhere, $\\hat{\\mc{X}}_j = \\spn(A_i^TA_{i+1}^T \\ldots A_k^TX_j)$ and $\\bar{\\mc{X}}$ and $\\bar{\\hat{\\mc{X}}}$ are the FM of $\\mc{X}_i$ and $\\hat{\\mc{X}}_i$ respectively. The dimension $m$ can be chosen according to the desired percentage of variance explained somewhat similar to the way one chooses the number of principal components.\n\n \\section{Experiments}\\label{exp}\n\nIn this section, we will demonstrate the performance of the proposed dimensionality reduction technique, i.e.\\ NG and sNG, via experiments on synthetic and real data.\n\n\\subsection{Synthetic Data}%\n\\label{sub:synthetic_data}\n\nIn this subsection, we compare the performance of the projection and the geodesic distances respectively. The questions we will answer are the following:\n\\begin{itemize}\n\\item From Section \\ref{sub:distance}, we see that using projection distance is more efficient than using the geodesic distance. But how do they perform compared to each other under varying dimension $n$ and variance level $\\sigma^2$?\n\\item Is our method of dimensionality reduction better than PGA? Under what conditions does our method outperform the PGA? \n\\end{itemize}\n\n\\subsubsection{Comparison of projection and geodesic distances}%\n\\label{sub:comparison_of_projective_f_norm_and_geodesic_distance}\n\nThe procedure we used to generate random points on $\\gr(p, n)$ for the synthetic experiments is outlined in Algorithm~\\ref{algo:synth_exp}. The generation of random points from the uniform distribution on $\\st(m, n)$ is as follows. First, we generate $\\tilde{X} \\in \\R^{m\\times p}$ where $\\tilde{X}_{ij}\\iid N(0, 1)$, then $X = \\tilde{X}(\\tilde{X}^T\\tilde{X})^{-1/2}$ follows the uniform distribution on $\\st(m, n)$ \\citep[Ch.\\ 2.5]{chikuse2003statistics}.\n\n\\begin{algorithm}\n\\SetAlgoLined\n\\KwIn{sample size $N$, variance $\\sigma^2$, dimension $p$, $m$, and $n$}\n\\KwOut{$\\mc{X}_1,\\ldots, \\mc{X}_N \\in \\gr(p, n)$}\n\\begin{enumerate}\n    \\item Generate $X_1,\\ldots,X_N$ from the uniform distribution on $\\st(p, m)$\n    \\item Generate $A$ from the uniform distribution on $\\st(m, n)$\n    \\item Compute $\\tilde{\\mc{X}}_i = \\spn(AX_i) \\in \\gr(p, n)$, $i=1,\\ldots,N$\n    \\item Generate $\\tilde{U}_i \\in T_{\\tilde{\\mc{X}}_i}\\gr(p, n)$ and $U_i = \\tilde{U}_i/\\|\\tilde{U}_i\\|$, $i=1,\\ldots,N$\n    \\item Compute $\\mc{X}_i = \\text{Exp}_{\\tilde{\\mc{X}}_i}(\\sigma U_i)$, $i=1,\\ldots,N$.\n\\end{enumerate}\n \\caption{Synthetic data generation in $\\gr(p, n)$ with different variances}\\label{algo:synth_exp}\n\\end{algorithm}\n\nThe first experiment involves comparing the computational efficiency of the NG dimension reduction method using the geodesic distance and the projection distance respectively. In this experiment, we set $N=50$, $m=10$, $p=1$, and $\\sigma=1$ and $n$ is ranging from 20 to 300. Then, we apply the algorithms in Section~\\ref{sub:dr} to solve for $A$ and evaluate the performance using the ratio of the variance explained and the computational time respectively. The results are averaged over $100$ repetitions and are shown in Figure~\\ref{fig:time}. Clearly, the projection distance is computationally much more efficient than the geodesic distance as one would expect since the geodesic distance requires SVD which has a time complexity of $O(n^3)$ and the projection distance only requires matrix multiplication which has a time complexity $O(n^2)$.\n\n\nThe second experiment involves comparing the performance of the NG representation in terms of the ratio of the variance explained, under different levels of data variance. In this experiment, we set $N=50$, $n=10$, $m=3$, and $p=1$ and $\\sigma$ is ranging from 1 to 10. The results are averaged over $100$ repetitions and are shown in Figure~\\ref{fig:var_sig}. From these results, we can see that the ratios of variance explained for the projection distance and the geodesic distance are indistinguishable but the one using projection distance is much faster than the one using the geodesic distance. The reason is that when two points on the Grassmann manifold are close, the geodesic distance can be well-approximated by the projection distance. When the algorithm converges, the original point $\\mc{X}_i$ and the reconstructed point $\\hat{\\mc{X}}_i$ should be close and the geodesic distance can thus be well-approximated by the projection distance. Therefore, for the experiments in the next section, we use the projection distance for the sake of efficiency.\n\n\\begin{minipage}[t]{\\linewidth}\n      %\\centering\n      \\begin{minipage}[t]{0.4\\linewidth}\n        \\begin{figure}[H]\n            \\centering\n            \\includegraphics[width=\\linewidth]{time}\n            \\caption{CPU time comparison for computing the NG using $L_{u,p}$ and $L_{u,g}$ respectively.}\n            \\label{fig:time}\n        \\end{figure}\n      \\end{minipage}\n      \\hspace{0.1 \\linewidth}\n      \\begin{minipage}[t]{0.4\\linewidth}\n        \\begin{figure}[H]\n            \\centering\n            \\includegraphics[width=\\linewidth]{var_sig}\n            \\caption{Comparison of the NG representations based on the projection and geodesic distances using expressed variance as a function of varying levels of variance.}\n            \\label{fig:var_sig}\n        \\end{figure}\n      \\end{minipage}\n\\end{minipage}\n\n\\subsubsection{Comparison of NG and PGA}%\n\\label{sub:comparison_of_nested_grassmann_and_pga}\n\nNow we compare our NG representation to PGA. Similar to the previous experiment, we set $N=50$, $n=20$, $m=10$, $p=1$, and $\\sigma=1$ and apply Algorithm~\\ref{algo:synth_exp} to generate synthetic data. There is a subtle difference between PGA and NG, that is,  in order to project the points on $\\gr(p, n) = \\gr(1, 20)$ to an $\\tilde{m}$-dimensional submanifold, for PGA we need to choose $\\tilde{m}$ principal components and for NG we need to project them to $\\gr(1, \\tilde{m}+1)$ (since $\\dim\\gr(1, \\tilde{m}+1) = \\tilde{m}$). The results are averaged over $100$ repetitions and are shown in Table~\\ref{tab:pga}.\n\n\\begin{table}[!ht]\n\\centering\n\\begin{tabular}{lccccc}\n    \\toprule\n    & \\multicolumn{5}{c}{$\\tilde{m}$}\\\\\n    \\cmidrule{2-6}\n    & 1 & 2 & 3 & 4 & 5 \\\\\n    \\midrule\n    NG & 48.74\\% & 68.56\\% & 79.29\\% & 85.4\\% & 90.85\\% \\\\\n    PGA        & 18.96\\% & 35.14\\% & 48.81\\% & 61.17\\% & 71.61\\% \\\\\n    \\bottomrule\n\\end{tabular}\n\\caption{The percentage of variance explained by PGA and NG representations respectively.}\n\\label{tab:pga}\n\\end{table}\n\nFrom table \\ref{tab:pga}, we can see that our method outperforms PGA by virtue of the fact that it is able to capture a larger amount of variance contained in the data. Next, we will investigate the conditions under which our method and PGA perform equally well and when our method outperforms PGA. To answer this question, we set $N=50$, $n=10$, $m=3$, $p=1$, and $\\sigma$ is ranging from 1 to 10 in Algorithm~\\ref{algo:synth_exp}. We then apply PGA and NG to reduce the dimension to 1 (i.e.\\ choosing 1 principal component in PGA and project to $\\gr(1, 2)$ in NG). The results are averaged over $100$ repetitions and are shown in Figure~\\ref{fig:var_PGA}. We can see that when the variance is small, our method produces almost the same result as PGA, whereas, our method is significantly better for the large data variance case. Note that when the variance in the data is small, i.e.\\ the data are tightly clustered around the FM, PGA captures the essence of the data well. However, the requirement in PGA on the geodesic submanifold to pass through the anchor point, namely the FM, is not meaningful for data with large variance as explained through the following simple example. Consider, a few data points spread out on the equator of a sphere. The FM in this case is likely to be the north pole of the sphere if we restrict ourselves to the upper hemisphere. Thus, the geodesic submanifold computed by PGA will pass through this FM. However, what is more meaningful is a submanifold corresponding to the equator, which is what a nested spheres representation \\cite{jung2012analysis} in this case yields. In similar vein, for data with large variance on a Grassmann manifold, our NG representation will yield a more meaningful representation than PGA.\n\n\\begin{figure}[!ht]\n    \\centering\n    \\includegraphics[width=0.5\\linewidth]{var_sig_PGA}\n    \\caption{Comparison of the percentage of variance explained by the NG and PGA respectively.}\n    \\label{fig:var_PGA}\n\\end{figure}\n\n\\subsection{Application to Planar Shape Analysis}%\n\\label{sub:applications_to_planar_shape_analysis}\n\nWe now apply our method to planar (2-dimensional) shape analysis. A planar shape $\\sigma$ can be represented an ordered set of $k > 2$ points in $\\R^2$, called $k$-ads. Here we assume that these $k$ points are not all identical. A $k$-ad can also be represented by a $k \\times 2$ real matrix. When representing a planar shape as a matrix, we would like to ignore the effect of translations, rotations, and scaling. Formally speaking, the space of all planar shapes, denoted $\\Sigma^k_2$, is defined as\n\\[\n    \\Sigma^k_2 = (\\mathbb{R}^{k \\times 2}/\\text{Sim}(2)) \\setminus \\{0\\}\n\\]\nwhere $\\text{Sim}(2)$ is the group of similarity transformations of $\\R^2$, i.e.\\ if $g \\in \\text{Sim}(2)$, then $g(x) = sRx+t$ for some $s > 0$, $R \\in \\text{O}(2)$, and $t \\in \\R^2$. The $\\{0\\}$ is excluded because we assume the $k$ points are not all identical. \\citet{kendall1984shape} showed that $\\Sigma^k_2$ is a smooth manifold and, when equipped with the Procrustean metric, is isometric to the complex projective space $\\C P^{k-2}$ equipped with the Fubini-Study metric which is a special case of the complex Grassmannians, i.e.\\ $\\C P^{k-2} \\cong \\gr(1,\\C^{k-1})$.\n\nIn practice, we need to preprocess the $k$-ads as follows to make it lie in $\\gr(1, \\C^{k-1})$. Let \n\\[\nX=\\left[\\begin{array}{cc}\n        x_{0} & y_{0}\\\\\n        \\vdots & \\vdots\\\\\n        x_{k-1} & y_{k-1}\n\\end{array}\\right]_{k \\times 2}\n\\]\nbe the matrix containing the $k$ points. First, the effect of translation is removed by subtracting the first point.  Then all these points are mapped to the complex vector space and take the span of the resulting vector to remove the effect of rotation and scaling. To sum up,\n\\[\n    \\mc{X} = \\spn\\left(LX\n            \\left[\\begin{array}{c}\n                    1\\\\\n                    i\n            \\end{array}\\right]\n    \\right)\n\\]\nis the point on $\\gr(1, \\C^{k-1})$ corresponding to $X$ where $L=[-{\\bf 1}_{k-1} \\;\\; I_{k-1}]$.\n\n\\paragraph{OASIS Corpus Callosum Data Experiment}\n\nThe OASIS database \\citep{marcus2007open} is a publicly available database that contains T1-MR scans of subjects with age ranging from 18 to 96. In particular, it includes subjects that are clinically diagnosed with mile to moderate Alzheimer\u2019s disease. We further classify them into three groups: \\emph{young} (aged between 10 and 40), \\emph{middle-aged} (aged between 40 and 70), and \\emph{old} (aged above 70). For demonstration, we randomly choose 4 brain scans within each decade, totalling 36 brain scans. From each scan, the Corpus Callosum (CC) region is segmented and 250 points are taken on the boundary of the CC region. See Figure~\\ref{fig:CC} for example. In this case, the shape space is $\\Sigma^{248}_2 \\cong \\mathbb{C}P^{248} \\cong \\mathsf{Gr}(1, \\mathbb{C}^{249})$. The result is shown in Table~\\ref{tab:CC_pga}. Note that in Table~\\ref{tab:CC_pga}, $m$ is the dimension of the submanifold, i.e.\\ for NG, we project to $\\gr(p, \\C^{m+1})$ and for PGA, we take first $m$ principal components. \n\n\\begin{figure}[!ht]\n    \\centering\n    \\includegraphics[width=0.6\\linewidth]{OASIS_CC_shape}\n    \\caption{Example Corpus Callosi shapes from three distinct age groups, each depicted using the boundary point sets.}\n    \\label{fig:CC}\n\\end{figure}\n\n\\begin{table}[!ht]\n\\centering\n\\begin{tabular}{lccccc}\n    \\toprule\n    & \\multicolumn{5}{c}{m}\\\\\n    \\cmidrule{2-6} \n    & 1 & 5 & 10 & 15 & 20\\\\\n    \\midrule\n    NG  & 26.38\\% & 68.56\\% & 84.18\\% & 90.63\\% & 94.04\\%\\\\\n    PGA & 7.33\\% & 43.74\\% & 73.48\\% & 76.63\\% & 79.9\\%\\\\\n    \\bottomrule\n\\end{tabular}\n\\caption{Percentage of variance explained by PGA and NG representations respectively.}\n\\label{tab:CC_pga}\n\\end{table}\n\nSince the data are divided into three groups (young, middle-aged, and old), we can apply the sNG described in Section~\\ref{sub:supervised_dr} to reduce the dimension. {\\it The purpose of this experiment is not to demonstrate state-of-the-art classification accuracy for this dataset. Instead, our goal here is to demonstrate that the proposed nested Grassmann representation in a supervised setting is much more discriminative than the competition, namely the supervised PGA}. Hence, we choose a naive and impoverished classifier such as the geodesic $k$NN (gKNN) to highlight the aforementioned discriminative power of the nested Grassmann over PGA.\n\nIn this experiment, for the computation of affinity matrix, we choose $\\nu_w = \\nu_b = 5$. For comparison, the PGA can be easily extended to {\\it supervised PGA} (sPGA) by first diffeomorphically mapping all the data to the tangent space anchored at the FM and then performing supervised PCA \\citep{bair2006prediction, barshan2011supervised} on the tangent space. In this demonstration, we apply a gKNN  classifier with $k=5$ to the data before and after reducing the dimension (with and without supervision). Specifically, {\\it the classification here is using a leave-one-out technique}, i.e.\\ the prediction of $\\mc{X}_j$ is determined by the geodesic $k$ nearest neighbors of the $\\mc{X}_i$'s excluding $\\mc{X}_j$. In this experiment, we choose $m = 11$, i.e.\\ $\\gr(1, \\C^{249}) \\to \\gr(1, \\C^{11})$ (for PGA/sPGA, the number of principal components would be $m - 1 = 10$). The results are shown in Table~\\ref{tab:classification}. These results are in accordance with our expectation since in both sNG and sPGA, we seek a projection that minimizes the within-group variance while maximizing the between-group variance. However, as we observed earlier, the constraint of requiring the geodesic submanifold to pass through the FM is not well suited for this dataset which has a large variance across the data. This accounts for why the sNG exhibits far superior performance compared to sPGA in accuracy as well as in explained variance.    \n\n\\begin{table}[!ht]\n\\centering\n\\begin{tabular}{lcc}\n    \\toprule\n    & Accuracy & Explained Var.\\\\\n    \\midrule \n    gKNN        & 33.33\\% & N/A\\\\\n    gKNN + sPGA & 38.89\\% & 3.27\\% \\\\\n    gKNN + sNG  & 66.67\\% & 98.7\\% \\\\\n    gKNN + PGA  & 30.56\\% & 46.61\\% \\\\\n    gKNN + NG   & 30.56\\% & 84.28\\% \\\\\n    \\bottomrule\n\\end{tabular}\n\\caption{Classification accuracies and explained variances for sPGA and sNG.}\n\\label{tab:classification}\n\\end{table}\n\n \\section{Conclusion}\\label{conc}\n\nIn this work, we presented a novel dimensionality reduction technique for Grassmann manifolds by utilizing the geometry of Grassmann manifolds. We showed that a lower dimensional Grassmann manifold can be isometrically embedded into a higher dimensional Grassmann manifold and via this embedding we constructed a sequence of nested Grassmann manifolds. Compared to the PGA, which is designed for general Riemannian manifolds, the proposed method can capture a higher percentage of variance after reducing the dimensionality. The main reason for this result is that by construction, the PGA constructs a geodesic submanifold passing through the Fr\\'{e}chet mean of the data while in nested Grassmann there is no such constraint. In Euclidean space, requiring the principal subspace to pass through the sample mean is actually not a constraint since for data lying in a vector subspace, the sample mean is still in the same subspace. However, in general Riemannian manifolds, one can easily construct a counterexample that the Fr\\'{e}chet mean of the data lying in a geodesic submanifold is not in the same submanifold. Hence by removing this constraint, we are able to design a better dimensionality reduction method on the Grassmann manifold. We also proposed a supervised dimensionality reduction technique similar to \\citet{harandi2018dimensionality} which tries to separate different classes while reducing dimensionality. For applications, we applied our method to the OASIS Corpus Callosi data for dimensionality reduction and classification. We showed that our method outperforms the widely used PGA significantly.   \n \n\n\\bibliographystyle{asa}\n\n\\bibliography{reference}\n\n\n\\end{document}", "meta": {"timestamp": "2020-10-29T00:04:01", "yymm": "2010", "arxiv_id": "2010.14589", "url": "https://arxiv.org/abs/2010.14589", "source": "arxiv"}}
{"text": "\\documentclass[a4paper, 11pt]{article}\r\n\\usepackage{anysize}\r\n\\marginsize{3,5cm}{2,5cm}{2,5cm}{2,5cm}\r\n\\usepackage{amssymb}\r\n\\usepackage{amsmath,amsbsy,amssymb,amscd}\r\n\\usepackage{t1enc}\\pagestyle{myheadings}\r\n\\usepackage[cp1250]{inputenc}\r\n\\usepackage[all]{xy}\r\n\\usepackage{color}\r\n\\usepackage{amsfonts}\r\n\\usepackage{latexsym}\r\n\\usepackage{amsthm}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{hyperref}\r\n\\usepackage{graphicx}\r\n\\usepackage{comment}\r\n\\newtheorem{Main}{Proposition}\r\n\\renewcommand{\\theMain}{\\Alph{Main}}\r\n\\usepackage{color}\r\n\\usepackage{caption}\r\n\\usepackage{subcaption}\r\n\\usepackage{enumerate}\r\n\\usepackage{xcolor}\r\n%\\usepackage{tikz-cd}\r\n\\usepackage[draft]{todonotes}\r\n\\usepackage{float}\r\n\\usepackage{amsmath}\r\n\\usepackage{amsfonts}\r\n\\usepackage{amssymb}\r\n\\usepackage{amsthm}\r\n\\usepackage{mathtools}\r\n\\usepackage{graphicx}\r\n\\usepackage{fancyhdr}\r\n\\usepackage{geometry}\r\n\\usepackage{hyperref}\r\n\\usepackage{mathrsfs}\r\n\\usepackage{longtable}\r\n\\usepackage[nottoc,numbib]{tocbibind}\r\n\\usepackage{centernot}\r\n\\usepackage{color}\r\n\\usepackage{verbatim}\r\n\\usetikzlibrary{arrows, calc, decorations.markings, positioning, quotes}\r\n\\usepackage{lipsum}\r\n\r\n\\allowdisplaybreaks\r\n\r\n\\makeatletter\r\n\\def\\blfootnote{\\xdef\\@thefnmark{}\\@footnotetext}\r\n\\makeatother\r\n\r\n\r\n\r\n\\pagestyle{fancy}\r\n\\makeatletter\r\n\\DeclareRobustCommand{\\format@sec@number}[2]{{\\normalfont\\upshape#1}#2}\r\n\\renewcommand{\\sectionmark}[1]{\\markright{#1}}\r\n\\makeatother\r\n\r\n\\fancyhf{}\r\n\\fancyhead[L]{\\itshape\\nouppercase{\\rightmark}}\r\n\\fancyhead[R]{\\thepage}\r\n\r\n\r\n\\definecolor{orange}{rgb}{1,0.5,0}\r\n\\def\\orange{\\color{orange}}\r\n\\def\\green{\\color{red}}\r\n\\def\\green{\\color{green}}\r\n\\def\\blue{\\color{blue}}\r\n\r\n\r\n\\newcommand\\xdownarrow[1][2ex]{%\r\n   \\mathrel{\\rotatebox{90}{$\\xleftarrow{\\rule{#1}{0pt}}$}}\r\n}\r\n\\newcommand{\\margem}[1]{\\marginpar{{\\scriptsize {#1}}}}\r\n%\\newcommand{\\comment}[1]{\\par {\\bfseries \\color{blue} #1 \\par}}\r\n%\\usepackage{pmat}\r\n\r\n%59.66.62.71\r\n%255.255.255.0\r\n%59.66.62.1\r\n%166.111.8.28/166.111.8.29\r\n\r\n%%=======================KURSYWY DU\u0139\u0165E===================\r\n\r\n\\usepackage{mathrsfs} %Script dla zapisu \\mathscr{}\r\n\r\n\\DeclareMathAlphabet{\\mathpzc}{OT1}{pzc}{L}{it} %stylizowany\r\n%dla zapisu $\\pzc{}\r\n\r\n\r\n\\def\\scr#1{{\\mathscr #1}} %skr\u0102\u0142t do script\r\n\\def\\cal#1{{\\mathcal #1}} %skr\u0102\u0142t do calligraphic\r\n\\def\\pzc#1{{\\mathpzc #1}} %skr\u0102\u0142t stylizowanego\r\n\r\n%%=================================================================\r\n\r\n%\\parskip 1,2mm\r\n%\\parindent 7mm \\voffset -17mm\r\n%\\hoffset -10mm \\textwidth 168mm \\textheight 23\r\n%9mm \\oddsidemargin 8\r\n%mm\\evensidemargin 7mm\\footnotesep 3mm \\hbadness 10000\r\n\r\n\\def\\vphi{\\varphi}\r\n\\def\\a{\\alpha}\r\n\\def\\epsilonp{\\varepsilon}\r\n\r\n\r\n\r\n\\numberwithin{equation}{section}\r\n\r\n\r\n\\theoremstyle{definition}\r\n\\newtheorem{definition}{Definition}[section]\r\n\\newtheorem{theorem}[definition]{Theorem}\r\n\\newtheorem{sublemma}[definition]{Sublemma}\r\n\\newtheorem{proposition}[definition]{Proposition}\r\n\\newtheorem{corollary}[definition]{Corollary}\r\n\\newtheorem{lemma}[definition]{Lemma}\r\n\\newtheorem{example}[definition]{Example}\r\n\\newtheorem{lemmata}[definition]{Lemmata}\r\n\\newtheorem{fakt}[definition]{Fact}\r\n\\newtheorem{remark}[definition]{Remark}\r\n\\newtheorem{question}[definition]{Question}\r\n\\newtheorem{claim}[definition]{Claim}\r\n\\newtheorem{target}[definition]{Target}\r\n\r\n\r\n%\\hoffset -5mm \\voffset -18mm\r\n%\\setlength{\\oddsidemargin}{1 cm} \\setlength{\\evensidemargin}{1 cm}\r\n%\\setlength{\\textwidth}{14.8cm} \\setlength{\\textheight}{22.9cm}\r\n%\\parskip 4mm\r\n\\def\\Re{\\mathrm{Re\\,}}\r\n\\def\\Im{\\mathrm{Im\\,}}\r\n\\def\\codim{\\mathrm{codim\\,}}\r\n\\def\\i{\\mathrm{i}}\r\n\\def\\dist{\\mathrm{dist}}\r\n\\def\\vp{\\varphi}\r\n\\def\\H{\\mathbb{H}}\r\n\\def\\C{\\mathbb{C}}\r\n\\def\\cP{\\mathcal{P}}\r\n\\def\\geq{\\geqslant}\r\n\\def\\leq{\\leqslant}\r\n\\def\\R{\\mathbb{R}}\r\n\\def\\T{\\mathbb{T}}\r\n%\\def\\S{\\mathbb{S}}\r\n\\def\\eps{\\varepsilon}\r\n\\def\\cl{\\mathrm{cl\\,}}\r\n\\def\\Int{\\mathrm{int\\,}}\r\n\\def\\bd{\\mathrm{bd\\,}}\r\n\\def\\multi{\\multimap}\r\n\\def\\Hom{\\mathrm{Hom}}\r\n\\def\\mul{\\multimap}\r\n\\def\\Gr{\\mathrm{Gr}}\r\n\\def\\E{\\mathbb{E}}\r\n\\def\\Z{\\mathbb{Z}}\r\n\\def\\N{\\mathbb{N}}\r\n\\def\\F{\\mathbb{F}}\r\n\\def\\id{\\mathrm{id}}\r\n\\def\\lla{\\longleftarrow}\r\n\\def\\lra{\\longrightarrow}\r\n\\def\\ka{\\times}\r\n\\def\\Per{\\mathrm{Per}}\r\n\\def\\Tr{\\mathrm{Tr}}\r\n\\def\\Fix{\\mathrm{Fix}}\r\n\\def\\Ker{\\mathrm{Ker}\\,}\r\n\\def\\la{\\langle}\r\n\\def\\ra{\\rangle}\r\n\\def\\sgn{\\mathrm{sgn}\\,}\r\n\\def\\ind{\\mathrm{ind}}\r\n\\def\\K{\\mathbb{K}}\r\n\\def\\Q{\\mathbb{Q}}\r\n\\def\\cB{\\mathbb{B}}\r\n\\def\\bI{\\bar I}\r\n\\def\\cF{\\mathcal F}\r\n\\def\\tu{\\tilde{u}}\r\n\\def\\ts{\\tilde{s}}\r\n\\def\\tv{\\tilde{v}}\r\n\\def\\th{\\theta}\r\n\\def\\epsilon{\\varepsilon}\r\n\\def\\cC{\\mathcal{C}}\r\n\\def\\Aut{\\operatorname{Aut}}\r\n\\def\\mf{\\mathfrak}\r\n\\def\\Lie{\\operatorname{Lie}}\r\n\\def\\ad{\\operatorname{ad}}\r\n\\def\\Ad{\\operatorname{Ad}}\r\n\\def\\rank{\\operatorname{rank}}\r\n\\def\\diag{\\operatorname{diag}}\r\n\\def\\End{\\operatorname{End}}\r\n\\def\\inj{\\operatorname{inj}}\r\n\\def\\Kak{\\operatorname{Kak}}\r\n\\def\\Bow{\\operatorname{Bow}}\r\n\\def\\Isom{\\operatorname{Isom}}\r\n\\def\\arcsinh{\\operatorname{arcsinh}}\r\n\\def\\ker{\\operatorname{ker}}\r\n\\def\\vspan{\\operatorname{span}}\r\n\\def\\Sym{\\operatorname{Sym}}\r\n\\def\\Leb{\\operatorname{Leb}}\r\n\\def\\e{\\varepsilon}\r\n\\def\\f{\\phi}\r\n\\def\\vf{\\varphi}\r\n\\def\\a{\\alpha}\r\n\\def\\b{\\beta}\r\n\\def\\P{\\mathfrak P}\r\n\\def\\th{\\theta}\r\n\\def\\d{\\delta}\r\n\\def\\vt{\\vartheta}\r\n\\def\\D{\\Delta}\r\n\\def\\G{\\Gamma}\r\n\\def\\g{\\gamma}\r\n\\def\\k{\\kappa}\r\n\\def\\DD{\\mathcal D}\r\n\\def\\l{\\lambda}\r\n\\def\\L{\\Lambda}\r\n\\def\\EE{\\mathcal E}\r\n\\def\\s{\\sigma}\r\n\\def\\Si{\\Sigma}\r\n\\def\\x{\\times}\r\n\\def\\R{\\mathbb R}\r\n\\def\\N{{\\mathbb N}}\r\n\\def\\E{\\mathbb E}\r\n\\def\\Z{\\mathbb Z}\r\n\\def\\T{\\mathbb T}\r\n\\def\\H{\\mathbb H}\r\n\\def\\F{\\mathbb F}\r\n\\def\\P{\\mathbb P}\r\n\\def\\S{\\mathbb S}\r\n\\def\\X{\\mathfrak{X}}\r\n\\def\\ov{\\overline}\r\n\\def\\un{\\underline}\r\n\\def\\f{\\flushpar}\r\n\\def\\usim{\\underset{\\sim}\\to{<}}\r\n\\def\\v{\\varphi}\r\n\\def\\p{\\phi}\r\n\\def\\U{\\underbar}\r\n\\def\\om{\\omega}\r\n\\def\\Om{\\Omega}\r\n\\def\\B{\\mathcal B}\r\n\\def\\A{\\mathcal A}\r\n\\def\\C{\\mathbb C}\r\n\\def\\CC{\\mathcal C}\r\n\\def\\FF{\\mathcal F}\r\n\\def\\Q{\\mathbb Q}\r\n\\def\\O{\\mathcal O}\r\n\\def\\U{\\mathcal U}\r\n\\def\\W{\\mathcal W}\r\n\\def\\I{\\mathcal I}\r\n\\def\\wh{\\widehat}\r\n\\def\\wt{\\widetilde}\r\n\\def\\({\\biggl(}\r\n\\def\\){\\biggr)}\r\n\\def\\<{\\mathbf{\\langle}}\r\n\\def\\>{\\mathbf{\\rangle}}\r\n\\def\\pprime{\\prime\\prime}\r\n\\def\\r{\\Cal R}\r\n\\def\\OLL{{\\overline{\\mathcal L}}}\r\n\\def\\LL{{{\\mathcal L}}}\r\n\\def\\seq{\\circeq}\r\n\\def\\t{\\un{\\theta}}\r\n\\def\\M{\\mathcal {M}}\r\n\\def\\MM{\\widehat {M}}\r\n\\def\\ovpi{\\overline \\pi}\r\n\\def\\P{\\mathcal P}\r\n\\def\\diff{\\text{Diff }^\\omega_\\infty(S^3,\\mu)}\r\n\\def\\diffr{\\text{Diff }^\\omega_\\rho(S^3,\\mu)}\r\n\\def\\para{[0,1]^{L+1}}\r\n\\def\\bk{\\bar{k}}\r\n\\def\\bt{\\bar{t}}\r\n\\def\\dist{\\text{dist}}\r\n\\def\\uent{\\overline{\\text{ent}}}\r\n\\def\\lent{\\underline{\\text{ent}}}\r\n\\def\\ent{\\text{ent}}\r\n\r\n\\DeclareMathOperator*{\\ess}{ess}\r\n\r\n\\newcommand{\\Meng}[2]{\\left\\{#1\\mathrel{}\\middle|\\mathrel{}#2\\right\\}}\r\n%\\newcommand{\\abs}[1]{\\left\\lvert#1\\right\\rvert}\r\n%\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\r\n\r\n\\newcommand{\\rr}{\\color{red}}\r\n\\newcommand{\\bb}{\\color{blue}}\r\n\r\n\r\n\r\n\\newcommand{\\bea}{\\begin{eqnarray}}\r\n  \\newcommand{\\eea}{\\end{eqnarray}}\r\n  \\newcommand{\\beab}{\\begin{eqnarray*}}\r\n  \\newcommand{\\eeab}{\\end{eqnarray*}}\r\n\\renewcommand{\\a}{\\alpha}\r\n  \\newcommand{\\be}{\\begin{equation}}\r\n  \\newcommand{\\ee}{\\end{equation}}\r\n  \\newcommand{\\RQ}{\\R \\setminus \\Q}\r\n\\newcommand{\\cI}{\\mathcal I}\r\n\\newcommand{\\cD}{\\mathcal D}\r\n\\newcommand{\\cE}{\\mathcal E}\r\n\\newcommand{\\set}[1]{\\left\\lbrace #1 \\right\\rbrace}\r\n\\newcommand{\\abs}[1]{\\left| #1 \\right|}\r\n\\newcommand{\\mc}{\\mathcal}\r\n\\newcommand{\\norm}[1]{\\abs{\\abs{#1}}}\r\n\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\r\n\\newcommand{\\pw}[1]{\\left\\lbrace \\begin{array}{ll} #1 \\end{array}\\right.}\r\n\\newcommand{\\of}{\\circ}\r\n\\newcommand{\\inner}[2]{\\left\\langle #1, #2 \\right\\rangle}\r\n\\newcommand{\\algexp}{\\exp_{\\operatorname{alg}}}\r\n\\newcommand{\\geomexp}{\\exp_{\\operatorname{geom}}}\r\n\\newcommand{\\alglog}{\\log_{\\operatorname{alg}}}\r\n\\newcommand{\\geomlog}{\\log_{\\operatorname{geom}}}\r\n\\newcommand{\\mbf}{\\mathbf}\r\n\\newcommand{\\ve}{\\epsilon}\r\n\r\n\\newcommand{\\carre}{\\hfill $\\Box$}\r\n\\newcommand{\\freq}{\\operatorname{freq}}\r\n\\newcommand{\\sh}{\\operatorname{sh}}\r\n\r\n\\title{Slow entropy of some combinatorial constructions\\blfootnote{Keywords: Slow entropy, finite rank, rigid, cyclic approximation, approximation-by-conjugation method.}\r\n\\blfootnote{2020 Mathematics Subject Classification:\tPrimary 37A35; Secondary 37A05, 37A25.}}\r\n\\author{Shilpak Banerjee\\footnote{Department of Mathematics, Indraprastha Institute of Information Technology Delhi (IIIT-Delhi), Okhla Industrial Estate, Phase-III, New Delhi, 110020, India, E-mail: shilpak@iiitd.ac.in} \\and Philipp Kunde\\footnote{Department of Mathematics, The Pennsylvania State University, University Park, PA 16802, USA, E-mail: pkunde.math@gmail.com P.K. acknowledges financial support from a DFG Forschungsstipendium under Grant No. 405305501.} \\and Daren Wei\\footnote{Einstein Institute of Mathematics, The Hebrew University of Jerusalem, Givat Ram. Jerusalem, 9190401, Israel, E-mail: Daren.Wei@mail.huji.ac.il  D.W. was partially supported by the NSF grant DMS-16-02409 and ERC 2020 grant HomDyn (grant no. 833423).}}\r\n\r\n\\setlength{\\marginparwidth }{2 cm}\r\n\\begin{document}\r\n\\maketitle\r\n\r\n\\begin{abstract}\r\nMeasure-theoretic slow entropy is a more refined invariant than the classical measure-theoretic entropy to characterize the complexity of dynamical systems with subexponential growth rates of distinguishable orbit types. In this paper we show that there cannot exist a general upper bound on the lower measure-theoretic slow entropy for systems of finite rank. Moreover, we prove flexibility results for the values of upper and lower polynomial slow entropy of rigid transformations as well as maps admitting a good cyclic approximation.\r\n\r\n%{\\color{red}We study the measure-theoretic slow entropy of some combinatorial constructions. In particular, we show that there cannot exist a general upper bound on the lower measure-theoretic slow entropy for systems of finite rank. Moreover, we prove flexibility results for the values of upper and lower polynomial slow entropy of rigid transformations as well as maps admitting a good cyclic approximation.}\r\n\\end{abstract}\r\n%In this paper we address three problems stated in the recent survey article \\cite{KanigowskiKatokWei}. In particular,\r\n\r\n\r\n\\section{Introduction}\r\nDating back to the foundational paper of J.\\ von Neumann \\cite{Ne} the classification of measure-preserving transformations (MPT's) up to isomorphism is a fundamental theme in ergodic theory. While the \\emph{isomorphism problem} for general ergodic transformations remains intractable and is inaccessible to countable methods that use countable amount of information \\cite{FRW}, it has been solved for some special classes of transformations. Two great successes are the Halmos-von Neumann\r\nclassification of ergodic MPT's with pure point spectrum by countable subgroups of the unit circle \\cite{HN} and D. Ornstein's classification of Bernoulli shifts by their\r\nmeasure-theoretic entropy \\cite{Or}.\r\n\r\nIn general, measure-theoretic entropy plays a central role in structural questions for dynamical systems and is a crucial tool in detecting chaoticity of a system. However, the measure-theoretic entropy is positive if and only if the system has exponential growth of distinguishable orbit types and it does not provide any information for systems with slower orbit growth. To measure the complexity of systems with subexponential orbit growth several invariants like \\emph{sequence entropy} by A. Kushnirenko \\cite{Kushnirenko}, \\emph{slow entropy} by A. Katok and J.-P. Thouvenot \\cite{KatokThou}, \\emph{measure-theoretic complexity} by S. Ferenczi \\cite{Fe}, and \\emph{entropy dimension} by M. de Carvalho \\cite{Carvalho} have been introduced and studied intensely (e.g. \\cite{Goodman}, \\cite{Hulse}, \\cite{HuangShaoYe}, \\cite{FerencziPark}, \\cite{ADP}, \\cite{DouHuangPark}, \\cite{HKM}, \\cite{CK}, \\cite{KanigowskiVinhageWei}, \\cite{KanigowskiKundeVinhageWei}). We refer to the recent survey article \\cite{KanigowskiKatokWei} by A. Kanigowski, A. Katok and D. Wei for definitions and further background. In this paper we focus on measure-theoretic slow entropy (see Section \\ref{sec:slowentropy}) and address three problems stated in \\cite{KanigowskiKatokWei}.\r\n\r\nMotivated by results of Ferenczi \\cite[Proposition 5]{Fe} and Kanigowski \\cite[Proposition 1.3]{Kanigowski} showing that the lower measure-theoretic slow entropy of rank-one systems with respect to the polynomial scaling function $a_n(t)=n^t$ is bounded from above by $1$, Question 6.2.1 in \\cite{KanigowskiKatokWei} asks about the slow entropy for systems of finite rank. On the one hand, we prove in Proposition \\ref{prop:Nospacers} that every rank-two transformation \\textit{without} spacers has lower measure-theoretic polynomial slow entropy at most $1$. On the other hand, we show in Section \\ref{sec:CrazyRankTwo} that there cannot be a general bound on the lower measure-theoretic slow entropy for systems of finite rank.\r\n\\begin{theorem}[Slow entropy of finite rank system]\\label{thm:slowentropyFiniterank}\r\nFor any scaling function $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ satisfying $\\lim_{n\\to+\\infty}\\frac{\\log a_n(t)}{n}=0$, there exists a weakly mixing but not mixing system $(T,X,\\mathcal{B},\\mu_X)$ of rank two such that its lower slow entropy %$\\lent_{a_n(t)}^{\\mu}(T)$ satisfying\r\n$$\\lent_{a_n(t)}^{\\mu_X}(T)=+\\infty,$$\r\nwhere $\\mu_X(A)=\\frac{\\mu(A\\cap X)}{\\mu(X)}$ for any $A\\in\\mathcal{B}$ and $\\mu$ is Lebesgue measure of $\\mathbb{R}$.\r\n\\end{theorem}\r\n\r\nThe construction bases upon the \\emph{cutting-and-stacking technique} (cf. \\cite{Fried}) and uses additional spacer levels.\r\n\r\nRecall that for a measure preserving dynamical system $(X, \\mathscr{B},\\mu, T)$, $T$ is \\emph{rigid} if there exists an increasing sequence $\\{t_n\\}_{n \\in \\N}$ such that for any $f\\in L^2(X,\\mathscr{B},\\mu)$, $$T^{t_n}f\\to f$$ in $L^2$. Since rigid transformations always have measure-theoretic entropy zero \\cite{FuWe}, Question 6.1.2 from \\cite{KanigowskiKatokWei} asks whether it is possible for the upper measure-theoretic slow entropy of a rigid transformation to be positive with respect to the polynomial scale $a_n(t)=n^t$. In Section \\ref{sec:rigidConstruction} we answer this question in the affirmative and obtain the following flexibility result.\r\n\\begin{theorem} \\label{theo:rigidUpper}\r\n\tFor every $u\\in [0,\\infty]$ there exists an ergodic Lebesgue measure preserving rigid transformation $T$ with $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{theorem}\r\nWe are even able to construct rigid transformations with positive lower measure-theoretic polynomial slow entropy.\r\n\\begin{theorem} \\label{theo:rigidLower}\r\n\tFor every $u\\in [0,\\infty]$ there exists an ergodic Lebesgue measure preserving rigid transformation $T$ with $\\lent^{\\mu}_{n^t}(T)= u$.\r\n\\end{theorem}\r\nCurrently we do not know if there exists a rigid transformation $T$ with $\\lent^{\\mu}_{n^t}(T)=\\uent^{\\mu}_{n^t}(T)=u$ for some $0<u<\\infty$. In Theorem \\ref{theo:rigidLowerInf} we actually show that for any given subexponential rate $a_n(t)$ there exists an ergodic Lebesgue measure preserving rigid transformation $T$ with $\\lent^{\\mu}_{a_n(t)}(T)= \\infty$. Independently and by different methods, T. Adams also gave a positive answer to \\cite[Question 6.1.2]{KanigowskiKatokWei} in his recent preprint \\cite{Adams}. He shows that for any given subexponential rate $a_n(t)$ there exists a rigid and weakly mixing transformation such that the lower slow entropy is infinite with respect to $a_n(t)$. While his construction uses the technique of independent cutting-and-stacking, we use an abstract \\emph{Approximation by Conjugation method} (also known as AbC or Anosov-Katok method).\r\n\r\nThe AbC method was developed by D. Anosov and A. Katok in \\cite{AK} and is one of the most powerful tools of constructing smooth volume-preserving diffeomorphisms of entropy zero with prescribed ergodic or topological properties. In particular, it provided the first example of an ergodic $C^{\\infty}$ diffeomorphism on the disc $\\mathbb{D}^2$. In a more general framework as described in \\cite[chapter 8]{K}, one can consider any measure space admitting a non-trivial circle action $\\mathcal{R} = \\left\\{R_t\\right\\}_{t \\in \\mathbb{S}^1}$. The transformations are constructed as limits of conjugates $T_n = H_n \\circ R_{\\alpha_{n+1}} \\circ H^{-1}_n$ with $\\alpha_{n+1} = \\frac{p_{n+1}}{q_{n+1}}=\\alpha_n + \\frac{1}{k_n \\cdot l_n \\cdot q^2_n} \\in \\mathbb{Q}$ and $H_n = H_{n-1} \\circ h_n$, where the $h_n$'s are measure-preserving maps in the regularity under consideration (e.g. measurable, smooth or real-analytic) satisfying $R_{\\frac{1}{q_n}} \\circ h_n = h_n \\circ R_{\\frac{1}{q_n}}$. In each step the conjugation map $h_n$ and the parameter $k_n$ are chosen such that the transformation $T_n$ imitates the desired property with a certain precision. In a final step of the construction, the parameter $l_n$ is chosen large enough to guarantee closeness of $T_{n}$ to $T_{n-1}$, and so the convergence of the sequence $\\left(T_n\\right)_{n \\in \\mathbb{N}}$ to a limit transformation in the measurable, smooth, or even real-analytic category is provided. We refer to the survey articles \\cite{FK} and \\cite{Ksurvey} for more information on the AbC method and its wide range of applications.\r\n\r\nIn many ways, the AbC method can be seen as a constructive and smooth version of the concept of \\emph{periodic approximation in ergodic theory} which was developed by A. Katok and A. Stepin \\cite{KS}. The  concept has numerous applications in measurable dynamics and helped to solve several long-standing problems dating back to von Neumann and Kolmogorov. We give a primer on periodic approximation in Section \\ref{sec:periodicApp} and recommend \\cite{K} as a comprehensive exposition of the concept.\r\n\r\nIn particular, our transformations from Theorems \\ref{theo:rigidUpper} and \\ref{theo:rigidLower} admit periodic approximations. Hereby, these results already give a first answer to Question 6.3.1 in \\cite{KanigowskiKatokWei} which asks about the slow entropy of systems constructed by fast periodic approximation. A particularly important class are cyclic approximations, where the periodic process consists of a single tower (see Definition \\ref{def:cyclicApp} for the precise notion). The existence of a good cyclic approximation implies various properties for the limit transformation $T$ as summarized in \\cite[Proposition 3.2]{K}, e.g. $T$ is ergodic, rigid, has simple spectrum and its maximal spectral type is singular. In Section \\ref{sec:goodCyclic} we continue our investigation of slow entropy for transformations with periodic approximation by realizing systems with good cyclic approximation and any given value of upper polynomial slow entropy.\r\n\\begin{theorem} \\label{theo:cyclicUpper}\r\n\tFor every $u\\in [0,\\infty]$ there exists a Lebesgue measure preserving transformation $T$ with good cyclic approximation and $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{theorem}\r\nBy \\cite{KS} (see also \\cite[Proposition 3.2]{K}) a transformation admitting a good cyclic approximation is ergodic and rigid. Hence, our construction for Theorem \\ref{theo:cyclicUpper} provides another family of examples for Theorem \\ref{theo:rigidUpper}. In fact, we show in Theorem \\ref{theo:CyclicInfinity} that for any subexponential scale $a_n(t)$ there is a transformation $T$ with good cyclic approximation and $\\uent^{\\mu}_{a_n(t)}=\\infty$. Like \\cite[Theorem 1]{Adams} these constructions confirm a conjecture by Ferenczi in \\cite[page 205]{Fe} that there are rank one systems $T$ with $\\uent^{\\mu}_{n^t}(T)=\\infty$ (therein the conjecture is phrased in terms of the measure-theoretic complexity). To the best of our knowledge, they also provide the first standard systems (i.e. loosely Bernoulli with zero entropy or loosely Kronecker) with growth rate faster than any polynomial scale.\r\n\r\nSince transformations with good cyclic approximations are rank one, their lower measure-theoretic polynomial slow entropy can be at most $1$ by the aforementioned results of Ferenczi and Kanigowski (See Proposition \\ref{prop:upperBoundLowerCyclic} for more details). We realize all possible values of the lower polynomial slow entropy.\r\n\\begin{theorem}\\label{theo:cyclicLower}\r\n\tFor every $u\\in [0,1]$ there exists a Lebesgue measure preserving transformation $T$ with good cyclic approximation and $\\lent^{\\mu}_{n^t}(T)=u$.\r\n\\end{theorem}\r\n\r\nThese transformations are constructed by a twisted version of the abstract AbC method. We stress that the AbC transformations constructed in this paper are not necessarily smooth (To guarantee smoothness further growth conditions have to be posed on the parameter sequence $\\left(l_n \\right)_{n\\in \\N}$.). In an accompanying paper \\cite{BKW} we present a method how to compute the measure-theoretic and topological slow entropy of smooth AbC diffeomorphisms.\r\n\r\n\\paragraph{Acknowledgments:} The authors would like to thank Elon Lindenstrauss and Svetlana Katok for their warm encouragement. We are grateful to Adam Kanigowski for helpful discussions and warm support. We are also grateful to Terry Adams for sharing his preprints and helpful discussions. S.~B. would like to thank Federico Rodriguez Hertz for an invitation for a project related visit to Penn State, however this trip could not be materialized since travel restrictions were imposed due to the COVID19 outbreak.\r\n\r\n\\paragraph{Plan of the paper:} In Section \\ref{sec:DefandPre}, we provide definitions of measure-theoretic slow entropy, finite rank systems, and periodic approximations. Furthermore, we prove probabilistic lemmas that will serve as tools for our combinatorial constructions throughout the paper. In Section \\ref{sec:finiterank}, we first provide an upper bound of lower measure-theoretic slow entropy for rank two system without spacers. Then for any subexponential scale, we construct a rank two system such that its lower measure-theoretic slow entropy is infinite with respect to the given scale. In Section \\ref{sec:rigidConstruction}, we prove the flexibility of both upper and lower measure-theoretic slow entropy of the rigid transformations with respect to polynomial scale. In Section \\ref{sec:goodCyclic}, we first show the flexibility of upper measure-theoretic slow entropy for good cyclic transformations with values from $0$ to $+\\infty$ with respect to polynomial scale. Then we prove flexibility of lower measure-theoretic polynomial slow entropy of good cyclic transformations with values from $0$ to $1$, which implies that Proposition 1.3 in \\cite{Kanigowski} is sharp.\r\n\r\n\\section{Definitions and Preliminaries}\\label{sec:DefandPre}\r\n\\subsection{Measure-theoretic slow entropy}\\label{sec:slowentropy}\r\n\r\nIn this section, we define measure-theoretic slow entropy for an invertible measure-preserving transformation on a standard Borel probability space. Suppose $T$ is a measure-preserving transformation on a standard Borel probability space $(X,\\mathcal{B},\\mu)$, $\\mathcal{P}=\\{P_1,\\ldots,P_m\\}$ is a finite measurable partition and $$\\Omega_{m,n}=\\{w=(w_k)_{k=0}^n:w_k\\in\\{1,\\ldots,m\\}\\}.$$ The coding map $\\phi_{\\mathcal{P},n}(x):X\\to\\Omega_{m,n}$ of $T$ with respect to partition $\\mathcal{P}$ is defined as $\\phi_{\\mathcal{P},n}(x)=w(x)$, where $T^k(x)\\in P_{w_k(x)}$. Then for $w,w'\\in\\Omega_{m,n}$, the Hamming metric $d_n^H(w,w')$ is defined by\r\n\\begin{equation}\\label{eq:HammingMetric}\r\nd_{n}^H(w,w')=\\frac{1}{n}\\sum_{k=0}^n(1-\\delta_{w_k,w'_k}),\r\n\\end{equation}\r\nwhere $\\delta_{a,b}=\\left\\{\r\n                     \\begin{array}{ll}\r\n                       1, & \\hbox{if $a=b$;} \\\\\r\n                       0, & \\hbox{if $a\\neq b$.}\r\n                     \\end{array}\r\n                   \\right.$. Next define an $\\epsilon$-Hamming ball as $$B_{\\mathcal{P},n}(x,\\epsilon)=\\{y\\in X:d_n^H(w(x),w(y))<\\epsilon\\}$$ and a family $\\alpha_n(\\epsilon,\\mathcal{P})$ of  $\\epsilon$-Hamming balls such that $\\mu(\\cup\\alpha_n(\\epsilon,\\mathcal{P}))>1-\\epsilon$ is a $(\\epsilon,\\mathcal{P},n)$-covering of $X$. Finally we denote the minimal cardinality of  $(\\epsilon,\\mathcal{P},n)$-covering as \\begin{equation}\r\nS(\\mathcal{P},n,\\epsilon)=\\min\\{\\operatorname{Card}(\\alpha_n(\\epsilon,\\mathcal{P}))\\}.\r\n\\end{equation}\r\nIn order to simplify our notation, we define $N(\\mathcal{P},n,\\epsilon)$ as the maximal cardinality of $\\epsilon-$separated sets in $X$ with respect to Hamming metric induced by $\\mathcal{P}$ up to length $n$. Then it is clear that we have\r\n\\begin{equation}\\label{eq:CoveringSeparated}\r\nS(\\mathcal{P},n,\\epsilon)\\leq N(\\mathcal{P},n,\\epsilon).\r\n\\end{equation}\r\n\r\nIn this setting, slow entropy of invertible measure-preserving transformations can be introduced as following:\r\n\\begin{definition}[Slow entropy, Katok-Thouvenot \\cite{KatokThou}]\\label{def:slowEntropy}\r\nLet $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ be a family of positive sequences increasing to infinity and monotone in $t$. Then define the lower measure-theoretic slow entropy of $T$ with respect to a finite measurable partition $\\mathcal{P}$ by\r\n\\begin{equation}\\label{eq:slowEntroDef}\r\n\\lent_{a_n(t)}^{\\mu}(T,\\mathcal{P})=\\lim_{\\epsilon\\to0} A(\\epsilon,\\mathcal{P}),\r\n\\end{equation}\r\nwhere\r\n$\r\nA(\\epsilon,\\mathcal{P})=\\left\\{\r\n\\begin{array}{ll}\r\n\\sup B(\\epsilon,\\mathcal{P}), & \\hbox{if $B(\\epsilon,\\mathcal{P})\\neq\\emptyset$;} \\\\\r\n0, & \\hbox{if $B(\\epsilon,\\mathcal{P})=\\emptyset$,}\r\n\\end{array}\r\n\\right.\r\n$\r\nfor\r\n\\begin{equation}\\label{eq:lowerSlowKey}\r\nB(\\epsilon,\\mathcal{P})=\\{t>0:\\liminf_{n\\to\\infty}\\frac{ S(\\mathcal{P},n,\\epsilon)}{a_n(t)}>0\\}.\r\n\\end{equation}\r\nThe lower measure-theoretic slow entropy of $T$ is defined by\r\n\\begin{equation}\r\n\\lent_{a_n(t)}^{\\mu}(T)=\\sup_{\\mathcal{P}}\\lent_{a_n(t)}^{\\mu}(T,\\mathcal{P}).\r\n\\end{equation}\r\nThe upper measure-theoretic slow entropy of $T$ can be defined in a similar way by replacing $\\liminf$ by $\\limsup$ in \\eqref{eq:lowerSlowKey} and denoted as $\\uent_{a_n(t)}^{\\mu}(T)$. If $\\lent_{a_n(t)}^{\\mu}(T)=\\uent_{a_n(t)}^{\\mu}(T)$, then we define this value as the measure-theoretic slow entropy of $T$ with respect to $a_n(t)$ and denote it as $\\ent_{a_n(t)}^{\\mu}(T)$.\r\n\\end{definition}\r\n\r\nOne of the most important features of measure-theoretic slow entropy is the following generating sequence property:\r\n\\begin{proposition}[Proposition 1 in \\cite{KatokThou}]\\label{prop:generatingSequence}\r\nLet $(X,\\mathcal{B},\\mu,T)$ be a measure-preserving transformation and  $\\mathcal{P}_1\\leq\\mathcal{P}_2\\leq\\ldots$ be an increasing sequence of finite measurable partitions of $X$ such that $\\vee_{m=1}^{+\\infty}\\mathcal{P}_m$ generates the $\\sigma-$algebra $\\mathcal{B}$. Then for any scales $a_n(t)$, we have\r\n$$\\lent_{a_n(t)}^{\\mu}(T)=\\lim_{m\\to+\\infty}\\lent_{a_n(t)}^{\\mu}(T,\\mathcal{P}_m),$$\r\n$$\\uent_{a_n(t)}^{\\mu}(T)=\\lim_{m\\to+\\infty}\\uent_{a_n(t)}^{\\mu}(T,\\mathcal{P}_m).$$\r\n\\end{proposition}\r\n\r\n\r\n\\subsection{Finite rank systems}\r\nAlthough there are many equivalent definitions of finite rank systems, we only provide the following geometrically definition of finite rank systems in our paper. For other equivalent definitions we refer to \\cite{Ferenczirank} for more details.\r\n\\begin{definition}[Finite rank system \\cite{Ferenczirank}]\\label{def:finiteRank}\r\nA system is of rank at most $\\ell$ if for every partition $\\mathcal{P}$ of $X$, for every $\\epsilon>0$, there exist $\\ell$ subsets $B_i$ of $X$, $\\ell$ positive integers $h_i$ and a partition $\\mathcal{P}'$ of $X$ such that\r\n\\begin{enumerate}[(a)]\r\n  \\item $T^jB_i$ are disjoint for $1\\leq i\\leq\\ell$ and $0\\leq j\\leq h_i-1$;\r\n  \\item $|\\mathcal{P}-\\mathcal{P}'|<\\epsilon$;\r\n  \\item $\\mathcal{P}'$ is refined by the partition $$\\{T^jB_i:1\\leq i\\leq\\ell, 0\\leq j\\leq h_i-1\\}\\cup\\{X\\setminus\\cup_{1\\leq i\\leq\\ell, 0\\leq j\\leq h_i-1}T^jB_i\\}.$$\r\n\\end{enumerate}\r\nA system is of rank $\\ell$ if it is of rank at most $\\ell$ and not of rank at most $\\ell-1$. A system is of infinite rank if no such finite $\\ell$ exists. Moreover, if $X\\setminus\\cup_{1\\leq i\\leq\\ell, 0\\leq j\\leq h_i-1}T^jB_i=\\emptyset$, then we call such systems as finite rank systems \\emph{without} spacers.\r\n\\end{definition}\r\n\r\n\\begin{remark}\\label{rem:towerLength}\r\nIt is worth to point out that for a rank $\\ell$-system $(X,T,\\mathcal{B},\\mu)$, each $h_i$ will go to $+\\infty$ as $\\mathcal{P}$ converges to an atom partition and $\\epsilon\\to0$. If there is at least one $h_i$ is bounded in this process, then the $\\mathcal{P}\\to\\text{atom partition}$ and $\\epsilon\\to0$ imply that $\\mu(B_i)\\to0$ and thus $\\mu(\\bigcup_{j=0}^{h_i}T^jB_i)\\to 0$, which gives that the rank of $T$ is less than or equal to $\\ell-1$ and thus a contradiction.\r\n\\end{remark}\r\n\\begin{remark}\\label{rem:fullmeasure}\r\nIf $\\mathcal{P}_n$ is a family of partitions that converges to atom partition as $n\\to+\\infty$ and $\\epsilon>0$, then by taking a subsequence if necessary, we can always assume that  $\\sum_{i=1}^nh_n^{(i)}\\mu(B_n^i)\\geq1-\\epsilon$ as the measure of each atom of $\\mathcal{P}_n$ goes to zero as $n\\to\\infty$, where $h_n^{(i)}$ and $B_n^i$ are the heights and bases in Definition \\ref{def:finiteRank} with respect to $\\mathcal{P}_n$ and $\\epsilon$.\r\n\\end{remark}\r\n\r\n\\subsection{Periodic approximation}\\label{sec:periodicApp}\r\nIn this section, we provide an elementary introduction about periodic approximation, which will be used in Section \\ref{sec:goodCyclic}. We refer to \\cite{K} for more details.\r\n\r\nSuppose $(X,\\mu)$ is a Lebesgue space. A tower $t$ is an ordered sequence of disjoint subsets: $t=\\{c_1,\\ldots,c_{h(t)}\\}$ of $X$ with $\\mu(c_i)=m(t)$ for $1\\leq i\\leq h(t)$, where $c_1$ is denoted as the base of the tower $t$ and  $h(t)$ is denoted as the height of the tower $t$. Moreover, we associated a cyclic measure-preserving permutation $\\sigma$ with tower $t$ such that $\\sigma(c_i)=c_{i+1}$ for $1\\leq i\\leq h(t)$, where $c_{h(t)+1}=c_1$. Then the periodic process can be defined as follows:\r\n\\begin{definition}[Periodic process]\r\nA periodic process is a collection of disjoint towers covering $X$, together with an equivalence relation among these towers which identifies their bases.\r\n\\end{definition}\r\n\r\nFor any given periodic process, we introduce the following two standard partitions associated with the periodic process. The first partition $\\xi$ consists of all elements of all towers of the periodic process and the second partition $\\eta$ consists of the unions of bases of towers in each equivalence class and their images under the iterates of $\\sigma$, where we will drop certain towers if we go beyond the heights of these towers and we continue until the highest tower in the equivalence class has been exhausted. It is clear that $\\eta$ is a subpartition of $\\xi$, i.e. $\\eta\\leq\\xi$. In fact, $(\\xi,\\eta,\\sigma)$ completely determines the periodic process except the situation that all towers within an equivalence class have the same height, which is the case we will not make the distinction. From now on, we identity the triple $(\\xi,\\eta,\\sigma)$ with the periodic process. With the help of these notations, we can introduce the periodic approximations:\r\n\\begin{definition}[Exhaustive periodic process]\r\nThe sequence $(\\xi_n,\\eta_n,\\sigma_n)$ of periodic processes is called exhaustive if $\\eta_n$ converges to atom partition as $n\\to\\infty$.\r\n\\end{definition}\r\n\\begin{definition}[Periodic approximation]\r\nFor a given measure-preserving transformation $T$ and an exhaustive sequence of periodic processes $(\\xi_n,\\eta_n,\\sigma_n)$, we say $(\\xi_n,\\eta_n,\\sigma_n)$ forms a periodic approximation of $T$ if\r\n$$\\sum_{c\\in\\xi_n}\\mu(Tc\\triangle\\sigma_nc)\\to 0\\text{ as }n\\to\\infty.$$\r\n\\end{definition}\r\n\r\nOne of the important features of periodic approximation is the speed of approximation:\r\n\\begin{definition}\r\nA measure-preserving transformation admits a periodic approximation $(\\xi_n,\\eta_n,\\sigma_n)$ with speed $g(n)$ if for a certain subsequence $\\{n_k\\}$ we have\r\n$$\\sum_{c\\in\\xi_{n_k}}\\mu(Tc\\triangle\\sigma_{n_k}c)<g(n_k).$$\r\n\\end{definition}\r\n\r\nNow we have enough ingredients to define a good cyclic approximation.\r\n\r\n\\begin{definition}[Cyclic approximation]\\label{def:cyclicApp}\r\nA periodic process which consists of a single tower is called a cyclic process. An approximation by an exhaustive sequence of cyclic processes is a cyclic approximation. In particular, a cyclic approximation is a good cyclic approximation if its speed is $o(\\frac{1}{q_n})$, where $q_n$ is the height of cyclic processes' single tower at step $n$.\r\n\\end{definition}\r\n\r\n\r\n\\subsection{A probabilistic method}\\label{sec:probabilisticLemma}\r\nOne of the key tools for all our combinatorial constructions throughout this paper is a probabilistic method similar to the so-called ``Substitution Lemma'' in \\cite{FRW}. More precisely, we present a method to select good choices of words so that the constructed sequences satisfy strong uniformity and that all pairs of building blocks occur with about the same frequency when comparing two sequences with each other, even after some sliding along the sequence. To state this precisely, we introduce some notation.\r\n\r\n\\begin{definition}\r\n\tLet $\\Sigma$ be an alphabet. For a word $w\\in\\Sigma^{k}$ and $x\\in\\Sigma$\r\n\twe write $r(x,w)$ for the number of times that $x$ occurs in $w$\r\n\tand $\\freq(x,w)=\\frac{r(x,w)}{k}$ for the frequency of occurrences\r\n\tof $x$ in $w$. Similarly, for $(w,w')\\in\\Sigma^{k}\\times\\Sigma^{k}$\r\n\tand $(x,y)\\in\\Sigma\\times\\Sigma$ we write $r(x,y,w,w')$ for the\r\n\tnumber of $i<k$ such that $x$ is the $i$-th member of $w$ and\r\n\t$y$ is the $i$-th member of $w'$. We also introduce $\\freq(x,y,w,w')=\\frac{r(x,y,w,w')}{k}$.\r\n\\end{definition}\r\nWe also state the Law of Large Numbers with its large deviations using Chernoff bounds:\r\n\\begin{lemma}[Law of Large Numbers]\r\n\tLet $\\left(X_{i}\\right)_{i\\in\\mathbb{N}}$ be a sequence of independent\r\n\tidentically distributed random variables taking value $1$ with probability\r\n\t$p$ and taking value $0$ with probability $1-p$. Then for any $\\delta>0$\r\n\twe have\r\n\t\\[\r\n\t\\mathbb{P}\\left(\\left|\\frac{1}{n}\\sum_{i=1}^{n}X_{i}-p\\right|\\geq\\delta\\right)<\\exp\\left(-\\frac{n\\delta^{2}}{4}\\right).\r\n\t\\]\r\n\t%and for the upper tail we have the following estimate\r\n\t%\\[\r\n\t%\\mathbb{P}\\left(\\sum_{i=1}^{n}X_{i}\\geq(1+\\delta)np\\right)\\leq\\exp\\left(-\\frac{\\delta^{2}}{2+\\delta}np\\right).\r\n\t%\\]\r\n\\end{lemma}\r\nInspired by the proof of the Substitution Lemma in \\cite{FRW} we apply the Law of Large Numbers to guarantee the existence of selections with the desired properties mentioned above.\r\n%In this section, we provide several modifications of probabilistic lemmas in \\cite{FRW} in order to complete the proof of main theorems.\r\n%With the help of these notations, our first probabilistic lemma can be stated as following:\r\n\\begin{lemma}\\label{lem:prob}\r\nLet $\\epsilon>0$ and $\\Sigma$ be a finite alphabet. For any sequence $\\{b_n\\}_{n\\in \\N}$ with $\\lim_{n\\to \\infty} \\frac{\\log b_n}{n} = 0$ there exists $K_0 \\in\\mathbb{N}$ such that for all $k\\geq K_0$, that are multiples of $|\\Sigma|$, and all $N\\leq b_k$ there is a collection of sequences $\\Theta\\subset\\Sigma^k$ with cardinality $|\\Theta|=N$ satisfying the following properties:\r\n\\begin{enumerate}[(1)]\r\n  \\item(Exact uniformity) For every $x\\in\\Sigma$ and every $w\\in\\Theta$, we have\r\n      $$\\operatorname{freq}(x,w)=\\frac{1}{|\\Sigma|};$$\r\n  \\item(Hamming separation) Let $0\\leq t<(1-\\epsilon)k$, $w,w'\\in\\Theta$ and $I\\subset[0,k-1]\\cap\\mathbb{Z}$ be the indices in the overlap of $w$ and $\\sh^t(w')$, where $\\sh^t(w')$ moves $w'$'s digits to the left by $t$ units. If $w,w'$ are different from each other, then we have\r\n      \\begin{equation}\r\n      d^H_{k-t}(w\\upharpoonright I,\\sh^t(w')\\upharpoonright I)\\geq 1-\\frac{1}{|\\Sigma|}-\\epsilon|\\Sigma|;\r\n      \\end{equation}\r\n      if $1\\leq t\\leq(1-\\epsilon)k$, then we have\r\n      \\begin{equation}\\label{eq:selfSliding}\r\n      d^H_{k-t}(w\\upharpoonright I,\\sh^t(w)\\upharpoonright I)\\geq 1-\\frac{1}{|\\Sigma|}-\\epsilon|\\Sigma|,\r\n      \\end{equation}\r\n  where $w\\upharpoonright I$ denotes the restriction of $w$ on the index set $I$, i.e. if $I=\\{i_1,i_2,\\ldots\\}$, then $(w\\upharpoonright I)_p=w_{i_p}$.\r\n\\end{enumerate}\r\n\r\n\\end{lemma}\r\n\r\n\r\n\\begin{proof}\r\n\r\nWe will use the Law of Large Numbers to show that for sufficiently large $k\\in \\N$ most choices in $\\Sigma^{k}$\tsatisfy the aimed properties.\r\n\t\r\nLet $\\delta<\\frac{\\epsilon}{5}$. We consider $\\varOmega_{k}\\coloneqq\\left(\\Sigma^{k} \\right)^{N}=\\Sigma^{k}\\times\\dots\\times\\Sigma^{k}$ equipped with the counting measure as our probability space. For each $x\\in\\Sigma$ and every $i\\in\\left\\{ 0,1,\\dots,k-1\\right\\} $ let $X_{i}$ be the random variable that takes the value $1$ if $x$ occurs in the $i$-th place of an element $w\\in\\Sigma^{k}$ and $0$ otherwise. Then the $X_{i}$ are independent and identically distributed. Hence, the Law of Large Numbers gives $k_{x}=k_{x}(\\delta)$ such that for all $k\\geq k_{x}$ a proportion $\\left(1-(\\exp(-\\delta^2/4))^k\\right)$ of sequences in $\\Sigma^{k}$ satisfy\r\n\\begin{equation}\\label{eq:prop13}\r\n\\abs{\\frac{1}{k}\\sum_{i=0}^{k-1}X_{i}-\\frac{1}{|\\Sigma|}}<\\delta.\r\n\\end{equation}\r\nMoreover, we define for each $0\\leq t <(1-\\e)k$ and pair $(x,y)\\in\\Sigma\\times\\Sigma$ the random variable $Y^t_{i}$ that takes the value $1$ if $x$ occurs in the $i$-th place of $w$ for an element $w\\in\\Sigma^{k}$ and $y$ is the $i$-th entry of $\\sh^t(w')$ for some $w'\\in\\Sigma^{k}$, $w'\\neq w$. Otherwise, $Y^t_{i}$ takes the value $0$. Since the $Y^t_{i}$ are independent and identically distributed, the Law of Large Numbers gives $k_{x,y}=k_{x,y}(\\delta)$ such that for all $k\\geq k_{x,y}$, all $0\\leq t <(1-\\e)k$ and all but a $(\\exp(-\\delta^2/4))^k$ proportion of sequences $(w,w')\\in\\Sigma^{k}\\times\\Sigma^{k}$ satisfy\r\n\\begin{equation}\\label{eq:prop23}\r\n\\abs{\\frac{1}{k-t}\\sum_{i=0}^{k-t-1}Y^t_{i}-\\frac{1}{|\\Sigma|^{2}}}<\\delta.\r\n\\end{equation}\r\nFinally, we introduce for each $1\\leq t <(1-\\e)k$ the random variable $Z^t_i$ that takes the value $1$ if the $i$-th symbol of $w$ agrees with the $i$-th symbol of $\\sh^t(w)$ for some $w\\in \\Sigma^k$. Otherwise, $Z^t_i$ takes the value $0$. Since the $Z^t_{i}$ are independent and identically distributed, the Law of Large Numbers gives $k(\\delta)$ such that for all $k\\geq k(\\delta)$ and all $1\\leq t <(1-\\e)k$  a $\\left(1-(\\exp(-\\delta^2/4))^k\\right)$ proportion of sequences $w\\in\\Sigma^{k}$ satisfy\r\n\\begin{equation}\\label{eq:prop33}\r\n\\abs{\\frac{1}{k-t}\\sum_{i=0}^{k-t-1}Z^t_{i}-\\frac{1}{|\\Sigma|}}<\\delta.\r\n\\end{equation}\r\n\t\r\nWe point out that the number of requirements is less than $N |\\Sigma|+2kN^2|\\Sigma|^{2} \\leq 3kN^2|\\Sigma|^{2}$. Since\r\n\\[\r\n3kN^2|\\Sigma|^{2} \\cdot (\\exp(-\\delta^2/4))^k \\leq 3kb_k^2|\\Sigma|^{2} \\cdot (\\exp(-\\delta^2/4))^k \\to 0 \\text{ as } k\\to \\infty,\r\n\\]\r\nwe conclude by Bernoulli inequality that for sufficiently large $k$ the vast majority of elements in $\\varOmega_{k}$ satisfies all the conditions \\eqref{eq:prop13}, \\eqref{eq:prop23}, and \\eqref{eq:prop33}. We pick $k$ large enough such that there is such a collection of sequences $\\Theta'\\subset\\Sigma^{k}$ with cardinality $|\\Theta'|=N$. Then by equation \\eqref{eq:prop13} in any $w_{in}\\in\\Theta^{\\prime}$, we can remove symbols at at most $2\\delta k$ places to obtain a word $w_{red}$ in which each element of $\\Sigma$ occurs the same number of times. Afterwards, each element of $\\Sigma$ can be filled into the empty slots exactly the same number of times. Clearly, the constructed word $w$ satisfies uniformity. The sequences built this way constitute our collection $\\Theta\\subset\\Sigma^{k}$.\r\n\r\nTo check the second property we denote for $w,w^{\\prime}\\in\\Theta$ their original strings in $\\Theta^{\\prime}$ by $w_{in}$ and $w_{in}^{\\prime}$, respectively. From equation \\eqref{eq:prop23} we obtain for every $x,y\\in\\Sigma$ that\r\n\t\\[\r\n\t\\abs{\\frac{r(x,y,w_{in}\\upharpoonright I,\\sh^t(w'_{in})\\upharpoonright I)}{k}-\\frac{1}{|\\Sigma|^{2}}}<\\delta.\r\n\t\\]\r\nSince $w_{in}$ and $\\sh^t(w'_{in})$ were changed at most $2\\delta k$ places, at most $4\\delta k$ positions in the alignment of $w$ and $\\sh^t(w')$ can be affected. Hereby, we conclude that\r\n\\begin{equation}\r\n\\begin{aligned}\r\n\t& \\abs{\\freq\\left(x,y,w\\upharpoonright I,\\sh^t(w')\\upharpoonright I\\right)-\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\t\\leq & \\abs{ \\frac{r(x,y,w\\upharpoonright I,\\sh^t(w')\\upharpoonright I)-r(x,y,w_{in}\\upharpoonright I,\\sh^t(w'_{in})\\upharpoonright I)}{k}} \\\\&+ \\abs{\\frac{r(x,y,w_{in}\\upharpoonright I,\\sh^t(w'_{in})\\upharpoonright I)}{ k} -\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\t\\leq & \\frac{4\\delta  k}{ k}+\\delta\t< \\epsilon.\r\n\\end{aligned}\r\n\\end{equation}\r\n\r\nIn particular, this implies\r\n\\[\r\nd^H_{k-t-1}\\left(w\\upharpoonright I,\\sh^t(w')\\upharpoonright I\\right)\\geq 1-\\frac{1}{|\\Sigma|}-\\e |\\Sigma|,\r\n\\]\r\nwhich yields the first part of property (2). Similarly, we check its second part with the aid of (\\ref{eq:prop33}).\r\n\r\n\\end{proof}\r\n\r\nThis lemma suffices to prove Theorems \\ref{thm:slowentropyFiniterank}, \\ref{theo:rigidUpper}, and \\ref{theo:cyclicUpper}. For the proof of Theorems \\ref{theo:rigidLower} and \\ref{theo:cyclicLower} on the lower slow entropy, we need an extension to deal with the small number of iterates at each stage of the construction. For a start, we make the following immediate observation from Lemma \\ref{lem:prob} to fix some notation.\r\n\r\n\\begin{remark} \\label{rem:kForCLT}\r\n\tLet $s\\in \\Z^+$ and $\\{b_n\\}_{n\\in \\N}$ be a subexponential sequence with $b_n \\to \\infty$. Then there is $K_1=K_1(\\{b_n\\}_{n\\in \\N},s,\\varepsilon)$ such that for all $k\\geq K_1$ and any finite alphabet $\\Sigma$ of cardinality $|\\Sigma|=s$ there is a collection $\\Theta \\subset \\Sigma^{k}$ of cardinality $|\\Theta|=\\lfloor b_k\\rfloor $ such that the words in $\\Theta$ satisfy property (2) from Lemma \\ref{lem:prob}.\r\n\\end{remark}\r\n\r\n\\begin{lemma}\\label{lem:prob2}\r\n\tLet $s\\in \\Z^+$, $\\varepsilon>0$, $\\Sigma$ be a finite alphabet of cardinality $|\\Sigma|\\geq s$, and $\\{b_n\\}_{n\\in \\N}$, $\\{c_n\\}_{n\\in \\N}$ be two subexponential sequences growing to infinity with $nb_n \\leq c_n$. Moreover, let  $k\\geq K_1(\\{b_n\\}_{n\\in \\N},s,\\varepsilon)$.\r\n\t\r\n\tThen there exists a $L_{0}\\in\\mathbb{N}$ such that for all $\\ell\\geq L_{0}$, that are multiples of $|\\Sigma|$, there is $0<\\gamma<\\varepsilon$ and a collection of sequences $\\Theta\\subset\\Sigma^{\\ell}$ with cardinality $|\\Theta|=\\lfloor c_\\ell \\rfloor $ satisfying the following properties:\r\n\t\\begin{itemize}\r\n\t\t\\item[(1)] For every $x\\in\\Sigma$ and every $w\\in\\Theta$ we have $\\freq(x,w)=\\frac{1}{|\\Sigma|}$.\r\n\t\t\\item[(2)] For every $\\gamma \\ell \\leq L \\leq \\ell$ and every pair of different $w,w'\\in\\Theta$ there are substrings $W$ and $W'$ of $w$ and $w'$, respectively, with length $L$ such that\r\n\t\t\\[\r\n\t\td^H_L(W,W')\\geq 1-\\frac{1}{|\\Sigma|}-\\varepsilon |\\Sigma|.\r\n\t\t\\]\r\n\t\t\\item[(3)] For every $k\\leq j <\\gamma \\ell$ there is a subcollection $\\Theta_j \\subseteq \\Theta$ with $|\\Theta_j|=\\lfloor b_j \\rfloor$ such that for every pair of different $w,w'\\in\\Theta_j$ there are substrings $W$ and $W'$ of $w$ and $w'$, respectively, with length $j$ such that we have\r\n\t\t\\[\r\n\t\td^H_j(W,W')\\geq 1-\\frac{1}{s}-\\varepsilon s.\r\n\t\t\\]\r\n\t\t\\item[(4)] For every $1\\leq j <k$ there is a subcollection $\\overline{\\Theta}_j \\subseteq \\Theta$ with $|\\overline{\\Theta}_j|=|\\Sigma|$ such that for every pair of different $w,w'\\in\\overline{\\Theta}_j$ there are substrings $W$ and $W'$ of $w$ and $w'$, respectively, with length $j$ such that we have $d^H_j(W,W')=1$.\r\n\t\\end{itemize}\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tLet $0<\\gamma'<\\frac{\\varepsilon}{40}$. The proof of this lemma bases upon two mechanisms. On the one hand, we use the method from Lemma \\ref{lem:prob} to build a collection of words that are Hamming apart from each other on substantial substrings of length at least $\\gamma'\\ell$. On the other hand, we exploit $k\\geq K_1(\\{b_n\\}_{n\\in \\N},s,\\varepsilon)$ to construct the required number of short words that are apart from each other. Then we use these short words as end strings. Since they represent a small proportion of the total word length, we can still fulfill properties (1) and (2).\r\n\t\r\n\tAs in the proof of Lemma \\ref{lem:prob} we consider the probability space $\\varOmega_{l}\\coloneqq\\left(\\Sigma^{l} \\right)^{N}$ equipped with the counting measure, where we set $N=\\lfloor c_{2l} \\rfloor$. Once again, for each $x\\in\\Sigma$\r\n\tand every $i\\in\\left\\{ 0,1,\\dots,l-1\\right\\} $ let $X_{i}$ be the\r\n\trandom variable that takes the value $1$ if $x$ occurs in the $i$-th\r\n\tplace of an element $w\\in\\Sigma^{l}$ and $0$ otherwise. Since the\r\n\t$X_{i}$ are independent and identically distributed, the Law\r\n\tof Large Numbers gives $0<\\beta < 1$ and $l_{x}=l_{x}(\\gamma')$ such\r\n\tthat for all $l\\geq l_{x}$ a proportion $\\left(1-\\beta^l\\right)$ of\r\n\tsequences in $\\Sigma^{l}$ satisfy\r\n\t\\begin{equation}\r\n\t\\abs{\\frac{2}{l}\\sum_{i=0}^{\\lfloor 0.5l-1 \\rfloor}X_{i}-\\frac{1}{|\\Sigma|}}<\\gamma'\\ \\ \\text{ and } \\ \\ \\abs{\\frac{2}{l}\\sum_{i=\\lceil 0.5l \\rceil }^{l-1}X_{i}-\\frac{1}{|\\Sigma|}}<\\gamma'.\\label{eq:prop21}\r\n\t\\end{equation}\r\n\tMoreover, we use for each pair $(x,y)\\in\\Sigma\\times\\Sigma$ the\r\n\trandom variable $Y_{i}$ that takes the value $1$, if $x$ occurs\r\n\tin the $i$-th place of $w$ for an element $w\\in\\Sigma^{l}$ and $y$ is the\r\n\t$i$-th member of $w'\\in\\Sigma^{l}$, and $0$ otherwise. As before,\r\n\tthe Law of Large Numbers gives $0<\\beta < 1$ and $l_{x,y}=l_{x,y}(\\gamma')$\r\n\tsuch that for all $l'\\geq \\gamma' l_{x,y}$ a proportion $\\left(1-\\beta^{l'}\\right)$ of sequences $(w,w')\\in\\Sigma^{l}\\times\\Sigma^{l}$ satisfy\r\n\t\\begin{equation}\r\n\t\\abs{\\frac{1}{l'}\\sum_{i=0}^{l'-1}Y_{i}-\\frac{1}{|\\Sigma|^{2}}}<\\gamma'.\\label{eq:prop22}\r\n\t\\end{equation}\r\n\tWe require this to hold for all $\\gamma'l \\leq l'\\leq l$. We note that the total number of requirements is less than $2N|\\Sigma|+N^{2}|\\Sigma|^{2}l\\leq 2 c^2_{2l}|\\Sigma|^{2}$ which grows subexponentially.\r\n\tHence, for sufficiently large $l$ the vast majority of elements in\r\n\t$\\varOmega_{l}$ satisfies all the conditions (\\ref{eq:prop21}) and\r\n\t(\\ref{eq:prop22}). We pick $L^{\\prime}_0$ large enough such that for every $l\\geq L^{\\prime}_0$ there is such a collection of sequences $\\Theta^{\\prime}_{in}\\subset\\Sigma^{l}$\r\n\twith cardinality $|\\Theta^{\\prime}_{in}|=\\lfloor  c_{2l}\\rfloor $. Then for any $l\\geq L^{\\prime}_0$ we choose $\\gamma$ satisfying $\\gamma'\\leq \\gamma <\\frac{\\varepsilon}{20}$ such that $(1+\\frac{\\gamma}{1-\\gamma})l=\\frac{1}{1-\\gamma}l$ is a multiple of $|\\Sigma|$. Regarding the statement of the Lemma we set $L_0=2L^{\\prime}_0$ and $\\frac{1}{1-\\gamma}l$ corresponds to $\\ell$. We also delete sufficiently many words from the collection $\\Theta^{\\prime}_{in}\\subset\\Sigma^{l}$, which had cardinality $\\lfloor c_{2l} \\rfloor $, to get a collection $\\Theta_{in}\\subset\\Sigma^{l}$ of cardinality $\\lfloor  c_{\\frac{1}{1-\\gamma}l}\\rfloor =\\lfloor c_{\\ell} \\rfloor$.\r\n\t\r\n\tIn a separate step, we choose an arbitrary subalphabet $\\Sigma'$ of $\\Sigma$ with cardinality $|\\Sigma'|=s$. Since $k\\geq K_1(\\{b_n\\},s,\\varepsilon)$ we can find for each $k\\leq j\\leq \\gamma \\ell=\\frac{\\gamma}{1-\\gamma}l$ a collection of words $\\Theta^{\\prime}_j \\subset (\\Sigma')^j$ with $|\\Theta^{\\prime}_j|=\\lfloor b_j \\rfloor $ such that for every pair of different $w,w'\\in \\Theta^{\\prime}_j$ we have for every $x,y\\in \\Sigma'$ that\t\r\n\t\\[\r\n\t\\abs{\\frac{r(x,y,w,w')}{j}-\\frac{1}{|\\Sigma'|^{2}}}<\\varepsilon,\r\n\t\\]\r\n\twhich implies\r\n\t\\[\r\n\td^H_j(W,W')\\geq 1-\\frac{1}{s}-\\varepsilon s.\r\n\t\\]\r\n\tBy adding symbols from $\\Sigma$ in an arbitrary manner we extend words from $\\Theta^{\\prime}_j$ to words of length $\\gamma \\ell$. The resulting collection is called $\\Theta_j$. Furthermore, for every $x\\in \\Sigma$ we build a word $w_x$ of length $\\gamma \\ell$ by repeating $k$ many times the symbol $x$ and then adding symbols from $\\Sigma$ in an arbitrary manner. Then we set $\\Theta_{k-1}=\\{w_x:x\\in \\Sigma\\}$. Clearly, this collection will give us property (4). We note that\r\n\t\\[\r\n\t\\sum^{\\gamma \\ell}_{j=k-1} |\\Theta_j| \\leq  |\\Sigma|+\\sum^{\\gamma \\ell}_{j=k} \\lfloor b_j \\rfloor   < \\ell \\lfloor b_{\\ell} \\rfloor \\leq \\lfloor c_{\\ell} \\rfloor  =|\\Theta_{in}|.\r\n\t\\]\r\n\tHence, we can attach to each word in $\\Theta_{in}$ a different word from exactly one of $\\Theta_j$. To the remaining words in $\\Theta_{in}$ we attach arbitrary words in the alphabet $\\Sigma$ of length $\\gamma \\ell$. This yields a collection of words $\\Theta^{\\prime} \\subseteq \\Sigma^{\\ell}$.\r\n\t\r\n    By construction, $\\Theta^{\\prime}$ fulfills properties (3) and (4). We modify its words slightly on their initial segments from $\\Theta_{in}$ so that the words also satisfy (1) and (2).\r\n\r\n\tUsing equation (\\ref{eq:prop21}) and that the endstrings $w_{end}$ have length $\\gamma \\ell\\leq 2\\gamma l$, in any $w=w_{in}w_{end}\\in\\Theta^{\\prime}$\r\n\twe can remove symbols at most $6\\gamma l$ places in the second half $w_{in,2}$ of $w_{in}=w_{in,1}w_{in,2}$ to obtain a word $w_{red}$ in which each element of $\\Sigma$ occurs the same number of times. Afterwards, each element of $\\Sigma$ can be filled into the empty slots exactly the same number of times.\r\n\tClearly, the constructed word $w$ satisfies uniformity in $\\Sigma$. The sequences built this way constitute our collection $\\Theta\\subset\\Sigma^{\\ell}$.\r\n\t\r\n\tTo verify (2) we recall that $\\gamma \\ell = \\frac{\\gamma}{1-\\gamma}l > \\gamma' l$. Hence, for $\\gamma \\ell \\leq L \\leq \\lfloor 0.5l \\rfloor$ there are substrings satisfying property (2) by equation (\\ref{eq:prop22}) which is not affected by the modifications on the second half of the words $w_{in}$. For lengths $\\lfloor 0.5l \\rfloor +1 \\leq L <l$ we take the initial strings $\\overline{w}, \\overline{w}^{\\prime}$ of length $L$ in $w$ and $w^{\\prime}$, respectively, as well as their original versions $\\overline{w}_{in}, \\overline{w}^{\\prime}_{in}$ in $w_{in}$ and $w^{\\prime}_{in}$. Then for any $x,y \\in \\Sigma$ we estimate that\r\n\t\\begin{align*}\r\n& \\abs{\\freq(x,y,\\overline{w},\\overline{w}^{\\prime})-\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\\leq & \\abs{ \\frac{r(x,y,\\overline{w},\\overline{w}^{\\prime})-r(x,y,\\overline{w}_{in},\\overline{w}^{\\prime}_{in})}{L}} + \\abs{\\frac{r(x,y,\\overline{w}_{in},\\overline{w}^{\\prime}_{in})}{ L} -\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\\leq & \\frac{6 \\gamma l}{ 0.5 l}+\\gamma'\\\\\r\n< & \\varepsilon.\r\n\\end{align*}\r\n\r\nSimilarly, for lengths $l \\leq L \\leq \\ell$ we approximate the initial strings $\\overline{w}, \\overline{w}^{\\prime}$ of length $L$ in $w$ and $w^{\\prime}$ by the original words $w_{in}$ and $w^{\\prime}_{in}$ of length $l$. Then we get\r\n\\begin{align*}\r\n& \\abs{\\freq(x,y,\\overline{w},\\overline{w}^{\\prime})-\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\\leq & \\abs{ \\frac{r(x,y,\\overline{w},\\overline{w}^{\\prime})-r(x,y,w_{in},w^{\\prime}_{in})}{l}} + \\abs{\\frac{r(x,y,w_{in},w^{\\prime}_{in})}{ l} -\\frac{1}{|\\Sigma|^{2}}}\\\\\r\n\\leq & \\frac{8 \\gamma l}{l}+\\gamma'\\\\\r\n< & \\varepsilon.\r\n\\end{align*}\r\n\t\r\nThis concludes the proof.\t\r\n\\end{proof}\r\n\r\n\r\n\r\n\\section{Slow entropy of finite rank systems}\\label{sec:finiterank}\r\nIn this section, we discuss the slow entropy of finite rank systems. We first provide an upper bound of some special rank two systems' lower slow entropy. Then for any given subexponential scale, we construct a rank two system such that its lower slow entropy is infinity with respect to the given scale.\r\n\\subsection{Slow entropy of rank two system without spacers}\r\n\r\n\\begin{proposition}\\label{prop:Nospacers}\r\nIf $(X,T,\\mathcal{B},\\mu)$ is a rank $2$ system without spacers, then we have the following estimate of its slow entropy with respect to scale $a_n(t)=n^t$:\r\n$$\\lent_{n^t}^{\\mu}(T)\\leq1.$$\r\n\\end{proposition}\r\n\\begin{proof}\r\n\r\nLet $h_1^n$, $h_2^n$, $F_1^n$, $F_2^n$ and $\\mathcal{P}_n=\\{T^jF_i^n:1\\leq i\\leq2, 0\\leq j\\leq h_i^n-1\\}$ be defined as in Definition \\ref{def:finiteRank} for a fixed partition $\\mathcal{P}$ and $\\epsilon>0$. We have the following two situations (by passing to subsequences if necessary):\r\n\\begin{enumerate}[(i)]\r\n  \\item\\label{case1} $\\lim_{n\\to\\infty}\\frac{h_2^n}{h_1^n}=+\\infty\\text{ or }0$;\r\n  \\item\\label{case2} $0<\\lim_{n\\to\\infty}\\frac{h_2^n}{h_1^n}<+\\infty$.\r\n\\end{enumerate}\r\n\\paragraph{Case \\ref{case1}:}\r\nWe start with the situation that $\\lim_{n\\to\\infty}\\frac{h_2^n}{h_1^n}=+\\infty$ and the other situation follows by switching the two towers. We assume that $\\frac{h_1^n}{h_2^n}<\\epsilon^3$ by enlarging $n$ if necessary. Denote $\\mathcal{T}_1^n=\\cup_{i=0}^{h_1^n-1}T^iF_1^n$ and $\\mathcal{T}_2^n=\\cup_{i=0}^{h_2^n-1}T^iF_2^n$. We will do some small ``surgeries'' to the system, which will help us to estimate the number of Hamming balls with length $\\epsilon^2h_2^n$ with respect to $\\mathcal{P}_n$.\r\n\r\nDenote $A=\\mathcal{T}_1^n\\cap T^{-1}(\\mathcal{T}_2^n)$, i.e. the points belonging to the shorter tower which will enter the tall tower at the next iteration. Then let $B=\\cup_{i=1}^{2\\epsilon^2h_2^n-1}T^{-i}A$. We obtain from the definition of $A$ that $\\mu(A)\\leq\\mu(F_2^n)\\leq\\frac{1}{h_2^n}$ and thus we know that $\\mu(B)<2\\epsilon^2$. Recall that there exists $m\\in\\mathbb{Z}$ such that $mh_1^n\\leq2\\epsilon^2h_2^n<(m+1)h_1^n$. Moreover, we also have $mh_1^n>\\epsilon^2h_2^n$ since $h_1^n<\\epsilon^3h_2^n$. Thus for $x,y\\in\\mathcal{T}_1^n\\setminus B$, if they are in the same level set, they will stay in the same atom with respect to partition $\\mathcal{P}_n$. Let $C$ be the top level of $\\mathcal{T}_2^n$ and $D=\\cup_{i=1}^{2\\epsilon^2h_2^n-1}T^{-i}C$. For any $x,y\\in\\mathcal{T}_2^n\\setminus (B\\cup D)$ we have, that if they are in the same level set, then they stay in the atom with respect to partition $\\mathcal{P}_n$ up to $\\epsilon^2h_2^n$. Since the total measure of these points is larger than $\\mu(\\mathcal{T}_1^n\\setminus B)+\\mu(\\mathcal{T}_2^n\\setminus(B\\cup D))$, i.e. $1-4\\epsilon^2$, we obtain that we need at most $h_1^n+h_2^n$ different $\\epsilon^2-$Hamming balls with length $\\epsilon^2h_2^n$ to cover an $1-4\\epsilon^2$ portion of the space with respect to partition $\\mathcal{P}_n$. Since $|\\mathcal{P}_n-\\mathcal{P}|<\\epsilon$, we complete the proof in this case.\r\n%Moreover, denote $\\mathcal{P}_n=\\{T^jF_i^n:1\\leq i\\leq2, 0\\leq j\\leq h_i^n-1\\}$, then we have\r\n%$$\\mu(\\mathcal{P}_n\\vartriangle\\mathcal{\\widetilde{P}}_n)<3\\epsilon^2,$$\r\n%which implies that we need at most $h_1^n+h_2^n$ different $7\\epsilon^2-$Hamming balls with length $\\epsilon^2h_2^n$ to cover the $1-3\\epsilon^2$ portion of the space with respect to $\\mathcal{P}_n$. As a result, we obtain linear bounds in this case for subsequence $n=\\epsilon^2h_2^n$.\r\n\\paragraph{Case \\ref{case2}:}\r\nIn this situation, by passing to a subsequence, we can assume that $h_1^n$ and $h_2^n$'s ratio is approximating to a constant. Then either by considering $\\epsilon$-Hamming balls with length $\\epsilon^2h_1^n$ or $\\epsilon^2h_2^n$ with respect to $\\mathcal{P}_n$, we need at most $h_1^n+h_2^n$ different such Hamming balls with length $\\epsilon^2h_1^n$ or $\\epsilon^2h_2^n$ to cover an $1-2\\epsilon^2$ portion of the space, which is a similar argument as we deal with the high tower in case \\ref{case1}. As a result, we obtain linear bounds in this case for subsequence $n=\\epsilon^2h_2^n$ or $\\epsilon^2h_1^n$. Since $|\\mathcal{P}_n-\\mathcal{P}|<\\epsilon$, we also complete the proof in this case.\r\n\\end{proof}\r\n\r\n\\subsection{Construction of rank two system with arbitrary large lower slow entropy}\\label{sec:CrazyRankTwo}\r\nThe construction of our target finite rank system is a rank two system with spacers. More precisely, we proceed the construction by cutting and stacking method with two towers and spacers, where the ratio of heights of the two towers is increasing to infinity. The finite rank system $T$ will act on $(X,\\mathcal{B},\\mu_X)$, where $X$ is a non-empty interval of $[0,+\\infty)$ of finite length, $\\mathcal{B}$ is Borel $\\sigma$-algebra and $\\mu$ is Lebesgue measure. Recall that $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ is a family of positive sequences increasing to infinity and monotone in $t$ that has subexponential growth, i.e. satisfying the following conditions:\r\n\\begin{equation}\\label{eq:scalingFunction}\r\n\\begin{aligned}\r\n&\\lim_{n\\to+\\infty}a_n(t)=+\\infty, \\forall t>0,\\\\\r\n&a_n(t)\\leq a_{n+1}(t),\\forall t>0,\\\\\r\n&a_n(t_1)=o(a_n(t_2)), \\forall t_2> t_1>0,\\\\\r\n&\\lim_{n\\to+\\infty}\\frac{\\log a_n(t)}{n}=0, \\forall t>0.\r\n\\end{aligned}\r\n\\end{equation}\r\nFrom now on, we fix a positive increasing sequence $\\{t_n\\}_{n \\in \\N}$ such that $\\lim_{n\\to+\\infty}t_n=+\\infty$, which will be used in our construction of a rank two system with infinite lower slow entropy.\r\n\r\nWe start our construction from two stacks $S_0^1$, $S_0^2$ and a ``chaos'' region $\\Omega$, where $S_0^1=[0,\\frac{1}{3})$, $S_0^2=[\\frac{1}{3},\\frac{2}{3})$, $\\Omega$ is a nonempty bounded interval of $[\\frac{2}{3},+\\infty)$, $H_0=K_0=1$ and $L_{-1}=0$. We denote our towers in the inductive process at step $n$ as $S_n^1$ and $S_n^2$ with heights $h_n^{(1)}$, $h_n^{(2)}$ and bases $B_n^1$, $B_n^2$, respectively, as in the following picture:\r\n\\begin{figure}[H]\r\n \\centering\r\n \\scalebox{0.6}\r\n {\r\n \\begin{tikzpicture}[scale=5]\r\n\t \\tikzstyle{vertex}=[circle,minimum size=0pt,inner sep=0pt]\r\n\t \\tikzstyle{selected vertex} = [vertex, fill=red!24]\r\n\t \\tikzstyle{edge1} = [draw,line width=5pt,-,red!50]\r\n     \\tikzstyle{edge2} = [draw,line width=5pt,-,green!50]\r\n     \\tikzstyle{edge3} = [draw,line width=5pt,-,blue!50]\r\n     \\tikzstyle{edge4} = [draw,line width=5pt,-,brown!50]\r\n\r\n\t \\tikzstyle{edge} = [draw,thick,-,black]\r\n\t %\\node[vertex] (v00) at (0,0) {$0000$};\r\n     \\node[vertex] (t000) at (0.0,0) {};\r\n\t \\node[vertex] (t001) at (2,0) {};\r\n     \\node[vertex] (t010) at (0.0,0.1) {};\r\n  \t \\node[vertex] (t011) at (2,0.1) {};\r\n     \\node[vertex] (t020) at (0.0,0.2) {};\r\n \t \\node[vertex] (t021) at (2,0.2) {};\r\n     \\node[vertex] (t030) at (0.0,0.3) {};\r\n\t \\node[vertex] (t031) at (2,0.3) {};\r\n     \\node[vertex] (w00) at (1,-0.1) {$B_n^1$};\r\n     \\node[vertex] (w01) at (-0.1,0.15) {$h_n^{(1)}$};\r\n\r\n\t \\node[vertex] (t100) at (2.2,0) {};\r\n\t \\node[vertex] (t101) at (2.5,0) {};\r\n\t \\node[vertex] (t110) at (2.2,0.1) {};\r\n\t \\node[vertex] (t111) at (2.5,0.1) {};\r\n\t \\node[vertex] (t120) at (2.2,0.2) {};\r\n\t \\node[vertex] (t121) at (2.5,0.2) {};\r\n\t \\node[vertex] (t130) at (2.2,0.3) {};\r\n\t \\node[vertex] (t131) at (2.5,0.3) {};\r\n\t \\node[vertex] (t140) at (2.2,0.4) {};\r\n\t \\node[vertex] (t141) at (2.5,0.4) {};\r\n\t \\node[vertex] (t150) at (2.2,0.5) {};\r\n\t \\node[vertex] (t151) at (2.5,0.5) {};\r\n\t \\node[vertex] (t160) at (2.2,0.6) {};\r\n\t \\node[vertex] (t161) at (2.5,0.6) {};\r\n\t \\node[vertex] (t170) at (2.2,0.7) {};\r\n\t \\node[vertex] (t171) at (2.5,0.7) {};\r\n\t \\node[vertex] (t180) at (2.2,0.8) {};\r\n\t \\node[vertex] (t181) at (2.5,0.8) {};\r\n\t \\node[vertex] (t190) at (2.2,0.9) {};\r\n\t \\node[vertex] (t191) at (2.5,0.9) {};\r\n\t \\node[vertex] (t1100) at (2.2,1) {};\r\n\t \\node[vertex] (t1101) at (2.5,1) {};\r\n\t \\node[vertex] (t1110) at (2.2,1.1) {};\r\n\t \\node[vertex] (t1111) at (2.5,1.1) {};\r\n\t \\node[vertex] (b10) at (2.4,-0.1) {$B_n^2$};\r\n     \\node[vertex] (b11) at (2.6,0.35) {$h_n^{(2)}$};\r\n\t\r\n\t \\draw[edge1] (t000)--(t001);\r\n\t \\draw[edge1] (t010)--(t011);\r\n\t \\draw[thick,dash dot] (t020)--(t021);\r\n\t \\draw[edge1] (t030)--(t031);\r\n\r\n\r\n     \\draw[edge2] (t100)--(t101);\r\n     \\draw[edge2] (t110)--(t111);\r\n     \\draw[thick,dash dot] (t120)--(t121);\r\n     \\draw[edge2] (t130)--(t131);\r\n     \\draw[thick,dash dot] (t140)--(t141);\r\n     \\draw[thick,dash dot] (t150)--(t151);\r\n     \\draw[thick,dash dot] (t160)--(t161);\r\n     \\draw[thick,dash dot] (t170)--(t171);\r\n     \\draw[thick,dash dot] (t180)--(t181);\r\n     \\draw[thick,dash dot] (t190)--(t191);\r\n     \\draw[thick,dash dot] (t1100)--(t1101);\r\n     \\draw[edge2] (t1110)--(t1111);\r\n\r\n\r\n\r\n \\end{tikzpicture}.\r\n }\r\n \\end{figure}\r\n\r\nUnder this setting, the inductive construction is defined as follows:\r\n\\begin{enumerate}[(i)]\r\n\\item Suppose we have already constructed towers $S_n^1$, $S_n^2$ and positive integers $H_n$, $K_n$, $L_{n-1}$ are given such that the following conditions are satisfied:\r\n      \\begin{equation}\\label{eq:initialEquation}\r\n      \\begin{aligned}\r\n       &H_n=\\prod_{i=0}^{n^2-1}(h_n^{(1)}+i),\\\\\r\n       &h_n^{(1)}>10000n^8,\\\\\r\n       &h_n^{(2)}>a_{K_nH_n}(t_n)\\cdot L_{n-1}>10000(n+1)^8,\\\\\r\n       &\\frac{h_n^{(1)}}{h_n^{(2)}}<\\frac{1}{10^9},\\\\\r\n       &\\frac{1}{3}\\mu(S_n^2)<\\mu(S_n^1)<\\frac{31}{10}\\mu(S_n^2),\r\n       \\end{aligned}\r\n      \\end{equation}\r\n      where $K_n$ is sufficiently large such that Lemma \\ref{lem:prob} with $\\epsilon=\\frac{1}{n^4}$ and alphabet $\\Sigma=\\{0,1,\\dots , n^2-1\\}$ gives for every $k\\geq K_n$ at least $a_{(k+1)H_n}(t_n)$ many different words in $\\Sigma^k$ satisfying property (2) of Lemma \\ref{lem:prob};\r\n\\item\\label{item:newStep2} Cut $B_n^1$ into three intervals $B_n^{1,1}$, $B_n^{1,2}$ and $B_n^{1,3}$ such that $\\mu(B_n^{1,2})$ and $\\mu(B_n^{1,3})$ are multiples of $\\mu(B_n^2)$ and\r\n    \\begin{equation}\\label{eq:choiceOfB23}\r\n    \\frac{\\mu(B_n^{1,2})}{\\mu(B_n^{1})},\\frac{\\mu(B_n^{1,3})}{\\mu(B_n^{1})}\\in(\\frac{1}{200},\\frac{1}{150}),\r\n    \\end{equation}\r\n    which can be achieved by the properties in \\eqref{eq:initialEquation};\r\n\\item\\label{item:step2} Cut $B_n^{1,1}$ into $n^2$ disjoint intervals $W_n^k$ such that for any $0\\leq k\\leq n^2-1$, we have\r\n    \\begin{equation} \\label{eq:WidthsBases}\r\n    \\begin{aligned}\r\n    &\\mu(W_n^k)=\\frac{\\frac{1}{h_n^{(1)}+k}}{\\sum_{i=0}^{n^2-1}\\frac{1}{h_n^{(1)}+i}}\\mu(B_n^{1,1}).\\\\\r\n    %&\\mu(E_n^1)=\\mu(B_n^2).\r\n    \\end{aligned}\r\n    \\end{equation}\r\n    Then we add $k$ spacers on the top of $W_n^k$ and one spacer on the top of $B_n^{1,3}$ as newly added mass. Indeed this construction can be intuitively expressed by the following picture, where the red  levels belong to $S_n^1$, green levels belong to $S_n^2$ and blue levels are newly added spacers:\r\n   \\begin{figure}[H]\r\n \\centering\r\n \\scalebox{0.6}\r\n {\r\n \\begin{tikzpicture}[scale=5]\r\n\t \\tikzstyle{vertex}=[circle,minimum size=0pt,inner sep=0pt]\r\n\t \\tikzstyle{selected vertex} = [vertex, fill=red!24]\r\n\t \\tikzstyle{edge1} = [draw,line width=5pt,-,red!50]\r\n     \\tikzstyle{edge2} = [draw,line width=5pt,-,green!50]\r\n     \\tikzstyle{edge3} = [draw,line width=5pt,-,blue!50]\r\n     \\tikzstyle{edge4} = [draw,line width=5pt,-,brown!50]\r\n\r\n\t \\tikzstyle{edge} = [draw,thick,-,black]\r\n\t %\\node[vertex] (v00) at (0,0) {$0000$};\r\n     \\node[vertex] (t000) at (0.0,0) {};\r\n\t \\node[vertex] (t001) at (3,0) {};\r\n     \\node[vertex] (t010) at (0.0,0.15) {};\r\n  \t \\node[vertex] (t011) at (3,0.15) {};\r\n     \\node[vertex] (t020) at (0.0,0.3) {};\r\n \t \\node[vertex] (t021) at (3,0.3) {};\r\n     \\node[vertex] (t030) at (0.0,0.45) {};\r\n\t \\node[vertex] (t031) at (3,0.45) {};\r\n     \\node[vertex] (b00) at (1.5,-0.2) {$B_n^1$};\r\n     \\node[vertex] (b01) at (-0.15,0.225) {$h_n^{(1)}$};\r\n\r\n     \\node[vertex] (e00) at (2.55,-0.03) {};\r\n     \\node[vertex] (e01) at (2.55,1.35) {};\r\n     \\node[vertex] (e02) at (2.675,-0.15) {$B_n^{1,2}$};\r\n     \\node[vertex] (e03) at (2.875,-0.15) {$B_n^{1,3}$};\r\n     \\node[vertex] (w00) at (0.3,-0.02) {};\r\n\t \\node[vertex] (w01) at (0.3,0.6) {};\r\n\t \\node[vertex] (w02) at (0.15,-0.1) {$W_n^0$};\r\n\t \\node[vertex] (w10) at (0.57,-0.03) {};\r\n\t \\node[vertex] (w11) at (0.57,0.75) {};\r\n\t \\node[vertex] (w12) at (0.435,-0.1) {$W_n^1$};\r\n     \\node[vertex] (w20) at (0.81,-0.03) {};\r\n\t \\node[vertex] (w21) at (0.81,0.9) {};\r\n\t \\node[vertex] (w22) at (0.69,-0.1) {$W_n^2$};\r\n\t \\node[vertex] (w30) at (1.05,-0.03) {};\r\n\t \\node[vertex] (w31) at (1.05,1.05) {};\r\n\t \\node[vertex] (w32) at (0.93,-0.1) {$W_n^3$};\r\n\t \\node[vertex] (w40) at (1.26,-0.03) {};\r\n\t \\node[vertex] (w41) at (1.26,1.05) {};\r\n\t \\node[vertex] (w42) at (1.155,-0.1) {$W_n^4$};\r\n     \\node[vertex] (dots) at (1.8,-0.1) {$\\ldots\\ldots\\ldots\\ldots\\ldots\\ldots$};\r\n     \\node[vertex] (w50) at (2.4,-0.03) {};\r\n\t \\node[vertex] (w51) at (2.4,1.35) {};\r\n\t \\node[vertex] (w52) at (2.55,-0.1) {$W_n^{n^2-1}$};\r\n\r\n     \\node[vertex] (i00) at (2.4,0.6) {};\r\n     \\node[vertex] (i01) at (2.55,0.6) {};\r\n     \\node[vertex] (i10) at (2.4,0.75) {};\r\n     \\node[vertex] (i11) at (2.55,0.75) {};\r\n     \\node[vertex] (i20) at (2.4,0.9) {};\r\n     \\node[vertex] (i21) at (2.55,0.9) {};\r\n     \\node[vertex] (i30) at (2.4,1.05) {};\r\n     \\node[vertex] (i31) at (2.55,1.05) {};\r\n     \\node[vertex] (i40) at (2.4,1.2) {};\r\n     \\node[vertex] (i41) at (2.55,1.2) {};\r\n\r\n     \\node[vertex] (n00) at (2.775,0) {};\r\n     \\node[vertex] (n01) at (2.775,0.6) {};\r\n     \\node[vertex] (n02) at (3,0.6) {};\r\n\r\n\r\n\t \\node[vertex] (sp10) at (1.26,0.6) {};\r\n     \\node[vertex] (sp20) at (1.26,0.75) {};\r\n     \\node[vertex] (sp30) at (1.26,0.9) {};\r\n     \\node[vertex] (sp40) at (1.26,1.05) {};\r\n\r\n     \\node[vertex] (h00) at (2.85,1.05) {$n^2-1$};\r\n\r\n     \\node[vertex] (h01) at (1.8,0.9) {$\\ldots\\ldots\\ldots\\ldots\\ldots$};\r\n\r\n\t \\node[vertex] (t100) at (3.3,0) {};\r\n\t \\node[vertex] (t101) at (3.45,0) {};\r\n\t \\node[vertex] (t110) at (3.3,0.15) {};\r\n\t \\node[vertex] (t111) at (3.45,0.15) {};\r\n\t \\node[vertex] (t120) at (3.3,0.3) {};\r\n\t \\node[vertex] (t121) at (3.45,0.3) {};\r\n\t \\node[vertex] (t130) at (3.3,0.45) {};\r\n\t \\node[vertex] (t131) at (3.45,0.45) {};\r\n\t \\node[vertex] (t140) at (3.3,0.6) {};\r\n\t \\node[vertex] (t141) at (3.45,0.6) {};\r\n\t \\node[vertex] (t150) at (3.3,0.75) {};\r\n\t \\node[vertex] (t151) at (3.45,0.75) {};\r\n\t \\node[vertex] (t160) at (3.3,0.9) {};\r\n\t \\node[vertex] (t161) at (3.45,0.9) {};\r\n\t \\node[vertex] (t170) at (3.3,1.05) {};\r\n\t \\node[vertex] (t171) at (3.45,1.05) {};\r\n\t \\node[vertex] (t180) at (3.3,1.2) {};\r\n\t \\node[vertex] (t181) at (3.45,1.2) {};\r\n\t \\node[vertex] (t190) at (3.3,1.35) {};\r\n\t \\node[vertex] (t191) at (3.45,1.35) {};\r\n\t \\node[vertex] (t1100) at (3.3,1.5) {};\r\n\t \\node[vertex] (t1101) at (3.45,1.5) {};\r\n\t \\node[vertex] (t1110) at (3.3,1.65) {};\r\n\t \\node[vertex] (t1111) at (3.45,1.65) {};\r\n\t \\node[vertex] (b10) at (3.37,-0.1) {$B_n^2$};\r\n     \\node[vertex] (b11) at (3.55,0.675) {$h_n^{(2)}$};\r\n\r\n\r\n\t\r\n\t \\draw[edge1] (t000)--(t001);\r\n\t \\draw[edge1] (t010)--(t011);\r\n\t \\draw[thick,dash dot] (t020)--(t021);\r\n\t \\draw[edge1] (t030)--(t031);\r\n\r\n\r\n     \\draw[edge2] (t100)--(t101);\r\n     \\draw[edge2] (t110)--(t111);\r\n     \\draw[thick,dash dot] (t120)--(t121);\r\n     \\draw[edge2] (t130)--(t131);\r\n     \\draw[thick,dash dot] (t140)--(t141);\r\n     \\draw[thick,dash dot] (t150)--(t151);\r\n     \\draw[thick,dash dot] (t160)--(t161);\r\n     \\draw[thick,dash dot] (t170)--(t171);\r\n     \\draw[thick,dash dot] (t180)--(t181);\r\n     \\draw[thick,dash dot] (t190)--(t191);\r\n     \\draw[thick,dash dot] (t1100)--(t1101);\r\n     \\draw[edge2] (t1110)--(t1111);\r\n\r\n\r\n     \\draw[edge3] (w01)--(sp10);\r\n     \\draw[edge3] (w11)--(sp20);\r\n     \\draw[edge3] (w21)--(sp30);\r\n     \\draw[edge3] (w31)--(sp40);\r\n     \\draw[edge3] (e01)--(w51);\r\n     \\draw[edge3] (i00)--(i01);\r\n     \\draw[thick,dash dot] (i10)--(i11);\r\n     \\draw[thick,dash dot] (i20)--(i21);\r\n     \\draw[thick,dash dot] (i30)--(i31);\r\n     \\draw[thick,dash dot] (i40)--(i41);\r\n\r\n     \\draw[thick,dash dot] (e00)--(e01);\r\n     \\draw[thick,dash dot] (w00)--(w01);\r\n     \\draw[thick,dash dot] (w10)--(w11);\r\n     \\draw[thick,dash dot] (w20)--(w21);\r\n     \\draw[thick,dash dot] (w30)--(w31);\r\n     \\draw[thick,dash dot] (w40)--(w41);\r\n     \\draw[thick,dash dot] (w50)--(w51);\r\n\r\n     \\draw[thick,dash dot] (n00)--(n01);\r\n     \\draw[edge3] (n01)--(n02);\r\n\r\n \\end{tikzpicture}\r\n }.\r\n \\end{figure}\r\n It is worth to point out that the total mass we added to our system, i.e. the blue levels in the above picture, at step $n$ satisfies the following estimate:\r\n    \\begin{equation}\\label{eq:addMass}\r\n    \\mu(B_n^{1,3})+\\sum_{k=1}^{n^2-1}k\\mu(W_n^k)\\leq n^2\\mu(B_n^1)<\\frac{n^2}{h_n^{(1)}}\\mu(S_n^1)<\\frac{1}{10000n^2};\r\n    \\end{equation}\r\n\\item\\label{item:step3} For $0\\leq k\\leq n^2-1$, we define: \\begin{equation}\r\n    \\overline{D}_n^k=\\bigcup_{i=0}^{h_n^{(1)}+k-1}T^iW_n^k.\r\n    \\end{equation}\r\n    Then we divide $\\overline{D}_n^k$ into $\\frac{H_n}{h_n^{(1)}+k}$ sub-towers of the same width and then stack them together. We denote this new tower by $D_n^k$ and observe that the height of $D_n^k$ is $H_n$. We also note that all these towers $D_n^k$, $0\\leq k <n^2$, have the same width by our choices of $\\mu(W^k_n)$ in (\\ref{eq:WidthsBases}). The following picture provides an intuitive explanation of this step:\r\n    \\begin{figure}[H]\r\n \\centering\r\n \\scalebox{0.6}\r\n {\r\n \\begin{tikzpicture}[scale=5]\r\n\t \\tikzstyle{vertex}=[circle,minimum size=2pt,inner sep=0pt]\r\n\t \\tikzstyle{selected vertex} = [vertex, fill=red!24]\r\n\t \\tikzstyle{edge1} = [draw,line width=5pt,-,red!50]\r\n     \\tikzstyle{edge2} = [draw,line width=5pt,-,green!50]\r\n     \\tikzstyle{edge3} = [draw,line width=5pt,-,blue!50]\r\n     \\tikzstyle{edge4} = [draw,line width=5pt,-,brown!50]\r\n\r\n\t \\tikzstyle{edge} = [draw,thick,-,black]\r\n\t %\\node[vertex] (v00) at (0,0) {$0000$};\r\n     \\node[vertex] (d00) at (0,-0.1) {$D_n^0$};\r\n     \\node[vertex] (t00) at (0,0) {};\r\n     \\node[vertex] (t01) at (0,0.2) {};\r\n     \\node[vertex] (t02) at (0,0.4) {};\r\n     \\node[vertex] (t03) at (0,0.6) {};\r\n     \\node[vertex] (t04) at (0,0.7) {$\\vdots$};\r\n     \\node[vertex] (t05) at (0,0.8) {};\r\n     \\node[vertex] (t06) at (0,1) {};\r\n     \\node[vertex] (t07) at (0,1.2) {};\r\n     \\node[vertex] (e01) at (-0.1,0.1) {$h_n^{(1)}$};\r\n     \\node[vertex] (e02) at (-0.1,0.3) {$h_n^{(1)}$};\r\n     \\node[vertex] (e03) at (-0.1,0.5) {$h_n^{(1)}$};\r\n     \\node[vertex] (e04) at (-0.1,0.9) {$h_n^{(1)}$};\r\n     \\node[vertex] (e05) at (-0.1,1.1) {$h_n^{(1)}$};\r\n\r\n     \\draw[edge1] (t00)--(t01);\r\n     \\draw[edge1] (t01)--(t02);\r\n     \\draw[edge1] (t02)--(t03);\r\n     \\draw[edge1] (t05)--(t06);\r\n     \\draw[edge1] (t06)--(t07);\r\n\r\n     \\node[vertex] (d10) at (0.5,-0.1) {$D_n^1$};\r\n     \\node[vertex] (t10) at (0.5,0) {};\r\n     \\node[vertex] (t11) at (0.5,0.22) {};\r\n     \\node[vertex] (t12) at (0.5,0.44) {};\r\n     \\node[vertex] (t13) at (0.5,0.66) {};\r\n     \\node[vertex] (t14) at (0.5,0.72) {$\\vdots$};\r\n     \\node[vertex] (t15) at (0.5,0.76) {};\r\n     \\node[vertex] (t16) at (0.5,0.98) {};\r\n     \\node[vertex] (t17) at (0.5,1.2) {};\r\n     \\node[vertex] (e11) at (0.35,0.1) {$h_n^{(1)}+1$};\r\n     \\node[vertex] (e12) at (0.35,0.3) {$h_n^{(1)}+1$};\r\n     \\node[vertex] (e13) at (0.35,0.5) {$h_n^{(1)}+1$};\r\n     \\node[vertex] (e14) at (0.35,0.9) {$h_n^{(1)}+1$};\r\n     \\node[vertex] (e15) at (0.35,1.1) {$h_n^{(1)}+1$};\r\n\r\n     \\draw[edge1] (t10)--(t11);\r\n     \\draw[edge1] (t11)--(t12);\r\n     \\draw[edge1] (t12)--(t13);\r\n     \\draw[edge1] (t15)--(t16);\r\n     \\draw[edge1] (t16)--(t17);\r\n\r\n\r\n     \\node[vertex] (d20) at (1.6,-0.1) {$D_n^{n^2-1}$};\r\n     \\node[vertex] (t20) at (1.6,0) {};\r\n     \\node[vertex] (t21) at (1.6,0.35) {};\r\n     \\node[vertex] (t22) at (1.6,0.7) {};\r\n     \\node[vertex] (t23) at (1.6,0.78) {$\\vdots$};\r\n     \\node[vertex] (t24) at (1.6,0.85) {};\r\n     \\node[vertex] (t25) at (1.6,1.2) {};\r\n\r\n     \\node[vertex] (e21) at (1.35,0.17) {$h_n^{(1)}+n^2-1$};\r\n     \\node[vertex] (e22) at (1.35,0.52) {$h_n^{(1)}+n^2-1$};\r\n     \\node[vertex] (e23) at (1.35,1) {$h_n^{(1)}+n^2-1$};\r\n\r\n\r\n     \\draw[edge1] (t20)--(t21);\r\n     \\draw[edge1] (t21)--(t22);\r\n     \\draw[edge1] (t24)--(t25);\r\n\r\n     \\node[vertex] (t25) at (1,0.6) {$\\ldots\\ldots\\ldots\\ldots\\ldots$};\r\n\r\n\r\n \\end{tikzpicture}\r\n }.\r\n \\end{figure}\r\n Moreover, for any $0\\leq i< j\\leq n^2-1$ we consider the coding of $w_i\\in D^i_n$ and $w_j\\in D^j_n$ with respect to partition \\begin{equation}\\label{eq:finiteRankPartition}\r\n    \\mathcal{P}_n=\\{B_n^1,\\ldots,T^{h_n^{(1)}-1}B_n^1,B_n^2,\\ldots,T^{h_n^{(2)}-1}B_n^2,X\\setminus(S_n^1\\cup S_n^2)\\}.\r\n    \\end{equation}\r\n    For any $0\\leq k\\leq (h_n^{(1)}+i)(h_n^{(1)}+j)-1$ there exist unique $p,q'\\in[0,h_n^{(1)}+i-1]$ and $q,p'\\in[0,h_n^{(1)}+j-1]$ such that\r\n    $$k=p(h_n^{(1)}+j)+q=p'(h_n^{(1)}+i)+q',$$\r\n    which gives the $k$'s code of $w_i$ is $q'$ if $q'\\leq h_n^{(1)}-1$ and $k$'s code of $w_j$ is $q$ if $q\\leq h_n^{(1)}-1$. Thus, for $q,q'\\in[0,h_n^{(1)}-1]$ the $k$'s codes of $w_i$ and $w_j$ agree if and only if $q=q'$ and \\begin{equation}\\label{eq:ratioEquation}\r\n    \\frac{p}{p'}=\\frac{h_n^{(1)}+i}{h_n^{(1)}+j}.\r\n    \\end{equation}\r\n    However, if $s$ is a common divisor of $h_n^{(1)}+i$ and $h_n^{(1)}+j$, then $s$ is also a divisor of $j-i$, which guarantees that $s\\in[0,n^2]$ since $i,j\\in[0,n^2-1]$. Denote $s_{\\max}$ as the greatest common divisor of $h_n^{(1)}+i$ and $h_n^{(1)}+j$. Then we know that $s_{\\max}\\leq n^2$. Moreover, the definition of $s_{\\max}$ implies that the number of integer pairs $(p,p')$ satisfying  \\eqref{eq:ratioEquation} such that $p\\in[0,h_n^{(1)}+i]$ and $p'\\in[0,h_n^{(1)}+j]$ is less than $s_{\\max}$ and thus also less than $n^2$. Note that each integer pair of \\eqref{eq:ratioEquation} gives at most $h_n^{(1)}+j$ identical codes between $w_i$ and $w_j$. Thus we know that if $q,q'\\in[0,h_n^{(1)}-1]$, then we have at most $n^2(h_n^{(1)}+j)$ identical codes between $w_i$ and $w_j$.\r\n\r\n    On the other hand, if $q$ and $q'$ are larger than or equal to $h_n^{(1)}$, then $k$'s codes of $w_i$ and $w_j$ are identical since the corresponding points stay in $X\\setminus(S_n^1\\cup S_n^2)$. In this case, we obtain at most $j(h_n^{(1)}+j)$ identical codes between $w_i$ and $w_j$ since we assume $j>i$.\r\n\r\n    Combining these two cases, the number of identical codes between $w_i$ and $w_j$ is at most $n^2(h_n^{(1)}+j)+j(h_n^{(1)}+j)$. Since the code from $0$ up to $(h_n^{(1)}+i)(h_n^{(1)}+j)-1$ repeats periodically from $0$ to $H_n-1$, we obtain that\r\n    \\begin{equation}\r\n    \\begin{aligned}\r\n    d_{H_n}^{H}(w_i,w_j)\\geq1-\\frac{n^2(h_n^{(1)}+j)+j(h_n^{(1)}+j)}{(h_n^{(1)}+i)(h_n^{(1)}+j)}\\geq 1-\\frac{2n^2}{h_n^{(1)}+i}\\geq 1-\\frac{1}{n^4};\r\n    \\end{aligned}\r\n    \\end{equation}\r\n\r\n    In step (\\ref{item:step5}) we are going to cut all $D^i_n$'s into the same number of columns and stack them in a specific way to build tower $S_{n+1}^2$.\r\n\\item\\label{item:step4} Cut $B_n^{1,2}$ and $B_n^{1,3}$ into intervals with length equal to $\\mu(B_n^2)$ and then stack them over $S_n^2$. We define this new tower as $S_{n+1}^1$. Recall that our constructions guarantee that  $\\frac{\\mu(B_n^{1,2})}{\\mu(B_n^{1})},\\frac{\\mu(B_n^{1,3})}{\\mu(B_n^{1})}\\in(\\frac{1}{200},\\frac{1}{150})$ and  $\\frac{1}{3}\\mu(S_n^2)<\\mu(S_n^1)<\\frac{31}{10}\\mu(S_n^2)$. Thus we have the following estimates for the height $h_{n+1}^{(1)}=h_n^{(2)}+\\frac{\\mu(B^{1,2}_n)}{\\mu(B^2_n)} h_n^{(1)}+\\frac{\\mu(B^{1,3}_n)}{\\mu(B^2_n)} (h_n^{(1)}+1)$ of tower $S_{n+1}^1$:\r\n    \\begin{equation}\\label{eq:heightHn21}\r\n    \\begin{aligned}\r\n    h_{n+1}^{(1)} &< h_n^{(2)}+\\frac{ \\frac{1}{150}  \\mu(B_n^{1}) h_n^{(1)}}{\\mu(B^2_n) h_n^{(2)}} h_n^{(2)}+\\frac{ \\frac{1}{150}  \\mu(B_n^{1}) (h_n^{(1)}+1)}{\\mu(B^2_n) h_n^{(2)}} h_n^{(2)}\\\\\r\n     &< h_n^{(2)}+\\frac{ \\frac{3}{100}  \\mu(S_n^{1})}{\\mu(S^2_n)} h_n^{(2)} \\\\\r\n    &< \\left(1+\\frac{3}{100}\\cdot\\frac{31}{10} \\right)h_n^{(2)}<2h_n^{(2)}.\r\n    \\end{aligned}\r\n    \\end{equation}\r\nSimilarly, we have\r\n\\begin{equation}\\label{eq:heightHn22}\r\n\\begin{aligned}\r\nh_{n+1}^{(1)} &> h_n^{(2)}+\\frac{ \\frac{1}{100}  \\mu(B_n^{1}) h_n^{(1)}}{\\mu(B^2_n) h_n^{(2)}} h_n^{(2)} = h_n^{(2)}+\\frac{ \\frac{1}{100}  \\mu(S_n^{1})}{\\mu(S^2_n)} h_n^{(2)}\\\\\r\n& > \\left(1+\\frac{1}{100}\\cdot\\frac{1}{3}\\right)h_n^{(2)}>\\frac{1001}{1000}h_n^{(2)}.\r\n\\end{aligned}\r\n\\end{equation}\r\n    %Thus we have the following estimates for the height $h_{n+1}^{(1)}$ of tower $S_{n+1}^1$:\r\n    %\\begin{equation}\\label{eq:heightHn2}\r\n    %\\begin{aligned}\r\n    %&h_n^{(2)}+\\frac{\\frac{1}{100}\\mu(S_n^1)}{\\mu(B_n^2)}<h_{n+1}^{(1)}<h_n^{(2)}+\\frac{\\frac{2}{100}\\mu(S_n^1)}{\\mu(B_n^2)}\\\\\r\n%\\Leftrightarrow&h_n^{(2)}+\\frac{\\frac{1}{100}\\mu(B_n^1)\\cdot h_n^{(1)}}{\\mu(B_n^2)}<h_{n+1}^{(1)}<h_n^{(2)}+\\frac{\\frac{2}{100}\\mu(B_n^1)\\cdot h_n^{(1)}}{\\mu(B_n^2)}\\\\\r\n%\\Leftrightarrow& h_n^{(2)}+\\frac{1}{100}\\cdot(\\frac{97}{100}\\cdot\\frac{h_n^{(2)}}{h_n^{(1)}})\\cdot h_n^{(1)}<h_{n+1}^{(1)}<h_n^{(2)}+\\frac{2}{100}\\cdot(\\frac{103}{100}\\cdot\\frac{h_n^{(2)}}{h_n^{(1)}})\\cdot h_n^{(1)},\\\\\r\n%\\Leftrightarrow& \\frac{1001}{1000}h_n^{(2)}<h_{n+1}^{(1)}<\\frac{103}{100}h_n^{(2)},\r\n%    \\end{aligned}\r\n%    \\end{equation}\r\n%    where we used $\\mu(S_n^1)=\\mu(B_n^1)\\cdot h_n^{(1)}$, $\\mu(S_n^2)=\\mu(B_n^2)\\cdot h_n^{(2)}$ and $\\frac{97}{100}\\mu(S_n^2)<\\mu(S_n^1)<\\frac{103}{100}\\mu(S_n^2)$;\r\n\r\n\r\n\\item\\label{item:step5} We introduce a subexponential sequence $\\{b_k\\}_{k\\in \\N}$ defined by $b_k =  a_{(k+1)H_{n+1}}(t_{n+1})$, where $H_{n+1}=\\prod_{i=0}^{(n+1)^2-1}(h_{n+1}^{(1)}+i)$. Applying Lemma \\ref{lem:prob} with $\\epsilon=\\frac{1}{(n+1)^4}$, alphabet $\\Sigma=\\{0,1,\\dots , (n+1)^2-1\\}$, and sequence $\\{b_k\\}_{k\\in \\N}$ gives $K_{n+1} \\in \\Z^{+}$ large enough such that for every $k\\geq K_{n+1}$ we have\r\n    \\begin{equation}\\label{eq:heightHn23}\r\n    a_{kH_{n+1}}(t_{n+1}) >\\max\\{2\\cdot10^9h_n^{(2)},10000(n+2)^8\\}\r\n    \\end{equation}\r\n    and that there are at least $b_k$ many words in $\\Sigma^k$ that satisfy property (2) of Lemma \\ref{lem:prob}.\r\n\r\nThen we apply Lemma \\ref{lem:prob} again. This times with $\\epsilon=\\frac{1}{n^4}$, $\\Sigma=\\{0,1,\\dots , n^2-1\\}$ (corresponding to the labels of the blocks $D^i_n$ from step (\\ref{item:step3})), and subexponential sequence $\\{b_k\\}_{k\\in \\N}$ to find $N_n \\coloneqq a_{K_{n+1}H_{n+1}}(t_{n+1})$ many different words built by concatenating blocks $D^i_n$, $0\\leq i < n^2-1$, uniformly such that the Hamming distance between any two different words among them is larger than $(1-\\frac{2}{n^2})(1-\\frac{1}{n^4})$ with respect to $\\mathcal{P}_n$. This application gives a number $L_n$ of required concatenations. By exact uniformity in (1) of Lemma \\ref{lem:prob} we obtain that each $D^i_n$ occurs the same number of times in the construction so that we cut all of them into the same number of columns as indicated in step (\\ref{item:step3}).\r\n\\item Stacking all the words we get from previous step above each other, we have a tower with height $N_nL_nH_n$ and denote this tower as $S_{n+1}^2$. Moreover, we check that our construction satisfies our inductive assumption in \\eqref{eq:initialEquation}: the third equation in \\eqref{eq:initialEquation} and \\eqref{eq:heightHn22} guarantee that\r\n    $$h_{n+1}^{(1)}>10000(n+1)^8;$$ Step \\eqref{item:step5} and\r\n    \\eqref{eq:heightHn23} guarantee that\r\n    $$h_{n+1}^{(2)}>a_{K_{n+1}H_{n+1}}(t_{n+1})\\cdot L_n>10000(n+2)^4;$$\r\n    Combining \\eqref{eq:heightHn21}, step \\eqref{item:step5} and \\eqref{eq:heightHn23}, we obtain\r\n    $$\\frac{h_{n+1}^{(1)}}{h_{n+1}^{(2)}}<\\frac{1}{10^9};$$\r\n    Finally, \\eqref{eq:addMass} and step \\eqref{item:step4} imply\r\n    \\begin{equation}\\label{eq:meaureEstimate1}\r\n    \\begin{aligned}\r\n\\frac{98}{100}\\mu(S_n^1)\\leq&\\mu(S_{n+1}^2)\\leq\\frac{99}{100}\\mu(S_n^1)+\\frac{1}{10000}\\mu(S_n^1),\\\\\r\n\\mu(S_n^2)+\\frac{1}{100}\\mu(S_n^1)\\leq&\\mu(S_{n+1}^1)\\leq\\mu(S_n^2)+\\frac{2}{100}\\mu(S_n^1).\r\n    \\end{aligned}\r\n    \\end{equation}\r\n    Combining the fifth equation of \\eqref{eq:initialEquation} and \\eqref{eq:meaureEstimate1}, we obtain:\r\n    \\begin{equation}\r\n    \\begin{aligned}\r\n    \\frac{\\mu(S_{n+1}^1)}{\\mu(S_{n+1}^2)}\\leq\\frac{\\mu(S_n^2)+\\frac{2}{100}\\mu(S_n^1)}{\\frac{98}{100}\\mu(S_n^1)}<\\frac{3\\mu(S_n^1)+\\frac{2}{100}\\mu(S_n^1)}{\\frac{98}{100}\\mu(S_n^1)}=\\frac{302}{98}<\\frac{31}{10},\r\n    \\end{aligned}\r\n    \\end{equation}\r\n    and\r\n    \\begin{equation}\r\n    \\begin{aligned}\r\n    \\frac{\\mu(S_{n+1}^1)}{\\mu(S_{n+1}^2)}\\geq\\frac{\\mu(S_n^2)+\\frac{1}{100}\\mu(S_n^1)}{\\frac{99}{100}\\mu(S_n^1)+\\frac{1}{10000}\\mu(S_n^1)}>\\frac{\\frac{10}{31}\\mu(S_n^1)+\\frac{1}{100}\\mu(S_n^1)}{\\frac{99}{100}\\mu(S_n^1)+\\frac{1}{10000}\\mu(S_n^1)}=\\frac{\\frac{10}{31}+\\frac{1}{100}}{\\frac{9901}{10000}}>\\frac{1}{3},\r\n    \\end{aligned}\r\n    \\end{equation}\r\n    which together guarantee that\r\n    $$\\frac{1}{3}\\mu(S_{n+1}^2)<\\mu(S_{n+1}^1)<\\frac{31}{10}\\mu(S_{n+1}^2).$$\r\n\\end{enumerate}\r\nNoticing that the right side of \\eqref{eq:addMass} is a summable sequence, we know that the measurable system $(T,X,\\mathcal{B},\\mu_X)$\\footnote{For any $A\\in\\mathcal{B}$, $\\mu_X(A)=\\frac{\\mu(A\\cap X)}{\\mu(X)}$.}, which we construct above is a measure preserving transformation on a finite interval of $[0,+\\infty)$. Moreover, the construction implies that this system's rank is at most $2$. In the next step, we show that this measure preserving system $T$ indeed is ergodic:\r\n\\begin{proposition}\\label{prop:ergodic}\r\n$(T,X,\\mathcal{B})$ is ergodic with respect to the measure $\\mu_X$ induced from Lebesgue measure $\\mu$.\r\n\\end{proposition}\r\n\\begin{proof}\r\nWe first show that $T$ preserves Lebesgue measure $\\mu$. By the construction of $T$, we know that there exist countable disjoint intervals $I_i\\subset X$ for $i\\in\\mathcal{I}$ such that $\\cup_{\\mathcal{I}}I_i=X$ and $T$ is measure preserving from $I_i$ to $T(I_i)$. Let $A\\subset X$ be a measurable subset, then there exists a countable decomposition of $A$ into $A_i=A\\cap I_i$ for $i\\in\\mathcal{I}$ such that $A=\\cup_{i\\in\\mathcal{I}}A_i$. Since $T$ is a measure preserving map on each interval $I_i$, we have $\\mu(A_i)=\\mu(T^{-1}(A_i))=\\mu(T(A_i))$, which gives that $\\mu(A)=\\mu(T^{-1}(A))=\\mu(T(A))$.\r\n\r\nNow suppose that $A$ is an $T$-invariant set with positive measure, i.e. $A=T^{-1}(A)$ and $\\mu(A)>0$. Based on our construction, there exists $N_0\\in\\mathbb{N}$ such that for any $n\\geq N_0$, we have\r\n\\begin{equation}\r\n\\mu(A\\cap(S_n^1\\cup S_n^2))>\\frac{\\mu(A)}{2}>0.\r\n\\end{equation}\r\nMoreover, it is worth to point out that our construction also gives us that for any $n\\leq m$:\r\n$$S_n^1\\cup S_n^2\\subset S_m^1\\cup S_m^2,$$\r\nthus we have\r\n\\begin{equation}\r\nA\\cap(S_n^1\\cup S_n^2)\\subset A\\cap(S_m^1\\cup S_m^2).\r\n\\end{equation}\r\n\r\nDenote $A'=A\\cap(S_{N_0}^1\\cup S_{N_0}^2)$ and let $x\\in A'$ with Lebesgue density equal to $1$. This implies that for any $\\epsilon>0$, there exists $\\delta>0$ such that if $I$ is an interval that contains $x$ and $\\mu(I)<\\delta$, we have $\\mu(A'\\cap I)>(1-\\epsilon)\\mu(I)$.\r\n\r\n\r\nLet $N_1\\in\\mathbb{N}$ such that for any $n\\geq N_1$, $\\mu(B(S_{n}^1)),\\mu(B(S_n^2))<\\delta$ and $\\mu(X\\setminus(S_n^1\\cup S_n^2))<\\epsilon\\mu(X)$. By Lebesgue density Theorem and the definition of $A'$, we obtain that for any $n\\geq N_1$, there exists at least one level $I_0$ from $S_n^1$ or $S_n^2$ such that \\begin{equation}\\label{eq:firstInterval}\r\n\\mu(A'\\cap I_0)\\geq(1-\\epsilon)\\mu(I_0).\r\n\\end{equation}\r\nBy the stack's definition and $A=\\cup_{i=-\\infty}^{+\\infty}T^i(A)\\supset\\cup_{i=-\\infty}^{+\\infty}T^i(A')$, we know that \\eqref{eq:firstInterval} implies\r\n\\begin{equation}\\label{eq:goodRegion2}\r\n\\mu(A\\cap S_n^1)\\geq (1-\\epsilon)\\mu(S_n^1).\r\n\\end{equation}\r\nor\r\n\\begin{equation}\\label{eq:goodRegion3}\r\n\\mu(A\\cap S_n^2)\\geq (1-\\epsilon)\\mu(S_n^2).\r\n\\end{equation}\r\n\r\nIf \\eqref{eq:goodRegion2} holds, then denote the levels of $S_{n+1}^1$ from $S_n^1$ as $D_i$ and the levels of $S_{n+1}^2$ from $S_n^1$ as $E_j$. Since $\\frac{\\mu(\\cup D_i)}{\\mu(\\cup E_j)}\\in(\\frac{1}{99},\\frac{2}{98})$ (see \\eqref{eq:initialEquation} and Step \\eqref{item:newStep2} in our construction) and $(\\cup D_i)\\cup(\\cup E_j)=S_n^1$, we obtain following inequalities from \\eqref{eq:goodRegion2}:\r\n\\begin{equation}\\label{eq:markovPreparation}\r\n\\begin{aligned}\r\n&\\mu\\left(A\\cap(\\cup D_i)\\right)\\geq(1-100\\epsilon)\\mu(\\cup D_i),\\\\\r\n&\\mu\\left(A\\cap(\\cup E_j)\\right)\\geq(1-100\\epsilon)\\mu(\\cup E_j).\r\n\\end{aligned}\r\n\\end{equation}\r\n\r\nDenote $k_{bad}^1=\\operatorname{Card}\\{D_i:\\mu(A\\cap D_i)\\leq (1-10^5\\epsilon)\\mu(D_i)\\}$ and $k_{bad}^2=\\operatorname{Card}\\{E_j:\\mu(A\\cap E_j)\\leq (1-10^5\\epsilon)\\mu(E_j)\\}$, we have the following inequality by \\eqref{eq:markovPreparation}:\r\n\\begin{equation}\r\n\\begin{aligned}\r\n&k_{bad}^1\\cdot10^5\\epsilon\\cdot\\mu(D_i)\\leq100\\epsilon\\mu(\\cup D_i),\\\\\r\n&k_{bad}^2\\cdot10^5\\epsilon\\cdot\\mu(E_j)\\leq100\\epsilon\\mu(\\cup E_j),\r\n\\end{aligned}\r\n\\end{equation}\r\nwhich implies that\r\n\\begin{equation}\\label{eq:markovResults}\r\n\\begin{aligned}\r\nk_{bad}^1&\\leq \\frac{1}{1000}\\operatorname{Card}(\\{D_i\\}),\\\\\r\nk_{bad}^2&\\leq \\frac{1}{1000}\\operatorname{Card}(\\{E_j\\}).\r\n\\end{aligned}\r\n\\end{equation}\r\nThen \\eqref{eq:markovResults} implies that there exists $i_0$ and $j_0$ such that\r\n\\begin{equation}\\label{eq:goodLevels}\r\n\\begin{aligned}\r\n&\\mu(A\\cap D_{i_0})\\geq(1-10^5\\epsilon)\\mu(D_{i_0}),\\\\\r\n&\\mu(A\\cap E_{j_0})\\geq(1-10^5\\epsilon)\\mu(E_{j_0}).\r\n\\end{aligned}\r\n\\end{equation}\r\nRecall that $D_{i_0}$ and $E_{j_0}$ are levels of $S_{n+1}^1$ and $S_{n+1}^2$, together with that $A=T^i(A)$ for $i\\in\\mathbb{N}$ and the definition of towers, we obtain that\r\n\\begin{equation}\\label{eq:ergodicInequality}\r\n\\begin{aligned}\r\n\\mu(A)&\\geq\\mu(A\\cap(S_{n+1}^1\\cup S_{n+1}^2))\\geq(1-10^5\\epsilon)(\\mu(S_{n+1}^1)+\\mu(S_{n+1}^2))\\\\\r\n&\\geq (1-\\epsilon)(1-10^5\\epsilon)\\mu(X).\r\n\\end{aligned}\r\n\\end{equation}\r\n\r\nSince $\\epsilon>0$ is arbitrary, we obtain that $\\mu(A)=\\mu(X)$. If \\eqref{eq:goodRegion3} holds, instead of $S_{n+1}^1$ and $S_{n+1}^2$, we will consider the towers $S_{n+2}^1$ and $S_{n+2}^2$ and then we will have \\eqref{eq:ergodicInequality} again. Combining these two cases, we obtain that $T$ is ergodic with respect to $\\mu_X$.\r\n\\end{proof}\r\n\r\n\\begin{proposition}\r\n$(T,X,\\mathcal{B})$ is not mixing but is weakly mixing with respect to measure $\\mu_X$ induced from Lebesgue measure $\\mu$.\r\n\\end{proposition}\r\n\\begin{proof}\r\nThe proof of this proposition follows from ideas similar to Chacon's proof in \\cite{Chacon} together with some combinatorial arguments.\r\n\\paragraph{Proof of no mixing:}\r\nWe first show our system is not mixing. Applying Rokhlin lemma to $T$ with $\\epsilon=10^{-10}$ and $m=3000$, we obtain a set $A$ such that $T^i(A)\\cap T^j(A)=\\emptyset$ for $1\\leq i,j\\leq 3000$ and $\\cup_{i=1}^{3000}\\mu(T^i(A))>(1-10^{-10})\\mu(X)$. For any $n\\in\\mathbb{Z}^+$, denote the tower over $B_n^{1,2}$ as $S_n^{1,2}$. Then \\eqref{eq:initialEquation} and step \\eqref{item:step4} imply that\r\n\\begin{equation}\\label{eq:returnPortion}\r\n\\text{ $T^{h_n^{(1)}}$ will map $1-\\frac{6}{10^7}$ portion of $B_n^{1,2}$ to $B_n^{1,2}$.}\r\n\\end{equation}\r\nMore precisely, two of the key steps to obtain \\eqref{eq:returnPortion} are noticing that the subtowers of $S_n^{1,2}$ in step \\eqref{item:step4} are stacked above each other and $\\frac{\\mu(B_n^{2})}{\\mu(B_n^{1,2})}<\\frac{\\mu(B_n^{2})}{\\frac{1}{200}\\mu(B_n^{1})}<600\\cdot\\frac{h_n^{(1)}}{h_n^{(2)}}$ from \\eqref{eq:initialEquation} and \\eqref{eq:choiceOfB23}.\r\n\r\nMoreover, \\eqref{eq:initialEquation}, \\eqref{eq:choiceOfB23} and \\eqref{eq:addMass} guarantee that $$\\frac{\\mu(S_n^{1,2})}{\\mu(X)}\\geq\\frac{1}{1000},$$ then by pigeonhole principle, there exists $i_n\\in\\{1,\\ldots,3000\\}$ such that\r\n\\begin{equation}\\label{eq:pigeonholePrin}\r\n\\frac{\\mu(T^{i_n}(A)\\cap S_n^{1,2})}{\\mu(X)}\\geq\\frac{1}{1500}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}.\r\n\\end{equation}\r\nCombining \\eqref{eq:initialEquation}, \\eqref{eq:returnPortion}, \\eqref{eq:pigeonholePrin} and notice that $\\frac{\\mu(A)}{\\mu(X)}\\in(\\frac{1}{4000},\\frac{1}{3000})$, we obtain that\r\n\\begin{equation}\\label{eq:nomixing1}\r\n\\begin{aligned}\r\n\\frac{\\mu(T^{h_n^{(1)}}(T^{i_n}(A))\\cap T^{i_n}(A))}{\\mu(X)}&\\geq \\frac{1}{1500}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}-\\frac{6}{10^7}\\frac{\\mu(S_n^{1,2})}{\\mu(X)}\\\\\r\n&\\geq\\frac{1}{1500}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}-\\frac{6}{10^7}\\cdot\\frac{1}{150}\\\\\r\n&\\geq\\frac{1}{1500}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}-\\frac{1}{15000}\\cdot\\frac{6}{10^5}\\\\\r\n&\\geq\\frac{1}{1500}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}-\\frac{1}{15000}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}\\\\\r\n&\\geq\\frac{1}{2000}\\frac{\\mu(T^{i_n}(A))}{\\mu(X)}.\r\n\\end{aligned}\r\n\\end{equation}\r\nSince $i_n\\in\\{1,\\ldots,3000\\}$ for every $n$, there exists $i_0\\in\\{1,\\ldots,3000\\}$ such that there are infinitely many $n$ satisfying \\eqref{eq:nomixing1} and $i_n=i_0$. By taking a subsequence $\\{n_k\\}$ such that $i_{n_k}=i_0$, \\eqref{eq:nomixing1} implies\r\n\\begin{equation}\\label{eq:nomixing3}\r\n\\frac{\\mu(T^{h_{n_k}^{(1)}}(T^{i_0}(A))\\cap T^{i_0}(A))}{\\mu(X)}\\geq \\frac{1}{2000}\\cdot\\frac{\\mu(T^{i_0}(A))}{\\mu(X)}.\r\n\\end{equation}\r\nNotice that $\\frac{\\mu(T^{i_0}(A))}{\\mu(X)}<\\frac{1}{3000}$ and $n_k\\to+\\infty$, then \\eqref{eq:nomixing3} implies that $(T,X,\\mathcal{B})$ is not mixing with respect to $\\mu_X$.\r\n\r\n\\paragraph{Proof of weak mixing:} Notice that \\eqref{eq:initialEquation} and step \\eqref{item:step4} imply that\r\n\\begin{equation}\\label{eq:returnPortion1}\r\n\\text{ $T^{h_n^{(1)}+1}$ will map $1-\\frac{6}{10^7}$ portion of $B_n^{1,3}$ to $B_n^{1,3}$.}\r\n\\end{equation}\r\n\r\nThen suppose $f$ is a step function defined on  $$\\mathcal{P}_n=\\{B_n^1,T(B_n^1),\\ldots,T^{h_n^{(1)}-1}(B_n^1),B_n^2,T(B_n^2),\\ldots,T^{h_n^{(2)}-1}(B_n^2)\\},$$\r\ni.e. $f$ is constant on each atom of $\\mathcal{P}_n$. Moreover, we also suppose $f$ is an eigenfunction of $T$ with eigenvalue $\\lambda$. Since $f$ is a step function, we denote $f=\\alpha$ on $B_n^1$ and we can assume $\\alpha \\neq 0$. Then \\eqref{eq:returnPortion} and \\eqref{eq:returnPortion1} imply that there exist $x_1,x_2\\in B_n^1$ with $T^{h_n^{(1)}}(x_1)\\in B_n^1$ and $T^{h_n^{(1)}+1}(x_2)\\in B_n^1$ such that\r\n\\begin{equation}\r\n\\begin{aligned}\r\n&\\alpha=f(T^{h_n^{(1)}}(x_1))=\\lambda^{h_n^{(1)}}f(x_1)=\\lambda^{h_n^{(1)}}\\alpha,\\\\\r\n&\\alpha=f(T^{h_n^{(1)}}(x_2))=\\lambda^{h_n^{(1)}+1}f(x_2)=\\lambda^{h_n^{(1)}+1}\\alpha,\r\n\\end{aligned}\r\n\\end{equation}\r\nwhich implies that $\\lambda=1$.\r\n\r\nFor the general case, suppose that $f$ is a nontrivial eigenfunction of $T$, i.e. $f\\neq0$. Since $T$ is ergodic with respect to $\\mu_X$ by Proposition \\ref{prop:ergodic}, $|f|$ is constant. Recall that $\\mathcal{P}_n$ generates the $\\sigma-$algebra $\\mathcal{B}$, thus for any $L^1$ function $f$ and $\\epsilon>0$, there exists $N_0$ such that if $n\\geq N_0$, then we have a step function $\\bar{f}\\neq0$ defined on $\\mathcal{P}_n$ satisfying:\r\n\\begin{equation}\r\n\\mu\\left(x\\in P_i:|f(x)-\\bar{f}(x)|>\\epsilon\\right)<\\epsilon\\mu(P_i),\r\n\\end{equation}\r\nfor every atom $P_i$ of $\\mathcal{P}_n$.\r\n\r\nThen \\eqref{eq:returnPortion} and \\eqref{eq:returnPortion1} imply that there exist $x_1,x_2\\in B_n^1$ with $T^{h_n^{(1)}}(x_1)\\in B_n^1$ and $T^{h_n^{(1)}+1}(x_2)\\in B_n^1$ such that\r\n\\begin{equation}\\label{eq:weaklyMixing}\r\n\\begin{aligned}\r\n&\\alpha+\\delta_1=f(T^{h_n^{(1)}}(x_1))=\\lambda^{h_n^{(1)}}f(x_1)=\\lambda^{h_n^{(1)}}(\\alpha+\\delta_2),\\\\\r\n&\\alpha+\\delta_3=f(T^{h_n^{(1)}}(x_2))=\\lambda^{h_n^{(1)}+1}f(x_2)=\\lambda^{h_n^{(1)}+1}(\\alpha+\\delta_4),\r\n\\end{aligned}\r\n\\end{equation}\r\nwhere $\\alpha=\\bar{f}(B_n^1)\\neq0$ and $|\\delta_1|,|\\delta_2|,|\\delta_3|,|\\delta_4|<\\epsilon$. Combining equations in \\eqref{eq:weaklyMixing}, we obtain that\r\n\\begin{equation}\\label{eq:weaklyMixing1}\r\n\\lambda=\\frac{(\\alpha+\\delta_2)(\\alpha+\\delta_3)}{(\\alpha+\\delta_1)(\\alpha+\\delta_4)}.\r\n\\end{equation}\r\n\r\nSince $T$ is ergodic with respect to $\\mu_X$, the absolute value of each eigenvalue of $T$ is equal to $1$, i.e. $|\\lambda|=1$. Then by choosing $\\epsilon<\\frac{1}{4}$, a direct computation and the fact that eigenvalues of $T$ form a subgroup of the unit circle show that \\eqref{eq:weaklyMixing1} will guarantee $\\lambda=1$. Thus, the only eigenvalue of $T$ is $1$ and $T$ is weakly mixing.\r\n\\end{proof}\r\n\r\n\r\nTo compute the slow entropy we first estimate the number of Hamming balls we need to cover a large portion of the space along a given subsequence:\r\n\\begin{proposition}\\label{prop:towerSequence}\r\nThere exists $N_1\\in\\mathbb{N}$ such that for any  $n_0\\geq N_1$, $H_n$, $K_n$ and $L_n$ be defined as above, we have for every $n\\geq n_0$:\r\n\\begin{equation}\r\nS(\\mathcal{P}_{n_0},L_nH_n,\\epsilon)\\geq a_{K_{n+1}H_{n+1}}(t_{n+1}).\r\n\\end{equation}\r\n\\end{proposition}\r\n\\begin{proof}\r\nIf $n=n_0$, the proposition follows from construction step \\eqref{item:step5}. If $n=n_0+1$, then by \\eqref{eq:selfSliding} in part (2) of Lemma \\ref{lem:prob} with $\\epsilon=\\frac{1}{(n-1)^4}$ and $\\Sigma=\\{0,1,\\ldots,n_0^2-1\\}$, construction \\eqref{item:step3} and \\eqref{item:step5}, we have for $w_i\\in W_n^i$ and $w_j\\in W_n^j$ that the Hamming distance with respect to partition $\\mathcal{P}_{n_0}$ up to iteration $H_n$ is\r\n\\begin{equation}\r\nd_{H_n}^H(w_i,w_j)\\geq (1-\\frac{1}{n^4})(1-\\frac{1}{(n-1)^4})(1-\\frac{2}{(n-1)^2}).\r\n\\end{equation}\r\nThen it follows from construction step \\eqref{item:step5}, that there are $a_{K_{n+1}H_{n+1}}(t_{n+1})$ many different words with length $H_{n}L_{n}$ such that the Hamming distance between any two different words among them is at least\r\n\\begin{equation}\r\n(1-\\frac{1}{n^4})(1-\\frac{1}{(n-1)^4})(1-\\frac{2}{(n-1)^2}) (1-\\frac{2}{n^2})=\\prod_{m=n_0}^{n}(1-\\frac{2}{m^2})(1-\\frac{2}{m^4}).\r\n\\end{equation}\r\nEnlarging $N_1$ if necessary, we can always guarantee that\r\n$$\\prod_{m=n_0}^{n}(1-\\frac{2}{m^2})(1-\\frac{2}{m^4})>\\epsilon,$$\r\nwhich implies that $S(\\mathcal{P}_{n_0},L_nH_n,\\epsilon)\\geq a_{K_{n+1}H_{n+1}}(t_{n+1})$.\r\n\r\nThe proof of general case follows along the same lines noticing that there exists $N_1$ such that for any $n_0\\geq N_1$, we always have $$\\prod_{m=n_0}^{+\\infty}(1-\\frac{2}{m^2})(1-\\frac{2}{m^4})>\\prod_{m=n_0}^{+\\infty}(1-\\frac{2}{m^2})^2>\\epsilon,$$\r\nwhich will imply that $S(\\mathcal{P}_{n_0},L_nH_n,\\epsilon)\\geq a_{K_{n+1}H_{n+1}}(t_{n+1})$ for any $n\\geq n_0$.\r\n\\end{proof}\r\n\r\nNow we will show that the lower slow entropy of $T$ with respect to $a_n$ defined in \\eqref{eq:scalingFunction} is positive:\r\n\\begin{proposition}\r\nFor $a_n(t)$ defined in \\eqref{eq:scalingFunction}  and $n_0\\in\\mathbb{N}$ fixed, we have\r\n$$\\lent^{\\mu_X}_{a_n(t)}(T,\\mathcal{P}_{n_0})=+\\infty,$$\r\nwhere $\\mathcal{P}_{n_0}$ is defined in \\eqref{eq:finiteRankPartition}.\r\n\\end{proposition}\r\n\\begin{proof}\r\nWe divide $[0,+\\infty)$ into different intervals with the aid of sequences $\\{L_nH_n\\}_{n\\in \\N}$ and $\\{K_nH_n\\}_{n\\in \\N}$. Then for any $m\\in[L_nH_n,K_{n+1}H_{n+1}]$, by Proposition \\ref{prop:towerSequence}, we have\r\n\\begin{equation}\\label{eq:firstInfinity1}\r\n\\frac{ S(\\mathcal{P}_{n_0},m,\\epsilon)}{ a_m(t)}\\geq\\frac{S(\\mathcal{P}_{n_0},L_nH_n,\\epsilon)}{ a_{K_{n+1}H_{n+1}}(t)}\\geq\\frac{ a_{K_{n+1}H_{n+1}}(t_{n+1})}{a_{K_{n+1}H_{n+1}}(t)}.\r\n\\end{equation}\r\nSince for any fixed $t>0$ there exists $N_0$ such that for every $n>N_0$ we have $t_{n+1}>t$, we get\r\n\\begin{equation}\\label{eq:firstInfinity2}\r\na_{K_{n+1}H_{n+1}}(t)=o(a_{K_{n+1}H_{n+1}}(t_{n+1}))\r\n\\end{equation}\r\nfor every $n>N_0$, where we recall that $a_n(t_1)=o(a_n(t_2))$ for $t_2>t_1>0$.\r\n\r\nFor any $m\\in[K_{n+1}H_{n+1},L_{n+1}H_{n+1}]$, there exists $k_m\\in[K_{n+1},L_{n+1}]$ such that $m\\in[k_mH_{n+1},(k_m+1)H_{n+1}]$. Then by Lemma \\ref{lem:prob} and construction step \\eqref{item:step5}, we have\r\n\\begin{equation}\\label{eq:secondInfinity1}\r\n\\frac{S(\\mathcal{P}_{n_0},m,\\epsilon)}{ a_m(t)}\\geq \\frac{ S(\\mathcal{P}_{n_0},k_mH_{n+1},\\epsilon)}{ a_{(k_m+1)H_{n+1}}(t)}\\geq\\frac{ b_{k_m}}{a_{(k_m+1)H_{n+1}}(t)}=\\frac{a_{(k_m+1)H_{n+1}}(t_{n+1})}{a_{(k_m+1)H_{n+1}}(t)},\r\n\\end{equation}\r\nRecall that for any fixed $t>0$ there exists $N_0$ such that for every $n>N_0$ we have $t_{n+1}>t$. Moreover, recall that $a_n(t_1)=o(a_n(t_2))$ for $t_2>t_1>0$. Then for every $n>N_0$, we have\r\n\\begin{equation}\\label{eq:secondInfinity2}\r\na_{(k_m+1)H_{n+1}}(t)\\leq o(a_{(k_m+1)H_{n+1}}(t_{n+1})).\r\n\\end{equation}\r\n\r\nCombining \\eqref{eq:firstInfinity1}, \\eqref{eq:firstInfinity2}, \\eqref{eq:secondInfinity1} and \\eqref{eq:secondInfinity2}, we complete the proof of the proposition.\r\n\\end{proof}\r\n\r\nThen since $\\mathcal{P}_{n_0}$ converges to the decomposition into points as $n_0\\to+\\infty$, we conclude $\\lent_{a_n(t)}^{\\mu_X}(T)=+\\infty$.  Recalling that our system has rank at most $2$, our estimates and the bounds on the polynomial lower slow entropy in Ferenczi \\cite[Proposition 5]{Fe} and Kanigowski \\cite[Proposition 1.3]{Kanigowski} show that the rank of our system is exactly $2$. This completes the proof of Theorem \\ref{thm:slowentropyFiniterank}.\r\n\r\n\\section{Slow entropy of rigid transformations}\\label{sec:rigidConstruction}\r\n\r\n\r\n\\subsection{Combinatorics of the conjugation map} \\label{subsec:combin}\r\nFor the construction we briefly review the symbolic representation of AbC transformations from \\cite{FW1} and \\cite{K}. Here, our constructions can be viewed as taking place on $\\mathbb{T}^2=\\R^2 / \\Z^2$, $\\mathbb{D}$ or $\\mathbb{A}=\\mathbb{S}^1\\times [0,1]$. For this purpose, we introduce the following notation with $q,s\\in \\Z^+$:\r\n\\begin{align*}\r\n& \\Delta_{q,s} := \\{(x,y)\\in \\S^1\\times [0,1) :0\\leq x  < \\frac{1}{q}, 0\\leq y < \\frac{1}{s}\\},\\\\\r\n& \\Delta_{q,s}^{i,j} := \\{(x,y)\\in \\S^1\\times [0,1) :(x,y)=\\big(x'+\\frac{i}{q},y'+\\frac{j}{s}\\big)\\text{ for some }(x',y')\\in \\Delta_{q,s}\\}.\r\n\\end{align*}\r\n\r\nWe collect the above sets to form the following partition\r\n\\begin{align*}\r\n& \\xi_{q, s} =\\{\\Delta_{q,s}^{i,j}: 0\\leq i< q,\\; 0\\leq j< s\\}.\r\n\\end{align*}\r\nEach transformation $T$ in Theorems \\ref{theo:rigidUpper} and \\ref{theo:rigidLower} is obtained as a limit of an \\emph{untwisted} AbC construction $T_n=H_n \\circ R_{\\alpha_{n+1}}\\circ H^{-1}_n$, i.e. $h_n\\left( \\Delta_{q_n,1}\\right)=\\Delta_{q_n,1}$. We use three sequences of parameters $(k_n)_{n\\in\\N}$, $(l_n)_{n\\in\\N}$, and $(s_n)_{n\\in\\N}$. In particular, we suppose that $k_n$ as well as $s_n$ are multiples of $s_{n-1}$. In our application $k_n$ will be chosen large enough to satisfy some requirements determined by the lemmas in Section \\ref{sec:probabilisticLemma}. Moreover, we will choose $h_n$ as a measure preserving translation permuting $\\xi_{k_nq_n,s_n}$, i.e. it takes atoms of the form $\\Delta_{k_nq_n,s_n}^{i,j}$ to atoms $\\Delta_{k_nq_n,s_n}^{i',j'}$. Clearly, $h_n$ is determined by its action on $\\Delta_{q_n,1}$ since it commutes with $R_{\\alpha_n}$. We also state some requirements on the action of $h_n$ that guarantee ergodicity of our limit transformation $T$ (see \\cite[Theorem 58]{FW1}):\r\n\\begin{itemize}\r\n\t\\item[(R1)] The sequence $s_n$ tends to $\\infty$.\r\n\t\\item[(R2)] Strong uniformity: For each $\\Delta^{0,j}_{q_{n-1},s_{n-1}}\\in \\xi_{q_{n-1},s_{n-1}}$ and each $s<s_n$ we have that the cardinality of\r\n\t\\[\r\n\t\\Meng{t<k_n}{h_n \\left( \\Bigg[\\frac{t}{k_nq_n},\\frac{t+1}{k_nq_n}\\Bigg) \\times \\Bigg[\\frac{s}{s_n},\\frac{s+1}{s_n}\\Bigg) \\right)\\subseteq \\Delta^{0,j}_{q_{n-1},s_{n-1}}}\r\n\t\\]\r\n\tis $\\frac{k_n}{s_n}$.\r\n\t\\item[(R3)] Given $s<s_n$ we can associate a $k_n$-tuple $\\left(j_0,j_1,\\dots,j_{k_n-1}\\right)_s$ such that\r\n\t\\[\r\n\th_n\\left( \\Bigg[\\frac{t}{k_nq_n},\\frac{t+1}{k_nq_n}\\Bigg) \\times \\Bigg[\\frac{s}{s_n},\\frac{s+1}{s_n}\\Bigg) \\right) \\subseteq \\Delta^{0,j_t}_{q_{n-1},s_{n-1}}\r\n\t\\]\r\n\tfor all $0\\leq t<k_n$. Then we assume that the map $s \\mapsto \\left(j_0,j_1,\\dots,j_{k_n-1}\\right)_s$ is one-to-one.\r\n\\end{itemize}\r\n\r\nTo give the symbolic representation of untwisted AbC transformations we inductively assume that the $T_{n-1}$-names with length $q_n$ of the tower bases $H_{n-1} (\\Delta^{0,s}_{q_n,s_{n-1}})$, $0\\leq s<s_{n-1}$, are $u_0,\\dots , u_{s_{n-1}-1}$. Then for each $0\\leq s^{\\ast}<s_{n}$ we define a sequence of words $w_0,\\dots , w_{k_n -1}$ by setting $w_j=u_s$ iff\r\n\\[\r\nh_n\\left( \\Big[\\frac{j}{k_nq_n}, \\frac{j+1}{k_nq_n} \\Big) \\times \\Big[\\frac{s^{\\ast}}{s_n}, \\frac{s^{\\ast}+1}{s_n}\\Big) \\right) \\subseteq \\Delta^{0,s}_{q_{n}, s_{n-1}}.\r\n\\]\r\nThen according to \\cite[section 7]{FW1} the $T_n$-name with length $k_nl_nq^2_n=q_{n+1}$ of the tower $H_n(\\Delta^{0,s^{\\ast}}_{q_{n+1}, s_n})$ is given by\r\n\\begin{equation}\\label{eq:circularOperator}\r\n\\mathcal{C}_n(w_0,\\dots,w_{k_n-1}) \\coloneqq \\prod^{q_n -1}_{i=0} \\prod^{k_n-1}_{j=0} \\left(b^{q_n-j_i} w^{l_n-1}_j e^{j_i}\\right),\r\n\\end{equation}\r\nwhere $b,e$ are so-called spacer symbols and $j_i \\in \\{0,\\dots , q_n-1\\}$ such that $j_i \\equiv (p_n)^{-1}i \\mod q_n$.\r\n\r\nWe also add the following well-known fact for AbC transformations.\r\n\\begin{lemma} \\label{lem:rig}\r\n\tLet $T$ be constructed by the abstract AbC method with any sequence $(l_n)_{n\\in\\N}$ such that $\\sum_{n\\in \\N}\\frac{1}{l_n}<\\infty$. Then $T$ is rigid along the sequence $(q_n)_{n\\in\\N}$.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tLet $A\\subseteq X$ be any measurable set and $\\varepsilon>0$. Since the sequence $\\{\\eta_m\\}_{m\\in \\N}$ of partitions $\\eta_m\\coloneqq H_m\\left(\\xi_{k_mq_m,s_m}\\right)$ is generating, there is $N\\in \\N$ such that for all $n\\geq N$ we can $\\varepsilon$-approximate $A$ by a union of sets in $\\eta_n$. We also note that for $t\\leq q_{n}$ and $n$ sufficiently large we have by our assumption on the sequence $(l_n)_{n\\in\\N}$ that\r\n\t\\begin{align*}\r\n\t\\sum_{c\\in \\eta_n} \\mu\\left(T^t(c)\\triangle T^t_{n-1}(c)\\right) & \\leq  \\sum_{i=n}^{\\infty}\\sum_{c\\in \\eta_i} \\mu\\left(T^t_{i}(c)\\triangle T^t_{i-1}(c)\\right) \\\\\r\n\t& = \\sum_{i=n}^{\\infty}\\sum_{c\\in \\eta_i} \\mu\\left(H_{i}R^t_{\\alpha_{i+1}}H^{-1}_i(c)\\triangle H_{i-1} \\circ h_i \\circ R^t_{\\alpha_i} \\circ h^{-1}_i \\circ H^{-1}_{i-1}(c)\\right) \\\\\r\n\t& = \\sum_{i=n}^{\\infty}\\sum_{\\tilde{c}\\in \\xi_{k_iq_i,s_i}} \\mu\\left(R^t_{\\alpha_{i+1}-\\alpha_i}(\\tilde{c})\\triangle \\tilde{c}\\right) \\\\\r\n\t& \\leq \\sum_{i=n}^{\\infty}\\frac{t}{l_{i}q_{i}} < \\sum_{i=n}^{\\infty}\\frac{1}{l_{i}} < \\varepsilon\r\n\t\\end{align*}\r\nwhere the first equality is due to $h_i\\circ R_{\\alpha_i}=R_{\\alpha_i}\\circ h_i$. Since $T^{q_{n}}_{n-1}=\\text{id}$, we conclude $\\mu\\left(T^{q_n}(A)\\triangle A\\right)<2\\varepsilon$. This yields the rigidity of $T$.\r\n\\end{proof}\r\n\r\n\\begin{remark} \\label{rem:safety}\r\n\tWhen moving from the partition element $\\Delta^{i,j}_{k_nq_n,s_n}$ to $\\Delta^{i+1,j}_{k_nq_n,s_n}$ the mapping behavior of $h_n$ changes instantly. To keep control of the orbit of $T^t_n$ compared to $T^t_{n-1}$ for small numbers of iterates $t\\leq q_n$ we introduce the sets\r\n\t\\[\r\n\t\\overline{\\Delta}^{i,j}_{k_nq_n,s_n} =\\Bigg[ \\frac{i}{k_nq_n}, \\frac{i+1}{k_nq_n}-\\frac{2}{k_nl_nq_n} \\Bigg) \\times \\Bigg[\\frac{j}{s_n}, \\frac{j+1}{s_n} \\Bigg).\r\n\t\\]\r\n\tSince $t\\cdot \\abs{\\a_{n+1}-\\a_n}\\leq \\frac{1}{k_nl_nq_n}$, for any point $P\\in \\overline{\\Delta}^{i,j}_{k_nq_n,s_n}$ the images $T^t_n(P)$ and $T^t_{n-1}(P)$ lie in the same element $\\Delta^{i',j'}_{k_nq_n,s_n}$.\r\n\t\r\n\tThen we define\r\n\t\\[\r\n\t\\Theta_n \\coloneqq \\bigcup_{0\\leq i<k_nq_n}\\bigcup_{0\\leq j <s_n} \\overline{\\Delta}^{i,j}_{k_nq_n,s_n}\r\n\t\\]\r\n\tand call it the \\emph{safe domain}.\r\n\t\r\n\tSimilarly, to compare the orbits of $T^t$ and $T^t_{n-1}$ for small numbers of iterates $t\\leq q_n$ we define for $m\\geq n$ the sets\r\n\t\\[\r\n\t\\tilde{\\Delta}^{i,j}_{k_mq_m,s_m} =\\Bigg[ \\frac{i}{k_mq_m}, \\frac{i+1}{k_mq_m}-\\frac{2q_n}{k_ml_mq^2_m} \\Bigg) \\times \\Bigg[\\frac{j}{s_m}, \\frac{j+1}{s_m} \\Bigg)\r\n\t\\]\r\n\tand its union\r\n\t\\[\r\n\t\\Xi_{n,m} \\coloneqq \\bigcup_{0\\leq i<k_mq_m}\\bigcup_{0\\leq j <s_m} \\tilde{\\Delta}^{i,j}_{k_mq_m,s_m}.\r\n\t\\]\r\n\tNote that $\\Xi_{n,n}=\\Theta_n$. Hereby, we define\r\n\t\\[\r\n\t\\Xi_n \\coloneqq \\bigcap_{m\\geq n} \\Xi_{n,m}.\r\n\t\\]\r\n\tThen we note that for any $0\\leq t\\leq q_n$ and any point $P\\in \\Delta^{i,j}_{k_nq_n,s_n}\\cap \\Xi_n$ the images $T^t(P)$ and $T^t_{n-1}(P)$ lie in the same element $\\Delta^{i',j'}_{k_nq_n,s_n}$.\r\n\t\r\n\tWe note that $\\mu\\left(\\Xi_{n,m}\\right) \\geq  1-\\frac{2}{l_m}$. Under the assumption $\\sum_{m\\in \\N}\\frac{1}{l_m}<\\infty$ this yields for any given $\\delta>0$ that $\\mu\\left(\\Xi_n  \\right)>1-\\delta$ for $n$ sufficiently large.\r\n\\end{remark}\r\n\r\n\r\n\r\n\r\n\r\n\\subsection{Proof of Theorem \\ref{theo:rigidUpper}}\r\nLet $0 < u <\\infty$. We want to construct an ergodic rigid transformation $T$ with $\\uent^{\\mu}_{n^t}(T)=u$. For a start, we choose a sequence $(\\epsilon_n)_{n\\in \\N}$ of quickly decreasing positive numbers satisfying\r\n\\begin{equation} \\label{eq:eps1}\r\n\\prod^{\\infty}_{n=1}(1-\\epsilon_n)>\\frac{1}{2}.\r\n\\end{equation}\r\nThe parameter sequences $(k_m)_{m\\in\\N}$, $(l_m)_{m\\in\\N}$, and $(s_m)_{m\\in\\N}$ are defined inductively. Assume that they have been defined up to $m=n-1$. Notice that this also determines the number $q_n=k_{n-1}l_{n-1}q^2_{n-1}$. Then we apply Lemma \\ref{lem:prob} with $\\varepsilon=\\frac{1}{s^2_{n-1}}$, alphabet $\\Sigma=\\{0,1,\\dots,s_{n-1}-1\\}$, and subexponential sequence $\\{b_k\\}_{k\\in \\N}=\\{k^{q_n+1}\\}_{k\\in \\N}$. According to this we choose $k_n$ as a multiple of $s_{n-1}$ and sufficiently large such that there are at least $\\lfloor \\frac{4}{\\epsilon_n}k^{q_n}_n q^{2u}_n  \\rfloor s_{n-1}$ many \\emph{good words} satisfying all the properties of Lemma \\ref{lem:prob}. Then we set\r\n\\begin{equation}\\label{eq:s1}\r\ns_n=\\lfloor \\frac{4}{\\epsilon_n}k^{q_n}_n q^{2u}_n \\rfloor \\cdot s_{n-1}.\r\n\\end{equation}\r\nAs adumbrated before, $s_n$ is a multiple of $s_{n-1}$ and (R1) is satisfied. The collection of good words determines the combinatorics of the conjugation map $h_n$. In particular, property (1) from Lemma \\ref{lem:prob} gives (R2) and property (2) implies (R3). Thus, $T$ is ergodic by \\cite[Theorem 58]{FW1}. Finally, we set\r\n\\begin{equation}\\label{eq:l1}\r\nl_n=\\lfloor \\frac{4}{\\epsilon_n} \\left(k_{n}\\right)^{\\frac{q_n}{u}} \\rfloor.\r\n\\end{equation}\r\nClearly, $\\sum_{n\\in \\N} \\frac{1}{l_n} <\\infty$ which implies that $T$ is a rigid transformation by Lemma \\ref{lem:rig}.\r\n\r\nTo compute the upper measure-theoretic slow entropy we use the Proposition \\ref{prop:generatingSequence} with the generating sequence $\\{\\eta_m\\}_{m\\in \\N}$ of partitions $\\eta_m\\coloneqq H_m\\left(\\xi_{k_mq_m,s_m}\\right)$. Recall that $S(\\eta_m,t,\\epsilon)$ and $N(\\eta_m,t,2\\epsilon)$ is defined in Section \\ref{sec:slowentropy}, then we have:\r\n\r\n\\begin{lemma}\\label{lem:lower1}\r\n\tLet $0<\\varepsilon<\\frac{1}{2}$ and $m\\in \\N$. For $n>m$ we have\r\n\t\\[\r\n\tS\\left(\\eta_m, q_{n+1},\\epsilon\\right)\\geq s_n.\r\n\t\\]\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tWe show this inductively starting with $n=m+1$. For any $0\\leq i <k_nq_n$ and $0\\leq j<s_{n}$ we define the set\r\n$$A^{(n)}_{i,j}=\\Delta^{i,j}_{k_nq_n,s_n}\\cap \\Xi_n,$$\r\nthen we claim that points $P_1=(x,y_1) \\in H_n\\left(A^{(n)}_{i,j_1}\\right)$ and $P_2=(x,y_2) \\in H_n\\left(A^{(n)}_{i,j_2}\\right)$ with $j_1\\neq j_2$ are $\\left(1-\\frac{2}{s_{n-1}},q_{n+1}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$. To see this we note that for every $t\\leq q_{n+1}$ the images $T^t\\left(H_n\\left(A^{(n)}_{i,j}\\right)\\right)$ and $T^t_n\\left(H_n\\left(A^{(n)}_{i,j}\\right)\\right)$ lie in the same element $\\Delta^{i',j'}_{k_nq_n,s_n}$ by Remark \\ref{rem:safety}. Then we use that for the map $T_n$ the points from $H_n\\left(A^{(n)}_{i,j_1}\\right)$ and $H_n\\left(A^{(n)}_{i,j_2}\\right)$ with $j_1\\neq j_2$ are $\\left(1-\\frac{2}{s_{n-1}},q_{n+1}\\right)$-Hamming apart from each other by the second property of Lemma \\ref{lem:prob} describing the combinatorics of $h_n$.\r\n\t\r\n\tIn the inductive step, we suppose that for some $n>m$ points  $(x,y_1) \\in H_n\\left(A^{(n)}_{i,j_1}\\right)$ and $(x,y_2) \\in H_n\\left(A^{(n)}_{i,j_2}\\right)$ with $j_1\\neq j_2$ are $\\left(\\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{2}{l_{i}}\\right),q_{n+1}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$, where the sets $A^{(n)}_{i,j}$ are defined as above for any $0\\leq i <k_nq_n$ and $0\\leq j<s_{n}$. Then we consider the sets $A^{(n+1)}_{v,w}$ for $0\\leq v <k_{n+1}q_{n+1}$ and $0\\leq w<s_{n+1}$. Once again, we use the second property of Lemma \\ref{lem:prob} to see that points $(x^{\\prime},y^{\\prime}_1)$ from $A^{(n+1)}_{v,w_1}$ and $(x^{\\prime},y^{\\prime}_2)$ from $A^{(n+1)}_{v,w_2}$ with $w_1\\neq w_2$ have $\\{h_{n+1}\\circ R^t_{\\alpha_{n+2}}\\}_{0\\leq t \\leq q_{n+2}}$-trajectories that are $1-\\frac{2}{s_n}$ apart from each other with respect to the alphabet $\\{0,1,\\dots,s_n -1\\}$ labeling the $j$-coordinate in $A^{(n)}_{i,j}$. We also note that for at most $\\frac{2q_{n+2}}{l_n}$ many $t\\leq q_{n+2}$ we have that $h_{n+1}\\circ R^t_{\\alpha_{n+2}}(A^{(n+1)}_{v,w_1})$ or $h_{n+1}\\circ R^t_{\\alpha_{n+2}}(A^{(n+1)}_{v,w_2})$ do not lie in the safe domain of $h_n$. Along the other iterates we can apply the induction assumption. Altogether this yields that for the map $T_{n+1}$ points $(x,y_1) \\in H_{n+1}\\left(A^{(n+1)}_{v,w_1}\\right)$ and $(x,y_2) \\in H_{n+1}\\left(A^{(n+1)}_{v,w_2}\\right)$ with $w_1\\neq w_2$ are $\\left(\\prod^{n}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{2}{l_{i}}\\right),q_{n+2}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$. Since for every $t\\leq q_{n+2}$ the images $T^t\\left(H_{n+1}\\left(A^{(n+1)}_{v,w}\\right)\\right)$ and $T^t_{n+1}\\left(H_{n+1}\\left(A^{(n+1)}_{v,w}\\right)\\right)$ lie in the same element $\\Delta^{i',j'}_{k_{n+1}q_{n+1},s_{n+1}}$ by Remark \\ref{rem:safety}, this finishes the proof of the induction step.\r\n\t\r\n\tSince $\\frac{2}{s_i}+\\frac{2}{l_{i}}<\\epsilon_i$ by (\\ref{eq:s1}) and (\\ref{eq:l1}), assumption (\\ref{eq:eps1}) implies $\\prod^{\\infty}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{2}{l_{i}}\\right)>\\varepsilon$.\r\n\\end{proof}\r\n\r\n\\begin{lemma}\\label{lem:upper1}\r\n\tLet $\\varepsilon>0$ and $m\\in \\N$. For $n$ sufficiently large and $\\frac{\\varepsilon}{2} l_nq_n\\leq L<\\frac{\\varepsilon}{2} l_{n+1}q_{n+1}$ we have\r\n$$N\\left(\\eta_m, L,\\epsilon\\right)\\leq \\frac{2}{\\varepsilon^2}k_n q_n s_n.$$\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tFor any $n\\in \\N$, $0\\leq i_1 <k_n q_n$, and $0\\leq i_2 <s_n$ we define the sets\r\n\t\\[\r\n\t\\tilde{\\Delta}_{i_1,i_2}=\\Bigg[ \\frac{i_1}{k_nq_n}, \\frac{i_1 +1-\\frac{\\varepsilon}{2}}{k_n q_n} \\Bigg) \\times \\Bigg[\\frac{i_2}{s_n}, \\frac{i_2 +1}{s_n} \\Bigg)\r\n\t\\]\r\n\tand its union\r\n\t\\[\r\n\t\\Theta_{n,\\varepsilon} \\coloneqq \\bigcup_{0\\leq i_1 <k_n q_n} \\bigcup_{0\\leq i_2 <s_n}\\tilde{\\Delta}_{i_1,i_2}.\r\n\t\\]\r\n\tWe note that the sets $\\tilde{\\Delta}_{i_1,i_2}$ are defined in this way to guarantee that for any point $P\\in \\tilde{\\Delta}_{i_1,i_2}$ and all $0\\leq t <\\frac{\\varepsilon}{2} l_nq_n$ the images $T^t_n(P)$ and $T^t_{n-1}(P)$ lie in the same element $\\Delta^{i',j'}_{k_nq_n,s_n}$.\r\n\t\r\n\tHereby, we define for $0\\leq j_1<k_nq_n$, $0\\leq j_2 < \\lfloor \\frac{2}{\\varepsilon^2} \\rfloor$, and $0\\leq j_3<s_n$ the sets\r\n\t\\[\r\n\tB_{j_1,j_2,j_3} = \\Bigg[\\frac{j_1}{k_nq_n}+\\frac{j_2 \\cdot \\varepsilon^2 }{2k_nq_n},\\frac{j_1}{k_nq_n}+\\frac{(j_2 +1) \\cdot \\varepsilon^2 }{2k_nq_n} \\Bigg) \\times \\Bigg[ \\frac{j_3}{s_n}, \\frac{j_3 +1}{s_n} \\Bigg) \\cap \\Theta_{n+1,\\varepsilon} \\cap  \\Xi_{n+2},\r\n\t\\]\r\nwhere the intersection with $\\Theta_{n+1,\\varepsilon}$ guarantees that $T_{n+1}^t(P)$ and $T_{n}^t(P)$ lie in the same atom for $t\\in[0,\\frac{\\epsilon}{2}l_nq_n]$ and the intersection with $\\Xi_{n+2}$ guarantees that $T^t(P)$ and $T^t_{n+1}(P)$ lie in the same atom for $0\\leq t\\leq q_{n+2}$ by Remark \\ref{rem:safety}.\r\n\r\n\tFor $n$ sufficiently large the union of all these sets $B_{j_1,j_2,j_3}$ covers a measure of at least $1-\\varepsilon$ of the space. Since points within one set $B_{j_1,j_2,j_3}$ stay $(\\varepsilon,L)$-Hamming close for $\\frac{\\varepsilon}{2} l_{n}q_{n}\\leq L<\\frac{\\varepsilon}{2} l_{n+1}q_{n+1}$, we conclude the statement.\r\n\\end{proof}\r\n\r\n\\begin{remark}\\label{rem:IndepCombi}\r\n\tWe conclude from its proof that the statement of Lemma \\ref{lem:upper1} is independent of the combinatorics of the conjugation map $h_n$.\r\n\\end{remark}\r\n\r\nAltogether we can compute the upper measure-theoretic slow entropy of $T$.\r\n\\begin{lemma}\r\n\tWe have $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tOn the one hand, we see with the aid of Lemma \\ref{lem:lower1} that\r\n\t\\begin{equation*}\r\n\t\\limsup_{N\\to \\infty} \\frac{S\\left(\\eta_m,N,\\epsilon\\right)}{N^t} \\geq \\limsup_{n\\to \\infty} \\frac{S\\left(\\eta_m,q_{n+1},\\varepsilon\\right)}{q^t_{n+1}} \\geq \\lim_{n\\to \\infty} \\frac{s_n}{\\left(k_nl_nq^2_n\\right)^t}\r\n\t\\geq \\lim_{n\\to \\infty} \\frac{\\epsilon^t_n \\cdot k^{q_n}_n \\cdot q^{2u}_n}{4^t \\cdot \\left(k_n\\right)^{t+q_n\\frac{t}{u}}\\cdot q^{2t}_n},\r\n\t\\end{equation*}\r\nwhich is positive for all $t<u$. This yields $\\uent^{\\mu}_{n^t}(T)\\geq u$.\r\n\r\nOn the other hand, \\eqref{eq:CoveringSeparated} and Lemma \\ref{lem:upper1} implies that\r\n\\begin{equation}\r\n\\begin{aligned}\r\n\\limsup_{L\\to \\infty} \\frac{S\\left(\\eta_m,L,\\epsilon\\right)}{L^t}&\\leq\r\n\\limsup_{L\\to \\infty} \\frac{N\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} \\leq \\lim_{n\\to \\infty} \\frac{\\frac{2}{\\varepsilon^2}k_n q_n s_n}{\\left(\\frac{\\varepsilon}{2} l_{n}q_{n}\\right)^t}\\\\  &\\leq \\lim_{n\\to \\infty} \\frac{8\\epsilon^{t-1}_n k^{q_n+1}_n q^{2u+1}_n s_{n-1}}{\\varepsilon^{t+2} \\left(k_n\\right)^{q_n\\frac{t}{u}}q^{t}_n},\r\n\\end{aligned}\r\n\\end{equation}\r\nwhich is zero for all $t> u$.\r\n\r\nAltogether, we obtain $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{proof}\r\n\r\nFor any given subexponential scale $a_n(t)$ the existence of an ergodic rigid transformation $T$ with $\\uent^{\\mu}_{a_n(t)}(T)=\\infty$ follows from the stronger Theorem \\ref{theo:rigidLowerInf} in the next subsection. This finishes the proof of Theorem \\ref{theo:rigidUpper}.\r\n\r\n\r\n\\subsection{Proof of Theorem \\ref{theo:rigidLower}}\r\n\r\nWe present the construction in the two cases $\\lent^{\\mu}_{n^t}(T)=u<\\infty$ or $\\lent^{\\mu}_{n^t}(T)=\\infty$.\r\n\r\n\\subsubsection{Case 1: $\\lent^{\\mu}_{n^t}(T)=u<\\infty$}\r\nWe start by constructing a rigid transformation with $\\lent^{\\mu}_{n^t}(T)=u$ for some $0<u<\\infty$.\r\n\r\nAs before, we choose a sequence $(\\epsilon_n)_{n\\in \\N}$ of quickly decreasing positive numbers satisfying\r\n\\begin{equation} \\label{eq:eps2}\r\n\\prod^{\\infty}_{n=1}(1-\\epsilon_n)>\\frac{1}{2}\r\n\\end{equation}\r\nand the parameter sequences $(k_m)_{m\\in\\N}$, $(l_m)_{m\\in\\N}$, and $(s_m)_{m\\in\\N}$ are defined inductively. Assume that they have been defined up to $m=n-1$ which also determines the number $q_n=k_{n-1}l_{n-1}q^2_{n-1}$. Furthermore, we assume\r\n\\[\r\nk_{n-1} \\geq K_1\\left(\\{ k^{q_{n-1}u}\\}_{k\\in \\N},s_{n-2},\\frac{1}{s^2_{n-2}}\\right),\r\n\\]\r\nwhere we recall its definition from Remark \\ref{rem:kForCLT}.\r\n\r\nIn the next step, we set\r\n\\begin{equation} \\label{eq:l2}\r\nl_n = \\lfloor \\frac{6}{\\epsilon_n}\\cdot (k_{n-1})^{q_{n-1}-1} \\rfloor.\r\n\\end{equation}\r\nWe apply Lemma \\ref{lem:prob2} with $s=s_{n-2}$,  $\\varepsilon=\\frac{1}{s^2_{n-1}}$, alphabet $\\Sigma=\\{0,1,\\dots, s_{n-1} -1\\}$, and subexponential sequences $\\{b_k\\}_{k\\in \\N} = \\{k^{q_{n-1}u}\\}_{k\\in \\N}$ and $\\{c_k\\}_{k\\in \\N} = \\{ k^{q_n u}\\}_{k\\in \\N}$. Let $L_0$ be the resulting threshold. Then we choose\r\n\\begin{equation}\\label{eq:k2}\r\nk_n \\geq \\max\\left( L_0 , K_1\\left(\\{k^{q_n u}\\}_{k\\in \\N},s_{n-1},\\frac{1}{s^2_{n-1}}\\right),\\frac{4}{\\epsilon_{n}}\\right)\r\n\\end{equation}\r\nas a multiple of $s_{n-1}$ and such that\r\n\\begin{equation}\\label{eq:s2}\r\ns_n =\\lfloor (k_{n})^{q_{n}u}\\rfloor\r\n\\end{equation}\r\nis a multiple of $s_{n-1}$. We also denote the corresponding value of $\\gamma$ from Lemma \\ref{lem:prob2} by $\\gamma_n$. Moreover, the collection of words $\\Theta$ with cardinality $|\\Theta | =s_n$ constructed in Lemma \\ref{lem:prob2} determines the combinatorics of the conjugation map $h_n$. This finishes the construction in the inductive step.\r\n\r\nTo estimate the lower measure-theoretic slow entropy via Proposition \\ref{prop:generatingSequence}, we make the following observation with regard to the generating sequence $\\{\\eta_m=H_m\\left(\\xi_{k_mq_m,s_m}\\right)\\}_{m\\in \\N}$.\r\n\\begin{lemma}\\label{lem:lower2}\r\n\tLet $0<\\varepsilon <\\frac{1}{2}$ and $m\\in \\N$. For $n>m$ we have\r\n\t\\[\r\n\tS\\left(\\eta_{m},N,\\varepsilon\\right)\\geq\\begin{cases}\r\n\ts_{n-1} & \\text{for }q_{n}\\leq N<k_{n-1}l_{n}q_{n},\\\\\r\n\t\\lfloor j^{q_{n-1}u} \\rfloor & \\text{for }jl_{n}q_{n} \\leq N <(j+1)l_nq_n,\\text{ where }k_{n-1}\\leq j<\\gamma_{n}k_{n},\\\\\r\n\ts_{n} & \\text{for }\\gamma_{n}k_{n}l_{n}q_{n}\\leq N<k_{n}l_{n}q_{n}^{2}=q_{n+1}.\r\n\t\\end{cases}\r\n\t\\]\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\nWe consider for any $0\\leq i<k_nq_n$, $0\\leq j<s_{n}$ the set\r\n\\[\r\nA^{(n)}_{i,j}=\\overline{\\Delta}^{i,j}_{k_nq_n,s_n}\\cap \\Xi_n.\r\n\\]\r\nWe recall that for every $i\\leq N \\leq q_{n+1}$ the images $T^i\\left(H_n\\left(A^{(n)}_{i,j}\\right)\\right)$ and $T^i_n\\left(H_n\\left(A^{(n)}_{i,j}\\right)\\right)$ lie in the same element $\\Delta^{i',j'}_{k_nq_n,s_n}$ by Remark \\ref{rem:safety}. As in the proof of Lemma \\ref{lem:lower1} we show inductively that for every $n>m$ points $P_1 =(x,y_1) \\in H_n\\left(A^{(n)}_{i,j_1}\\right)$ and $P_2=(x,y_2) \\in H_n\\left(A^{(n)}_{i,j_2}\\right)$ with $j_1 \\neq j_2$ are $\\left(\\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right),q_{n+1}\\right)$-Hamming apart from each other for the map $T_n$ with respect to the partition $\\eta_m$. Here, we recall that for the map $T_n$ the trajectories from different $H_n\\left(A^{(n)}_{i,j}\\right)$ are determined by the properties of Lemma \\ref{lem:prob2} describing the combinatorics of $h_n$. Hence, Lemma \\ref{lem:prob2} also describes the combinatorics for the different $A^{(n+1)}_{v, w}$ under $\\{h_{n+1}\\circ R^t_{\\alpha_{n+2}}\\}_{0\\leq t \\leq N}$ with respect to the alphabet $\\{0,1,\\dots,s_{n} -1\\}$ labeling the $j$-coordinate in $A^{(n)}_{i,j}$. We also use that for at most $\\frac{3N}{l_n}$ many $t\\leq N \\leq q_{n+2}$ we have that $h_{n+1}\\circ R^t_{\\alpha_{n+2}}(A^{(n+1)}_{v,w})$ does not lie in the safe domain of $h_n$.\r\n\\begin{itemize}\r\n\t\\item Part (4) of Lemma \\ref{lem:prob2} guarantees for each $q_{n+1}\\leq N <k_{n}l_{n+1}q_{n+1}$ that there are at least $s_{n}$ many $H_{n+1}\\left(A^{(n+1)}_{v,w}\\right)$ whose trajectories under $T_{n+1}$ are $$\\left(\\left(1-\\frac{3}{l_n}\\right)\\cdot \\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right),N\\right)$$-Hamming apart from each other with respect to the partition $\\eta_m$.\r\n\t\\item By part (3) of Lemma \\ref{lem:prob2} we have that for $jl_{n+1}q_{n+1} \\leq N <(j+1)l_{n+1}q_{n+1}$ with $k_{n}\\leq j < \\gamma_{n+1}k_{n+1}$ there are at least $\\lfloor j^{q_{n}u}\\rfloor $ many $H_{n+1}\\left(A^{(n+1)}_{v,w}\\right)$ whose trajectories under $T_{n+1}$ are $\\left(\\left(1-\\frac{2}{s_{n-1}}-\\frac{3}{l_n}\\right)\\cdot \\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right),N\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$.\r\n\t\\item Part (2) of Lemma \\ref{lem:prob2} yields that for every $\\gamma_{n+1}k_{n+1}l_{n+1}q_{n+1}\\leq N \\leq k_{n+1}l_{n+1}q_{n+1}$ there are at least $s_{n+1}$ many $H_{n+1}\\left(A^{(n+1)}_{v,w}\\right)$ whose trajectories  under $T_{n+1}$ have Hamming distance $\\left(\\prod^{n}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right),N\\right)$ from each other with respect to the partition $\\eta_m$. Then for $k_{n+1}l_{n+1}q_{n+1}< N \\leq k_{n+1}l_{n+1}q^2_{n+1}=q_{n+2}$ the different strings coming from Lemma \\ref{lem:prob2} are repeated as in the symbolic representation in (\\ref{eq:circularOperator}). Since $\\gamma_{n+1}<\\varepsilon=\\frac{1}{s^2_n}$ we conclude that for every such $N$ the trajectories are $\\left(\\left(1-\\frac{3}{s_{n}}-\\frac{3}{l_{n}} \\right) \\cdot \\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right),N\\right)$-Hamming apart from each other.\r\n\\end{itemize}\r\nSince for every $i\\leq N\\leq q_{n+2}$ the images $T^i\\left(H_{n+1}\\left(A^{(n+1)}_{i_2,j_2}\\right)\\right)$ and $T^i_{n+1}\\left(H_{n+1}\\left(A^{(n+1)}_{i_2,j_2}\\right)\\right)$ lie in the same element $\\Delta^{i',j'}_{k_{n+1}q_{n+1},s_{n+1}}$ as recalled above and since we have using equations (\\ref{eq:l2}), (\\ref{eq:k2}), and (\\ref{eq:s2}) that\r\n\\begin{align*}\r\n\\left(1-\\frac{3}{s_{n}}-\\frac{3}{l_{n}}\\right) \\cdot \\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right) & \\geq \\left(1-\\frac{2}{s_{n-1}}-\\frac{3}{l_{n}}\\right)\\cdot \\prod^{n-1}_{i=m}\\left(1-\\frac{2}{s_{i}}-\\frac{3}{l_{i}}\\right) \\\\\r\n& \\geq \\prod^{n-1}_{i=m}\\left(1-\\frac{4}{s_{i}}-\\frac{6}{l_{i}}\\right) \\\\\r\n& \\geq\\prod^{n-1}_{i=m}\\left(1-\\epsilon_i\\right) >\\varepsilon\r\n\\end{align*}\r\nby our assumption (\\ref{eq:eps2}), we conclude the proof.\r\n\\end{proof}\t\r\n\r\nHereby, we can compute the lower measure-theoretic polynomial entropy of $T$.\r\n\\begin{lemma} \\label{lem:rigidLowerExact}\r\n\tWe have $\\lent^{\\mu}_{n^t}(T)=u$.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tOn the one hand, we investigate\r\n$$\\liminf_{N\\to \\infty}\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}\t$$\r\nby examining the three different cases in the statement of Lemma \\ref{lem:lower2}. In case of $q_n \\leq N<k_{n-1}l_nq_n$ we see\r\n$$ \\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}\\geq \\frac{s_{n-1}}{\\left(k_{n-1}l_nq_n\\right)^t} \\geq  \\frac{(k_{n-1})^{q_{n-1}u}}{2 \\cdot \\left(\\frac{6}{\\epsilon_n} \\cdot (k_{n-1})^{q_{n-1}+1} \\cdot l_{n-1} \\cdot q^2_{n-1}\\right)^t},$$\r\nwhose limit is positive for all $t<u$. Similarly, for $k_{n-1}l_nq_n\\leq N< \\gamma_n k_n l_nq_n$ written as $N=jl_nq_n$ we have\r\n$$\t\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}\\geq \\frac{j^{q_{n-1}u}}{2 \\cdot \\left((j+1) l_nq_n\\right)^t} \\geq \\frac{j^{u} \\cdot (k_{n-1})^{(q_{n-1}-1)u}} {2 \\cdot \\left((j+1)\\cdot \\frac{6}{\\epsilon_n} \\cdot (k_{n-1})^{q_{n-1}}\\cdot l_{n-1} \\cdot q^2_{n-1}\\right)^t},$$\r\nwhose limit is also positive for all $t<u$. Clearly, in the remaining case $\\gamma_n k_n l_nq_n \\leq N <q_{n+1}$ the limit is positive for all $t<u$ as well. Altogether, this yields $\\lent^{\\mu}_{n^t}(T)\\geq u$.\r\n\t\r\n\tOn the other hand, as observed in Remark \\ref{rem:IndepCombi} we can apply \\eqref{eq:CoveringSeparated} and Lemma \\ref{lem:upper1} again, which yields.\r\n\\begin{equation}\r\n\\begin{aligned}\r\n\\liminf_{L\\to \\infty} \\frac{S\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} &\\leq\\liminf_{L\\to \\infty} \\frac{N\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} \\leq \\lim_{n\\to \\infty} \\frac{\\frac{2}{\\varepsilon^2}k_n q_n s_n}{\\left(\\frac{\\varepsilon}{2} l_{n+1}q_{n+1}\\right)^t}  \\\\&\\leq \\lim_{n\\to \\infty} \\frac{2\\epsilon^t_{n+1} \\cdot k_n \\cdot (k_{n})^{q_{n}u}  \\cdot q_n}{\\varepsilon^{t+2} \\cdot\\left( (k_n)^{q_n} \\cdot l_{n} \\cdot q^2_n\\right)^t}.\r\n\\end{aligned}\r\n\\end{equation}\t\r\nThis is zero for all $t> u$.\r\n\t\r\n\tAltogether, we obtain $\\lent^{\\mu}_{n^t}(T)=u$.\r\n\\end{proof}\r\n\r\nThis finishes the proof of Theorem \\ref{theo:rigidLower} for $0<u<\\infty$.\r\n\r\n\\subsubsection{Case 2: $\\lent^{\\mu}_{n^t}(T)=\\infty$}\r\nTo cover the case $\\lent^{\\mu}_{n^t}(T)=\\infty$ we prove the following stronger statement.\r\n\r\n\\begin{theorem} \\label{theo:rigidLowerInf}\r\n\tFor any scaling function $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ satisfying $\\lim_{n\\to\\infty}\\frac{\\log a_n(t)}{n}=0$, there exists an ergodic Lebesgue measure preserving rigid transformation $T$ with $\\lent_{a_n(t)}^{\\mu}(T)=\\infty$.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\n\tIt suffices to prove the theorem for any scaling function $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ with at least polynomial growth. In particular, for any given $t_1 >0$ there exists $t_2>t_1$ such that $a_n(t_2)>a_{n^2}(t_1)$. To build a rigid ergodic transformation $T$ with $\\lent^{\\mu}_{a_n(t)}(T)=\\infty$ we follow the construction above but this time we will use an additional inductively defined sequence $(u_n)_{n\\in \\N}$ of parameters and we choose $l_n=n^2$ in advance. This choice guarantees $\\sum^{\\infty}_{n=1} \\frac{1}{l_n} <\\infty$ and, hence, rigidity of $T$ by Lemma \\ref{lem:rig}. For the inductive choice of the other parameters we proceed as follows. We assume that\r\n\t\\[\r\n\tk_{n-1} \\geq K\\left( \\{a_{(j+1)l_nq_{n-1}}(u_n)\\}_{j\\in \\N},s_{n-2}, \\frac{1}{s^2_{n-1}}\\right)\r\n\t\\]\r\n\tand that $u_n \\in \\Z^+$ is large enough such that $a_{m}(u_n) \\geq a_{m^2}(u_{n-1})$ for all $m\\in \\N$.\r\n\t\r\n\tWe start the inductive step by choosing an $u_{n+1}\\in \\Z^{+}$ such that $a_m(u_{n+1}) \\geq a_{m^2}(u_n)$ for all $m\\in \\N$. Then we apply Lemma \\ref{lem:prob2} with $s=s_{n-2}$,  $\\varepsilon=\\frac{1}{s^2_{n-1}}$, alphabet $\\Sigma=\\{0,1,\\dots, s_{n-1} -1\\}$, and subexponential sequences $\\{b_j\\}_{j\\in \\N} = \\{a_{(j+1)l_nq_{n-1}}(u_n)\\}_{j\\in \\N}$ and $\\{c_j\\}_{j\\in \\N} = \\{ a_{(j+1)l_{n+1}q_{n}}(u_{n+1})\\}_{j\\in \\N}$. Let $L_0$ be the resulting threshold. Then we choose\r\n\t\\begin{equation*}\r\n\tk_n \\geq \\max\\left( L_0 , K_1\\left(\\{ a_{(j+1)l_{n+1}q_{n}}(u_{n+1})\\}_{j\\in \\N},s_{n-1},\\frac{1}{s^2_{n-1}}\\right),\\frac{4}{\\epsilon_{n}}\\right)\r\n\t\\end{equation*}\r\n\tas a multiple of $s_{n-1}$ and such that\r\n\t\\begin{equation*}\r\n\ts_n \\coloneqq \\lfloor a_{k_n l_{n+1}q_n}(u_{n+1})\\rfloor\r\n\t\\end{equation*}\r\n\tis a multiple of $s_{n-1}$. We note that $a_{k_n l_{n+1}q_n}(u_{n+1}) \\geq a_{k^2_n l^2_{n+1}q^2_n}(u_{n}) \\geq a_{k_n l_{n+1}q_{n+1}}(u_{n})$.\r\n\t\r\n\tHereby, we investigate\r\n\t$$\\liminf_{N\\to \\infty}\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{a_n(t)}\t$$\r\n\tas in the proof of Lemma \\ref{lem:rigidLowerExact}. In case of $q_n \\leq N<k_{n-1}l_nq_n$ we see\r\n\t$$ \\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{a_N(t)}\\geq \\frac{s_{n-1}}{a_{k_{n-1}l_nq_n}(t)} \\geq  \\frac{a_{k_{n-1}l_n q_{n-1}}(u_n)}{2a_{k_{n-1}l_nq_n}(t)} \\geq  \\frac{a_{k_{n-1}l_n q_{n}}(u_{n-1})}{2a_{k_{n-1}l_nq_n}(t)}  ,$$\r\n\twhose limit is positive for all $t\\leq u_{n-1}$. Similarly, for $k_{n-1}l_nq_n\\leq N< \\gamma_n k_n l_nq_n$ written as $N=jl_nq_n$ we have\r\n\t$$\t\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{a_N(t)}\\geq \\frac{a_{(j+1)l_nq_{n-1}}(u_n)}{2 \\cdot a_{(j+1) l_nq_n}(t)} \\geq \\frac{a_{(j+1)l_nq_{n}}(u_{n-1})}{2 \\cdot a_{(j+1) l_nq_n}(t)},$$\r\n\twhose limit is also positive for all $t\\leq u_{n-1}$. In the remaining case $\\gamma_n k_n l_nq_n \\leq N <q_{n+1}$ we have\r\n\t$$\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{a_N(t)}\\geq \\frac{s_{n}}{a_{q_{n+1}}(t)} \\geq  \\frac{a_{k_n l_{n+1}q_n}(u_{n+1})}{2a_{k_{n}l_nq^2_n}(t)} >  \\frac{a_{k_n l_{n+1}q^2_n}(u_{n})}{2a_{k_{n}l_nq^2_n}(t)} $$\r\n\tand this limit is positive for all $t\\leq u_{n}$. Since $u_n \\to \\infty$ as $n\\to \\infty$, this yields $\\lent^{\\mu}_{a_n(t)}(T)=\\infty$.\r\n\\end{proof}\r\n\r\n\r\n\r\n\\section{Slow entropy for good cyclic approximations} \\label{sec:goodCyclic}\r\nThe previous section already provides examples of measure preserving transformations admitting a periodic approximation with positive or even infinite lower measure-theoretic polynomial entropy. In this section we examine one particular class of periodic approximations, the so-called good cyclic approximations. We recall their definition from Definition \\ref{def:cyclicApp}.\r\n\r\nOn the one hand, we know that the lower measure-theoretic polynomial entropy for a transformation with good cyclic approximation is at most one following from estimates in Proposition $5$ in \\cite{Fe} and Proposition 1.3 in \\cite{Kanigowski}:\r\n\\begin{proposition}\\label{prop:upperBoundLowerCyclic}\r\nIf $T:(X,\\mu)\\to (X,\\mu)$ admits a good cyclic approximation, then the lower measure-theoretic slow entropy with respect to the polynomial scale $a_n(t)=n^t$ is at most $1$.\r\n\\end{proposition}\r\nIn fact, we show that the above estimate is optimal by Theorem \\ref{theo:cyclicLower}:  every possible value in $[0,1]$ is attained by a transformation admitting a good cyclic approximation.\r\n%\\begin{theorem}\\label{theo:cyclicLower}\r\n%\tFor every $u\\in [0,1]$ there exists a Lebesgue measure preserving transformation $T$ with good cyclic approximation and $\\lent^{\\mu}_{n^t}(T)=u$.\r\n%\\end{theorem}\r\n\r\nOn the other hand, we are able to construct transformations admitting a good cyclic approximation with positive or even infinite upper measure-theoretic polynomial entropy in Theorem \\ref{theo:cyclicUpper}, which exhibits different features of upper and lower measure-theoretic slow entropy.\r\n\r\n%\\begin{theorem} \\label{theo:cyclicUpper}\r\n%\tFor every $u\\in [0,\\infty]$ there exists a Lebesgue measure preserving transformation $T$ with good cyclic approximation and $\\uent^{\\mu}_{n^t}(T)=u$.\r\n%\\end{theorem}\r\n\r\nAs for the proof Theorem \\ref{theo:cyclicUpper} and Theorem \\ref{theo:cyclicLower}, both constructions are based on a \\emph{twisted} abstract AbC method. For this purpose, we introduce further notation: For $0\\leq i<q$, $0\\leq j <k$ we define the ``stripes''\r\n\\begin{equation*}\r\n\\Gamma^{i,j}_{k,q} \\coloneqq \\Bigg[\\frac{i}{q}+\\frac{j}{kq}, \\frac{i}{q}+\\frac{j+1}{kq} \\Bigg) \\times \\left[0,1 \\right].\r\n\\end{equation*}\r\nHereby, we introduce the partition\r\n\\[\r\n\\zeta_{k,q} \\coloneqq \\Meng{\\Gamma^{i,j}_{k,q}}{0\\leq i<q, \\ 0\\leq j<k}.\r\n\\]\r\nUnder the assumption that $k$ is a multiple of $s$ we also use the following rectangles for $0\\leq i<q$, $0\\leq j< \\frac{k}{s}$, $0\\leq t <s$:\r\n\\[\r\nR^{i,j,t}_{q,k,s} \\coloneqq \\Bigg[\\frac{i}{q}+\\frac{j\\cdot s}{kq}, \\frac{i}{q}+\\frac{(j+1)\\cdot s}{kq}\\Bigg) \\times \\Bigg[\\frac{t}{s}, \\frac{t+1}{s}\\Bigg) =\\bigcup_{0\\leq u<s} \\Delta^{ik+js+u,t}_{kq,s}.\r\n\\]\r\nNotice that $\\mu(\\Gamma^{i,j}_{k,q})=\\mu(R^{i,j,t}_{q,k,s})$.\r\n\r\n\r\n\r\n\\subsection{Proof of Theorem \\ref{theo:cyclicUpper}}\r\nFor a start, we let $0<u<\\infty$. We choose a sequence $(\\epsilon_n)_{n\\in \\N}$ of quickly decreasing positive numbers satisfying\r\n\\begin{equation} \\label{eq:eps3}\r\n\\prod^{\\infty}_{n=1}(1-\\epsilon_n)>\\frac{1}{2}\r\n\\end{equation}\r\nand this time we fix $(s_n)_{n\\in\\N}$ as a strictly increasing sequence of positive integers from the beginning, where $s_n$ is a multiple of $s_{n-1}$. This will suffice to guarantee that $\\{\\eta_m=H_m\\left(\\xi_{k_mq_m,s_m}\\right)\\}_{m\\in \\N}$ is a generating sequence. Besides that, we follow our inductive scheme again. Assume that the parameter sequences $(k_m)_{m\\in\\N}$ and $(l_m)_{m\\in\\N}$ have been defined up to $m=n-1$, which also determines the number $q_n=k_{n-1}l_{n-1}q^2_{n-1}$. Moreover, we assume that $k_{n-1}$ is of the form $k_{n-1}=r_{n-1} \\cdot \\lfloor (r_{n-1})^{q_{n-1} u} \\rfloor$ with some $r_{n-1}\\in \\Z^+$.\r\nThen we apply Lemma \\ref{lem:prob} with subexponential sequence $\\{b_j\\}_{j\\in \\N} = \\{j^{uq_n}\\}_{j\\in \\N}$,\r\n\\[\r\n\\varepsilon = \\frac{r^2_{n-1}}{k^2_{n-1}},  \\ \\text{ and alphabet } \\Sigma =\\left\\{0,1,\\dots , \\frac{k_{n-1}}{r_{n-1}}-1\\right\\}.\r\n\\]\r\nAccordingly, we can choose a number $r_n \\in \\N$ as a multiple of $k_{n-1}$ as well as $s_n$ and sufficiently large such that $r_n \\geq \\frac{6}{\\epsilon_n}$ and there is a collection $\\Theta \\subset \\Sigma^{r_n}$ with $|\\Theta |= \\lfloor (r_n)^{q_n u} \\rfloor$ of \\emph{good words} of length $r_n$ satisfying properties (1) and (2) in Lemma \\ref{lem:prob}. In particular, property (2) yields for all $w,w' \\in \\Theta$ that\r\n\\begin{equation}\\label{Hamming3}\r\nd^H(w,w')\\geq 1-\\frac{2r_{n-1}}{k_{n-1}}.\r\n\\end{equation}\r\nThen we concatenate all these words from $\\Theta$ to obtain one word of length\r\n\\begin{equation} \\label{eq:k3}\r\nk_n \\coloneqq r_n \\cdot \\lfloor (r_n)^{q_n u} \\rfloor.\r\n\\end{equation}\r\nThis word $w=w_0 \\dots w_{k_n-1}$ determines an assignment\r\n\\begin{equation}\\label{eq:assignment1}\r\n\\psi_n:\\{0,1,\\dots ,k_n -1\\} \\to \\left\\{0,1,\\dots ,\\frac{k_{n-1}}{r_{n-1}} -1\\right\\}, \\ \\psi_n(j)=w_j.\r\n\\end{equation}\r\nWith it $h_n$ will be of the form\r\n\\begin{equation}\r\n\\begin{aligned}\r\n& h_n\\left(\\Gamma^{i,j}_{k_n,q_n}\\right) \\\\\r\n= & R^{i+\\psi_n(j)r_{n-1} l_{n-1}q_{n-1}, \\ \\lfloor \\frac{j}{s_n} \\rfloor ,\\ j \\mod s_n}_{q_n,k_n,s_n} \\\\\r\n= &  \\Bigg[\\frac{\\psi_n(j) \\cdot r_{n-1}}{k_{n-1}q_{n-1}}+\\frac{i}{q_n}+\\frac{\\lfloor \\frac{j}{s_n} \\rfloor \\cdot s_n}{k_nq_n}, \\frac{\\psi_n(j) \\cdot r_{n-1}}{k_{n-1}q_{n-1}}+\\frac{i}{q_n}+\\frac{\\left(\\lfloor \\frac{j}{s_n} \\rfloor+1\\right)\\cdot s_n}{k_nq_n}\\Bigg)\\\\& \\times \\Bigg[\\frac{j \\mod s_n}{s_n}, \\frac{j \\mod s_n +1}{s_n}\\Bigg),\r\n\\end{aligned}\r\n\\end{equation}\r\ni.e. descriptively speaking long stripes are mapped to rectangles. This will guarantee that the sequence of partitions $\\{H_n(\\zeta_{k_n,q_n})\\}_{n\\in \\N}$ is generating. We also note that the conjugation map $h_n$ of this form satisfies the required relation\r\n\\[\r\nh_n \\circ R_{\\frac{1}{q_n}} = R_{\\frac{1}{q_n}} \\circ h_n.\r\n\\]\r\n\r\nTo finalize the construction we set\r\n\\begin{equation}\\label{eq:l3}\r\nl_n= (r_n)^{q_n}.\r\n\\end{equation}\r\n\r\nThe combinatorics allows us to make the following observation with regard to the generating sequence $\\{\\eta_m=H_m\\left(\\xi_{k_mq_m,s_m}\\right)\\}_{m\\in \\N}$. It will prove useful when estimating the upper measure-theoretic slow entropy via the Proposition \\ref{prop:generatingSequence}:\r\n\\begin{lemma}\\label{lem:lower3}\r\n\tLet $0<\\varepsilon<\\frac{1}{2}$ and $m\\in \\N$. For $n>m$ we have\r\n$$S\\left(\\eta_m,r_nl_nq_n,\\varepsilon\\right)\\geq \\lfloor (r_n)^{q_n u}\\rfloor .$$\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tFor any $0\\leq i<q_n$ and $0\\leq j<k_{n}$ we define the set\r\n\t\\begin{equation*}\r\n\t\\overline{\\Gamma}^{i,j}_{k_n,q_n} \\coloneqq \\Gamma^{i,j}_{k_n,q_n} \\cap \\Xi_n.\r\n\t\\end{equation*}\r\n\tThen we note that for every $t\\leq q_{n+1}$ the images $T^t\\left(H_n\\left(\\overline{\\Gamma}^{i,j}_{k_n,q_n}\\right)\\right)$ and $T^t_n\\left(H_n\\left(\\overline{\\Gamma}^{i,j}_{k_n,q_n}\\right)\\right)$ lie in the same element $R^{i',j'}_{k_nq_n,s_n}$ by Remark \\ref{rem:safety}. The proof of our lemma follows from the following three claims:\r\n\\begin{claim}\\label{claim:1}\r\nLet $0\\leq i_1,i_2<q_{m+1}$, $0\\leq j_1,j_2 < \\frac{k_{m+1}}{r_{m+1}}$, and $0\\leq v<r_{m+1}$, then the points $P_1 \\in H_{m+1}\\left(\\overline{\\Gamma}^{i_1,j_1r_{m+1}+v}_{k_{m+1},q_{m+1}}\\right)$ and $P_2 \\in H_{m+1}\\left(\\overline{\\Gamma}^{i_2,j_2r_{m+1}+v}_{k_{m+1},q_{m+1}}\\right)$ with $j_1 \\neq j_2$ are $\\left(1-\\frac{3r_m}{k_{m}},q_{m+2}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$ and the map $T$.\r\n\\end{claim}\r\n\t\r\n\\begin{proof}\r\nSince $q_{m+2}= k_{m+1} l_{m+1} q^2_{m+1}$ the $\\{h_{m+1}\\circ R^t_{\\alpha_{m+2}}\\}_{t\\leq q_{m+2}}$ trajectory of such a set $H_{m+1}\\left(\\overline{\\Gamma}^{i,jr_{m+1}+v}_{k_{m+1},q_{m+1}}\\right)$ corresponds to $q_{m+1}$ times repeating a string of length $k_{m+1}=r_{m+1} \\cdot \\lfloor (r_{m+1})^{q_{m+1} u} \\rfloor$ in the alphabet $\\Sigma=\\{0,1,\\dots ,\\frac{k_{m}}{r_{m}} -1\\}$ describing the assignment $\\psi_{m+1}$ (see \\eqref{eq:assignment1}).\r\n\r\nWe divide this string into the words of length $r_{m+1}$ obtained by Lemma \\ref{lem:prob} where we ignore possible partial words at the beginning or end. Hereby, we ignore a proportion of symbols of at most $\\frac{2}{\\lfloor (r_{m+1})^{q_{m+1} u} \\rfloor } = \\frac{2r_{m+1}}{k_{m+1}}$. Under our assumption $j_1 \\neq j_2$ the aligned words are different from each other and we can exploit property (2) in Lemma \\ref{lem:prob} to see that in those words for every pair of $x,y \\in \\Sigma$ the frequency of $x$ and $y$ occurring aligned is at most $2\\left(\\frac{r_{m}}{k_{m}}\\right)^2$. This yields that with frequency at most $\\frac{3r_{m}}{k_{m}}$ our stripes $\\overline{\\Gamma}^{i_1,j_1r_{m+1}+v}_{k_{m+1},q_{m+1}}$ and $\\overline{\\Gamma}^{i_2,j_2r_{m+1}+v}_{k_{m+1},q_{m+1}}$ are mapped to the same $\\frac{r_{m}}{k_{m}q_{m}}$-domain $\\Big[\\frac{ir_{m}}{k_{m}q_{m}},\\frac{(i+1) r_{m}}{k_{m}q_{m}}\\Big)$, $i\\in \\mathbb{N}$, under $h_{m+1}\\circ R^t_{\\alpha_{m+2}}$, $t\\leq q_{m+2}$. Hence, $H_{m+1}\\left(\\overline{\\Gamma}^{i_1,j_1r_{m+1}+v}_{k_{m+1},q_{m+1}}\\right)$ and $H_{m+1}\\left(\\overline{\\Gamma}^{i_2,j_2r_{m+1}+v}_{k_{m+1},q_{m+1}}\\right)$ with $j_1 \\neq j_2$ are $\\left(1-\\frac{3r_{m}}{k_{m}},q_{m+2}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m=H_m\\left(\\xi_{k_{m}q_{m},s_{m}}\\right)$ and the map $T_{m+1}$. By our observation above this also holds true for the map $T$.\r\n\\end{proof}\r\n\r\n\t\t\r\n\\begin{claim}\\label{claim:2}\r\nLet $n>m$. Moreover, let $0\\leq i_1,i_2<q_n$, $0\\leq j_1,j_2 < \\frac{k_n}{r_n}$, and $0\\leq v<r_n$. Suppose that either $j_1 <j_2$ and $i_2=i_1$ or $j_2<j_1$ and $i_2=i_1+1 \\mod q_n$, then the points $P_1 \\in H_n\\left(\\overline{\\Gamma}^{i_1,j_1r_n+v}_{k_n,q_n}\\right)$ and $P_2 \\in H_n\\left(\\overline{\\Gamma}^{i_2,j_2r_n+v}_{k_n,q_n}\\right)$ are $\\left(\\prod^{n-1}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right),q_{n+1}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$ and the map $T$.\r\n\\end{claim}\r\n\t\r\n\\begin{proof}\r\nWe show this by induction. The base clause $n=m+1$ follows from Claim \\ref{claim:1}. In the inductive step, we suppose that for some $n>m$ points from $H_n\\left(\\overline{\\Gamma}^{i_1,j_1r_n+v}_{k_n,q_n}\\right)$ and $H_n\\left(\\overline{\\Gamma}^{i_2,j_2r_n+v}_{k_n,q_n}\\right)$, respectively, with $j_1 < j_2$ and $i_2=i_1$ or $j_2<j_1$ and $i_2=i_1+1 \\mod q_n$ are $\\left(\\prod^{n-1}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right),q_{n+1}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$. Then we consider the sets $A_1 \\coloneqq \\overline{\\Gamma}^{i^{\\prime}_1,j^{\\prime}_1r_{n+1}+v^{\\prime}}_{k_{n+1},q_{n+1}}$ and $A_2 \\coloneqq \\overline{\\Gamma}^{i^{\\prime}_2,j^{\\prime}_2r_{n+1}+v^{\\prime}}_{k_{n+1},q_{n+1}}$ with $j^{\\prime}_1 < j^{\\prime}_2$ and $i^{\\prime}_2=i^{\\prime}_1$ (the case $j^{\\prime}_2 < j^{\\prime}_1$ and $i^{\\prime}_2=i^{\\prime}_1+1 \\mod q_{n+1}$ follows analogously).\r\n\r\nThen for at most $\\frac{2q_{n+2}}{l_n}$ many $t\\leq q_{n+2}$ we have that $h_{n+1}\\circ R^t_{\\alpha_{n+2}}(A_1)$ or $h_{n+1}\\circ R^t_{\\alpha_{n+2}}(A_2)$ do not lie in the safe domain of $h_n$. For at most $k_nq_n\\cdot \\frac{q_{n+2}}{q_{n+1}}$ many iterates (which corresponds to a proportion of $\\frac{1}{l_{n}q_n}$) the images of $A_1$ and $A_2$ under $h_{n+1} \\circ R^t_{\\alpha_{n+2}}$, $t\\leq q_{n+2}$, do not lie in the same domain modulo $\\frac{r_n}{k_nq_n}$. On the remaining iterates we use the second property in Lemma \\ref{lem:prob} again and follow the argument from Claim \\ref{claim:1} to see that with frequency at most $\\frac{3r_{n}}{k_{n}}$ these stripes are mapped into the same $\\frac{r_n}{k_{n}q_{n}}$-domain under $h_{n+1}\\circ R^t_{\\alpha_{n+2}}$, $t\\leq q_{n+2}$.  By the induction assumption this yields that for the map $T_{n+1}$, the points from $H_{n+1}\\left(A_1\\right)$ and $H_{n+1}\\left(A_2 \\right)$, respectively, are $\\left(\\prod^{n}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right),q_{n+2}\\right)$-Hamming apart from each other with respect to the partition $\\eta_m$. By the initial observation this also holds true under the map $T$.\r\n\\end{proof}\r\n\t\r\n\t\r\n\\begin{claim}\r\nPoints from different $H_n\\left(\\overline{\\Gamma}^{0,j\\cdot r_n}_{k_n,q_n}\\right)$ with $0\\leq j <\\lfloor (r_n)^{q_n} \\rfloor$ are  $$\\left(\\prod^{n}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right),r_nl_nq_n\\right)$$-Hamming apart from each other with respect to the partition $\\eta_m$.\r\n\\end{claim}\t\r\n\\begin{proof}\r\nBy the second property of Lemma \\ref{lem:prob} describing the assignment $\\psi_n$ and, hence, the combinatorics of $h_n$ we have that for different $\\overline{\\Gamma}^{0,j\\cdot r_n}_{k_n,q_n}$ a proportion of at most $\\frac{2r_{n-1}}{k_{n-1}}$ of the iterates $h_{n}\\circ R^t_{\\alpha_{n+1}}$, $t\\leq r_nl_nq_n$, is mapped into the same $\\frac{r_{n-1}}{k_{n-1}q_{n-1}}$ domain. Using Claim \\ref{claim:2} this yields that for the map $T_n$ the points from different $H_n\\left(\\overline{\\Gamma}^{0,j\\cdot r_n}_{k_n,q_n}\\right)$ are $\\left(\\prod^{n}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right),r_nl_nq_n\\right)$-Hamming apart from each other. By the initial observation this also holds true under the map $T$ since $r_nl_nq_n <q_{n+1}$.\r\n\\end{proof}\r\n\t\r\n\tFinally, we note that $\\prod^{\\infty}_{i=m}\\left(1-\\frac{3r_i}{k_{i}}-\\frac{3}{l_i}\\right)>\\prod^{\\infty}_{i=m}\\left(1-\\epsilon_i\\right)>\\varepsilon$ by assumption (\\ref{eq:eps3}).\r\n\\end{proof}\r\n\r\nThen we also check that our limit transformation $T=\\lim_{n\\to \\infty} T_n$ admits a good cyclic approximation.\r\n\\begin{lemma}\\label{lem:goodcyclic}\r\n\tSuppose $\\sum_{n\\in \\N}\\frac{1}{l_n} < \\infty$ and that the conjugation map $h_n$ is of the form $h_n\\left(\\Gamma^{i,j}_{k_n,q_n}\\right)\r\n\t= R^{i+\\psi_n(j)r_{n-1} l_{n-1}q_{n-1}, \\ \\lfloor \\frac{j}{s_n} \\rfloor ,\\ j \\mod s_n}_{q_n,k_n,s_n}$. Then the limit transformation $T=\\lim_{n\\to \\infty} T_n$ admits a good cyclic approximation.\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tWe recall that under the given form of the conjugation map $h_n$ the sequence of partitions $\\{H_n(\\zeta_{k_n,q_n})\\}_{n\\in \\N}$ is generating. We compute the weak distance between $T$ and $T_n$ with respect to the partition $H_n(\\zeta_{k_n,q_n})$:\r\n\t\\begin{align*}\r\n\tq_{n+1} \\cdot d\\left(H_n(\\zeta_{k_n,q_n}),T,T_n\\right) & = q_{n+1} \\cdot \\sum_{c\\in \\zeta_{k_n,q_n}} \\mu\\left(T(H_n(c))\\triangle T_n(H_n(c))\\right) \\\\\r\n\t& \\leq q_{n+1} \\cdot \\sum_{i=n+1}^{\\infty}\\sum_{\\tilde{c}\\in \\xi_{k_iq_i,s_i}} \\mu\\left(R_{\\alpha_{i+1}-\\alpha_i}(\\tilde{c})\\triangle \\tilde{c}\\right) \\\\\r\n\t& \\leq q_{n+1} \\cdot \\sum_{i=n+1}^{\\infty}\\frac{1}{l_{i}q_{i}} < \\sum_{i=n+1}^{\\infty}\\frac{1}{l_{i}}\r\n\t\\end{align*}\r\n\tSince this goes to $0$ as $n\\to \\infty$, this suffices to conclude the weak convergence of the cyclic approximation $(H_n(\\zeta_{k_n,q_n}),T_n)$ to the limit transformation $T$. We also obtain that the speed of convergence is of the order $o(\\frac{1}{q})$, i.e. we have a good cyclic approximation.\r\n\\end{proof}\r\n\r\n\\begin{remark}\\label{rem:cyclicCrit}\r\n\tWe note that proof and conclusion of Lemma \\ref{lem:goodcyclic} do not depend on the exact combinatorics of the assignment $\\psi_n:\\{0,1,\\dots ,k_n -1\\} \\to \\left\\{0,1,\\dots ,\\frac{k_{n-1}}{r_{n-1}} -1\\right\\}$.\r\n\\end{remark}\r\n\r\nNow we are ready to compute the upper slow entropy\r\n\r\n\\begin{lemma}\r\n\tWe have $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{lemma}\t\r\n\r\n\\begin{proof}\r\n\tOn the one hand, we see with the aid of Lemma \\ref{lem:lower3} that\r\n\t\\begin{equation*}\r\n\t\\limsup_{N\\to \\infty} \\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t} \\geq \\limsup_{n\\to \\infty} \\frac{S\\left(\\eta_m,r_nl_nq_n,\\varepsilon\\right)}{\\left(r_nl_nq_n\\right)^t}  \\geq \\lim_{n\\to \\infty} \\frac{\\lfloor (r_n)^{q_n u}\\rfloor}{\\left((r_n)^{q_n +1}\\cdot q_n\\right)^t},\r\n\t\\end{equation*}\r\n\twhich is positive for all $t<u$. This yields $\\uent^{\\mu}_{n^t}(T)\\geq u$.\r\n\t\r\n\tOn the other hand, Lemma \\ref{lem:upper1} still holds true since its proof was independent of the combinatorics of $h_n$ as observed in Remark \\ref{rem:IndepCombi}. This implies that\r\n\\begin{equation}\r\n\\begin{aligned}\r\n\\limsup_{L\\to \\infty} \\frac{S\\left(\\eta_m,L,\\varepsilon\\right)}{L^t}&\\leq\r\n\t\\limsup_{L\\to \\infty} \\frac{N\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} \\leq \\lim_{n\\to \\infty} \\frac{\\frac{2}{\\varepsilon^2}k_n q_n s_n}{\\left(\\frac{\\varepsilon}{2} l_{n}q_{n}\\right)^t}  \\\\&\\leq \\lim_{n\\to \\infty} \\frac{2^{t+1}\\cdot \\lfloor (r_n)^{q_nu} \\rfloor \\cdot r_n \\cdot q_n \\cdot s_n}{\\varepsilon^{t+2} \\cdot (r_n)^{q_nt} \\cdot q^{t}_n},\r\n\\end{aligned}\r\n\\end{equation}\r\nwhich is zero for all $t> u$. Altogether, we obtain $\\uent^{\\mu}_{n^t}(T)=u$.\r\n\\end{proof}\r\n\r\nThe case of a transformation with good cyclic approximation and $\\uent^{\\mu}_{n^t}(T)=\\infty$ is covered by the subsequent more general theorem.\r\n\r\n\\begin{theorem} \\label{theo:CyclicInfinity}\r\n\tFor any scaling function $\\{a_n(t)\\}_{n\\in\\mathbb{N},t>0}$ satisfying $\\lim_{n\\to+\\infty}\\frac{\\log a_n(t)}{n}=0$, there exists a Lebesgue measure preserving  transformation $T$ with good cyclic approximation and $\\uent_{a_n(t)}^{\\mu}(T)=\\infty$.\r\n\\end{theorem}\r\n\r\n\\begin{proof}\r\n\tAs before, we fix $(s_n)_{n\\in\\N}$ as a strictly increasing sequence of positive integers from the beginning, where $s_n$ is a multiple of $s_{n-1}$. We also set $l_n=n^2$ which yields that the limit transformation admits a good cyclic approximation by Lemma \\ref{lem:goodcyclic}. Additionally, we fix a strictly increasing sequence $(u_n)_{n\\in \\N}$ of positive integers. Besides that, we follow our inductive scheme again.\r\n\t\r\n\tAssume that the parameter sequence $(k_m)_{m\\in\\N}$ has been defined up to $m=n-1$, which also determines the number $q_n=k_{n-1}l_{n-1}q^2_{n-1}$. Moreover, we assume that $k_{n-1}$ is of the form $k_{n-1}=r_{n-1} \\cdot \\lfloor a_{r_{n-1}l_{n-1}q_{n-1}}(u_{n-1}) \\rfloor$ with some $r_{n-1}\\in \\Z^+$. Then we apply Lemma \\ref{lem:prob} with subexponential sequence $\\{b_j\\}_{j\\in \\N}=\\{a_{jl_{n}q_{n}}(u_n)\\}_{j\\in \\N}$,\r\n\t\\[\r\n\t\\varepsilon = \\frac{r^2_{n-1}}{k^2_{n-1}}, \\ \\text{ and alphabet } \\Sigma =\\left\\{0,1,\\dots , \\frac{k_{n-1}}{r_{n-1}}-1\\right\\}.\r\n\t\\]\r\n\tAccordingly, we can choose a number $r_n \\in \\N$ as a multiple of $k_{n-1}$ as well as $s_n$ and sufficiently large such that $r_n \\geq \\frac{6}{\\epsilon_n}$ and there is a collection $\\Theta \\subset \\Sigma^{r_n}$ with $|\\Theta |= \\lfloor a_{r_nl_{n}q_{n}}(u_n) \\rfloor$ of \\emph{good words} of length $r_n$ satisfying properties (1) and (2) in Lemma \\ref{lem:prob}. Then we concatenate all these words from $\\Theta$ to obtain one word of length\r\n\t\\begin{equation}\r\n\tk_n \\coloneqq r_n \\cdot \\lfloor a_{r_nl_{n}q_{n}}(u_n) \\rfloor.\r\n\t\\end{equation}\r\n\tThis accomplishes the inductive step.\r\n\t\r\n\tFinally, we compute with the aid of Lemma \\ref{lem:lower3} that\r\n\t\\begin{equation*}\r\n\t\\limsup_{N\\to \\infty} \\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{a_N(t)} \\geq \\limsup_{n\\to \\infty} \\frac{S\\left(\\eta_m,r_nl_nq_n,\\varepsilon\\right)}{a_{r_nl_nq_n}(t)}  \\geq \\lim_{n\\to \\infty} \\frac{\\lfloor a_{r_nl_{n}q_{n}}(u_n)\\rfloor}{a_{r_nl_nq_n}(t)},\r\n\t\\end{equation*}\r\n\twhich is positive for all $t \\leq u_n$. Since $u_n \\to \\infty$ as $n\\to \\infty$, this yields $\\uent^{\\mu}_{a_n(t)}(T) = \\infty$.\r\n\\end{proof}\r\n\r\n\\subsection{Proof of Theorem \\ref{theo:cyclicLower}}\r\nWe fix $0<u\\leq 1$ and choose a sequence $(\\epsilon_n)_{n\\in \\N}$ of quickly decreasing positive numbers satisfying (\\ref{eq:eps3}). Moreover, we choose a strictly increasing sequence $(s_n)_{n\\in\\N}$ of positive integers, where $s_n$ is a multiple of $s_{n-1}$. The parameter sequences $(k_m)_{m\\in\\N}$ and $(l_m)_{m\\in\\N}$ are defined inductively. Assume that they have been defined up to $m=n-1$. At this juncture, we assume that $k_{n-1}$ is of the form $k_{n-1}= (r_{n-1})^{q_{n-1}+1}$ with some $r_{n-1}\\in \\Z$ satisfying $r_{n-1} \\geq K_1\\left(\\{k^{q_{n-1}}\\}_{k \\in \\N},\\frac{k_{n-2}}{r_{n-2}},\\left(\\frac{r_{n-2}}{k_{n-2}}\\right)^2\\right)$, where we recall its definition from Remark \\ref{rem:kForCLT}.\r\n\r\nIn the inductive step, we set\r\n\\begin{equation} \\label{eq:l4}\r\nl_n = \\lfloor (r_{n-1})^{(q_{n-1}+1)\\cdot \\frac{1-u}{u}} \\cdot \\frac{6}{\\epsilon_n} \\rfloor.\r\n\\end{equation}\r\nWe apply Lemma \\ref{lem:prob2} with subexponential sequences $\\{b_k\\}_{k\\in \\N} = \\{k^{q_{n-1}}\\}_{k \\in \\N}$, $\\{c_k\\}_{k \\in \\N} = \\{ k^{q_n}\\}_{k \\in \\N}$,\r\n\\[\r\ns=\\frac{k_{n-2}}{r_{n-2}},  \\ \\ \\varepsilon=\\left(\\frac{r_{n-1}}{k_{n-1}}\\right)^2, \\ \\text{ and alphabet } \\Sigma=\\left\\{0,1,\\dots, \\frac{k_{n-1}}{r_{n-1}} -1\\right\\}.\r\n\\]\r\nLet $L_0$ be the resulting threshold. Then we choose\r\n\\begin{equation}\\label{eq:r4}\r\nr_n \\geq \\max\\left( L_0 , K_1\\left(\\{k^{q_n}\\}_{k \\in \\N},\\frac{k_{n-1}}{r_{n-1}},\\left(\\frac{r_{n-1}}{k_{n-1}}\\right)^2\\right),\\frac{4}{\\epsilon_{n}}\\right)\r\n\\end{equation}\r\nas a multiple of $k_{n-1}$ and $s_{n}$. Hereby, we set\r\n\\begin{equation} \\label{eq:k4}\r\nk_n \\coloneqq  (r_n)^{q_n+1}.\r\n\\end{equation}\r\nWe also denote the corresponding value of $\\gamma$ from Lemma \\ref{lem:prob2} by $\\gamma_n$. Moreover, the collection of words $\\Theta$ constructed in Lemma \\ref{lem:prob2} determines the assignment\r\n\\begin{equation}\\label{eq:assignment2}\r\n\\psi_n:\\{0,1,\\dots ,k_n -1\\} \\to \\left\\{0,1,\\dots ,\\frac{k_{n-1}}{r_{n-1}} -1\\right\\}\r\n\\end{equation}\r\nand, hence, the combinatorics of the conjugation map $h_n$ of the form\r\n\\begin{equation*}\r\nh_n\\left(\\Gamma^{i,j}_{k_n,q_n}\\right) = R^{i+\\psi_n(j)r_{n-1} l_{n-1}q_{n-1}, \\ \\lfloor \\frac{j}{s_n} \\rfloor ,\\ j \\mod s_n}_{q_n,k_n,s_n}.\r\n\\end{equation*}\r\nThis finishes the construction in the inductive step.\r\n\r\nTaking this combinatorics into account we make the following observation with regard to the generating sequence $\\{\\eta_m=H_m\\left(\\xi_{k_mq_m,s_m}\\right)\\}_{m\\in \\N}$.\r\n\r\n\\begin{lemma}\\label{lem:lower4}\r\n\tLet $0<\\varepsilon <\\frac{1}{2}$ and $m\\in \\N$. For $n>m$ we have\r\n$$\tS\\left(\\eta_{m},N,\\varepsilon\\right)\\geq\\begin{cases}\r\n\t\\frac{k_{n-1}}{r_{n-1}} & \\text{for }q_{n}\\leq N<r_{n-1}l_{n}q_{n},\\\\\r\n\tj^{q_{n-1}} & \\text{for }jl_{n}q_{n}\\leq N<(j+1)l_nq_n,\\text{ where } r_{n-1}\\leq j <\\gamma_{n}r_{n},\\\\\r\n\t(r_n)^{q_n}  & \\text{for }\\gamma_{n}r_{n}l_{n}q_{n}\\leq N<k_{n}l_{n}q_{n}^{2}=q_{n+1}.\r\n\t\\end{cases}\r\n$$\r\n\\end{lemma}\r\n\r\n\\begin{proof}\r\n\tAs in the proof of Lemma \\ref{lem:lower3} we define the sets\r\n\t\\begin{equation*}\r\n\t\\overline{\\Gamma}^{i,j}_{k_n,q_n} \\coloneqq \\Gamma^{i,j}_{k_n,q_n} \\cap \\Xi_n\r\n\t\\end{equation*}\r\n\tand recall that for every $t\\leq q_{n+1}$ the images $T^t\\left(H_n\\left(\\overline{\\Gamma}^{i,j}_{k_n,q_n}\\right)\\right)$ and $T^t_n\\left(H_n\\left(\\overline{\\Gamma}^{i,j}_{k_n,q_n}\\right)\\right)$ lie in the same element $R^{i',j'}_{k_nq_n,s_n}$ by Remark \\ref{rem:safety}. By the same methods as in the proof of Lemma \\ref{lem:lower3} we can show that Claim \\ref{claim:1} and Claim \\ref{claim:2} also hold true in our new setting (instead of property (2) from Lemma \\ref{lem:prob} one uses part (2) of Lemma \\ref{lem:prob2}). Then Lemma \\ref{lem:prob2} also determines the Hamming-distance of $\\{h_n \\circ R^t_{\\alpha_{n+1}}\\}_{t\\leq q_{n+1}}$-trajectories of different $H_n\\left(\\overline{\\Gamma}^{0,j\\cdot r_n}_{k_n,q_n}\\right)$ with $0\\leq j <(r_n)^{q_n}$. An analysis like in the proof of Lemma \\ref{lem:lower2} yields the statement.\t\r\n\\end{proof}\r\n\r\n\\begin{proof}[Proof of Theorem \\ref{theo:cyclicLower}]\r\n\tFrom Lemma \\ref{lem:goodcyclic} and the accompanying Remark \\ref{rem:cyclicCrit} we conclude that our transformation $T=\\lim_{n\\to \\infty} T_n$ admits a good cyclic approximation.\r\n\t\r\n\tTo get a lower bound on $\\lent^{\\mu}_{n^t}(T)$ we investigate\r\n$$\\liminf_{N\\to \\infty} \\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}$$\r\n\tby examining the three different cases in the statement of Lemma \\ref{lem:lower4}. In case of $q_n \\leq N<r_{n-1}l_nq_n$ we see\r\n\t\\begin{align*}\r\n\t\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t} &\\geq \\frac{\\frac{k_{n-1}}{r_{n-1}}}{\\left(r_{n-1}l_nq_n\\right)^t} \\\\\r\n\t& \\geq  \\frac{(r_{n-1})^{q_{n-1}}}{\\left(r_{n-1} \\cdot \\frac{6}{\\epsilon_n} \\cdot  (r_{n-1})^{(q_{n-1}+1)\\cdot \\frac{1-u}{u}}\\cdot (r_{n-1})^{q_{n-1}+1} \\cdot l_{n-1}\\cdot q^2_{n-1}\\right)^t} \\\\\r\n\t& =  \\frac{\\epsilon^t_n \\cdot (r_{n-1})^{q_{n-1}}}{\\left(6 \\cdot (r_{n-1})^{(q_{n-1}+1)\\cdot \\frac{1}{u}+1} \\cdot l_{n-1}\\cdot q^2_{n-1}\\right)^t},\r\n\t\\end{align*}\r\n\twhose limit is positive for all $t<u$. Similarly, for $jl_{n}q_{n}\\leq N<(j+1)l_nq_n$, where $r_{n-1}\\leq j <\\gamma_{n}r_{n}$ and $u\\in[0,1]$, we have\r\n\t\\[\r\n\t\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}\\geq \\frac{j^{q_{n-1}}}{\\left((j+1)l_nq_n\\right)^t} \\geq \\frac{j^{u} \\cdot (r_{n-1})^{q_{n-1}-1}} {\\left((j+1)\\cdot \\frac{6}{\\epsilon_n} \\cdot (r_{n-1})^{(q_{n-1}+1)\\cdot \\frac{1}{u}}\\cdot l_{n-1} \\cdot q^2_{n-1}\\right)^t},\r\n\t\\]\r\n\twhose limit is also positive for all $t<u$. In the remaining case $\\gamma_n r_n l_nq_n \\leq N <q_{n+1}$ we have\r\n\t\\[\t\\frac{S\\left(\\eta_m,N,\\varepsilon\\right)}{N^t}\\geq \\frac{(r_n)^{q_n}}{\\left(k_n l_nq^2_n\\right)^t} \\geq \\frac{(r_n)^{q_n}} {\\left((r_n)^{q_n+1}\\cdot l_n \\cdot q^2_n\\right)^t},\r\n\t\\]\r\n\twhich is positive for all $t\\leq 1$. Altogether, this yields $\\lent^{\\mu}_{n^t}(T)\\geq u$.\r\n\t\r\n\tOn the other hand, Lemma \\ref{lem:upper1} still holds true since its proof was independent of the combinatorics of $h_n$ as observed in Remark \\ref{rem:IndepCombi}. This implies that\r\n\t\\begin{align*}\r\n\t\\liminf_{L\\to \\infty} \\frac{S\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} & \\leq\\liminf_{L\\to \\infty} \\frac{N\\left(\\eta_m,L,\\varepsilon\\right)}{L^t} \\leq \\lim_{n\\to \\infty} \\frac{\\frac{2}{\\varepsilon^2}k_n q_n s_n}{\\left(\\frac{\\varepsilon}{2} l_{n+1}q_{n+1}\\right)^t}  \\\\\r\n\t& \\leq \\lim_{n\\to \\infty} \\frac{2 \\cdot \\epsilon^t_{n+1} \\cdot (r_n)^{q_n+1} \\cdot q_n \\cdot s_n }{\\varepsilon^{t+2} \\cdot\\left((r_n)^{(q_n+1)\\cdot \\frac{1-u}{u}} \\cdot (r_n)^{q_n+1} \\cdot  l_{n} \\cdot q^2_n\\right)^t} \\\\\r\n\t& \\leq \\lim_{n\\to \\infty} \\frac{2 \\cdot \\epsilon^t_{n+1} \\cdot (r_n)^{q_n+1} \\cdot q_n \\cdot s_n }{\\varepsilon^{t+2} \\cdot\\left( (r_n)^{(q_n+1)\\cdot \\frac{1}{u}} \\cdot l_{n} \\cdot q^2_n\\right)^t},\r\n\t\\end{align*}\r\n\twhich is zero for all $t> u$.\r\n\t\r\n\tOverall, we obtain $\\lent^{\\mu}_{n^t}(T)=u$.\r\n\\end{proof}\r\n\r\n\\begin{thebibliography}{9}\r\n\\bibitem[App]{Adams} T. Adams, {\\it Generic transformations have zero lower slow entropy and infinite upper slow entropy}, Preprint, arXiv:2006.15462.\r\n\\bibitem[ADP10]{ADP} Y. Ahn, D. Dou, K. K. Park, {\\it Entropy dimension and variational principle}, Studia Math. 199 (2010), no. 3, 295--309.\r\n\\bibitem[AK70]{AK} D. V. Anosov, A. Katok, {\\it New examples in smooth ergodic theory. Ergodic diffeomorphisms}, Trudy Moskov. Mat. Obsc. 23 (1970), 3--36.\r\n\\bibitem[BKWpp]{BKW} S. Banerjee, P. Kunde, D. Wei, {\\it Slow entropy for some Anosov-Katok diffeomorphisms}, In preparation.\r\n\\bibitem[CKpp]{CK} V. Cyr, B. Kra {\\it Realizing ergodic properties in zero entropy subshifts}\r\n    Preprint, arXiv:1902.08645.\r\n\\bibitem[C97]{Carvalho} M. de Carvalho, {\\it Entropy dimension of dynamical systems}, Portugal. Math. 54 (1997), no. 1, 19--40.\r\n\\bibitem[Cha69]{Chacon} R. V. Chacon, {\\it Weakly mixing transformations which are not strongly mixing}, Proc. Amer. Math. Soc. 22 (1969), 559--562.\r\n\\bibitem[DHP11]{DouHuangPark} D. Dou, W. Huang, K. K. Park, {\\it Entropy dimension of topological dynamical systems}, Trans. Amer. Math. Soc. 363 (2011), no. 2, 659--680.\r\n%\\bibitem[DHP19]{DouHuangPark2} D. Dou, W. Huang, K. K. Park, {\\it Entropy dimension of measure preserving systems}, (English summary) Trans. Amer. Math. Soc. 371 (2019), no. 10, 7029--7065.\r\n\\bibitem[FK04]{FK} B. Fayad, A. Katok, {\\it Constructions in elliptic dynamics}, Ergodic Theory Dynam Systems 24 (2004), 1477--1520.\r\n\\bibitem[Fer97S]{Ferenczirank} S. Ferenczi, {\\it Systems of finite rank}, Colloq. Math. 73 (1997), no. 1, 35--65.\r\n\\bibitem[Fer97M]{Fe} S. Ferenczi, {\\it Measure-theoretic complexity of ergodic systems}, Israel J. Math. 100 (1997), 189--207.\r\n%\\bibitem[Fer99]{Ferenczi2} S. Ferenczi, {\\it Complexity of sequences and dynamical systems}, Combinatorics and number theory (Tiruchirapalli, 1996). Discrete Mathematics 206 (1999), no.~1--3, 145--154.\r\n\\bibitem[FP07]{FerencziPark} S. Ferenczi, K. K. Park, {\\it Entropy dimensions and a class of constructive examples}, Discrete Contin. Dyn. Syst. 17 (2007), no. 1, 133--141.\r\n\\bibitem[FRW11]{FRW} M. Foreman, D. Rudolph, B.Weiss, {\\it The conjugacy problem in ergodic theory}, Ann. of Math. (2) 173 (2011), no. 3, 1529--1586.\r\n\\bibitem[FW19]{FW1} M. Foreman, B. Weiss, {\\it A symbolic representation for Anosov-Katok Systems}, Journal d'Analyse Mathematique 137 (2019), no. 2, 603--661.\r\n\\bibitem[F70]{Fried} N. Friedman, {\\it Introduction to Ergodic Theory}, Van Nostrand Reinhold, New York, 1970.\r\n\\bibitem[FW78]{FuWe} H. Furstenberg, B. Weiss, {\\it The finite multipliers of infinite ergodic transformations}, Lecture Notes in Math., 668, Springer, Berlin, 1978.\r\n\\bibitem[G74]{Goodman} T. N. T. Goodman, {\\it Topological sequence entropy}, Proc. London Math. Soc. (3) 29 (1974), 331--350.\r\n\\bibitem[HN42]{HN} P. Halmos, J. von Neumann, {\\it Operator methods in classical mechanics. II}, Ann. of Math. (2) 43 (1942), 332--350.\r\n\\bibitem[HKM14]{HKM} B. Host, B. Kra, A. Maass, {\\it Complexity of nilsystems and systems lacking nilfactors}, J. Anal. Math. 124 (2014), 261--295.\r\n%\\bibitem[HLSY03]{HLSY}  W. Huang, S. M. Li, S. Shao, X. Ye, {\\it Null systems and sequence entropy pairs}, (English summary) Ergodic Theory Dynam. Systems 23 (2003), no. 5, 1505--1523.\r\n\\bibitem[HSY05]{HuangShaoYe} W. Huang, S. Shao, X. Ye, {\\it Mixing via sequence entropy}, Algebraic and topological dynamics, 101--122, Contemp. Math., 385, Amer. Math. Soc., Providence, RI, 2005.\r\n\\bibitem[H82]{Hulse} P. Hulse, {\\it Sequence entropy and subsequence generators}, J. London Math. Soc. (2) 26 (1982), no. 3, 441--450.\r\n\\bibitem[Kan18]{Kanigowski} A. Kanigowski, {\\it Slow entropy for some smooth flows on surfaces}, Israel J. Math. 226 (2018), no. 2, 535--577.\r\n\\bibitem[KKWpp]{KanigowskiKatokWei} A. Kanigowski, A. Katok, D. Wei, {\\it Survey on entropy-type invariants of sub-exponential growth in dynamical systems}, Preprint, arXiv:2004.04655.\r\n\\bibitem[KKVWpp]{KanigowskiKundeVinhageWei} A. Kanigowski, P. Kunde, K. Vinhage, D. Wei, {\\it Slow entropy of higher rank abelian unipotent actions}, Preprint, arXiv:2005.02212.\r\n\\bibitem[KVW19]{KanigowskiVinhageWei} A. Kanigowski, K. Vinhage, D. Wei, {\\it Slow entropy of some parabolic flows}, Comm. Math. Phys. 370 (2019), no. 2, 449--474.\r\n\\bibitem[KS67]{KS} A. Katok, A. Stepin, {\\it Approximations in ergodic theory}, Uspehi Mat. Nauk 22 (1967), 81--106.\r\n\\bibitem[K77]{K77} A. Katok, {\\it Monotone equivalence in ergodic theory}, Mathematics of the USSR-Izvestiya 11 (1977), no. 1, 99--146.\r\n\\bibitem[KT97]{KatokThou} A. Katok, J.-P. Thouvenot, {\\it Slow entropy type invariants and smooth realization of commuting measure-preserving transformations}, Ann. Inst. H. Poincar\\'{e} Probab. Statist. 33 (1997), no. 3, 323--338.\r\n\\bibitem[K03]{K} A. Katok, {\\it Combinatorial constructions in ergodic theory and dynamics}, University Lecture Series, 30. American Mathematical Society, Providence, RI, 2003. ISBN: 0-8218-3496-7\r\n\\bibitem[Kpp]{Ksurvey} P. Kunde, {\\it On the smooth realization problem and the AbC method}, Preprint.\r\n\\bibitem[K67]{Kushnirenko} A. G. Kushnirenko, {\\it Metric invariants of entropy type}, Uspekhi Mat. Nauk, 22:5(137) (1967), 57--65.\r\n\\bibitem[N32]{Ne} J. von Neumann, {\\it Zur Operatorenmethode in der klassischen Mechanik}, Ann. of Math. (2) 33 (1932), no. 3, 587--642.\r\n\\bibitem[O70]{Or} D. Ornstein, {\\it Bernoulli shifts with the same entropy are isomorphic}, Advances in Math. 4 (1970), 337--352.\r\n\\end{thebibliography}\r\n\\end{document}", "meta": {"timestamp": "2020-10-28T00:31:35", "yymm": "2010", "arxiv_id": "2010.14472", "url": "https://arxiv.org/abs/2010.14472", "source": "arxiv"}}
